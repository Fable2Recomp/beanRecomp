#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_820CA5A0"))) PPC_WEAK_FUNC(sub_820CA5A0);
PPC_FUNC_IMPL(__imp__sub_820CA5A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f29.u64);
	// stfd f30,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, f30.u64);
	// stfd f31,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
	// fmr f30,f2
	f30.f64 = ctx.f2.f64;
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// bl 0x82110d08
	sub_82110D08(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lfs f0,14020(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14020);
	f0.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// fsubs f13,f0,f31
	ctx.f13.f64 = double(float(f0.f64 - f31.f64));
	// lwz r3,428(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,13980(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13980);
	f0.f64 = double(temp.f32);
	// fmuls f29,f13,f0
	f29.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x820ce1f0
	sub_820CE1F0(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// addi r9,r11,428
	ctx.r9.s64 = r11.s64 + 428;
	// lwz r10,428(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// lfs f0,1460(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1460);
	f0.f64 = double(temp.f32);
	// lwz r29,8(r10)
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// stfs f0,1328(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1328, temp.u32);
	// lfs f0,1464(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1464);
	f0.f64 = double(temp.f32);
	// stfs f0,1332(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1332, temp.u32);
	// lfs f0,1468(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1468);
	f0.f64 = double(temp.f32);
	// stfs f0,1336(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1336, temp.u32);
	// lfs f0,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,12(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 12, temp.u32);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,16(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 16, temp.u32);
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,20(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 20, temp.u32);
	// beq cr6,0x820ca650
	if (cr6.getEQ()) goto loc_820CA650;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r28,24(r11)
	PPC_STORE_U32(r11.u32 + 24, r28.u32);
loc_820CA650:
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f29.f64;
	// lwz r3,28(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,20(r29)
	PPC_STORE_U32(r29.u32 + 20, r11.u32);
	// bl 0x82119178
	sub_82119178(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r3,28(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// lwz r11,428(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// addi r4,r11,12
	ctx.r4.s64 = r11.s64 + 12;
	// bl 0x82119118
	sub_82119118(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8211e6f8
	sub_8211E6F8(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f0.f64 = double(temp.f32);
	// li r4,1
	ctx.r4.s64 = 1;
	// stfs f0,1460(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1460, temp.u32);
	// stw r28,1456(r11)
	PPC_STORE_U32(r11.u32 + 1456, r28.u32);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,1464(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1464, temp.u32);
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,1468(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1468, temp.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f31,596(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 596, temp.u32);
	// lwz r3,428(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// stfs f30,612(r11)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r11.u32 + 612, temp.u32);
	// bl 0x820ce1f0
	sub_820CE1F0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f30,-56(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820CA6D0"))) PPC_WEAK_FUNC(sub_820CA6D0);
PPC_FUNC_IMPL(__imp__sub_820CA6D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f29.u64);
	// stfd f30,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, f30.u64);
	// stfd f31,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
	// fmr f30,f2
	f30.f64 = ctx.f2.f64;
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// bl 0x82110d08
	sub_82110D08(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lfs f0,14020(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14020);
	f0.f64 = double(temp.f32);
	// fsubs f13,f0,f31
	ctx.f13.f64 = double(float(f0.f64 - f31.f64));
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lwz r3,428(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,13980(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13980);
	f0.f64 = double(temp.f32);
	// fmuls f29,f13,f0
	f29.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x820ce1f0
	sub_820CE1F0(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// addi r9,r11,428
	ctx.r9.s64 = r11.s64 + 428;
	// lwz r10,428(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// lfs f0,1460(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1460);
	f0.f64 = double(temp.f32);
	// lwz r29,8(r10)
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// stfs f0,1328(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1328, temp.u32);
	// lfs f0,1464(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1464);
	f0.f64 = double(temp.f32);
	// stfs f0,1332(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1332, temp.u32);
	// lfs f0,1468(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1468);
	f0.f64 = double(temp.f32);
	// stfs f0,1336(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1336, temp.u32);
	// lfs f0,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,12(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 12, temp.u32);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,16(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 16, temp.u32);
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,20(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 20, temp.u32);
	// beq cr6,0x820ca7d8
	if (cr6.getEQ()) goto loc_820CA7D8;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// stw r28,24(r11)
	PPC_STORE_U32(r11.u32 + 24, r28.u32);
	// lfs f2,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x820b2588
	sub_820B2588(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stfs f1,372(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r11.u32 + 372, temp.u32);
	// stfs f1,376(r11)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r11.u32 + 376, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,15416(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15416);
	f0.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// fmuls f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 * f0.f64));
	// addi r3,r11,1456
	ctx.r3.s64 = r11.s64 + 1456;
	// stfs f0,368(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 368, temp.u32);
	// bl 0x820b0998
	sub_820B0998(ctx, base);
loc_820CA7D8:
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f29.f64;
	// lwz r3,28(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,20(r29)
	PPC_STORE_U32(r29.u32 + 20, r11.u32);
	// bl 0x82119178
	sub_82119178(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r3,28(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// lwz r11,428(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// addi r4,r11,12
	ctx.r4.s64 = r11.s64 + 12;
	// bl 0x82119118
	sub_82119118(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8211e6f8
	sub_8211E6F8(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// li r4,1
	ctx.r4.s64 = 1;
	// stfs f0,1460(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1460, temp.u32);
	// stw r28,1456(r11)
	PPC_STORE_U32(r11.u32 + 1456, r28.u32);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,1464(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1464, temp.u32);
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,1468(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1468, temp.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,15612(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15612);
	f0.f64 = double(temp.f32);
	// stfs f31,596(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 596, temp.u32);
	// lwz r3,428(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// stfs f30,612(r11)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r11.u32 + 612, temp.u32);
	// lfs f13,1500(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1500);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,1248(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1248, temp.u32);
	// lfs f13,1504(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1504);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,1252(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1252, temp.u32);
	// lfs f13,1508(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1508);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,1256(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1256, temp.u32);
	// bl 0x820ce1f0
	sub_820CE1F0(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f30,-56(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820CA888"))) PPC_WEAK_FUNC(sub_820CA888);
PPC_FUNC_IMPL(__imp__sub_820CA888) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r10,r11,-1384
	ctx.r10.s64 = r11.s64 + -1384;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ca8c0
	if (cr6.getEQ()) goto loc_820CA8C0;
	// lwz r11,428(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ca8c0
	if (cr6.getEQ()) goto loc_820CA8C0;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ca8c0
	if (cr6.getEQ()) goto loc_820CA8C0;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// oris r9,r9,8192
	ctx.r9.u64 = ctx.r9.u64 | 536870912;
	// stw r9,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r9.u32);
loc_820CA8C0:
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ca8f0
	if (cr6.getEQ()) goto loc_820CA8F0;
	// lwz r11,428(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ca8f0
	if (cr6.getEQ()) goto loc_820CA8F0;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ca8f0
	if (cr6.getEQ()) goto loc_820CA8F0;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// oris r9,r9,8192
	ctx.r9.u64 = ctx.r9.u64 | 536870912;
	// stw r9,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r9.u32);
loc_820CA8F0:
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ca920
	if (cr6.getEQ()) goto loc_820CA920;
	// lwz r11,428(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ca920
	if (cr6.getEQ()) goto loc_820CA920;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ca920
	if (cr6.getEQ()) goto loc_820CA920;
	// lwz r9,20(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// oris r9,r9,8192
	ctx.r9.u64 = ctx.r9.u64 | 536870912;
	// stw r9,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r9.u32);
loc_820CA920:
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lwz r11,428(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// oris r10,r10,8192
	ctx.r10.u64 = ctx.r10.u64 | 536870912;
	// stw r10,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CA958"))) PPC_WEAK_FUNC(sub_820CA958);
PPC_FUNC_IMPL(__imp__sub_820CA958) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r6,2
	ctx.r6.s64 = 2;
	// addi r11,r11,14756
	r11.s64 = r11.s64 + 14756;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// bl 0x8216c178
	sub_8216C178(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r24,r11,-1384
	r24.s64 = r11.s64 + -1384;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r29,r11,-1360
	r29.s64 = r11.s64 + -1360;
loc_820CA994:
	// lwz r3,92(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// beq cr6,0x820ca9b0
	if (cr6.getEQ()) goto loc_820CA9B0;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x820ca9b4
	if (!cr6.getEQ()) goto loc_820CA9B4;
loc_820CA9B0:
	// li r11,1
	r11.s64 = 1;
loc_820CA9B4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820caaa0
	if (!cr6.getEQ()) goto loc_820CAAA0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82159128
	sub_82159128(ctx, base);
	// addi r11,r31,1544
	r11.s64 = r31.s64 + 1544;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// clrlwi r25,r10,24
	r25.u64 = ctx.r10.u32 & 0xFF;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mulli r30,r25,112
	r30.s64 = r25.s64 * 112;
	// lwz r11,24(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r10,r29,28
	ctx.r10.s64 = r29.s64 + 28;
	// addi r11,r31,1596
	r11.s64 = r31.s64 + 1596;
	// stwx r3,r30,r10
	PPC_STORE_U32(r30.u32 + ctx.r10.u32, ctx.r3.u32);
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r11,24(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r10,r29,32
	ctx.r10.s64 = r29.s64 + 32;
	// addi r11,r29,36
	r11.s64 = r29.s64 + 36;
	// addi r28,r31,1648
	r28.s64 = r31.s64 + 1648;
	// li r27,4
	r27.s64 = 4;
	// add r26,r30,r11
	r26.u64 = r30.u64 + r11.u64;
	// stwx r3,r30,r10
	PPC_STORE_U32(r30.u32 + ctx.r10.u32, ctx.r3.u32);
loc_820CAA24:
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r27,r27,-1
	r27.s64 = r27.s64 + -1;
	// stw r3,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r3.u32);
	// addi r28,r28,52
	r28.s64 = r28.s64 + 52;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x820caa24
	if (!cr6.getEQ()) goto loc_820CAA24;
	// addi r3,r31,1856
	ctx.r3.s64 = r31.s64 + 1856;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r10,r29,104
	ctx.r10.s64 = r29.s64 + 104;
	// addi r11,r31,1908
	r11.s64 = r31.s64 + 1908;
	// stbx r3,r30,r10
	PPC_STORE_U8(r30.u32 + ctx.r10.u32, ctx.r3.u8);
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r11,24(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// rlwinm r10,r25,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwzx r10,r10,r24
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r24.u32);
	// stw r11,8280(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8280, r11.u32);
	// bl 0x8216c2a8
	sub_8216C2A8(ctx, base);
	// b 0x820ca994
	goto loc_820CA994;
loc_820CAAA0:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_820CAAA8"))) PPC_WEAK_FUNC(sub_820CAAA8);
PPC_FUNC_IMPL(__imp__sub_820CAAA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// rlwinm r31,r3,2,0,29
	r31.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-1384
	r11.s64 = r11.s64 + -1384;
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cab54
	if (cr6.getEQ()) goto loc_820CAB54;
	// lwz r11,480(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 480);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820cab54
	if (cr6.getEQ()) goto loc_820CAB54;
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cab04
	if (!cr6.getEQ()) goto loc_820CAB04;
loc_820CAAEC:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_820CAB04:
	// bl 0x820ec268
	sub_820EC268(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x820cab54
	if (!cr6.getEQ()) goto loc_820CAB54;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x820cab54
	if (!cr6.getGT()) goto loc_820CAB54;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r11,r11,-1360
	r11.s64 = r11.s64 + -1360;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
loc_820CAB34:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// add r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 + ctx.r8.u64;
	// cmpwi cr6,r8,2
	cr6.compare<int32_t>(ctx.r8.s32, 2, xer);
	// bge cr6,0x820caaec
	if (!cr6.getLT()) goto loc_820CAAEC;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,112
	r11.s64 = r11.s64 + 112;
	// cmpw cr6,r9,r3
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r3.s32, xer);
	// blt cr6,0x820cab34
	if (cr6.getLT()) goto loc_820CAB34;
loc_820CAB54:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CAB70"))) PPC_WEAK_FUNC(sub_820CAB70);
PPC_FUNC_IMPL(__imp__sub_820CAB70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r28,0
	r28.s64 = 0;
	// bl 0x820eb810
	sub_820EB810(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x820f6290
	sub_820F6290(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r31,0
	r31.s64 = 0;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// ble cr6,0x820cabfc
	if (!cr6.getGT()) goto loc_820CABFC;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// li r26,-1
	r26.s64 = -1;
	// addi r30,r11,-1384
	r30.s64 = r11.s64 + -1384;
loc_820CABA8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ca3e8
	sub_820CA3E8(ctx, base);
	// cmpw cr6,r27,r29
	cr6.compare<int32_t>(r27.s32, r29.s32, xer);
	// bge cr6,0x820cabdc
	if (!cr6.getLT()) goto loc_820CABDC;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820cabd0
	if (cr6.getEQ()) goto loc_820CABD0;
	// bl 0x8216c140
	sub_8216C140(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cabdc
	if (!cr6.getEQ()) goto loc_820CABDC;
loc_820CABD0:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// stw r26,8528(r11)
	PPC_STORE_U32(r11.u32 + 8528, r26.u32);
	// b 0x820cabec
	goto loc_820CABEC;
loc_820CABDC:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// stw r10,8528(r11)
	PPC_STORE_U32(r11.u32 + 8528, ctx.r10.u32);
loc_820CABEC:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmpw cr6,r31,r29
	cr6.compare<int32_t>(r31.s32, r29.s32, xer);
	// blt cr6,0x820caba8
	if (cr6.getLT()) goto loc_820CABA8;
loc_820CABFC:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820CAC08"))) PPC_WEAK_FUNC(sub_820CAC08);
PPC_FUNC_IMPL(__imp__sub_820CAC08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,8576
	ctx.r3.s64 = 8576;
	// bl 0x8209cbc8
	sub_8209CBC8(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// rlwinm r30,r28,2,0,29
	r30.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r31,r11,-1384
	r31.s64 = r11.s64 + -1384;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r29,0
	r29.s64 = 0;
	// li r8,2
	ctx.r8.s64 = 2;
	// stwx r3,r30,r31
	PPC_STORE_U32(r30.u32 + r31.u32, ctx.r3.u32);
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stw r29,128(r3)
	PPC_STORE_U32(ctx.r3.u32 + 128, r29.u32);
	// lfs f13,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,132(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 132, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,136(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 136, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,140(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 140, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,144(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 144, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,148(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 148, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,152(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 152, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,156(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 156, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,160(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 160, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,164(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 164, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,168(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 168, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,172(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 172, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,176(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 176, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,180(r11)
	PPC_STORE_U32(r11.u32 + 180, r29.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,184(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 184, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,188(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 188, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,192(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 192, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,196(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 196, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,200(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 200, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,204(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 204, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,208(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 208, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,212(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 212, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,216(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 216, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,368(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 368, temp.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,372(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 372, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// li r11,1
	r11.s64 = 1;
	// stfs f0,376(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 376, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,380(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 380, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,384(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 384, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,388(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 388, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,392(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 392, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,396(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 396, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,400(r10)
	PPC_STORE_U32(ctx.r10.u32 + 400, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,404(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 404, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,408(r10)
	PPC_STORE_U32(ctx.r10.u32 + 408, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,412(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 412, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4892(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4892, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4896(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4896, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4900(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4900, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r8,416(r10)
	PPC_STORE_U32(ctx.r10.u32 + 416, ctx.r8.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stb r29,8520(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8520, r29.u8);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r8,8316(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8316, ctx.r8.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,420(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 420, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,424(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 424, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,428(r10)
	PPC_STORE_U32(ctx.r10.u32 + 428, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r11,432(r10)
	PPC_STORE_U32(ctx.r10.u32 + 432, r11.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,468(r10)
	PPC_STORE_U32(ctx.r10.u32 + 468, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,472(r10)
	PPC_STORE_U32(ctx.r10.u32 + 472, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,476(r10)
	PPC_STORE_U32(ctx.r10.u32 + 476, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,480(r10)
	PPC_STORE_U32(ctx.r10.u32 + 480, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,484(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 484, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,488(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 488, temp.u32);
	// lwzx r9,r30,r31
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// stfs f13,492(r9)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r9.u32 + 492, temp.u32);
	// li r9,-1
	ctx.r9.s64 = -1;
	// lfs f12,6580(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6580);
	ctx.f12.f64 = double(temp.f32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,496(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 496, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,500(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 500, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,504(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 504, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,508(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 508, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,512(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 512, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,524(r10)
	PPC_STORE_U32(ctx.r10.u32 + 524, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,528(r10)
	PPC_STORE_U32(ctx.r10.u32 + 528, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,532(r10)
	PPC_STORE_U32(ctx.r10.u32 + 532, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,536(r10)
	PPC_STORE_U32(ctx.r10.u32 + 536, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r11,540(r10)
	PPC_STORE_U32(ctx.r10.u32 + 540, r11.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r11,544(r10)
	PPC_STORE_U32(ctx.r10.u32 + 544, r11.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,548(r10)
	PPC_STORE_U32(ctx.r10.u32 + 548, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r11,552(r10)
	PPC_STORE_U32(ctx.r10.u32 + 552, r11.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,556(r10)
	PPC_STORE_U32(ctx.r10.u32 + 556, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,560(r10)
	PPC_STORE_U32(ctx.r10.u32 + 560, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r11,564(r10)
	PPC_STORE_U32(ctx.r10.u32 + 564, r11.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,568(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 568, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,572(r10)
	PPC_STORE_U32(ctx.r10.u32 + 572, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r9,576(r10)
	PPC_STORE_U32(ctx.r10.u32 + 576, ctx.r9.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r11,580(r10)
	PPC_STORE_U32(ctx.r10.u32 + 580, r11.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,584(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 584, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,588(r10)
	PPC_STORE_U32(ctx.r10.u32 + 588, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r9,592(r10)
	PPC_STORE_U32(ctx.r10.u32 + 592, ctx.r9.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,596(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 596, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,600(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 600, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,8516(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8516, temp.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lfs f11,15088(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15088);
	ctx.f11.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// stfs f13,604(r7)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 604, temp.u32);
	// lfs f10,16068(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16068);
	ctx.f10.f64 = double(temp.f32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,608(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 608, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f11,612(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 612, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f10,616(r10)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 616, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,620(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 620, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,8512(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8512, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,624(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 624, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,628(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 628, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,632(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 632, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,636(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 636, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,640(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 640, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,8396(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8396, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,644(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 644, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,652(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 652, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,656(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 656, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,660(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 660, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,664(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 664, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,668(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 668, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,672(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 672, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,676(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 676, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,680(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 680, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,684(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 684, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,688(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 688, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,692(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 692, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,696(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 696, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,700(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 700, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,704(r10)
	PPC_STORE_U32(ctx.r10.u32 + 704, r29.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lfs f11,16064(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16064);
	ctx.f11.f64 = double(temp.f32);
	// stw r29,736(r7)
	PPC_STORE_U32(ctx.r7.u32 + 736, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,740(r10)
	PPC_STORE_U32(ctx.r10.u32 + 740, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,744(r10)
	PPC_STORE_U32(ctx.r10.u32 + 744, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r11,748(r10)
	PPC_STORE_U32(ctx.r10.u32 + 748, r11.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,752(r10)
	PPC_STORE_U32(ctx.r10.u32 + 752, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lis r7,-32256
	ctx.r7.s64 = -2113929216;
	// stfs f0,756(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 756, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,760(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 760, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f11,764(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 764, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lfs f11,15612(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 15612);
	ctx.f11.f64 = double(temp.f32);
	// stfs f0,768(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 768, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,772(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 772, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,776(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 776, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,780(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 780, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,784(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 784, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,788(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 788, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,800(r10)
	PPC_STORE_U32(ctx.r10.u32 + 800, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,804(r10)
	PPC_STORE_U32(ctx.r10.u32 + 804, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,808(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 808, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,812(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 812, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,816(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 816, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,820(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 820, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,824(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 824, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,828(r10)
	PPC_STORE_U32(ctx.r10.u32 + 828, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r11,832(r10)
	PPC_STORE_U32(ctx.r10.u32 + 832, r11.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,836(r10)
	PPC_STORE_U32(ctx.r10.u32 + 836, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,840(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 840, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,1240(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1240, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,1244(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1244, r29.u32);
	// li r10,255
	ctx.r10.s64 = 255;
	// lwzx r6,r30,r31
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1248(r6)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 1248, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1252(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1252, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f11,1256(r7)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1256, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1260(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1260, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1264(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1264, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,1268(r7)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1268, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r10,1272(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1272, ctx.r10.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r10,1276(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1276, ctx.r10.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r10,1280(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1280, ctx.r10.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1284(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1284, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,1288(r7)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1288, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,1292(r7)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1292, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r10,1296(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1296, ctx.r10.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r10,1300(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1300, ctx.r10.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r10,1304(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1304, ctx.r10.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r10,1308(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1308, ctx.r10.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r10,1312(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1312, ctx.r10.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r10,1316(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1316, ctx.r10.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1320(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1320, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1324(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1324, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,1348(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1348, r29.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r11,1352(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1352, r11.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,1356(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1356, r29.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,1360(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1360, r29.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r8,1364(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1364, ctx.r8.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,1368(r8)
	PPC_STORE_U32(ctx.r8.u32 + 1368, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r11,1540(r8)
	PPC_STORE_U32(ctx.r8.u32 + 1540, r11.u32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lfs f11,14468(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 14468);
	ctx.f11.f64 = double(temp.f32);
	// stw r11,1544(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1544, r11.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r11,1548(r8)
	PPC_STORE_U32(ctx.r8.u32 + 1548, r11.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,1552(r8)
	PPC_STORE_U32(ctx.r8.u32 + 1552, r29.u32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lfs f12,14472(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 14472);
	ctx.f12.f64 = double(temp.f32);
	// stfs f11,1556(r7)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1556, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,1560(r8)
	PPC_STORE_U32(ctx.r8.u32 + 1560, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,1564(r8)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1564, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,1568(r8)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1568, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1572(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1572, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1576(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1576, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1580(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1580, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1584(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1584, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1588(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1588, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,1592(r8)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1592, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1596(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1596, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,1600(r8)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1600, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1604(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1604, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1608(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1608, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1612(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1612, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1616(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1616, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1620(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1620, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1624(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1624, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,1628(r8)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1628, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1632(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1632, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,1636(r8)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1636, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1640(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1640, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1644(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1644, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1648(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 1648, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// li r8,100
	ctx.r8.s64 = 100;
	// stfs f0,1652(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1652, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1656(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1656, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1660(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1660, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1664(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1664, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1668(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1668, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1672(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1672, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1676(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1676, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1680(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1680, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,1684(r7)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1684, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1688(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1688, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1692(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1692, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,1696(r7)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1696, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1700(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1700, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,1704(r7)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1704, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1708(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1708, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1712(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1712, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,1716(r7)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1716, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,1720(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 1720, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,1724(r7)
	PPC_STORE_U32(ctx.r7.u32 + 1724, r29.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// sth r8,2304(r7)
	PPC_STORE_U16(ctx.r7.u32 + 2304, ctx.r8.u16);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// sth r8,2306(r7)
	PPC_STORE_U16(ctx.r7.u32 + 2306, ctx.r8.u16);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// sth r29,2308(r8)
	PPC_STORE_U16(ctx.r8.u32 + 2308, r29.u16);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// sth r29,2310(r8)
	PPC_STORE_U16(ctx.r8.u32 + 2310, r29.u16);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,2312(r8)
	PPC_STORE_U32(ctx.r8.u32 + 2312, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,2316(r8)
	PPC_STORE_U32(ctx.r8.u32 + 2316, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,2320(r8)
	PPC_STORE_U32(ctx.r8.u32 + 2320, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,2324(r8)
	PPC_STORE_U32(ctx.r8.u32 + 2324, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r9,8388(r8)
	PPC_STORE_U32(ctx.r8.u32 + 8388, ctx.r9.u32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lfs f12,14064(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 14064);
	ctx.f12.f64 = double(temp.f32);
	// stw r9,8392(r7)
	PPC_STORE_U32(ctx.r7.u32 + 8392, ctx.r9.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,8400(r8)
	PPC_STORE_U32(ctx.r8.u32 + 8400, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,8404(r8)
	PPC_STORE_U32(ctx.r8.u32 + 8404, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,2328(r8)
	PPC_STORE_U32(ctx.r8.u32 + 2328, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,2332(r8)
	PPC_STORE_U32(ctx.r8.u32 + 2332, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,4216(r8)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + 4216, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,4220(r8)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + 4220, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4224(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4224, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4228(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4228, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4232(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4232, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4236(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4236, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4240(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4240, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stb r10,4244(r8)
	PPC_STORE_U8(ctx.r8.u32 + 4244, ctx.r10.u8);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stb r10,4245(r8)
	PPC_STORE_U8(ctx.r8.u32 + 4245, ctx.r10.u8);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stb r10,4246(r8)
	PPC_STORE_U8(ctx.r8.u32 + 4246, ctx.r10.u8);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stb r29,4247(r10)
	PPC_STORE_U8(ctx.r10.u32 + 4247, r29.u8);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r11,4248(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4248, r11.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4252(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4252, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4256(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4256, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4260(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4260, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4264(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4264, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4268(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4268, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,4272(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4272, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4276(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4276, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4280(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4280, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4284(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4284, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// stfs f0,4288(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 4288, temp.u32);
	// lfs f9,14444(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14444);
	ctx.f9.f64 = double(temp.f32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,4292(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4292, temp.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lfs f12,13960(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13960);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// stfs f0,4296(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 4296, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lfs f11,14120(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14120);
	ctx.f11.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// stfs f9,4300(r8)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r8.u32 + 4300, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lfs f10,15844(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15844);
	ctx.f10.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// stfs f0,4304(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 4304, temp.u32);
	// lfs f8,2952(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2952);
	ctx.f8.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f9,16060(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16060);
	ctx.f9.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f7,12460(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12460);
	ctx.f7.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f6,12464(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12464);
	ctx.f6.f64 = double(temp.f32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4372(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4372, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4376(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4376, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4380(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4380, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4388(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4388, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4392(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4392, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4396(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4396, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4400(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4400, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4404(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4404, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4408(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4408, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,4412(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4412, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,4416(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4416, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r9,4420(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4420, ctx.r9.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f11,4424(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4424, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f10,4428(r10)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4428, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// li r8,8
	ctx.r8.s64 = 8;
	// stfs f0,4432(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4432, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4436(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4436, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f8,4440(r10)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4440, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f9,4444(r10)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4444, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,4448(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4448, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f7,4452(r10)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4452, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f6,4456(r10)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4456, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,4460(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4460, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,4464(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4464, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,4468(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4468, temp.u32);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// addi r10,r10,11952
	ctx.r10.s64 = ctx.r10.s64 + 11952;
	// stfs f13,4472(r7)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 4472, temp.u32);
	// lwzx r6,r30,r31
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// stw r29,4476(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4476, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4480(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4480, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4484(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4484, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4488(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4488, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4492(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4492, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4496(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4496, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4500(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4500, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4504(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4504, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// addi r10,r10,8448
	ctx.r10.s64 = ctx.r10.s64 + 8448;
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
loc_820CB5A4:
	// ld r8,0(r7)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r7.u32 + 0);
	// addi r7,r7,8
	ctx.r7.s64 = ctx.r7.s64 + 8;
	// std r8,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r8.u64);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// bdnz 0x820cb5a4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820CB5A4;
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lis r8,1
	ctx.r8.s64 = 65536;
	// stw r29,4508(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4508, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4512(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4512, r29.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// lfs f9,14124(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14124);
	ctx.f9.f64 = double(temp.f32);
	// stfs f13,4516(r7)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 4516, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,4520(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4520, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,4524(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4524, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r8,4528(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4528, ctx.r8.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4556(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4556, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4560(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4560, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f11,4564(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4564, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f10,4568(r10)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4568, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4572(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4572, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4704(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4704, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4700(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4700, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4708(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4708, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4712(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4712, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,4716(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4716, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,4720(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4720, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,4724(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4724, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f12,4728(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4728, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f9,4732(r10)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4732, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4736(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4736, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r9,4740(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4740, ctx.r9.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4744(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4744, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4748(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4748, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4752(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4752, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4756(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4756, r29.u32);
	// li r10,7
	ctx.r10.s64 = 7;
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4760(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4760, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4764(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4764, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4904(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 4904, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,4908(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4908, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,4912(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 4912, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stb r29,4998(r8)
	PPC_STORE_U8(ctx.r8.u32 + 4998, r29.u8);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r10,8248(r8)
	PPC_STORE_U32(ctx.r8.u32 + 8248, ctx.r10.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,8252(r8)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + 8252, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,8256(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 8256, temp.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,8260(r8)
	PPC_STORE_U32(ctx.r8.u32 + 8260, r29.u32);
	// lwzx r8,r30,r31
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r10,8276(r8)
	PPC_STORE_U32(ctx.r8.u32 + 8276, ctx.r10.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,8280(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8280, r29.u32);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r8,-1368(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1368);
	// lwzx r7,r30,r31
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r8,8288(r7)
	PPC_STORE_U32(ctx.r7.u32 + 8288, ctx.r8.u32);
	// lwz r8,-1368(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1368);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// stw r8,-1368(r10)
	PPC_STORE_U32(ctx.r10.u32 + -1368, ctx.r8.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r9,8292(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8292, ctx.r9.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r9,8296(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8296, ctx.r9.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r9,8300(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8300, ctx.r9.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r9,8304(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8304, ctx.r9.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,8320(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8320, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,8368(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8368, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,8372(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8372, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r11,8376(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8376, r11.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,8380(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8380, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f13,8384(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8384, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,8412(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8412, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stfs f0,8416(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8416, temp.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,8420(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8420, r29.u32);
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r11,8424(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8424, r11.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,8428(r11)
	PPC_STORE_U32(r11.u32 + 8428, r29.u32);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// stw r29,8432(r11)
	PPC_STORE_U32(r11.u32 + 8432, r29.u32);
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cb834
	if (cr6.getEQ()) goto loc_820CB834;
	// bl 0x8215fc88
	sub_8215FC88(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bne cr6,0x820cb7e4
	if (!cr6.getEQ()) goto loc_820CB7E4;
	// bl 0x82159590
	sub_82159590(ctx, base);
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820cb818
	if (cr6.getEQ()) goto loc_820CB818;
	// addi r6,r3,768
	ctx.r6.s64 = ctx.r3.s64 + 768;
	// li r7,16
	ctx.r7.s64 = 16;
	// li r5,16
	ctx.r5.s64 = 16;
	// addi r4,r11,8532
	ctx.r4.s64 = r11.s64 + 8532;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x823eda38
	sub_823EDA38(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_820CB7E4:
	// bl 0x82183908
	sub_82183908(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820cb814
	if (cr6.getEQ()) goto loc_820CB814;
	// bl 0x82183850
	sub_82183850(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwzx r10,r30,r31
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r10,8532
	ctx.r3.s64 = ctx.r10.s64 + 8532;
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// bl 0x823edad0
	sub_823EDAD0(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_820CB814:
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
loc_820CB818:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r5,r10,16044
	ctx.r5.s64 = ctx.r10.s64 + 16044;
	// addi r3,r11,8532
	ctx.r3.s64 = r11.s64 + 8532;
	// bl 0x823edad0
	sub_823EDAD0(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_820CB834:
	// lwzx r11,r30,r31
	r11.u64 = PPC_LOAD_U32(r30.u32 + r31.u32);
	// sth r29,8532(r11)
	PPC_STORE_U16(r11.u32 + 8532, r29.u16);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820CB848"))) PPC_WEAK_FUNC(sub_820CB848);
PPC_FUNC_IMPL(__imp__sub_820CB848) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// li r28,0
	r28.s64 = 0;
	// addi r31,r11,-1384
	r31.s64 = r11.s64 + -1384;
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// stw r11,-1368(r10)
	PPC_STORE_U32(ctx.r10.u32 + -1368, r11.u32);
	// ble cr6,0x820cb8e8
	if (!cr6.getGT()) goto loc_820CB8E8;
	// mr r29,r28
	r29.u64 = r28.u64;
loc_820CB8A4:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820cac08
	sub_820CAC08(ctx, base);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmpw cr6,r29,r30
	cr6.compare<int32_t>(r29.s32, r30.s32, xer);
	// blt cr6,0x820cb8a4
	if (cr6.getLT()) goto loc_820CB8A4;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lis r9,-32014
	ctx.r9.s64 = -2098069504;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r11,r11,-1360
	r11.s64 = r11.s64 + -1360;
	// stw r28,-912(r10)
	PPC_STORE_U32(ctx.r10.u32 + -912, r28.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r10,-1364(r9)
	PPC_STORE_U32(ctx.r9.u32 + -1364, ctx.r10.u32);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// stw r11,-908(r10)
	PPC_STORE_U32(ctx.r10.u32 + -908, r11.u32);
	// bl 0x820cab70
	sub_820CAB70(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_820CB8E8:
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820cac08
	sub_820CAC08(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// addi r9,r11,-1360
	ctx.r9.s64 = r11.s64 + -1360;
	// mr r11,r28
	r11.u64 = r28.u64;
	// lis r8,-32014
	ctx.r8.s64 = -2098069504;
	// li r7,640
	ctx.r7.s64 = 640;
	// li r6,480
	ctx.r6.s64 = 480;
	// stw r11,-912(r10)
	PPC_STORE_U32(ctx.r10.u32 + -912, r11.u32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r9,-908(r8)
	PPC_STORE_U32(ctx.r8.u32 + -908, ctx.r9.u32);
	// stw r10,-1364(r11)
	PPC_STORE_U32(r11.u32 + -1364, ctx.r10.u32);
	// sth r7,2304(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2304, ctx.r7.u16);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// sth r6,2306(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2306, ctx.r6.u16);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// sth r28,2308(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2308, r28.u16);
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// sth r28,2310(r11)
	PPC_STORE_U16(r11.u32 + 2310, r28.u16);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820CB948"))) PPC_WEAK_FUNC(sub_820CB948);
PPC_FUNC_IMPL(__imp__sub_820CB948) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stfd f30,-24(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -24, f30.u64);
	// stfd f31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f13,f2
	ctx.f13.f64 = ctx.f2.f64;
	// fmr f0,f1
	f0.f64 = ctx.f1.f64;
	// stw r10,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r10.u32);
	// fmr f9,f5
	ctx.f9.f64 = ctx.f5.f64;
	// stw r9,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r9.u32);
	// fmr f10,f6
	ctx.f10.f64 = ctx.f6.f64;
	// stw r8,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r8.u32);
	// fmr f11,f7
	ctx.f11.f64 = ctx.f7.f64;
	// lfs f2,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	ctx.f2.f64 = double(temp.f32);
	// lwz r11,260(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// fmuls f31,f3,f2
	f31.f64 = double(float(ctx.f3.f64 * ctx.f2.f64));
	// fmuls f30,f4,f2
	f30.f64 = double(float(ctx.f4.f64 * ctx.f2.f64));
	// fmr f12,f8
	ctx.f12.f64 = ctx.f8.f64;
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f4,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// fadds f7,f31,f0
	ctx.f7.f64 = double(float(f31.f64 + f0.f64));
	// fadds f8,f30,f13
	ctx.f8.f64 = double(float(f30.f64 + ctx.f13.f64));
	// fsubs f6,f13,f30
	ctx.f6.f64 = double(float(ctx.f13.f64 - f30.f64));
	// fsubs f5,f0,f31
	ctx.f5.f64 = double(float(f0.f64 - f31.f64));
	// bl 0x820982e0
	sub_820982E0(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f30,-24(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// lfd f31,-16(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CB9D8"))) PPC_WEAK_FUNC(sub_820CB9D8);
PPC_FUNC_IMPL(__imp__sub_820CB9D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f21{};
	PPCRegister f22{};
	PPCRegister f23{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// addi r12,r1,-72
	r12.s64 = ctx.r1.s64 + -72;
	// bl 0x823ed52c
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820ec268
	sub_820EC268(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// cmpwi cr6,r25,1
	cr6.compare<int32_t>(r25.s32, 1, xer);
	// beq cr6,0x820cbd48
	if (cr6.getEQ()) goto loc_820CBD48;
	// lis r26,-32014
	r26.s64 = -2098069504;
	// lwz r11,-1364(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + -1364);
	// lwz r10,8260(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8260);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x820cbd48
	if (!cr6.getEQ()) goto loc_820CBD48;
	// lwz r11,480(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 480);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820cbd48
	if (!cr6.getEQ()) goto loc_820CBD48;
	// li r3,23
	ctx.r3.s64 = 23;
	// bl 0x82136fa0
	sub_82136FA0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820cbd48
	if (!cr6.getEQ()) goto loc_820CBD48;
	// bl 0x8210e400
	sub_8210E400(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// addi r31,r11,-16
	r31.s64 = r11.s64 + -16;
	// bl 0x8210e290
	sub_8210E290(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// addi r31,r11,-30
	r31.s64 = r11.s64 + -30;
	// bl 0x8210e2f0
	sub_8210E2F0(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// cmpwi cr6,r25,2
	cr6.compare<int32_t>(r25.s32, 2, xer);
	// addi r30,r11,36
	r30.s64 = r11.s64 + 36;
	// ble cr6,0x820cba7c
	if (!cr6.getGT()) goto loc_820CBA7C;
	// clrlwi r11,r24,31
	r11.u64 = r24.u32 & 0x1;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820cba7c
	if (!cr6.getEQ()) goto loc_820CBA7C;
	// addi r31,r31,15
	r31.s64 = r31.s64 + 15;
loc_820CBA7C:
	// extsw r10,r30
	ctx.r10.s64 = r30.s32;
	// extsw r9,r31
	ctx.r9.s64 = r31.s32;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// std r10,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r10.u64);
	// std r9,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r9.u64);
	// lfs f29,2776(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f29.f64 = double(temp.f32);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// addi r3,r11,28040
	ctx.r3.s64 = r11.s64 + 28040;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,16076(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16076);
	f30.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f28,16024(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16024);
	f28.f64 = double(temp.f32);
	// lfd f0,128(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// lfd f13,136(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f26,f0
	f26.f64 = double(float(f0.f64));
	// frsp f25,f13
	f25.f64 = double(float(ctx.f13.f64));
	// bl 0x821463f0
	sub_821463F0(ctx, base);
	// li r11,2
	r11.s64 = 2;
	// fmr f1,f25
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f25.f64;
	// li r8,0
	ctx.r8.s64 = 0;
	// fmr f2,f26
	ctx.f2.f64 = f26.f64;
	// li r9,0
	ctx.r9.s64 = 0;
	// fmr f3,f28
	ctx.f3.f64 = f28.f64;
	// li r10,1
	ctx.r10.s64 = 1;
	// fmr f4,f30
	ctx.f4.f64 = f30.f64;
	// fmr f5,f31
	ctx.f5.f64 = f31.f64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// fmr f6,f31
	ctx.f6.f64 = f31.f64;
	// fmr f7,f29
	ctx.f7.f64 = f29.f64;
	// fmr f8,f29
	ctx.f8.f64 = f29.f64;
	// bl 0x820cb948
	sub_820CB948(ctx, base);
	// li r7,64
	ctx.r7.s64 = 64;
	// addi r6,r30,2
	ctx.r6.s64 = r30.s64 + 2;
	// addi r5,r31,2
	ctx.r5.s64 = r31.s64 + 2;
	// addi r4,r30,-2
	ctx.r4.s64 = r30.s64 + -2;
	// addi r3,r31,-2
	ctx.r3.s64 = r31.s64 + -2;
	// bl 0x8213e018
	sub_8213E018(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// cmpwi cr6,r27,5
	cr6.compare<int32_t>(r27.s32, 5, xer);
	// addi r29,r11,-1360
	r29.s64 = r11.s64 + -1360;
	// beq cr6,0x820cbb50
	if (cr6.getEQ()) goto loc_820CBB50;
	// cmpwi cr6,r27,6
	cr6.compare<int32_t>(r27.s32, 6, xer);
	// beq cr6,0x820cbb50
	if (cr6.getEQ()) goto loc_820CBB50;
	// cmpwi cr6,r27,2
	cr6.compare<int32_t>(r27.s32, 2, xer);
	// beq cr6,0x820cbb50
	if (cr6.getEQ()) goto loc_820CBB50;
	// cmpwi cr6,r27,3
	cr6.compare<int32_t>(r27.s32, 3, xer);
	// beq cr6,0x820cbb50
	if (cr6.getEQ()) goto loc_820CBB50;
	// li r7,-96
	ctx.r7.s64 = -96;
	// b 0x820cbb78
	goto loc_820CBB78;
loc_820CBB50:
	// mulli r11,r24,112
	r11.s64 = r24.s64 * 112;
	// addi r10,r29,105
	ctx.r10.s64 = r29.s64 + 105;
	// lbzx r11,r11,r10
	r11.u64 = PPC_LOAD_U8(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cbb70
	if (!cr6.getEQ()) goto loc_820CBB70;
	// lis r7,-137
	ctx.r7.s64 = -8978432;
	// ori r7,r7,30719
	ctx.r7.u64 = ctx.r7.u64 | 30719;
	// b 0x820cbb78
	goto loc_820CBB78;
loc_820CBB70:
	// lis r7,-30584
	ctx.r7.s64 = -2004353024;
	// ori r7,r7,65535
	ctx.r7.u64 = ctx.r7.u64 | 65535;
loc_820CBB78:
	// addi r6,r30,1
	ctx.r6.s64 = r30.s64 + 1;
	// addi r5,r31,1
	ctx.r5.s64 = r31.s64 + 1;
	// addi r4,r30,-1
	ctx.r4.s64 = r30.s64 + -1;
	// addi r3,r31,-1
	ctx.r3.s64 = r31.s64 + -1;
	// bl 0x8213e018
	sub_8213E018(ctx, base);
	// li r30,0
	r30.s64 = 0;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// ble cr6,0x820cbd48
	if (!cr6.getGT()) goto loc_820CBD48;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// addi r28,r11,-1384
	r28.s64 = r11.s64 + -1384;
	// lis r7,-32256
	ctx.r7.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f28,3060(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 3060);
	f28.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f27,13980(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 13980);
	f27.f64 = double(temp.f32);
	// addi r29,r29,105
	r29.s64 = r29.s64 + 105;
	// lfs f24,14220(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 14220);
	f24.f64 = double(temp.f32);
	// lfs f21,16072(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 16072);
	f21.f64 = double(temp.f32);
	// lfs f22,14216(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14216);
	f22.f64 = double(temp.f32);
	// lfs f23,14308(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14308);
	f23.f64 = double(temp.f32);
loc_820CBBD4:
	// cmpw cr6,r30,r24
	cr6.compare<int32_t>(r30.s32, r24.s32, xer);
	// beq cr6,0x820cbd34
	if (cr6.getEQ()) goto loc_820CBD34;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lwz r10,480(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 480);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x820cbd34
	if (!cr6.getEQ()) goto loc_820CBD34;
	// lwz r10,-1364(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + -1364);
	// lwz r11,428(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// lwz r10,428(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 428);
	// lfs f0,12(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12);
	f0.f64 = double(temp.f32);
	// lfs f12,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f31,f0,f13
	f31.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f0,20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	f0.f64 = double(temp.f32);
	// fsubs f30,f12,f0
	f30.f64 = double(float(ctx.f12.f64 - f0.f64));
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// fmr f2,f30
	ctx.f2.f64 = f30.f64;
	// bl 0x8210ae20
	sub_8210AE20(ctx, base);
	// fmuls f13,f31,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(f31.f64 * f31.f64));
	// lwz r11,-1364(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + -1364);
	// cmpwi cr6,r27,5
	cr6.compare<int32_t>(r27.s32, 5, xer);
	// lfs f0,596(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 596);
	f0.f64 = double(temp.f32);
	// fmadds f0,f1,f23,f0
	f0.f64 = double(float(ctx.f1.f64 * f23.f64 + f0.f64));
	// fmadds f13,f30,f30,f13
	ctx.f13.f64 = double(float(f30.f64 * f30.f64 + ctx.f13.f64));
	// fadds f0,f0,f22
	f0.f64 = double(float(f0.f64 + f22.f64));
	// fsqrts f13,f13
	ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
	// fmuls f30,f13,f21
	f30.f64 = double(float(ctx.f13.f64 * f21.f64));
	// beq cr6,0x820cbc7c
	if (cr6.getEQ()) goto loc_820CBC7C;
	// cmpwi cr6,r27,6
	cr6.compare<int32_t>(r27.s32, 6, xer);
	// beq cr6,0x820cbc7c
	if (cr6.getEQ()) goto loc_820CBC7C;
	// cmpwi cr6,r27,2
	cr6.compare<int32_t>(r27.s32, 2, xer);
	// beq cr6,0x820cbc7c
	if (cr6.getEQ()) goto loc_820CBC7C;
	// cmpwi cr6,r27,3
	cr6.compare<int32_t>(r27.s32, 3, xer);
	// beq cr6,0x820cbc7c
	if (cr6.getEQ()) goto loc_820CBC7C;
	// fcmpu cr6,f30,f24
	cr6.compare(f30.f64, f24.f64);
	// lis r31,-1
	r31.s64 = -65536;
	// bge cr6,0x820cbc70
	if (!cr6.getLT()) goto loc_820CBC70;
	// ori r31,r31,160
	r31.u64 = r31.u64 | 160;
	// b 0x820cbcc8
	goto loc_820CBCC8;
loc_820CBC70:
	// fmr f30,f24
	ctx.fpscr.disableFlushMode();
	f30.f64 = f24.f64;
	// ori r31,r31,96
	r31.u64 = r31.u64 | 96;
	// b 0x820cbcc8
	goto loc_820CBCC8;
loc_820CBC7C:
	// lbz r11,0(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// fcmpu cr6,f30,f24
	ctx.fpscr.disableFlushMode();
	cr6.compare(f30.f64, f24.f64);
	// bge cr6,0x820cbca8
	if (!cr6.getLT()) goto loc_820CBCA8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cbc9c
	if (!cr6.getEQ()) goto loc_820CBC9C;
	// lis r31,-256
	r31.s64 = -16777216;
	// ori r31,r31,160
	r31.u64 = r31.u64 | 160;
	// b 0x820cbcc8
	goto loc_820CBCC8;
loc_820CBC9C:
	// lis r31,10280
	r31.s64 = 673710080;
	// ori r31,r31,65535
	r31.u64 = r31.u64 | 65535;
	// b 0x820cbcc8
	goto loc_820CBCC8;
loc_820CBCA8:
	// fmr f30,f24
	ctx.fpscr.disableFlushMode();
	f30.f64 = f24.f64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cbcc0
	if (!cr6.getEQ()) goto loc_820CBCC0;
	// lis r31,-256
	r31.s64 = -16777216;
	// ori r31,r31,96
	r31.u64 = r31.u64 | 96;
	// b 0x820cbcc8
	goto loc_820CBCC8;
loc_820CBCC0:
	// lis r31,10280
	r31.s64 = 673710080;
	// ori r31,r31,65456
	r31.u64 = r31.u64 | 65456;
loc_820CBCC8:
	// fmuls f31,f0,f27
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(f0.f64 * f27.f64));
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmadds f31,f0,f30,f25
	f31.f64 = double(float(f0.f64 * f30.f64 + f25.f64));
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// fadds f3,f31,f28
	ctx.f3.f64 = double(float(f31.f64 + f28.f64));
	// li r3,64
	ctx.r3.s64 = 64;
	// fsubs f1,f31,f28
	ctx.f1.f64 = double(float(f31.f64 - f28.f64));
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmadds f30,f0,f30,f26
	f30.f64 = double(float(f0.f64 * f30.f64 + f26.f64));
	// fadds f4,f30,f28
	ctx.f4.f64 = double(float(f30.f64 + f28.f64));
	// fsubs f2,f30,f28
	ctx.f2.f64 = double(float(f30.f64 - f28.f64));
	// bl 0x820972f8
	sub_820972F8(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// fadds f4,f30,f29
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = double(float(f30.f64 + f29.f64));
	// li r8,0
	ctx.r8.s64 = 0;
	// fadds f3,f31,f29
	ctx.f3.f64 = double(float(f31.f64 + f29.f64));
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fsubs f2,f30,f29
	ctx.f2.f64 = double(float(f30.f64 - f29.f64));
	// fsubs f1,f31,f29
	ctx.f1.f64 = double(float(f31.f64 - f29.f64));
	// bl 0x820972f8
	sub_820972F8(ctx, base);
loc_820CBD34:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// addi r29,r29,112
	r29.s64 = r29.s64 + 112;
	// cmpw cr6,r30,r25
	cr6.compare<int32_t>(r30.s32, r25.s32, xer);
	// blt cr6,0x820cbbd4
	if (cr6.getLT()) goto loc_820CBBD4;
loc_820CBD48:
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// addi r12,r1,-72
	r12.s64 = ctx.r1.s64 + -72;
	// bl 0x823ed578
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_820CBD58"))) PPC_WEAK_FUNC(sub_820CBD58);
PPC_FUNC_IMPL(__imp__sub_820CBD58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stfd f30,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, f30.u64);
	// stfd f31,-40(r1)
	PPC_STORE_U64(ctx.r1.u32 + -40, f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// beq cr6,0x820cbf04
	if (cr6.getEQ()) goto loc_820CBF04;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,8260(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8260);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x820cbf04
	if (!cr6.getEQ()) goto loc_820CBF04;
	// lwz r11,480(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 480);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820cbf04
	if (!cr6.getEQ()) goto loc_820CBF04;
	// li r3,23
	ctx.r3.s64 = 23;
	// bl 0x82136fa0
	sub_82136FA0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820cbf04
	if (!cr6.getEQ()) goto loc_820CBF04;
	// bl 0x8210e400
	sub_8210E400(ctx, base);
	// extsh r31,r3
	r31.s64 = ctx.r3.s16;
	// bl 0x8210e290
	sub_8210E290(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lis r31,-32190
	r31.s64 = -2109603840;
	// addi r11,r11,-25
	r11.s64 = r11.s64 + -25;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, r11.u64);
	// lfd f0,120(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f13,f0
	ctx.f13.f64 = double(float(f0.f64));
	// lfs f0,19380(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 19380);
	f0.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, f0.u32);
	// bl 0x8210e2f0
	sub_8210E2F0(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// addi r10,r1,120
	ctx.r10.s64 = ctx.r1.s64 + 120;
	// addi r11,r11,10
	r11.s64 = r11.s64 + 10;
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, r11.u64);
	// lfd f0,120(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f13,f0
	ctx.f13.f64 = double(float(f0.f64));
	// lfs f0,19380(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 19380);
	f0.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, f0.u32);
	// ble cr6,0x820cbe4c
	if (!cr6.getGT()) goto loc_820CBE4C;
	// clrlwi r11,r29,31
	r11.u64 = r29.u32 & 0x1;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820cbe4c
	if (!cr6.getEQ()) goto loc_820CBE4C;
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// addi r30,r11,15
	r30.s64 = r11.s64 + 15;
	// b 0x820cbe50
	goto loc_820CBE50;
loc_820CBE4C:
	// lwz r30,112(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_820CBE50:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820eb9a8
	sub_820EB9A8(ctx, base);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lfs f31,19380(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 19380);
	f31.f64 = double(temp.f32);
	// rlwinm r10,r3,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r11,r11,27480
	r11.s64 = r11.s64 + 27480;
	// lfs f0,15412(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 15412);
	f0.f64 = double(temp.f32);
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + r11.u64;
	// fmuls f30,f31,f0
	f30.f64 = double(float(f31.f64 * f0.f64));
	// bl 0x821463f0
	sub_821463F0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r7,2
	ctx.r7.s64 = 2;
	// bl 0x82096fb0
	sub_82096FB0(ctx, base);
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// extsw r9,r30
	ctx.r9.s64 = r30.s32;
	// extsw r10,r11
	ctx.r10.s64 = r11.s32;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// std r9,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r9.u64);
	// lfd f13,112(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// std r10,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r10.u64);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// lfs f0,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lfs f10,19376(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 19376);
	ctx.f10.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// fsubs f12,f0,f10
	ctx.f12.f64 = double(float(f0.f64 - ctx.f10.f64));
	// lfd f0,120(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// fmr f9,f10
	ctx.f9.f64 = ctx.f10.f64;
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// lfs f4,19372(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 19372);
	ctx.f4.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lfs f3,19368(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 19368);
	ctx.f3.f64 = double(temp.f32);
	// fmr f2,f3
	ctx.f2.f64 = ctx.f3.f64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmr f1,f3
	ctx.f1.f64 = ctx.f3.f64;
	// fmr f11,f12
	ctx.f11.f64 = ctx.f12.f64;
	// fadds f7,f13,f30
	ctx.f7.f64 = double(float(ctx.f13.f64 + f30.f64));
	// fsubs f5,f13,f30
	ctx.f5.f64 = double(float(ctx.f13.f64 - f30.f64));
	// fadds f8,f0,f31
	ctx.f8.f64 = double(float(f0.f64 + f31.f64));
	// fsubs f6,f0,f31
	ctx.f6.f64 = double(float(f0.f64 - f31.f64));
	// bl 0x82098638
	sub_82098638(ctx, base);
loc_820CBF04:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f30,-48(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// lfd f31,-40(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820CBF18"))) PPC_WEAK_FUNC(sub_820CBF18);
PPC_FUNC_IMPL(__imp__sub_820CBF18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-792(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -792);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cbf44
	if (cr6.getEQ()) goto loc_820CBF44;
	// clrlwi r10,r3,16
	ctx.r10.u64 = ctx.r3.u32 & 0xFFFF;
loc_820CBF2C:
	// lhz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U16(r11.u32 + 4);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// beq cr6,0x820cbf4c
	if (cr6.getEQ()) goto loc_820CBF4C;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cbf2c
	if (!cr6.getEQ()) goto loc_820CBF2C;
loc_820CBF44:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_820CBF4C:
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CBF58"))) PPC_WEAK_FUNC(sub_820CBF58);
PPC_FUNC_IMPL(__imp__sub_820CBF58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-792(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -792);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cbf84
	if (cr6.getEQ()) goto loc_820CBF84;
	// clrlwi r10,r3,16
	ctx.r10.u64 = ctx.r3.u32 & 0xFFFF;
loc_820CBF6C:
	// lhz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U16(r11.u32 + 4);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// beq cr6,0x820cbf88
	if (cr6.getEQ()) goto loc_820CBF88;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cbf6c
	if (!cr6.getEQ()) goto loc_820CBF6C;
loc_820CBF84:
	// li r11,0
	r11.s64 = 0;
loc_820CBF88:
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lwz r3,12(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lwz r11,100(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 100);
	// rlwinm r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CBFB8"))) PPC_WEAK_FUNC(sub_820CBFB8);
PPC_FUNC_IMPL(__imp__sub_820CBFB8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,-884(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -884);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cc00c
	if (cr6.getEQ()) goto loc_820CC00C;
loc_820CBFDC:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// beq cr6,0x820cbff8
	if (cr6.getEQ()) goto loc_820CBFF8;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cbfdc
	if (!cr6.getEQ()) goto loc_820CBFDC;
	// b 0x820cc00c
	goto loc_820CC00C;
loc_820CBFF8:
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// clrlwi r3,r11,16
	ctx.r3.u64 = r11.u32 & 0xFFFF;
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x820cc038
	if (!cr6.getEQ()) goto loc_820CC038;
loc_820CC00C:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// lis r3,0
	ctx.r3.s64 = 0;
	// bne cr6,0x820cc020
	if (!cr6.getEQ()) goto loc_820CC020;
	// ori r3,r3,45097
	ctx.r3.u64 = ctx.r3.u64 | 45097;
	// b 0x820cc034
	goto loc_820CC034;
loc_820CC020:
	// cmpwi cr6,r31,1
	cr6.compare<int32_t>(r31.s32, 1, xer);
	// bne cr6,0x820cc030
	if (!cr6.getEQ()) goto loc_820CC030;
	// ori r3,r3,45098
	ctx.r3.u64 = ctx.r3.u64 | 45098;
	// b 0x820cc034
	goto loc_820CC034;
loc_820CC030:
	// ori r3,r3,45099
	ctx.r3.u64 = ctx.r3.u64 | 45099;
loc_820CC034:
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
loc_820CC038:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CC050"))) PPC_WEAK_FUNC(sub_820CC050);
PPC_FUNC_IMPL(__imp__sub_820CC050) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r11,19384(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19384);
	// addi r3,r11,1
	ctx.r3.s64 = r11.s64 + 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CC060"))) PPC_WEAK_FUNC(sub_820CC060);
PPC_FUNC_IMPL(__imp__sub_820CC060) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// bge cr6,0x820cc08c
	if (!cr6.getLT()) goto loc_820CC08C;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-876
	r11.s64 = r11.s64 + -876;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cc08c
	if (cr6.getEQ()) goto loc_820CC08C;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// clrlwi r3,r11,16
	ctx.r3.u64 = r11.u32 & 0xFFFF;
	// b 0x82136ad8
	sub_82136AD8(ctx, base);
	return;
loc_820CC08C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CC098"))) PPC_WEAK_FUNC(sub_820CC098);
PPC_FUNC_IMPL(__imp__sub_820CC098) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// bge cr6,0x820cc0c4
	if (!cr6.getLT()) goto loc_820CC0C4;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-876
	r11.s64 = r11.s64 + -876;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cc0c4
	if (cr6.getEQ()) goto loc_820CC0C4;
	// lbz r11,15(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 15);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// blr 
	return;
loc_820CC0C4:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CC0D0"))) PPC_WEAK_FUNC(sub_820CC0D0);
PPC_FUNC_IMPL(__imp__sub_820CC0D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r28,1
	r28.s64 = 1;
	// cmpwi cr6,r3,10
	cr6.compare<int32_t>(ctx.r3.s32, 10, xer);
	// bge cr6,0x820cc328
	if (!cr6.getLT()) goto loc_820CC328;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,-876
	ctx.r10.s64 = ctx.r10.s64 + -876;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820cc114
	if (!cr6.getEQ()) goto loc_820CC114;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// addi r10,r10,-836
	ctx.r10.s64 = ctx.r10.s64 + -836;
	// lwzx r3,r11,r10
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820CC114:
	// mr r29,r10
	r29.u64 = ctx.r10.u64;
	// lbz r4,3(r29)
	ctx.r4.u64 = PPC_LOAD_U8(r29.u32 + 3);
	// cmplwi cr6,r4,24
	cr6.compare<uint32_t>(ctx.r4.u32, 24, xer);
	// beq cr6,0x820cc328
	if (cr6.getEQ()) goto loc_820CC328;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r27,r11,16080
	r27.s64 = r11.s64 + 16080;
loc_820CC12C:
	// addi r11,r4,-23
	r11.s64 = ctx.r4.s64 + -23;
	// li r30,1
	r30.s64 = 1;
	// cmplwi cr6,r11,11
	cr6.compare<uint32_t>(r11.u32, 11, xer);
	// bgt cr6,0x820cc2d8
	if (cr6.getGT()) goto loc_820CC2D8;
	// lis r12,-32243
	r12.s64 = -2113077248;
	// addi r12,r12,-16044
	r12.s64 = r12.s64 + -16044;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820CC2E0;
	case 1:
		goto loc_820CC2E0;
	case 2:
		goto loc_820CC184;
	case 3:
		goto loc_820CC1B4;
	case 4:
		goto loc_820CC1D0;
	case 5:
		goto loc_820CC1EC;
	case 6:
		goto loc_820CC230;
	case 7:
		goto loc_820CC260;
	case 8:
		goto loc_820CC2E0;
	case 9:
		goto loc_820CC29C;
	case 10:
		goto loc_820CC2B0;
	case 11:
		goto loc_820CC2C4;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-15648(r12)
	r16.u64 = PPC_LOAD_U32(r12.u32 + -15648);
	// lwz r16,-15648(r12)
	r16.u64 = PPC_LOAD_U32(r12.u32 + -15648);
	// lwz r16,-15996(r12)
	r16.u64 = PPC_LOAD_U32(r12.u32 + -15996);
	// lwz r16,-15948(r12)
	r16.u64 = PPC_LOAD_U32(r12.u32 + -15948);
	// lwz r16,-15920(r12)
	r16.u64 = PPC_LOAD_U32(r12.u32 + -15920);
	// lwz r16,-15892(r12)
	r16.u64 = PPC_LOAD_U32(r12.u32 + -15892);
	// lwz r16,-15824(r12)
	r16.u64 = PPC_LOAD_U32(r12.u32 + -15824);
	// lwz r16,-15776(r12)
	r16.u64 = PPC_LOAD_U32(r12.u32 + -15776);
	// lwz r16,-15648(r12)
	r16.u64 = PPC_LOAD_U32(r12.u32 + -15648);
	// lwz r16,-15716(r12)
	r16.u64 = PPC_LOAD_U32(r12.u32 + -15716);
	// lwz r16,-15696(r12)
	r16.u64 = PPC_LOAD_U32(r12.u32 + -15696);
	// lwz r16,-15676(r12)
	r16.u64 = PPC_LOAD_U32(r12.u32 + -15676);
loc_820CC184:
	// lwz r3,4(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// bl 0x820cbf58
	sub_820CBF58(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820cc2e0
	if (cr6.getEQ()) goto loc_820CC2E0;
	// lwz r11,16(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cc2e0
	if (cr6.getEQ()) goto loc_820CC2E0;
	// bl 0x820db380
	sub_820DB380(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cc2e0
	if (cr6.getEQ()) goto loc_820CC2E0;
	// li r30,0
	r30.s64 = 0;
	// b 0x820cc2e0
	goto loc_820CC2E0;
loc_820CC1B4:
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r4,4(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// bl 0x82126830
	sub_82126830(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820cc2e0
	if (!cr6.getEQ()) goto loc_820CC2E0;
	// li r30,0
	r30.s64 = 0;
	// b 0x820cc2e0
	goto loc_820CC2E0;
loc_820CC1D0:
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r4,4(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// bl 0x82126830
	sub_82126830(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cc2e0
	if (cr6.getEQ()) goto loc_820CC2E0;
loc_820CC1E4:
	// li r30,2
	r30.s64 = 2;
	// b 0x820cc2e0
	goto loc_820CC2E0;
loc_820CC1EC:
	// lwz r3,4(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// bl 0x820cbf58
	sub_820CBF58(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820cc1e4
	if (cr6.getEQ()) goto loc_820CC1E4;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cc1e4
	if (cr6.getEQ()) goto loc_820CC1E4;
	// bl 0x820db380
	sub_820DB380(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cc1e4
	if (cr6.getEQ()) goto loc_820CC1E4;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x820c1630
	sub_820C1630(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820cc2e0
	if (!cr6.getEQ()) goto loc_820CC2E0;
	// li r30,0
	r30.s64 = 0;
	// b 0x820cc2e0
	goto loc_820CC2E0;
loc_820CC230:
	// lwz r3,4(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// bl 0x820cbf58
	sub_820CBF58(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820cc2e0
	if (cr6.getEQ()) goto loc_820CC2E0;
	// lwz r3,16(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820cc2e0
	if (cr6.getEQ()) goto loc_820CC2E0;
	// bl 0x820c1630
	sub_820C1630(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cc2e0
	if (cr6.getEQ()) goto loc_820CC2E0;
	// li r30,0
	r30.s64 = 0;
	// b 0x820cc2e0
	goto loc_820CC2E0;
loc_820CC260:
	// lwz r3,4(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// bl 0x820cbf58
	sub_820CBF58(ctx, base);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cc2e0
	if (!cr6.getEQ()) goto loc_820CC2E0;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820cc1e4
	if (cr6.getEQ()) goto loc_820CC1E4;
	// lwz r11,16(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cc1e4
	if (cr6.getEQ()) goto loc_820CC1E4;
	// bl 0x820db380
	sub_820DB380(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cc1e4
	if (cr6.getEQ()) goto loc_820CC1E4;
	// li r30,0
	r30.s64 = 0;
	// b 0x820cc2e0
	goto loc_820CC2E0;
loc_820CC29C:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cc2e0
	if (!cr6.getEQ()) goto loc_820CC2E0;
	// li r30,0
	r30.s64 = 0;
	// b 0x820cc2e0
	goto loc_820CC2E0;
loc_820CC2B0:
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cc2e0
	if (!cr6.getEQ()) goto loc_820CC2E0;
	// li r30,0
	r30.s64 = 0;
	// b 0x820cc2e0
	goto loc_820CC2E0;
loc_820CC2C4:
	// bl 0x820a4238
	sub_820A4238(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820cc2e0
	if (!cr6.getEQ()) goto loc_820CC2E0;
	// li r30,0
	r30.s64 = 0;
	// b 0x820cc2e0
	goto loc_820CC2E0;
loc_820CC2D8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
loc_820CC2E0:
	// cmpwi cr6,r28,1
	cr6.compare<int32_t>(r28.s32, 1, xer);
	// bne cr6,0x820cc2f8
	if (!cr6.getEQ()) goto loc_820CC2F8;
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// beq cr6,0x820cc30c
	if (cr6.getEQ()) goto loc_820CC30C;
	// mr r28,r30
	r28.u64 = r30.u64;
	// b 0x820cc30c
	goto loc_820CC30C;
loc_820CC2F8:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// bne cr6,0x820cc30c
	if (!cr6.getEQ()) goto loc_820CC30C;
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// bne cr6,0x820cc30c
	if (!cr6.getEQ()) goto loc_820CC30C;
	// li r28,2
	r28.s64 = 2;
loc_820CC30C:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820d0010
	sub_820D0010(ctx, base);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// add r29,r11,r29
	r29.u64 = r11.u64 + r29.u64;
	// lbz r4,3(r29)
	ctx.r4.u64 = PPC_LOAD_U8(r29.u32 + 3);
	// cmplwi cr6,r4,24
	cr6.compare<uint32_t>(ctx.r4.u32, 24, xer);
	// bne cr6,0x820cc12c
	if (!cr6.getEQ()) goto loc_820CC12C;
loc_820CC328:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820CC338"))) PPC_WEAK_FUNC(sub_820CC338);
PPC_FUNC_IMPL(__imp__sub_820CC338) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r28,-32190
	r28.s64 = -2109603840;
	// li r31,0
	r31.s64 = 0;
	// lwz r11,19384(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 19384);
	// addic. r11,r11,1
	xer.ca = r11.u32 > 4294967294;
	r11.s64 = r11.s64 + 1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x820cc3b8
	if (!cr0.getGT()) goto loc_820CC3B8;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r29,r11,-876
	r29.s64 = r11.s64 + -876;
loc_820CC360:
	// cmpwi cr6,r31,10
	cr6.compare<int32_t>(r31.s32, 10, xer);
	// bge cr6,0x820cc380
	if (!cr6.getLT()) goto loc_820CC380;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cc380
	if (cr6.getEQ()) goto loc_820CC380;
	// lbz r11,15(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 15);
	// extsb r30,r11
	r30.s64 = r11.s8;
	// b 0x820cc384
	goto loc_820CC384;
loc_820CC380:
	// li r30,0
	r30.s64 = 0;
loc_820CC384:
	// bl 0x8209f598
	sub_8209F598(ctx, base);
	// cmpw cr6,r30,r3
	cr6.compare<int32_t>(r30.s32, ctx.r3.s32, xer);
	// bgt cr6,0x820cc3a0
	if (cr6.getGT()) goto loc_820CC3A0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cc0d0
	sub_820CC0D0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x820cc3c4
	if (!cr6.getEQ()) goto loc_820CC3C4;
loc_820CC3A0:
	// lwz r11,19384(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 19384);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmpw cr6,r31,r11
	cr6.compare<int32_t>(r31.s32, r11.s32, xer);
	// blt cr6,0x820cc360
	if (cr6.getLT()) goto loc_820CC360;
loc_820CC3B8:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_820CC3C4:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820CC3D0"))) PPC_WEAK_FUNC(sub_820CC3D0);
PPC_FUNC_IMPL(__imp__sub_820CC3D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// li r11,1
	r11.s64 = 1;
	// stw r11,-788(r10)
	PPC_STORE_U32(ctx.r10.u32 + -788, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CC3E0"))) PPC_WEAK_FUNC(sub_820CC3E0);
PPC_FUNC_IMPL(__imp__sub_820CC3E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed118
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r5,98
	ctx.r5.s64 = 98;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,82
	ctx.r3.s64 = ctx.r1.s64 + 82;
	// lhz r11,3292(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 3292);
	// sth r11,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, r11.u16);
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-788(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -788);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820cc588
	if (!cr6.getEQ()) goto loc_820CC588;
	// lis r20,-32190
	r20.s64 = -2109603840;
	// li r28,0
	r28.s64 = 0;
	// lwz r11,19384(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 19384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x820cc588
	if (cr6.getLT()) goto loc_820CC588;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// li r21,97
	r21.s64 = 97;
	// addi r26,r11,-876
	r26.s64 = r11.s64 + -876;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r29,0
	r29.s64 = 0;
	// addi r25,r11,16124
	r25.s64 = r11.s64 + 16124;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r22,-31994
	r22.s64 = -2096758784;
	// addi r24,r11,16108
	r24.s64 = r11.s64 + 16108;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r27,r11,-836
	r27.s64 = r11.s64 + -836;
	// lis r11,0
	r11.s64 = 0;
	// ori r23,r11,45100
	r23.u64 = r11.u64 | 45100;
loc_820CC460:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x820cc0d0
	sub_820CC0D0(ctx, base);
	// lwzx r11,r29,r27
	r11.u64 = PPC_LOAD_U32(r29.u32 + r27.u32);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpw cr6,r30,r11
	cr6.compare<int32_t>(r30.s32, r11.s32, xer);
	// beq cr6,0x820cc540
	if (cr6.getEQ()) goto loc_820CC540;
	// cmpwi cr6,r28,10
	cr6.compare<int32_t>(r28.s32, 10, xer);
	// stwx r30,r29,r27
	PPC_STORE_U32(r29.u32 + r27.u32, r30.u32);
	// bge cr6,0x820cc49c
	if (!cr6.getLT()) goto loc_820CC49C;
	// lwzx r11,r29,r26
	r11.u64 = PPC_LOAD_U32(r29.u32 + r26.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cc49c
	if (cr6.getEQ()) goto loc_820CC49C;
	// lbz r11,15(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 15);
	// extsb r31,r11
	r31.s64 = r11.s8;
	// b 0x820cc4a0
	goto loc_820CC4A0;
loc_820CC49C:
	// li r31,0
	r31.s64 = 0;
loc_820CC4A0:
	// bl 0x8209f598
	sub_8209F598(ctx, base);
	// cmpw cr6,r31,r3
	cr6.compare<int32_t>(r31.s32, ctx.r3.s32, xer);
	// bgt cr6,0x820cc540
	if (cr6.getGT()) goto loc_820CC540;
	// lwz r11,11488(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 11488);
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820cc4d0
	if (cr6.getEQ()) goto loc_820CC4D0;
	// addi r31,r21,-71
	r31.s64 = r21.s64 + -71;
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// b 0x820cc4dc
	goto loc_820CC4DC;
loc_820CC4D0:
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
loc_820CC4DC:
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// li r4,50
	ctx.r4.s64 = 50;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823eda88
	sub_823EDA88(ctx, base);
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// bne cr6,0x820cc500
	if (!cr6.getEQ()) goto loc_820CC500;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,45101
	ctx.r3.u64 = ctx.r3.u64 | 45101;
	// b 0x820cc524
	goto loc_820CC524;
loc_820CC500:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x820cc514
	if (!cr6.getEQ()) goto loc_820CC514;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,45102
	ctx.r3.u64 = ctx.r3.u64 | 45102;
	// b 0x820cc524
	goto loc_820CC524;
loc_820CC514:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// bne cr6,0x820cc538
	if (!cr6.getEQ()) goto loc_820CC538;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,45103
	ctx.r3.u64 = ctx.r3.u64 | 45103;
loc_820CC524:
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,50
	ctx.r4.s64 = 50;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823ee840
	sub_823EE840(ctx, base);
loc_820CC538:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820b4260
	sub_820B4260(ctx, base);
loc_820CC540:
	// cmpwi cr6,r28,10
	cr6.compare<int32_t>(r28.s32, 10, xer);
	// bge cr6,0x820cc560
	if (!cr6.getLT()) goto loc_820CC560;
	// lwzx r11,r29,r26
	r11.u64 = PPC_LOAD_U32(r29.u32 + r26.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cc560
	if (cr6.getEQ()) goto loc_820CC560;
	// lbz r11,15(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 15);
	// extsb r31,r11
	r31.s64 = r11.s8;
	// b 0x820cc564
	goto loc_820CC564;
loc_820CC560:
	// li r31,0
	r31.s64 = 0;
loc_820CC564:
	// bl 0x8209f598
	sub_8209F598(ctx, base);
	// cmpw cr6,r31,r3
	cr6.compare<int32_t>(r31.s32, ctx.r3.s32, xer);
	// bgt cr6,0x820cc574
	if (cr6.getGT()) goto loc_820CC574;
	// addi r21,r21,1
	r21.s64 = r21.s64 + 1;
loc_820CC574:
	// lwz r11,19384(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 19384);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmpw cr6,r28,r11
	cr6.compare<int32_t>(r28.s32, r11.s32, xer);
	// ble cr6,0x820cc460
	if (!cr6.getGT()) goto loc_820CC460;
loc_820CC588:
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// b 0x823ed168
	return;
}

__attribute__((alias("__imp__sub_820CC590"))) PPC_WEAK_FUNC(sub_820CC590);
PPC_FUNC_IMPL(__imp__sub_820CC590) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r8,-888(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + -888);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r9,r11,928
	ctx.r9.s64 = r11.s64 + 928;
loc_820CC5AC:
	// lwz r11,8(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cc5fc
	if (!cr6.getEQ()) goto loc_820CC5FC;
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmplwi cr6,r11,10000
	cr6.compare<uint32_t>(r11.u32, 10000, xer);
	// bge cr6,0x820cc5d0
	if (!cr6.getLT()) goto loc_820CC5D0;
	// lwz r10,24(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// mulli r11,r11,44
	r11.s64 = r11.s64 * 44;
	// b 0x820cc5dc
	goto loc_820CC5DC;
loc_820CC5D0:
	// addi r11,r11,-10000
	r11.s64 = r11.s64 + -10000;
	// lwz r10,28(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28);
	// mulli r11,r11,68
	r11.s64 = r11.s64 * 68;
loc_820CC5DC:
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cc5fc
	if (cr6.getEQ()) goto loc_820CC5FC;
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmpw cr6,r11,r3
	cr6.compare<int32_t>(r11.s32, ctx.r3.s32, xer);
	// bne cr6,0x820cc5fc
	if (!cr6.getEQ()) goto loc_820CC5FC;
	// stw r7,8(r8)
	PPC_STORE_U32(ctx.r8.u32 + 8, ctx.r7.u32);
loc_820CC5FC:
	// lwz r8,12(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820cc5ac
	if (!cr6.getEQ()) goto loc_820CC5AC;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CC610"))) PPC_WEAK_FUNC(sub_820CC610);
PPC_FUNC_IMPL(__imp__sub_820CC610) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r8,-796(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + -796);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r9,r11,928
	ctx.r9.s64 = r11.s64 + 928;
loc_820CC62C:
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cc688
	if (!cr6.getEQ()) goto loc_820CC688;
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// cmpw cr6,r3,r11
	cr6.compare<int32_t>(ctx.r3.s32, r11.s32, xer);
	// bne cr6,0x820cc688
	if (!cr6.getEQ()) goto loc_820CC688;
	// lwz r11,8(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// cmplwi cr6,r11,10000
	cr6.compare<uint32_t>(r11.u32, 10000, xer);
	// bge cr6,0x820cc65c
	if (!cr6.getLT()) goto loc_820CC65C;
	// lwz r10,24(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	// mulli r11,r11,44
	r11.s64 = r11.s64 * 44;
	// b 0x820cc668
	goto loc_820CC668;
loc_820CC65C:
	// addi r11,r11,-10000
	r11.s64 = r11.s64 + -10000;
	// lwz r10,28(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28);
	// mulli r11,r11,68
	r11.s64 = r11.s64 * 68;
loc_820CC668:
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cc688
	if (cr6.getEQ()) goto loc_820CC688;
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmpw cr6,r11,r4
	cr6.compare<int32_t>(r11.s32, ctx.r4.s32, xer);
	// bne cr6,0x820cc688
	if (!cr6.getEQ()) goto loc_820CC688;
	// stw r7,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, ctx.r7.u32);
loc_820CC688:
	// lwz r8,16(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 16);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820cc62c
	if (!cr6.getEQ()) goto loc_820CC62C;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CC698"))) PPC_WEAK_FUNC(sub_820CC698);
PPC_FUNC_IMPL(__imp__sub_820CC698) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stfd f30,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, f30.u64);
	// stfd f31,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r30,-880(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + -880);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820cc858
	if (cr6.getEQ()) goto loc_820CC858;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r29,-32014
	r29.s64 = -2098069504;
	// li r28,1
	r28.s64 = 1;
	// lfs f31,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
loc_820CC6CC:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cc84c
	if (!cr6.getEQ()) goto loc_820CC84C;
	// lwz r11,-792(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -792);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cc704
	if (cr6.getEQ()) goto loc_820CC704;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
loc_820CC6EC:
	// lhz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U16(r11.u32 + 4);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// beq cr6,0x820cc708
	if (cr6.getEQ()) goto loc_820CC708;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cc6ec
	if (!cr6.getEQ()) goto loc_820CC6EC;
loc_820CC704:
	// li r11,0
	r11.s64 = 0;
loc_820CC708:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cc84c
	if (cr6.getEQ()) goto loc_820CC84C;
	// lwz r31,12(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820cc84c
	if (cr6.getEQ()) goto loc_820CC84C;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cc84c
	if (cr6.getEQ()) goto loc_820CC84C;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cc84c
	if (cr6.getEQ()) goto loc_820CC84C;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// rlwinm r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820cc84c
	if (cr6.getEQ()) goto loc_820CC84C;
	// lfs f0,28(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 28);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// blt cr6,0x820cc84c
	if (cr6.getLT()) goto loc_820CC84C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820db380
	sub_820DB380(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cc84c
	if (cr6.getEQ()) goto loc_820CC84C;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// bl 0x820dc538
	sub_820DC538(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cc84c
	if (cr6.getEQ()) goto loc_820CC84C;
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x820d4698
	sub_820D4698(ctx, base);
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f1
	cr6.compare(f0.f64, ctx.f1.f64);
	// ble cr6,0x820cc84c
	if (!cr6.getGT()) goto loc_820CC84C;
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// fadds f0,f30,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f30.f64 + ctx.f1.f64));
	// lfs f13,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820cc84c
	if (!cr6.getLT()) goto loc_820CC84C;
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// lfs f0,88(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f1
	cr6.compare(f0.f64, ctx.f1.f64);
	// ble cr6,0x820cc84c
	if (!cr6.getGT()) goto loc_820CC84C;
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// fadds f0,f30,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f30.f64 + ctx.f1.f64));
	// lfs f13,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820cc84c
	if (!cr6.getLT()) goto loc_820CC84C;
	// bl 0x8210d8d0
	sub_8210D8D0(ctx, base);
	// lfs f0,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f1
	cr6.compare(f0.f64, ctx.f1.f64);
	// ble cr6,0x820cc84c
	if (!cr6.getGT()) goto loc_820CC84C;
	// bl 0x8210d8d0
	sub_8210D8D0(ctx, base);
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// bl 0x8210d8b0
	sub_8210D8B0(ctx, base);
	// fadds f0,f30,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f30.f64 + ctx.f1.f64));
	// lfs f13,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820cc84c
	if (!cr6.getLT()) goto loc_820CC84C;
	// bl 0x8210d8d0
	sub_8210D8D0(ctx, base);
	// lfs f0,92(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f1
	cr6.compare(f0.f64, ctx.f1.f64);
	// ble cr6,0x820cc84c
	if (!cr6.getGT()) goto loc_820CC84C;
	// bl 0x8210d8d0
	sub_8210D8D0(ctx, base);
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// bl 0x8210d8b0
	sub_8210D8B0(ctx, base);
	// fadds f0,f30,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f30.f64 + ctx.f1.f64));
	// lfs f13,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820cc84c
	if (!cr6.getLT()) goto loc_820CC84C;
	// stw r28,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r28.u32);
loc_820CC84C:
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x820cc6cc
	if (!cr6.getEQ()) goto loc_820CC6CC;
loc_820CC858:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f30,-56(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820CC868"))) PPC_WEAK_FUNC(sub_820CC868);
PPC_FUNC_IMPL(__imp__sub_820CC868) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// li r11,0
	r11.s64 = 0;
	// addi r9,r10,-836
	ctx.r9.s64 = ctx.r10.s64 + -836;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r8,r10,-876
	ctx.r8.s64 = ctx.r10.s64 + -876;
loc_820CC880:
	// lwzx r10,r11,r8
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820cc8ac
	if (cr6.getEQ()) goto loc_820CC8AC;
	// lbz r10,14(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 14);
	// clrlwi r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820cc8ac
	if (cr6.getEQ()) goto loc_820CC8AC;
	// lwzx r10,r11,r9
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// beq cr6,0x820cc8ac
	if (cr6.getEQ()) goto loc_820CC8AC;
	// stwx r7,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r7.u32);
loc_820CC8AC:
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmpwi cr6,r11,40
	cr6.compare<int32_t>(r11.s32, 40, xer);
	// blt cr6,0x820cc880
	if (cr6.getLT()) goto loc_820CC880;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CC8C0"))) PPC_WEAK_FUNC(sub_820CC8C0);
PPC_FUNC_IMPL(__imp__sub_820CC8C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820ae360
	sub_820AE360(ctx, base);
	// cmpwi cr6,r3,90
	cr6.compare<int32_t>(ctx.r3.s32, 90, xer);
	// beq cr6,0x820cc904
	if (cr6.getEQ()) goto loc_820CC904;
	// lis r9,-32190
	ctx.r9.s64 = -2109603840;
	// li r10,-1
	ctx.r10.s64 = -1;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r11,r11,-836
	r11.s64 = r11.s64 + -836;
	// stw r10,19384(r9)
	PPC_STORE_U32(ctx.r9.u32 + 19384, ctx.r10.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r10,10
	ctx.r10.s64 = 10;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_820CC8F8:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x820cc8f8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820CC8F8;
loc_820CC904:
	// lis r9,-32014
	ctx.r9.s64 = -2098069504;
	// li r10,0
	ctx.r10.s64 = 0;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r11,r11,-876
	r11.s64 = r11.s64 + -876;
	// stw r10,-788(r9)
	PPC_STORE_U32(ctx.r9.u32 + -788, ctx.r10.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r10,10
	ctx.r10.s64 = 10;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_820CC924:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x820cc924
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820CC924;
	// li r11,0
	r11.s64 = 0;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// stw r11,-792(r10)
	PPC_STORE_U32(ctx.r10.u32 + -792, r11.u32);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// stw r11,-884(r10)
	PPC_STORE_U32(ctx.r10.u32 + -884, r11.u32);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// stw r11,-888(r10)
	PPC_STORE_U32(ctx.r10.u32 + -888, r11.u32);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// stw r11,-796(r10)
	PPC_STORE_U32(ctx.r10.u32 + -796, r11.u32);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// stw r11,-880(r10)
	PPC_STORE_U32(ctx.r10.u32 + -880, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CC970"))) PPC_WEAK_FUNC(sub_820CC970);
PPC_FUNC_IMPL(__imp__sub_820CC970) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,-792(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -792);
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r3,-792(r11)
	PPC_STORE_U32(r11.u32 + -792, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CC988"))) PPC_WEAK_FUNC(sub_820CC988);
PPC_FUNC_IMPL(__imp__sub_820CC988) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,-884(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -884);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r3,-884(r11)
	PPC_STORE_U32(r11.u32 + -884, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CC9A0"))) PPC_WEAK_FUNC(sub_820CC9A0);
PPC_FUNC_IMPL(__imp__sub_820CC9A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r11,r11,-876
	r11.s64 = r11.s64 + -876;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r3,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r3.u32);
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r9,19384(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 19384);
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// blelr cr6
	if (!cr6.getGT()) return;
	// stw r11,19384(r10)
	PPC_STORE_U32(ctx.r10.u32 + 19384, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CC9D0"))) PPC_WEAK_FUNC(sub_820CC9D0);
PPC_FUNC_IMPL(__imp__sub_820CC9D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,-888(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -888);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r3,-888(r11)
	PPC_STORE_U32(r11.u32 + -888, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CC9E8"))) PPC_WEAK_FUNC(sub_820CC9E8);
PPC_FUNC_IMPL(__imp__sub_820CC9E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,-796(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -796);
	// stw r10,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, ctx.r10.u32);
	// stw r3,-796(r11)
	PPC_STORE_U32(r11.u32 + -796, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CCA00"))) PPC_WEAK_FUNC(sub_820CCA00);
PPC_FUNC_IMPL(__imp__sub_820CCA00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,-880(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -880);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// stw r3,-880(r11)
	PPC_STORE_U32(r11.u32 + -880, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CCA18"))) PPC_WEAK_FUNC(sub_820CCA18);
PPC_FUNC_IMPL(__imp__sub_820CCA18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lbz r11,1(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// stb r11,1(r3)
	PPC_STORE_U8(ctx.r3.u32 + 1, r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CCA28"))) PPC_WEAK_FUNC(sub_820CCA28);
PPC_FUNC_IMPL(__imp__sub_820CCA28) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// lbz r11,1(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1);
	// andi. r11,r11,251
	r11.u64 = r11.u64 & 251;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stb r11,1(r3)
	PPC_STORE_U8(ctx.r3.u32 + 1, r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CCA38"))) PPC_WEAK_FUNC(sub_820CCA38);
PPC_FUNC_IMPL(__imp__sub_820CCA38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r3,908(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 908);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CCA48"))) PPC_WEAK_FUNC(sub_820CCA48);
PPC_FUNC_IMPL(__imp__sub_820CCA48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r9,-32013
	ctx.r9.s64 = -2098003968;
	// lwz r31,916(r9)
	r31.u64 = PPC_LOAD_U32(ctx.r9.u32 + 916);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820ccae4
	if (cr6.getEQ()) goto loc_820CCAE4;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// addi r10,r31,40
	ctx.r10.s64 = r31.s64 + 40;
	// stw r11,916(r9)
	PPC_STORE_U32(ctx.r9.u32 + 916, r11.u32);
	// li r11,0
	r11.s64 = 0;
	// li r9,255
	ctx.r9.s64 = 255;
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// stb r11,1(r31)
	PPC_STORE_U8(r31.u32 + 1, r11.u8);
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stb r9,48(r31)
	PPC_STORE_U8(r31.u32 + 48, ctx.r9.u8);
	// bl 0x8217ee38
	sub_8217EE38(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// li r10,-1
	ctx.r10.s64 = -1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f0,16144(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16144);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,68(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 68, temp.u32);
	// stw r9,56(r31)
	PPC_STORE_U32(r31.u32 + 56, ctx.r9.u32);
	// stw r10,60(r31)
	PPC_STORE_U32(r31.u32 + 60, ctx.r10.u32);
	// stw r10,64(r31)
	PPC_STORE_U32(r31.u32 + 64, ctx.r10.u32);
	// lfs f13,16140(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16140);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,72(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 72, temp.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_820CCAE4:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CCB00"))) PPC_WEAK_FUNC(sub_820CCB00);
PPC_FUNC_IMPL(__imp__sub_820CCB00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32013
	r11.s64 = -2098003968;
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r10,916(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 916);
	// stw r9,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, ctx.r9.u32);
	// stw r9,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r9.u32);
	// stw r10,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r10.u32);
	// stw r3,916(r11)
	PPC_STORE_U32(r11.u32 + 916, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CCB20"))) PPC_WEAK_FUNC(sub_820CCB20);
PPC_FUNC_IMPL(__imp__sub_820CCB20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r10,908(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 908);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820ccb4c
	if (cr6.getEQ()) goto loc_820CCB4C;
	// stw r3,44(r10)
	PPC_STORE_U32(ctx.r10.u32 + 44, ctx.r3.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r10,908(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 908);
	// stw r9,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, ctx.r9.u32);
	// stw r10,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r10.u32);
	// stw r3,908(r11)
	PPC_STORE_U32(r11.u32 + 908, ctx.r3.u32);
	// blr 
	return;
loc_820CCB4C:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r10.u32);
	// stw r10,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, ctx.r10.u32);
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// stw r3,908(r11)
	PPC_STORE_U32(r11.u32 + 908, ctx.r3.u32);
	// stw r3,912(r10)
	PPC_STORE_U32(ctx.r10.u32 + 912, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CCB68"))) PPC_WEAK_FUNC(sub_820CCB68);
PPC_FUNC_IMPL(__imp__sub_820CCB68) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r10,912(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 912);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820ccb94
	if (cr6.getEQ()) goto loc_820CCB94;
	// stw r3,40(r10)
	PPC_STORE_U32(ctx.r10.u32 + 40, ctx.r3.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r10,912(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 912);
	// stw r9,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r9.u32);
	// stw r10,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, ctx.r10.u32);
	// stw r3,912(r11)
	PPC_STORE_U32(r11.u32 + 912, ctx.r3.u32);
	// blr 
	return;
loc_820CCB94:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r10.u32);
	// stw r10,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, ctx.r10.u32);
	// stw r3,912(r11)
	PPC_STORE_U32(r11.u32 + 912, ctx.r3.u32);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// stw r3,908(r11)
	PPC_STORE_U32(r11.u32 + 908, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CCBB0"))) PPC_WEAK_FUNC(sub_820CCBB0);
PPC_FUNC_IMPL(__imp__sub_820CCBB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r10,908(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 908);
	// cmplw cr6,r10,r3
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r3.u32, xer);
	// bne cr6,0x820ccbc8
	if (!cr6.getEQ()) goto loc_820CCBC8;
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// stw r10,908(r11)
	PPC_STORE_U32(r11.u32 + 908, ctx.r10.u32);
loc_820CCBC8:
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r10,912(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 912);
	// cmplw cr6,r10,r3
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r3.u32, xer);
	// bne cr6,0x820ccbe0
	if (!cr6.getEQ()) goto loc_820CCBE0;
	// lwz r10,44(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// stw r10,912(r11)
	PPC_STORE_U32(r11.u32 + 912, ctx.r10.u32);
loc_820CCBE0:
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ccbf4
	if (cr6.getEQ()) goto loc_820CCBF4;
	// lwz r10,44(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// stw r10,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r10.u32);
loc_820CCBF4:
	// lwz r11,44(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ccc08
	if (cr6.getEQ()) goto loc_820CCC08;
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// stw r10,40(r11)
	PPC_STORE_U32(r11.u32 + 40, ctx.r10.u32);
loc_820CCC08:
	// li r11,0
	r11.s64 = 0;
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, r11.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CCC18"))) PPC_WEAK_FUNC(sub_820CCC18);
PPC_FUNC_IMPL(__imp__sub_820CCC18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// stw r4,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r4.u32);
	// lwz r11,36(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ccc2c
	if (cr6.getEQ()) goto loc_820CCC2C;
	// stw r3,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r3.u32);
loc_820CCC2C:
	// lwz r10,36(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 36);
	// li r11,0
	r11.s64 = 0;
	// stw r10,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r10.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r3,36(r4)
	PPC_STORE_U32(ctx.r4.u32 + 36, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CCC48"))) PPC_WEAK_FUNC(sub_820CCC48);
PPC_FUNC_IMPL(__imp__sub_820CCC48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,32(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// cmplw cr6,r10,r3
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r3.u32, xer);
	// bne cr6,0x820ccc68
	if (!cr6.getEQ()) goto loc_820CCC68;
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// stw r10,36(r11)
	PPC_STORE_U32(r11.u32 + 36, ctx.r10.u32);
loc_820CCC68:
	// lwz r11,40(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ccc7c
	if (cr6.getEQ()) goto loc_820CCC7C;
	// lwz r10,44(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// stw r10,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r10.u32);
loc_820CCC7C:
	// lwz r11,44(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ccc90
	if (cr6.getEQ()) goto loc_820CCC90;
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// stw r10,40(r11)
	PPC_STORE_U32(r11.u32 + 40, ctx.r10.u32);
loc_820CCC90:
	// li r11,0
	r11.s64 = 0;
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, r11.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CCCA8"))) PPC_WEAK_FUNC(sub_820CCCA8);
PPC_FUNC_IMPL(__imp__sub_820CCCA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,24(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cccc0
	if (!cr6.getEQ()) goto loc_820CCCC0;
	// li r11,-1
	r11.s64 = -1;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// blr 
	return;
loc_820CCCC0:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// cmplwi cr6,r10,6
	cr6.compare<uint32_t>(ctx.r10.u32, 6, xer);
	// bne cr6,0x820cccec
	if (!cr6.getEQ()) goto loc_820CCCEC;
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820cccec
	if (!cr6.getEQ()) goto loc_820CCCEC;
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// stw r10,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, ctx.r10.u32);
	// blr 
	return;
loc_820CCCEC:
	// lbz r10,48(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 48);
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r3,48
	ctx.r8.s64 = ctx.r3.s64 + 48;
	// cmplwi cr6,r10,255
	cr6.compare<uint32_t>(ctx.r10.u32, 255, xer);
	// beq cr6,0x820ccd1c
	if (cr6.getEQ()) goto loc_820CCD1C;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
loc_820CCD04:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lbzx r10,r8,r9
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + ctx.r9.u32);
	// cmplwi cr6,r10,255
	cr6.compare<uint32_t>(ctx.r10.u32, 255, xer);
	// bne cr6,0x820ccd04
	if (!cr6.getEQ()) goto loc_820CCD04;
loc_820CCD1C:
	// rlwinm r11,r9,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// li r10,-1
	ctx.r10.s64 = -1;
	// stwx r10,r11,r4
	PPC_STORE_U32(r11.u32 + ctx.r4.u32, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CCD30"))) PPC_WEAK_FUNC(sub_820CCD30);
PPC_FUNC_IMPL(__imp__sub_820CCD30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// bl 0x820ae360
	sub_820AE360(ctx, base);
	// cmpwi cr6,r3,54
	cr6.compare<int32_t>(ctx.r3.s32, 54, xer);
	// bne cr6,0x820ccdac
	if (!cr6.getEQ()) goto loc_820CCDAC;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x820cd070
	if (cr6.getEQ()) goto loc_820CD070;
	// cmpwi cr6,r27,2
	cr6.compare<int32_t>(r27.s32, 2, xer);
	// bne cr6,0x820ccdac
	if (!cr6.getEQ()) goto loc_820CCDAC;
	// li r27,0
	r27.s64 = 0;
loc_820CCD64:
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r11,-2320(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -2320);
	// addi r30,r11,-4
	r30.s64 = r11.s64 + -4;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r28,r11,-2296
	r28.s64 = r11.s64 + -2296;
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// blt cr6,0x820cd070
	if (cr6.getLT()) goto loc_820CD070;
	// lis r11,-32009
	r11.s64 = -2097741824;
	// addi r29,r11,-9856
	r29.s64 = r11.s64 + -9856;
loc_820CCD88:
	// lwz r31,0(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820cd064
	if (cr6.getEQ()) goto loc_820CD064;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x820ccf74
	if (!cr6.getEQ()) goto loc_820CCF74;
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// andi. r11,r11,33
	r11.u64 = r11.u64 & 33;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// b 0x820ccf88
	goto loc_820CCF88;
loc_820CCDAC:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x820ccd64
	if (cr6.getEQ()) goto loc_820CCD64;
	// cmpwi cr6,r27,2
	cr6.compare<int32_t>(r27.s32, 2, xer);
	// beq cr6,0x820ccd64
	if (cr6.getEQ()) goto loc_820CCD64;
	// lis r28,-32013
	r28.s64 = -2098003968;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r30,r11,-2296
	r30.s64 = r11.s64 + -2296;
	// lwz r11,-2320(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -2320);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bge cr6,0x820cd070
	if (!cr6.getLT()) goto loc_820CD070;
	// lis r11,-32009
	r11.s64 = -2097741824;
	// addi r29,r11,-9856
	r29.s64 = r11.s64 + -9856;
loc_820CCDDC:
	// lwz r31,0(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820ccf5c
	if (cr6.getEQ()) goto loc_820CCF5C;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ccca8
	sub_820CCCA8(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x820ccf5c
	if (cr6.getLT()) goto loc_820CCF5C;
loc_820CCE04:
	// mulli r11,r11,156
	r11.s64 = r11.s64 * 156;
	// lbzx r11,r11,r29
	r11.u64 = PPC_LOAD_U8(r11.u32 + r29.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cce28
	if (!cr6.getEQ()) goto loc_820CCE28;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820cce04
	if (!cr6.getLT()) goto loc_820CCE04;
	// b 0x820ccf5c
	goto loc_820CCF5C;
loc_820CCE28:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpw cr6,r11,r26
	cr6.compare<int32_t>(r11.s32, r26.s32, xer);
	// bne cr6,0x820ccf5c
	if (!cr6.getEQ()) goto loc_820CCF5C;
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// rlwinm r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cced0
	if (cr6.getEQ()) goto loc_820CCED0;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x820cce60
	if (!cr6.getEQ()) goto loc_820CCE60;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8211f230
	sub_8211F230(ctx, base);
	// b 0x820cced0
	goto loc_820CCED0;
loc_820CCE60:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820ccec0
	if (cr6.getEQ()) goto loc_820CCEC0;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x820ccec0
	if (cr6.getEQ()) goto loc_820CCEC0;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x820ccec0
	if (cr6.getEQ()) goto loc_820CCEC0;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// bne cr6,0x820cce90
	if (!cr6.getEQ()) goto loc_820CCE90;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821431c0
	sub_821431C0(ctx, base);
	// b 0x820cced0
	goto loc_820CCED0;
loc_820CCE90:
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bne cr6,0x820ccea8
	if (!cr6.getEQ()) goto loc_820CCEA8;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8213fb80
	sub_8213FB80(ctx, base);
	// b 0x820cced0
	goto loc_820CCED0;
loc_820CCEA8:
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820cced0
	if (!cr6.getEQ()) goto loc_820CCED0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820b5750
	sub_820B5750(ctx, base);
	// b 0x820cced0
	goto loc_820CCED0;
loc_820CCEC0:
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d9f30
	sub_820D9F30(ctx, base);
loc_820CCED0:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x820cceec
	if (!cr6.getEQ()) goto loc_820CCEEC;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8211f230
	sub_8211F230(ctx, base);
	// b 0x820ccf5c
	goto loc_820CCF5C;
loc_820CCEEC:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820ccf4c
	if (cr6.getEQ()) goto loc_820CCF4C;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x820ccf4c
	if (cr6.getEQ()) goto loc_820CCF4C;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x820ccf4c
	if (cr6.getEQ()) goto loc_820CCF4C;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// bne cr6,0x820ccf1c
	if (!cr6.getEQ()) goto loc_820CCF1C;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821431c0
	sub_821431C0(ctx, base);
	// b 0x820ccf5c
	goto loc_820CCF5C;
loc_820CCF1C:
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bne cr6,0x820ccf34
	if (!cr6.getEQ()) goto loc_820CCF34;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8213fb80
	sub_8213FB80(ctx, base);
	// b 0x820ccf5c
	goto loc_820CCF5C;
loc_820CCF34:
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820ccf5c
	if (!cr6.getEQ()) goto loc_820CCF5C;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820b5750
	sub_820B5750(ctx, base);
	// b 0x820ccf5c
	goto loc_820CCF5C;
loc_820CCF4C:
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d9f30
	sub_820D9F30(ctx, base);
loc_820CCF5C:
	// lwz r11,-2320(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -2320);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x820ccddc
	if (cr6.getLT()) goto loc_820CCDDC;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed180
	return;
loc_820CCF74:
	// cmpwi cr6,r27,2
	cr6.compare<int32_t>(r27.s32, 2, xer);
	// bne cr6,0x820cd064
	if (!cr6.getEQ()) goto loc_820CD064;
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// andi. r11,r11,33
	r11.u64 = r11.u64 & 33;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
loc_820CCF88:
	// bne cr6,0x820cd064
	if (!cr6.getEQ()) goto loc_820CD064;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ccca8
	sub_820CCCA8(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x820cd064
	if (cr6.getLT()) goto loc_820CD064;
loc_820CCFA8:
	// mulli r11,r11,156
	r11.s64 = r11.s64 * 156;
	// lbzx r11,r11,r29
	r11.u64 = PPC_LOAD_U8(r11.u32 + r29.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820ccfcc
	if (!cr6.getEQ()) goto loc_820CCFCC;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820ccfa8
	if (!cr6.getLT()) goto loc_820CCFA8;
	// b 0x820cd064
	goto loc_820CD064;
loc_820CCFCC:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpw cr6,r11,r26
	cr6.compare<int32_t>(r11.s32, r26.s32, xer);
	// bne cr6,0x820cd064
	if (!cr6.getEQ()) goto loc_820CD064;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x820ccff4
	if (!cr6.getEQ()) goto loc_820CCFF4;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8211f230
	sub_8211F230(ctx, base);
	// b 0x820cd064
	goto loc_820CD064;
loc_820CCFF4:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820cd054
	if (cr6.getEQ()) goto loc_820CD054;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x820cd054
	if (cr6.getEQ()) goto loc_820CD054;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x820cd054
	if (cr6.getEQ()) goto loc_820CD054;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// bne cr6,0x820cd024
	if (!cr6.getEQ()) goto loc_820CD024;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821431c0
	sub_821431C0(ctx, base);
	// b 0x820cd064
	goto loc_820CD064;
loc_820CD024:
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bne cr6,0x820cd03c
	if (!cr6.getEQ()) goto loc_820CD03C;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8213fb80
	sub_8213FB80(ctx, base);
	// b 0x820cd064
	goto loc_820CD064;
loc_820CD03C:
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820cd064
	if (!cr6.getEQ()) goto loc_820CD064;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820b5750
	sub_820B5750(ctx, base);
	// b 0x820cd064
	goto loc_820CD064;
loc_820CD054:
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d9f30
	sub_820D9F30(ctx, base);
loc_820CD064:
	// addi r30,r30,-4
	r30.s64 = r30.s64 + -4;
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// bge cr6,0x820ccd88
	if (!cr6.getLT()) goto loc_820CCD88;
loc_820CD070:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820CD078"))) PPC_WEAK_FUNC(sub_820CD078);
PPC_FUNC_IMPL(__imp__sub_820CD078) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed11c
	// addi r12,r1,-96
	r12.s64 = ctx.r1.s64 + -96;
	// bl 0x823ed540
	// stwu r1,-1216(r1)
	ea = -1216 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r30,0
	r30.s64 = 0;
	// addi r10,r1,148
	ctx.r10.s64 = ctx.r1.s64 + 148;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r25,r30
	r25.u64 = r30.u64;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// addi r11,r1,156
	r11.s64 = ctx.r1.s64 + 156;
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmr f26,f0
	f26.f64 = f0.f64;
	// stw r30,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r30.u32);
	// mr r22,r30
	r22.u64 = r30.u64;
	// stw r30,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r30.u32);
	// mr r27,r30
	r27.u64 = r30.u64;
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// mr r26,r30
	r26.u64 = r30.u64;
	// stw r30,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r30.u32);
	// li r23,-1
	r23.s64 = -1;
	// stw r30,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r30.u32);
	// stw r30,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r30.u32);
	// stw r30,16(r11)
	PPC_STORE_U32(r11.u32 + 16, r30.u32);
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r4,r1,268
	ctx.r4.s64 = ctx.r1.s64 + 268;
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// mr r24,r30
	r24.u64 = r30.u64;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// bl 0x820a49a0
	sub_820A49A0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820a0d30
	sub_820A0D30(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stw r3,280(r1)
	PPC_STORE_U32(ctx.r1.u32 + 280, ctx.r3.u32);
	// li r10,10
	ctx.r10.s64 = 10;
	// lfs f0,16148(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16148);
	f0.f64 = double(temp.f32);
	// addi r11,r1,320
	r11.s64 = ctx.r1.s64 + 320;
	// stfs f0,308(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
loc_820CD120:
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r30,-4(r11)
	PPC_STORE_U32(r11.u32 + -4, r30.u32);
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// stw r30,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r30.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// addi r11,r11,76
	r11.s64 = r11.s64 + 76;
	// bne cr6,0x820cd120
	if (!cr6.getEQ()) goto loc_820CD120;
	// lfs f0,256(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	f0.f64 = double(temp.f32);
	// addi r31,r1,284
	r31.s64 = ctx.r1.s64 + 284;
	// stfs f0,284(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// lfs f0,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	f0.f64 = double(temp.f32);
	// stfs f0,288(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// lfs f0,264(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	f0.f64 = double(temp.f32);
	// stfs f0,292(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8210b6e0
	sub_8210B6E0(ctx, base);
	// lfs f0,268(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	f0.f64 = double(temp.f32);
	// stfs f0,296(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// addi r31,r1,296
	r31.s64 = ctx.r1.s64 + 296;
	// lfs f0,272(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 272);
	f0.f64 = double(temp.f32);
	// stfs f0,300(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// lfs f0,276(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	f0.f64 = double(temp.f32);
	// stfs f0,304(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,296(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	f0.f64 = double(temp.f32);
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// lfs f3,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f3.f64 = double(temp.f32);
	// lfs f13,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f12.f64 = double(temp.f32);
	// lfs f27,16156(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16156);
	f27.f64 = double(temp.f32);
	// fmadds f30,f0,f27,f3
	f30.f64 = double(float(f0.f64 * f27.f64 + ctx.f3.f64));
	// lfs f4,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f4.f64 = double(temp.f32);
	// lfs f0,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	f0.f64 = double(temp.f32);
	// fmadds f29,f12,f27,f4
	f29.f64 = double(float(ctx.f12.f64 * f27.f64 + ctx.f4.f64));
	// lfs f2,20(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// fmadds f28,f13,f27,f0
	f28.f64 = double(float(ctx.f13.f64 * f27.f64 + f0.f64));
	// lfs f1,12(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cd394
	if (cr6.getEQ()) goto loc_820CD394;
	// bl 0x82113110
	sub_82113110(ctx, base);
	// bl 0x820b3dc0
	sub_820B3DC0(ctx, base);
	// bl 0x8210f8f0
	sub_8210F8F0(ctx, base);
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// lfs f2,292(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f2.f64 = double(temp.f32);
	// fmr f4,f29
	ctx.f4.f64 = f29.f64;
	// lfs f1,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f1.f64 = double(temp.f32);
	// fmr f3,f30
	ctx.f3.f64 = f30.f64;
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820cd214
	if (!cr6.getEQ()) goto loc_820CD214;
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// addi r4,r1,296
	ctx.r4.s64 = ctx.r1.s64 + 296;
	// addi r3,r1,284
	ctx.r3.s64 = ctx.r1.s64 + 284;
	// bl 0x82121c20
	sub_82121C20(ctx, base);
	// li r25,1
	r25.s64 = 1;
	// b 0x820cd220
	goto loc_820CD220;
loc_820CD214:
	// stfs f30,120(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// stfs f28,124(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// stfs f29,128(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
loc_820CD220:
	// lwz r3,100(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// bl 0x82110d78
	sub_82110D78(ctx, base);
	// lis r11,-32015
	r11.s64 = -2098135040;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lbz r3,-8431(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + -8431);
	// bl 0x821131a8
	sub_821131A8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x820cd354
	if (cr6.getEQ()) goto loc_820CD354;
	// bl 0x821130e0
	sub_821130E0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,284(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	ctx.f13.f64 = double(temp.f32);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,208
	ctx.r7.s64 = ctx.r1.s64 + 208;
	// lfs f0,3904(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3904);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f31,f1,f0
	f31.f64 = double(float(ctx.f1.f64 * f0.f64));
	// addi r6,r1,240
	ctx.r6.s64 = ctx.r1.s64 + 240;
	// addi r5,r1,224
	ctx.r5.s64 = ctx.r1.s64 + 224;
	// addi r4,r1,192
	ctx.r4.s64 = ctx.r1.s64 + 192;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lfs f0,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// fdivs f0,f0,f31
	f0.f64 = double(float(f0.f64 / f31.f64));
	// fmuls f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f13,192(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f13,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f13,196(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// lfs f13,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f13,200(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// fmuls f13,f0,f30
	ctx.f13.f64 = double(float(f0.f64 * f30.f64));
	// stfs f13,224(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// fmuls f13,f0,f28
	ctx.f13.f64 = double(float(f0.f64 * f28.f64));
	// stfs f13,228(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// stfs f0,232(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// bl 0x8209bed8
	sub_8209BED8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cd354
	if (cr6.getEQ()) goto loc_820CD354;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lfs f11,208(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f11.f64 = double(temp.f32);
	// stfs f11,156(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// sth r30,172(r1)
	PPC_STORE_U16(ctx.r1.u32 + 172, r30.u16);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// lfs f11,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	f0.f64 = double(temp.f32);
	// sth r30,174(r1)
	PPC_STORE_U16(ctx.r1.u32 + 174, r30.u16);
	// lfs f13,244(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 244);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// lfs f12,248(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * f31.f64));
	// stfs f11,160(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * f31.f64));
	// lfs f11,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f11.f64 = double(temp.f32);
	// sth r11,170(r1)
	PPC_STORE_U16(ctx.r1.u32 + 170, r11.u16);
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// sth r30,168(r1)
	PPC_STORE_U16(ctx.r1.u32 + 168, r30.u16);
	// stfs f13,148(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// mr r26,r31
	r26.u64 = r31.u64;
	// stfs f12,152(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// stfs f11,164(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// ble cr6,0x820cd354
	if (!cr6.getGT()) goto loc_820CD354;
	// stfs f0,176(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// li r27,1
	r27.s64 = 1;
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// extsh r23,r11
	r23.s64 = r11.s16;
	// stfs f13,180(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// stfs f13,108(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f12,184(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// stfs f12,112(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// b 0x820cd368
	goto loc_820CD368;
loc_820CD354:
	// stfs f30,104(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// mr r26,r31
	r26.u64 = r31.u64;
	// stfs f28,108(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// mr r23,r30
	r23.u64 = r30.u64;
	// stfs f29,112(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
loc_820CD368:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bne cr6,0x820cd378
	if (!cr6.getEQ()) goto loc_820CD378;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x820cd394
	if (cr6.getEQ()) goto loc_820CD394;
loc_820CD378:
	// addi r31,r1,104
	r31.s64 = ctx.r1.s64 + 104;
	// bl 0x8210d820
	sub_8210D820(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8210b6e0
	sub_8210B6E0(ctx, base);
	// lfs f0,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	f0.f64 = double(temp.f32);
	// fneg f26,f0
	f26.u64 = f0.u64 ^ 0x8000000000000000;
	// stfs f26,308(r1)
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
loc_820CD394:
	// lwz r11,280(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// cmpwi cr6,r11,23
	cr6.compare<int32_t>(r11.s32, 23, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,12020(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12020);
	f31.f64 = double(temp.f32);
	// bne cr6,0x820cd3b8
	if (!cr6.getEQ()) goto loc_820CD3B8;
	// lfs f0,308(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 308);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x820cd3b8
	if (!cr6.getGT()) goto loc_820CD3B8;
	// stfs f31,308(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
loc_820CD3B8:
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r11,-2320(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -2320);
	// addi r29,r11,-4
	r29.s64 = r11.s64 + -4;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r28,r11,-2296
	r28.s64 = r11.s64 + -2296;
	// cmplw cr6,r29,r28
	cr6.compare<uint32_t>(r29.u32, r28.u32, xer);
	// blt cr6,0x820cd45c
	if (cr6.getLT()) goto loc_820CD45C;
loc_820CD3D4:
	// lwz r31,0(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820cd450
	if (cr6.getEQ()) goto loc_820CD450;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x820cd444
	if (cr6.getEQ()) goto loc_820CD444;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820cd418
	if (!cr6.getEQ()) goto loc_820CD418;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cd418
	if (cr6.getEQ()) goto loc_820CD418;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820c9b90
	sub_820C9B90(ctx, base);
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// cmpw cr6,r21,r3
	cr6.compare<int32_t>(r21.s32, ctx.r3.s32, xer);
	// bne cr6,0x820cd444
	if (!cr6.getEQ()) goto loc_820CD444;
loc_820CD418:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820cd434
	if (cr6.getEQ()) goto loc_820CD434;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x820cd434
	if (cr6.getEQ()) goto loc_820CD434;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x820cd450
	if (!cr6.getEQ()) goto loc_820CD450;
loc_820CD434:
	// addi r4,r1,256
	ctx.r4.s64 = ctx.r1.s64 + 256;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820db2f0
	sub_820DB2F0(ctx, base);
	// b 0x820cd450
	goto loc_820CD450;
loc_820CD444:
	// addi r4,r1,256
	ctx.r4.s64 = ctx.r1.s64 + 256;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8211f7d0
	sub_8211F7D0(ctx, base);
loc_820CD450:
	// addi r29,r29,-4
	r29.s64 = r29.s64 + -4;
	// cmplw cr6,r29,r28
	cr6.compare<uint32_t>(r29.u32, r28.u32, xer);
	// bge cr6,0x820cd3d4
	if (!cr6.getLT()) goto loc_820CD3D4;
loc_820CD45C:
	// addi r31,r1,316
	r31.s64 = ctx.r1.s64 + 316;
	// li r29,10
	r29.s64 = 10;
loc_820CD464:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cd4e4
	if (cr6.getEQ()) goto loc_820CD4E4;
	// lbz r11,0(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x820cd4ac
	if (cr6.getEQ()) goto loc_820CD4AC;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// beq cr6,0x820cd4ac
	if (cr6.getEQ()) goto loc_820CD4AC;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820cd49c
	if (cr6.getEQ()) goto loc_820CD49C;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x820cd49c
	if (cr6.getEQ()) goto loc_820CD49C;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x820cd4b8
	if (!cr6.getEQ()) goto loc_820CD4B8;
loc_820CD49C:
	// addi r4,r31,-4
	ctx.r4.s64 = r31.s64 + -4;
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// bl 0x820e7f68
	sub_820E7F68(ctx, base);
	// b 0x820cd4b8
	goto loc_820CD4B8;
loc_820CD4AC:
	// addi r4,r31,-4
	ctx.r4.s64 = r31.s64 + -4;
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// bl 0x8211fda0
	sub_8211FDA0(ctx, base);
loc_820CD4B8:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820cd4e4
	if (cr6.getEQ()) goto loc_820CD4E4;
	// lwz r3,280(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// bl 0x820a11f0
	sub_820A11F0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmpw cr6,r24,r11
	cr6.compare<int32_t>(r24.s32, r11.s32, xer);
	// blt cr6,0x820cd4e4
	if (cr6.getLT()) goto loc_820CD4E4;
	// mr r27,r30
	r27.u64 = r30.u64;
	// mr r25,r30
	r25.u64 = r30.u64;
loc_820CD4E4:
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// addi r31,r31,76
	r31.s64 = r31.s64 + 76;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x820cd464
	if (!cr6.getEQ()) goto loc_820CD464;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x820cd504
	if (!cr6.getEQ()) goto loc_820CD504;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x820cd6ac
	if (cr6.getEQ()) goto loc_820CD6AC;
loc_820CD504:
	// lwz r3,280(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// li r28,1
	r28.s64 = 1;
	// cmpwi cr6,r3,23
	cr6.compare<int32_t>(ctx.r3.s32, 23, xer);
	// bne cr6,0x820cd520
	if (!cr6.getEQ()) goto loc_820CD520;
	// fcmpu cr6,f26,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f26.f64, f31.f64);
	// ble cr6,0x820cd520
	if (!cr6.getGT()) goto loc_820CD520;
	// mr r28,r30
	r28.u64 = r30.u64;
loc_820CD520:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x820cd5bc
	if (cr6.getEQ()) goto loc_820CD5BC;
	// lhz r11,170(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 170);
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// extsh r10,r11
	ctx.r10.s64 = r11.s16;
	// lis r11,-32033
	r11.s64 = -2099314688;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-5072
	r11.s64 = r11.s64 + -5072;
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// beq cr6,0x820cd5b0
	if (cr6.getEQ()) goto loc_820CD5B0;
	// lhz r11,10(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 10);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820cd5b0
	if (!cr6.getGT()) goto loc_820CD5B0;
	// cmpwi cr6,r3,23
	cr6.compare<int32_t>(ctx.r3.s32, 23, xer);
	// beq cr6,0x820cd5b0
	if (cr6.getEQ()) goto loc_820CD5B0;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// lhz r10,10(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 10);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r5,4(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// twllei r10,0
	// divwu r31,r11,r10
	r31.u32 = r11.u32 / ctx.r10.u32;
	// li r9,0
	ctx.r9.s64 = 0;
	// mullw r10,r31,r10
	ctx.r10.s64 = int64_t(r31.s32) * int64_t(ctx.r10.s32);
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// li r8,-1
	ctx.r8.s64 = -1;
	// li r7,0
	ctx.r7.s64 = 0;
	// extsh r6,r26
	ctx.r6.s64 = r26.s16;
	// addi r4,r1,156
	ctx.r4.s64 = ctx.r1.s64 + 156;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// lbzx r5,r11,r5
	ctx.r5.u64 = PPC_LOAD_U8(r11.u32 + ctx.r5.u32);
	// bl 0x82141a98
	sub_82141A98(ctx, base);
loc_820CD5B0:
	// lwz r3,280(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	// addi r31,r1,176
	r31.s64 = ctx.r1.s64 + 176;
	// b 0x820cd5f8
	goto loc_820CD5F8;
loc_820CD5BC:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x820cd6ac
	if (cr6.getEQ()) goto loc_820CD6AC;
	// lfs f13,296(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f13.f64 = double(temp.f32);
	// addi r31,r1,120
	r31.s64 = ctx.r1.s64 + 120;
	// lfs f0,284(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	f0.f64 = double(temp.f32);
	// fmadds f0,f13,f27,f0
	f0.f64 = double(float(ctx.f13.f64 * f27.f64 + f0.f64));
	// stfs f0,120(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f13,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,288(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 288);
	f0.f64 = double(temp.f32);
	// fmadds f0,f13,f27,f0
	f0.f64 = double(float(ctx.f13.f64 * f27.f64 + f0.f64));
	// stfs f0,124(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f0,292(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	f0.f64 = double(temp.f32);
	// lfs f13,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f13,f27,f0
	f0.f64 = double(float(ctx.f13.f64 * f27.f64 + f0.f64));
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
loc_820CD5F8:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x820cd650
	if (cr6.getEQ()) goto loc_820CD650;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x820a3fc0
	sub_820A3FC0(ctx, base);
	// li r11,255
	r11.s64 = 255;
	// stb r26,96(r1)
	PPC_STORE_U8(ctx.r1.u32 + 96, r26.u8);
	// addi r29,r1,96
	r29.s64 = ctx.r1.s64 + 96;
	// stb r11,97(r1)
	PPC_STORE_U8(ctx.r1.u32 + 97, r11.u8);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// li r11,-1
	r11.s64 = -1;
	// stb r30,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, r30.u8);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// bl 0x821427b8
	sub_821427B8(ctx, base);
loc_820CD650:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f11,296(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 296);
	ctx.f11.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f13,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f31,16152(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16152);
	f31.f64 = double(temp.f32);
	// fnmsubs f0,f11,f31,f0
	f0.f64 = double(float(-(ctx.f11.f64 * f31.f64 - f0.f64)));
	// stfs f0,0(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// lfs f0,300(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	f0.f64 = double(temp.f32);
	// fnmsubs f0,f0,f31,f13
	f0.f64 = double(float(-(f0.f64 * f31.f64 - ctx.f13.f64)));
	// stfs f0,4(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// lfs f0,304(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 304);
	f0.f64 = double(temp.f32);
	// fnmsubs f0,f0,f31,f12
	f0.f64 = double(float(-(f0.f64 * f31.f64 - ctx.f12.f64)));
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// bl 0x820a4540
	sub_820A4540(ctx, base);
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x820cd6ac
	if (cr6.getEQ()) goto loc_820CD6AC;
	// extsh r6,r26
	ctx.r6.s64 = r26.s16;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8213d980
	sub_8213D980(ctx, base);
loc_820CD6AC:
	// addi r1,r1,1216
	ctx.r1.s64 = ctx.r1.s64 + 1216;
	// addi r12,r1,-96
	r12.s64 = ctx.r1.s64 + -96;
	// bl 0x823ed58c
	// b 0x823ed16c
	return;
}

__attribute__((alias("__imp__sub_820CD6C0"))) PPC_WEAK_FUNC(sub_820CD6C0);
PPC_FUNC_IMPL(__imp__sub_820CD6C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed11c
	// stfd f30,-112(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -112, f30.u64);
	// stfd f31,-104(r1)
	PPC_STORE_U64(ctx.r1.u32 + -104, f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r21,284(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// fmr f30,f1
	f30.f64 = ctx.f1.f64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// mr r24,r8
	r24.u64 = ctx.r8.u64;
	// mr r23,r9
	r23.u64 = ctx.r9.u64;
	// mr r22,r10
	r22.u64 = ctx.r10.u64;
	// li r28,0
	r28.s64 = 0;
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// beq cr6,0x820cd8d4
	if (cr6.getEQ()) goto loc_820CD8D4;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r30,r28
	r30.u64 = r28.u64;
	// mr r31,r28
	r31.u64 = r28.u64;
	// li r10,2
	ctx.r10.s64 = 2;
	// lfs f0,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// addi r11,r29,56
	r11.s64 = r29.s64 + 56;
	// fmr f31,f0
	f31.f64 = f0.f64;
loc_820CD720:
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820cd754
	if (cr6.getEQ()) goto loc_820CD754;
	// lwz r9,60(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x820cd754
	if (cr6.getEQ()) goto loc_820CD754;
	// lfs f13,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820cd754
	if (!cr6.getGT()) goto loc_820CD754;
	// fmr f31,f0
	f31.f64 = f0.f64;
	// addi r30,r10,-2
	r30.s64 = ctx.r10.s64 + -2;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
loc_820CD754:
	// lwz r9,80(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 80);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820cd788
	if (cr6.getEQ()) goto loc_820CD788;
	// lwz r9,136(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 136);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x820cd788
	if (cr6.getEQ()) goto loc_820CD788;
	// lfs f13,76(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 76);
	ctx.f13.f64 = double(temp.f32);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820cd788
	if (!cr6.getGT()) goto loc_820CD788;
	// fmr f31,f0
	f31.f64 = f0.f64;
	// addi r30,r10,-1
	r30.s64 = ctx.r10.s64 + -1;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
loc_820CD788:
	// lwz r9,156(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 156);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820cd7bc
	if (cr6.getEQ()) goto loc_820CD7BC;
	// lwz r9,212(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 212);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x820cd7bc
	if (cr6.getEQ()) goto loc_820CD7BC;
	// lfs f13,152(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 152);
	ctx.f13.f64 = double(temp.f32);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820cd7bc
	if (!cr6.getGT()) goto loc_820CD7BC;
	// fmr f31,f0
	f31.f64 = f0.f64;
	// mr r30,r10
	r30.u64 = ctx.r10.u64;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
loc_820CD7BC:
	// lwz r9,232(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 232);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820cd7f0
	if (cr6.getEQ()) goto loc_820CD7F0;
	// lwz r9,288(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 288);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x820cd7f0
	if (cr6.getEQ()) goto loc_820CD7F0;
	// lfs f13,228(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 228);
	ctx.f13.f64 = double(temp.f32);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820cd7f0
	if (!cr6.getGT()) goto loc_820CD7F0;
	// fmr f31,f0
	f31.f64 = f0.f64;
	// addi r30,r10,1
	r30.s64 = ctx.r10.s64 + 1;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
loc_820CD7F0:
	// lwz r9,308(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 308);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820cd824
	if (cr6.getEQ()) goto loc_820CD824;
	// lwz r9,364(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 364);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x820cd824
	if (cr6.getEQ()) goto loc_820CD824;
	// lfs f13,304(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 304);
	ctx.f13.f64 = double(temp.f32);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820cd824
	if (!cr6.getGT()) goto loc_820CD824;
	// fmr f31,f0
	f31.f64 = f0.f64;
	// addi r30,r10,2
	r30.s64 = ctx.r10.s64 + 2;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
loc_820CD824:
	// addi r10,r10,5
	ctx.r10.s64 = ctx.r10.s64 + 5;
	// addi r11,r11,380
	r11.s64 = r11.s64 + 380;
	// addi r9,r10,-2
	ctx.r9.s64 = ctx.r10.s64 + -2;
	// cmpwi cr6,r9,10
	cr6.compare<int32_t>(ctx.r9.s32, 10, xer);
	// blt cr6,0x820cd720
	if (cr6.getLT()) goto loc_820CD720;
	// lwz r3,24(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// bl 0x820a11f0
	sub_820A11F0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmpw cr6,r31,r11
	cr6.compare<int32_t>(r31.s32, r11.s32, xer);
	// blt cr6,0x820cd8ac
	if (cr6.getLT()) goto loc_820CD8AC;
	// mulli r11,r30,76
	r11.s64 = r30.s64 * 76;
	// fcmpu cr6,f30,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f30.f64, f31.f64);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// stw r28,60(r11)
	PPC_STORE_U32(r11.u32 + 60, r28.u32);
	// stfs f31,52(r29)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r29.u32 + 52, temp.u32);
	// ble cr6,0x820cd868
	if (!cr6.getGT()) goto loc_820CD868;
	// stfs f30,52(r29)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r29.u32 + 52, temp.u32);
loc_820CD868:
	// addi r11,r29,60
	r11.s64 = r29.s64 + 60;
	// li r10,10
	ctx.r10.s64 = 10;
loc_820CD870:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820cd898
	if (cr6.getEQ()) goto loc_820CD898;
	// lwz r9,56(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x820cd898
	if (!cr6.getEQ()) goto loc_820CD898;
	// lfs f0,-4(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -4);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x820cd898
	if (!cr6.getGT()) goto loc_820CD898;
	// stw r28,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r28.u32);
loc_820CD898:
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r11,r11,76
	r11.s64 = r11.s64 + 76;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820cd870
	if (!cr6.getEQ()) goto loc_820CD870;
	// b 0x820cd8d4
	goto loc_820CD8D4;
loc_820CD8AC:
	// lwz r3,24(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// bl 0x820a11f0
	sub_820A11F0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmpw cr6,r31,r11
	cr6.compare<int32_t>(r31.s32, r11.s32, xer);
	// bne cr6,0x820cd8d4
	if (!cr6.getEQ()) goto loc_820CD8D4;
	// lfs f0,52(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 52);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f30,f0
	cr6.compare(f30.f64, f0.f64);
	// bge cr6,0x820cd8d4
	if (!cr6.getLT()) goto loc_820CD8D4;
	// stfs f30,52(r29)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r29.u32 + 52, temp.u32);
loc_820CD8D4:
	// lwz r11,292(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820cd92c
	if (cr6.getEQ()) goto loc_820CD92C;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// cmpwi cr6,r11,18
	cr6.compare<int32_t>(r11.s32, 18, xer);
	// beq cr6,0x820cd92c
	if (cr6.getEQ()) goto loc_820CD92C;
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// beq cr6,0x820cd92c
	if (cr6.getEQ()) goto loc_820CD92C;
	// addi r11,r29,60
	r11.s64 = r29.s64 + 60;
	// li r10,10
	ctx.r10.s64 = 10;
loc_820CD8FC:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820cd918
	if (cr6.getEQ()) goto loc_820CD918;
	// lfs f0,-4(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -4);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// ble cr6,0x820cd918
	if (!cr6.getGT()) goto loc_820CD918;
	// stw r28,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r28.u32);
loc_820CD918:
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r11,r11,76
	r11.s64 = r11.s64 + 76;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820cd8fc
	if (!cr6.getEQ()) goto loc_820CD8FC;
	// stfs f30,52(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r29.u32 + 52, temp.u32);
loc_820CD92C:
	// mr r11,r28
	r11.u64 = r28.u64;
	// addi r10,r29,60
	ctx.r10.s64 = r29.s64 + 60;
loc_820CD934:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820cd960
	if (cr6.getEQ()) goto loc_820CD960;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,76
	ctx.r10.s64 = ctx.r10.s64 + 76;
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// blt cr6,0x820cd934
	if (cr6.getLT()) goto loc_820CD934;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f30,-112(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// lfd f31,-104(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// b 0x823ed16c
	return;
loc_820CD960:
	// mulli r11,r11,76
	r11.s64 = r11.s64 * 76;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// mr r10,r24
	ctx.r10.u64 = r24.u64;
	// li r8,8
	ctx.r8.s64 = 8;
	// addi r11,r11,56
	r11.s64 = r11.s64 + 56;
	// addi r9,r11,16
	ctx.r9.s64 = r11.s64 + 16;
	// stfs f30,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// stw r27,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r27.u32);
	// stw r26,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r26.u32);
	// stw r25,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r25.u32);
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
loc_820CD98C:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r8,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r8.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// bdnz 0x820cd98c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820CD98C;
	// lwz r10,276(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// addi r9,r11,64
	ctx.r9.s64 = r11.s64 + 64;
	// stw r23,48(r11)
	PPC_STORE_U32(r11.u32 + 48, r23.u32);
	// stw r22,52(r11)
	PPC_STORE_U32(r11.u32 + 52, r22.u32);
	// stw r21,60(r11)
	PPC_STORE_U32(r11.u32 + 60, r21.u32);
	// stw r10,56(r11)
	PPC_STORE_U32(r11.u32 + 56, ctx.r10.u32);
	// lwz r11,300(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 300);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r10,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r10,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r10.u32);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r11,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, r11.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f30,-112(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// lfd f31,-104(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// b 0x823ed16c
	return;
}

__attribute__((alias("__imp__sub_820CD9E8"))) PPC_WEAK_FUNC(sub_820CD9E8);
PPC_FUNC_IMPL(__imp__sub_820CD9E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed120
	// addi r12,r1,-88
	r12.s64 = ctx.r1.s64 + -88;
	// bl 0x823ed53c
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// li r25,0
	r25.s64 = 0;
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// lwz r3,-1364(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// bl 0x820b3c80
	sub_820B3C80(ctx, base);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// fmr f28,f1
	ctx.fpscr.disableFlushMode();
	f28.f64 = ctx.f1.f64;
	// lwz r11,-2320(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -2320);
	// addi r28,r11,-4
	r28.s64 = r11.s64 + -4;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r26,r11,-2296
	r26.s64 = r11.s64 + -2296;
	// cmplw cr6,r28,r26
	cr6.compare<uint32_t>(r28.u32, r26.u32, xer);
	// blt cr6,0x820cdc30
	if (cr6.getLT()) goto loc_820CDC30;
	// lis r7,-32256
	ctx.r7.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f29,2776(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 2776);
	f29.f64 = double(temp.f32);
	// lfs f31,2688(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 2688);
	f31.f64 = double(temp.f32);
	// lfs f26,2944(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2944);
	f26.f64 = double(temp.f32);
	// lfs f27,2960(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2960);
	f27.f64 = double(temp.f32);
	// lfs f25,14052(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14052);
	f25.f64 = double(temp.f32);
loc_820CDA64:
	// lwz r30,0(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820cdc1c
	if (cr6.getEQ()) goto loc_820CDC1C;
	// lfs f0,28(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 28);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f25
	cr6.compare(f0.f64, f25.f64);
	// bge cr6,0x820cdc1c
	if (!cr6.getLT()) goto loc_820CDC1C;
	// lbz r11,0(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x820cdab4
	if (cr6.getEQ()) goto loc_820CDAB4;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820cdc1c
	if (!cr6.getEQ()) goto loc_820CDC1C;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cdc1c
	if (cr6.getEQ()) goto loc_820CDC1C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820c9b90
	sub_820C9B90(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// cmpw cr6,r31,r3
	cr6.compare<int32_t>(r31.s32, ctx.r3.s32, xer);
	// beq cr6,0x820cdc1c
	if (cr6.getEQ()) goto loc_820CDC1C;
loc_820CDAB4:
	// lwz r29,8(r30)
	r29.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// fmr f30,f27
	ctx.fpscr.disableFlushMode();
	f30.f64 = f27.f64;
	// bl 0x820a0b68
	sub_820A0B68(ctx, base);
	// cmpwi cr6,r3,17
	cr6.compare<int32_t>(ctx.r3.s32, 17, xer);
	// bne cr6,0x820cdacc
	if (!cr6.getEQ()) goto loc_820CDACC;
	// fmr f30,f26
	ctx.fpscr.disableFlushMode();
	f30.f64 = f26.f64;
loc_820CDACC:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,28(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// addi r4,r1,100
	ctx.r4.s64 = ctx.r1.s64 + 100;
	// bl 0x820d43e8
	sub_820D43E8(ctx, base);
	// lfs f0,100(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// blt cr6,0x820cdc1c
	if (cr6.getLT()) goto loc_820CDC1C;
	// lfs f0,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bgt cr6,0x820cdc1c
	if (cr6.getGT()) goto loc_820CDC1C;
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r3,28(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r1,108
	ctx.r4.s64 = ctx.r1.s64 + 108;
	// bl 0x820d43e8
	sub_820D43E8(ctx, base);
	// lfs f0,108(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// blt cr6,0x820cdc1c
	if (cr6.getLT()) goto loc_820CDC1C;
	// lfs f0,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bgt cr6,0x820cdc1c
	if (cr6.getGT()) goto loc_820CDC1C;
	// li r6,2
	ctx.r6.s64 = 2;
	// lwz r3,28(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// bl 0x820d43e8
	sub_820D43E8(ctx, base);
	// lfs f0,116(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bgt cr6,0x820cdc1c
	if (cr6.getGT()) goto loc_820CDC1C;
	// fneg f0,f30
	f0.u64 = f30.u64 ^ 0x8000000000000000;
	// lfs f13,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x820cdc1c
	if (cr6.getLT()) goto loc_820CDC1C;
	// lwz r11,24(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 24);
	// li r8,19
	ctx.r8.s64 = 19;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f4,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// fmr f8,f29
	ctx.f8.f64 = f29.f64;
	// lfs f2,20(r23)
	temp.u32 = PPC_LOAD_U32(r23.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// fmr f7,f31
	ctx.f7.f64 = f31.f64;
	// lfs f1,12(r23)
	temp.u32 = PPC_LOAD_U32(r23.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmr f6,f28
	ctx.f6.f64 = f28.f64;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// fmr f5,f28
	ctx.f5.f64 = f28.f64;
	// bl 0x82112020
	sub_82112020(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cdc1c
	if (cr6.getEQ()) goto loc_820CDC1C;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x820cdc1c
	if (!cr6.getEQ()) goto loc_820CDC1C;
	// li r31,15
	r31.s64 = 15;
	// bl 0x820b0088
	sub_820B0088(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x820cdbb8
	if (!cr6.getEQ()) goto loc_820CDBB8;
	// li r31,200
	r31.s64 = 200;
	// b 0x820cdbc8
	goto loc_820CDBC8;
loc_820CDBB8:
	// bl 0x820b0088
	sub_820B0088(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820cdbc8
	if (!cr6.getEQ()) goto loc_820CDBC8;
	// li r31,201
	r31.s64 = 201;
loc_820CDBC8:
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x820a49a0
	sub_820A49A0(ctx, base);
	// addi r22,r1,128
	r22.s64 = ctx.r1.s64 + 128;
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82128fa8
	sub_82128FA8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cdc1c
	if (cr6.getEQ()) goto loc_820CDC1C;
	// li r5,-1
	ctx.r5.s64 = -1;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x820a3c20
	sub_820A3C20(ctx, base);
	// li r25,1
	r25.s64 = 1;
loc_820CDC1C:
	// addi r28,r28,-4
	r28.s64 = r28.s64 + -4;
	// cmplw cr6,r28,r26
	cr6.compare<uint32_t>(r28.u32, r26.u32, xer);
	// bge cr6,0x820cda64
	if (!cr6.getLT()) goto loc_820CDA64;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bne cr6,0x820cdc60
	if (!cr6.getEQ()) goto loc_820CDC60;
loc_820CDC30:
	// cmpwi cr6,r27,1
	cr6.compare<int32_t>(r27.s32, 1, xer);
	// bne cr6,0x820cdc60
	if (!cr6.getEQ()) goto loc_820CDC60;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,1193
	ctx.r8.s64 = 1193;
	// addi r7,r11,16160
	ctx.r7.s64 = r11.s64 + 16160;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,105
	ctx.r4.s64 = 105;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
loc_820CDC60:
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// addi r12,r1,-88
	r12.s64 = ctx.r1.s64 + -88;
	// bl 0x823ed588
	// b 0x823ed170
	return;
}

__attribute__((alias("__imp__sub_820CDC70"))) PPC_WEAK_FUNC(sub_820CDC70);
PPC_FUNC_IMPL(__imp__sub_820CDC70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x820a0de8
	sub_820A0DE8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820a0d30
	sub_820A0D30(ctx, base);
	// cmpwi cr6,r3,30
	cr6.compare<int32_t>(ctx.r3.s32, 30, xer);
	// bne cr6,0x820cdcac
	if (!cr6.getEQ()) goto loc_820CDCAC;
	// bl 0x820dc7f8
	sub_820DC7F8(ctx, base);
	// b 0x820cddc8
	goto loc_820CDDC8;
loc_820CDCAC:
	// cmpwi cr6,r3,24
	cr6.compare<int32_t>(ctx.r3.s32, 24, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// cmpwi cr6,r3,25
	cr6.compare<int32_t>(ctx.r3.s32, 25, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// cmpwi cr6,r3,26
	cr6.compare<int32_t>(ctx.r3.s32, 26, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// cmpwi cr6,r3,3
	cr6.compare<int32_t>(ctx.r3.s32, 3, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// cmpwi cr6,r3,29
	cr6.compare<int32_t>(ctx.r3.s32, 29, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// cmpwi cr6,r3,28
	cr6.compare<int32_t>(ctx.r3.s32, 28, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// cmpwi cr6,r3,27
	cr6.compare<int32_t>(ctx.r3.s32, 27, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// cmpwi cr6,r3,35
	cr6.compare<int32_t>(ctx.r3.s32, 35, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// cmpwi cr6,r3,36
	cr6.compare<int32_t>(ctx.r3.s32, 36, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// cmpwi cr6,r3,33
	cr6.compare<int32_t>(ctx.r3.s32, 33, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// cmpwi cr6,r3,47
	cr6.compare<int32_t>(ctx.r3.s32, 47, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// cmpwi cr6,r3,48
	cr6.compare<int32_t>(ctx.r3.s32, 48, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// cmpwi cr6,r3,61
	cr6.compare<int32_t>(ctx.r3.s32, 61, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// cmpwi cr6,r3,88
	cr6.compare<int32_t>(ctx.r3.s32, 88, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// cmpwi cr6,r3,34
	cr6.compare<int32_t>(ctx.r3.s32, 34, xer);
	// beq cr6,0x820cddc8
	if (cr6.getEQ()) goto loc_820CDDC8;
	// cmpwi cr6,r3,32
	cr6.compare<int32_t>(ctx.r3.s32, 32, xer);
	// bne cr6,0x820cdd38
	if (!cr6.getEQ()) goto loc_820CDD38;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820a8b20
	sub_820A8B20(ctx, base);
	// b 0x820cddc8
	goto loc_820CDDC8;
loc_820CDD38:
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x820cddbc
	if (cr6.getEQ()) goto loc_820CDDBC;
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// beq cr6,0x820cddbc
	if (cr6.getEQ()) goto loc_820CDDBC;
	// cmpwi cr6,r3,15
	cr6.compare<int32_t>(ctx.r3.s32, 15, xer);
	// beq cr6,0x820cdd98
	if (cr6.getEQ()) goto loc_820CDD98;
	// cmpwi cr6,r3,16
	cr6.compare<int32_t>(ctx.r3.s32, 16, xer);
	// beq cr6,0x820cdd98
	if (cr6.getEQ()) goto loc_820CDD98;
	// cmpwi cr6,r3,40
	cr6.compare<int32_t>(ctx.r3.s32, 40, xer);
	// bne cr6,0x820cdd68
	if (!cr6.getEQ()) goto loc_820CDD68;
	// bl 0x820cc698
	sub_820CC698(ctx, base);
	// b 0x820cddc8
	goto loc_820CDDC8;
loc_820CDD68:
	// cmpwi cr6,r3,60
	cr6.compare<int32_t>(ctx.r3.s32, 60, xer);
	// bne cr6,0x820cdd84
	if (!cr6.getEQ()) goto loc_820CDD84;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r10,4888(r11)
	PPC_STORE_U32(r11.u32 + 4888, ctx.r10.u32);
	// b 0x820cddc8
	goto loc_820CDDC8;
loc_820CDD84:
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x820a6610
	sub_820A6610(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820cd078
	sub_820CD078(ctx, base);
	// b 0x820cddc8
	goto loc_820CDDC8;
loc_820CDD98:
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x820a6610
	sub_820A6610(ctx, base);
	// li r31,5
	r31.s64 = 5;
loc_820CDDA4:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820cd078
	sub_820CD078(ctx, base);
	// addi r31,r31,-1
	r31.s64 = r31.s64 + -1;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x820cdda4
	if (!cr6.getEQ()) goto loc_820CDDA4;
	// b 0x820cddc8
	goto loc_820CDDC8;
loc_820CDDBC:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820cd9e8
	sub_820CD9E8(ctx, base);
loc_820CDDC8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CDDE0"))) PPC_WEAK_FUNC(sub_820CDDE0);
PPC_FUNC_IMPL(__imp__sub_820CDDE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820cdc70
	sub_820CDC70(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x820cdc70
	sub_820CDC70(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CDE10"))) PPC_WEAK_FUNC(sub_820CDE10);
PPC_FUNC_IMPL(__imp__sub_820CDE10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lis r29,-32013
	r29.s64 = -2098003968;
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r11,-2320(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -2320);
	// addi r31,r11,-4
	r31.s64 = r11.s64 + -4;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r30,r11,-2296
	r30.s64 = r11.s64 + -2296;
	// li r11,0
	r11.s64 = 0;
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// stw r11,904(r29)
	PPC_STORE_U32(r29.u32 + 904, r11.u32);
	// blt cr6,0x820cdeac
	if (cr6.getLT()) goto loc_820CDEAC;
loc_820CDE48:
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820cde94
	if (cr6.getEQ()) goto loc_820CDE94;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x820cde8c
	if (cr6.getEQ()) goto loc_820CDE8C;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820cde84
	if (cr6.getEQ()) goto loc_820CDE84;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x820cde84
	if (cr6.getEQ()) goto loc_820CDE84;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x820cde8c
	if (!cr6.getEQ()) goto loc_820CDE8C;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x820df060
	sub_820DF060(ctx, base);
	// b 0x820cde8c
	goto loc_820CDE8C;
loc_820CDE84:
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x820db3c8
	sub_820DB3C8(ctx, base);
loc_820CDE8C:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cdea0
	if (cr6.getEQ()) goto loc_820CDEA0;
loc_820CDE94:
	// addi r31,r31,-4
	r31.s64 = r31.s64 + -4;
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// bge cr6,0x820cde48
	if (!cr6.getLT()) goto loc_820CDE48;
loc_820CDEA0:
	// lwz r3,904(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 904);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
loc_820CDEAC:
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820CDEB8"))) PPC_WEAK_FUNC(sub_820CDEB8);
PPC_FUNC_IMPL(__imp__sub_820CDEB8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// ble cr6,0x820cdf60
	if (!cr6.getGT()) goto loc_820CDF60;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f11,12(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f10,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// addi r11,r11,-1384
	r11.s64 = r11.s64 + -1384;
	// lfs f8,16180(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16180);
	ctx.f8.f64 = double(temp.f32);
loc_820CDF00:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r10,428(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 428);
	// lfs f0,16(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f10
	f0.f64 = double(float(f0.f64 - ctx.f10.f64));
	// lfs f13,20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// lfs f12,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// fmuls f0,f0,f0
	f0.f64 = double(float(f0.f64 * f0.f64));
	// fmadds f0,f13,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// fmadds f0,f12,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + f0.f64));
	// fsqrts f0,f0
	f0.f64 = double(float(sqrt(f0.f64)));
	// fcmpu cr6,f0,f8
	cr6.compare(f0.f64, ctx.f8.f64);
	// blt cr6,0x820cdf5c
	if (cr6.getLT()) goto loc_820CDF5C;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmpw cr6,r9,r8
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r8.s32, xer);
	// blt cr6,0x820cdf00
	if (cr6.getLT()) goto loc_820CDF00;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_820CDF5C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_820CDF60:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CDF78"))) PPC_WEAK_FUNC(sub_820CDF78);
PPC_FUNC_IMPL(__imp__sub_820CDF78) {
	PPC_FUNC_PROLOGUE();
	// b 0x820ccca8
	sub_820CCCA8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820CDF80"))) PPC_WEAK_FUNC(sub_820CDF80);
PPC_FUNC_IMPL(__imp__sub_820CDF80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x820cdf9c
	if (!cr6.getEQ()) goto loc_820CDF9C;
	// b 0x82120300
	sub_82120300(ctx, base);
	return;
loc_820CDF9C:
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820cdfa8
	if (!cr6.getEQ()) goto loc_820CDFA8;
	// b 0x820b3e90
	sub_820B3E90(ctx, base);
	return;
loc_820CDFA8:
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820cdfc0
	if (cr6.getEQ()) goto loc_820CDFC0;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
loc_820CDFC0:
	// b 0x820db5d0
	sub_820DB5D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820CDFC4"))) PPC_WEAK_FUNC(sub_820CDFC4);
PPC_FUNC_IMPL(__imp__sub_820CDFC4) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CDFC8"))) PPC_WEAK_FUNC(sub_820CDFC8);
PPC_FUNC_IMPL(__imp__sub_820CDFC8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x820ce008
	if (!cr6.getEQ()) goto loc_820CE008;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// bl 0x82120300
	sub_82120300(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820CE008:
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820ce02c
	if (!cr6.getEQ()) goto loc_820CE02C;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// bl 0x820b3e90
	sub_820B3E90(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820CE02C:
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x820ce050
	if (cr6.getEQ()) goto loc_820CE050;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820ce044
	if (cr6.getEQ()) goto loc_820CE044;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x820ce050
	if (!cr6.getEQ()) goto loc_820CE050;
loc_820CE044:
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// bl 0x820db5d0
	sub_820DB5D0(ctx, base);
loc_820CE050:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CE060"))) PPC_WEAK_FUNC(sub_820CE060);
PPC_FUNC_IMPL(__imp__sub_820CE060) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// li r6,-1
	ctx.r6.s64 = -1;
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// bgt cr6,0x820ce074
	if (cr6.getGT()) goto loc_820CE074;
loc_820CE06C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_820CE074:
	// li r7,0
	ctx.r7.s64 = 0;
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// ble cr6,0x820ce13c
	if (!cr6.getGT()) goto loc_820CE13C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f11,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// mr r9,r4
	ctx.r9.u64 = ctx.r4.u64;
	// lfs f12,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f12.f64 = double(temp.f32);
loc_820CE094:
	// addi r11,r7,1
	r11.s64 = ctx.r7.s64 + 1;
	// lfs f13,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,4(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	f0.f64 = double(temp.f32);
	// fsubs f8,f11,f13
	ctx.f8.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// divw r10,r11,r5
	ctx.r10.s32 = r11.s32 / ctx.r5.s32;
	// fsubs f9,f10,f0
	ctx.f9.f64 = double(float(ctx.f10.f64 - f0.f64));
	// rotlwi r8,r11,1
	ctx.r8.u64 = __builtin_rotateleft32(r11.u32, 1);
	// mullw r10,r10,r5
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r5.s32);
	// subf r10,r10,r11
	ctx.r10.s64 = r11.s64 - ctx.r10.s64;
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// andc r8,r5,r8
	ctx.r8.u64 = ctx.r5.u64 & ~ctx.r8.u64;
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// twllei r5,0
	// twlgei r8,-1
	// lfs f7,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f13,f7,f13
	ctx.f13.f64 = double(float(ctx.f7.f64 - ctx.f13.f64));
	// lfs f7,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f0,f7,f0
	f0.f64 = double(float(ctx.f7.f64 - f0.f64));
	// fmuls f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fmsubs f0,f0,f8,f13
	f0.f64 = double(float(f0.f64 * ctx.f8.f64 - ctx.f13.f64));
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// beq cr6,0x820ce12c
	if (cr6.getEQ()) goto loc_820CE12C;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x820ce11c
	if (cr6.getEQ()) goto loc_820CE11C;
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// blt cr6,0x820ce11c
	if (cr6.getLT()) goto loc_820CE11C;
	// beq cr6,0x820ce110
	if (cr6.getEQ()) goto loc_820CE110;
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// blt cr6,0x820ce06c
	if (cr6.getLT()) goto loc_820CE06C;
	// b 0x820ce12c
	goto loc_820CE12C;
loc_820CE110:
	// fcmpu cr6,f0,f12
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f12.f64);
	// bgt cr6,0x820ce06c
	if (cr6.getGT()) goto loc_820CE06C;
	// b 0x820ce12c
	goto loc_820CE12C;
loc_820CE11C:
	// fcmpu cr6,f0,f12
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f12.f64);
	// li r6,1
	ctx.r6.s64 = 1;
	// bgt cr6,0x820ce12c
	if (cr6.getGT()) goto loc_820CE12C;
	// li r6,0
	ctx.r6.s64 = 0;
loc_820CE12C:
	// mr r7,r11
	ctx.r7.u64 = r11.u64;
	// addi r9,r9,8
	ctx.r9.s64 = ctx.r9.s64 + 8;
	// cmpw cr6,r7,r5
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r5.s32, xer);
	// blt cr6,0x820ce094
	if (cr6.getLT()) goto loc_820CE094;
loc_820CE13C:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CE148"))) PPC_WEAK_FUNC(sub_820CE148);
PPC_FUNC_IMPL(__imp__sub_820CE148) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x820ce158
	if (!cr6.getEQ()) goto loc_820CE158;
	// b 0x821203d0
	sub_821203D0(ctx, base);
	return;
loc_820CE158:
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820ce164
	if (!cr6.getEQ()) goto loc_820CE164;
	// b 0x820b4028
	sub_820B4028(ctx, base);
	return;
loc_820CE164:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r4)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CE178"))) PPC_WEAK_FUNC(sub_820CE178);
PPC_FUNC_IMPL(__imp__sub_820CE178) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x820ce1a4
	if (!cr6.getEQ()) goto loc_820CE1A4;
	// bl 0x821203f8
	sub_821203F8(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820CE1A4:
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820ce1d4
	if (!cr6.getEQ()) goto loc_820CE1D4;
	// bl 0x820c9b90
	sub_820C9B90(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-1384
	r11.s64 = r11.s64 + -1384;
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// bl 0x820b3c78
	sub_820B3C78(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820CE1D4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f1.f64 = double(temp.f32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CE1F0"))) PPC_WEAK_FUNC(sub_820CE1F0);
PPC_FUNC_IMPL(__imp__sub_820CE1F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x820ce204
	if (!cr6.getEQ()) goto loc_820CE204;
	// lwz r3,8(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// b 0x8211dd98
	sub_8211DD98(ctx, base);
	return;
loc_820CE204:
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820ce210
	if (!cr6.getEQ()) goto loc_820CE210;
	// b 0x820b3e10
	sub_820B3E10(ctx, base);
	return;
loc_820CE210:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820ce228
	if (cr6.getEQ()) goto loc_820CE228;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x820ce228
	if (cr6.getEQ()) goto loc_820CE228;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
loc_820CE228:
	// b 0x820db5a0
	sub_820DB5A0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820CE22C"))) PPC_WEAK_FUNC(sub_820CE22C);
PPC_FUNC_IMPL(__imp__sub_820CE22C) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CE230"))) PPC_WEAK_FUNC(sub_820CE230);
PPC_FUNC_IMPL(__imp__sub_820CE230) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f22{};
	PPCRegister f23{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed530
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// bl 0x8210d8b0
	sub_8210D8B0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,16188(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16188);
	f0.f64 = double(temp.f32);
	// fmuls f31,f1,f0
	f31.f64 = double(float(ctx.f1.f64 * f0.f64));
	// bl 0x8210d8d0
	sub_8210D8D0(ctx, base);
	// fadds f30,f1,f31
	ctx.fpscr.disableFlushMode();
	f30.f64 = double(float(ctx.f1.f64 + f31.f64));
	// bl 0x8210d8b0
	sub_8210D8B0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,16184(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16184);
	f0.f64 = double(temp.f32);
	// fmuls f31,f1,f0
	f31.f64 = double(float(ctx.f1.f64 * f0.f64));
	// bl 0x8210d8d0
	sub_8210D8D0(ctx, base);
	// fadds f24,f1,f31
	ctx.fpscr.disableFlushMode();
	f24.f64 = double(float(ctx.f1.f64 + f31.f64));
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,12900(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12900);
	f0.f64 = double(temp.f32);
	// fmuls f31,f1,f0
	f31.f64 = double(float(ctx.f1.f64 * f0.f64));
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// fadds f23,f1,f31
	ctx.fpscr.disableFlushMode();
	f23.f64 = double(float(ctx.f1.f64 + f31.f64));
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,12888(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12888);
	f0.f64 = double(temp.f32);
	// fmuls f31,f1,f0
	f31.f64 = double(float(ctx.f1.f64 * f0.f64));
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fadds f22,f1,f31
	ctx.fpscr.disableFlushMode();
	f22.f64 = double(float(ctx.f1.f64 + f31.f64));
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f29,14264(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14264);
	f29.f64 = double(temp.f32);
	// bl 0x8210d660
	sub_8210D660(ctx, base);
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// stfs f0,152(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,156(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,160(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// bl 0x8210d660
	sub_8210D660(ctx, base);
	// lfs f0,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// stfs f0,152(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,156(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,160(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// bl 0x8210d660
	sub_8210D660(ctx, base);
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// stfs f0,152(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// lfs f0,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,156(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,160(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// bl 0x8210d660
	sub_8210D660(ctx, base);
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// stfs f0,152(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// lfs f0,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,156(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,160(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// bl 0x8210d660
	sub_8210D660(ctx, base);
	// lfs f0,140(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// blt cr6,0x820ce604
	if (cr6.getLT()) goto loc_820CE604;
	// lfs f0,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f24
	cr6.compare(f0.f64, f24.f64);
	// bgt cr6,0x820ce604
	if (cr6.getGT()) goto loc_820CE604;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// lfs f25,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f25.f64 = double(temp.f32);
	// fmr f27,f25
	f27.f64 = f25.f64;
	// bl 0x820a4950
	sub_820A4950(ctx, base);
	// lfs f1,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x823ed4c8
	sub_823ED4C8(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// lfs f1,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f1.f64 = double(temp.f32);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// bl 0x823ee958
	sub_823EE958(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// stfs f0,120(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// bl 0x820b08e8
	sub_820B08E8(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// lfs f26,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f26.f64 = double(temp.f32);
	// beq cr6,0x820ce47c
	if (cr6.getEQ()) goto loc_820CE47C;
	// fcmpu cr6,f13,f22
	cr6.compare(ctx.f13.f64, f22.f64);
	// bgt cr6,0x820ce604
	if (cr6.getGT()) goto loc_820CE604;
	// lfs f0,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f23
	cr6.compare(f0.f64, f23.f64);
	// blt cr6,0x820ce604
	if (cr6.getLT()) goto loc_820CE604;
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,12896(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12896);
	f0.f64 = double(temp.f32);
	// fmuls f27,f13,f0
	f27.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x820ce404
	if (!cr6.getEQ()) goto loc_820CE404;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lfs f0,19388(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 19388);
	f0.f64 = double(temp.f32);
	// fmuls f27,f0,f27
	f27.f64 = double(float(f0.f64 * f27.f64));
loc_820CE404:
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// fmuls f31,f1,f26
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(ctx.f1.f64 * f26.f64));
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// lfs f13,120(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	f0.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// fadds f13,f1,f31
	ctx.f13.f64 = double(float(ctx.f1.f64 + f31.f64));
	// fmsubs f0,f0,f26,f27
	f0.f64 = double(float(f0.f64 * f26.f64 - f27.f64));
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x820ce604
	if (cr6.getLT()) goto loc_820CE604;
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// fmuls f31,f1,f26
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(ctx.f1.f64 * f26.f64));
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// lfs f13,120(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	f0.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// fadds f13,f1,f31
	ctx.f13.f64 = double(float(ctx.f1.f64 + f31.f64));
	// fmadds f0,f0,f26,f27
	f0.f64 = double(float(f0.f64 * f26.f64 + f27.f64));
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bgt cr6,0x820ce604
	if (cr6.getGT()) goto loc_820CE604;
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f23
	cr6.compare(f0.f64, f23.f64);
	// blt cr6,0x820ce604
	if (cr6.getLT()) goto loc_820CE604;
	// fcmpu cr6,f0,f22
	cr6.compare(f0.f64, f22.f64);
	// ble cr6,0x820ce494
	if (!cr6.getGT()) goto loc_820CE494;
	// fmr f1,f29
	ctx.f1.f64 = f29.f64;
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed57c
	// b 0x823ed184
	return;
loc_820CE47C:
	// lfs f0,100(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820ce604
	if (cr6.getLT()) goto loc_820CE604;
	// lfs f13,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x820ce604
	if (cr6.getGT()) goto loc_820CE604;
loc_820CE494:
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,-1364(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// bl 0x820b3c80
	sub_820B3C80(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820b3e10
	sub_820B3E10(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,19
	ctx.r8.s64 = 19;
	// lfs f4,20(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + 20);
	ctx.f4.f64 = double(temp.f32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f3,12(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// fmr f7,f25
	ctx.f7.f64 = f25.f64;
	// lfs f1,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmr f6,f31
	ctx.f6.f64 = f31.f64;
	// lfs f28,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f28.f64 = double(temp.f32);
	// fmr f5,f31
	ctx.f5.f64 = f31.f64;
	// fmr f8,f28
	ctx.f8.f64 = f28.f64;
	// bl 0x82112020
	sub_82112020(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ce5f8
	if (cr6.getEQ()) goto loc_820CE5F8;
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x820ce5f8
	if (!cr6.getEQ()) goto loc_820CE5F8;
	// lfs f0,132(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// bge cr6,0x820ce520
	if (!cr6.getLT()) goto loc_820CE520;
	// fmr f0,f30
	f0.f64 = f30.f64;
	// b 0x820ce52c
	goto loc_820CE52C;
loc_820CE520:
	// fcmpu cr6,f0,f24
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f24.f64);
	// ble cr6,0x820ce52c
	if (!cr6.getGT()) goto loc_820CE52C;
	// fmr f0,f24
	f0.f64 = f24.f64;
loc_820CE52C:
	// stfs f0,4(r27)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r27.u32 + 4, temp.u32);
	// bl 0x820b08e8
	sub_820B08E8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ce560
	if (cr6.getEQ()) goto loc_820CE560;
	// lfs f0,128(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f23
	cr6.compare(f0.f64, f23.f64);
	// bge cr6,0x820ce550
	if (!cr6.getLT()) goto loc_820CE550;
	// fmr f0,f23
	f0.f64 = f23.f64;
	// b 0x820ce55c
	goto loc_820CE55C;
loc_820CE550:
	// fcmpu cr6,f0,f22
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f22.f64);
	// ble cr6,0x820ce55c
	if (!cr6.getGT()) goto loc_820CE55C;
	// fmr f0,f22
	f0.f64 = f22.f64;
loc_820CE55C:
	// stfs f0,0(r27)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r27.u32 + 0, temp.u32);
loc_820CE560:
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// fmuls f31,f1,f26
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(ctx.f1.f64 * f26.f64));
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// fadds f0,f1,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 + f31.f64));
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820ce5a0
	if (cr6.getLT()) goto loc_820CE5A0;
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// fmuls f31,f1,f26
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(ctx.f1.f64 * f26.f64));
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// fadds f0,f1,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 + f31.f64));
	// lfs f13,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x820ce5a0
	if (cr6.getGT()) goto loc_820CE5A0;
	// fmr f29,f28
	f29.f64 = f28.f64;
	// b 0x820ce5f8
	goto loc_820CE5F8;
loc_820CE5A0:
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// fmuls f31,f1,f26
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(ctx.f1.f64 * f26.f64));
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// fadds f0,f1,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 + f31.f64));
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820ce5d8
	if (cr6.getLT()) goto loc_820CE5D8;
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// fmuls f31,f1,f26
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(ctx.f1.f64 * f26.f64));
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// fadds f0,f1,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 + f31.f64));
	// lfs f13,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// b 0x820ce5f0
	goto loc_820CE5F0;
loc_820CE5D8:
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// fmuls f31,f1,f26
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(ctx.f1.f64 * f26.f64));
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// fadds f0,f1,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 + f31.f64));
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
loc_820CE5F0:
	// fdivs f0,f0,f27
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f0.f64 / f27.f64));
	// fsubs f29,f28,f0
	f29.f64 = double(float(f28.f64 - f0.f64));
loc_820CE5F8:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820b3e10
	sub_820B3E10(ctx, base);
loc_820CE604:
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f29.f64;
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed57c
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820CE618"))) PPC_WEAK_FUNC(sub_820CE618);
PPC_FUNC_IMPL(__imp__sub_820CE618) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed544
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r27,0
	r27.s64 = 0;
	// lfs f27,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f27.f64 = double(temp.f32);
	// fmr f28,f27
	f28.f64 = f27.f64;
	// fmr f29,f27
	f29.f64 = f27.f64;
	// bl 0x820b0828
	sub_820B0828(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ce7b4
	if (cr6.getEQ()) goto loc_820CE7B4;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r11,-2320(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -2320);
	// addi r29,r11,-4
	r29.s64 = r11.s64 + -4;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r28,r11,-2296
	r28.s64 = r11.s64 + -2296;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// cmplw cr6,r29,r28
	cr6.compare<uint32_t>(r29.u32, r28.u32, xer);
	// lfs f30,6580(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6580);
	f30.f64 = double(temp.f32);
	// blt cr6,0x820ce7b4
	if (cr6.getLT()) goto loc_820CE7B4;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f31.f64 = double(temp.f32);
loc_820CE678:
	// lwz r31,0(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820ce73c
	if (cr6.getEQ()) goto loc_820CE73C;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x820ce6bc
	if (cr6.getEQ()) goto loc_820CE6BC;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820ce73c
	if (!cr6.getEQ()) goto loc_820CE73C;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ce73c
	if (cr6.getEQ()) goto loc_820CE73C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820c9b90
	sub_820C9B90(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// cmpw cr6,r30,r3
	cr6.compare<int32_t>(r30.s32, ctx.r3.s32, xer);
	// beq cr6,0x820ce73c
	if (cr6.getEQ()) goto loc_820CE73C;
loc_820CE6BC:
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82120290
	sub_82120290(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x820ce6e8
	if (!cr6.getEQ()) goto loc_820CE6E8;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82120290
	sub_82120290(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820ce73c
	if (cr6.getEQ()) goto loc_820CE73C;
loc_820CE6E8:
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82120408
	sub_82120408(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ce73c
	if (cr6.getEQ()) goto loc_820CE73C;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ce230
	sub_820CE230(ctx, base);
	// fcmpu cr6,f1,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f30.f64);
	// ble cr6,0x820ce73c
	if (!cr6.getGT()) goto loc_820CE73C;
	// lfs f28,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f28.f64 = double(temp.f32);
	// fmr f30,f1
	f30.f64 = ctx.f1.f64;
	// lfs f29,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f29.f64 = double(temp.f32);
	// mr r27,r31
	r27.u64 = r31.u64;
	// fcmpu cr6,f1,f31
	cr6.compare(ctx.f1.f64, f31.f64);
	// bge cr6,0x820ce748
	if (!cr6.getLT()) goto loc_820CE748;
loc_820CE73C:
	// addi r29,r29,-4
	r29.s64 = r29.s64 + -4;
	// cmplw cr6,r29,r28
	cr6.compare<uint32_t>(r29.u32, r28.u32, xer);
	// bge cr6,0x820ce678
	if (!cr6.getLT()) goto loc_820CE678;
loc_820CE748:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x820ce7b4
	if (cr6.getEQ()) goto loc_820CE7B4;
	// bl 0x8210d8d0
	sub_8210D8D0(ctx, base);
	// fsubs f29,f29,f1
	ctx.fpscr.disableFlushMode();
	f29.f64 = double(float(f29.f64 - ctx.f1.f64));
	// bl 0x8210d8b0
	sub_8210D8B0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lfs f30,2692(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f30.f64 = double(temp.f32);
	// fmuls f0,f1,f30
	f0.f64 = double(float(ctx.f1.f64 * f30.f64));
	// fdivs f0,f29,f0
	f0.f64 = double(float(f29.f64 / f0.f64));
	// fsubs f1,f0,f31
	ctx.f1.f64 = double(float(f0.f64 - f31.f64));
	// bl 0x820b0888
	sub_820B0888(ctx, base);
	// bl 0x820b08e8
	sub_820B08E8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ce7cc
	if (cr6.getEQ()) goto loc_820CE7CC;
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// fsubs f29,f28,f1
	ctx.fpscr.disableFlushMode();
	f29.f64 = double(float(f28.f64 - ctx.f1.f64));
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// fmuls f0,f1,f30
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 * f30.f64));
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// fdivs f0,f29,f0
	f0.f64 = double(float(f29.f64 / f0.f64));
	// fsubs f1,f0,f31
	ctx.f1.f64 = double(float(f0.f64 - f31.f64));
	// bl 0x820b0938
	sub_820B0938(ctx, base);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed590
	// b 0x823ed184
	return;
loc_820CE7B4:
	// li r3,0
	ctx.r3.s64 = 0;
	// fmr f1,f27
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f27.f64;
	// bl 0x820b0888
	sub_820B0888(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// fmr f1,f27
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f27.f64;
	// bl 0x820b0938
	sub_820B0938(ctx, base);
loc_820CE7CC:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed590
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820CE7E0"))) PPC_WEAK_FUNC(sub_820CE7E0);
PPC_FUNC_IMPL(__imp__sub_820CE7E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,180(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 180);
	f0.f64 = double(temp.f32);
	// lfs f13,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x820ce800
	if (cr6.getGT()) goto loc_820CE800;
	// li r3,4096
	ctx.r3.s64 = 4096;
	// b 0x820ce814
	goto loc_820CE814;
loc_820CE800:
	// lfs f13,132(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// li r3,8192
	ctx.r3.s64 = 8192;
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820ce814
	if (!cr6.getLT()) goto loc_820CE814;
	// li r3,16384
	ctx.r3.s64 = 16384;
loc_820CE814:
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// rlwinm r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// ori r3,r3,32768
	ctx.r3.u64 = ctx.r3.u64 | 32768;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CE830"))) PPC_WEAK_FUNC(sub_820CE830);
PPC_FUNC_IMPL(__imp__sub_820CE830) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x820ce8c4
	if (!cr6.getEQ()) goto loc_820CE8C4;
	// rlwinm r11,r4,0,23,23
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x100;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ce868
	if (cr6.getEQ()) goto loc_820CE868;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r11,0,5,5
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ce868
	if (cr6.getEQ()) goto loc_820CE868;
	// li r3,0
	ctx.r3.s64 = 0;
loc_820CE868:
	// rlwinm r11,r4,0,30,30
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,180(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 180);
	f0.f64 = double(temp.f32);
	// lfs f13,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x820ce894
	if (cr6.getGT()) goto loc_820CE894;
	// li r11,4096
	r11.s64 = 4096;
	// b 0x820ce8a8
	goto loc_820CE8A8;
loc_820CE894:
	// lfs f13,132(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// li r11,8192
	r11.s64 = 8192;
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820ce8a8
	if (!cr6.getLT()) goto loc_820CE8A8;
	// li r11,16384
	r11.s64 = 16384;
loc_820CE8A8:
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// rlwinm r10,r10,0,2,2
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20000000;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820ce8bc
	if (cr6.getEQ()) goto loc_820CE8BC;
	// ori r11,r11,32768
	r11.u64 = r11.u64 | 32768;
loc_820CE8BC:
	// and r11,r11,r4
	r11.u64 = r11.u64 & ctx.r4.u64;
	// b 0x820ce940
	goto loc_820CE940;
loc_820CE8C4:
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820ce8d4
	if (!cr6.getEQ()) goto loc_820CE8D4;
	// rlwinm r11,r4,0,29,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x4;
	// b 0x820ce940
	goto loc_820CE940;
loc_820CE8D4:
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x820ce8e4
	if (!cr6.getEQ()) goto loc_820CE8E4;
	// rlwinm r11,r4,0,28,28
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x8;
	// b 0x820ce940
	goto loc_820CE940;
loc_820CE8E4:
	// rlwinm r9,r4,0,23,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x100;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820ce908
	if (cr6.getEQ()) goto loc_820CE908;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r10,r10,0,5,5
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4000000;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820ce908
	if (cr6.getEQ()) goto loc_820CE908;
	// li r3,0
	ctx.r3.s64 = 0;
loc_820CE908:
	// rlwinm r10,r4,0,22,22
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x200;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820ce928
	if (cr6.getEQ()) goto loc_820CE928;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r10,r10,0,14,14
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20000;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820ce928
	if (!cr6.getEQ()) goto loc_820CE928;
	// li r3,0
	ctx.r3.s64 = 0;
loc_820CE928:
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// rlwinm r11,r4,0,27,27
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0x10;
	// bne cr6,0x820ce940
	if (!cr6.getEQ()) goto loc_820CE940;
	// clrlwi r11,r4,31
	r11.u64 = ctx.r4.u32 & 0x1;
loc_820CE940:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CE950"))) PPC_WEAK_FUNC(sub_820CE950);
PPC_FUNC_IMPL(__imp__sub_820CE950) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// blt cr6,0x820ce998
	if (cr6.getLT()) goto loc_820CE998;
	// lwz r8,0(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
loc_820CE960:
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x820ce988
	if (cr6.getLT()) goto loc_820CE988;
loc_820CE970:
	// cmpw cr6,r9,r11
	cr6.compare<int32_t>(ctx.r9.s32, r11.s32, xer);
	// beq cr6,0x820ce9a0
	if (cr6.getEQ()) goto loc_820CE9A0;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820ce970
	if (!cr6.getLT()) goto loc_820CE970;
loc_820CE988:
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bge cr6,0x820ce960
	if (!cr6.getLT()) goto loc_820CE960;
loc_820CE998:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_820CE9A0:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CE9A8"))) PPC_WEAK_FUNC(sub_820CE9A8);
PPC_FUNC_IMPL(__imp__sub_820CE9A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r9,-32013
	ctx.r9.s64 = -2098003968;
	// rlwinm r10,r4,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 5) & 0xFFFFFFE0;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// lwz r9,-2316(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + -2316);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
loc_820CE9C0:
	// lhz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
	// cmplwi cr6,r7,32768
	cr6.compare<uint32_t>(ctx.r7.u32, 32768, xer);
	// bge cr6,0x820ce9e4
	if (!cr6.getLT()) goto loc_820CE9E4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// blt cr6,0x820ce9c0
	if (cr6.getLT()) goto loc_820CE9C0;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_820CE9E4:
	// rlwinm r10,r4,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 4) & 0xFFFFFFF0;
	// li r3,1
	ctx.r3.s64 = 1;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// sthx r8,r11,r9
	PPC_STORE_U16(r11.u32 + ctx.r9.u32, ctx.r8.u16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CEA00"))) PPC_WEAK_FUNC(sub_820CEA00);
PPC_FUNC_IMPL(__imp__sub_820CEA00) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r6,-32013
	ctx.r6.s64 = -2098003968;
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r8,-2316(r6)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + -2316);
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
loc_820CEA1C:
	// lhz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 0);
	// cmplwi cr6,r10,65534
	cr6.compare<uint32_t>(ctx.r10.u32, 65534, xer);
	// beq cr6,0x820cea58
	if (cr6.getEQ()) goto loc_820CEA58;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,32
	r11.s64 = r11.s64 + 32;
	// cmpwi cr6,r9,256
	cr6.compare<int32_t>(ctx.r9.s32, 256, xer);
	// blt cr6,0x820cea1c
	if (cr6.getLT()) goto loc_820CEA1C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r11,16192
	ctx.r3.s64 = r11.s64 + 16192;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820CEA58:
	// rlwinm r10,r9,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 5) & 0xFFFFFFE0;
	// li r11,16
	r11.s64 = 16;
	// li r7,-1
	ctx.r7.s64 = -1;
	// b 0x820cea6c
	goto loc_820CEA6C;
loc_820CEA68:
	// lwz r8,-2316(r6)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + -2316);
loc_820CEA6C:
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// sthx r7,r10,r8
	PPC_STORE_U16(ctx.r10.u32 + ctx.r8.u32, ctx.r7.u16);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cea68
	if (!cr6.getEQ()) goto loc_820CEA68;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// blt cr6,0x820ceaac
	if (cr6.getLT()) goto loc_820CEAAC;
	// lwz r11,-2316(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + -2316);
	// rlwinm r10,r4,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 5) & 0xFFFFFFE0;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// sth r9,30(r11)
	PPC_STORE_U16(r11.u32 + 30, ctx.r9.u16);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820CEAAC:
	// lis r11,-32013
	r11.s64 = -2098003968;
	// rlwinm r8,r3,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// lwz r11,-2308(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -2308);
	// sthx r9,r8,r11
	PPC_STORE_U16(ctx.r8.u32 + r11.u32, ctx.r9.u16);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CEAD0"))) PPC_WEAK_FUNC(sub_820CEAD0);
PPC_FUNC_IMPL(__imp__sub_820CEAD0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// extsh r3,r4
	ctx.r3.s64 = ctx.r4.s16;
	// li r4,-1
	ctx.r4.s64 = -1;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x820ceb98
	if (cr6.getLT()) goto loc_820CEB98;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r9,26214
	ctx.r9.s64 = 1717960704;
	// addi r11,r11,-784
	r11.s64 = r11.s64 + -784;
	// ori r9,r9,26215
	ctx.r9.u64 = ctx.r9.u64 | 26215;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// mulhw r10,r10,r9
	ctx.r10.s64 = (int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32)) >> 32;
	// lwz r11,-2308(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -2308);
	// rlwinm r8,r3,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// srawi r10,r10,5
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1F) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 5;
	// rlwinm r9,r10,1,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// lhzx r11,r8,r11
	r11.u64 = PPC_LOAD_U16(ctx.r8.u32 + r11.u32);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// extsh r31,r10
	r31.s64 = ctx.r10.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x820ceb80
	if (cr6.getLT()) goto loc_820CEB80;
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// lwz r7,-2316(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + -2316);
loc_820CEB40:
	// rlwinm r9,r11,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// li r10,0
	ctx.r10.s64 = 0;
	// add r8,r9,r7
	ctx.r8.u64 = ctx.r9.u64 + ctx.r7.u64;
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
loc_820CEB50:
	// lhz r6,0(r9)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// cmplwi cr6,r6,32768
	cr6.compare<uint32_t>(ctx.r6.u32, 32768, xer);
	// bge cr6,0x820cebac
	if (!cr6.getLT()) goto loc_820CEBAC;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,2
	ctx.r9.s64 = ctx.r9.s64 + 2;
	// cmpwi cr6,r10,15
	cr6.compare<int32_t>(ctx.r10.s32, 15, xer);
	// blt cr6,0x820ceb50
	if (cr6.getLT()) goto loc_820CEB50;
	// lhz r10,30(r8)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r8.u32 + 30);
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// extsh r11,r10
	r11.s64 = ctx.r10.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820ceb40
	if (!cr6.getLT()) goto loc_820CEB40;
loc_820CEB80:
	// bl 0x820cea00
	sub_820CEA00(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// blt cr6,0x820ceb98
	if (cr6.getLT()) goto loc_820CEB98;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ce9a8
	sub_820CE9A8(ctx, base);
loc_820CEB98:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_820CEBAC:
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// sthx r31,r11,r7
	PPC_STORE_U16(r11.u32 + ctx.r7.u32, r31.u16);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CEBD0"))) PPC_WEAK_FUNC(sub_820CEBD0);
PPC_FUNC_IMPL(__imp__sub_820CEBD0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x823ed130
	// extsh r11,r4
	r11.s64 = ctx.r4.s16;
	// li r27,-1
	r27.s64 = -1;
	// li r30,0
	r30.s64 = 0;
	// mr r29,r27
	r29.u64 = r27.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x820ced04
	if (cr6.getLT()) goto loc_820CED04;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// rlwinm r31,r11,1,0,30
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r11,26214
	r11.s64 = 1717960704;
	// addi r10,r10,-784
	ctx.r10.s64 = ctx.r10.s64 + -784;
	// ori r9,r11,26215
	ctx.r9.u64 = r11.u64 | 26215;
	// subf r11,r10,r3
	r11.s64 = ctx.r3.s64 - ctx.r10.s64;
	// lis r3,-32013
	ctx.r3.s64 = -2098003968;
	// mulhw r11,r11,r9
	r11.s64 = (int64_t(r11.s32) * int64_t(ctx.r9.s32)) >> 32;
	// lwz r10,-2308(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + -2308);
	// lhzx r10,r31,r10
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + ctx.r10.u32);
	// srawi r11,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	r11.s64 = r11.s32 >> 5;
	// extsh r5,r10
	ctx.r5.s64 = ctx.r10.s16;
	// rlwinm r10,r11,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// blt cr6,0x820ced04
	if (cr6.getLT()) goto loc_820CED04;
	// lis r8,-32013
	ctx.r8.s64 = -2098003968;
	// extsh r28,r11
	r28.s64 = r11.s16;
	// li r26,-2
	r26.s64 = -2;
	// lwz r11,-2316(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2316);
loc_820CEC44:
	// rlwinm r7,r5,5,0,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 5) & 0xFFFFFFE0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r6,15
	ctx.r6.s64 = 15;
	// mr r10,r7
	ctx.r10.u64 = ctx.r7.u64;
loc_820CEC54:
	// lhzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + r11.u32);
	// extsh r9,r9
	ctx.r9.s64 = ctx.r9.s16;
	// cmpw cr6,r9,r28
	cr6.compare<int32_t>(ctx.r9.s32, r28.s32, xer);
	// bne cr6,0x820cec74
	if (!cr6.getEQ()) goto loc_820CEC74;
	// sthx r27,r10,r11
	PPC_STORE_U16(ctx.r10.u32 + r11.u32, r27.u16);
	// li r30,1
	r30.s64 = 1;
	// lwz r11,-2316(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2316);
	// b 0x820cec88
	goto loc_820CEC88;
loc_820CEC74:
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// bne cr6,0x820cec88
	if (!cr6.getEQ()) goto loc_820CEC88;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// blt cr6,0x820cec88
	if (cr6.getLT()) goto loc_820CEC88;
	// li r4,1
	ctx.r4.s64 = 1;
loc_820CEC88:
	// addi r6,r6,-1
	ctx.r6.s64 = ctx.r6.s64 + -1;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// bne cr6,0x820cec54
	if (!cr6.getEQ()) goto loc_820CEC54;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// bne cr6,0x820cece4
	if (!cr6.getEQ()) goto loc_820CECE4;
	// sthx r26,r7,r11
	PPC_STORE_U16(ctx.r7.u32 + r11.u32, r26.u16);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// lwz r11,-2316(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2316);
	// blt cr6,0x820ceccc
	if (cr6.getLT()) goto loc_820CECCC;
	// add r9,r7,r11
	ctx.r9.u64 = ctx.r7.u64 + r11.u64;
	// rlwinm r10,r29,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 5) & 0xFFFFFFE0;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lhz r10,30(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + 30);
	// sth r10,30(r11)
	PPC_STORE_U16(r11.u32 + 30, ctx.r10.u16);
	// lwz r11,-2316(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2316);
	// b 0x820cece8
	goto loc_820CECE8;
loc_820CECCC:
	// add r11,r7,r11
	r11.u64 = ctx.r7.u64 + r11.u64;
	// lhz r10,30(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 30);
	// lwz r11,-2308(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + -2308);
	// sthx r10,r31,r11
	PPC_STORE_U16(r31.u32 + r11.u32, ctx.r10.u16);
	// lwz r11,-2316(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2316);
	// b 0x820cece8
	goto loc_820CECE8;
loc_820CECE4:
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
loc_820CECE8:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x820ced04
	if (!cr6.getEQ()) goto loc_820CED04;
	// add r10,r7,r11
	ctx.r10.u64 = ctx.r7.u64 + r11.u64;
	// lhz r10,30(r10)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + 30);
	// extsh r5,r10
	ctx.r5.s64 = ctx.r10.s16;
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// bge cr6,0x820cec44
	if (!cr6.getLT()) goto loc_820CEC44;
loc_820CED04:
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820CED08"))) PPC_WEAK_FUNC(sub_820CED08);
PPC_FUNC_IMPL(__imp__sub_820CED08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x820ced1c
	if (!cr6.getEQ()) goto loc_820CED1C;
	// lwz r3,8(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// b 0x8211e6f8
	sub_8211E6F8(ctx, base);
	return;
loc_820CED1C:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820ced2c
	if (cr6.getEQ()) goto loc_820CED2C;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
loc_820CED2C:
	// lwz r3,8(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// b 0x820d0458
	sub_820D0458(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820CED34"))) PPC_WEAK_FUNC(sub_820CED34);
PPC_FUNC_IMPL(__imp__sub_820CED34) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CED38"))) PPC_WEAK_FUNC(sub_820CED38);
PPC_FUNC_IMPL(__imp__sub_820CED38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r29,r30,48
	r29.s64 = r30.s64 + 48;
	// mr r31,r29
	r31.u64 = r29.u64;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,255
	cr6.compare<uint32_t>(r11.u32, 255, xer);
	// beq cr6,0x820ced78
	if (cr6.getEQ()) goto loc_820CED78;
loc_820CED5C:
	// clrlwi r4,r11,24
	ctx.r4.u64 = r11.u32 & 0xFF;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820cebd0
	sub_820CEBD0(ctx, base);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,255
	cr6.compare<uint32_t>(r11.u32, 255, xer);
	// bne cr6,0x820ced5c
	if (!cr6.getEQ()) goto loc_820CED5C;
loc_820CED78:
	// lbz r11,1(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 1);
	// rlwinm r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820ced90
	if (!cr6.getEQ()) goto loc_820CED90;
	// li r11,255
	r11.s64 = 255;
	// stb r11,0(r29)
	PPC_STORE_U8(r29.u32 + 0, r11.u8);
loc_820CED90:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820CED98"))) PPC_WEAK_FUNC(sub_820CED98);
PPC_FUNC_IMPL(__imp__sub_820CED98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r31,r30,48
	r31.s64 = r30.s64 + 48;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,255
	cr6.compare<uint32_t>(r11.u32, 255, xer);
	// beq cr6,0x820ceddc
	if (cr6.getEQ()) goto loc_820CEDDC;
loc_820CEDC0:
	// clrlwi r4,r11,24
	ctx.r4.u64 = r11.u32 & 0xFF;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820cead0
	sub_820CEAD0(ctx, base);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,255
	cr6.compare<uint32_t>(r11.u32, 255, xer);
	// bne cr6,0x820cedc0
	if (!cr6.getEQ()) goto loc_820CEDC0;
loc_820CEDDC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CEDF8"))) PPC_WEAK_FUNC(sub_820CEDF8);
PPC_FUNC_IMPL(__imp__sub_820CEDF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// fmr f3,f1
	ctx.fpscr.disableFlushMode();
	ctx.f3.f64 = ctx.f1.f64;
	// li r30,0
	r30.s64 = 0;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// rlwinm r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ceeb4
	if (cr6.getEQ()) goto loc_820CEEB4;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820cee48
	if (cr6.getEQ()) goto loc_820CEE48;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x820cee48
	if (cr6.getEQ()) goto loc_820CEE48;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x820cee7c
	if (!cr6.getEQ()) goto loc_820CEE7C;
loc_820CEE48:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cee7c
	if (cr6.getEQ()) goto loc_820CEE7C;
	// lwz r10,100(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 100);
	// rlwinm r10,r10,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820cee7c
	if (cr6.getEQ()) goto loc_820CEE7C;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// addi r8,r11,204
	ctx.r8.s64 = r11.s64 + 204;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820cee80
	if (!cr6.getEQ()) goto loc_820CEE80;
loc_820CEE7C:
	// addi r8,r31,48
	ctx.r8.s64 = r31.s64 + 48;
loc_820CEE80:
	// lbz r10,0(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// cmplwi cr6,r10,255
	cr6.compare<uint32_t>(ctx.r10.u32, 255, xer);
	// beq cr6,0x820ceeac
	if (cr6.getEQ()) goto loc_820CEEAC;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
loc_820CEE94:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lbzx r10,r9,r8
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r8.u32);
	// cmplwi cr6,r10,255
	cr6.compare<uint32_t>(ctx.r10.u32, 255, xer);
	// bne cr6,0x820cee94
	if (!cr6.getEQ()) goto loc_820CEE94;
loc_820CEEAC:
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// b 0x820ceedc
	goto loc_820CEEDC;
loc_820CEEB4:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r9,7
	ctx.r9.s64 = 7;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// lfs f2,20(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// lfs f1,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bl 0x8210fd90
	sub_8210FD90(ctx, base);
loc_820CEEDC:
	// li r7,7
	ctx.r7.s64 = 7;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821149d8
	sub_821149D8(ctx, base);
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r11,r30
	r11.u64 = r30.u64;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// ble cr6,0x820cef24
	if (!cr6.getGT()) goto loc_820CEF24;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r9,r31,48
	ctx.r9.s64 = r31.s64 + 48;
loc_820CEF0C:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stbx r7,r9,r11
	PPC_STORE_U8(ctx.r9.u32 + r11.u32, ctx.r7.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// blt cr6,0x820cef0c
	if (cr6.getLT()) goto loc_820CEF0C;
loc_820CEF24:
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// li r10,255
	ctx.r10.s64 = 255;
	// stb r10,48(r11)
	PPC_STORE_U8(r11.u32 + 48, ctx.r10.u8);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820CEF38"))) PPC_WEAK_FUNC(sub_820CEF38);
PPC_FUNC_IMPL(__imp__sub_820CEF38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x823ed134
	// lis r31,-32013
	r31.s64 = -2098003968;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// lwz r5,-2304(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + -2304);
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
	// blt cr6,0x820cf00c
	if (cr6.getLT()) goto loc_820CF00C;
	// lis r30,-32013
	r30.s64 = -2098003968;
	// lis r28,-32013
	r28.s64 = -2098003968;
	// lwz r7,-2316(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + -2316);
loc_820CEF64:
	// lwz r9,-2308(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + -2308);
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r11,r11,r9
	r11.u64 = PPC_LOAD_U16(r11.u32 + ctx.r9.u32);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x820ceffc
	if (cr6.getLT()) goto loc_820CEFFC;
loc_820CEF7C:
	// rlwinm r29,r11,5,0,26
	r29.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// li r4,15
	ctx.r4.s64 = 15;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
loc_820CEF88:
	// lhzx r8,r6,r7
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r6.u32 + ctx.r7.u32);
	// extsh r9,r8
	ctx.r9.s64 = ctx.r8.s16;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// blt cr6,0x820cefd8
	if (cr6.getLT()) goto loc_820CEFD8;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x820cefc4
	if (!cr6.getLT()) goto loc_820CEFC4;
loc_820CEFA4:
	// lhz r27,0(r11)
	r27.u64 = PPC_LOAD_U16(r11.u32 + 0);
	// extsh r27,r27
	r27.s64 = r27.s16;
	// cmpw cr6,r27,r9
	cr6.compare<int32_t>(r27.s32, ctx.r9.s32, xer);
	// beq cr6,0x820cefc0
	if (cr6.getEQ()) goto loc_820CEFC0;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x820cefa4
	if (cr6.getLT()) goto loc_820CEFA4;
loc_820CEFC0:
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
loc_820CEFC4:
	// bne cr6,0x820cefd8
	if (!cr6.getEQ()) goto loc_820CEFD8;
	// sth r8,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r8.u16);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// lwz r5,-2304(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + -2304);
	// lwz r7,-2316(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + -2316);
loc_820CEFD8:
	// addi r4,r4,-1
	ctx.r4.s64 = ctx.r4.s64 + -1;
	// addi r6,r6,2
	ctx.r6.s64 = ctx.r6.s64 + 2;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// bne cr6,0x820cef88
	if (!cr6.getEQ()) goto loc_820CEF88;
	// add r11,r29,r7
	r11.u64 = r29.u64 + ctx.r7.u64;
	// lhz r11,30(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 30);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820cef7c
	if (!cr6.getLT()) goto loc_820CEF7C;
loc_820CEFFC:
	// addi r3,r3,4
	ctx.r3.s64 = ctx.r3.s64 + 4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820cef64
	if (!cr6.getLT()) goto loc_820CEF64;
loc_820CF00C:
	// li r11,-1
	r11.s64 = -1;
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// lwz r11,-2304(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -2304);
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// srawi r11,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	r11.s64 = r11.s32 >> 1;
	// stw r11,-2300(r10)
	PPC_STORE_U32(ctx.r10.u32 + -2300, r11.u32);
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820CF030"))) PPC_WEAK_FUNC(sub_820CF030);
PPC_FUNC_IMPL(__imp__sub_820CF030) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x823ed12c
	// lis r26,-32123
	r26.s64 = -2105212928;
	// li r28,0
	r28.s64 = 0;
	// lwz r6,32608(r26)
	ctx.r6.u64 = PPC_LOAD_U32(r26.u32 + 32608);
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// ble cr6,0x820cf198
	if (!cr6.getGT()) goto loc_820CF198;
	// lis r7,-32013
	ctx.r7.s64 = -2098003968;
	// li r29,0
	r29.s64 = 0;
	// lis r27,-32013
	r27.s64 = -2098003968;
	// li r31,-1
	r31.s64 = -1;
	// li r30,-2
	r30.s64 = -2;
	// lwz r11,-2316(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + -2316);
loc_820CF064:
	// lwz r10,-2308(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + -2308);
	// lhzx r10,r29,r10
	ctx.r10.u64 = PPC_LOAD_U16(r29.u32 + ctx.r10.u32);
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blt cr6,0x820cf188
	if (cr6.getLT()) goto loc_820CF188;
	// rlwinm r9,r10,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + r11.u64;
	// lhz r9,30(r9)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r9.u32 + 30);
	// extsh r8,r9
	ctx.r8.s64 = ctx.r9.s16;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// blt cr6,0x820cf188
	if (cr6.getLT()) goto loc_820CF188;
loc_820CF090:
	// rlwinm r4,r10,5,0,26
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// li r3,0
	ctx.r3.s64 = 0;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
loc_820CF09C:
	// lhzx r10,r5,r11
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r5.u32 + r11.u32);
	// cmplwi cr6,r10,32768
	cr6.compare<uint32_t>(ctx.r10.u32, 32768, xer);
	// blt cr6,0x820cf150
	if (cr6.getLT()) goto loc_820CF150;
	// rlwinm r6,r8,5,0,26
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// li r10,0
	ctx.r10.s64 = 0;
	// add r9,r6,r11
	ctx.r9.u64 = ctx.r6.u64 + r11.u64;
loc_820CF0B4:
	// lhz r25,0(r9)
	r25.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// cmplwi cr6,r25,32768
	cr6.compare<uint32_t>(r25.u32, 32768, xer);
	// blt cr6,0x820cf0d4
	if (cr6.getLT()) goto loc_820CF0D4;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,2
	ctx.r9.s64 = ctx.r9.s64 + 2;
	// cmpwi cr6,r10,15
	cr6.compare<int32_t>(ctx.r10.s32, 15, xer);
	// blt cr6,0x820cf0b4
	if (cr6.getLT()) goto loc_820CF0B4;
	// b 0x820cf11c
	goto loc_820CF11C;
loc_820CF0D4:
	// rlwinm r9,r8,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// cmpwi cr6,r10,15
	cr6.compare<int32_t>(ctx.r10.s32, 15, xer);
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// rlwinm r9,r9,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r25,r9,r11
	r25.u64 = PPC_LOAD_U16(ctx.r9.u32 + r11.u32);
	// sthx r25,r5,r11
	PPC_STORE_U16(ctx.r5.u32 + r11.u32, r25.u16);
	// lwz r11,-2316(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + -2316);
	// sthx r31,r9,r11
	PPC_STORE_U16(ctx.r9.u32 + r11.u32, r31.u16);
	// lwz r11,-2316(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + -2316);
	// bge cr6,0x820cf120
	if (!cr6.getLT()) goto loc_820CF120;
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + r11.u64;
loc_820CF100:
	// lhz r25,0(r9)
	r25.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// cmplwi cr6,r25,32768
	cr6.compare<uint32_t>(r25.u32, 32768, xer);
	// blt cr6,0x820cf11c
	if (cr6.getLT()) goto loc_820CF11C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r9,r9,2
	ctx.r9.s64 = ctx.r9.s64 + 2;
	// cmpwi cr6,r10,15
	cr6.compare<int32_t>(ctx.r10.s32, 15, xer);
	// blt cr6,0x820cf100
	if (cr6.getLT()) goto loc_820CF100;
loc_820CF11C:
	// cmpwi cr6,r10,15
	cr6.compare<int32_t>(ctx.r10.s32, 15, xer);
loc_820CF120:
	// bne cr6,0x820cf150
	if (!cr6.getEQ()) goto loc_820CF150;
	// sthx r30,r6,r11
	PPC_STORE_U16(ctx.r6.u32 + r11.u32, r30.u16);
	// addi r10,r4,30
	ctx.r10.s64 = ctx.r4.s64 + 30;
	// lwz r11,-2316(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + -2316);
	// add r9,r6,r11
	ctx.r9.u64 = ctx.r6.u64 + r11.u64;
	// lhz r9,30(r9)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r9.u32 + 30);
	// sthx r9,r10,r11
	PPC_STORE_U16(ctx.r10.u32 + r11.u32, ctx.r9.u16);
	// lwz r11,-2316(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + -2316);
	// lhzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + r11.u32);
	// extsh r8,r10
	ctx.r8.s64 = ctx.r10.s16;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// blt cr6,0x820cf184
	if (cr6.getLT()) goto loc_820CF184;
loc_820CF150:
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// cmpwi cr6,r3,15
	cr6.compare<int32_t>(ctx.r3.s32, 15, xer);
	// blt cr6,0x820cf09c
	if (cr6.getLT()) goto loc_820CF09C;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// blt cr6,0x820cf184
	if (cr6.getLT()) goto loc_820CF184;
	// rlwinm r9,r8,5,0,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 5) & 0xFFFFFFE0;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + r11.u64;
	// lhz r9,30(r9)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r9.u32 + 30);
	// extsh r8,r9
	ctx.r8.s64 = ctx.r9.s16;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bge cr6,0x820cf090
	if (!cr6.getLT()) goto loc_820CF090;
loc_820CF184:
	// lwz r6,32608(r26)
	ctx.r6.u64 = PPC_LOAD_U32(r26.u32 + 32608);
loc_820CF188:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r29,r29,2
	r29.s64 = r29.s64 + 2;
	// cmpw cr6,r28,r6
	cr6.compare<int32_t>(r28.s32, ctx.r6.s32, xer);
	// blt cr6,0x820cf064
	if (cr6.getLT()) goto loc_820CF064;
loc_820CF198:
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_820CF1A0"))) PPC_WEAK_FUNC(sub_820CF1A0);
PPC_FUNC_IMPL(__imp__sub_820CF1A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r11,908(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 908);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cf1c8
	if (cr6.getEQ()) goto loc_820CF1C8;
loc_820CF1B0:
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmpw cr6,r10,r3
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r3.s32, xer);
	// beq cr6,0x820cf1d0
	if (cr6.getEQ()) goto loc_820CF1D0;
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cf1b0
	if (!cr6.getEQ()) goto loc_820CF1B0;
loc_820CF1C8:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_820CF1D0:
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CF1D8"))) PPC_WEAK_FUNC(sub_820CF1D8);
PPC_FUNC_IMPL(__imp__sub_820CF1D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// li r5,0
	ctx.r5.s64 = 0;
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
	// addi r4,r10,-2296
	ctx.r4.s64 = ctx.r10.s64 + -2296;
	// lwz r11,908(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 908);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cf228
	if (cr6.getEQ()) goto loc_820CF228;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
loc_820CF200:
	// lbz r9,1(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// rlwinm r9,r9,0,29,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x6;
	// cmplwi cr6,r9,6
	cr6.compare<uint32_t>(ctx.r9.u32, 6, xer);
	// bne cr6,0x820cf21c
	if (!cr6.getEQ()) goto loc_820CF21C;
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
loc_820CF21C:
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cf200
	if (!cr6.getEQ()) goto loc_820CF200;
loc_820CF228:
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// rlwinm r11,r7,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// add r11,r11,r4
	r11.u64 = r11.u64 + ctx.r4.u64;
	// stw r7,-2312(r10)
	PPC_STORE_U32(ctx.r10.u32 + -2312, ctx.r7.u32);
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// stw r5,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r5.u32);
	// stw r11,-2320(r10)
	PPC_STORE_U32(ctx.r10.u32 + -2320, r11.u32);
	// ble cr6,0x820cf350
	if (!cr6.getGT()) goto loc_820CF350;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// mr r6,r4
	ctx.r6.u64 = ctx.r4.u64;
	// lfs f12,16228(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16228);
	ctx.f12.f64 = double(temp.f32);
loc_820CF25C:
	// li r9,-1
	ctx.r9.s64 = -1;
	// fmr f0,f12
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f12.f64;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// blt cr6,0x820cf2e8
	if (cr6.getLT()) goto loc_820CF2E8;
	// addi r8,r7,-3
	ctx.r8.s64 = ctx.r7.s64 + -3;
	// addi r10,r6,4
	ctx.r10.s64 = ctx.r6.s64 + 4;
loc_820CF278:
	// lwz r31,-4(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	// lfs f13,28(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820cf290
	if (!cr6.getGT()) goto loc_820CF290;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
loc_820CF290:
	// lwz r31,0(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lfs f13,28(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820cf2a8
	if (!cr6.getGT()) goto loc_820CF2A8;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
loc_820CF2A8:
	// lwz r31,4(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lfs f13,28(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820cf2c0
	if (!cr6.getGT()) goto loc_820CF2C0;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
	// addi r9,r11,2
	ctx.r9.s64 = r11.s64 + 2;
loc_820CF2C0:
	// lwz r31,8(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lfs f13,28(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820cf2d8
	if (!cr6.getGT()) goto loc_820CF2D8;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
	// addi r9,r11,3
	ctx.r9.s64 = r11.s64 + 3;
loc_820CF2D8:
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// blt cr6,0x820cf278
	if (cr6.getLT()) goto loc_820CF278;
loc_820CF2E8:
	// cmpw cr6,r11,r7
	cr6.compare<int32_t>(r11.s32, ctx.r7.s32, xer);
	// bge cr6,0x820cf320
	if (!cr6.getLT()) goto loc_820CF320;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
loc_820CF2F8:
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lfs f13,28(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820cf310
	if (!cr6.getGT()) goto loc_820CF310;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
loc_820CF310:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmpw cr6,r11,r7
	cr6.compare<int32_t>(r11.s32, ctx.r7.s32, xer);
	// blt cr6,0x820cf2f8
	if (cr6.getLT()) goto loc_820CF2F8;
loc_820CF320:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// blt cr6,0x820cf33c
	if (cr6.getLT()) goto loc_820CF33C;
	// rlwinm r11,r9,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,0(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// lwzx r9,r11,r4
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// stw r9,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r9.u32);
	// stwx r10,r11,r4
	PPC_STORE_U32(r11.u32 + ctx.r4.u32, ctx.r10.u32);
loc_820CF33C:
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r3,r3,-1
	ctx.r3.s64 = ctx.r3.s64 + -1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmpw cr6,r5,r7
	cr6.compare<int32_t>(ctx.r5.s32, ctx.r7.s32, xer);
	// blt cr6,0x820cf25c
	if (cr6.getLT()) goto loc_820CF25C;
loc_820CF350:
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CF358"))) PPC_WEAK_FUNC(sub_820CF358);
PPC_FUNC_IMPL(__imp__sub_820CF358) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,1
	cr6.compare<int32_t>(ctx.r4.s32, 1, xer);
	// bne cr6,0x820cf444
	if (!cr6.getEQ()) goto loc_820CF444;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x820cf388
	if (cr6.getEQ()) goto loc_820CF388;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x820cf3f8
	if (!cr6.getEQ()) goto loc_820CF3F8;
loc_820CF388:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820cf3f8
	if (cr6.getEQ()) goto loc_820CF3F8;
	// li r9,1200
	ctx.r9.s64 = 1200;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r9,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r9.u32);
	// lfs f0,2688(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2688);
	f0.f64 = double(temp.f32);
	// lwz r9,100(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 100);
	// li r10,1
	ctx.r10.s64 = 1;
	// lbz r8,2(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// stfs f0,112(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 112, temp.u32);
	// rlwimi r9,r10,11,29,29
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r10.u32, 11) & 0x4) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFFB);
	// clrlwi r8,r8,25
	ctx.r8.u64 = ctx.r8.u32 & 0x7F;
	// rlwimi r9,r10,11,20,20
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r10.u32, 11) & 0x800) | (ctx.r9.u64 & 0xFFFFFFFFFFFFF7FF);
	// stb r8,2(r11)
	PPC_STORE_U8(r11.u32 + 2, ctx.r8.u8);
	// stw r9,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r9.u32);
	// bl 0x820ced38
	sub_820CED38(ctx, base);
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// andi. r11,r11,251
	r11.u64 = r11.u64 & 251;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stb r11,1(r31)
	PPC_STORE_U8(r31.u32 + 1, r11.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_820CF3F8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ced38
	sub_820CED38(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ccbb0
	sub_820CCBB0(ctx, base);
	// lbz r10,1(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// li r11,0
	r11.s64 = 0;
	// andi. r10,r10,251
	ctx.r10.u64 = ctx.r10.u64 & 251;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stb r10,1(r31)
	PPC_STORE_U8(r31.u32 + 1, ctx.r10.u8);
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// lwz r9,916(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 916);
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// stw r9,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r9.u32);
	// stw r31,916(r10)
	PPC_STORE_U32(ctx.r10.u32 + 916, r31.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_820CF444:
	// cmpwi cr6,r4,2
	cr6.compare<int32_t>(ctx.r4.s32, 2, xer);
	// bne cr6,0x820cf47c
	if (!cr6.getEQ()) goto loc_820CF47C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ced38
	sub_820CED38(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ccbb0
	sub_820CCBB0(ctx, base);
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// andi. r11,r11,251
	r11.u64 = r11.u64 & 251;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stb r11,1(r31)
	PPC_STORE_U8(r31.u32 + 1, r11.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_820CF47C:
	// cmpwi cr6,r4,4
	cr6.compare<int32_t>(ctx.r4.s32, 4, xer);
	// bne cr6,0x820cf4dc
	if (!cr6.getEQ()) goto loc_820CF4DC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ced38
	sub_820CED38(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ccbb0
	sub_820CCBB0(ctx, base);
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// andi. r11,r11,251
	r11.u64 = r11.u64 & 251;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stb r11,1(r31)
	PPC_STORE_U8(r31.u32 + 1, r11.u8);
	// bl 0x820da578
	sub_820DA578(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d5430
	sub_820D5430(ctx, base);
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// stw r3,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r3.u32);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cf4c4
	if (cr6.getEQ()) goto loc_820CF4C4;
	// stw r31,44(r11)
	PPC_STORE_U32(r11.u32 + 44, r31.u32);
loc_820CF4C4:
	// lwz r10,36(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// li r11,0
	r11.s64 = 0;
	// stw r10,40(r31)
	PPC_STORE_U32(r31.u32 + 40, ctx.r10.u32);
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// stw r31,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r31.u32);
loc_820CF4DC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CF4F0"))) PPC_WEAK_FUNC(sub_820CF4F0);
PPC_FUNC_IMPL(__imp__sub_820CF4F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820cde10
	sub_820CDE10(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820cf568
	if (cr6.getEQ()) goto loc_820CF568;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x820cf530
	if (cr6.getEQ()) goto loc_820CF530;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x820cf55c
	if (cr6.getEQ()) goto loc_820CF55C;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bne cr6,0x820cf538
	if (!cr6.getEQ()) goto loc_820CF538;
loc_820CF530:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820e3df0
	sub_820E3DF0(ctx, base);
loc_820CF538:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cf358
	sub_820CF358(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_820CF55C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820e3240
	sub_820E3240(ctx, base);
	// b 0x820cf538
	goto loc_820CF538;
loc_820CF568:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CF580"))) PPC_WEAK_FUNC(sub_820CF580);
PPC_FUNC_IMPL(__imp__sub_820CF580) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed10c
	// stfd f29,-152(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -152, f29.u64);
	// stfd f30,-144(r1)
	PPC_STORE_U64(ctx.r1.u32 + -144, f30.u64);
	// stfd f31,-136(r1)
	PPC_STORE_U64(ctx.r1.u32 + -136, f31.u64);
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x82130240
	sub_82130240(ctx, base);
	// lis r17,-32013
	r17.s64 = -2098003968;
	// lwz r31,908(r17)
	r31.u64 = PPC_LOAD_U32(r17.u32 + 908);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820cfb9c
	if (cr6.getEQ()) goto loc_820CFB9C;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// addi r20,r11,-1384
	r20.s64 = r11.s64 + -1384;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r23,r11,16160
	r23.s64 = r11.s64 + 16160;
	// lfs f29,16140(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 16140);
	f29.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r24,-32013
	r24.s64 = -2098003968;
	// lfs f30,16144(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 16144);
	f30.f64 = double(temp.f32);
	// lis r21,-31994
	r21.s64 = -2096758784;
	// lfs f31,2688(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2688);
	f31.f64 = double(temp.f32);
	// lis r22,-31994
	r22.s64 = -2096758784;
	// addi r18,r11,16232
	r18.s64 = r11.s64 + 16232;
	// lis r19,-32014
	r19.s64 = -2098069504;
	// li r26,0
	r26.s64 = 0;
loc_820CF5F0:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// mr r25,r26
	r25.u64 = r26.u64;
	// lwz r30,40(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x820cf61c
	if (!cr6.getEQ()) goto loc_820CF61C;
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r3,r30,384
	ctx.r3.s64 = r30.s64 + 384;
	// bl 0x820a34c8
	sub_820A34C8(ctx, base);
	// addi r3,r30,428
	ctx.r3.s64 = r30.s64 + 428;
	// bl 0x820a34c8
	sub_820A34C8(ctx, base);
	// b 0x820cf650
	goto loc_820CF650;
loc_820CF61C:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820cf750
	if (cr6.getEQ()) goto loc_820CF750;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x820cf750
	if (cr6.getEQ()) goto loc_820CF750;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x820cf750
	if (cr6.getEQ()) goto loc_820CF750;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// bne cr6,0x820cf6d4
	if (!cr6.getEQ()) goto loc_820CF6D4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82142be0
	sub_82142BE0(ctx, base);
loc_820CF644:
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// cmpwi cr6,r25,5
	cr6.compare<int32_t>(r25.s32, 5, xer);
	// beq cr6,0x820cfb90
	if (cr6.getEQ()) goto loc_820CFB90;
loc_820CF650:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmpwi cr6,r25,3
	cr6.compare<int32_t>(r25.s32, 3, xer);
	// mr r30,r11
	r30.u64 = r11.u64;
	// bne cr6,0x820cfb84
	if (!cr6.getEQ()) goto loc_820CFB84;
	// lwz r10,908(r17)
	ctx.r10.u64 = PPC_LOAD_U32(r17.u32 + 908);
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// bne cr6,0x820cf670
	if (!cr6.getEQ()) goto loc_820CF670;
	// stw r11,908(r17)
	PPC_STORE_U32(r17.u32 + 908, r11.u32);
loc_820CF670:
	// lwz r11,912(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 912);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x820cf684
	if (!cr6.getEQ()) goto loc_820CF684;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r11,912(r24)
	PPC_STORE_U32(r24.u32 + 912, r11.u32);
loc_820CF684:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cf698
	if (cr6.getEQ()) goto loc_820CF698;
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r10,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r10.u32);
loc_820CF698:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cf6ac
	if (cr6.getEQ()) goto loc_820CF6AC;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// stw r10,40(r11)
	PPC_STORE_U32(r11.u32 + 40, ctx.r10.u32);
loc_820CF6AC:
	// stw r26,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r26.u32);
	// stw r26,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r26.u32);
	// lwz r11,912(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 912);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cfb64
	if (cr6.getEQ()) goto loc_820CFB64;
	// stw r31,40(r11)
	PPC_STORE_U32(r11.u32 + 40, r31.u32);
	// lwz r11,912(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 912);
	// stw r26,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r26.u32);
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// b 0x820cfb70
	goto loc_820CFB70;
loc_820CF6D4:
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bne cr6,0x820cf6e8
	if (!cr6.getEQ()) goto loc_820CF6E8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8213fab0
	sub_8213FAB0(ctx, base);
	// b 0x820cf644
	goto loc_820CF644;
loc_820CF6E8:
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820cf650
	if (!cr6.getEQ()) goto loc_820CF650;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820c9b90
	sub_820C9B90(ctx, base);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r20
	r11.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// addi r3,r11,2828
	ctx.r3.s64 = r11.s64 + 2828;
	// bl 0x820a34c8
	sub_820A34C8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820c9b90
	sub_820C9B90(ctx, base);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r20
	r11.u64 = PPC_LOAD_U32(r11.u32 + r20.u32);
	// addi r3,r11,3764
	ctx.r3.s64 = r11.s64 + 3764;
	// bl 0x820a34c8
	sub_820A34C8(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cf650
	if (cr6.getEQ()) goto loc_820CF650;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820cf650
	if (!cr6.getGT()) goto loc_820CF650;
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r3,r30,384
	ctx.r3.s64 = r30.s64 + 384;
	// bl 0x820a34c8
	sub_820A34C8(ctx, base);
	// addi r3,r30,428
	ctx.r3.s64 = r30.s64 + 428;
	// bl 0x820a34c8
	sub_820A34C8(ctx, base);
	// b 0x820cf650
	goto loc_820CF650;
loc_820CF750:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r27,r26
	r27.u64 = r26.u64;
	// lwz r28,8(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820cfb48
	if (!cr6.getGT()) goto loc_820CFB48;
	// li r30,1
	r30.s64 = 1;
	// cmpwi cr6,r11,60
	cr6.compare<int32_t>(r11.s32, 60, xer);
	// blt cr6,0x820cf774
	if (cr6.getLT()) goto loc_820CF774;
	// mr r30,r26
	r30.u64 = r26.u64;
loc_820CF774:
	// lwz r10,-6384(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + -6384);
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// cmpwi cr6,r11,60
	cr6.compare<int32_t>(r11.s32, 60, xer);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// bge cr6,0x820cf7c4
	if (!cr6.getLT()) goto loc_820CF7C4;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x820cf7c4
	if (!cr6.getEQ()) goto loc_820CF7C4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cdeb8
	sub_820CDEB8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820cf7c4
	if (!cr6.getEQ()) goto loc_820CF7C4;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,60
	cr6.compare<int32_t>(r11.s32, 60, xer);
	// bge cr6,0x820cf7c4
	if (!cr6.getLT()) goto loc_820CF7C4;
loc_820CF7AC:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r11,r11,60
	r11.s64 = r11.s64 + 60;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// cmpwi cr6,r11,60
	cr6.compare<int32_t>(r11.s32, 60, xer);
	// blt cr6,0x820cf7ac
	if (cr6.getLT()) goto loc_820CF7AC;
loc_820CF7C4:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x820cf800
	if (cr6.getGT()) goto loc_820CF800;
	// stw r26,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r26.u32);
	// lbz r11,2(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 2);
	// rlwinm r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r11,100(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 100);
	// beq cr6,0x820cf7f4
	if (cr6.getEQ()) goto loc_820CF7F4;
	// ori r11,r11,4096
	r11.u64 = r11.u64 | 4096;
	// stw r11,100(r28)
	PPC_STORE_U32(r28.u32 + 100, r11.u32);
	// b 0x820cfb48
	goto loc_820CFB48;
loc_820CF7F4:
	// rlwinm r11,r11,0,20,18
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFEFFF;
	// stw r11,100(r28)
	PPC_STORE_U32(r28.u32 + 100, r11.u32);
	// b 0x820cfb48
	goto loc_820CFB48;
loc_820CF800:
	// cmpwi cr6,r11,60
	cr6.compare<int32_t>(r11.s32, 60, xer);
	// bge cr6,0x820cfb48
	if (!cr6.getLT()) goto loc_820CFB48;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x820cfb48
	if (!cr6.getEQ()) goto loc_820CFB48;
	// lfs f0,112(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + 112);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x820cfa54
	if (!cr6.getEQ()) goto loc_820CFA54;
	// lbz r11,2(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 2);
	// rlwinm r11,r11,0,0,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cfa54
	if (!cr6.getEQ()) goto loc_820CFA54;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// rlwinm r11,r11,0,16,16
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cf8e4
	if (cr6.getEQ()) goto loc_820CF8E4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ced38
	sub_820CED38(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ccbb0
	sub_820CCBB0(ctx, base);
	// lwz r11,100(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 100);
	// rlwinm r11,r11,0,21,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFF7FF;
	// stw r11,100(r28)
	PPC_STORE_U32(r28.u32 + 100, r11.u32);
	// bl 0x820d0370
	sub_820D0370(ctx, base);
	// lhz r11,6(r28)
	r11.u64 = PPC_LOAD_U16(r28.u32 + 6);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// add r30,r11,r29
	r30.u64 = r11.u64 + r29.u64;
	// bl 0x8209ec18
	sub_8209EC18(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x820d0600
	sub_820D0600(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820cf8d4
	if (cr6.getEQ()) goto loc_820CF8D4;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cf8d4
	if (cr6.getEQ()) goto loc_820CF8D4;
	// lwz r3,20(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// lfs f1,20(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x823ada90
	sub_823ADA90(ctx, base);
	// lwz r10,16(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// stw r10,32(r11)
	PPC_STORE_U32(r11.u32 + 32, ctx.r10.u32);
	// lwz r9,36(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820cf8b8
	if (cr6.getEQ()) goto loc_820CF8B8;
	// stw r11,44(r9)
	PPC_STORE_U32(ctx.r9.u32 + 44, r11.u32);
loc_820CF8B8:
	// lwz r9,36(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 36);
	// li r27,1
	r27.s64 = 1;
	// stw r26,44(r11)
	PPC_STORE_U32(r11.u32 + 44, r26.u32);
	// stw r26,24(r11)
	PPC_STORE_U32(r11.u32 + 24, r26.u32);
	// stw r9,40(r11)
	PPC_STORE_U32(r11.u32 + 40, ctx.r9.u32);
	// stw r11,36(r10)
	PPC_STORE_U32(ctx.r10.u32 + 36, r11.u32);
	// b 0x820cfb08
	goto loc_820CFB08;
loc_820CF8D4:
	// addi r4,r29,1
	ctx.r4.s64 = r29.s64 + 1;
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// b 0x820cfb08
	goto loc_820CFB08;
loc_820CF8E4:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cf90c
	if (cr6.getEQ()) goto loc_820CF90C;
	// bl 0x8215fca8
	sub_8215FCA8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820cf90c
	if (!cr6.getEQ()) goto loc_820CF90C;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820cfb08
	if (!cr6.getLT()) goto loc_820CFB08;
loc_820CF90C:
	// lbz r11,3(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 3);
	// cmplwi cr6,r11,42
	cr6.compare<uint32_t>(r11.u32, 42, xer);
	// beq cr6,0x820cf9d0
	if (cr6.getEQ()) goto loc_820CF9D0;
	// cmplwi cr6,r11,47
	cr6.compare<uint32_t>(r11.u32, 47, xer);
	// beq cr6,0x820cf9d0
	if (cr6.getEQ()) goto loc_820CF9D0;
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bne cr6,0x820cf94c
	if (!cr6.getEQ()) goto loc_820CF94C;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lbz r11,128(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 128);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,88
	cr6.compare<int32_t>(r11.s32, 88, xer);
	// beq cr6,0x820cf948
	if (cr6.getEQ()) goto loc_820CF948;
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// bne cr6,0x820cf94c
	if (!cr6.getEQ()) goto loc_820CF94C;
loc_820CF948:
	// li r10,1
	ctx.r10.s64 = 1;
loc_820CF94C:
	// clrlwi r11,r10,24
	r11.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820cfb08
	if (!cr6.getEQ()) goto loc_820CFB08;
	// lbz r10,1(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// stb r10,1(r31)
	PPC_STORE_U8(r31.u32 + 1, ctx.r10.u8);
	// bne cr6,0x820cf97c
	if (!cr6.getEQ()) goto loc_820CF97C;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x8211e6f8
	sub_8211E6F8(ctx, base);
	// b 0x820cf994
	goto loc_820CF994;
loc_820CF97C:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820cf98c
	if (cr6.getEQ()) goto loc_820CF98C;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bne cr6,0x820cf994
	if (!cr6.getEQ()) goto loc_820CF994;
loc_820CF98C:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x820d0458
	sub_820D0458(ctx, base);
loc_820CF994:
	// lwz r11,100(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 100);
	// rlwinm r11,r11,0,21,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFF7FF;
	// stw r11,100(r28)
	PPC_STORE_U32(r28.u32 + 100, r11.u32);
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cfb08
	if (cr6.getEQ()) goto loc_820CFB08;
	// bl 0x8215fca8
	sub_8215FCA8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cfb08
	if (cr6.getEQ()) goto loc_820CFB08;
	// lwz r3,56(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x820cfb08
	if (cr6.getLT()) goto loc_820CFB08;
	// bl 0x8216bdb0
	sub_8216BDB0(ctx, base);
	// b 0x820cfb08
	goto loc_820CFB08;
loc_820CF9D0:
	// lbz r10,1(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// stb r10,1(r31)
	PPC_STORE_U8(r31.u32 + 1, ctx.r10.u8);
	// bne cr6,0x820cf9f4
	if (!cr6.getEQ()) goto loc_820CF9F4;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x8211e6f8
	sub_8211E6F8(ctx, base);
	// b 0x820cfa0c
	goto loc_820CFA0C;
loc_820CF9F4:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820cfa04
	if (cr6.getEQ()) goto loc_820CFA04;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bne cr6,0x820cfa0c
	if (!cr6.getEQ()) goto loc_820CFA0C;
loc_820CFA04:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x820d0458
	sub_820D0458(ctx, base);
loc_820CFA0C:
	// lwz r11,100(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 100);
	// rlwinm r11,r11,0,21,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFF7FF;
	// stw r11,100(r28)
	PPC_STORE_U32(r28.u32 + 100, r11.u32);
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cfa4c
	if (cr6.getEQ()) goto loc_820CFA4C;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cfa4c
	if (cr6.getEQ()) goto loc_820CFA4C;
	// bl 0x8215fca8
	sub_8215FCA8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820cfa4c
	if (!cr6.getEQ()) goto loc_820CFA4C;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820cfb08
	if (!cr6.getLT()) goto loc_820CFB08;
loc_820CFA4C:
	// lwz r30,56(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// b 0x820cfafc
	goto loc_820CFAFC;
loc_820CFA54:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cfa88
	if (cr6.getEQ()) goto loc_820CFA88;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cfa88
	if (cr6.getEQ()) goto loc_820CFA88;
	// bl 0x8215fca8
	sub_8215FCA8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820cfa88
	if (!cr6.getEQ()) goto loc_820CFA88;
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820cfb08
	if (!cr6.getLT()) goto loc_820CFB08;
loc_820CFA88:
	// lbz r11,2(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 2);
	// rlwinm r10,r11,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// beq cr6,0x820cfaa4
	if (cr6.getEQ()) goto loc_820CFAA4;
	// ori r10,r10,256
	ctx.r10.u64 = ctx.r10.u64 | 256;
	// b 0x820cfaa8
	goto loc_820CFAA8;
loc_820CFAA4:
	// rlwinm r10,r10,0,24,22
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFEFF;
loc_820CFAA8:
	// clrlwi r11,r11,25
	r11.u64 = r11.u32 & 0x7F;
	// lwz r3,20(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// stfs f31,112(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r28.u32 + 112, temp.u32);
	// stw r10,8(r28)
	PPC_STORE_U32(r28.u32 + 8, ctx.r10.u32);
	// stb r11,2(r28)
	PPC_STORE_U8(r28.u32 + 2, r11.u8);
	// bl 0x820dc5f0
	sub_820DC5F0(ctx, base);
	// stfs f30,68(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 68, temp.u32);
	// stfs f29,72(r31)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r31.u32 + 72, temp.u32);
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cfb08
	if (cr6.getEQ()) goto loc_820CFB08;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cfb08
	if (cr6.getEQ()) goto loc_820CFB08;
	// bl 0x8215fca8
	sub_8215FCA8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820cfb08
	if (cr6.getEQ()) goto loc_820CFB08;
	// lwz r30,56(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x820cfb08
	if (cr6.getLT()) goto loc_820CFB08;
loc_820CFAFC:
	// bl 0x82181e58
	sub_82181E58(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82182158
	sub_82182158(ctx, base);
loc_820CFB08:
	// lbz r11,3(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 3);
	// cmplwi cr6,r11,21
	cr6.compare<uint32_t>(r11.u32, 21, xer);
	// bne cr6,0x820cfb1c
	if (!cr6.getEQ()) goto loc_820CFB1C;
	// lfs f0,128(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + 128);
	f0.f64 = double(temp.f32);
	// stfs f0,132(r28)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r28.u32 + 132, temp.u32);
loc_820CFB1C:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x820cfb48
	if (!cr6.getEQ()) goto loc_820CFB48;
	// li r8,1557
	ctx.r8.s64 = 1557;
	// lwz r6,19944(r22)
	ctx.r6.u64 = PPC_LOAD_U32(r22.u32 + 19944);
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// lwz r3,19936(r21)
	ctx.r3.u64 = PPC_LOAD_U32(r21.u32 + 19936);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,82
	ctx.r4.s64 = 82;
	// bl 0x82144920
	sub_82144920(ctx, base);
	// addi r4,r31,12
	ctx.r4.s64 = r31.s64 + 12;
	// bl 0x820dd8d8
	sub_820DD8D8(ctx, base);
loc_820CFB48:
	// lbz r11,3(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 3);
	// cmplwi cr6,r11,13
	cr6.compare<uint32_t>(r11.u32, 13, xer);
	// bne cr6,0x820cf650
	if (!cr6.getEQ()) goto loc_820CF650;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r3,204(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 204);
	// bl 0x820a34c8
	sub_820A34C8(ctx, base);
	// b 0x820cf650
	goto loc_820CF650;
loc_820CFB64:
	// stw r26,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r26.u32);
	// stw r26,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r26.u32);
	// stw r31,908(r17)
	PPC_STORE_U32(r17.u32 + 908, r31.u32);
loc_820CFB70:
	// stw r31,912(r24)
	PPC_STORE_U32(r24.u32 + 912, r31.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x820cfb90
	if (!cr6.getEQ()) goto loc_820CFB90;
	// mr r30,r31
	r30.u64 = r31.u64;
	// b 0x820cfb90
	goto loc_820CFB90;
loc_820CFB84:
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cf358
	sub_820CF358(ctx, base);
loc_820CFB90:
	// mr r31,r30
	r31.u64 = r30.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x820cf5f0
	if (!cr6.getEQ()) goto loc_820CF5F0;
loc_820CFB9C:
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// lfd f29,-152(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -152);
	// lfd f30,-144(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -144);
	// lfd f31,-136(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -136);
	// b 0x823ed15c
	return;
}

__attribute__((alias("__imp__sub_820CFBB0"))) PPC_WEAK_FUNC(sub_820CFBB0);
PPC_FUNC_IMPL(__imp__sub_820CFBB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r27,-32013
	r27.s64 = -2098003968;
	// lwz r31,908(r27)
	r31.u64 = PPC_LOAD_U32(r27.u32 + 908);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820cfd14
	if (cr6.getEQ()) goto loc_820CFD14;
	// lis r29,-32013
	r29.s64 = -2098003968;
	// li r28,0
	r28.s64 = 0;
loc_820CFBD4:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r30,40(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x820cfbf4
	if (!cr6.getEQ()) goto loc_820CFBF4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8211e840
	sub_8211E840(ctx, base);
	// b 0x820cfc50
	goto loc_820CFC50;
loc_820CFBF4:
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820cfc48
	if (cr6.getEQ()) goto loc_820CFC48;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x820cfc48
	if (cr6.getEQ()) goto loc_820CFC48;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x820cfc48
	if (cr6.getEQ()) goto loc_820CFC48;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// bne cr6,0x820cfc20
	if (!cr6.getEQ()) goto loc_820CFC20;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8213ea30
	sub_8213EA30(ctx, base);
	// b 0x820cfc50
	goto loc_820CFC50;
loc_820CFC20:
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bne cr6,0x820cfc34
	if (!cr6.getEQ()) goto loc_820CFC34;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8213ea30
	sub_8213EA30(ctx, base);
	// b 0x820cfc50
	goto loc_820CFC50;
loc_820CFC34:
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820cfc58
	if (!cr6.getEQ()) goto loc_820CFC58;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820b4d48
	sub_820B4D48(ctx, base);
	// b 0x820cfc50
	goto loc_820CFC50;
loc_820CFC48:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820e4080
	sub_820E4080(ctx, base);
loc_820CFC50:
	// cmpwi cr6,r3,5
	cr6.compare<int32_t>(ctx.r3.s32, 5, xer);
	// beq cr6,0x820cfd08
	if (cr6.getEQ()) goto loc_820CFD08;
loc_820CFC58:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmpwi cr6,r3,3
	cr6.compare<int32_t>(ctx.r3.s32, 3, xer);
	// mr r30,r11
	r30.u64 = r11.u64;
	// bne cr6,0x820cfcfc
	if (!cr6.getEQ()) goto loc_820CFCFC;
	// lwz r10,908(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 908);
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// bne cr6,0x820cfc78
	if (!cr6.getEQ()) goto loc_820CFC78;
	// stw r11,908(r27)
	PPC_STORE_U32(r27.u32 + 908, r11.u32);
loc_820CFC78:
	// lwz r11,912(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 912);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bne cr6,0x820cfc8c
	if (!cr6.getEQ()) goto loc_820CFC8C;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r11,912(r29)
	PPC_STORE_U32(r29.u32 + 912, r11.u32);
loc_820CFC8C:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cfca0
	if (cr6.getEQ()) goto loc_820CFCA0;
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// stw r10,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r10.u32);
loc_820CFCA0:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cfcb4
	if (cr6.getEQ()) goto loc_820CFCB4;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// stw r10,40(r11)
	PPC_STORE_U32(r11.u32 + 40, ctx.r10.u32);
loc_820CFCB4:
	// stw r28,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r28.u32);
	// stw r28,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r28.u32);
	// lwz r11,912(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 912);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cfcdc
	if (cr6.getEQ()) goto loc_820CFCDC;
	// stw r31,40(r11)
	PPC_STORE_U32(r11.u32 + 40, r31.u32);
	// lwz r11,912(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 912);
	// stw r28,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r28.u32);
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// b 0x820cfce8
	goto loc_820CFCE8;
loc_820CFCDC:
	// stw r28,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r28.u32);
	// stw r28,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r28.u32);
	// stw r31,908(r27)
	PPC_STORE_U32(r27.u32 + 908, r31.u32);
loc_820CFCE8:
	// stw r31,912(r29)
	PPC_STORE_U32(r29.u32 + 912, r31.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x820cfd08
	if (!cr6.getEQ()) goto loc_820CFD08;
	// mr r30,r31
	r30.u64 = r31.u64;
	// b 0x820cfd08
	goto loc_820CFD08;
loc_820CFCFC:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cf358
	sub_820CF358(ctx, base);
loc_820CFD08:
	// mr r31,r30
	r31.u64 = r30.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x820cfbd4
	if (!cr6.getEQ()) goto loc_820CFBD4;
loc_820CFD14:
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// bl 0x820ca060
	sub_820CA060(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820cfd30
	if (!cr6.getEQ()) goto loc_820CFD30;
	// bl 0x820dfc68
	sub_820DFC68(ctx, base);
	// bl 0x823d22e0
	sub_823D22E0(ctx, base);
	// bl 0x820cf030
	sub_820CF030(ctx, base);
loc_820CFD30:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820CFD38"))) PPC_WEAK_FUNC(sub_820CFD38);
PPC_FUNC_IMPL(__imp__sub_820CFD38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820b1010
	sub_820B1010(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820cfddc
	if (!cr6.getEQ()) goto loc_820CFDDC;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1736(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1736);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820cfddc
	if (!cr6.getEQ()) goto loc_820CFDDC;
	// bl 0x820ca520
	sub_820CA520(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820cfddc
	if (cr6.getEQ()) goto loc_820CFDDC;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r31,908(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 908);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820cfddc
	if (cr6.getEQ()) goto loc_820CFDDC;
loc_820CFD88:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r3,0
	ctx.r3.s64 = 0;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x820cfdc0
	if (cr6.getGT()) goto loc_820CFDC0;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x820cfdb8
	if (cr6.getEQ()) goto loc_820CFDB8;
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bne cr6,0x820cfdc0
	if (!cr6.getEQ()) goto loc_820CFDC0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820e3008
	sub_820E3008(ctx, base);
	// b 0x820cfdc0
	goto loc_820CFDC0;
loc_820CFDB8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820e1e08
	sub_820E1E08(ctx, base);
loc_820CFDC0:
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lwz r30,40(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cf358
	sub_820CF358(ctx, base);
	// mr r31,r30
	r31.u64 = r30.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x820cfd88
	if (!cr6.getEQ()) goto loc_820CFD88;
loc_820CFDDC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820CFDF8"))) PPC_WEAK_FUNC(sub_820CFDF8);
PPC_FUNC_IMPL(__imp__sub_820CFDF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,1024
	ctx.r3.s64 = 1024;
	// bl 0x8209cbc8
	sub_8209CBC8(ctx, base);
	// lis r31,-32123
	r31.s64 = -2105212928;
	// lis r30,-32013
	r30.s64 = -2098003968;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r11,32608(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32608);
	// stw r3,-2304(r30)
	PPC_STORE_U32(r30.u32 + -2304, ctx.r3.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,15
	r11.s64 = r11.s64 + 15;
	// ori r11,r11,15
	r11.u64 = r11.u64 | 15;
	// xori r3,r11,15
	ctx.r3.u64 = r11.u64 ^ 15;
	// bl 0x8209cbc8
	sub_8209CBC8(ctx, base);
	// lis r29,-32013
	r29.s64 = -2098003968;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r3,-2308(r29)
	PPC_STORE_U32(r29.u32 + -2308, ctx.r3.u32);
	// li r3,8192
	ctx.r3.s64 = 8192;
	// bl 0x8209cbc8
	sub_8209CBC8(ctx, base);
	// lis r8,-32013
	ctx.r8.s64 = -2098003968;
	// lwz r10,-2304(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + -2304);
	// li r7,-1
	ctx.r7.s64 = -1;
	// li r11,0
	r11.s64 = 0;
	// stw r3,-2316(r8)
	PPC_STORE_U32(ctx.r8.u32 + -2316, ctx.r3.u32);
	// sth r7,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r7.u16);
	// lwz r10,32608(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32608);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// ble cr6,0x820cfe90
	if (!cr6.getGT()) goto loc_820CFE90;
	// li r10,0
	ctx.r10.s64 = 0;
loc_820CFE74:
	// lwz r9,-2308(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + -2308);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// sthx r7,r10,r9
	PPC_STORE_U16(ctx.r10.u32 + ctx.r9.u32, ctx.r7.u16);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// lwz r9,32608(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 32608);
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// blt cr6,0x820cfe74
	if (cr6.getLT()) goto loc_820CFE74;
loc_820CFE90:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-2
	ctx.r5.s64 = -2;
loc_820CFE98:
	// lwz r9,-2316(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2316);
	// addi r10,r6,2
	ctx.r10.s64 = ctx.r6.s64 + 2;
	// li r11,15
	r11.s64 = 15;
	// sthx r5,r6,r9
	PPC_STORE_U16(ctx.r6.u32 + ctx.r9.u32, ctx.r5.u16);
loc_820CFEA8:
	// lwz r9,-2316(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + -2316);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// sthx r7,r10,r9
	PPC_STORE_U16(ctx.r10.u32 + ctx.r9.u32, ctx.r7.u16);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// bne cr6,0x820cfea8
	if (!cr6.getEQ()) goto loc_820CFEA8;
	// addi r6,r6,32
	ctx.r6.s64 = ctx.r6.s64 + 32;
	// cmpwi cr6,r6,8192
	cr6.compare<int32_t>(ctx.r6.s32, 8192, xer);
	// blt cr6,0x820cfe98
	if (cr6.getLT()) goto loc_820CFE98;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820CFED8"))) PPC_WEAK_FUNC(sub_820CFED8);
PPC_FUNC_IMPL(__imp__sub_820CFED8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// li r9,0
	ctx.r9.s64 = 0;
	// lis r8,-32013
	ctx.r8.s64 = -2098003968;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f0,2776(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	f0.f64 = double(temp.f32);
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// addi r11,r11,-784
	r11.s64 = r11.s64 + -784;
	// stw r9,912(r8)
	PPC_STORE_U32(ctx.r8.u32 + 912, ctx.r9.u32);
	// lis r8,-32013
	ctx.r8.s64 = -2098003968;
	// stfs f0,19388(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 19388, temp.u32);
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// stw r9,908(r8)
	PPC_STORE_U32(ctx.r8.u32 + 908, ctx.r9.u32);
	// addi r10,r10,-2296
	ctx.r10.s64 = ctx.r10.s64 + -2296;
	// lis r8,-32013
	ctx.r8.s64 = -2098003968;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r9,-2312(r8)
	PPC_STORE_U32(ctx.r8.u32 + -2312, ctx.r9.u32);
	// lis r9,-32013
	ctx.r9.s64 = -2098003968;
	// stw r10,-2320(r9)
	PPC_STORE_U32(ctx.r9.u32 + -2320, ctx.r10.u32);
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// stw r11,916(r10)
	PPC_STORE_U32(ctx.r10.u32 + 916, r11.u32);
	// addi r10,r11,40
	ctx.r10.s64 = r11.s64 + 40;
loc_820CFF2C:
	// addi r9,r10,40
	ctx.r9.s64 = ctx.r10.s64 + 40;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addis r9,r11,1
	ctx.r9.s64 = r11.s64 + 65536;
	// addi r10,r10,80
	ctx.r10.s64 = ctx.r10.s64 + 80;
	// addi r9,r9,-1576
	ctx.r9.s64 = ctx.r9.s64 + -1576;
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// blt cr6,0x820cff2c
	if (cr6.getLT()) goto loc_820CFF2C;
	// b 0x820cfdf8
	sub_820CFDF8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820CFF50"))) PPC_WEAK_FUNC(sub_820CFF50);
PPC_FUNC_IMPL(__imp__sub_820CFF50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// fmr f3,f1
	ctx.fpscr.disableFlushMode();
	ctx.f3.f64 = ctx.f1.f64;
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r6)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// lfs f0,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,4(r6)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 4, temp.u32);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r6)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 8, temp.u32);
	// stw r4,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r4.u32);
	// bne cr6,0x820cffac
	if (!cr6.getEQ()) goto loc_820CFFAC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r11,16308
	ctx.r3.s64 = r11.s64 + 16308;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820CFFAC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f4,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f4.f64 = double(temp.f32);
	// fcmpu cr6,f3,f4
	cr6.compare(ctx.f3.f64, ctx.f4.f64);
	// ble cr6,0x820cfffc
	if (!cr6.getGT()) goto loc_820CFFFC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f2,8(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// li r7,31
	ctx.r7.s64 = 31;
	// lfs f1,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lfs f5,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f5.f64 = double(temp.f32);
	// bl 0x821126c0
	sub_821126C0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x820cfffc
	if (cr6.getLT()) goto loc_820CFFFC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r11,16276
	ctx.r3.s64 = r11.s64 + 16276;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820CFFFC:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D0010"))) PPC_WEAK_FUNC(sub_820D0010);
PPC_FUNC_IMPL(__imp__sub_820D0010) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r4,3(r3)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r3.u32 + 3);
	// addi r11,r4,-1
	r11.s64 = ctx.r4.s64 + -1;
	// cmplwi cr6,r11,46
	cr6.compare<uint32_t>(r11.u32, 46, xer);
	// bgt cr6,0x820d0268
	if (cr6.getGT()) goto loc_820D0268;
	// lis r12,-32243
	r12.s64 = -2113077248;
	// addi r12,r12,68
	r12.s64 = r12.s64 + 68;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820D0114;
	case 1:
		goto loc_820D0128;
	case 2:
		goto loc_820D013C;
	case 3:
		goto loc_820D0164;
	case 4:
		goto loc_820D013C;
	case 5:
		goto loc_820D0178;
	case 6:
		goto loc_820D0164;
	case 7:
		goto loc_820D018C;
	case 8:
		goto loc_820D0100;
	case 9:
		goto loc_820D01A0;
	case 10:
		goto loc_820D01B4;
	case 11:
		goto loc_820D013C;
	case 12:
		goto loc_820D01C8;
	case 13:
		goto loc_820D01DC;
	case 14:
		goto loc_820D0268;
	case 15:
		goto loc_820D0268;
	case 16:
		goto loc_820D013C;
	case 17:
		goto loc_820D01DC;
	case 18:
		goto loc_820D01F0;
	case 19:
		goto loc_820D0218;
	case 20:
		goto loc_820D022C;
	case 21:
		goto loc_820D01F0;
	case 22:
		goto loc_820D01F0;
	case 23:
		goto loc_820D0274;
	case 24:
		goto loc_820D0128;
	case 25:
		goto loc_820D0128;
	case 26:
		goto loc_820D0128;
	case 27:
		goto loc_820D0128;
	case 28:
		goto loc_820D0128;
	case 29:
		goto loc_820D01F0;
	case 30:
		goto loc_820D0274;
	case 31:
		goto loc_820D01F0;
	case 32:
		goto loc_820D0204;
	case 33:
		goto loc_820D0274;
	case 34:
		goto loc_820D01F0;
	case 35:
		goto loc_820D013C;
	case 36:
		goto loc_820D0240;
	case 37:
		goto loc_820D01F0;
	case 38:
		goto loc_820D0178;
	case 39:
		goto loc_820D0218;
	case 40:
		goto loc_820D0268;
	case 41:
		goto loc_820D013C;
	case 42:
		goto loc_820D013C;
	case 43:
		goto loc_820D0204;
	case 44:
		goto loc_820D0254;
	case 45:
		goto loc_820D0100;
	case 46:
		goto loc_820D0150;
	default:
		__builtin_unreachable();
	}
	// lwz r16,276(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 276);
	// lwz r16,296(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 296);
	// lwz r16,316(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 316);
	// lwz r16,356(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 356);
	// lwz r16,316(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 316);
	// lwz r16,376(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 376);
	// lwz r16,356(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 356);
	// lwz r16,396(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 396);
	// lwz r16,256(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 256);
	// lwz r16,416(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 416);
	// lwz r16,436(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 436);
	// lwz r16,316(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 316);
	// lwz r16,456(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 456);
	// lwz r16,476(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 476);
	// lwz r16,616(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 616);
	// lwz r16,616(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 616);
	// lwz r16,316(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 316);
	// lwz r16,476(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 476);
	// lwz r16,496(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 496);
	// lwz r16,536(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 536);
	// lwz r16,556(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 556);
	// lwz r16,496(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 496);
	// lwz r16,496(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 496);
	// lwz r16,628(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 628);
	// lwz r16,296(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 296);
	// lwz r16,296(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 296);
	// lwz r16,296(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 296);
	// lwz r16,296(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 296);
	// lwz r16,296(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 296);
	// lwz r16,496(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 496);
	// lwz r16,628(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 628);
	// lwz r16,496(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 496);
	// lwz r16,516(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 516);
	// lwz r16,628(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 628);
	// lwz r16,496(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 496);
	// lwz r16,316(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 316);
	// lwz r16,576(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 576);
	// lwz r16,496(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 496);
	// lwz r16,376(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 376);
	// lwz r16,536(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 536);
	// lwz r16,616(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 616);
	// lwz r16,316(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 316);
	// lwz r16,316(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 316);
	// lwz r16,516(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 516);
	// lwz r16,596(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 596);
	// lwz r16,256(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 256);
	// lwz r16,336(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 336);
loc_820D0100:
	// li r3,7
	ctx.r3.s64 = 7;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D0114:
	// li r3,63
	ctx.r3.s64 = 63;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D0128:
	// li r3,2
	ctx.r3.s64 = 2;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D013C:
	// li r3,32
	ctx.r3.s64 = 32;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D0150:
	// li r3,37
	ctx.r3.s64 = 37;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D0164:
	// li r3,33
	ctx.r3.s64 = 33;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D0178:
	// li r3,59
	ctx.r3.s64 = 59;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D018C:
	// li r3,35
	ctx.r3.s64 = 35;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D01A0:
	// li r3,64
	ctx.r3.s64 = 64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D01B4:
	// li r3,149
	ctx.r3.s64 = 149;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D01C8:
	// li r3,54
	ctx.r3.s64 = 54;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D01DC:
	// li r3,3
	ctx.r3.s64 = 3;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D01F0:
	// li r3,4
	ctx.r3.s64 = 4;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D0204:
	// li r3,5
	ctx.r3.s64 = 5;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D0218:
	// li r3,45
	ctx.r3.s64 = 45;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D022C:
	// li r3,34
	ctx.r3.s64 = 34;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D0240:
	// li r3,10
	ctx.r3.s64 = 10;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D0254:
	// li r3,56
	ctx.r3.s64 = 56;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820D0268:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r11,16332
	ctx.r3.s64 = r11.s64 + 16332;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
loc_820D0274:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D0288"))) PPC_WEAK_FUNC(sub_820D0288);
PPC_FUNC_IMPL(__imp__sub_820D0288) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// lwz r31,12(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// blt cr6,0x820d02ec
	if (cr6.getLT()) goto loc_820D02EC;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820d02ec
	if (cr6.getEQ()) goto loc_820D02EC;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// beq cr6,0x820d02ec
	if (cr6.getEQ()) goto loc_820D02EC;
loc_820D02C4:
	// cmpw cr6,r30,r29
	cr6.compare<int32_t>(r30.s32, r29.s32, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq cr6,0x820d02f0
	if (cr6.getEQ()) goto loc_820D02F0;
	// bl 0x820d0010
	sub_820D0010(ctx, base);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// add r31,r11,r31
	r31.u64 = r11.u64 + r31.u64;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// bne cr6,0x820d02c4
	if (!cr6.getEQ()) goto loc_820D02C4;
loc_820D02EC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_820D02F0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820D02F8"))) PPC_WEAK_FUNC(sub_820D02F8);
PPC_FUNC_IMPL(__imp__sub_820D02F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// lwz r31,12(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820d0354
	if (cr6.getEQ()) goto loc_820D0354;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// beq cr6,0x820d0354
	if (cr6.getEQ()) goto loc_820D0354;
loc_820D032C:
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// beq cr6,0x820d0360
	if (cr6.getEQ()) goto loc_820D0360;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d0010
	sub_820D0010(ctx, base);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// add r31,r11,r31
	r31.u64 = r11.u64 + r31.u64;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// bne cr6,0x820d032c
	if (!cr6.getEQ()) goto loc_820D032C;
loc_820D0354:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
loc_820D0360:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820D0370"))) PPC_WEAK_FUNC(sub_820D0370);
PPC_FUNC_IMPL(__imp__sub_820D0370) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// lwz r31,12(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820d03d0
	if (cr6.getEQ()) goto loc_820D03D0;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// beq cr6,0x820d03d0
	if (cr6.getEQ()) goto loc_820D03D0;
loc_820D03A4:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// beq cr6,0x820d03dc
	if (cr6.getEQ()) goto loc_820D03DC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d0010
	sub_820D0010(ctx, base);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// add r31,r11,r31
	r31.u64 = r11.u64 + r31.u64;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// bne cr6,0x820d03a4
	if (!cr6.getEQ()) goto loc_820D03A4;
loc_820D03D0:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
loc_820D03DC:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820D03E8"))) PPC_WEAK_FUNC(sub_820D03E8);
PPC_FUNC_IMPL(__imp__sub_820D03E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32164
	r11.s64 = -2107899904;
	// rlwinm r31,r3,4,0,27
	r31.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r30,r11,-3616
	r30.s64 = r11.s64 + -3616;
	// addi r29,r30,12
	r29.s64 = r30.s64 + 12;
	// lbzx r11,r31,r29
	r11.u64 = PPC_LOAD_U8(r31.u32 + r29.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d044c
	if (!cr6.getEQ()) goto loc_820D044C;
	// lwzx r3,r31,r30
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + r30.u32);
	// addi r10,r30,4
	ctx.r10.s64 = r30.s64 + 4;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r5,r11,16376
	ctx.r5.s64 = r11.s64 + 16376;
	// lwzx r4,r31,r10
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + ctx.r10.u32);
	// lwz r7,0(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r6,8(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// bl 0x8211db38
	sub_8211DB38(ctx, base);
	// lwzx r3,r31,r30
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + r30.u32);
	// bl 0x8211c6c8
	sub_8211C6C8(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// stbx r11,r31,r29
	PPC_STORE_U8(r31.u32 + r29.u32, r11.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
loc_820D044C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820D0458"))) PPC_WEAK_FUNC(sub_820D0458);
PPC_FUNC_IMPL(__imp__sub_820D0458) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stfd f30,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, f30.u64);
	// stfd f31,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r28,16(r29)
	r28.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lfs f31,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x820ced38
	sub_820CED38(ctx, base);
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// rlwinm r11,r11,0,14,14
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d04c0
	if (cr6.getEQ()) goto loc_820D04C0;
	// lwz r11,24(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d04b4
	if (cr6.getEQ()) goto loc_820D04B4;
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// li r10,255
	ctx.r10.s64 = 255;
	// stb r11,48(r28)
	PPC_STORE_U8(r28.u32 + 48, r11.u8);
	// stb r10,49(r28)
	PPC_STORE_U8(r28.u32 + 49, ctx.r10.u8);
	// b 0x820d05e4
	goto loc_820D05E4;
loc_820D04B4:
	// li r11,255
	r11.s64 = 255;
	// stb r11,48(r28)
	PPC_STORE_U8(r28.u32 + 48, r11.u8);
	// b 0x820d05e4
	goto loc_820D05E4;
loc_820D04C0:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820d4ac0
	sub_820D4AC0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820d05e4
	if (cr6.getEQ()) goto loc_820D05E4;
	// addi r31,r29,24
	r31.s64 = r29.s64 + 24;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x820d3978
	sub_820D3978(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lfs f30,3112(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3112);
	f30.f64 = double(temp.f32);
	// fsubs f0,f1,f30
	f0.f64 = double(float(ctx.f1.f64 - f30.f64));
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// bl 0x820d3a48
	sub_820D3A48(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stfs f1,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// bl 0x820d3b18
	sub_820D3B18(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// fsubs f0,f1,f30
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 - f30.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// bl 0x820d39e0
	sub_820D39E0(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// fadds f0,f1,f30
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 + f30.f64));
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// bl 0x820d3ab0
	sub_820D3AB0(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stfs f1,100(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// bl 0x820d3b80
	sub_820D3B80(ctx, base);
	// lfs f8,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f8.f64 = double(temp.f32);
	// fneg f0,f8
	f0.u64 = ctx.f8.u64 ^ 0x8000000000000000;
	// fadds f10,f1,f30
	ctx.f10.f64 = double(float(ctx.f1.f64 + f30.f64));
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x820d055c
	if (!cr6.getGT()) goto loc_820D055C;
	// fmr f31,f0
	f31.f64 = f0.f64;
loc_820D055C:
	// lfs f9,88(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f9.f64 = double(temp.f32);
	// fneg f0,f9
	f0.u64 = ctx.f9.u64 ^ 0x8000000000000000;
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x820d0570
	if (!cr6.getGT()) goto loc_820D0570;
	// fmr f31,f0
	f31.f64 = f0.f64;
loc_820D0570:
	// lfs f11,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f11.f64 = double(temp.f32);
	// fcmpu cr6,f11,f31
	cr6.compare(ctx.f11.f64, f31.f64);
	// ble cr6,0x820d0580
	if (!cr6.getGT()) goto loc_820D0580;
	// fmr f31,f11
	f31.f64 = ctx.f11.f64;
loc_820D0580:
	// fcmpu cr6,f10,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f10.f64, f31.f64);
	// ble cr6,0x820d058c
	if (!cr6.getGT()) goto loc_820D058C;
	// fmr f31,f10
	f31.f64 = ctx.f10.f64;
loc_820D058C:
	// lfs f0,88(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 88);
	f0.f64 = double(temp.f32);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// fadds f8,f0,f8
	ctx.f8.f64 = double(float(f0.f64 + ctx.f8.f64));
	// lfs f13,92(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f11
	f0.f64 = double(float(f0.f64 + ctx.f11.f64));
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	f0.f64 = double(temp.f32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stfs f8,80(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// lfs f12,96(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lfs f8,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f8.f64 = double(temp.f32);
	// fadds f9,f12,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 + ctx.f9.f64));
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fadds f8,f13,f8
	ctx.f8.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// fadds f0,f12,f10
	f0.f64 = double(float(ctx.f12.f64 + ctx.f10.f64));
	// stfs f8,84(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f9,88(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// bl 0x820cedf8
	sub_820CEDF8(ctx, base);
loc_820D05E4:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x820ced98
	sub_820CED98(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f30,-56(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820D0600"))) PPC_WEAK_FUNC(sub_820D0600);
PPC_FUNC_IMPL(__imp__sub_820D0600) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// bl 0x820d0288
	sub_820D0288(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d0704
	if (cr6.getEQ()) goto loc_820D0704;
	// lbz r11,3(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 3);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplwi cr6,r11,46
	cr6.compare<uint32_t>(r11.u32, 46, xer);
	// bgt cr6,0x820d0704
	if (cr6.getGT()) goto loc_820D0704;
	// lis r12,-32243
	r12.s64 = -2113077248;
	// addi r12,r12,1604
	r12.s64 = r12.s64 + 1604;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820D0704;
	case 1:
		goto loc_820D0700;
	case 2:
		goto loc_820D0704;
	case 3:
		goto loc_820D0704;
	case 4:
		goto loc_820D0704;
	case 5:
		goto loc_820D0704;
	case 6:
		goto loc_820D0704;
	case 7:
		goto loc_820D0704;
	case 8:
		goto loc_820D0700;
	case 9:
		goto loc_820D0704;
	case 10:
		goto loc_820D0704;
	case 11:
		goto loc_820D0704;
	case 12:
		goto loc_820D0704;
	case 13:
		goto loc_820D0700;
	case 14:
		goto loc_820D0704;
	case 15:
		goto loc_820D0704;
	case 16:
		goto loc_820D0704;
	case 17:
		goto loc_820D0700;
	case 18:
		goto loc_820D0700;
	case 19:
		goto loc_820D0704;
	case 20:
		goto loc_820D0704;
	case 21:
		goto loc_820D0700;
	case 22:
		goto loc_820D0700;
	case 23:
		goto loc_820D0700;
	case 24:
		goto loc_820D0700;
	case 25:
		goto loc_820D0700;
	case 26:
		goto loc_820D0700;
	case 27:
		goto loc_820D0700;
	case 28:
		goto loc_820D0700;
	case 29:
		goto loc_820D0700;
	case 30:
		goto loc_820D0700;
	case 31:
		goto loc_820D0700;
	case 32:
		goto loc_820D0700;
	case 33:
		goto loc_820D0700;
	case 34:
		goto loc_820D0700;
	case 35:
		goto loc_820D0704;
	case 36:
		goto loc_820D0700;
	case 37:
		goto loc_820D0700;
	case 38:
		goto loc_820D0704;
	case 39:
		goto loc_820D0704;
	case 40:
		goto loc_820D0704;
	case 41:
		goto loc_820D0704;
	case 42:
		goto loc_820D0704;
	case 43:
		goto loc_820D0700;
	case 44:
		goto loc_820D0704;
	case 45:
		goto loc_820D0700;
	case 46:
		goto loc_820D0704;
	default:
		__builtin_unreachable();
	}
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
	// lwz r16,1792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1792);
	// lwz r16,1796(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 1796);
loc_820D0700:
	// li r3,0
	ctx.r3.s64 = 0;
loc_820D0704:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D0718"))) PPC_WEAK_FUNC(sub_820D0718);
PPC_FUNC_IMPL(__imp__sub_820D0718) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed120
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r24,r5
	r24.u64 = ctx.r5.u64;
	// mr r23,r6
	r23.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// lwz r31,12(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r26,r8
	r26.u64 = ctx.r8.u64;
	// li r29,0
	r29.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820d0830
	if (cr6.getEQ()) goto loc_820D0830;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// beq cr6,0x820d0830
	if (cr6.getEQ()) goto loc_820D0830;
	// clrlwi r22,r28,24
	r22.u64 = r28.u32 & 0xFF;
loc_820D0768:
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// bne cr6,0x820d0814
	if (!cr6.getEQ()) goto loc_820D0814;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d0798
	if (!cr6.getEQ()) goto loc_820D0798;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x820d0814
	if (!cr6.getEQ()) goto loc_820D0814;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x820d0814
	if (!cr6.getEQ()) goto loc_820D0814;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed170
	return;
loc_820D0798:
	// cmplwi cr6,r28,8
	cr6.compare<uint32_t>(r28.u32, 8, xer);
	// beq cr6,0x820d0814
	if (cr6.getEQ()) goto loc_820D0814;
	// lwz r10,100(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r10,r10,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820d0814
	if (!cr6.getEQ()) goto loc_820D0814;
	// lbz r10,2(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820d0814
	if (!cr6.getEQ()) goto loc_820D0814;
	// lwz r11,32(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d0814
	if (!cr6.getEQ()) goto loc_820D0814;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x820d07e8
	if (cr6.getEQ()) goto loc_820D07E8;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// bl 0x82118510
	sub_82118510(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d0814
	if (cr6.getEQ()) goto loc_820D0814;
loc_820D07E8:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x820d0808
	if (!cr6.getEQ()) goto loc_820D0808;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lbz r11,1(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d0808
	if (!cr6.getEQ()) goto loc_820D0808;
	// mr r29,r31
	r29.u64 = r31.u64;
loc_820D0808:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x820d0814
	if (!cr6.getEQ()) goto loc_820D0814;
	// mr r30,r31
	r30.u64 = r31.u64;
loc_820D0814:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d0010
	sub_820D0010(ctx, base);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// add r31,r11,r31
	r31.u64 = r11.u64 + r31.u64;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// bne cr6,0x820d0768
	if (!cr6.getEQ()) goto loc_820D0768;
loc_820D0830:
	// stw r29,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r29.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r30,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r30.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed170
	return;
}

__attribute__((alias("__imp__sub_820D0848"))) PPC_WEAK_FUNC(sub_820D0848);
PPC_FUNC_IMPL(__imp__sub_820D0848) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// lwz r31,12(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820d0980
	if (cr6.getEQ()) goto loc_820D0980;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// beq cr6,0x820d0980
	if (cr6.getEQ()) goto loc_820D0980;
loc_820D0878:
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplwi cr6,r11,46
	cr6.compare<uint32_t>(r11.u32, 46, xer);
	// bgt cr6,0x820d0964
	if (cr6.getGT()) goto loc_820D0964;
	// lis r12,-32243
	r12.s64 = -2113077248;
	// addi r12,r12,2204
	r12.s64 = r12.s64 + 2204;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820D0958;
	case 1:
		goto loc_820D0964;
	case 2:
		goto loc_820D0958;
	case 3:
		goto loc_820D0958;
	case 4:
		goto loc_820D0958;
	case 5:
		goto loc_820D0958;
	case 6:
		goto loc_820D0958;
	case 7:
		goto loc_820D0958;
	case 8:
		goto loc_820D0964;
	case 9:
		goto loc_820D0958;
	case 10:
		goto loc_820D0958;
	case 11:
		goto loc_820D0958;
	case 12:
		goto loc_820D0958;
	case 13:
		goto loc_820D0964;
	case 14:
		goto loc_820D0964;
	case 15:
		goto loc_820D0964;
	case 16:
		goto loc_820D0958;
	case 17:
		goto loc_820D0964;
	case 18:
		goto loc_820D0964;
	case 19:
		goto loc_820D0958;
	case 20:
		goto loc_820D0958;
	case 21:
		goto loc_820D0964;
	case 22:
		goto loc_820D0964;
	case 23:
		goto loc_820D0964;
	case 24:
		goto loc_820D0964;
	case 25:
		goto loc_820D0964;
	case 26:
		goto loc_820D0964;
	case 27:
		goto loc_820D0964;
	case 28:
		goto loc_820D0964;
	case 29:
		goto loc_820D0964;
	case 30:
		goto loc_820D0964;
	case 31:
		goto loc_820D0964;
	case 32:
		goto loc_820D0964;
	case 33:
		goto loc_820D0964;
	case 34:
		goto loc_820D0964;
	case 35:
		goto loc_820D0958;
	case 36:
		goto loc_820D0964;
	case 37:
		goto loc_820D0964;
	case 38:
		goto loc_820D0958;
	case 39:
		goto loc_820D0958;
	case 40:
		goto loc_820D0958;
	case 41:
		goto loc_820D0958;
	case 42:
		goto loc_820D0958;
	case 43:
		goto loc_820D0964;
	case 44:
		goto loc_820D0958;
	case 45:
		goto loc_820D0964;
	case 46:
		goto loc_820D0958;
	default:
		__builtin_unreachable();
	}
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
	// lwz r16,2404(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2404);
	// lwz r16,2392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 2392);
loc_820D0958:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820e0358
	sub_820E0358(ctx, base);
loc_820D0964:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d0010
	sub_820D0010(ctx, base);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// add r31,r11,r31
	r31.u64 = r11.u64 + r31.u64;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// bne cr6,0x820d0878
	if (!cr6.getEQ()) goto loc_820D0878;
loc_820D0980:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D0998"))) PPC_WEAK_FUNC(sub_820D0998);
PPC_FUNC_IMPL(__imp__sub_820D0998) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// li r30,0
	r30.s64 = 0;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// lwz r31,12(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820d09f4
	if (cr6.getEQ()) goto loc_820D09F4;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// beq cr6,0x820d09f4
	if (cr6.getEQ()) goto loc_820D09F4;
	// clrlwi r29,r3,24
	r29.u64 = ctx.r3.u32 & 0xFF;
loc_820D09CC:
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// bne cr6,0x820d09d8
	if (!cr6.getEQ()) goto loc_820D09D8;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
loc_820D09D8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d0010
	sub_820D0010(ctx, base);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// add r31,r11,r31
	r31.u64 = r11.u64 + r31.u64;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// bne cr6,0x820d09cc
	if (!cr6.getEQ()) goto loc_820D09CC;
loc_820D09F4:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820D0A00"))) PPC_WEAK_FUNC(sub_820D0A00);
PPC_FUNC_IMPL(__imp__sub_820D0A00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// addi r12,r1,-8
	r12.s64 = ctx.r1.s64 + -8;
	// bl 0x823ed544
	// lfs f5,12(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f5.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f8,32(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	ctx.f8.f64 = double(temp.f32);
	// fmr f31,f5
	f31.f64 = ctx.f5.f64;
	// fmuls f29,f5,f8
	f29.f64 = double(float(ctx.f5.f64 * ctx.f8.f64));
	// lfs f9,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// lfs f6,24(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f27,f10,f9
	f27.f64 = double(float(ctx.f10.f64 * ctx.f9.f64));
	// lfs f13,60(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 60);
	ctx.f13.f64 = double(temp.f32);
	// fmr f1,f6
	ctx.f1.f64 = ctx.f6.f64;
	// lfs f4,64(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 64);
	ctx.f4.f64 = double(temp.f32);
	// lfs f7,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f7.f64 = double(temp.f32);
	// fadds f13,f4,f13
	ctx.f13.f64 = double(float(ctx.f4.f64 + ctx.f13.f64));
	// fmuls f28,f6,f7
	f28.f64 = double(float(ctx.f6.f64 * ctx.f7.f64));
	// lfs f11,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	ctx.f12.f64 = double(temp.f32);
	// fadds f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// lfs f0,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f3,44(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	ctx.f3.f64 = double(temp.f32);
	// fmsubs f10,f6,f10,f29
	ctx.f10.f64 = double(float(ctx.f6.f64 * ctx.f10.f64 - f29.f64));
	// lfs f2,48(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	ctx.f2.f64 = double(temp.f32);
	// fadds f11,f2,f3
	ctx.f11.f64 = double(float(ctx.f2.f64 + ctx.f3.f64));
	// lfs f30,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	f30.f64 = double(temp.f32);
	// fmsubs f8,f7,f8,f27
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64 - f27.f64));
	// fmuls f7,f13,f1
	ctx.f7.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// fmsubs f9,f5,f9,f28
	ctx.f9.f64 = double(float(ctx.f5.f64 * ctx.f9.f64 - f28.f64));
	// fmuls f6,f10,f10
	ctx.f6.f64 = double(float(ctx.f10.f64 * ctx.f10.f64));
	// fmadds f5,f12,f31,f7
	ctx.f5.f64 = double(float(ctx.f12.f64 * f31.f64 + ctx.f7.f64));
	// fmadds f7,f9,f9,f6
	ctx.f7.f64 = double(float(ctx.f9.f64 * ctx.f9.f64 + ctx.f6.f64));
	// fmadds f7,f8,f8,f7
	ctx.f7.f64 = double(float(ctx.f8.f64 * ctx.f8.f64 + ctx.f7.f64));
	// fsqrts f6,f7
	ctx.f6.f64 = double(float(sqrt(ctx.f7.f64)));
	// lfs f7,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f7.f64 = double(temp.f32);
	// fdivs f7,f7,f6
	ctx.f7.f64 = double(float(ctx.f7.f64 / ctx.f6.f64));
	// fmuls f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// fmuls f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// fmuls f9,f7,f9
	ctx.f9.f64 = double(float(ctx.f7.f64 * ctx.f9.f64));
	// fmadds f8,f11,f8,f5
	ctx.f8.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 + ctx.f5.f64));
	// fmadds f8,f8,f0,f30
	ctx.f8.f64 = double(float(ctx.f8.f64 * f0.f64 + f30.f64));
	// stfs f8,0(r4)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f8,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f8,f12
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// lfs f7,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f8,f13,f7,f8
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f7.f64 + ctx.f8.f64));
	// fmadds f10,f11,f10,f8
	ctx.f10.f64 = double(float(ctx.f11.f64 * ctx.f10.f64 + ctx.f8.f64));
	// fmadds f10,f10,f0,f6
	ctx.f10.f64 = double(float(ctx.f10.f64 * f0.f64 + ctx.f6.f64));
	// stfs f10,4(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// lfs f10,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f10,32(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f12,f11,f9,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f9.f64 + ctx.f12.f64));
	// fmadds f13,f10,f13,f12
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fmadds f0,f13,f0,f8
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f8.f64));
	// stfs f0,8(r4)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 8, temp.u32);
	// addi r12,r1,-8
	r12.s64 = ctx.r1.s64 + -8;
	// bl 0x823ed590
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D0B08"))) PPC_WEAK_FUNC(sub_820D0B08);
PPC_FUNC_IMPL(__imp__sub_820D0B08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed544
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// li r31,0
	r31.s64 = 0;
	// lhz r11,4(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 4);
	// extsh r28,r11
	r28.s64 = r11.s16;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x820d03e8
	sub_820D03E8(ctx, base);
	// lwz r11,116(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 116);
	// lhz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U16(r29.u32 + 0);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// std r10,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r10.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lfd f13,112(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f12,f0
	ctx.f12.f64 = double(float(f0.f64));
	// lfs f0,15620(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15620);
	f0.f64 = double(temp.f32);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * f0.f64));
	// stfs f0,116(r29)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r29.u32 + 116, temp.u32);
	// lfs f0,16604(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16604);
	f0.f64 = double(temp.f32);
	// fmuls f27,f13,f0
	f27.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820d0bcc
	if (!cr6.getGT()) goto loc_820D0BCC;
	// bl 0x820ec268
	sub_820EC268(ctx, base);
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// bne cr6,0x820d0ba8
	if (!cr6.getEQ()) goto loc_820D0BA8;
	// lhz r11,4(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 4);
	// cmplwi cr6,r11,333
	cr6.compare<uint32_t>(r11.u32, 333, xer);
	// beq cr6,0x820d0bcc
	if (cr6.getEQ()) goto loc_820D0BCC;
loc_820D0BA8:
	// bl 0x820ec268
	sub_820EC268(ctx, base);
	// cmpwi cr6,r3,3
	cr6.compare<int32_t>(ctx.r3.s32, 3, xer);
	// bne cr6,0x820d0bc0
	if (!cr6.getEQ()) goto loc_820D0BC0;
	// lhz r11,4(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 4);
	// cmplwi cr6,r11,208
	cr6.compare<uint32_t>(r11.u32, 208, xer);
	// beq cr6,0x820d0bcc
	if (cr6.getEQ()) goto loc_820D0BCC;
loc_820D0BC0:
	// lbz r11,2(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 2);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// stb r11,2(r29)
	PPC_STORE_U8(r29.u32 + 2, r11.u8);
loc_820D0BCC:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r10,r11,0,16,16
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820d0c44
	if (cr6.getEQ()) goto loc_820D0C44;
	// lbz r11,3(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 3);
	// rlwinm r10,r28,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// lis r11,-32164
	r11.s64 = -2107899904;
	// addi r11,r11,-3616
	r11.s64 = r11.s64 + -3616;
	// lwzx r4,r10,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// bne cr6,0x820d0c20
	if (!cr6.getEQ()) goto loc_820D0C20;
	// bl 0x820e2a88
	sub_820E2A88(ctx, base);
	// lwz r3,20(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lfs f0,20(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	f0.f64 = double(temp.f32);
	// fmuls f1,f0,f27
	ctx.f1.f64 = double(float(f0.f64 * f27.f64));
	// bl 0x823ada90
	sub_823ADA90(ctx, base);
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed590
	// b 0x823ed184
	return;
loc_820D0C20:
	// bl 0x820d4fa0
	sub_820D4FA0(ctx, base);
	// lwz r3,20(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lfs f0,20(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	f0.f64 = double(temp.f32);
	// fmuls f1,f0,f27
	ctx.f1.f64 = double(float(f0.f64 * f27.f64));
	// bl 0x823ada90
	sub_823ADA90(ctx, base);
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed590
	// b 0x823ed184
	return;
loc_820D0C44:
	// rlwinm r11,r11,0,17,17
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lhz r11,6(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 6);
	// beq cr6,0x820d0d04
	if (cr6.getEQ()) goto loc_820D0D04;
	// extsh r31,r11
	r31.s64 = r11.s16;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82120230
	sub_82120230(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820d0ce0
	if (cr6.getEQ()) goto loc_820D0CE0;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d0ce0
	if (cr6.getEQ()) goto loc_820D0CE0;
	// lwz r11,28(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d0ce0
	if (cr6.getEQ()) goto loc_820D0CE0;
	// lbz r11,3(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 3);
	// rlwinm r10,r28,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// lis r11,-32164
	r11.s64 = -2107899904;
	// addi r11,r11,-3616
	r11.s64 = r11.s64 + -3616;
	// lwzx r4,r10,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// bne cr6,0x820d0cac
	if (!cr6.getEQ()) goto loc_820D0CAC;
	// bl 0x820e2a88
	sub_820E2A88(ctx, base);
	// b 0x820d0cb0
	goto loc_820D0CB0;
loc_820D0CAC:
	// bl 0x820d4fa0
	sub_820D4FA0(ctx, base);
loc_820D0CB0:
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,20(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lfs f0,20(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	f0.f64 = double(temp.f32);
	// fmuls f1,f0,f27
	ctx.f1.f64 = double(float(f0.f64 * f27.f64));
	// bl 0x823ada90
	sub_823ADA90(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,24(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// bl 0x820ccc18
	sub_820CCC18(ctx, base);
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed590
	// b 0x823ed184
	return;
loc_820D0CE0:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r5,r27,1
	ctx.r5.s64 = r27.s64 + 1;
	// addi r3,r11,16548
	ctx.r3.s64 = r11.s64 + 16548;
	// addi r4,r31,1
	ctx.r4.s64 = r31.s64 + 1;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed590
	// b 0x823ed184
	return;
loc_820D0D04:
	// extsh r11,r11
	r11.s64 = r11.s16;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// cmpwi cr6,r11,10000
	cr6.compare<int32_t>(r11.s32, 10000, xer);
	// bge cr6,0x820d0db0
	if (!cr6.getLT()) goto loc_820D0DB0;
	// mulli r10,r11,44
	ctx.r10.s64 = r11.s64 * 44;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// add r30,r10,r11
	r30.u64 = ctx.r10.u64 + r11.u64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r11,r11,2688
	r11.s64 = r11.s64 + 2688;
	// lfs f0,32(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 32);
	f0.f64 = double(temp.f32);
	// fneg f6,f0
	ctx.f6.u64 = f0.u64 ^ 0x8000000000000000;
	// lfs f13,28(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,24(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 24);
	f0.f64 = double(temp.f32);
	// fneg f5,f13
	ctx.f5.u64 = ctx.f13.u64 ^ 0x8000000000000000;
	// lfs f31,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	f31.f64 = double(temp.f32);
	// fneg f4,f0
	ctx.f4.u64 = f0.u64 ^ 0x8000000000000000;
	// lfs f9,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// lfs f8,16(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// lfs f7,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x8210c040
	sub_8210C040(ctx, base);
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,136(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,140(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lfs f0,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,120(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,124(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// b 0x820d0f8c
	goto loc_820D0F8C;
loc_820D0DB0:
	// addi r10,r11,-10000
	ctx.r10.s64 = r11.s64 + -10000;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mulli r10,r10,68
	ctx.r10.s64 = ctx.r10.s64 * 68;
	// addi r11,r11,2688
	r11.s64 = r11.s64 + 2688;
	// lfs f31,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	f31.f64 = double(temp.f32);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// add r31,r10,r11
	r31.u64 = ctx.r10.u64 + r11.u64;
	// lfs f0,32(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	f0.f64 = double(temp.f32);
	// lfs f13,28(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fneg f6,f0
	ctx.f6.u64 = f0.u64 ^ 0x8000000000000000;
	// lfs f12,24(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fneg f5,f13
	ctx.f5.u64 = ctx.f13.u64 ^ 0x8000000000000000;
	// lfs f9,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// fneg f4,f12
	ctx.f4.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// lfs f8,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// bl 0x8210c040
	sub_8210C040(ctx, base);
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// clrlwi r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d0efc
	if (!cr6.getEQ()) goto loc_820D0EFC;
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// bl 0x820d0a00
	sub_820D0A00(ctx, base);
	// lfs f12,56(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 56);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,52(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f12,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// lfs f3,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f3.f64 = double(temp.f32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f4,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f4.f64 = double(temp.f32);
	// lfs f0,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// fmadds f13,f13,f0,f3
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f3.f64));
	// stfs f13,120(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f12,56(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 56);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,52(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f12,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f12,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f13,124(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f12,56(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 56);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,52(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f12,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// fmadds f0,f13,f0,f4
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f4.f64));
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// lfs f2,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820d0f8c
	if (!cr6.getEQ()) goto loc_820D0F8C;
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// stfs f0,136(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,140(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// rlwinm r10,r11,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820d0f8c
	if (!cr6.getEQ()) goto loc_820D0F8C;
	// rlwinm r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d0f8c
	if (!cr6.getEQ()) goto loc_820D0F8C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r27,1
	ctx.r4.s64 = r27.s64 + 1;
	// addi r3,r11,16504
	ctx.r3.s64 = r11.s64 + 16504;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// b 0x820d0f8c
	goto loc_820D0F8C;
loc_820D0EFC:
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// stfs f0,136(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,140(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// bl 0x820d0a00
	sub_820D0A00(ctx, base);
	// lfs f12,56(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 56);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,52(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f12,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f12,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f13,120(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f12,56(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 56);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,52(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f12,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f12,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f13,124(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f12,56(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 56);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,52(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f12,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f0,f13,f0,f12
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
loc_820D0F8C:
	// addi r7,r1,100
	ctx.r7.s64 = ctx.r1.s64 + 100;
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r6,r1,152
	ctx.r6.s64 = ctx.r1.s64 + 152;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// addi r3,r1,136
	ctx.r3.s64 = ctx.r1.s64 + 136;
	// bl 0x820cff50
	sub_820CFF50(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d1320
	if (cr6.getEQ()) goto loc_820D1320;
	// lbz r11,3(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 3);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bne cr6,0x820d0fd4
	if (!cr6.getEQ()) goto loc_820D0FD4;
	// lis r11,-32164
	r11.s64 = -2107899904;
	// rlwinm r10,r28,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r11,r11,-3616
	r11.s64 = r11.s64 + -3616;
	// lwzx r4,r10,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// bl 0x820e2a88
	sub_820E2A88(ctx, base);
	// b 0x820d0fd8
	goto loc_820D0FD8;
loc_820D0FD4:
	// bl 0x820d4fb0
	sub_820D4FB0(ctx, base);
loc_820D0FD8:
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820d12a8
	if (cr6.getEQ()) goto loc_820D12A8;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820d4ac0
	sub_820D4AC0(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d12a8
	if (cr6.getEQ()) goto loc_820D12A8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lfs f28,2776(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f28.f64 = double(temp.f32);
	// rlwinm r11,r10,0,26,27
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x30;
	// fmr f12,f28
	ctx.f12.f64 = f28.f64;
	// fmr f13,f28
	ctx.f13.f64 = f28.f64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// fmr f11,f28
	ctx.f11.f64 = f28.f64;
	// beq cr6,0x820d1050
	if (cr6.getEQ()) goto loc_820D1050;
	// lfs f0,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f10,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f0,f0,f10
	f0.f64 = double(float(f0.f64 - ctx.f10.f64));
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x820d1050
	if (!cr6.getGT()) goto loc_820D1050;
	// rlwinm r11,r10,0,30,30
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	// lfs f10,44(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 44);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,48(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// fsubs f12,f12,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f10.f64));
	// lfs f10,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fdivs f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 / f0.f64));
loc_820D1050:
	// andi. r11,r10,80
	r11.u64 = ctx.r10.u64 & 80;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d10b4
	if (cr6.getEQ()) goto loc_820D10B4;
	// lfs f0,16(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	f0.f64 = double(temp.f32);
	// lfs f10,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f0,f0,f10
	f0.f64 = double(float(f0.f64 - ctx.f10.f64));
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x820d10b4
	if (!cr6.getGT()) goto loc_820D10B4;
	// rlwinm r11,r10,0,30,30
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// beq cr6,0x820d109c
	if (cr6.getEQ()) goto loc_820D109C;
	// lfs f10,60(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 60);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,64(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 64);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// lfs f10,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fdivs f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 / f0.f64));
	// b 0x820d10b4
	goto loc_820D10B4;
loc_820D109C:
	// lfs f10,52(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 52);
	ctx.f10.f64 = double(temp.f32);
	// lfs f13,56(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// lfs f10,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fdivs f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 / f0.f64));
loc_820D10B4:
	// andi. r11,r10,144
	r11.u64 = ctx.r10.u64 & 144;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d1118
	if (cr6.getEQ()) goto loc_820D1118;
	// lfs f0,24(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	f0.f64 = double(temp.f32);
	// lfs f10,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f0,f0,f10
	f0.f64 = double(float(f0.f64 - ctx.f10.f64));
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x820d1118
	if (!cr6.getGT()) goto loc_820D1118;
	// rlwinm r11,r10,0,30,30
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// beq cr6,0x820d1100
	if (cr6.getEQ()) goto loc_820D1100;
	// lfs f10,52(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 52);
	ctx.f10.f64 = double(temp.f32);
	// lfs f13,56(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// lfs f10,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fdivs f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 / f0.f64));
	// b 0x820d1118
	goto loc_820D1118;
loc_820D1100:
	// lfs f10,60(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 60);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,64(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 64);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// lfs f10,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fdivs f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 / f0.f64));
loc_820D1118:
	// fmr f0,f12
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f12.f64;
	// fcmpu cr6,f13,f12
	cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// bge cr6,0x820d1128
	if (!cr6.getLT()) goto loc_820D1128;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
loc_820D1128:
	// fcmpu cr6,f11,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f11.f64, f0.f64);
	// bge cr6,0x820d1134
	if (!cr6.getLT()) goto loc_820D1134;
	// fmr f0,f11
	f0.f64 = ctx.f11.f64;
loc_820D1134:
	// fmr f31,f12
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f12.f64;
	// fcmpu cr6,f13,f12
	cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// ble cr6,0x820d1144
	if (!cr6.getGT()) goto loc_820D1144;
	// fmr f31,f13
	f31.f64 = ctx.f13.f64;
loc_820D1144:
	// fcmpu cr6,f11,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f11.f64, f31.f64);
	// ble cr6,0x820d1150
	if (!cr6.getGT()) goto loc_820D1150;
	// fmr f31,f11
	f31.f64 = ctx.f11.f64;
loc_820D1150:
	// rlwinm r11,r10,0,27,27
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d116c
	if (cr6.getEQ()) goto loc_820D116C;
	// fmr f11,f0
	ctx.fpscr.disableFlushMode();
	ctx.f11.f64 = f0.f64;
	// fmr f13,f0
	ctx.f13.f64 = f0.f64;
	// fmr f12,f0
	ctx.f12.f64 = f0.f64;
	// b 0x820d120c
	goto loc_820D120C;
loc_820D116C:
	// rlwinm r11,r10,0,26,26
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d1194
	if (!cr6.getEQ()) goto loc_820D1194;
	// rlwinm r11,r10,0,30,30
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	// lfs f0,8(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f10,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// fcmpu cr6,f0,f10
	cr6.compare(f0.f64, ctx.f10.f64);
	// bne cr6,0x820d1194
	if (!cr6.getEQ()) goto loc_820D1194;
	// fmr f12,f31
	ctx.f12.f64 = f31.f64;
loc_820D1194:
	// rlwinm r11,r10,0,25,25
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d11d0
	if (!cr6.getEQ()) goto loc_820D11D0;
	// rlwinm r11,r10,0,30,30
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	// lfs f0,16(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	f0.f64 = double(temp.f32);
	// lfs f10,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d11c4
	if (cr6.getEQ()) goto loc_820D11C4;
	// fcmpu cr6,f0,f10
	cr6.compare(f0.f64, ctx.f10.f64);
	// bne cr6,0x820d11d0
	if (!cr6.getEQ()) goto loc_820D11D0;
	// fmr f11,f31
	ctx.f11.f64 = f31.f64;
	// b 0x820d11d0
	goto loc_820D11D0;
loc_820D11C4:
	// fcmpu cr6,f0,f10
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f10.f64);
	// bne cr6,0x820d11d0
	if (!cr6.getEQ()) goto loc_820D11D0;
	// fmr f13,f31
	ctx.f13.f64 = f31.f64;
loc_820D11D0:
	// rlwinm r11,r10,0,24,24
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d120c
	if (!cr6.getEQ()) goto loc_820D120C;
	// rlwinm r11,r10,0,30,30
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	// lfs f0,24(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	f0.f64 = double(temp.f32);
	// lfs f10,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d1200
	if (cr6.getEQ()) goto loc_820D1200;
	// fcmpu cr6,f0,f10
	cr6.compare(f0.f64, ctx.f10.f64);
	// bne cr6,0x820d120c
	if (!cr6.getEQ()) goto loc_820D120C;
	// fmr f13,f31
	ctx.f13.f64 = f31.f64;
	// b 0x820d120c
	goto loc_820D120C;
loc_820D1200:
	// fcmpu cr6,f0,f10
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f10.f64);
	// bne cr6,0x820d120c
	if (!cr6.getEQ()) goto loc_820D120C;
	// fmr f11,f31
	ctx.f11.f64 = f31.f64;
loc_820D120C:
	// fdivs f0,f28,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f28.f64 / f31.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f1,f12,f0
	ctx.f1.f64 = double(float(ctx.f12.f64 * f0.f64));
	// fmuls f29,f13,f0
	f29.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fmuls f30,f11,f0
	f30.f64 = double(float(ctx.f11.f64 * f0.f64));
	// lfs f0,16500(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16500);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// ble cr6,0x820d123c
	if (!cr6.getGT()) goto loc_820D123C;
	// fcmpu cr6,f29,f0
	cr6.compare(f29.f64, f0.f64);
	// ble cr6,0x820d123c
	if (!cr6.getGT()) goto loc_820D123C;
	// fcmpu cr6,f30,f0
	cr6.compare(f30.f64, f0.f64);
	// bgt cr6,0x820d1278
	if (cr6.getGT()) goto loc_820D1278;
loc_820D123C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f3,f30
	ctx.fpscr.disableFlushMode();
	ctx.f3.f64 = f30.f64;
	// fmr f2,f29
	ctx.f2.f64 = f29.f64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r11,16436
	ctx.r3.s64 = r11.s64 + 16436;
	// stfd f3,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.f3.u64);
	// stfd f2,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.f2.u64);
	// ld r7,48(r1)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r1.u32 + 48);
	// stfd f1,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.f1.u64);
	// ld r6,40(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 40);
	// ld r5,32(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 32);
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// fmr f30,f28
	ctx.fpscr.disableFlushMode();
	f30.f64 = f28.f64;
	// fmr f29,f28
	f29.f64 = f28.f64;
	// fmr f1,f28
	ctx.f1.f64 = f28.f64;
loc_820D1278:
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// bl 0x8210bc18
	sub_8210BC18(ctx, base);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f29.f64;
	// bl 0x8210bc40
	sub_8210BC40(ctx, base);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x8210bca0
	sub_8210BCA0(ctx, base);
	// lwz r3,20(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lfs f0,20(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	f0.f64 = double(temp.f32);
	// fmuls f1,f0,f31
	ctx.f1.f64 = double(float(f0.f64 * f31.f64));
	// bl 0x823ada90
	sub_823ADA90(ctx, base);
loc_820D12A8:
	// lwz r3,20(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lfs f0,20(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	f0.f64 = double(temp.f32);
	// fmuls f1,f0,f27
	ctx.f1.f64 = double(float(f0.f64 * f27.f64));
	// bl 0x823ada90
	sub_823ADA90(ctx, base);
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// lfs f1,20(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// addi r7,r1,120
	ctx.r7.s64 = ctx.r1.s64 + 120;
	// lwz r6,100(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// addi r4,r1,152
	ctx.r4.s64 = ctx.r1.s64 + 152;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// beq cr6,0x820d12f4
	if (cr6.getEQ()) goto loc_820D12F4;
	// bl 0x820d5300
	sub_820D5300(ctx, base);
	// b 0x820d12f8
	goto loc_820D12F8;
loc_820D12F4:
	// bl 0x820d5098
	sub_820D5098(ctx, base);
loc_820D12F8:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820d0458
	sub_820D0458(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820ccb20
	sub_820CCB20(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820cca18
	sub_820CCA18(ctx, base);
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed590
	// b 0x823ed184
	return;
loc_820D1320:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r27,1
	ctx.r4.s64 = r27.s64 + 1;
	// addi r3,r11,16384
	ctx.r3.s64 = r11.s64 + 16384;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed590
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820D1340"))) PPC_WEAK_FUNC(sub_820D1340);
PPC_FUNC_IMPL(__imp__sub_820D1340) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,17,17
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d14b0
	if (cr6.getEQ()) goto loc_820D14B0;
	// lhz r11,6(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 6);
	// extsh r30,r11
	r30.s64 = r11.s16;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82120230
	sub_82120230(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x820d1494
	if (cr6.getEQ()) goto loc_820D1494;
	// lwz r11,24(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d1494
	if (cr6.getEQ()) goto loc_820D1494;
	// lwz r11,28(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d1494
	if (cr6.getEQ()) goto loc_820D1494;
	// li r3,28
	ctx.r3.s64 = 28;
	// bl 0x82136fa0
	sub_82136FA0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d1468
	if (cr6.getEQ()) goto loc_820D1468;
	// lbz r11,128(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 128);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// addi r11,r11,-2
	r11.s64 = r11.s64 + -2;
	// cmplwi cr6,r11,29
	cr6.compare<uint32_t>(r11.u32, 29, xer);
	// bgt cr6,0x820d1468
	if (cr6.getGT()) goto loc_820D1468;
	// lis r12,-32243
	r12.s64 = -2113077248;
	// addi r12,r12,5080
	r12.s64 = r12.s64 + 5080;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820D1450;
	case 1:
		goto loc_820D1450;
	case 2:
		goto loc_820D1450;
	case 3:
		goto loc_820D1450;
	case 4:
		goto loc_820D1450;
	case 5:
		goto loc_820D1450;
	case 6:
		goto loc_820D1450;
	case 7:
		goto loc_820D1450;
	case 8:
		goto loc_820D1450;
	case 9:
		goto loc_820D1450;
	case 10:
		goto loc_820D1450;
	case 11:
		goto loc_820D1450;
	case 12:
		goto loc_820D1450;
	case 13:
		goto loc_820D1450;
	case 14:
		goto loc_820D1450;
	case 15:
		goto loc_820D1450;
	case 16:
		goto loc_820D1450;
	case 17:
		goto loc_820D1450;
	case 18:
		goto loc_820D1450;
	case 19:
		goto loc_820D1450;
	case 20:
		goto loc_820D1450;
	case 21:
		goto loc_820D1450;
	case 22:
		goto loc_820D1468;
	case 23:
		goto loc_820D1468;
	case 24:
		goto loc_820D1468;
	case 25:
		goto loc_820D1468;
	case 26:
		goto loc_820D1468;
	case 27:
		goto loc_820D1450;
	case 28:
		goto loc_820D1450;
	case 29:
		goto loc_820D1450;
	default:
		__builtin_unreachable();
	}
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5224(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5224);
	// lwz r16,5224(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5224);
	// lwz r16,5224(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5224);
	// lwz r16,5224(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5224);
	// lwz r16,5224(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5224);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
	// lwz r16,5200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 5200);
loc_820D1450:
	// li r11,25
	r11.s64 = 25;
	// li r10,211
	ctx.r10.s64 = 211;
	// li r9,256
	ctx.r9.s64 = 256;
	// stb r11,128(r31)
	PPC_STORE_U8(r31.u32 + 128, r11.u8);
	// sth r10,4(r31)
	PPC_STORE_U16(r31.u32 + 4, ctx.r10.u16);
	// sth r9,0(r31)
	PPC_STORE_U16(r31.u32 + 0, ctx.r9.u16);
loc_820D1468:
	// lbz r11,128(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 128);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x820a0b78
	sub_820A0B78(ctx, base);
	// lbz r11,128(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 128);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x820bfe00
	sub_820BFE00(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820e2b70
	sub_820E2B70(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820D1494:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r5,r27,1
	ctx.r5.s64 = r27.s64 + 1;
	// addi r3,r11,16608
	ctx.r3.s64 = r11.s64 + 16608;
	// addi r4,r30,1
	ctx.r4.s64 = r30.s64 + 1;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820D14B0:
	// li r29,1
	r29.s64 = 1;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820d1530
	if (!cr6.getGT()) goto loc_820D1530;
	// li r11,-1
	r11.s64 = -1;
	// lis r30,-32013
	r30.s64 = -2098003968;
	// stw r11,1000(r30)
	PPC_STORE_U32(r30.u32 + 1000, r11.u32);
	// lbz r11,128(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 128);
	// cmpwi cr6,r11,88
	cr6.compare<int32_t>(r11.s32, 88, xer);
	// beq cr6,0x820d1520
	if (cr6.getEQ()) goto loc_820D1520;
	// addi r11,r11,-240
	r11.s64 = r11.s64 + -240;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// bgt cr6,0x820d1530
	if (cr6.getGT()) goto loc_820D1530;
	// bl 0x820eaab8
	sub_820EAAB8(ctx, base);
	// lbz r11,128(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 128);
	// addi r11,r11,-240
	r11.s64 = r11.s64 + -240;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// stw r11,1000(r30)
	PPC_STORE_U32(r30.u32 + 1000, r11.u32);
	// add r11,r10,r3
	r11.u64 = ctx.r10.u64 + ctx.r3.u64;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// stb r10,128(r31)
	PPC_STORE_U8(r31.u32 + 128, ctx.r10.u8);
	// lhz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 4);
	// sth r10,4(r31)
	PPC_STORE_U16(r31.u32 + 4, ctx.r10.u16);
	// lhz r10,6(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 6);
	// sth r10,0(r31)
	PPC_STORE_U16(r31.u32 + 0, ctx.r10.u16);
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// extsb r29,r11
	r29.s64 = r11.s8;
	// b 0x820d1530
	goto loc_820D1530;
loc_820D1520:
	// bl 0x820ec268
	sub_820EC268(ctx, base);
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// beq cr6,0x820d1530
	if (cr6.getEQ()) goto loc_820D1530;
	// li r29,0
	r29.s64 = 0;
loc_820D1530:
	// lbz r11,128(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 128);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d1568
	if (cr6.getEQ()) goto loc_820D1568;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x820d1568
	if (cr6.getEQ()) goto loc_820D1568;
	// bl 0x820a0b78
	sub_820A0B78(ctx, base);
	// lbz r11,128(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 128);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x820bfe00
	sub_820BFE00(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x820d0b08
	sub_820D0B08(ctx, base);
loc_820D1568:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820D1570"))) PPC_WEAK_FUNC(sub_820D1570);
PPC_FUNC_IMPL(__imp__sub_820D1570) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,17,17
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d15f4
	if (cr6.getEQ()) goto loc_820D15F4;
	// lhz r11,6(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 6);
	// extsh r30,r11
	r30.s64 = r11.s16;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82120230
	sub_82120230(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x820d15d8
	if (cr6.getEQ()) goto loc_820D15D8;
	// lwz r11,24(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d15d8
	if (cr6.getEQ()) goto loc_820D15D8;
	// lwz r11,28(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d15d8
	if (cr6.getEQ()) goto loc_820D15D8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820dc768
	sub_820DC768(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
loc_820D15D8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r5,r29,1
	ctx.r5.s64 = r29.s64 + 1;
	// addi r3,r11,16664
	ctx.r3.s64 = r11.s64 + 16664;
	// addi r4,r30,1
	ctx.r4.s64 = r30.s64 + 1;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
loc_820D15F4:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x820d0b08
	sub_820D0B08(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820D1608"))) PPC_WEAK_FUNC(sub_820D1608);
PPC_FUNC_IMPL(__imp__sub_820D1608) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x820d0b08
	sub_820D0B08(ctx, base);
	// lwz r11,128(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x820d17f4
	if (cr6.getLT()) goto loc_820D17F4;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmpwi cr6,r11,10000
	cr6.compare<int32_t>(r11.s32, 10000, xer);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// bge cr6,0x820d165c
	if (!cr6.getLT()) goto loc_820D165C;
	// mulli r9,r11,44
	ctx.r9.s64 = r11.s64 * 44;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// b 0x820d1670
	goto loc_820D1670;
loc_820D165C:
	// addi r11,r11,-10000
	r11.s64 = r11.s64 + -10000;
	// mulli r9,r11,68
	ctx.r9.s64 = r11.s64 * 68;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
loc_820D1670:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// lfs f0,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	f0.f64 = double(temp.f32);
	// add r30,r9,r11
	r30.u64 = ctx.r9.u64 + r11.u64;
	// stfs f0,132(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f0,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,136(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lfs f13,128(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f11,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f11.f64 = double(temp.f32);
	// addi r29,r31,132
	r29.s64 = r31.s64 + 132;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lfs f0,12(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// stfs f13,132(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f12,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// fadds f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f11.f64));
	// lfs f31,2688(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2688);
	f31.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// stfs f12,136(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f11,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fmr f9,f31
	ctx.f9.f64 = f31.f64;
	// lfs f10,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fmr f7,f31
	ctx.f7.f64 = f31.f64;
	// lfs f4,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// lfs f8,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	ctx.f8.f64 = double(temp.f32);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// fsubs f4,f0,f4
	ctx.f4.f64 = double(float(f0.f64 - ctx.f4.f64));
	// fsubs f5,f13,f10
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// fsubs f6,f12,f11
	ctx.f6.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// bl 0x8210c040
	sub_8210C040(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lfs f1,20(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// lwz r11,228(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 228);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820d17bc
	if (!cr6.getEQ()) goto loc_820D17BC;
	// lwz r11,204(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 204);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r10,208(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 208);
	// lwz r8,220(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 220);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// lwz r7,232(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 232);
	// extsw r8,r8
	ctx.r8.s64 = ctx.r8.s32;
	// extsw r7,r7
	ctx.r7.s64 = ctx.r7.s32;
	// stw r9,228(r31)
	PPC_STORE_U32(r31.u32 + 228, ctx.r9.u32);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// std r10,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r10.u64);
	// std r8,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r8.u64);
	// std r7,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r7.u64);
	// lfd f0,96(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// lfd f13,104(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lfd f12,112(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// lfd f11,120(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// frsp f10,f0
	ctx.f10.f64 = double(float(f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// frsp f0,f11
	f0.f64 = double(float(ctx.f11.f64));
	// stfs f0,232(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 232, temp.u32);
	// lfs f0,16716(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16716);
	f0.f64 = double(temp.f32);
	// fmuls f11,f10,f0
	ctx.f11.f64 = double(float(ctx.f10.f64 * f0.f64));
	// stfs f11,204(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r31.u32 + 204, temp.u32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,208(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 208, temp.u32);
	// fmuls f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * f0.f64));
	// stfs f0,220(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 220, temp.u32);
loc_820D17BC:
	// li r29,0
	r29.s64 = 0;
	// lfs f0,204(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 204);
	f0.f64 = double(temp.f32);
	// stfs f0,200(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 200, temp.u32);
	// stfs f31,216(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 216, temp.u32);
	// lfs f12,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// stw r29,212(r31)
	PPC_STORE_U32(r31.u32 + 212, r29.u32);
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// fsubs f2,f12,f0
	ctx.f2.f64 = double(float(ctx.f12.f64 - f0.f64));
	// lfs f13,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	f0.f64 = double(temp.f32);
	// fsubs f1,f0,f13
	ctx.f1.f64 = double(float(f0.f64 - ctx.f13.f64));
	// bl 0x8210ae20
	sub_8210AE20(ctx, base);
	// stfs f1,196(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r31.u32 + 196, temp.u32);
	// stw r29,224(r31)
	PPC_STORE_U32(r31.u32 + 224, r29.u32);
loc_820D17F4:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f31,-40(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820D1800"))) PPC_WEAK_FUNC(sub_820D1800);
PPC_FUNC_IMPL(__imp__sub_820D1800) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stfd f29,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, f29.u64);
	// stfd f30,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, f30.u64);
	// stfd f31,-40(r1)
	PPC_STORE_U64(ctx.r1.u32 + -40, f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x820d0b08
	sub_820D0B08(ctx, base);
	// lwz r11,164(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 164);
	// li r29,0
	r29.s64 = 0;
	// lwz r10,168(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 168);
	// li r30,-1
	r30.s64 = -1;
	// extsw r8,r11
	ctx.r8.s64 = r11.s32;
	// lwz r9,136(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 136);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r7,140(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 140);
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// stw r29,172(r31)
	PPC_STORE_U32(r31.u32 + 172, r29.u32);
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r30,184(r31)
	PPC_STORE_U32(r31.u32 + 184, r30.u32);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// li r3,48
	ctx.r3.s64 = 48;
	// lfs f31,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// extsw r11,r7
	r11.s64 = ctx.r7.s32;
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// stfs f31,144(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 144, temp.u32);
	// std r9,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r9.u64);
	// stfs f31,148(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 148, temp.u32);
	// stfs f31,132(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 132, temp.u32);
	// stw r30,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r30.u32);
	// stfs f31,156(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 156, temp.u32);
	// stw r30,192(r31)
	PPC_STORE_U32(r31.u32 + 192, r30.u32);
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f31,160(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 160, temp.u32);
	// stw r29,196(r31)
	PPC_STORE_U32(r31.u32 + 196, r29.u32);
	// stfs f31,152(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 152, temp.u32);
	// stw r29,200(r31)
	PPC_STORE_U32(r31.u32 + 200, r29.u32);
	// stfs f31,176(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 176, temp.u32);
	// stfs f31,180(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 180, temp.u32);
	// lfd f0,80(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// lfd f12,96(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// lfd f11,104(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// frsp f10,f0
	ctx.f10.f64 = double(float(f0.f64));
	// lfs f0,16716(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16716);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// frsp f9,f13
	ctx.f9.f64 = double(float(ctx.f13.f64));
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// fmuls f13,f10,f0
	ctx.f13.f64 = double(float(ctx.f10.f64 * f0.f64));
	// stfs f13,164(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 164, temp.u32);
	// lfs f13,16720(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16720);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// stfs f13,168(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 168, temp.u32);
	// fmuls f13,f12,f0
	ctx.f13.f64 = double(float(ctx.f12.f64 * f0.f64));
	// stfs f13,136(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 136, temp.u32);
	// fmuls f0,f11,f0
	f0.f64 = double(float(ctx.f11.f64 * f0.f64));
	// stfs f0,140(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 140, temp.u32);
	// bl 0x8209cbc8
	sub_8209CBC8(ctx, base);
	// stw r3,204(r31)
	PPC_STORE_U32(r31.u32 + 204, ctx.r3.u32);
	// stb r30,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, r30.u8);
	// stfs f31,212(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 212, temp.u32);
	// lwz r11,128(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// stw r29,208(r31)
	PPC_STORE_U32(r31.u32 + 208, r29.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x820d19a4
	if (cr6.getLT()) goto loc_820D19A4;
	// cmpwi cr6,r11,10000
	cr6.compare<int32_t>(r11.s32, 10000, xer);
	// bge cr6,0x820d193c
	if (!cr6.getLT()) goto loc_820D193C;
	// mulli r10,r11,44
	ctx.r10.s64 = r11.s64 * 44;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// b 0x820d1950
	goto loc_820D1950;
loc_820D193C:
	// addi r11,r11,-10000
	r11.s64 = r11.s64 + -10000;
	// mulli r10,r11,68
	ctx.r10.s64 = r11.s64 * 68;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
loc_820D1950:
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r10,16(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f31,f0,f11
	f31.f64 = double(float(f0.f64 - ctx.f11.f64));
	// fsubs f30,f13,f10
	f30.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// lfs f12,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,16(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	f0.f64 = double(temp.f32);
	// fsubs f29,f12,f0
	f29.f64 = double(float(ctx.f12.f64 - f0.f64));
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// fmr f2,f30
	ctx.f2.f64 = f30.f64;
	// bl 0x8210ae20
	sub_8210AE20(ctx, base);
	// fmuls f0,f31,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f31.f64 * f31.f64));
	// stfs f1,132(r31)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r31.u32 + 132, temp.u32);
	// fmr f1,f29
	ctx.f1.f64 = f29.f64;
	// fmadds f0,f30,f30,f0
	f0.f64 = double(float(f30.f64 * f30.f64 + f0.f64));
	// fsqrts f2,f0
	ctx.f2.f64 = double(float(sqrt(f0.f64)));
	// bl 0x8210ae20
	sub_8210AE20(ctx, base);
	// stfs f1,152(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r31.u32 + 152, temp.u32);
loc_820D19A4:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f29,-56(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f30,-48(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// lfd f31,-40(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820D19B8"))) PPC_WEAK_FUNC(sub_820D19B8);
PPC_FUNC_IMPL(__imp__sub_820D19B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r30,r31,128
	r30.s64 = r31.s64 + 128;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// addi r4,r11,5416
	ctx.r4.s64 = r11.s64 + 5416;
	// li r5,116
	ctx.r5.s64 = 116;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,252(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 252);
	// bl 0x820d8760
	sub_820D8760(ctx, base);
	// lhz r11,6(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 6);
	// cmplwi cr6,r11,32768
	cr6.compare<uint32_t>(r11.u32, 32768, xer);
	// blt cr6,0x820d1b8c
	if (cr6.getLT()) goto loc_820D1B8C;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,16,16
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d1b8c
	if (!cr6.getEQ()) goto loc_820D1B8C;
	// lwz r11,244(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 244);
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 4);
	// add r3,r11,r29
	ctx.r3.u64 = r11.u64 + r29.u64;
	// extsh r29,r10
	r29.s64 = ctx.r10.s16;
	// bl 0x820d0288
	sub_820D0288(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820d03e8
	sub_820D03E8(ctx, base);
	// lwz r11,116(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// lhz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 0);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f12,f0
	ctx.f12.f64 = double(float(f0.f64));
	// lfs f0,15620(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15620);
	f0.f64 = double(temp.f32);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * f0.f64));
	// stfs f0,116(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 116, temp.u32);
	// lfs f0,16604(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16604);
	f0.f64 = double(temp.f32);
	// fmuls f31,f13,f0
	f31.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820d1a98
	if (!cr6.getGT()) goto loc_820D1A98;
	// lbz r11,2(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// stb r11,2(r31)
	PPC_STORE_U8(r31.u32 + 2, r11.u8);
loc_820D1A98:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d4fb0
	sub_820D4FB0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x820d4968
	sub_820D4968(ctx, base);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r3,108(r31)
	PPC_STORE_U32(r31.u32 + 108, ctx.r3.u32);
	// beq cr6,0x820d1b9c
	if (cr6.getEQ()) goto loc_820D1B9C;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d1b9c
	if (cr6.getEQ()) goto loc_820D1B9C;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// lfs f0,20(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	f0.f64 = double(temp.f32);
	// fmuls f1,f0,f31
	ctx.f1.f64 = double(float(f0.f64 * f31.f64));
	// bl 0x823ada90
	sub_823ADA90(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// lwz r11,248(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 248);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820d1b04
	if (!cr6.getEQ()) goto loc_820D1B04;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// b 0x820d1b40
	goto loc_820D1B40;
loc_820D1B04:
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x820d1b20
	if (!cr6.getEQ()) goto loc_820D1B20;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// b 0x820d1b40
	goto loc_820D1B40;
loc_820D1B20:
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// bne cr6,0x820d1b3c
	if (!cr6.getEQ()) goto loc_820D1B3C;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x820d1b40
	goto loc_820D1B40;
loc_820D1B3C:
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
loc_820D1B40:
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r11,28(r10)
	PPC_STORE_U32(ctx.r10.u32 + 28, r11.u32);
	// lwz r4,16(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// bl 0x820ccc18
	sub_820CCC18(ctx, base);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// addi r4,r11,4
	ctx.r4.s64 = r11.s64 + 4;
	// lfs f1,16724(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16724);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r9,20(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// addi r4,r11,4
	ctx.r4.s64 = r11.s64 + 4;
	// lfs f0,20(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	f0.f64 = double(temp.f32);
	// lfs f13,20(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f1,f0,f13
	ctx.f1.f64 = double(float(f0.f64 / ctx.f13.f64));
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// b 0x820d1b9c
	goto loc_820D1B9C;
loc_820D1B8C:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x820d0b08
	sub_820D0B08(ctx, base);
loc_820D1B9C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d1bc4
	if (cr6.getEQ()) goto loc_820D1BC4;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d1bc4
	if (cr6.getEQ()) goto loc_820D1BC4;
	// lbz r10,1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stb r10,1(r11)
	PPC_STORE_U8(r11.u32 + 1, ctx.r10.u8);
loc_820D1BC4:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820D1BD0"))) PPC_WEAK_FUNC(sub_820D1BD0);
PPC_FUNC_IMPL(__imp__sub_820D1BD0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r29,r31,128
	r29.s64 = r31.s64 + 128;
	// addi r30,r11,5416
	r30.s64 = r11.s64 + 5416;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// li r5,116
	ctx.r5.s64 = 116;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lbz r4,592(r31)
	ctx.r4.u64 = PPC_LOAD_U8(r31.u32 + 592);
	// bl 0x820d8760
	sub_820D8760(ctx, base);
	// addi r29,r31,244
	r29.s64 = r31.s64 + 244;
	// li r5,116
	ctx.r5.s64 = 116;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lbz r4,593(r31)
	ctx.r4.u64 = PPC_LOAD_U8(r31.u32 + 593);
	// bl 0x820d8760
	sub_820D8760(ctx, base);
	// addi r29,r31,360
	r29.s64 = r31.s64 + 360;
	// li r5,116
	ctx.r5.s64 = 116;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lbz r4,594(r31)
	ctx.r4.u64 = PPC_LOAD_U8(r31.u32 + 594);
	// bl 0x820d8760
	sub_820D8760(ctx, base);
	// addi r29,r31,476
	r29.s64 = r31.s64 + 476;
	// li r5,116
	ctx.r5.s64 = 116;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lbz r4,595(r31)
	ctx.r4.u64 = PPC_LOAD_U8(r31.u32 + 595);
	// bl 0x820d8760
	sub_820D8760(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x820d0b08
	sub_820D0B08(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820D1C88"))) PPC_WEAK_FUNC(sub_820D1C88);
PPC_FUNC_IMPL(__imp__sub_820D1C88) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed544
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// bl 0x820d0a00
	sub_820D0A00(ctx, base);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lfs f30,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	f30.f64 = double(temp.f32);
	// lfs f31,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	f31.f64 = double(temp.f32);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// lfs f2,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// fmr f4,f30
	ctx.f4.f64 = f30.f64;
	// lfs f1,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820d1d00
	if (!cr6.getEQ()) goto loc_820D1D00;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lfs f31,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f31.f64 = double(temp.f32);
	// lfs f27,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f27.f64 = double(temp.f32);
	// lfs f30,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f30.f64 = double(temp.f32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// b 0x820d1d04
	goto loc_820D1D04;
loc_820D1D00:
	// lfs f27,92(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	f27.f64 = double(temp.f32);
loc_820D1D04:
	// lfs f13,32(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lfs f9,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// fmuls f8,f9,f13
	ctx.f8.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f0,28(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	f0.f64 = double(temp.f32);
	// lfs f11,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// fmr f2,f30
	ctx.f2.f64 = f30.f64;
	// lfs f12,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f6,f11,f0
	ctx.f6.f64 = double(float(ctx.f11.f64 * f0.f64));
	// lfs f10,24(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// fmuls f7,f10,f12
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f27,4(r30)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r30.u32 + 4, temp.u32);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// fmsubs f11,f10,f11,f8
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 - ctx.f8.f64));
	// fmsubs f13,f12,f13,f6
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 - ctx.f6.f64));
	// fmsubs f0,f9,f0,f7
	f0.f64 = double(float(ctx.f9.f64 * f0.f64 - ctx.f7.f64));
	// fmuls f12,f11,f11
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f11.f64));
	// fmadds f12,f0,f0,f12
	ctx.f12.f64 = double(float(f0.f64 * f0.f64 + ctx.f12.f64));
	// fmadds f12,f13,f13,f12
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fsqrts f11,f12
	ctx.f11.f64 = double(float(sqrt(ctx.f12.f64)));
	// lfs f12,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f12.f64 = double(temp.f32);
	// fdivs f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 / ctx.f11.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * f0.f64));
	// lfs f0,2960(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2960);
	f0.f64 = double(temp.f32);
	// fmuls f29,f13,f0
	f29.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fmuls f28,f12,f0
	f28.f64 = double(float(ctx.f12.f64 * f0.f64));
	// fadds f3,f29,f31
	ctx.f3.f64 = double(float(f29.f64 + f31.f64));
	// stfs f3,0(r30)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(r30.u32 + 0, temp.u32);
	// fadds f4,f28,f30
	ctx.f4.f64 = double(float(f28.f64 + f30.f64));
	// stfs f4,8(r30)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(r30.u32 + 8, temp.u32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// fsubs f3,f31,f29
	ctx.fpscr.disableFlushMode();
	ctx.f3.f64 = double(float(f31.f64 - f29.f64));
	// fsubs f4,f30,f28
	ctx.f4.f64 = double(float(f30.f64 - f28.f64));
	// fmr f2,f30
	ctx.f2.f64 = f30.f64;
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// stfs f27,4(r29)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r29.u32 + 4, temp.u32);
	// stfs f3,0(r29)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// stfs f4,8(r29)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(r29.u32 + 8, temp.u32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x820d1dec
	if (!cr6.getEQ()) goto loc_820D1DEC;
	// li r11,-1
	r11.s64 = -1;
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
loc_820D1DEC:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed590
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820D1E00"))) PPC_WEAK_FUNC(sub_820D1E00);
PPC_FUNC_IMPL(__imp__sub_820D1E00) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f23{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// addi r12,r1,-72
	r12.s64 = ctx.r1.s64 + -72;
	// bl 0x823ed534
	// stwu r1,-560(r1)
	ea = -560 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r25,-1
	r25.s64 = -1;
	// li r24,-1
	r24.s64 = -1;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// li r27,-1
	r27.s64 = -1;
	// lhz r11,4(r30)
	r11.u64 = PPC_LOAD_U16(r30.u32 + 4);
	// stw r25,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r25.u32);
	// extsh r28,r11
	r28.s64 = r11.s16;
	// stw r24,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r24.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x820d03e8
	sub_820D03E8(ctx, base);
	// lhz r10,6(r30)
	ctx.r10.u64 = PPC_LOAD_U16(r30.u32 + 6);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// mulli r9,r10,68
	ctx.r9.s64 = ctx.r10.s64 * 68;
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// addi r10,r10,928
	ctx.r10.s64 = ctx.r10.s64 + 928;
	// lwz r10,28(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	// add r31,r9,r10
	r31.u64 = ctx.r9.u64 + ctx.r10.u64;
	// rlwinm r10,r11,0,3,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820d1e78
	if (!cr6.getEQ()) goto loc_820D1E78;
	// rlwinm r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d1ed0
	if (cr6.getEQ()) goto loc_820D1ED0;
loc_820D1E78:
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d1c88
	sub_820D1C88(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r25,96(r1)
	r25.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm r11,r11,0,3,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	// lwz r24,104(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d1ed0
	if (cr6.getEQ()) goto loc_820D1ED0;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// blt cr6,0x820d1ed0
	if (cr6.getLT()) goto loc_820D1ED0;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// blt cr6,0x820d1ed0
	if (cr6.getLT()) goto loc_820D1ED0;
	// addi r6,r1,160
	ctx.r6.s64 = ctx.r1.s64 + 160;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82117110
	sub_82117110(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
loc_820D1ED0:
	// lis r29,-32190
	r29.s64 = -2109603840;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,19392(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 19392);
	f0.f64 = double(temp.f32);
	// lfs f29,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f29.f64 = double(temp.f32);
	// fcmpu cr6,f0,f29
	cr6.compare(f0.f64, f29.f64);
	// beq cr6,0x820d1fc0
	if (cr6.getEQ()) goto loc_820D1FC0;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// blt cr6,0x820d1fa8
	if (cr6.getLT()) goto loc_820D1FA8;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82113f88
	sub_82113F88(ctx, base);
	// lfs f13,4(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f9,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f9.f64 = double(temp.f32);
	// lis r11,-32123
	r11.s64 = -2105212928;
	// fmuls f8,f13,f9
	ctx.f8.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// lfs f1,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lfs f12,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	ctx.f10.f64 = double(temp.f32);
	// lfs f2,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f0,32580(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 32580);
	f0.f64 = double(temp.f32);
	// lfs f11,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f10,f0,f10
	ctx.f10.f64 = double(float(f0.f64 * ctx.f10.f64));
	// lfs f0,19392(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 19392);
	f0.f64 = double(temp.f32);
	// stfs f10,172(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// fcmpu cr6,f0,f29
	cr6.compare(f0.f64, f29.f64);
	// fmadds f8,f1,f12,f8
	ctx.f8.f64 = double(float(ctx.f1.f64 * ctx.f12.f64 + ctx.f8.f64));
	// fmadds f8,f2,f11,f8
	ctx.f8.f64 = double(float(ctx.f2.f64 * ctx.f11.f64 + ctx.f8.f64));
	// fsubs f10,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 - ctx.f10.f64));
	// bge cr6,0x820d1f5c
	if (!cr6.getLT()) goto loc_820D1F5C;
	// fsubs f0,f29,f0
	f0.f64 = double(float(f29.f64 - f0.f64));
	// fmuls f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fnmsubs f31,f12,f0,f1
	f31.f64 = double(float(-(ctx.f12.f64 * f0.f64 - ctx.f1.f64)));
	// fnmsubs f28,f9,f0,f13
	f28.f64 = double(float(-(ctx.f9.f64 * f0.f64 - ctx.f13.f64)));
	// fnmsubs f30,f11,f0,f2
	f30.f64 = double(float(-(ctx.f11.f64 * f0.f64 - ctx.f2.f64)));
	// b 0x820d1f70
	goto loc_820D1F70;
loc_820D1F5C:
	// fsubs f0,f0,f29
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f0.f64 - f29.f64));
	// fmuls f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fmadds f31,f12,f0,f1
	f31.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f1.f64));
	// fmadds f28,f9,f0,f13
	f28.f64 = double(float(ctx.f9.f64 * f0.f64 + ctx.f13.f64));
	// fmadds f30,f11,f0,f2
	f30.f64 = double(float(ctx.f11.f64 * f0.f64 + ctx.f2.f64));
loc_820D1F70:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// fmr f4,f30
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f30.f64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d21ac
	if (cr6.getEQ()) goto loc_820D21AC;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lfs f0,19392(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 19392);
	f0.f64 = double(temp.f32);
	// stfs f31,0(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// stfs f28,4(r31)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// stfs f30,8(r31)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
loc_820D1FA8:
	// lfs f13,44(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 44);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,48(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 48);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fmuls f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * f0.f64));
	// stfs f13,44(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 44, temp.u32);
	// stfs f0,48(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 48, temp.u32);
loc_820D1FC0:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r4,40(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// addi r7,r1,100
	ctx.r7.s64 = ctx.r1.s64 + 100;
	// addi r6,r1,144
	ctx.r6.s64 = ctx.r1.s64 + 144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f25,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f25.f64 = double(temp.f32);
	// fmr f1,f25
	ctx.f1.f64 = f25.f64;
	// bl 0x820cff50
	sub_820CFF50(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d249c
	if (cr6.getEQ()) goto loc_820D249C;
	// lfs f0,32(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	f0.f64 = double(temp.f32);
	// addi r3,r1,352
	ctx.r3.s64 = ctx.r1.s64 + 352;
	// lfs f13,28(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// fneg f6,f0
	ctx.f6.u64 = f0.u64 ^ 0x8000000000000000;
	// lfs f12,24(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fneg f5,f13
	ctx.f5.u64 = ctx.f13.u64 ^ 0x8000000000000000;
	// lfs f9,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// fneg f4,f12
	ctx.f4.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// lfs f8,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// fmr f3,f25
	ctx.f3.f64 = f25.f64;
	// lfs f7,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// fmr f2,f25
	ctx.f2.f64 = f25.f64;
	// fmr f1,f25
	ctx.f1.f64 = f25.f64;
	// bl 0x8210c040
	sub_8210C040(ctx, base);
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// lis r11,-32164
	r11.s64 = -2107899904;
	// rlwinm r9,r28,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 4) & 0xFFFFFFF0;
	// lfs f30,44(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 44);
	f30.f64 = double(temp.f32);
	// addi r11,r11,-3616
	r11.s64 = r11.s64 + -3616;
	// lfs f28,48(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 48);
	f28.f64 = double(temp.f32);
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// lfs f24,52(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 52);
	f24.f64 = double(temp.f32);
	// lfs f23,56(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 56);
	f23.f64 = double(temp.f32);
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f27,60(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 60);
	f27.f64 = double(temp.f32);
	// lfs f26,64(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 64);
	f26.f64 = double(temp.f32);
	// lwzx r29,r9,r11
	r29.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// lfs f31,11980(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 11980);
	f31.f64 = double(temp.f32);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// addi r4,r1,288
	ctx.r4.s64 = ctx.r1.s64 + 288;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x8210b968
	sub_8210B968(ctx, base);
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// addi r3,r1,288
	ctx.r3.s64 = ctx.r1.s64 + 288;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// addi r3,r1,352
	ctx.r3.s64 = ctx.r1.s64 + 352;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d0a00
	sub_820D0A00(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// fsubs f0,f23,f24
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f23.f64 - f24.f64));
	// fsubs f13,f28,f30
	ctx.f13.f64 = double(float(f28.f64 - f30.f64));
	// fsubs f27,f26,f27
	f27.f64 = double(float(f26.f64 - f27.f64));
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// lfs f10,12(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,16(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// lfs f9,24(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 24);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// fdivs f31,f0,f12
	f31.f64 = double(float(f0.f64 / ctx.f12.f64));
	// lfs f0,16500(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16500);
	f0.f64 = double(temp.f32);
	// fdivs f30,f27,f11
	f30.f64 = double(float(f27.f64 / ctx.f11.f64));
	// fdivs f28,f13,f10
	f28.f64 = double(float(ctx.f13.f64 / ctx.f10.f64));
	// fcmpu cr6,f31,f0
	cr6.compare(f31.f64, f0.f64);
	// ble cr6,0x820d20fc
	if (!cr6.getGT()) goto loc_820D20FC;
	// fcmpu cr6,f30,f0
	cr6.compare(f30.f64, f0.f64);
	// ble cr6,0x820d20fc
	if (!cr6.getGT()) goto loc_820D20FC;
	// fcmpu cr6,f28,f0
	cr6.compare(f28.f64, f0.f64);
	// bgt cr6,0x820d213c
	if (cr6.getGT()) goto loc_820D213C;
loc_820D20FC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f3,f28
	ctx.fpscr.disableFlushMode();
	ctx.f3.f64 = f28.f64;
	// fmr f2,f30
	ctx.f2.f64 = f30.f64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// addi r3,r11,17016
	ctx.r3.s64 = r11.s64 + 17016;
	// stfd f3,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.f3.u64);
	// ld r7,48(r1)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r1.u32 + 48);
	// stfd f2,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.f2.u64);
	// ld r6,40(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 40);
	// stfd f1,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.f1.u64);
	// ld r5,32(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 32);
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// fmr f28,f29
	ctx.fpscr.disableFlushMode();
	f28.f64 = f29.f64;
	// fmr f30,f29
	f30.f64 = f29.f64;
	// fmr f31,f29
	f31.f64 = f29.f64;
loc_820D213C:
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x8210bc18
	sub_8210BC18(ctx, base);
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x8210bc40
	sub_8210BC40(ctx, base);
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// fmr f1,f28
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f28.f64;
	// bl 0x8210bca0
	sub_8210BCA0(ctx, base);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lfs f3,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f3.f64 = double(temp.f32);
	// clrlwi r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	// lfs f0,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	f0.f64 = double(temp.f32);
	// lfs f4,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f4.f64 = double(temp.f32);
	// stfs f3,160(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stfs f0,164(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// stfs f4,168(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// bne cr6,0x820d21f4
	if (!cr6.getEQ()) goto loc_820D21F4;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f2,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d21c0
	if (cr6.getEQ()) goto loc_820D21C0;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// b 0x820d220c
	goto loc_820D220C;
loc_820D21AC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r26,1
	ctx.r4.s64 = r26.s64 + 1;
	// addi r3,r11,16948
	ctx.r3.s64 = r11.s64 + 16948;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// b 0x820d1fc0
	goto loc_820D1FC0;
loc_820D21C0:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lfs f0,144(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	f0.f64 = double(temp.f32);
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// rlwinm r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	// lfs f0,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	f0.f64 = double(temp.f32);
	// stfs f0,120(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d220c
	if (!cr6.getEQ()) goto loc_820D220C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r26,1
	ctx.r4.s64 = r26.s64 + 1;
	// addi r3,r11,16896
	ctx.r3.s64 = r11.s64 + 16896;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// b 0x820d220c
	goto loc_820D220C;
loc_820D21F4:
	// lfs f0,144(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	f0.f64 = double(temp.f32);
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f0,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	f0.f64 = double(temp.f32);
	// stfs f0,116(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f0,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	f0.f64 = double(temp.f32);
	// stfs f0,120(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
loc_820D220C:
	// lhz r11,154(r30)
	r11.u64 = PPC_LOAD_U16(r30.u32 + 154);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x820d2244
	if (cr6.getEQ()) goto loc_820D2244;
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// beq cr6,0x820d2244
	if (cr6.getEQ()) goto loc_820D2244;
	// fsubs f0,f24,f23
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f24.f64 - f23.f64));
	// lfs f13,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f13,128(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fmuls f13,f12,f0
	ctx.f13.f64 = double(float(ctx.f12.f64 * f0.f64));
	// fmuls f0,f0,f11
	f0.f64 = double(float(f0.f64 * ctx.f11.f64));
	// b 0x820d2260
	goto loc_820D2260;
loc_820D2244:
	// lfs f0,24(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 24);
	f0.f64 = double(temp.f32);
	// fmuls f0,f27,f0
	f0.f64 = double(float(f27.f64 * f0.f64));
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f13,28(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,32(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	f0.f64 = double(temp.f32);
	// fmuls f13,f27,f13
	ctx.f13.f64 = double(float(f27.f64 * ctx.f13.f64));
	// fmuls f0,f27,f0
	f0.f64 = double(float(f27.f64 * f0.f64));
loc_820D2260:
	// lwz r10,136(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 136);
	// stfs f13,132(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lwz r9,140(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 140);
	// stfs f0,136(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// lwz r6,144(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 144);
	// lwz r5,148(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 148);
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// extsw r3,r6
	ctx.r3.s64 = ctx.r6.s32;
	// lwz r11,132(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 132);
	// extsw r31,r5
	r31.s64 = ctx.r5.s32;
	// lwz r6,100(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r10,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, ctx.r10.u64);
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// std r9,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, ctx.r9.u64);
	// addi r7,r1,128
	ctx.r7.s64 = ctx.r1.s64 + 128;
	// std r3,208(r1)
	PPC_STORE_U64(ctx.r1.u32 + 208, ctx.r3.u64);
	// addi r5,r1,224
	ctx.r5.s64 = ctx.r1.s64 + 224;
	// std r31,184(r1)
	PPC_STORE_U64(ctx.r1.u32 + 184, r31.u64);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// frsp f9,f0
	ctx.f9.f64 = double(float(f0.f64));
	// lfs f0,15620(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15620);
	f0.f64 = double(temp.f32);
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * f0.f64));
	// stfs f9,132(r30)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(r30.u32 + 132, temp.u32);
	// lfd f13,200(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 200);
	// lfd f12,192(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// lfd f11,208(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 208);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// lfd f10,184(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 184);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// fcfid f10,f10
	ctx.f10.f64 = double(ctx.f10.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,136(r30)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r30.u32 + 136, temp.u32);
	// fmuls f13,f12,f0
	ctx.f13.f64 = double(float(ctx.f12.f64 * f0.f64));
	// stfs f13,140(r30)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r30.u32 + 140, temp.u32);
	// fmuls f13,f11,f0
	ctx.f13.f64 = double(float(ctx.f11.f64 * f0.f64));
	// stfs f13,144(r30)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r30.u32 + 144, temp.u32);
	// fmuls f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 * f0.f64));
	// stfs f0,148(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 148, temp.u32);
	// bl 0x820dd4f8
	sub_820DD4F8(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// rlwinm r11,r11,0,3,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d2374
	if (cr6.getEQ()) goto loc_820D2374;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// stw r27,236(r30)
	PPC_STORE_U32(r30.u32 + 236, r27.u32);
	// blt cr6,0x820d2364
	if (cr6.getLT()) goto loc_820D2364;
	// lfs f0,180(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 180);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f25
	cr6.compare(f0.f64, f25.f64);
	// bne cr6,0x820d2364
	if (!cr6.getEQ()) goto loc_820D2364;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820dd4e0
	sub_820DD4E0(ctx, base);
	// b 0x820d2374
	goto loc_820D2374;
loc_820D2364:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r26,1
	ctx.r4.s64 = r26.s64 + 1;
	// addi r3,r11,16856
	ctx.r3.s64 = r11.s64 + 16856;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
loc_820D2374:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// stb r10,48(r31)
	PPC_STORE_U8(r31.u32 + 48, ctx.r10.u8);
	// lbz r4,3(r11)
	ctx.r4.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// bl 0x820cead0
	sub_820CEAD0(ctx, base);
	// li r11,255
	r11.s64 = 255;
	// stb r11,49(r31)
	PPC_STORE_U8(r31.u32 + 49, r11.u8);
	// stb r11,50(r31)
	PPC_STORE_U8(r31.u32 + 50, r11.u8);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r10,r11,0,3,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820d23b4
	if (!cr6.getEQ()) goto loc_820D23B4;
	// rlwinm r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d2430
	if (cr6.getEQ()) goto loc_820D2430;
loc_820D23B4:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmpw cr6,r11,r25
	cr6.compare<int32_t>(r11.s32, r25.s32, xer);
	// beq cr6,0x820d23d8
	if (cr6.getEQ()) goto loc_820D23D8;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// blt cr6,0x820d23f0
	if (cr6.getLT()) goto loc_820D23F0;
	// extsh r4,r25
	ctx.r4.s64 = r25.s16;
	// stb r25,49(r31)
	PPC_STORE_U8(r31.u32 + 49, r25.u8);
	// b 0x820d23e8
	goto loc_820D23E8;
loc_820D23D8:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// blt cr6,0x820d23f0
	if (cr6.getLT()) goto loc_820D23F0;
	// extsh r4,r24
	ctx.r4.s64 = r24.s16;
	// stb r24,49(r31)
	PPC_STORE_U8(r31.u32 + 49, r24.u8);
loc_820D23E8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cead0
	sub_820CEAD0(ctx, base);
loc_820D23F0:
	// lbz r11,49(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 49);
	// cmplwi cr6,r11,255
	cr6.compare<uint32_t>(r11.u32, 255, xer);
	// bne cr6,0x820d2408
	if (!cr6.getEQ()) goto loc_820D2408;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r11,16816
	ctx.r3.s64 = r11.s64 + 16816;
	// b 0x820d2428
	goto loc_820D2428;
loc_820D2408:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmpw cr6,r25,r11
	cr6.compare<int32_t>(r25.s32, r11.s32, xer);
	// beq cr6,0x820d2430
	if (cr6.getEQ()) goto loc_820D2430;
	// cmpw cr6,r24,r11
	cr6.compare<int32_t>(r24.s32, r11.s32, xer);
	// beq cr6,0x820d2430
	if (cr6.getEQ()) goto loc_820D2430;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r11,16780
	ctx.r3.s64 = r11.s64 + 16780;
loc_820D2428:
	// addi r4,r26,1
	ctx.r4.s64 = r26.s64 + 1;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
loc_820D2430:
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d2464
	if (cr6.getEQ()) goto loc_820D2464;
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = f31.f64;
	// fcmpu cr6,f30,f31
	cr6.compare(f30.f64, f31.f64);
	// ble cr6,0x820d244c
	if (!cr6.getGT()) goto loc_820D244C;
	// fmr f0,f30
	f0.f64 = f30.f64;
loc_820D244C:
	// fcmpu cr6,f28,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(f28.f64, f0.f64);
	// ble cr6,0x820d2458
	if (!cr6.getGT()) goto loc_820D2458;
	// fmr f0,f28
	f0.f64 = f28.f64;
loc_820D2458:
	// lfs f13,20(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x823ada90
	sub_823ADA90(ctx, base);
loc_820D2464:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ccb20
	sub_820CCB20(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cca18
	sub_820CCA18(ctx, base);
	// lwz r11,128(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 128);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820d24b4
	if (cr6.getEQ()) goto loc_820D24B4;
	// add r3,r11,r26
	ctx.r3.u64 = r11.u64 + r26.u64;
	// bl 0x820d0288
	sub_820D0288(ctx, base);
	// stw r3,200(r30)
	PPC_STORE_U32(r30.u32 + 200, ctx.r3.u32);
	// addi r1,r1,560
	ctx.r1.s64 = ctx.r1.s64 + 560;
	// addi r12,r1,-72
	r12.s64 = ctx.r1.s64 + -72;
	// bl 0x823ed580
	// b 0x823ed178
	return;
loc_820D249C:
	// li r10,0
	ctx.r10.s64 = 0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r26,1
	ctx.r4.s64 = r26.s64 + 1;
	// addi r3,r11,16728
	ctx.r3.s64 = r11.s64 + 16728;
	// stw r10,16(r30)
	PPC_STORE_U32(r30.u32 + 16, ctx.r10.u32);
	// bl 0x823ed380
	sub_823ED380(ctx, base);
loc_820D24B4:
	// addi r1,r1,560
	ctx.r1.s64 = ctx.r1.s64 + 560;
	// addi r12,r1,-72
	r12.s64 = ctx.r1.s64 + -72;
	// bl 0x823ed580
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_820D24C8"))) PPC_WEAK_FUNC(sub_820D24C8);
PPC_FUNC_IMPL(__imp__sub_820D24C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed114
	// addi r12,r1,-112
	r12.s64 = ctx.r1.s64 + -112;
	// bl 0x823ed538
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d24f8
	if (cr6.getEQ()) goto loc_820D24F8;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x8217ee78
	sub_8217EE78(ctx, base);
loc_820D24F8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r20,-32190
	r20.s64 = -2109603840;
	// lfs f0,2776(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// stfs f0,19392(r20)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r20.u32 + 19392, temp.u32);
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820d251c
	if (!cr6.getGT()) goto loc_820D251C;
	// bl 0x82113140
	sub_82113140(ctx, base);
	// b 0x820d2520
	goto loc_820D2520;
loc_820D251C:
	// bl 0x82113120
	sub_82113120(ctx, base);
loc_820D2520:
	// cmpwi cr6,r19,59
	cr6.compare<int32_t>(r19.s32, 59, xer);
	// bge cr6,0x820d3628
	if (!cr6.getLT()) goto loc_820D3628;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d3628
	if (cr6.getEQ()) goto loc_820D3628;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,72
	ctx.r4.s64 = 72;
	// bl 0x8209cca0
	sub_8209CCA0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// stw r31,920(r11)
	PPC_STORE_U32(r11.u32 + 920, r31.u32);
	// bl 0x82136728
	sub_82136728(ctx, base);
	// bl 0x82136a40
	sub_82136A40(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,40(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x8209cca0
	sub_8209CCA0(ctx, base);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r25,r11,928
	r25.s64 = r11.s64 + 928;
	// stw r3,0(r25)
	PPC_STORE_U32(r25.u32 + 0, ctx.r3.u32);
	// lwz r4,44(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// bl 0x8209cca0
	sub_8209CCA0(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r3,4(r25)
	PPC_STORE_U32(r25.u32 + 4, ctx.r3.u32);
	// lwz r4,48(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x8209cca0
	sub_8209CCA0(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r3,8(r25)
	PPC_STORE_U32(r25.u32 + 8, ctx.r3.u32);
	// lwz r4,52(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x8209cca0
	sub_8209CCA0(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r3,12(r25)
	PPC_STORE_U32(r25.u32 + 12, ctx.r3.u32);
	// lwz r4,56(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x8209cca0
	sub_8209CCA0(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r3,16(r25)
	PPC_STORE_U32(r25.u32 + 16, ctx.r3.u32);
	// lwz r4,60(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// bl 0x8209cca0
	sub_8209CCA0(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r3,20(r25)
	PPC_STORE_U32(r25.u32 + 20, ctx.r3.u32);
	// lwz r4,64(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// bl 0x8209cca0
	sub_8209CCA0(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r3,24(r25)
	PPC_STORE_U32(r25.u32 + 24, ctx.r3.u32);
	// lwz r4,68(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// bl 0x8209cca0
	sub_8209CCA0(ctx, base);
	// stw r3,28(r25)
	PPC_STORE_U32(r25.u32 + 28, ctx.r3.u32);
	// li r21,0
	r21.s64 = 0;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r11,16(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r10,32(r25)
	PPC_STORE_U32(r25.u32 + 32, ctx.r10.u32);
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// stw r10,36(r25)
	PPC_STORE_U32(r25.u32 + 36, ctx.r10.u32);
	// beq cr6,0x820d2678
	if (cr6.getEQ()) goto loc_820D2678;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820d2678
	if (cr6.getEQ()) goto loc_820D2678;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
loc_820D2630:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// blt cr6,0x820d2654
	if (cr6.getLT()) goto loc_820D2654;
loc_820D2640:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bge cr6,0x820d2640
	if (!cr6.getLT()) goto loc_820D2640;
loc_820D2654:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// sth r9,6(r11)
	PPC_STORE_U16(r11.u32 + 6, ctx.r9.u16);
	// lwz r11,16(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 16);
	// rlwinm r10,r8,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820d2630
	if (!cr6.getEQ()) goto loc_820D2630;
	// lwz r3,28(r25)
	ctx.r3.u64 = PPC_LOAD_U32(r25.u32 + 28);
loc_820D2678:
	// lwz r31,24(r25)
	r31.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// lis r26,-32123
	r26.s64 = -2105212928;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820d276c
	if (cr6.getEQ()) goto loc_820D276C;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// lfs f31,32580(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r26.u32 + 32580);
	f31.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d276c
	if (cr6.getEQ()) goto loc_820D276C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r28,r11,17480
	r28.s64 = r11.s64 + 17480;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r27,r11,17444
	r27.s64 = r11.s64 + 17444;
	// lis r11,11915
	r11.s64 = 780861440;
	// ori r30,r11,41705
	r30.u64 = r11.u64 | 41705;
loc_820D26B0:
	// addi r29,r31,40
	r29.s64 = r31.s64 + 40;
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f13,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f12,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// lwz r4,36(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * f31.f64));
	// stfs f0,0(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * f31.f64));
	// stfs f13,4(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// stfs f12,8(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// bl 0x82138120
	sub_82138120(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820d271c
	if (!cr6.getEQ()) goto loc_820D271C;
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,36(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// subf r11,r11,r31
	r11.s64 = r31.s64 - r11.s64;
	// mulhw r11,r11,r30
	r11.s64 = (int64_t(r11.s32) * int64_t(r30.s32)) >> 32;
	// srawi r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	// rlwinm r10,r11,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r4,r11,1
	ctx.r4.s64 = r11.s64 + 1;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// b 0x820d2758
	goto loc_820D2758;
loc_820D271C:
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// bne cr6,0x820d2758
	if (!cr6.getEQ()) goto loc_820D2758;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// bl 0x8210e518
	sub_8210E518(ctx, base);
	// lwz r11,24(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 24);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,36(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// subf r11,r11,r31
	r11.s64 = r31.s64 - r11.s64;
	// mulhw r11,r11,r30
	r11.s64 = (int64_t(r11.s32) * int64_t(r30.s32)) >> 32;
	// srawi r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	// rlwinm r10,r11,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r4,r11,1
	ctx.r4.s64 = r11.s64 + 1;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
loc_820D2758:
	// addi r31,r31,44
	r31.s64 = r31.s64 + 44;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d26b0
	if (!cr6.getEQ()) goto loc_820D26B0;
	// lwz r3,28(r25)
	ctx.r3.u64 = PPC_LOAD_U32(r25.u32 + 28);
loc_820D276C:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d28a0
	if (cr6.getEQ()) goto loc_820D28A0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lfs f31,32580(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r26.u32 + 32580);
	f31.f64 = double(temp.f32);
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d28a0
	if (cr6.getEQ()) goto loc_820D28A0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r28,r11,17400
	r28.s64 = r11.s64 + 17400;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r27,r11,17364
	r27.s64 = r11.s64 + 17364;
	// lis r11,30840
	r11.s64 = 2021130240;
	// ori r30,r11,30841
	r30.u64 = r11.u64 | 30841;
loc_820D27A0:
	// addi r29,r31,40
	r29.s64 = r31.s64 + 40;
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f13,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f12,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lfs f11,44(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 44);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// lfs f10,48(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 48);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * f31.f64));
	// lfs f9,52(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 52);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f12,f12,f31
	ctx.f12.f64 = double(float(ctx.f12.f64 * f31.f64));
	// lfs f8,56(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 56);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f11,f11,f31
	ctx.f11.f64 = double(float(ctx.f11.f64 * f31.f64));
	// lfs f7,60(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 60);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f10,f10,f31
	ctx.f10.f64 = double(float(ctx.f10.f64 * f31.f64));
	// lfs f6,64(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 64);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f9,f9,f31
	ctx.f9.f64 = double(float(ctx.f9.f64 * f31.f64));
	// fmuls f8,f8,f31
	ctx.f8.f64 = double(float(ctx.f8.f64 * f31.f64));
	// lwz r4,36(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// fmuls f7,f7,f31
	ctx.f7.f64 = double(float(ctx.f7.f64 * f31.f64));
	// stfs f0,0(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// fmuls f6,f6,f31
	ctx.f6.f64 = double(float(ctx.f6.f64 * f31.f64));
	// stfs f13,4(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// stfs f12,8(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// stfs f11,44(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r31.u32 + 44, temp.u32);
	// stfs f10,48(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(r31.u32 + 48, temp.u32);
	// stfs f9,52(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(r31.u32 + 52, temp.u32);
	// stfs f8,56(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(r31.u32 + 56, temp.u32);
	// stfs f7,60(r31)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(r31.u32 + 60, temp.u32);
	// stfs f6,64(r31)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(r31.u32 + 64, temp.u32);
	// bl 0x82138120
	sub_82138120(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820d2854
	if (!cr6.getEQ()) goto loc_820D2854;
	// lwz r11,28(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 28);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r5,36(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// subf r11,r11,r31
	r11.s64 = r31.s64 - r11.s64;
	// mulhw r11,r11,r30
	r11.s64 = (int64_t(r11.s32) * int64_t(r30.s32)) >> 32;
	// srawi r11,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	r11.s64 = r11.s32 >> 5;
	// rlwinm r10,r11,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r4,r11,1
	ctx.r4.s64 = r11.s64 + 1;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// b 0x820d2890
	goto loc_820D2890;
loc_820D2854:
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// bne cr6,0x820d2890
	if (!cr6.getEQ()) goto loc_820D2890;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// bl 0x8210e518
	sub_8210E518(ctx, base);
	// lwz r11,28(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 28);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r5,36(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// subf r11,r11,r31
	r11.s64 = r31.s64 - r11.s64;
	// mulhw r11,r11,r30
	r11.s64 = (int64_t(r11.s32) * int64_t(r30.s32)) >> 32;
	// srawi r11,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	r11.s64 = r11.s32 >> 5;
	// rlwinm r10,r11,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r4,r11,1
	ctx.r4.s64 = r11.s64 + 1;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
loc_820D2890:
	// addi r31,r31,68
	r31.s64 = r31.s64 + 68;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d27a0
	if (!cr6.getEQ()) goto loc_820D27A0;
loc_820D28A0:
	// li r3,9
	ctx.r3.s64 = 9;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// bl 0x82120f78
	sub_82120F78(ctx, base);
	// li r3,9
	ctx.r3.s64 = 9;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,8
	ctx.r3.s64 = 8;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,4
	ctx.r3.s64 = 4;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,17
	ctx.r3.s64 = 17;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,6
	ctx.r3.s64 = 6;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,13
	ctx.r3.s64 = 13;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,12
	ctx.r3.s64 = 12;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,10
	ctx.r3.s64 = 10;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,11
	ctx.r3.s64 = 11;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,21
	ctx.r3.s64 = 21;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,3
	ctx.r3.s64 = 3;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,42
	ctx.r3.s64 = 42;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,47
	ctx.r3.s64 = 47;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,43
	ctx.r3.s64 = 43;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,41
	ctx.r3.s64 = 41;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,36
	ctx.r3.s64 = 36;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,5
	ctx.r3.s64 = 5;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,7
	ctx.r3.s64 = 7;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,20
	ctx.r3.s64 = 20;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,39
	ctx.r3.s64 = 39;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,45
	ctx.r3.s64 = 45;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,40
	ctx.r3.s64 = 40;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// add r31,r11,r31
	r31.u64 = r11.u64 + r31.u64;
	// bl 0x82118930
	sub_82118930(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821189e8
	sub_821189E8(ctx, base);
	// mr r31,r21
	r31.u64 = r21.u64;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x820d2a58
	if (!cr6.getGT()) goto loc_820D2A58;
loc_820D2A34:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// li r3,14
	ctx.r3.s64 = 14;
	// bl 0x820d0998
	sub_820D0998(ctx, base);
	// bl 0x820c2800
	sub_820C2800(ctx, base);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpw cr6,r31,r3
	cr6.compare<int32_t>(r31.s32, ctx.r3.s32, xer);
	// blt cr6,0x820d2a34
	if (cr6.getLT()) goto loc_820D2A34;
loc_820D2A58:
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d3678
	if (cr6.getEQ()) goto loc_820D3678;
	// bl 0x8209f598
	sub_8209F598(ctx, base);
	// addi r11,r3,4
	r11.s64 = ctx.r3.s64 + 4;
	// li r31,1
	r31.s64 = 1;
	// slw r27,r31,r11
	r27.u64 = r11.u8 & 0x20 ? 0 : (r31.u32 << (r11.u8 & 0x3F));
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820d2a90
	if (!cr6.getGT()) goto loc_820D2A90;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// addi r11,r3,20
	r11.s64 = ctx.r3.s64 + 20;
	// slw r11,r31,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r31.u32 << (r11.u8 & 0x3F));
	// or r27,r11,r27
	r27.u64 = r11.u64 | r27.u64;
loc_820D2A90:
	// lwz r31,12(r25)
	r31.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// mr r28,r21
	r28.u64 = r21.u64;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// beq cr6,0x820d3238
	if (cr6.getEQ()) goto loc_820D3238;
	// lis r4,-32256
	ctx.r4.s64 = -2113929216;
	// lis r5,-32256
	ctx.r5.s64 = -2113929216;
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// lis r7,-32256
	ctx.r7.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f26,3904(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 3904);
	f26.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f27,6580(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 6580);
	f27.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f24,15416(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 15416);
	f24.f64 = double(temp.f32);
	// lfs f25,6588(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 6588);
	f25.f64 = double(temp.f32);
	// lis r26,-32013
	r26.s64 = -2098003968;
	// lfs f31,2688(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 2688);
	f31.f64 = double(temp.f32);
	// lis r22,-31994
	r22.s64 = -2096758784;
	// lfs f30,2952(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2952);
	f30.f64 = double(temp.f32);
	// addi r23,r11,17312
	r23.s64 = r11.s64 + 17312;
	// lfs f28,15620(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15620);
	f28.f64 = double(temp.f32);
	// li r24,-1
	r24.s64 = -1;
loc_820D2AF0:
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplwi cr6,r11,46
	cr6.compare<uint32_t>(r11.u32, 46, xer);
	// bgt cr6,0x820d3214
	if (cr6.getGT()) goto loc_820D3214;
	// lis r12,-32243
	r12.s64 = -2113077248;
	// addi r12,r12,11032
	r12.s64 = r12.s64 + 11032;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820D2C38;
	case 1:
		goto loc_820D2C5C;
	case 2:
		goto loc_820D2CA4;
	case 3:
		goto loc_820D2CA4;
	case 4:
		goto loc_820D2CA4;
	case 5:
		goto loc_820D2CEC;
	case 6:
		goto loc_820D2CA4;
	case 7:
		goto loc_820D2C80;
	case 8:
		goto loc_820D2C24;
	case 9:
		goto loc_820D2D34;
	case 10:
		goto loc_820D2D58;
	case 11:
		goto loc_820D2CA4;
	case 12:
		goto loc_820D2D10;
	case 13:
		goto loc_820D3214;
	case 14:
		goto loc_820D3214;
	case 15:
		goto loc_820D3214;
	case 16:
		goto loc_820D2CC8;
	case 17:
		goto loc_820D2BD4;
	case 18:
		goto loc_820D3214;
	case 19:
		goto loc_820D2EB4;
	case 20:
		goto loc_820D2D7C;
	case 21:
		goto loc_820D30CC;
	case 22:
		goto loc_820D31E8;
	case 23:
		goto loc_820D3214;
	case 24:
		goto loc_820D3214;
	case 25:
		goto loc_820D3214;
	case 26:
		goto loc_820D3214;
	case 27:
		goto loc_820D3214;
	case 28:
		goto loc_820D3214;
	case 29:
		goto loc_820D320C;
	case 30:
		goto loc_820D3214;
	case 31:
		goto loc_820D31F4;
	case 32:
		goto loc_820D3200;
	case 33:
		goto loc_820D3214;
	case 34:
		goto loc_820D3138;
	case 35:
		goto loc_820D2CA4;
	case 36:
		goto loc_820D3104;
	case 37:
		goto loc_820D3214;
	case 38:
		goto loc_820D2FC4;
	case 39:
		goto loc_820D3068;
	case 40:
		goto loc_820D2CA4;
	case 41:
		goto loc_820D2CA4;
	case 42:
		goto loc_820D2CA4;
	case 43:
		goto loc_820D3214;
	case 44:
		goto loc_820D2F4C;
	case 45:
		goto loc_820D3144;
	case 46:
		goto loc_820D2DD0;
	default:
		__builtin_unreachable();
	}
	// lwz r16,11320(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11320);
	// lwz r16,11356(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11356);
	// lwz r16,11428(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11428);
	// lwz r16,11428(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11428);
	// lwz r16,11428(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11428);
	// lwz r16,11500(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11500);
	// lwz r16,11428(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11428);
	// lwz r16,11392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11392);
	// lwz r16,11300(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11300);
	// lwz r16,11572(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11572);
	// lwz r16,11608(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11608);
	// lwz r16,11428(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11428);
	// lwz r16,11536(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11536);
	// lwz r16,12820(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12820);
	// lwz r16,12820(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12820);
	// lwz r16,12820(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12820);
	// lwz r16,11464(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11464);
	// lwz r16,11220(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11220);
	// lwz r16,12820(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12820);
	// lwz r16,11956(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11956);
	// lwz r16,11644(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11644);
	// lwz r16,12492(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12492);
	// lwz r16,12776(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12776);
	// lwz r16,12820(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12820);
	// lwz r16,12820(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12820);
	// lwz r16,12820(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12820);
	// lwz r16,12820(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12820);
	// lwz r16,12820(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12820);
	// lwz r16,12820(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12820);
	// lwz r16,12812(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12812);
	// lwz r16,12820(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12820);
	// lwz r16,12788(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12788);
	// lwz r16,12800(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12800);
	// lwz r16,12820(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12820);
	// lwz r16,12600(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12600);
	// lwz r16,11428(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11428);
	// lwz r16,12548(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12548);
	// lwz r16,12820(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12820);
	// lwz r16,12228(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12228);
	// lwz r16,12392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12392);
	// lwz r16,11428(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11428);
	// lwz r16,11428(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11428);
	// lwz r16,11428(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11428);
	// lwz r16,12820(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12820);
	// lwz r16,12108(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12108);
	// lwz r16,12612(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 12612);
	// lwz r16,11728(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 11728);
loc_820D2BD4:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi r30,r11,24
	r30.u64 = r11.u32 & 0xFF;
	// bl 0x82120230
	sub_82120230(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d2c0c
	if (cr6.getEQ()) goto loc_820D2C0C;
	// lwz r11,24(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d2c0c
	if (cr6.getEQ()) goto loc_820D2C0C;
	// lwz r11,28(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d2c0c
	if (cr6.getEQ()) goto loc_820D2C0C;
	// stb r30,16(r3)
	PPC_STORE_U8(ctx.r3.u32 + 16, r30.u8);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2C0C:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r5,r28,1
	ctx.r5.s64 = r28.s64 + 1;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// addi r4,r11,1
	ctx.r4.s64 = r11.s64 + 1;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2C24:
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x82136340
	sub_82136340(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2C38:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// and r11,r11,r27
	r11.u64 = r11.u64 & r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d3214
	if (!cr6.getEQ()) goto loc_820D3214;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d1e00
	sub_820D1E00(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2C5C:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,19392(r20)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r20.u32 + 19392, temp.u32);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2C80:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// and r11,r11,r27
	r11.u64 = r11.u64 & r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d3214
	if (!cr6.getEQ()) goto loc_820D3214;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d1340
	sub_820D1340(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2CA4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// and r11,r11,r27
	r11.u64 = r11.u64 & r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d3214
	if (!cr6.getEQ()) goto loc_820D3214;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d0b08
	sub_820D0B08(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2CC8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// and r11,r11,r27
	r11.u64 = r11.u64 & r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d3214
	if (!cr6.getEQ()) goto loc_820D3214;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d1570
	sub_820D1570(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2CEC:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// and r11,r11,r27
	r11.u64 = r11.u64 & r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d3214
	if (!cr6.getEQ()) goto loc_820D3214;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d1608
	sub_820D1608(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2D10:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// and r11,r11,r27
	r11.u64 = r11.u64 & r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d3214
	if (!cr6.getEQ()) goto loc_820D3214;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d1800
	sub_820D1800(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2D34:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// and r11,r11,r27
	r11.u64 = r11.u64 & r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d3214
	if (!cr6.getEQ()) goto loc_820D3214;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d19b8
	sub_820D19B8(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2D58:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// and r11,r11,r27
	r11.u64 = r11.u64 & r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d3214
	if (!cr6.getEQ()) goto loc_820D3214;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d1bd0
	sub_820D1BD0(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2D7C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// and r11,r11,r27
	r11.u64 = r11.u64 & r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d2d98
	if (cr6.getEQ()) goto loc_820D2D98;
	// lwz r11,11488(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 11488);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820d3214
	if (cr6.getEQ()) goto loc_820D3214;
loc_820D2D98:
	// lwz r11,128(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,128(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 128, temp.u32);
	// stfs f0,132(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 132, temp.u32);
	// bl 0x820d0b08
	sub_820D0B08(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2DD0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// and r11,r11,r27
	r11.u64 = r11.u64 & r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d3214
	if (!cr6.getEQ()) goto loc_820D3214;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,3,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d2ea0
	if (cr6.getEQ()) goto loc_820D2EA0;
	// lhz r11,6(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 6);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,10000
	cr6.compare<int32_t>(r11.s32, 10000, xer);
	// blt cr6,0x820d2ea0
	if (cr6.getLT()) goto loc_820D2EA0;
	// addi r11,r11,-10000
	r11.s64 = r11.s64 + -10000;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mulli r10,r11,68
	ctx.r10.s64 = r11.s64 * 68;
	// lwz r11,28(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 28);
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// bl 0x820d0a00
	sub_820D0A00(ctx, base);
	// lfs f13,12(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	f0.f64 = double(temp.f32);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// fmadds f13,f13,f30,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f30.f64 + f0.f64));
	// stfs f13,160(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f12,16(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// lfs f13,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f12,f12,f30,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * f30.f64 + ctx.f13.f64));
	// stfs f12,164(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f11,20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f11,f11,f30,f12
	ctx.f11.f64 = double(float(ctx.f11.f64 * f30.f64 + ctx.f12.f64));
	// stfs f11,168(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// lfs f11,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f0,f11,f30,f0
	f0.f64 = double(float(-(ctx.f11.f64 * f30.f64 - f0.f64)));
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f0,16(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	f0.f64 = double(temp.f32);
	// fnmsubs f0,f0,f30,f13
	f0.f64 = double(float(-(f0.f64 * f30.f64 - ctx.f13.f64)));
	// stfs f0,148(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f0,20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	f0.f64 = double(temp.f32);
	// fnmsubs f0,f0,f30,f12
	f0.f64 = double(float(-(f0.f64 * f30.f64 - ctx.f12.f64)));
	// stfs f0,152(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// bl 0x82117238
	sub_82117238(ctx, base);
	// lwz r11,144(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 144);
	// stw r3,140(r31)
	PPC_STORE_U32(r31.u32 + 140, ctx.r3.u32);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lfd f0,96(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,144(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 144, temp.u32);
loc_820D2EA0:
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d0b08
	sub_820D0B08(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2EB4:
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820d2ef4
	if (!cr6.getGT()) goto loc_820D2EF4;
	// bl 0x820eaab8
	sub_820EAAB8(ctx, base);
	// lwz r11,1000(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 1000);
	// rlwinm r11,r11,3,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// lbz r9,1(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// extsb r11,r10
	r11.s64 = ctx.r10.s8;
	// extsb r10,r9
	ctx.r10.s64 = ctx.r9.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r31
	ctx.r10.u64 = ctx.r10.u64 + r31.u64;
	// sth r11,126(r10)
	PPC_STORE_U16(ctx.r10.u32 + 126, r11.u16);
	// ble cr6,0x820d3214
	if (!cr6.getGT()) goto loc_820D3214;
loc_820D2EF4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// and r11,r11,r27
	r11.u64 = r11.u64 & r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d3214
	if (!cr6.getEQ()) goto loc_820D3214;
	// addi r30,r31,128
	r30.s64 = r31.s64 + 128;
	// li r29,13
	r29.s64 = 13;
loc_820D2F0C:
	// lhz r11,2(r30)
	r11.u64 = PPC_LOAD_U16(r30.u32 + 2);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d2f28
	if (cr6.getEQ()) goto loc_820D2F28;
	// lhz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U16(r30.u32 + 0);
	// cmplwi cr6,r3,65535
	cr6.compare<uint32_t>(ctx.r3.u32, 65535, xer);
	// beq cr6,0x820d2f28
	if (cr6.getEQ()) goto loc_820D2F28;
	// bl 0x820d03e8
	sub_820D03E8(ctx, base);
loc_820D2F28:
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x820d2f0c
	if (!cr6.getEQ()) goto loc_820D2F0C;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d0b08
	sub_820D0B08(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2F4C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// and r11,r11,r27
	r11.u64 = r11.u64 & r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d3214
	if (!cr6.getEQ()) goto loc_820D3214;
	// li r3,32
	ctx.r3.s64 = 32;
	// fmr f29,f31
	ctx.fpscr.disableFlushMode();
	f29.f64 = f31.f64;
	// bl 0x820bfe00
	sub_820BFE00(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d0b08
	sub_820D0B08(ctx, base);
	// lfs f2,64(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 64);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,56(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 56);
	ctx.f1.f64 = double(temp.f32);
	// stfs f31,200(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 200, temp.u32);
	// stfs f31,204(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 204, temp.u32);
	// bl 0x8210ae20
	sub_8210AE20(ctx, base);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// fsubs f0,f25,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f25.f64 - ctx.f1.f64));
	// stfs f0,220(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 220, temp.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d2fb4
	if (cr6.getEQ()) goto loc_820D2FB4;
	// lfs f2,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lfs f1,12(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x821108b0
	sub_821108B0(ctx, base);
	// fmr f29,f1
	ctx.fpscr.disableFlushMode();
	f29.f64 = ctx.f1.f64;
loc_820D2FB4:
	// fmuls f0,f29,f24
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f29.f64 * f24.f64));
	// stfs f29,212(r31)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r31.u32 + 212, temp.u32);
	// stfs f0,208(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 208, temp.u32);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D2FC4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// and r11,r11,r27
	r11.u64 = r11.u64 & r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d3214
	if (!cr6.getEQ()) goto loc_820D3214;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d0b08
	sub_820D0B08(ctx, base);
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d301c
	if (cr6.getEQ()) goto loc_820D301C;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820d301c
	if (cr6.getEQ()) goto loc_820D301C;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm r11,r11,4,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0x1;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
loc_820D301C:
	// stfs f31,136(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 136, temp.u32);
	// stw r21,140(r31)
	PPC_STORE_U32(r31.u32 + 140, r21.u32);
	// stw r21,144(r31)
	PPC_STORE_U32(r31.u32 + 144, r21.u32);
	// stw r21,148(r31)
	PPC_STORE_U32(r31.u32 + 148, r21.u32);
	// stw r21,152(r31)
	PPC_STORE_U32(r31.u32 + 152, r21.u32);
	// lwz r3,128(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// stfs f31,156(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 156, temp.u32);
	// stfs f31,160(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 160, temp.u32);
	// stfs f27,164(r31)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r31.u32 + 164, temp.u32);
	// stfs f31,168(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 168, temp.u32);
	// stfs f31,172(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 172, temp.u32);
	// bl 0x82131850
	sub_82131850(ctx, base);
	// stw r3,128(r31)
	PPC_STORE_U32(r31.u32 + 128, ctx.r3.u32);
	// sth r21,132(r31)
	PPC_STORE_U16(r31.u32 + 132, r21.u16);
	// sth r24,134(r31)
	PPC_STORE_U16(r31.u32 + 134, r24.u16);
	// stw r21,176(r31)
	PPC_STORE_U32(r31.u32 + 176, r21.u32);
	// stw r21,180(r31)
	PPC_STORE_U32(r31.u32 + 180, r21.u32);
	// stw r21,184(r31)
	PPC_STORE_U32(r31.u32 + 184, r21.u32);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D3068:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// and r11,r11,r27
	r11.u64 = r11.u64 & r27.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d3214
	if (!cr6.getEQ()) goto loc_820D3214;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d0b08
	sub_820D0B08(ctx, base);
	// lwz r3,128(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 128);
	// stfs f31,152(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 152, temp.u32);
	// stfs f31,156(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 156, temp.u32);
	// stfs f27,160(r31)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r31.u32 + 160, temp.u32);
	// stfs f31,136(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 136, temp.u32);
	// stfs f31,140(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 140, temp.u32);
	// stfs f31,144(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 144, temp.u32);
	// stfs f27,148(r31)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r31.u32 + 148, temp.u32);
	// stfs f31,164(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 164, temp.u32);
	// bl 0x82131850
	sub_82131850(ctx, base);
	// stw r3,128(r31)
	PPC_STORE_U32(r31.u32 + 128, ctx.r3.u32);
	// sth r21,132(r31)
	PPC_STORE_U16(r31.u32 + 132, r21.u16);
	// sth r24,134(r31)
	PPC_STORE_U16(r31.u32 + 134, r24.u16);
	// stw r21,168(r31)
	PPC_STORE_U32(r31.u32 + 168, r21.u32);
	// stw r21,172(r31)
	PPC_STORE_U32(r31.u32 + 172, r21.u32);
	// stw r21,176(r31)
	PPC_STORE_U32(r31.u32 + 176, r21.u32);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D30CC:
	// lhz r11,6(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 6);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// add r4,r11,r28
	ctx.r4.u64 = r11.u64 + r28.u64;
	// bl 0x820d0600
	sub_820D0600(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
	// beq cr6,0x820d30f8
	if (cr6.getEQ()) goto loc_820D30F8;
	// lwz r11,100(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 100);
	// ori r11,r11,16
	r11.u64 = r11.u64 | 16;
	// stw r11,100(r3)
	PPC_STORE_U32(ctx.r3.u32 + 100, r11.u32);
loc_820D30F8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cc970
	sub_820CC970(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D3104:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// add r4,r11,r28
	ctx.r4.u64 = r11.u64 + r28.u64;
	// bl 0x820d0600
	sub_820D0600(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r3.u32);
	// beq cr6,0x820d312c
	if (cr6.getEQ()) goto loc_820D312C;
	// lwz r11,100(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 100);
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// stw r11,100(r3)
	PPC_STORE_U32(ctx.r3.u32 + 100, r11.u32);
loc_820D312C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820c1de8
	sub_820C1DE8(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D3138:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cc988
	sub_820CC988(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D3144:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// lwz r8,16(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// lwz r7,20(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// extsw r8,r8
	ctx.r8.s64 = ctx.r8.s32;
	// extsw r7,r7
	ctx.r7.s64 = ctx.r7.s32;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// std r10,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r10.u64);
	// std r9,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r9.u64);
	// std r8,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r8.u64);
	// std r7,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r7.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lfd f13,112(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// lfd f12,120(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// lfd f11,128(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// lfd f10,136(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// fcfid f10,f10
	ctx.f10.f64 = double(ctx.f10.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// fmuls f0,f0,f26
	f0.f64 = double(float(f0.f64 * f26.f64));
	// stfs f0,4(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// fmuls f0,f13,f26
	f0.f64 = double(float(ctx.f13.f64 * f26.f64));
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// fmuls f0,f12,f26
	f0.f64 = double(float(ctx.f12.f64 * f26.f64));
	// stfs f0,12(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
	// fmuls f0,f11,f28
	f0.f64 = double(float(ctx.f11.f64 * f28.f64));
	// stfs f0,16(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 16, temp.u32);
	// fmuls f0,f10,f28
	f0.f64 = double(float(ctx.f10.f64 * f28.f64));
	// stfs f0,20(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D31E8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cc9a0
	sub_820CC9A0(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D31F4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cc9d0
	sub_820CC9D0(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D3200:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cc9e8
	sub_820CC9E8(ctx, base);
	// b 0x820d3214
	goto loc_820D3214;
loc_820D320C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cca00
	sub_820CCA00(ctx, base);
loc_820D3214:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d0010
	sub_820D0010(ctx, base);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// add r31,r11,r31
	r31.u64 = r11.u64 + r31.u64;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// bne cr6,0x820d2af0
	if (!cr6.getEQ()) goto loc_820D2AF0;
	// lwz r31,12(r25)
	r31.u64 = PPC_LOAD_U32(r25.u32 + 12);
loc_820D3238:
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// mr r30,r21
	r30.u64 = r21.u64;
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// beq cr6,0x820d3678
	if (cr6.getEQ()) goto loc_820D3678;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r25,r11,17268
	r25.s64 = r11.s64 + 17268;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r24,r11,17224
	r24.s64 = r11.s64 + 17224;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r23,r11,17180
	r23.s64 = r11.s64 + 17180;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r22,r11,17132
	r22.s64 = r11.s64 + 17132;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r21,r11,17084
	r21.s64 = r11.s64 + 17084;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r20,r11,16232
	r20.s64 = r11.s64 + 16232;
loc_820D3278:
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// addi r11,r11,-3
	r11.s64 = r11.s64 + -3;
	// cmplwi cr6,r11,44
	cr6.compare<uint32_t>(r11.u32, 44, xer);
	// bgt cr6,0x820d3604
	if (cr6.getGT()) goto loc_820D3604;
	// lis r12,-32243
	r12.s64 = -2113077248;
	// addi r12,r12,12960
	r12.s64 = r12.s64 + 12960;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820D3354;
	case 1:
		goto loc_820D3354;
	case 2:
		goto loc_820D3604;
	case 3:
		goto loc_820D3604;
	case 4:
		goto loc_820D3354;
	case 5:
		goto loc_820D3354;
	case 6:
		goto loc_820D3604;
	case 7:
		goto loc_820D3354;
	case 8:
		goto loc_820D3604;
	case 9:
		goto loc_820D3604;
	case 10:
		goto loc_820D3604;
	case 11:
		goto loc_820D33CC;
	case 12:
		goto loc_820D3604;
	case 13:
		goto loc_820D3604;
	case 14:
		goto loc_820D3604;
	case 15:
		goto loc_820D3604;
	case 16:
		goto loc_820D3430;
	case 17:
		goto loc_820D3354;
	case 18:
		goto loc_820D3354;
	case 19:
		goto loc_820D3604;
	case 20:
		goto loc_820D3604;
	case 21:
		goto loc_820D3604;
	case 22:
		goto loc_820D3604;
	case 23:
		goto loc_820D3604;
	case 24:
		goto loc_820D3604;
	case 25:
		goto loc_820D3604;
	case 26:
		goto loc_820D3604;
	case 27:
		goto loc_820D3604;
	case 28:
		goto loc_820D3604;
	case 29:
		goto loc_820D3604;
	case 30:
		goto loc_820D3604;
	case 31:
		goto loc_820D3604;
	case 32:
		goto loc_820D3604;
	case 33:
		goto loc_820D3354;
	case 34:
		goto loc_820D3604;
	case 35:
		goto loc_820D357C;
	case 36:
		goto loc_820D3604;
	case 37:
		goto loc_820D3604;
	case 38:
		goto loc_820D3354;
	case 39:
		goto loc_820D3354;
	case 40:
		goto loc_820D3354;
	case 41:
		goto loc_820D34B4;
	case 42:
		goto loc_820D3604;
	case 43:
		goto loc_820D3604;
	case 44:
		goto loc_820D3354;
	default:
		__builtin_unreachable();
	}
	// lwz r16,13140(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13140);
	// lwz r16,13140(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13140);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13140(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13140);
	// lwz r16,13140(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13140);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13140(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13140);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13260(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13260);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13360(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13360);
	// lwz r16,13140(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13140);
	// lwz r16,13140(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13140);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13140(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13140);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13692(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13692);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13140(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13140);
	// lwz r16,13140(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13140);
	// lwz r16,13140(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13140);
	// lwz r16,13492(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13492);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13828);
	// lwz r16,13140(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + 13140);
loc_820D3354:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d3604
	if (cr6.getEQ()) goto loc_820D3604;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,16,16
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d3604
	if (cr6.getEQ()) goto loc_820D3604;
	// lhz r11,6(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 6);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// add r4,r11,r30
	ctx.r4.u64 = r11.u64 + r30.u64;
	// bl 0x820d0600
	sub_820D0600(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x820d33c4
	if (cr6.getEQ()) goto loc_820D33C4;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d33c4
	if (cr6.getEQ()) goto loc_820D33C4;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// oris r11,r11,8
	r11.u64 = r11.u64 | 524288;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// lfs f1,20(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x823ada90
	sub_823ADA90(ctx, base);
	// lwz r4,16(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x820ccc18
	sub_820CCC18(ctx, base);
	// b 0x820d3604
	goto loc_820D3604;
loc_820D33C4:
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// b 0x820d35fc
	goto loc_820D35FC;
loc_820D33CC:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// add r3,r11,r30
	ctx.r3.u64 = r11.u64 + r30.u64;
	// bl 0x820d0288
	sub_820D0288(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// add r3,r11,r30
	ctx.r3.u64 = r11.u64 + r30.u64;
	// bl 0x820d0288
	sub_820D0288(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x820d3428
	if (cr6.getEQ()) goto loc_820D3428;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x820d3428
	if (cr6.getEQ()) goto loc_820D3428;
	// lbz r11,3(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 3);
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bne cr6,0x820d3420
	if (!cr6.getEQ()) goto loc_820D3420;
	// lbz r11,3(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bne cr6,0x820d3420
	if (!cr6.getEQ()) goto loc_820D3420;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820dcbe8
	sub_820DCBE8(ctx, base);
	// b 0x820d3604
	goto loc_820D3604;
loc_820D3420:
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// b 0x820d35fc
	goto loc_820D35FC;
loc_820D3428:
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// b 0x820d35fc
	goto loc_820D35FC;
loc_820D3430:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lwz r28,8(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// add r4,r11,r30
	ctx.r4.u64 = r11.u64 + r30.u64;
	// bl 0x820d0600
	sub_820D0600(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// add r3,r28,r30
	ctx.r3.u64 = r28.u64 + r30.u64;
	// bl 0x820d0288
	sub_820D0288(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x820d34ac
	if (cr6.getEQ()) goto loc_820D34AC;
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820d34ac
	if (cr6.getEQ()) goto loc_820D34AC;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d34ac
	if (cr6.getEQ()) goto loc_820D34AC;
	// lbz r9,3(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// bne cr6,0x820d34ac
	if (!cr6.getEQ()) goto loc_820D34AC;
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820d34ac
	if (cr6.getEQ()) goto loc_820D34AC;
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// bl 0x820e83c8
	sub_820E83C8(ctx, base);
	// lwz r11,100(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 100);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,100(r29)
	PPC_STORE_U32(r29.u32 + 100, r11.u32);
	// b 0x820d3604
	goto loc_820D3604;
loc_820D34AC:
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// b 0x820d35fc
	goto loc_820D35FC;
loc_820D34B4:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lwz r28,8(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// add r4,r11,r30
	ctx.r4.u64 = r11.u64 + r30.u64;
	// lwz r27,12(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x820d0600
	sub_820D0600(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// add r4,r28,r30
	ctx.r4.u64 = r28.u64 + r30.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d0600
	sub_820D0600(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// add r4,r27,r30
	ctx.r4.u64 = r27.u64 + r30.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d0600
	sub_820D0600(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x820d3574
	if (cr6.getEQ()) goto loc_820D3574;
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d3574
	if (cr6.getEQ()) goto loc_820D3574;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x820d3574
	if (cr6.getEQ()) goto loc_820D3574;
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d3574
	if (cr6.getEQ()) goto loc_820D3574;
	// lbz r11,3(r26)
	r11.u64 = PPC_LOAD_U8(r26.u32 + 3);
	// cmplwi cr6,r11,43
	cr6.compare<uint32_t>(r11.u32, 43, xer);
	// bne cr6,0x820d3574
	if (!cr6.getEQ()) goto loc_820D3574;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x820d3574
	if (cr6.getEQ()) goto loc_820D3574;
	// lwz r11,16(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d3574
	if (cr6.getEQ()) goto loc_820D3574;
	// lbz r11,3(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 3);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x820d3574
	if (!cr6.getEQ()) goto loc_820D3574;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r29,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r29.u32);
	// stw r26,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r26.u32);
	// stw r28,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r28.u32);
	// bl 0x820e83f8
	sub_820E83F8(ctx, base);
	// lwz r11,12(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// stw r11,12(r29)
	PPC_STORE_U32(r29.u32 + 12, r11.u32);
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// stw r11,12(r28)
	PPC_STORE_U32(r28.u32 + 12, r11.u32);
	// b 0x820d3604
	goto loc_820D3604;
loc_820D3574:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// b 0x820d35fc
	goto loc_820D35FC;
loc_820D357C:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// lwz r28,8(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// add r4,r11,r30
	ctx.r4.u64 = r11.u64 + r30.u64;
	// bl 0x820d0600
	sub_820D0600(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// add r4,r28,r30
	ctx.r4.u64 = r28.u64 + r30.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x820d0600
	sub_820D0600(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x820d35f8
	if (cr6.getEQ()) goto loc_820D35F8;
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820d35f8
	if (cr6.getEQ()) goto loc_820D35F8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d35f8
	if (cr6.getEQ()) goto loc_820D35F8;
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820d35f8
	if (cr6.getEQ()) goto loc_820D35F8;
	// lbz r10,3(r29)
	ctx.r10.u64 = PPC_LOAD_U8(r29.u32 + 3);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x820d35f8
	if (!cr6.getEQ()) goto loc_820D35F8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r29,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r29.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// bl 0x820e83e0
	sub_820E83E0(ctx, base);
	// lwz r11,100(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 100);
	// ori r11,r11,8192
	r11.u64 = r11.u64 | 8192;
	// stw r11,100(r29)
	PPC_STORE_U32(r29.u32 + 100, r11.u32);
	// b 0x820d3604
	goto loc_820D3604;
loc_820D35F8:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
loc_820D35FC:
	// addi r4,r30,1
	ctx.r4.s64 = r30.s64 + 1;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
loc_820D3604:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d0010
	sub_820D0010(ctx, base);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// add r31,r11,r31
	r31.u64 = r11.u64 + r31.u64;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// bne cr6,0x820d3278
	if (!cr6.getEQ()) goto loc_820D3278;
	// b 0x820d3678
	goto loc_820D3678;
loc_820D3628:
	// li r21,0
	r21.s64 = 0;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// stw r10,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r10.u32);
	// stw r10,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r10.u32);
	// stw r10,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r10.u32);
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// stw r10,28(r11)
	PPC_STORE_U32(r11.u32 + 28, ctx.r10.u32);
	// stw r10,32(r11)
	PPC_STORE_U32(r11.u32 + 32, ctx.r10.u32);
	// stw r10,36(r11)
	PPC_STORE_U32(r11.u32 + 36, ctx.r10.u32);
	// bl 0x82120f78
	sub_82120F78(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82118930
	sub_82118930(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821189e8
	sub_821189E8(ctx, base);
loc_820D3678:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d3690
	if (cr6.getEQ()) goto loc_820D3690;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8217ee78
	sub_8217EE78(ctx, base);
loc_820D3690:
	// bl 0x821309f0
	sub_821309F0(ctx, base);
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// addi r12,r1,-112
	r12.s64 = ctx.r1.s64 + -112;
	// bl 0x823ed584
	// b 0x823ed164
	return;
}

__attribute__((alias("__imp__sub_820D36A8"))) PPC_WEAK_FUNC(sub_820D36A8);
PPC_FUNC_IMPL(__imp__sub_820D36A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// clrlwi r31,r10,24
	r31.u64 = ctx.r10.u32 & 0xFF;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// subf r11,r11,r31
	r11.s64 = r31.s64 - r11.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D3710"))) PPC_WEAK_FUNC(sub_820D3710);
PPC_FUNC_IMPL(__imp__sub_820D3710) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lfs f13,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f13,f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// lfs f0,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f12,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f0,f0,f13
	ctx.f13.f64 = double(float(f0.f64 * f0.f64 + ctx.f13.f64));
	// fmadds f13,f12,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + ctx.f13.f64));
	// fsqrts f12,f13
	ctx.f12.f64 = double(float(sqrt(ctx.f13.f64)));
	// lfs f13,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 / ctx.f12.f64));
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,0(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f0,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,0(r4)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f0,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,0(r5)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D3760"))) PPC_WEAK_FUNC(sub_820D3760);
PPC_FUNC_IMPL(__imp__sub_820D3760) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f23{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// addi r12,r1,-16
	r12.s64 = ctx.r1.s64 + -16;
	// bl 0x823ed534
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lfs f0,24660(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 24660);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f27,f0,f1
	f27.f64 = double(float(f0.f64 * ctx.f1.f64));
	// fmuls f0,f3,f3
	f0.f64 = double(float(ctx.f3.f64 * ctx.f3.f64));
	// lfs f31,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f31.f64 = double(temp.f32);
	// fmr f1,f27
	ctx.f1.f64 = f27.f64;
	// fmadds f0,f2,f2,f0
	f0.f64 = double(float(ctx.f2.f64 * ctx.f2.f64 + f0.f64));
	// fmadds f0,f4,f4,f0
	f0.f64 = double(float(ctx.f4.f64 * ctx.f4.f64 + f0.f64));
	// fsqrts f0,f0
	f0.f64 = double(float(sqrt(f0.f64)));
	// fdivs f0,f31,f0
	f0.f64 = double(float(f31.f64 / f0.f64));
	// fmuls f28,f0,f2
	f28.f64 = double(float(f0.f64 * ctx.f2.f64));
	// fmuls f30,f0,f3
	f30.f64 = double(float(f0.f64 * ctx.f3.f64));
	// fmuls f29,f0,f4
	f29.f64 = double(float(f0.f64 * ctx.f4.f64));
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// fmr f1,f27
	ctx.f1.f64 = f27.f64;
	// frsp f26,f0
	f26.f64 = double(float(f0.f64));
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// frsp f27,f1
	ctx.fpscr.disableFlushMode();
	f27.f64 = double(float(ctx.f1.f64));
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fsubs f0,f31,f27
	f0.f64 = double(float(f31.f64 - f27.f64));
	// fmuls f13,f0,f28
	ctx.f13.f64 = double(float(f0.f64 * f28.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// fmuls f24,f13,f30
	f24.f64 = double(float(ctx.f13.f64 * f30.f64));
	// fmuls f25,f0,f29
	f25.f64 = double(float(f0.f64 * f29.f64));
	// fmuls f23,f13,f29
	f23.f64 = double(float(ctx.f13.f64 * f29.f64));
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// fmuls f0,f28,f28
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f28.f64 * f28.f64));
	// fmuls f13,f26,f28
	ctx.f13.f64 = double(float(f26.f64 * f28.f64));
	// fmuls f12,f26,f30
	ctx.f12.f64 = double(float(f26.f64 * f30.f64));
	// fmuls f11,f26,f29
	ctx.f11.f64 = double(float(f26.f64 * f29.f64));
	// fsubs f10,f31,f0
	ctx.f10.f64 = double(float(f31.f64 - f0.f64));
	// fsubs f9,f25,f13
	ctx.f9.f64 = double(float(f25.f64 - ctx.f13.f64));
	// stfs f9,36(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(r31.u32 + 36, temp.u32);
	// fadds f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 + f25.f64));
	// stfs f13,24(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 24, temp.u32);
	// fadds f13,f12,f23
	ctx.f13.f64 = double(float(ctx.f12.f64 + f23.f64));
	// stfs f13,32(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 32, temp.u32);
	// fsubs f13,f23,f12
	ctx.f13.f64 = double(float(f23.f64 - ctx.f12.f64));
	// stfs f13,8(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// fsubs f13,f24,f11
	ctx.f13.f64 = double(float(f24.f64 - ctx.f11.f64));
	// stfs f13,16(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 16, temp.u32);
	// fadds f13,f11,f24
	ctx.f13.f64 = double(float(ctx.f11.f64 + f24.f64));
	// stfs f13,4(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// fmadds f0,f10,f27,f0
	f0.f64 = double(float(ctx.f10.f64 * f27.f64 + f0.f64));
	// stfs f0,0(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// fmuls f0,f30,f30
	f0.f64 = double(float(f30.f64 * f30.f64));
	// fsubs f13,f31,f0
	ctx.f13.f64 = double(float(f31.f64 - f0.f64));
	// fmadds f0,f13,f27,f0
	f0.f64 = double(float(ctx.f13.f64 * f27.f64 + f0.f64));
	// stfs f0,20(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// fmuls f0,f29,f29
	f0.f64 = double(float(f29.f64 * f29.f64));
	// fsubs f13,f31,f0
	ctx.f13.f64 = double(float(f31.f64 - f0.f64));
	// fmadds f0,f13,f27,f0
	f0.f64 = double(float(ctx.f13.f64 * f27.f64 + f0.f64));
	// stfs f0,40(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 40, temp.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// addi r12,r1,-16
	r12.s64 = ctx.r1.s64 + -16;
	// bl 0x823ed580
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D3878"))) PPC_WEAK_FUNC(sub_820D3878);
PPC_FUNC_IMPL(__imp__sub_820D3878) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r11,100(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 100);
	// clrlwi r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d38dc
	if (cr6.getEQ()) goto loc_820D38DC;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r31,17296(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 17296);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820d38dc
	if (cr6.getEQ()) goto loc_820D38DC;
loc_820D38B4:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// bne cr6,0x820d38d0
	if (!cr6.getEQ()) goto loc_820D38D0;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d38d0
	if (cr6.getEQ()) goto loc_820D38D0;
	// bl 0x820df1b8
	sub_820DF1B8(ctx, base);
loc_820D38D0:
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x820d38b4
	if (!cr6.getEQ()) goto loc_820D38B4;
loc_820D38DC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D38F8"))) PPC_WEAK_FUNC(sub_820D38F8);
PPC_FUNC_IMPL(__imp__sub_820D38F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// rlwinm r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d395c
	if (cr6.getEQ()) goto loc_820D395C;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r11,17304(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 17304);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d395c
	if (cr6.getEQ()) goto loc_820D395C;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,2692(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2692);
	f0.f64 = double(temp.f32);
loc_820D3920:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r10,r3
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r3.u32, xer);
	// bne cr6,0x820d3950
	if (!cr6.getEQ()) goto loc_820D3950;
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820d3950
	if (cr6.getEQ()) goto loc_820D3950;
	// lwz r9,16(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820d3950
	if (cr6.getEQ()) goto loc_820D3950;
	// lfs f13,180(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 180);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820d3964
	if (!cr6.getGT()) goto loc_820D3964;
loc_820D3950:
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d3920
	if (!cr6.getEQ()) goto loc_820D3920;
loc_820D395C:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_820D3964:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D3970"))) PPC_WEAK_FUNC(sub_820D3970);
PPC_FUNC_IMPL(__imp__sub_820D3970) {
	PPC_FUNC_PROLOGUE();
	PPCRegister temp{};
	// lfs f1,12(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D3978"))) PPC_WEAK_FUNC(sub_820D3978);
PPC_FUNC_IMPL(__imp__sub_820D3978) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f12,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// blt cr6,0x820d3994
	if (cr6.getLT()) goto loc_820D3994;
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// b 0x820d3998
	goto loc_820D3998;
loc_820D3994:
	// lfs f13,8(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
loc_820D3998:
	// fmuls f13,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f0,16(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// blt cr6,0x820d39b0
	if (cr6.getLT()) goto loc_820D39B0;
	// lfs f11,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// b 0x820d39b4
	goto loc_820D39B4;
loc_820D39B0:
	// lfs f11,16(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
loc_820D39B4:
	// fmadds f13,f11,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f11.f64 * f0.f64 + ctx.f13.f64));
	// lfs f0,32(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// blt cr6,0x820d39d0
	if (cr6.getLT()) goto loc_820D39D0;
	// lfs f12,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// blr 
	return;
loc_820D39D0:
	// lfs f12,24(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D39E0"))) PPC_WEAK_FUNC(sub_820D39E0);
PPC_FUNC_IMPL(__imp__sub_820D39E0) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f12,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bgt cr6,0x820d39fc
	if (cr6.getGT()) goto loc_820D39FC;
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// b 0x820d3a00
	goto loc_820D3A00;
loc_820D39FC:
	// lfs f13,8(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
loc_820D3A00:
	// fmuls f13,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f0,16(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bgt cr6,0x820d3a18
	if (cr6.getGT()) goto loc_820D3A18;
	// lfs f11,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// b 0x820d3a1c
	goto loc_820D3A1C;
loc_820D3A18:
	// lfs f11,16(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
loc_820D3A1C:
	// fmadds f13,f11,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f11.f64 * f0.f64 + ctx.f13.f64));
	// lfs f0,32(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 32);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bgt cr6,0x820d3a38
	if (cr6.getGT()) goto loc_820D3A38;
	// lfs f12,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// blr 
	return;
loc_820D3A38:
	// lfs f12,24(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D3A48"))) PPC_WEAK_FUNC(sub_820D3A48);
PPC_FUNC_IMPL(__imp__sub_820D3A48) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,4(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f12,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// blt cr6,0x820d3a64
	if (cr6.getLT()) goto loc_820D3A64;
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// b 0x820d3a68
	goto loc_820D3A68;
loc_820D3A64:
	// lfs f13,8(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
loc_820D3A68:
	// fmuls f13,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f0,20(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// blt cr6,0x820d3a80
	if (cr6.getLT()) goto loc_820D3A80;
	// lfs f11,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// b 0x820d3a84
	goto loc_820D3A84;
loc_820D3A80:
	// lfs f11,16(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
loc_820D3A84:
	// fmadds f13,f11,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f11.f64 * f0.f64 + ctx.f13.f64));
	// lfs f0,36(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 36);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// blt cr6,0x820d3aa0
	if (cr6.getLT()) goto loc_820D3AA0;
	// lfs f12,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// blr 
	return;
loc_820D3AA0:
	// lfs f12,24(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D3AB0"))) PPC_WEAK_FUNC(sub_820D3AB0);
PPC_FUNC_IMPL(__imp__sub_820D3AB0) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,4(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f12,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bgt cr6,0x820d3acc
	if (cr6.getGT()) goto loc_820D3ACC;
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// b 0x820d3ad0
	goto loc_820D3AD0;
loc_820D3ACC:
	// lfs f13,8(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
loc_820D3AD0:
	// fmuls f13,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f0,20(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 20);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bgt cr6,0x820d3ae8
	if (cr6.getGT()) goto loc_820D3AE8;
	// lfs f11,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// b 0x820d3aec
	goto loc_820D3AEC;
loc_820D3AE8:
	// lfs f11,16(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
loc_820D3AEC:
	// fmadds f13,f11,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f11.f64 * f0.f64 + ctx.f13.f64));
	// lfs f0,36(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 36);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bgt cr6,0x820d3b08
	if (cr6.getGT()) goto loc_820D3B08;
	// lfs f12,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// blr 
	return;
loc_820D3B08:
	// lfs f12,24(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D3B18"))) PPC_WEAK_FUNC(sub_820D3B18);
PPC_FUNC_IMPL(__imp__sub_820D3B18) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,8(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f12,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// blt cr6,0x820d3b34
	if (cr6.getLT()) goto loc_820D3B34;
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// b 0x820d3b38
	goto loc_820D3B38;
loc_820D3B34:
	// lfs f13,8(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
loc_820D3B38:
	// fmuls f13,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f0,24(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// blt cr6,0x820d3b50
	if (cr6.getLT()) goto loc_820D3B50;
	// lfs f11,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// b 0x820d3b54
	goto loc_820D3B54;
loc_820D3B50:
	// lfs f11,16(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
loc_820D3B54:
	// fmadds f13,f11,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f11.f64 * f0.f64 + ctx.f13.f64));
	// lfs f0,40(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 40);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// blt cr6,0x820d3b70
	if (cr6.getLT()) goto loc_820D3B70;
	// lfs f12,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// blr 
	return;
loc_820D3B70:
	// lfs f12,24(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D3B80"))) PPC_WEAK_FUNC(sub_820D3B80);
PPC_FUNC_IMPL(__imp__sub_820D3B80) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,8(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f12,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bgt cr6,0x820d3b9c
	if (cr6.getGT()) goto loc_820D3B9C;
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// b 0x820d3ba0
	goto loc_820D3BA0;
loc_820D3B9C:
	// lfs f13,8(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
loc_820D3BA0:
	// fmuls f13,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f0,24(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bgt cr6,0x820d3bb8
	if (cr6.getGT()) goto loc_820D3BB8;
	// lfs f11,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// b 0x820d3bbc
	goto loc_820D3BBC;
loc_820D3BB8:
	// lfs f11,16(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
loc_820D3BBC:
	// fmadds f13,f11,f0,f13
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f11.f64 * f0.f64 + ctx.f13.f64));
	// lfs f0,40(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 40);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bgt cr6,0x820d3bd8
	if (cr6.getGT()) goto loc_820D3BD8;
	// lfs f12,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// blr 
	return;
loc_820D3BD8:
	// lfs f12,24(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D3BE8"))) PPC_WEAK_FUNC(sub_820D3BE8);
PPC_FUNC_IMPL(__imp__sub_820D3BE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	// mflr r12
	// bl 0x823ed138
	// stfd f30,-56(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -56, f30.u64);
	// stfd f31,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, f31.u64);
	// fmr f13,f3
	ctx.f13.f64 = ctx.f3.f64;
	// lfs f0,16(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	f0.f64 = double(temp.f32);
	// fmr f9,f5
	ctx.f9.f64 = ctx.f5.f64;
	// lfs f10,32(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 32);
	ctx.f10.f64 = double(temp.f32);
	// fmr f7,f6
	ctx.f7.f64 = ctx.f6.f64;
	// lfs f12,24(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fmr f11,f4
	ctx.f11.f64 = ctx.f4.f64;
	// lfs f8,40(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 40);
	ctx.f8.f64 = double(temp.f32);
	// fmr f3,f2
	ctx.f3.f64 = ctx.f2.f64;
	// lfs f6,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmr f5,f1
	ctx.f5.f64 = ctx.f1.f64;
	// lfs f4,8(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// li r31,0
	r31.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// fmul f2,f0,f13
	ctx.f2.f64 = f0.f64 * ctx.f13.f64;
	// li r6,1
	ctx.r6.s64 = 1;
	// fmul f31,f10,f9
	f31.f64 = ctx.f10.f64 * ctx.f9.f64;
	// li r8,0
	ctx.r8.s64 = 0;
	// fmul f1,f12,f13
	ctx.f1.f64 = ctx.f12.f64 * ctx.f13.f64;
	// li r11,16
	r11.s64 = 16;
	// fmul f9,f8,f9
	ctx.f9.f64 = ctx.f8.f64 * ctx.f9.f64;
	// fmul f10,f10,f7
	ctx.f10.f64 = ctx.f10.f64 * ctx.f7.f64;
	// fmul f8,f8,f7
	ctx.f8.f64 = ctx.f8.f64 * ctx.f7.f64;
	// fmul f7,f0,f11
	ctx.f7.f64 = f0.f64 * ctx.f11.f64;
	// fmul f30,f12,f11
	f30.f64 = ctx.f12.f64 * ctx.f11.f64;
	// fmul f0,f6,f5
	f0.f64 = ctx.f6.f64 * ctx.f5.f64;
	// fmul f12,f6,f3
	ctx.f12.f64 = ctx.f6.f64 * ctx.f3.f64;
	// fmul f13,f4,f5
	ctx.f13.f64 = ctx.f4.f64 * ctx.f5.f64;
	// fadd f6,f2,f31
	ctx.f6.f64 = ctx.f2.f64 + f31.f64;
	// fmul f11,f4,f3
	ctx.f11.f64 = ctx.f4.f64 * ctx.f3.f64;
	// fadd f5,f1,f9
	ctx.f5.f64 = ctx.f1.f64 + ctx.f9.f64;
	// fadd f4,f10,f2
	ctx.f4.f64 = ctx.f10.f64 + ctx.f2.f64;
	// fadd f3,f8,f1
	ctx.f3.f64 = ctx.f8.f64 + ctx.f1.f64;
	// fadd f2,f7,f31
	ctx.f2.f64 = ctx.f7.f64 + f31.f64;
	// fadd f10,f7,f10
	ctx.f10.f64 = ctx.f7.f64 + ctx.f10.f64;
	// fadd f8,f30,f8
	ctx.f8.f64 = f30.f64 + ctx.f8.f64;
	// fadd f9,f30,f9
	ctx.f9.f64 = f30.f64 + ctx.f9.f64;
	// fadd f7,f0,f6
	ctx.f7.f64 = f0.f64 + ctx.f6.f64;
	// stfd f7,-224(r1)
	PPC_STORE_U64(ctx.r1.u32 + -224, ctx.f7.u64);
	// fadd f7,f13,f5
	ctx.f7.f64 = ctx.f13.f64 + ctx.f5.f64;
	// stfd f7,-216(r1)
	PPC_STORE_U64(ctx.r1.u32 + -216, ctx.f7.u64);
	// fadd f7,f4,f0
	ctx.f7.f64 = ctx.f4.f64 + f0.f64;
	// stfd f7,-208(r1)
	PPC_STORE_U64(ctx.r1.u32 + -208, ctx.f7.u64);
	// fadd f7,f3,f13
	ctx.f7.f64 = ctx.f3.f64 + ctx.f13.f64;
	// stfd f7,-200(r1)
	PPC_STORE_U64(ctx.r1.u32 + -200, ctx.f7.u64);
	// fadd f7,f2,f0
	ctx.f7.f64 = ctx.f2.f64 + f0.f64;
	// stfd f7,-192(r1)
	PPC_STORE_U64(ctx.r1.u32 + -192, ctx.f7.u64);
	// fadd f0,f10,f0
	f0.f64 = ctx.f10.f64 + f0.f64;
	// stfd f0,-176(r1)
	PPC_STORE_U64(ctx.r1.u32 + -176, f0.u64);
	// fadd f0,f8,f13
	f0.f64 = ctx.f8.f64 + ctx.f13.f64;
	// stfd f0,-168(r1)
	PPC_STORE_U64(ctx.r1.u32 + -168, f0.u64);
	// fadd f0,f12,f6
	f0.f64 = ctx.f12.f64 + ctx.f6.f64;
	// stfd f0,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, f0.u64);
	// fadd f0,f11,f5
	f0.f64 = ctx.f11.f64 + ctx.f5.f64;
	// stfd f0,-152(r1)
	PPC_STORE_U64(ctx.r1.u32 + -152, f0.u64);
	// fadd f0,f12,f4
	f0.f64 = ctx.f12.f64 + ctx.f4.f64;
	// stfd f0,-144(r1)
	PPC_STORE_U64(ctx.r1.u32 + -144, f0.u64);
	// fadd f0,f11,f3
	f0.f64 = ctx.f11.f64 + ctx.f3.f64;
	// stfd f0,-136(r1)
	PPC_STORE_U64(ctx.r1.u32 + -136, f0.u64);
	// fadd f0,f12,f2
	f0.f64 = ctx.f12.f64 + ctx.f2.f64;
	// stfd f0,-128(r1)
	PPC_STORE_U64(ctx.r1.u32 + -128, f0.u64);
	// fadd f0,f11,f9
	f0.f64 = ctx.f11.f64 + ctx.f9.f64;
	// stfd f0,-120(r1)
	PPC_STORE_U64(ctx.r1.u32 + -120, f0.u64);
	// fadd f0,f12,f10
	f0.f64 = ctx.f12.f64 + ctx.f10.f64;
	// stfd f0,-112(r1)
	PPC_STORE_U64(ctx.r1.u32 + -112, f0.u64);
	// fadd f7,f9,f13
	ctx.f7.f64 = ctx.f9.f64 + ctx.f13.f64;
	// stfd f7,-184(r1)
	PPC_STORE_U64(ctx.r1.u32 + -184, ctx.f7.u64);
	// fadd f0,f11,f8
	f0.f64 = ctx.f11.f64 + ctx.f8.f64;
	// stfd f0,-104(r1)
	PPC_STORE_U64(ctx.r1.u32 + -104, f0.u64);
loc_820D3D14:
	// addi r7,r1,-224
	ctx.r7.s64 = ctx.r1.s64 + -224;
	// addi r30,r1,-224
	r30.s64 = ctx.r1.s64 + -224;
	// add r7,r11,r7
	ctx.r7.u64 = r11.u64 + ctx.r7.u64;
	// lfdx f0,r8,r30
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + r30.u32);
	// lfd f13,0(r7)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r7.u32 + 0);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x820d3d4c
	if (cr6.getLT()) goto loc_820D3D4C;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x820d3d54
	if (!cr6.getEQ()) goto loc_820D3D54;
	// addi r30,r1,-216
	r30.s64 = ctx.r1.s64 + -216;
	// lfd f0,8(r7)
	f0.u64 = PPC_LOAD_U64(ctx.r7.u32 + 8);
	// lfdx f13,r8,r30
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r8.u32 + r30.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820d3d54
	if (!cr6.getLT()) goto loc_820D3D54;
loc_820D3D4C:
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
loc_820D3D54:
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// cmpwi cr6,r11,128
	cr6.compare<int32_t>(r11.s32, 128, xer);
	// blt cr6,0x820d3d14
	if (cr6.getLT()) goto loc_820D3D14;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r11,16
	r11.s64 = 16;
loc_820D3D70:
	// addi r7,r1,-216
	ctx.r7.s64 = ctx.r1.s64 + -216;
	// addi r30,r1,-216
	r30.s64 = ctx.r1.s64 + -216;
	// add r7,r11,r7
	ctx.r7.u64 = r11.u64 + ctx.r7.u64;
	// lfdx f0,r8,r30
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + r30.u32);
	// lfd f13,0(r7)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r7.u32 + 0);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bgt cr6,0x820d3da8
	if (cr6.getGT()) goto loc_820D3DA8;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x820d3db0
	if (!cr6.getEQ()) goto loc_820D3DB0;
	// addi r30,r1,-224
	r30.s64 = ctx.r1.s64 + -224;
	// lfd f0,-8(r7)
	f0.u64 = PPC_LOAD_U64(ctx.r7.u32 + -8);
	// lfdx f13,r8,r30
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r8.u32 + r30.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820d3db0
	if (!cr6.getLT()) goto loc_820D3DB0;
loc_820D3DA8:
	// mr r31,r6
	r31.u64 = ctx.r6.u64;
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
loc_820D3DB0:
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// cmpwi cr6,r11,128
	cr6.compare<int32_t>(r11.s32, 128, xer);
	// blt cr6,0x820d3d70
	if (cr6.getLT()) goto loc_820D3D70;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r11,16
	r11.s64 = 16;
loc_820D3DCC:
	// addi r7,r1,-224
	ctx.r7.s64 = ctx.r1.s64 + -224;
	// addi r30,r1,-224
	r30.s64 = ctx.r1.s64 + -224;
	// add r7,r11,r7
	ctx.r7.u64 = r11.u64 + ctx.r7.u64;
	// lfdx f0,r8,r30
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + r30.u32);
	// lfd f13,0(r7)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r7.u32 + 0);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bgt cr6,0x820d3e04
	if (cr6.getGT()) goto loc_820D3E04;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x820d3e0c
	if (!cr6.getEQ()) goto loc_820D3E0C;
	// addi r30,r1,-216
	r30.s64 = ctx.r1.s64 + -216;
	// lfd f0,8(r7)
	f0.u64 = PPC_LOAD_U64(ctx.r7.u32 + 8);
	// lfdx f13,r8,r30
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r8.u32 + r30.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820d3e0c
	if (!cr6.getGT()) goto loc_820D3E0C;
loc_820D3E04:
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
loc_820D3E0C:
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// cmpwi cr6,r11,128
	cr6.compare<int32_t>(r11.s32, 128, xer);
	// blt cr6,0x820d3dcc
	if (cr6.getLT()) goto loc_820D3DCC;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r11,16
	r11.s64 = 16;
loc_820D3E28:
	// addi r7,r1,-216
	ctx.r7.s64 = ctx.r1.s64 + -216;
	// addi r30,r1,-216
	r30.s64 = ctx.r1.s64 + -216;
	// add r7,r11,r7
	ctx.r7.u64 = r11.u64 + ctx.r7.u64;
	// lfdx f0,r8,r30
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + r30.u32);
	// lfd f13,0(r7)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r7.u32 + 0);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x820d3e60
	if (cr6.getLT()) goto loc_820D3E60;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x820d3e68
	if (!cr6.getEQ()) goto loc_820D3E68;
	// addi r30,r1,-224
	r30.s64 = ctx.r1.s64 + -224;
	// lfd f0,-8(r7)
	f0.u64 = PPC_LOAD_U64(ctx.r7.u32 + -8);
	// lfdx f13,r8,r30
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r8.u32 + r30.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820d3e68
	if (!cr6.getGT()) goto loc_820D3E68;
loc_820D3E60:
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
loc_820D3E68:
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// cmpwi cr6,r11,128
	cr6.compare<int32_t>(r11.s32, 128, xer);
	// blt cr6,0x820d3e28
	if (cr6.getLT()) goto loc_820D3E28;
	// li r11,0
	r11.s64 = 0;
	// addi r8,r1,-96
	ctx.r8.s64 = ctx.r1.s64 + -96;
loc_820D3E80:
	// cmpw cr6,r11,r4
	cr6.compare<int32_t>(r11.s32, ctx.r4.s32, xer);
	// beq cr6,0x820d3ea8
	if (cr6.getEQ()) goto loc_820D3EA8;
	// cmpw cr6,r11,r3
	cr6.compare<int32_t>(r11.s32, ctx.r3.s32, xer);
	// beq cr6,0x820d3ea8
	if (cr6.getEQ()) goto loc_820D3EA8;
	// cmpw cr6,r11,r31
	cr6.compare<int32_t>(r11.s32, r31.s32, xer);
	// beq cr6,0x820d3ea8
	if (cr6.getEQ()) goto loc_820D3EA8;
	// cmpw cr6,r11,r5
	cr6.compare<int32_t>(r11.s32, ctx.r5.s32, xer);
	// beq cr6,0x820d3ea8
	if (cr6.getEQ()) goto loc_820D3EA8;
	// stw r11,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r11.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
loc_820D3EA8:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// blt cr6,0x820d3e80
	if (cr6.getLT()) goto loc_820D3E80;
	// rlwinm r11,r4,4,0,27
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r4,r1,-224
	ctx.r4.s64 = ctx.r1.s64 + -224;
	// addi r30,r1,-216
	r30.s64 = ctx.r1.s64 + -216;
	// rlwinm r8,r5,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r29,r1,-224
	r29.s64 = ctx.r1.s64 + -224;
	// addi r28,r1,-216
	r28.s64 = ctx.r1.s64 + -216;
	// lfdx f10,r11,r4
	ctx.fpscr.disableFlushMode();
	ctx.f10.u64 = PPC_LOAD_U64(r11.u32 + ctx.r4.u32);
	// li r7,1
	ctx.r7.s64 = 1;
	// lfdx f9,r11,r30
	ctx.f9.u64 = PPC_LOAD_U64(r11.u32 + r30.u32);
	// frsp f12,f10
	ctx.f12.f64 = double(float(ctx.f10.f64));
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// frsp f12,f9
	ctx.f12.f64 = double(float(ctx.f9.f64));
	// lfdx f0,r8,r29
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + r29.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// lfdx f13,r8,r28
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r8.u32 + r28.u32);
	// addi r6,r1,-96
	ctx.r6.s64 = ctx.r1.s64 + -96;
	// stfs f12,4(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// fsub f11,f9,f13
	ctx.f11.f64 = ctx.f9.f64 - ctx.f13.f64;
	// fsub f12,f10,f0
	ctx.f12.f64 = ctx.f10.f64 - f0.f64;
loc_820D3F00:
	// lwz r8,0(r6)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r4,r1,-216
	ctx.r4.s64 = ctx.r1.s64 + -216;
	// addi r30,r1,-224
	r30.s64 = ctx.r1.s64 + -224;
	// rlwinm r11,r8,4,0,27
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfdx f8,r11,r4
	ctx.fpscr.disableFlushMode();
	ctx.f8.u64 = PPC_LOAD_U64(r11.u32 + ctx.r4.u32);
	// lfdx f7,r11,r30
	ctx.f7.u64 = PPC_LOAD_U64(r11.u32 + r30.u32);
	// fsub f8,f8,f13
	ctx.f8.f64 = ctx.f8.f64 - ctx.f13.f64;
	// fsub f7,f7,f0
	ctx.f7.f64 = ctx.f7.f64 - f0.f64;
	// fmul f8,f8,f12
	ctx.f8.f64 = ctx.f8.f64 * ctx.f12.f64;
	// fmul f7,f7,f11
	ctx.f7.f64 = ctx.f7.f64 * ctx.f11.f64;
	// fcmpu cr6,f8,f7
	cr6.compare(ctx.f8.f64, ctx.f7.f64);
	// bgt cr6,0x820d3f44
	if (cr6.getGT()) goto loc_820D3F44;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmpwi cr6,r5,4
	cr6.compare<int32_t>(ctx.r5.s32, 4, xer);
	// blt cr6,0x820d3f00
	if (cr6.getLT()) goto loc_820D3F00;
	// b 0x820d3f6c
	goto loc_820D3F6C;
loc_820D3F44:
	// rlwinm r11,r8,4,0,27
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r8,r1,-224
	ctx.r8.s64 = ctx.r1.s64 + -224;
	// addi r6,r1,-216
	ctx.r6.s64 = ctx.r1.s64 + -216;
	// li r7,2
	ctx.r7.s64 = 2;
	// lfdx f12,r11,r8
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(r11.u32 + ctx.r8.u32);
	// lfdx f11,r11,r6
	ctx.f11.u64 = PPC_LOAD_U64(r11.u32 + ctx.r6.u32);
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// stfs f12,8(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// stfs f11,12(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 12, temp.u32);
loc_820D3F6C:
	// rlwinm r8,r3,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 4) & 0xFFFFFFF0;
	// frsp f8,f0
	ctx.fpscr.disableFlushMode();
	ctx.f8.f64 = double(float(f0.f64));
	// rlwinm r6,r7,3,0,28
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// frsp f7,f13
	ctx.f7.f64 = double(float(ctx.f13.f64));
	// addi r4,r1,-224
	ctx.r4.s64 = ctx.r1.s64 + -224;
	// addi r3,r1,-216
	ctx.r3.s64 = ctx.r1.s64 + -216;
	// addi r11,r7,1
	r11.s64 = ctx.r7.s64 + 1;
	// add r7,r6,r10
	ctx.r7.u64 = ctx.r6.u64 + ctx.r10.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lfdx f12,r8,r4
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r8.u32 + ctx.r4.u32);
	// addi r6,r1,-96
	ctx.r6.s64 = ctx.r1.s64 + -96;
	// lfdx f11,r8,r3
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r8.u32 + ctx.r3.u32);
	// fsub f0,f0,f12
	f0.f64 = f0.f64 - ctx.f12.f64;
	// fsub f13,f13,f11
	ctx.f13.f64 = ctx.f13.f64 - ctx.f11.f64;
	// stfs f8,0(r7)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// stfs f7,4(r7)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + 4, temp.u32);
loc_820D3FAC:
	// lwz r8,0(r6)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r4,r1,-216
	ctx.r4.s64 = ctx.r1.s64 + -216;
	// addi r3,r1,-224
	ctx.r3.s64 = ctx.r1.s64 + -224;
	// rlwinm r7,r8,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfdx f8,r7,r4
	ctx.fpscr.disableFlushMode();
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r7.u32 + ctx.r4.u32);
	// lfdx f7,r7,r3
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r7.u32 + ctx.r3.u32);
	// fsub f8,f8,f11
	ctx.f8.f64 = ctx.f8.f64 - ctx.f11.f64;
	// fsub f7,f7,f12
	ctx.f7.f64 = ctx.f7.f64 - ctx.f12.f64;
	// fmul f8,f8,f0
	ctx.f8.f64 = ctx.f8.f64 * f0.f64;
	// fmul f7,f7,f13
	ctx.f7.f64 = ctx.f7.f64 * ctx.f13.f64;
	// fcmpu cr6,f8,f7
	cr6.compare(ctx.f8.f64, ctx.f7.f64);
	// bgt cr6,0x820d3ff0
	if (cr6.getGT()) goto loc_820D3FF0;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmpwi cr6,r5,4
	cr6.compare<int32_t>(ctx.r5.s32, 4, xer);
	// blt cr6,0x820d3fac
	if (cr6.getLT()) goto loc_820D3FAC;
	// b 0x820d4020
	goto loc_820D4020;
loc_820D3FF0:
	// rlwinm r8,r8,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r7,r11,3,0,28
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r6,r1,-224
	ctx.r6.s64 = ctx.r1.s64 + -224;
	// addi r5,r1,-216
	ctx.r5.s64 = ctx.r1.s64 + -216;
	// add r7,r7,r10
	ctx.r7.u64 = ctx.r7.u64 + ctx.r10.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lfdx f0,r8,r6
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + ctx.r6.u32);
	// lfdx f13,r8,r5
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r8.u32 + ctx.r5.u32);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// stfs f0,0(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// stfs f13,4(r7)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r7.u32 + 4, temp.u32);
loc_820D4020:
	// rlwinm r7,r11,3,0,28
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// frsp f8,f12
	ctx.fpscr.disableFlushMode();
	ctx.f8.f64 = double(float(ctx.f12.f64));
	// rlwinm r8,r31,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 4) & 0xFFFFFFF0;
	// frsp f7,f11
	ctx.f7.f64 = double(float(ctx.f11.f64));
	// addi r4,r1,-224
	ctx.r4.s64 = ctx.r1.s64 + -224;
	// addi r3,r1,-216
	ctx.r3.s64 = ctx.r1.s64 + -216;
	// add r7,r7,r10
	ctx.r7.u64 = ctx.r7.u64 + ctx.r10.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// lfdx f0,r8,r4
	f0.u64 = PPC_LOAD_U64(ctx.r8.u32 + ctx.r4.u32);
	// addi r6,r1,-96
	ctx.r6.s64 = ctx.r1.s64 + -96;
	// lfdx f13,r8,r3
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r8.u32 + ctx.r3.u32);
	// fsub f12,f12,f0
	ctx.f12.f64 = ctx.f12.f64 - f0.f64;
	// stfs f8,0(r7)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// fsub f11,f11,f13
	ctx.f11.f64 = ctx.f11.f64 - ctx.f13.f64;
	// stfs f7,4(r7)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r7.u32 + 4, temp.u32);
loc_820D4060:
	// lwz r8,0(r6)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// addi r4,r1,-216
	ctx.r4.s64 = ctx.r1.s64 + -216;
	// addi r3,r1,-224
	ctx.r3.s64 = ctx.r1.s64 + -224;
	// rlwinm r7,r8,4,0,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// lfdx f8,r7,r4
	ctx.fpscr.disableFlushMode();
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r7.u32 + ctx.r4.u32);
	// lfdx f7,r7,r3
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r7.u32 + ctx.r3.u32);
	// fsub f8,f8,f13
	ctx.f8.f64 = ctx.f8.f64 - ctx.f13.f64;
	// fsub f7,f7,f0
	ctx.f7.f64 = ctx.f7.f64 - f0.f64;
	// fmul f8,f8,f12
	ctx.f8.f64 = ctx.f8.f64 * ctx.f12.f64;
	// fmul f7,f7,f11
	ctx.f7.f64 = ctx.f7.f64 * ctx.f11.f64;
	// fcmpu cr6,f8,f7
	cr6.compare(ctx.f8.f64, ctx.f7.f64);
	// bgt cr6,0x820d40a4
	if (cr6.getGT()) goto loc_820D40A4;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmpwi cr6,r5,4
	cr6.compare<int32_t>(ctx.r5.s32, 4, xer);
	// blt cr6,0x820d4060
	if (cr6.getLT()) goto loc_820D4060;
	// b 0x820d40d4
	goto loc_820D40D4;
loc_820D40A4:
	// rlwinm r8,r8,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r7,r11,3,0,28
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r6,r1,-224
	ctx.r6.s64 = ctx.r1.s64 + -224;
	// addi r5,r1,-216
	ctx.r5.s64 = ctx.r1.s64 + -216;
	// add r7,r7,r10
	ctx.r7.u64 = ctx.r7.u64 + ctx.r10.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lfdx f12,r8,r6
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r8.u32 + ctx.r6.u32);
	// lfdx f11,r8,r5
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r8.u32 + ctx.r5.u32);
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// stfs f12,0(r7)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// stfs f11,4(r7)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r7.u32 + 4, temp.u32);
loc_820D40D4:
	// rlwinm r8,r11,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// frsp f12,f0
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(f0.f64));
	// addi r7,r11,1
	ctx.r7.s64 = r11.s64 + 1;
	// frsp f11,f13
	ctx.f11.f64 = double(float(ctx.f13.f64));
	// add r11,r8,r10
	r11.u64 = ctx.r8.u64 + ctx.r10.u64;
	// fsub f0,f0,f10
	f0.f64 = f0.f64 - ctx.f10.f64;
	// li r5,0
	ctx.r5.s64 = 0;
	// fsub f13,f13,f9
	ctx.f13.f64 = ctx.f13.f64 - ctx.f9.f64;
	// addi r8,r1,-96
	ctx.r8.s64 = ctx.r1.s64 + -96;
	// stfs f12,0(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// stfs f11,4(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r11.u32 + 4, temp.u32);
loc_820D4100:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// addi r4,r1,-216
	ctx.r4.s64 = ctx.r1.s64 + -216;
	// addi r3,r1,-224
	ctx.r3.s64 = ctx.r1.s64 + -224;
	// rlwinm r6,r11,4,0,27
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// lfdx f12,r6,r4
	ctx.fpscr.disableFlushMode();
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r6.u32 + ctx.r4.u32);
	// lfdx f11,r6,r3
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r6.u32 + ctx.r3.u32);
	// fsub f12,f12,f9
	ctx.f12.f64 = ctx.f12.f64 - ctx.f9.f64;
	// fsub f11,f11,f10
	ctx.f11.f64 = ctx.f11.f64 - ctx.f10.f64;
	// fmul f12,f12,f0
	ctx.f12.f64 = ctx.f12.f64 * f0.f64;
	// fmul f11,f11,f13
	ctx.f11.f64 = ctx.f11.f64 * ctx.f13.f64;
	// fcmpu cr6,f12,f11
	cr6.compare(ctx.f12.f64, ctx.f11.f64);
	// bgt cr6,0x820d4144
	if (cr6.getGT()) goto loc_820D4144;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmpwi cr6,r5,4
	cr6.compare<int32_t>(ctx.r5.s32, 4, xer);
	// blt cr6,0x820d4100
	if (cr6.getLT()) goto loc_820D4100;
	// b 0x820d4174
	goto loc_820D4174;
loc_820D4144:
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// rlwinm r8,r7,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r6,r1,-224
	ctx.r6.s64 = ctx.r1.s64 + -224;
	// addi r5,r1,-216
	ctx.r5.s64 = ctx.r1.s64 + -216;
	// add r8,r8,r10
	ctx.r8.u64 = ctx.r8.u64 + ctx.r10.u64;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// lfdx f0,r11,r6
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r11.u32 + ctx.r6.u32);
	// lfdx f13,r11,r5
	ctx.f13.u64 = PPC_LOAD_U64(r11.u32 + ctx.r5.u32);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// stfs f0,0(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 0, temp.u32);
	// stfs f13,4(r8)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r8.u32 + 4, temp.u32);
loc_820D4174:
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// li r6,0
	ctx.r6.s64 = 0;
	// cmpwi cr6,r7,4
	cr6.compare<int32_t>(ctx.r7.s32, 4, xer);
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// blt cr6,0x820d422c
	if (cr6.getLT()) goto loc_820D422C;
	// addi r11,r7,-4
	r11.s64 = ctx.r7.s64 + -4;
	// rlwinm r11,r11,30,2,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r8,r11,1
	ctx.r8.s64 = r11.s64 + 1;
	// addi r11,r10,8
	r11.s64 = ctx.r10.s64 + 8;
	// rlwinm r6,r8,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
loc_820D419C:
	// lfs f0,48(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	f0.f64 = double(temp.f32);
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// lfs f13,-8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -8);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// stfs f0,-8(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + -8, temp.u32);
	// lfs f0,56(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 56);
	f0.f64 = double(temp.f32);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// lfs f13,-4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -4);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,-4(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + -4, temp.u32);
	// lfs f0,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	f0.f64 = double(temp.f32);
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,0(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// lfs f0,56(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 56);
	f0.f64 = double(temp.f32);
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// stfs f0,4(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4, temp.u32);
	// lfs f0,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// stfs f0,8(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8, temp.u32);
	// lfs f0,56(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 56);
	f0.f64 = double(temp.f32);
	// lfs f13,12(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,12(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 12, temp.u32);
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,16(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 16, temp.u32);
	// lfs f0,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	f0.f64 = double(temp.f32);
	// lfs f13,56(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,20(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 20, temp.u32);
	// addi r11,r11,32
	r11.s64 = r11.s64 + 32;
	// bne cr6,0x820d419c
	if (!cr6.getEQ()) goto loc_820D419C;
loc_820D422C:
	// cmpw cr6,r6,r7
	cr6.compare<int32_t>(ctx.r6.s32, ctx.r7.s32, xer);
	// bge cr6,0x820d4270
	if (!cr6.getLT()) goto loc_820D4270;
	// rlwinm r11,r6,3,0,28
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// subf r10,r6,r7
	ctx.r10.s64 = ctx.r7.s64 - ctx.r6.s64;
loc_820D4240:
	// lfs f13,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// lfs f0,48(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,0(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// lfs f0,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	f0.f64 = double(temp.f32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lfs f13,56(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,4(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4, temp.u32);
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// bne cr6,0x820d4240
	if (!cr6.getEQ()) goto loc_820D4240;
loc_820D4270:
	// lfd f30,-56(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820D4280"))) PPC_WEAK_FUNC(sub_820D4280);
PPC_FUNC_IMPL(__imp__sub_820D4280) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	// stfd f31,-8(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -8, f31.u64);
	// lfs f0,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f13,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f8,f0,f13
	ctx.f8.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,4(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f7,f12,f13
	ctx.f7.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// lfs f0,28(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 28);
	f0.f64 = double(temp.f32);
	// lfs f12,32(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// lfs f9,12(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// lfs f13,24(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 24);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f2,f9,f12
	ctx.f2.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// lfs f11,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,8(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f6,f11,f10
	ctx.f6.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// lfs f10,20(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,16(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f3,f10,f0
	ctx.f3.f64 = double(float(ctx.f10.f64 * f0.f64));
	// lfs f5,64(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 64);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f31,f13,f11
	f31.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// fadds f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fmuls f4,f0,f7
	ctx.f4.f64 = double(float(f0.f64 * ctx.f7.f64));
	// fmsubs f10,f13,f10,f2
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64 - ctx.f2.f64));
	// fmsubs f11,f11,f12,f3
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f12.f64 - ctx.f3.f64));
	// fmsubs f0,f9,f0,f31
	f0.f64 = double(float(ctx.f9.f64 * f0.f64 - f31.f64));
	// fmadds f4,f13,f8,f4
	ctx.f4.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 + ctx.f4.f64));
	// fmadds f13,f12,f6,f4
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f6.f64 + ctx.f4.f64));
	// fcmpu cr6,f13,f5
	cr6.compare(ctx.f13.f64, ctx.f5.f64);
	// bgt cr6,0x820d436c
	if (cr6.getGT()) goto loc_820D436C;
	// lfs f12,60(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 60);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f1
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f1.f64));
	// fcmpu cr6,f13,f12
	cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// blt cr6,0x820d436c
	if (cr6.getLT()) goto loc_820D436C;
	// fmr f13,f9
	ctx.f13.f64 = ctx.f9.f64;
	// lfs f12,20(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// lfs f9,16(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// lfs f5,56(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 56);
	ctx.f5.f64 = double(temp.f32);
	// fadds f5,f5,f1
	ctx.f5.f64 = double(float(ctx.f5.f64 + ctx.f1.f64));
	// fmuls f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f8.f64));
	// fmadds f13,f12,f6,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f6.f64 + ctx.f13.f64));
	// fmadds f13,f7,f9,f13
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f9.f64 + ctx.f13.f64));
	// fcmpu cr6,f13,f5
	cr6.compare(ctx.f13.f64, ctx.f5.f64);
	// bgt cr6,0x820d436c
	if (cr6.getGT()) goto loc_820D436C;
	// lfs f12,52(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 52);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f1
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f1.f64));
	// fcmpu cr6,f13,f12
	cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// blt cr6,0x820d436c
	if (cr6.getLT()) goto loc_820D436C;
	// fmuls f12,f10,f7
	ctx.f12.f64 = double(float(ctx.f10.f64 * ctx.f7.f64));
	// lfs f13,48(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f1.f64));
	// fmadds f0,f0,f6,f12
	f0.f64 = double(float(f0.f64 * ctx.f6.f64 + ctx.f12.f64));
	// fmadds f0,f11,f8,f0
	f0.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 + f0.f64));
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x820d436c
	if (cr6.getGT()) goto loc_820D436C;
	// lfs f13,44(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 44);
	ctx.f13.f64 = double(temp.f32);
	// li r3,1
	ctx.r3.s64 = 1;
	// fsubs f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f1.f64));
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820d4370
	if (!cr6.getLT()) goto loc_820D4370;
loc_820D436C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_820D4370:
	// lfd f31,-8(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D4378"))) PPC_WEAK_FUNC(sub_820D4378);
PPC_FUNC_IMPL(__imp__sub_820D4378) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d43e0
	if (cr6.getEQ()) goto loc_820D43E0;
loc_820D4388:
	// lbz r11,1(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// bne cr6,0x820d43a4
	if (!cr6.getEQ()) goto loc_820D43A4;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmpw cr6,r11,r4
	cr6.compare<int32_t>(r11.s32, ctx.r4.s32, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
loc_820D43A4:
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d43b8
	if (cr6.getEQ()) goto loc_820D43B8;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// b 0x820d43d8
	goto loc_820D43D8;
loc_820D43B8:
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d43d4
	if (!cr6.getEQ()) goto loc_820D43D4;
	// lwz r3,8(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x820d43b8
	if (!cr6.getEQ()) goto loc_820D43B8;
	// blr 
	return;
loc_820D43D4:
	// lwz r3,12(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
loc_820D43D8:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x820d4388
	if (!cr6.getEQ()) goto loc_820D4388;
loc_820D43E0:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D43E8"))) PPC_WEAK_FUNC(sub_820D43E8);
PPC_FUNC_IMPL(__imp__sub_820D43E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed12c
	// stfd f31,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// li r28,1
	r28.s64 = 1;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r30,0(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820d464c
	if (cr6.getEQ()) goto loc_820D464C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
loc_820D4424:
	// lbz r11,1(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 1);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// bne cr6,0x820d4608
	if (!cr6.getEQ()) goto loc_820D4608;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r31,4(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82118bc8
	sub_82118BC8(ctx, base);
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x820d44e8
	if (!cr6.getEQ()) goto loc_820D44E8;
	// lfs f11,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fcmpu cr6,f11,f31
	cr6.compare(ctx.f11.f64, f31.f64);
	// bgt cr6,0x820d4460
	if (cr6.getGT()) goto loc_820D4460;
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// b 0x820d4464
	goto loc_820D4464;
loc_820D4460:
	// lfs f0,8(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
loc_820D4464:
	// lfs f12,16(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f0,f0,f11
	f0.f64 = double(float(f0.f64 * ctx.f11.f64));
	// fcmpu cr6,f12,f31
	cr6.compare(ctx.f12.f64, f31.f64);
	// bgt cr6,0x820d447c
	if (cr6.getGT()) goto loc_820D447C;
	// lfs f13,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// b 0x820d4480
	goto loc_820D4480;
loc_820D447C:
	// lfs f13,16(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
loc_820D4480:
	// fmadds f0,f13,f12,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + f0.f64));
	// lfs f13,32(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// bgt cr6,0x820d4498
	if (cr6.getGT()) goto loc_820D4498;
	// lfs f10,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// b 0x820d449c
	goto loc_820D449C;
loc_820D4498:
	// lfs f10,24(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
loc_820D449C:
	// fmadds f0,f10,f13,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + f0.f64));
	// lfs f10,48(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	ctx.f10.f64 = double(temp.f32);
	// fcmpu cr6,f11,f31
	cr6.compare(ctx.f11.f64, f31.f64);
	// fadds f9,f10,f0
	ctx.f9.f64 = double(float(ctx.f10.f64 + f0.f64));
	// blt cr6,0x820d44b8
	if (cr6.getLT()) goto loc_820D44B8;
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// b 0x820d44bc
	goto loc_820D44BC;
loc_820D44B8:
	// lfs f0,8(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
loc_820D44BC:
	// fmuls f0,f0,f11
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f0.f64 * ctx.f11.f64));
	// fcmpu cr6,f12,f31
	cr6.compare(ctx.f12.f64, f31.f64);
	// blt cr6,0x820d44d0
	if (cr6.getLT()) goto loc_820D44D0;
	// lfs f11,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// b 0x820d44d4
	goto loc_820D44D4;
loc_820D44D0:
	// lfs f11,16(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
loc_820D44D4:
	// fmadds f0,f11,f12,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f11.f64 * ctx.f12.f64 + f0.f64));
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// blt cr6,0x820d45c8
	if (cr6.getLT()) goto loc_820D45C8;
	// lfs f12,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// b 0x820d45cc
	goto loc_820D45CC;
loc_820D44E8:
	// cmpwi cr6,r27,1
	cr6.compare<int32_t>(r27.s32, 1, xer);
	// bne cr6,0x820d455c
	if (!cr6.getEQ()) goto loc_820D455C;
	// lfs f11,4(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fcmpu cr6,f11,f31
	cr6.compare(ctx.f11.f64, f31.f64);
	// bgt cr6,0x820d4504
	if (cr6.getGT()) goto loc_820D4504;
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// b 0x820d4508
	goto loc_820D4508;
loc_820D4504:
	// lfs f0,8(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
loc_820D4508:
	// lfs f12,20(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f0,f0,f11
	f0.f64 = double(float(f0.f64 * ctx.f11.f64));
	// fcmpu cr6,f12,f31
	cr6.compare(ctx.f12.f64, f31.f64);
	// bgt cr6,0x820d4520
	if (cr6.getGT()) goto loc_820D4520;
	// lfs f13,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// b 0x820d4524
	goto loc_820D4524;
loc_820D4520:
	// lfs f13,16(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
loc_820D4524:
	// fmadds f0,f13,f12,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + f0.f64));
	// lfs f13,36(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// bgt cr6,0x820d453c
	if (cr6.getGT()) goto loc_820D453C;
	// lfs f10,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// b 0x820d4540
	goto loc_820D4540;
loc_820D453C:
	// lfs f10,24(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
loc_820D4540:
	// fmadds f0,f10,f13,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + f0.f64));
	// lfs f10,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	ctx.f10.f64 = double(temp.f32);
	// fcmpu cr6,f11,f31
	cr6.compare(ctx.f11.f64, f31.f64);
	// fadds f9,f10,f0
	ctx.f9.f64 = double(float(ctx.f10.f64 + f0.f64));
	// blt cr6,0x820d44b8
	if (cr6.getLT()) goto loc_820D44B8;
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// b 0x820d44bc
	goto loc_820D44BC;
loc_820D455C:
	// lfs f11,8(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fcmpu cr6,f11,f31
	cr6.compare(ctx.f11.f64, f31.f64);
	// bgt cr6,0x820d4570
	if (cr6.getGT()) goto loc_820D4570;
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// b 0x820d4574
	goto loc_820D4574;
loc_820D4570:
	// lfs f0,8(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
loc_820D4574:
	// lfs f12,24(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f0,f0,f11
	f0.f64 = double(float(f0.f64 * ctx.f11.f64));
	// fcmpu cr6,f12,f31
	cr6.compare(ctx.f12.f64, f31.f64);
	// bgt cr6,0x820d458c
	if (cr6.getGT()) goto loc_820D458C;
	// lfs f13,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// b 0x820d4590
	goto loc_820D4590;
loc_820D458C:
	// lfs f13,16(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
loc_820D4590:
	// fmadds f0,f13,f12,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + f0.f64));
	// lfs f13,40(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// bgt cr6,0x820d45a8
	if (cr6.getGT()) goto loc_820D45A8;
	// lfs f10,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// b 0x820d45ac
	goto loc_820D45AC;
loc_820D45A8:
	// lfs f10,24(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
loc_820D45AC:
	// fmadds f0,f10,f13,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + f0.f64));
	// lfs f10,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f10.f64 = double(temp.f32);
	// fcmpu cr6,f11,f31
	cr6.compare(ctx.f11.f64, f31.f64);
	// fadds f9,f10,f0
	ctx.f9.f64 = double(float(ctx.f10.f64 + f0.f64));
	// blt cr6,0x820d44b8
	if (cr6.getLT()) goto loc_820D44B8;
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// b 0x820d44bc
	goto loc_820D44BC;
loc_820D45C8:
	// lfs f12,24(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
loc_820D45CC:
	// fmadds f0,f12,f13,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + f0.f64));
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// fadds f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 + f0.f64));
	// bne cr6,0x820d45e8
	if (!cr6.getEQ()) goto loc_820D45E8;
	// lfs f13,0(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f9,f13
	cr6.compare(ctx.f9.f64, ctx.f13.f64);
	// ble cr6,0x820d45f4
	if (!cr6.getGT()) goto loc_820D45F4;
loc_820D45E8:
	// stfs f9,0(r26)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(r26.u32 + 0, temp.u32);
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// bne cr6,0x820d4600
	if (!cr6.getEQ()) goto loc_820D4600;
loc_820D45F4:
	// lfs f13,0(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r25.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820d4604
	if (!cr6.getLT()) goto loc_820D4604;
loc_820D4600:
	// stfs f0,0(r25)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r25.u32 + 0, temp.u32);
loc_820D4604:
	// li r28,0
	r28.s64 = 0;
loc_820D4608:
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d461c
	if (cr6.getEQ()) goto loc_820D461C;
	// mr r30,r11
	r30.u64 = r11.u64;
	// b 0x820d4644
	goto loc_820D4644;
loc_820D461C:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d4640
	if (!cr6.getEQ()) goto loc_820D4640;
	// lwz r30,8(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x820d461c
	if (!cr6.getEQ()) goto loc_820D461C;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-72(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x823ed17c
	return;
loc_820D4640:
	// lwz r30,12(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 12);
loc_820D4644:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x820d4424
	if (!cr6.getEQ()) goto loc_820D4424;
loc_820D464C:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-72(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_820D4658"))) PPC_WEAK_FUNC(sub_820D4658);
PPC_FUNC_IMPL(__imp__sub_820D4658) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// bl 0x820d43e8
	sub_820D43E8(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d43e8
	sub_820D43E8(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820D4698"))) PPC_WEAK_FUNC(sub_820D4698);
PPC_FUNC_IMPL(__imp__sub_820D4698) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f0.f64 = double(temp.f32);
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,92(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// bl 0x8210d660
	sub_8210D660(ctx, base);
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stfs f0,0(r28)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,92(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// bl 0x8210d660
	sub_8210D660(ctx, base);
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stfs f0,0(r27)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r27.u32 + 0, temp.u32);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lfs f0,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f0,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,92(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// bl 0x8210d660
	sub_8210D660(ctx, base);
	// lfs f0,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stfs f0,4(r28)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r28.u32 + 4, temp.u32);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lfs f0,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f0,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,92(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// bl 0x8210d660
	sub_8210D660(ctx, base);
	// lfs f0,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
	// stfs f0,4(r27)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r27.u32 + 4, temp.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820D4770"))) PPC_WEAK_FUNC(sub_820D4770);
PPC_FUNC_IMPL(__imp__sub_820D4770) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x820cca38
	sub_820CCA38(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d47c4
	if (cr6.getEQ()) goto loc_820D47C4;
loc_820D4794:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x820d47b8
	if (!cr6.getEQ()) goto loc_820D47B8;
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// extsh r10,r31
	ctx.r10.s64 = r31.s16;
	// lhz r9,6(r3)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r3.u32 + 6);
	// extsh r9,r9
	ctx.r9.s64 = ctx.r9.s16;
	// cmpw cr6,r9,r10
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, xer);
	// beq cr6,0x820d47c8
	if (cr6.getEQ()) goto loc_820D47C8;
loc_820D47B8:
	// lwz r11,40(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d4794
	if (!cr6.getEQ()) goto loc_820D4794;
loc_820D47C4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_820D47C8:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D47E0"))) PPC_WEAK_FUNC(sub_820D47E0);
PPC_FUNC_IMPL(__imp__sub_820D47E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// bl 0x820cca38
	sub_820CCA38(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820d4854
	if (cr6.getEQ()) goto loc_820D4854;
loc_820D4804:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x820d4848
	if (!cr6.getEQ()) goto loc_820D4848;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmpw cr6,r11,r29
	cr6.compare<int32_t>(r11.s32, r29.s32, xer);
	// bne cr6,0x820d4848
	if (!cr6.getEQ()) goto loc_820D4848;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cdfc8
	sub_820CDFC8(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x820ce060
	sub_820CE060(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820d4860
	if (!cr6.getEQ()) goto loc_820D4860;
loc_820D4848:
	// lwz r31,40(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x820d4804
	if (!cr6.getEQ()) goto loc_820D4804;
loc_820D4854:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed18c
	return;
loc_820D4860:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820D4870"))) PPC_WEAK_FUNC(sub_820D4870);
PPC_FUNC_IMPL(__imp__sub_820D4870) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d48d4
	if (cr6.getEQ()) goto loc_820D48D4;
	// lwz r3,152(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 152);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d48b4
	if (cr6.getEQ()) goto loc_820D48B4;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d48b4
	if (cr6.getEQ()) goto loc_820D48B4;
	// lwz r3,152(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 152);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820D48B4:
	// lwz r3,156(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 156);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d48d4
	if (cr6.getEQ()) goto loc_820D48D4;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d48d4
	if (cr6.getEQ()) goto loc_820D48D4;
	// lwz r3,156(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 156);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820D48D4:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// oris r11,r11,32768
	r11.u64 = r11.u64 | 2147483648;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D48F8"))) PPC_WEAK_FUNC(sub_820D48F8);
PPC_FUNC_IMPL(__imp__sub_820D48F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,100(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 100);
	// rlwinm r9,r10,0,25,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820d4918
	if (cr6.getEQ()) goto loc_820D4918;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// lwz r11,68(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// b 0x820d4928
	goto loc_820D4928;
loc_820D4918:
	// rlwinm r10,r10,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
loc_820D4928:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r10,24(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820d495c
	if (cr6.getEQ()) goto loc_820D495C;
	// lbz r10,3(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// li r9,255
	ctx.r9.s64 = 255;
	// stb r9,205(r11)
	PPC_STORE_U8(r11.u32 + 205, ctx.r9.u8);
	// stb r10,204(r11)
	PPC_STORE_U8(r11.u32 + 204, ctx.r10.u8);
	// blr 
	return;
loc_820D495C:
	// li r10,255
	ctx.r10.s64 = 255;
	// stb r10,204(r11)
	PPC_STORE_U8(r11.u32 + 204, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D4968"))) PPC_WEAK_FUNC(sub_820D4968);
PPC_FUNC_IMPL(__imp__sub_820D4968) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32013
	r11.s64 = -2098003968;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r10,r11,2408
	ctx.r10.s64 = r11.s64 + 2408;
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
loc_820D497C:
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// clrlwi r7,r7,31
	ctx.r7.u64 = ctx.r7.u32 & 0x1;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x820d49a8
	if (!cr6.getEQ()) goto loc_820D49A8;
	// addi r9,r9,72
	ctx.r9.s64 = ctx.r9.s64 + 72;
	// addi r7,r10,2880
	ctx.r7.s64 = ctx.r10.s64 + 2880;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmpw cr6,r9,r7
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r7.s32, xer);
	// blt cr6,0x820d497c
	if (cr6.getLT()) goto loc_820D497C;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_820D49A8:
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r7,r10,68
	ctx.r7.s64 = ctx.r10.s64 + 68;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,3,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// stwx r8,r11,r7
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, ctx.r8.u32);
	// stw r8,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r8.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D49C8"))) PPC_WEAK_FUNC(sub_820D49C8);
PPC_FUNC_IMPL(__imp__sub_820D49C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lbz r11,2(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 2);
	// lfs f13,112(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r11,r11,0,0,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d4a04
	if (!cr6.getEQ()) goto loc_820D4A04;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,3908(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3908);
	f0.f64 = double(temp.f32);
	// addi r11,r1,-16
	r11.s64 = ctx.r1.s64 + -16;
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f13,116(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 116);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r3,-16(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// blr 
	return;
loc_820D4A04:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r10,r1,-16
	ctx.r10.s64 = ctx.r1.s64 + -16;
	// lfs f0,12468(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12468);
	f0.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, f0.u32);
	// lwz r3,-16(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D4A28"))) PPC_WEAK_FUNC(sub_820D4A28);
PPC_FUNC_IMPL(__imp__sub_820D4A28) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lbz r11,2(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 2);
	// rlwinm r11,r11,0,0,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d4a40
	if (!cr6.getEQ()) goto loc_820D4A40;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_820D4A40:
	// addi r11,r1,-16
	r11.s64 = ctx.r1.s64 + -16;
	// lfs f0,112(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	f0.f64 = double(temp.f32);
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,-16(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// srawi r11,r11,2
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x3) != 0);
	r11.s64 = r11.s32 >> 2;
	// addi r3,r11,1
	ctx.r3.s64 = r11.s64 + 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D4A60"))) PPC_WEAK_FUNC(sub_820D4A60);
PPC_FUNC_IMPL(__imp__sub_820D4A60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820d4ab0
	if (cr6.getEQ()) goto loc_820D4AB0;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_820D4A74:
	// lhz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U16(r11.u32 + 0);
	// cmplwi cr6,r9,10
	cr6.compare<uint32_t>(ctx.r9.u32, 10, xer);
	// beq cr6,0x820d4ab8
	if (cr6.getEQ()) goto loc_820D4AB8;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d4a74
	if (!cr6.getEQ()) goto loc_820D4A74;
	// lwz r11,20(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d4ab0
	if (cr6.getEQ()) goto loc_820D4AB0;
loc_820D4A98:
	// lhz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 0);
	// cmplwi cr6,r10,10
	cr6.compare<uint32_t>(ctx.r10.u32, 10, xer);
	// beq cr6,0x820d4ab8
	if (cr6.getEQ()) goto loc_820D4AB8;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d4a98
	if (!cr6.getEQ()) goto loc_820D4A98;
loc_820D4AB0:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_820D4AB8:
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D4AC0"))) PPC_WEAK_FUNC(sub_820D4AC0);
PPC_FUNC_IMPL(__imp__sub_820D4AC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,20(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x820d4a60
	sub_820D4A60(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820D4AD0"))) PPC_WEAK_FUNC(sub_820D4AD0);
PPC_FUNC_IMPL(__imp__sub_820D4AD0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lfs f2,20(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// lwz r3,24(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// bl 0x82110ac8
	sub_82110AC8(ctx, base);
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// lbz r9,2(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// li r7,0
	ctx.r7.s64 = 0;
	// mulli r6,r11,79
	ctx.r6.s64 = r11.s64 * 79;
	// lbz r10,1(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// mulli r5,r9,21
	ctx.r5.s64 = ctx.r9.s64 * 21;
	// add r6,r6,r5
	ctx.r6.u64 = ctx.r6.u64 + ctx.r5.u64;
	// mulli r5,r10,156
	ctx.r5.s64 = ctx.r10.s64 * 156;
	// add r6,r6,r5
	ctx.r6.u64 = ctx.r6.u64 + ctx.r5.u64;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// srawi r11,r6,8
	xer.ca = (ctx.r6.s32 < 0) & ((ctx.r6.u32 & 0xFF) != 0);
	r11.s64 = ctx.r6.s32 >> 8;
	// li r8,0
	ctx.r8.s64 = 0;
	// subfic r11,r11,255
	xer.ca = r11.u32 <= 255;
	r11.s64 = 255 - r11.s64;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f13,f0
	ctx.f13.f64 = double(float(f0.f64));
	// lfs f0,12888(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12888);
	f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fctidz f0,f0
	f0.s64 = (f0.f64 > double(LLONG_MAX)) ? LLONG_MAX : _mm_cvttsd_si64(_mm_load_sd(&f0.f64));
	// stfd f0,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, f0.u64);
	// lbz r11,87(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 87);
	// stb r11,3(r31)
	PPC_STORE_U8(r31.u32 + 3, r11.u8);
	// ble cr6,0x820d4b68
	if (!cr6.getGT()) goto loc_820D4B68;
	// li r7,1
	ctx.r7.s64 = 1;
	// b 0x820d4b6c
	goto loc_820D4B6C;
loc_820D4B68:
	// li r8,1
	ctx.r8.s64 = 1;
loc_820D4B6C:
	// lbzx r11,r7,r31
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + r31.u32);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// ble cr6,0x820d4b84
	if (!cr6.getGT()) goto loc_820D4B84;
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
	// li r7,2
	ctx.r7.s64 = 2;
	// b 0x820d4ba0
	goto loc_820D4BA0;
loc_820D4B84:
	// lbzx r11,r8,r31
	r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + r31.u32);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// ble cr6,0x820d4b98
	if (!cr6.getGT()) goto loc_820D4B98;
	// li r9,2
	ctx.r9.s64 = 2;
	// b 0x820d4ba0
	goto loc_820D4BA0;
loc_820D4B98:
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
	// li r8,2
	ctx.r8.s64 = 2;
loc_820D4BA0:
	// lbzx r11,r7,r31
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + r31.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d4be4
	if (cr6.getEQ()) goto loc_820D4BE4;
	// lbzx r10,r8,r31
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + r31.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// lbzx r6,r9,r31
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r9.u32 + r31.u32);
	// twllei r11,0
	// subf r10,r10,r11
	ctx.r10.s64 = r11.s64 - ctx.r10.s64;
	// mullw r6,r6,r10
	ctx.r6.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r10.s32);
	// stbx r5,r8,r31
	PPC_STORE_U8(ctx.r8.u32 + r31.u32, ctx.r5.u8);
	// divw r8,r6,r11
	ctx.r8.s32 = ctx.r6.s32 / r11.s32;
	// rotlwi r6,r6,1
	ctx.r6.u64 = __builtin_rotateleft32(ctx.r6.u32, 1);
	// addi r6,r6,-1
	ctx.r6.s64 = ctx.r6.s64 + -1;
	// andc r11,r11,r6
	r11.u64 = r11.u64 & ~ctx.r6.u64;
	// stbx r8,r9,r31
	PPC_STORE_U8(ctx.r9.u32 + r31.u32, ctx.r8.u8);
	// stbx r10,r7,r31
	PPC_STORE_U8(ctx.r7.u32 + r31.u32, ctx.r10.u8);
	// twlgei r11,-1
loc_820D4BE4:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// lbz r10,1(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// lbz r9,2(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// rlwinm r11,r11,31,1,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r9,r9,31,1,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 31) & 0x7FFFFFFF;
	// stb r11,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r11.u8);
	// stb r10,1(r31)
	PPC_STORE_U8(r31.u32 + 1, ctx.r10.u8);
	// stb r9,2(r31)
	PPC_STORE_U8(r31.u32 + 2, ctx.r9.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D4C20"))) PPC_WEAK_FUNC(sub_820D4C20);
PPC_FUNC_IMPL(__imp__sub_820D4C20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d4c70
	if (!cr6.getEQ()) goto loc_820D4C70;
	// bl 0x820d4ad0
	sub_820D4AD0(ctx, base);
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// lbz r10,1(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// lbz r9,2(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// rlwinm r11,r11,31,1,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r9,r9,31,1,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 31) & 0x7FFFFFFF;
	// stb r11,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r11.u8);
	// stb r10,1(r31)
	PPC_STORE_U8(r31.u32 + 1, ctx.r10.u8);
	// stb r9,2(r31)
	PPC_STORE_U8(r31.u32 + 2, ctx.r9.u8);
loc_820D4C70:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D4C88"))) PPC_WEAK_FUNC(sub_820D4C88);
PPC_FUNC_IMPL(__imp__sub_820D4C88) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister r11{};
	PPCRegister r31{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// lbz r7,0(r4)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// mr r6,r11
	ctx.r6.u64 = r11.u64;
	// lbz r10,1(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1);
	// subf r11,r11,r7
	r11.s64 = ctx.r7.s64 - r11.s64;
	// lbz r9,2(r3)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r3.u32 + 2);
	// lbz r8,3(r3)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r3.u32 + 3);
	// addi r11,r11,7
	r11.s64 = r11.s64 + 7;
	// srawi r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	// add r11,r11,r6
	r11.u64 = r11.u64 + ctx.r6.u64;
	// stb r11,0(r3)
	PPC_STORE_U8(ctx.r3.u32 + 0, r11.u8);
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r11,r11,7
	r11.s64 = r11.s64 + 7;
	// srawi r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stb r11,1(r3)
	PPC_STORE_U8(ctx.r3.u32 + 1, r11.u8);
	// lbz r11,2(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 2);
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// addi r11,r11,7
	r11.s64 = r11.s64 + 7;
	// srawi r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// stb r11,2(r3)
	PPC_STORE_U8(ctx.r3.u32 + 2, r11.u8);
	// lbz r11,3(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 3);
	// subf r11,r8,r11
	r11.s64 = r11.s64 - ctx.r8.s64;
	// addi r11,r11,7
	r11.s64 = r11.s64 + 7;
	// srawi r11,r11,3
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7) != 0);
	r11.s64 = r11.s32 >> 3;
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// stb r11,3(r3)
	PPC_STORE_U8(ctx.r3.u32 + 3, r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D4D08"))) PPC_WEAK_FUNC(sub_820D4D08);
PPC_FUNC_IMPL(__imp__sub_820D4D08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d4dd8
	if (cr6.getEQ()) goto loc_820D4DD8;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// bl 0x820d4a60
	sub_820D4A60(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r31,88
	ctx.r3.s64 = r31.s64 + 88;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// lfs f6,24(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 24);
	ctx.f6.f64 = double(temp.f32);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lfs f5,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,16(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// lfs f1,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x820d3be8
	sub_820D3BE8(ctx, base);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820d3a48
	sub_820D3A48(ctx, base);
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// lfs f0,92(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	f0.f64 = double(temp.f32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// fadds f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 + f0.f64));
	// stfs f0,72(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 72, temp.u32);
	// bl 0x820d3ab0
	sub_820D3AB0(ctx, base);
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// lfs f0,92(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	f0.f64 = double(temp.f32);
	// fadds f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 + f0.f64));
	// stfs f0,68(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 68, temp.u32);
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// cmplwi cr6,r11,40
	cr6.compare<uint32_t>(r11.u32, 40, xer);
	// bne cr6,0x820d4dd8
	if (!cr6.getEQ()) goto loc_820D4DD8;
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,72(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 72);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,2940(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2940);
	f0.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// stfs f0,72(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 72, temp.u32);
loc_820D4DD8:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D4DF0"))) PPC_WEAK_FUNC(sub_820D4DF0);
PPC_FUNC_IMPL(__imp__sub_820D4DF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x820d4e20
	if (!cr6.getEQ()) goto loc_820D4E20;
	// bl 0x820cca48
	sub_820CCA48(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
loc_820D4E20:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x820d4e48
	if (!cr6.getEQ()) goto loc_820D4E48;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// cmplwi cr6,r11,40
	cr6.compare<uint32_t>(r11.u32, 40, xer);
	// bne cr6,0x820d4e40
	if (!cr6.getEQ()) goto loc_820D4E40;
	// bl 0x821186e0
	sub_821186E0(ctx, base);
	// b 0x820d4e44
	goto loc_820D4E44;
loc_820D4E40:
	// bl 0x82118550
	sub_82118550(ctx, base);
loc_820D4E44:
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
loc_820D4E48:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x820d4f44
	if (cr6.getEQ()) goto loc_820D4F44;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x820d4f84
	if (cr6.getEQ()) goto loc_820D4F84;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r30,0
	r30.s64 = 0;
	// stw r28,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r28.u32);
	// rlwinm r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r30,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r30.u32);
	// beq cr6,0x820d4e90
	if (cr6.getEQ()) goto loc_820D4E90;
	// li r4,1
	ctx.r4.s64 = 1;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x8209cbc8
	sub_8209CBC8(ctx, base);
	// lbz r11,2(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// stw r3,104(r31)
	PPC_STORE_U32(r31.u32 + 104, ctx.r3.u32);
	// ori r11,r11,8
	r11.u64 = r11.u64 | 8;
	// b 0x820d4e9c
	goto loc_820D4E9C;
loc_820D4E90:
	// lbz r11,2(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// stw r30,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r30.u32);
	// andi. r11,r11,247
	r11.u64 = r11.u64 & 247;
	cr0.compare<int32_t>(r11.s32, 0, xer);
loc_820D4E9C:
	// stb r11,2(r31)
	PPC_STORE_U8(r31.u32 + 2, r11.u8);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// li r9,-1
	ctx.r9.s64 = -1;
	// stw r29,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r29.u32);
	// stw r30,108(r31)
	PPC_STORE_U32(r31.u32 + 108, r30.u32);
	// stb r30,120(r31)
	PPC_STORE_U8(r31.u32 + 120, r30.u8);
	// lfs f31,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// stb r30,121(r31)
	PPC_STORE_U8(r31.u32 + 121, r30.u8);
	// stfs f31,112(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 112, temp.u32);
	// stb r30,122(r31)
	PPC_STORE_U8(r31.u32 + 122, r30.u8);
	// stb r30,123(r31)
	PPC_STORE_U8(r31.u32 + 123, r30.u8);
	// lis r11,-32164
	r11.s64 = -2107899904;
	// stb r30,124(r31)
	PPC_STORE_U8(r31.u32 + 124, r30.u8);
	// stb r30,125(r31)
	PPC_STORE_U8(r31.u32 + 125, r30.u8);
	// addi r11,r11,-3616
	r11.s64 = r11.s64 + -3616;
	// stb r30,126(r31)
	PPC_STORE_U8(r31.u32 + 126, r30.u8);
	// stb r30,127(r31)
	PPC_STORE_U8(r31.u32 + 127, r30.u8);
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// sth r9,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r9.u16);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// stw r30,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r30.u32);
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 4);
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// rlwinm r10,r10,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// lfsx f1,r10,r11
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x823ada90
	sub_823ADA90(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stfs f31,12(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r29.u32 + 12, temp.u32);
	// stw r31,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r31.u32);
	// stb r11,0(r29)
	PPC_STORE_U8(r29.u32 + 0, r11.u8);
	// stfs f31,88(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 88, temp.u32);
	// stfs f31,16(r29)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r29.u32 + 16, temp.u32);
	// stfs f31,92(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 92, temp.u32);
	// stfs f31,20(r29)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r29.u32 + 20, temp.u32);
	// stfs f31,96(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 96, temp.u32);
	// stw r30,24(r29)
	PPC_STORE_U32(r29.u32 + 24, r30.u32);
loc_820D4F34:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
loc_820D4F44:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x820d4f34
	if (cr6.getEQ()) goto loc_820D4F34;
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// cmplwi cr6,r11,40
	cr6.compare<uint32_t>(r11.u32, 40, xer);
	// bne cr6,0x820d4f70
	if (!cr6.getEQ()) goto loc_820D4F70;
	// bl 0x821188f8
	sub_821188F8(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
loc_820D4F70:
	// bl 0x821188f8
	sub_821188F8(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
loc_820D4F84:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820ccb00
	sub_820CCB00(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820D4FA0"))) PPC_WEAK_FUNC(sub_820D4FA0);
PPC_FUNC_IMPL(__imp__sub_820D4FA0) {
	PPC_FUNC_PROLOGUE();
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// b 0x820d4df0
	sub_820D4DF0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820D4FB0"))) PPC_WEAK_FUNC(sub_820D4FB0);
PPC_FUNC_IMPL(__imp__sub_820D4FB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lhz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r3.u32 + 4);
	// lis r11,-32164
	r11.s64 = -2107899904;
	// li r6,0
	ctx.r6.s64 = 0;
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// addi r11,r11,-3616
	r11.s64 = r11.s64 + -3616;
	// rlwinm r10,r10,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwzx r4,r10,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x820d4df0
	sub_820D4DF0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820D4FD8"))) PPC_WEAK_FUNC(sub_820D4FD8);
PPC_FUNC_IMPL(__imp__sub_820D4FD8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// addi r4,r31,24
	ctx.r4.s64 = r31.s64 + 24;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// lwz r30,16(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lfs f0,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r28,r31,124
	r28.s64 = r31.s64 + 124;
	// stfs f0,12(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 12, temp.u32);
	// stfs f0,88(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 88, temp.u32);
	// lfs f0,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,16(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 16, temp.u32);
	// stfs f0,92(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 92, temp.u32);
	// lfs f0,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,20(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 20, temp.u32);
	// stfs f0,96(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 96, temp.u32);
	// stw r27,24(r30)
	PPC_STORE_U32(r30.u32 + 24, r27.u32);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d5070
	if (!cr6.getEQ()) goto loc_820D5070;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x820d4ad0
	sub_820D4AD0(ctx, base);
	// lbz r11,0(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 0);
	// lbz r10,1(r28)
	ctx.r10.u64 = PPC_LOAD_U8(r28.u32 + 1);
	// lbz r9,2(r28)
	ctx.r9.u64 = PPC_LOAD_U8(r28.u32 + 2);
	// rlwinm r11,r11,31,1,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r9,r9,31,1,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 31) & 0x7FFFFFFF;
	// stb r11,0(r28)
	PPC_STORE_U8(r28.u32 + 0, r11.u8);
	// stb r10,1(r28)
	PPC_STORE_U8(r28.u32 + 1, ctx.r10.u8);
	// stb r9,2(r28)
	PPC_STORE_U8(r28.u32 + 2, ctx.r9.u8);
loc_820D5070:
	// lbz r11,0(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 0);
	// lbz r10,125(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 125);
	// lbz r9,126(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 126);
	// lbz r8,127(r31)
	ctx.r8.u64 = PPC_LOAD_U8(r31.u32 + 127);
	// stb r11,120(r31)
	PPC_STORE_U8(r31.u32 + 120, r11.u8);
	// stb r10,121(r31)
	PPC_STORE_U8(r31.u32 + 121, ctx.r10.u8);
	// stb r9,122(r31)
	PPC_STORE_U8(r31.u32 + 122, ctx.r9.u8);
	// stb r8,123(r31)
	PPC_STORE_U8(r31.u32 + 123, ctx.r8.u8);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820D5098"))) PPC_WEAK_FUNC(sub_820D5098);
PPC_FUNC_IMPL(__imp__sub_820D5098) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed544
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r31,r7
	r31.u64 = ctx.r7.u64;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// bl 0x820d4a60
	sub_820D4A60(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lfs f31,12(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	f31.f64 = double(temp.f32);
	// lfs f29,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	f29.f64 = double(temp.f32);
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r27.u32);
	// rlwinm r10,r11,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820d5134
	if (cr6.getEQ()) goto loc_820D5134;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lfs f1,14032(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14032);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210b968
	sub_8210B968(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// lfs f0,144(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	f0.f64 = double(temp.f32);
	// lfs f13,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f28,f0,f29,f13
	f28.f64 = double(float(-(f0.f64 * f29.f64 - ctx.f13.f64)));
	// lfs f9,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f27,f9,f29,f10
	f27.f64 = double(float(-(ctx.f9.f64 * f29.f64 - ctx.f10.f64)));
	// lfs f11,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// stfs f28,104(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fnmsubs f30,f12,f29,f11
	f30.f64 = double(float(-(ctx.f12.f64 * f29.f64 - ctx.f11.f64)));
	// stfs f27,112(r1)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// b 0x820d524c
	goto loc_820D524C;
loc_820D5134:
	// rlwinm r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d517c
	if (cr6.getEQ()) goto loc_820D517C;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lfs f0,144(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	f0.f64 = double(temp.f32);
	// lfs f13,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f28,f0,f31,f13
	f28.f64 = double(float(-(f0.f64 * f31.f64 - ctx.f13.f64)));
	// lfs f9,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f27,f9,f31,f10
	f27.f64 = double(float(-(ctx.f9.f64 * f31.f64 - ctx.f10.f64)));
	// lfs f11,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// stfs f28,104(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fnmsubs f30,f12,f31,f11
	f30.f64 = double(float(-(ctx.f12.f64 * f31.f64 - ctx.f11.f64)));
	// stfs f27,112(r1)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// b 0x820d524c
	goto loc_820D524C;
loc_820D517C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lfs f2,8(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x821108b0
	sub_821108B0(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lfs f0,144(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	f0.f64 = double(temp.f32);
	// lfs f13,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f13.f64 = double(temp.f32);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lfs f12,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lbz r4,3(r27)
	ctx.r4.u64 = PPC_LOAD_U8(r27.u32 + 3);
	// lfs f11,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f28,f0,f31,f12
	f28.f64 = double(float(-(f0.f64 * f31.f64 - ctx.f12.f64)));
	// fnmsubs f27,f13,f31,f11
	f27.f64 = double(float(-(ctx.f13.f64 * f31.f64 - ctx.f11.f64)));
	// stfs f28,104(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stfs f27,112(r1)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// bl 0x820d47e0
	sub_820D47E0(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d5238
	if (cr6.getEQ()) goto loc_820D5238;
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// lwz r3,16(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x820cdf80
	sub_820CDF80(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f12,f30
	cr6.compare(ctx.f12.f64, f30.f64);
	// lfs f13,12468(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12468);
	ctx.f13.f64 = double(temp.f32);
	// ble cr6,0x820d522c
	if (!cr6.getGT()) goto loc_820D522C;
	// fsubs f11,f29,f31
	ctx.f11.f64 = double(float(f29.f64 - f31.f64));
	// lfs f10,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f11,f11,f0,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 * f0.f64 + f30.f64));
	// fadds f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fcmpu cr6,f10,f11
	cr6.compare(ctx.f10.f64, ctx.f11.f64);
	// bge cr6,0x820d522c
	if (!cr6.getLT()) goto loc_820D522C;
	// lwz r11,100(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 100);
	// fnmsubs f30,f0,f31,f12
	f30.f64 = double(float(-(f0.f64 * f31.f64 - ctx.f12.f64)));
	// ori r11,r11,32768
	r11.u64 = r11.u64 | 32768;
	// stw r11,100(r30)
	PPC_STORE_U32(r30.u32 + 100, r11.u32);
	// b 0x820d524c
	goto loc_820D524C;
loc_820D522C:
	// fnmsubs f0,f0,f31,f30
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(-(f0.f64 * f31.f64 - f30.f64)));
	// fadds f30,f0,f13
	f30.f64 = double(float(f0.f64 + ctx.f13.f64));
	// b 0x820d524c
	goto loc_820D524C;
loc_820D5238:
	// lfs f0,148(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fnmsubs f13,f0,f31,f30
	ctx.f13.f64 = double(float(-(f0.f64 * f31.f64 - f30.f64)));
	// lfs f0,12468(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12468);
	f0.f64 = double(temp.f32);
	// fadds f30,f13,f0
	f30.f64 = double(float(ctx.f13.f64 + f0.f64));
loc_820D524C:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// stfs f30,108(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// clrlwi r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d5298
	if (!cr6.getEQ()) goto loc_820D5298;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f2,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmr f4,f27
	ctx.f4.f64 = f27.f64;
	// fmr f3,f28
	ctx.f3.f64 = f28.f64;
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d5298
	if (cr6.getEQ()) goto loc_820D5298;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820d4fd8
	sub_820D4FD8(ctx, base);
	// b 0x820d52e8
	goto loc_820D52E8;
loc_820D5298:
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820d4fd8
	sub_820D4FD8(ctx, base);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// clrlwi r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d52dc
	if (!cr6.getEQ()) goto loc_820D52DC;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d52dc
	if (!cr6.getEQ()) goto loc_820D52DC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r11,17524
	ctx.r3.s64 = r11.s64 + 17524;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// b 0x820d52e8
	goto loc_820D52E8;
loc_820D52DC:
	// stfs f28,88(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(r30.u32 + 88, temp.u32);
	// stfs f30,92(r30)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r30.u32 + 92, temp.u32);
	// stfs f27,96(r30)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r30.u32 + 96, temp.u32);
loc_820D52E8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820d4d08
	sub_820D4D08(ctx, base);
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed590
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820D5300"))) PPC_WEAK_FUNC(sub_820D5300);
PPC_FUNC_IMPL(__imp__sub_820D5300) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stfd f29,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, f29.u64);
	// stfd f30,-64(r1)
	PPC_STORE_U64(ctx.r1.u32 + -64, f30.u64);
	// stfd f31,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, f31.u64);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r30,r7
	r30.u64 = ctx.r7.u64;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// bl 0x820d4a60
	sub_820D4A60(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,20(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	f31.f64 = double(temp.f32);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// lfs f1,14036(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14036);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// lfs f1,14032(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14032);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210b8c8
	sub_8210B8C8(ctx, base);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lfs f0,144(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	f0.f64 = double(temp.f32);
	// lfs f13,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f13.f64 = double(temp.f32);
	// clrlwi r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f30,f0,f31,f12
	f30.f64 = double(float(-(f0.f64 * f31.f64 - ctx.f12.f64)));
	// lfs f11,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f11.f64 = double(temp.f32);
	// fnmsubs f29,f13,f31,f10
	f29.f64 = double(float(-(ctx.f13.f64 * f31.f64 - ctx.f10.f64)));
	// lfs f9,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// fnmsubs f31,f11,f31,f9
	f31.f64 = double(float(-(ctx.f11.f64 * f31.f64 - ctx.f9.f64)));
	// stfs f30,88(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f29,92(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// stfs f31,96(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// bne cr6,0x820d53f0
	if (!cr6.getEQ()) goto loc_820D53F0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f2,8(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// fmr f3,f30
	ctx.f3.f64 = f30.f64;
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d53f0
	if (cr6.getEQ()) goto loc_820D53F0;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d4fd8
	sub_820D4FD8(ctx, base);
	// b 0x820d5410
	goto loc_820D5410;
loc_820D53F0:
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d4fd8
	sub_820D4FD8(ctx, base);
	// stfs f30,88(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 88, temp.u32);
	// stfs f29,92(r31)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r31.u32 + 92, temp.u32);
	// stfs f31,96(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 96, temp.u32);
loc_820D5410:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d4d08
	sub_820D4D08(ctx, base);
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// lfd f29,-72(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f30,-64(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f31,-56(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820D5430"))) PPC_WEAK_FUNC(sub_820D5430);
PPC_FUNC_IMPL(__imp__sub_820D5430) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r31,8(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r10,r11,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820d54f0
	if (cr6.getEQ()) goto loc_820D54F0;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d5494
	if (cr6.getEQ()) goto loc_820D5494;
	// lwz r3,68(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d5478
	if (cr6.getEQ()) goto loc_820D5478;
	// bl 0x820d4870
	sub_820D4870(ctx, base);
loc_820D5478:
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,26,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFBF;
	// b 0x820d550c
	goto loc_820D550C;
loc_820D5494:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r11,17624
	ctx.r3.s64 = r11.s64 + 17624;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 4);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// extsh r4,r10
	ctx.r4.s64 = ctx.r10.s16;
	// addi r3,r11,17612
	ctx.r3.s64 = r11.s64 + 17612;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lbz r4,1(r30)
	ctx.r4.u64 = PPC_LOAD_U8(r30.u32 + 1);
	// addi r3,r11,17596
	ctx.r3.s64 = r11.s64 + 17596;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r4,12(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r3,r11,17576
	ctx.r3.s64 = r11.s64 + 17576;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r3,r11,17556
	ctx.r3.s64 = r11.s64 + 17556;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,26,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFBF;
	// b 0x820d550c
	goto loc_820D550C;
loc_820D54F0:
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d5518
	if (cr6.getEQ()) goto loc_820D5518;
	// lwz r3,108(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// bl 0x820d4870
	sub_820D4870(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,25,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFF7F;
loc_820D550C:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// stw r10,108(r31)
	PPC_STORE_U32(r31.u32 + 108, ctx.r10.u32);
loc_820D5518:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D5530"))) PPC_WEAK_FUNC(sub_820D5530);
PPC_FUNC_IMPL(__imp__sub_820D5530) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lfs f13,4(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,4(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// lfs f12,8(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// lfs f9,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fmadds f10,f9,f13,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 + ctx.f10.f64));
	// lfs f9,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f10,f12,f11,f10
	ctx.f10.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f10.f64));
	// fcmpu cr6,f10,f9
	cr6.compare(ctx.f10.f64, ctx.f9.f64);
	// ble cr6,0x820d55b4
	if (!cr6.getGT()) goto loc_820D55B4;
	// fmuls f0,f0,f0
	f0.f64 = double(float(f0.f64 * f0.f64));
	// lfs f8,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f10,f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f10.f64));
	// li r3,1
	ctx.r3.s64 = 1;
	// fmadds f0,f13,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// fmuls f13,f8,f8
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fmadds f0,f11,f11,f0
	f0.f64 = double(float(ctx.f11.f64 * ctx.f11.f64 + f0.f64));
	// fmadds f13,f9,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f9.f64 + ctx.f13.f64));
	// fnmsubs f0,f1,f1,f0
	f0.f64 = double(float(-(ctx.f1.f64 * ctx.f1.f64 - f0.f64)));
	// fmadds f13,f12,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + ctx.f13.f64));
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f10,f0
	cr6.compare(ctx.f10.f64, f0.f64);
	// bgelr cr6
	if (!cr6.getLT()) return;
loc_820D55B4:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D55C0"))) PPC_WEAK_FUNC(sub_820D55C0);
PPC_FUNC_IMPL(__imp__sub_820D55C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed120
	// stfd f31,-96(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -96, f31.u64);
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r27,-32015
	r27.s64 = -2098135040;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r24,r6
	r24.u64 = ctx.r6.u64;
	// lbz r11,-8431(r27)
	r11.u64 = PPC_LOAD_U8(r27.u32 + -8431);
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// lwz r28,20(r30)
	r28.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r23,r8
	r23.u64 = ctx.r8.u64;
	// mr r22,r9
	r22.u64 = ctx.r9.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d5624
	if (cr6.getEQ()) goto loc_820D5624;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r3,36(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// bl 0x8209c578
	sub_8209C578(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d5624
	if (cr6.getEQ()) goto loc_820D5624;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r29,36(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// b 0x820d562c
	goto loc_820D562C;
loc_820D5624:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r29,44(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 44);
loc_820D562C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// li r6,33
	ctx.r6.s64 = 33;
	// lfs f11,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lfs f10,0(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// stfs f13,120(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f0,16156(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16156);
	f0.f64 = double(temp.f32);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lfs f9,4(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f13,f10,f0,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 * f0.f64 + ctx.f13.f64));
	// addi r31,r11,17312
	r31.s64 = r11.s64 + 17312;
	// lfs f8,8(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// stfs f13,104(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmadds f13,f9,f0,f12
	ctx.f13.f64 = double(float(ctx.f9.f64 * f0.f64 + ctx.f12.f64));
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// fmadds f0,f8,f0,f11
	f0.f64 = double(float(ctx.f8.f64 * f0.f64 + ctx.f11.f64));
	// stfs f12,124(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// stfs f11,128(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f13,108(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// bl 0x8209b548
	sub_8209B548(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8209c558
	sub_8209C558(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x820d56f8
	if (!cr6.getGT()) goto loc_820D56F8;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d56bc
	if (cr6.getEQ()) goto loc_820D56BC;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x8209a590
	sub_8209A590(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d56f8
	if (cr6.getEQ()) goto loc_820D56F8;
loc_820D56BC:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,168
	ctx.r10.s64 = ctx.r1.s64 + 168;
	// addi r9,r1,152
	ctx.r9.s64 = ctx.r1.s64 + 152;
	// addi r8,r1,136
	ctx.r8.s64 = ctx.r1.s64 + 136;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// lwz r7,48(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// li r11,0
	r11.s64 = 0;
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// bl 0x8209c1e8
	sub_8209C1E8(ctx, base);
	// b 0x820d571c
	goto loc_820D571C;
loc_820D56F8:
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r9,r1,168
	ctx.r9.s64 = ctx.r1.s64 + 168;
	// addi r8,r1,152
	ctx.r8.s64 = ctx.r1.s64 + 152;
	// addi r7,r1,136
	ctx.r7.s64 = ctx.r1.s64 + 136;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8209c610
	sub_8209C610(ctx, base);
loc_820D571C:
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d58d0
	if (cr6.getEQ()) goto loc_820D58D0;
	// lbz r11,-8431(r27)
	r11.u64 = PPC_LOAD_U8(r27.u32 + -8431);
	// li r4,0
	ctx.r4.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// beq cr6,0x820d5744
	if (cr6.getEQ()) goto loc_820D5744;
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// b 0x820d5748
	goto loc_820D5748;
loc_820D5744:
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 56);
loc_820D5748:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820d5788
	if (cr6.getEQ()) goto loc_820D5788;
	// lwz r9,48(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// li r11,0
	r11.s64 = 0;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// ble cr6,0x820d5788
	if (!cr6.getGT()) goto loc_820D5788;
	// lwz r8,96(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
loc_820D5764:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpw cr6,r7,r8
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, xer);
	// beq cr6,0x820d5784
	if (cr6.getEQ()) goto loc_820D5784;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// blt cr6,0x820d5764
	if (cr6.getLT()) goto loc_820D5764;
	// b 0x820d5788
	goto loc_820D5788;
loc_820D5784:
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
loc_820D5788:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8211caa8
	sub_8211CAA8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x820d57a4
	if (!cr6.getEQ()) goto loc_820D57A4;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
loc_820D57A4:
	// lfs f0,136(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r24)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r24.u32 + 0, temp.u32);
	// lfs f0,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	f0.f64 = double(temp.f32);
	// stfs f0,4(r24)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r24.u32 + 4, temp.u32);
	// lfs f0,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r24)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r24.u32 + 8, temp.u32);
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x8210b6e0
	sub_8210B6E0(ctx, base);
	// lfs f0,152(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	f0.f64 = double(temp.f32);
	// lfs f13,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f12.f64 = double(temp.f32);
	// stfs f0,0(r25)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r25.u32 + 0, temp.u32);
	// stfs f13,4(r25)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r25.u32 + 4, temp.u32);
	// stfs f12,8(r25)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r25.u32 + 8, temp.u32);
	// lfs f11,8(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f11,f11,f12
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f10,0(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,4(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// lfs f31,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// fmadds f11,f10,f0,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * f0.f64 + ctx.f11.f64));
	// fmadds f11,f13,f9,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 + ctx.f11.f64));
	// fcmpu cr6,f11,f31
	cr6.compare(ctx.f11.f64, f31.f64);
	// ble cr6,0x820d5820
	if (!cr6.getGT()) goto loc_820D5820;
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// stfs f0,0(r25)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r25.u32 + 0, temp.u32);
	// fneg f13,f13
	ctx.f13.u64 = ctx.f13.u64 ^ 0x8000000000000000;
	// stfs f13,4(r25)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r25.u32 + 4, temp.u32);
	// fneg f0,f12
	f0.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// stfs f0,8(r25)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r25.u32 + 8, temp.u32);
loc_820D5820:
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// lfs f13,0(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r25.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// bne cr6,0x820d5874
	if (!cr6.getEQ()) goto loc_820D5874;
	// lfs f0,4(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 4);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x820d5874
	if (!cr6.getEQ()) goto loc_820D5874;
	// lfs f0,8(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 8);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x820d5874
	if (!cr6.getEQ()) goto loc_820D5874;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stw r28,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r28.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r31,0(r22)
	PPC_STORE_U32(r22.u32 + 0, r31.u32);
	// lfs f0,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r25)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r25.u32 + 8, temp.u32);
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// lfd f31,-96(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x823ed170
	return;
loc_820D5874:
	// lfs f12,4(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r25.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f12,f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
	// lfs f0,8(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 8);
	f0.f64 = double(temp.f32);
	// stw r28,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r28.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r31,0(r22)
	PPC_STORE_U32(r22.u32 + 0, r31.u32);
	// fmadds f0,f0,f0,f12
	f0.f64 = double(float(f0.f64 * f0.f64 + ctx.f12.f64));
	// fmadds f0,f13,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// fsqrts f12,f0
	ctx.f12.f64 = double(float(sqrt(f0.f64)));
	// lfs f0,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// fdivs f0,f0,f12
	f0.f64 = double(float(f0.f64 / ctx.f12.f64));
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,0(r25)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r25.u32 + 0, temp.u32);
	// lfs f13,4(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,4(r25)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r25.u32 + 4, temp.u32);
	// lfs f13,8(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,8(r25)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r25.u32 + 8, temp.u32);
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// lfd f31,-96(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x823ed170
	return;
loc_820D58D0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// lfd f31,-96(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x823ed170
	return;
}

__attribute__((alias("__imp__sub_820D58E0"))) PPC_WEAK_FUNC(sub_820D58E0);
PPC_FUNC_IMPL(__imp__sub_820D58E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed118
	// stfd f30,-120(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -120, f30.u64);
	// stfd f31,-112(r1)
	PPC_STORE_U64(ctx.r1.u32 + -112, f31.u64);
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// mr r20,r7
	r20.u64 = ctx.r7.u64;
	// lfs f30,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f30.f64 = double(temp.f32);
	// addi r7,r1,92
	ctx.r7.s64 = ctx.r1.s64 + 92;
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// fmr f31,f30
	f31.f64 = f30.f64;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// mr r22,r8
	r22.u64 = ctx.r8.u64;
	// mr r23,r9
	r23.u64 = ctx.r9.u64;
	// li r24,-1
	r24.s64 = -1;
	// bl 0x820cdf80
	sub_820CDF80(ctx, base);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820d5bf4
	if (!cr6.getGT()) goto loc_820D5BF4;
	// lfs f0,4(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820d595c
	if (!cr6.getGT()) goto loc_820D595C;
	// lfs f12,4(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// bgt cr6,0x820d5bf4
	if (cr6.getGT()) goto loc_820D5BF4;
loc_820D595C:
	// lfs f13,92(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820d5974
	if (!cr6.getLT()) goto loc_820D5974;
	// lfs f0,4(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 4);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820d5bf4
	if (cr6.getLT()) goto loc_820D5BF4;
loc_820D5974:
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// li r26,0
	r26.s64 = 0;
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,108(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f0,0(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f0,8(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// ble cr6,0x820d5bf4
	if (!cr6.getGT()) goto loc_820D5BF4;
	// li r28,0
	r28.s64 = 0;
loc_820D59A4:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r29,r26,1
	r29.s64 = r26.s64 + 1;
	// twllei r11,0
	// lfs f4,8(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// add r9,r28,r10
	ctx.r9.u64 = r28.u64 + ctx.r10.u64;
	// lfs f3,0(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// divw r7,r29,r11
	ctx.r7.s32 = r29.s32 / r11.s32;
	// lfs f2,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// rotlwi r8,r29,1
	ctx.r8.u64 = __builtin_rotateleft32(r29.u32, 1);
	// lfs f1,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lfsx f5,r28,r10
	temp.u32 = PPC_LOAD_U32(r28.u32 + ctx.r10.u32);
	ctx.f5.f64 = double(temp.f32);
	// addi r8,r8,-1
	ctx.r8.s64 = ctx.r8.s64 + -1;
	// lfs f6,4(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// mullw r9,r7,r11
	ctx.r9.s64 = int64_t(ctx.r7.s32) * int64_t(r11.s32);
	// subf r9,r9,r29
	ctx.r9.s64 = r29.s64 - ctx.r9.s64;
	// andc r11,r11,r8
	r11.u64 = r11.u64 & ~ctx.r8.u64;
	// rlwinm r30,r9,3,0,28
	r30.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// twlgei r11,-1
	// add r11,r30,r10
	r11.u64 = r30.u64 + ctx.r10.u64;
	// lfsx f7,r30,r10
	temp.u32 = PPC_LOAD_U32(r30.u32 + ctx.r10.u32);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// bl 0x8210eed0
	sub_8210EED0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d5a54
	if (cr6.getEQ()) goto loc_820D5A54;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r6,r1,120
	ctx.r6.s64 = ctx.r1.s64 + 120;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// add r10,r28,r11
	ctx.r10.u64 = r28.u64 + r11.u64;
	// add r9,r30,r11
	ctx.r9.u64 = r30.u64 + r11.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lfsx f0,r28,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + r11.u32);
	f0.f64 = double(temp.f32);
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f0,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,116(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfsx f0,r30,r11
	temp.u32 = PPC_LOAD_U32(r30.u32 + r11.u32);
	f0.f64 = double(temp.f32);
	// stfs f0,120(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f0,4(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,124(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// bl 0x8210a990
	sub_8210A990(ctx, base);
	// fcmpu cr6,f1,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f31.f64);
	// bge cr6,0x820d5a54
	if (!cr6.getLT()) goto loc_820D5A54;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// mr r24,r26
	r24.u64 = r26.u64;
loc_820D5A54:
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r26,r29
	r26.u64 = r29.u64;
	// addi r28,r28,8
	r28.s64 = r28.s64 + 8;
	// cmpw cr6,r26,r11
	cr6.compare<int32_t>(r26.s32, r11.s32, xer);
	// blt cr6,0x820d59a4
	if (cr6.getLT()) goto loc_820D59A4;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// ble cr6,0x820d5bf4
	if (!cr6.getGT()) goto loc_820D5BF4;
	// addi r7,r24,1
	ctx.r7.s64 = r24.s64 + 1;
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// twllei r11,0
	// rotlwi r5,r7,1
	ctx.r5.u64 = __builtin_rotateleft32(ctx.r7.u32, 1);
	// divw r8,r7,r11
	ctx.r8.s32 = ctx.r7.s32 / r11.s32;
	// addi r4,r5,-1
	ctx.r4.s64 = ctx.r5.s64 + -1;
	// mullw r8,r8,r11
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(r11.s32);
	// andc r11,r11,r4
	r11.u64 = r11.u64 & ~ctx.r4.u64;
	// rlwinm r10,r24,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 3) & 0xFFFFFFF8;
	// twlgei r11,-1
	// lis r11,-32256
	r11.s64 = -2113929216;
	// subf r8,r8,r7
	ctx.r8.s64 = ctx.r7.s64 - ctx.r8.s64;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lfs f31,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// rlwinm r11,r8,3,0,28
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f0,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f31,132(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lfs f0,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,136(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f31,148(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f0,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,152(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// bl 0x82121b50
	sub_82121B50(ctx, base);
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f13,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// lfs f11,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,0(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f9,f12,f11
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// lfs f8,4(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// lfs f11,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f7,f11,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 - ctx.f7.f64));
	// lfs f6,8(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 8);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,0(r23)
	temp.u32 = PPC_LOAD_U32(r23.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f0,f0,f10
	f0.f64 = double(float(f0.f64 * ctx.f10.f64));
	// fmadds f0,f9,f8,f0
	f0.f64 = double(float(ctx.f9.f64 * ctx.f8.f64 + f0.f64));
	// fmadds f0,f7,f6,f0
	f0.f64 = double(float(ctx.f7.f64 * ctx.f6.f64 + f0.f64));
	// fcmpu cr6,f0,f5
	cr6.compare(f0.f64, ctx.f5.f64);
	// bge cr6,0x820d5bf4
	if (!cr6.getLT()) goto loc_820D5BF4;
	// stfs f0,0(r23)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r23.u32 + 0, temp.u32);
	// stfs f13,0(r20)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r20.u32 + 0, temp.u32);
	// stfs f12,4(r20)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r20.u32 + 4, temp.u32);
	// stfs f11,8(r20)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r20.u32 + 8, temp.u32);
	// lfs f0,0(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 0);
	f0.f64 = double(temp.f32);
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// stfs f0,0(r22)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r22.u32 + 0, temp.u32);
	// stfs f31,4(r22)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r22.u32 + 4, temp.u32);
	// lfs f0,8(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 8);
	f0.f64 = double(temp.f32);
	// fneg f13,f0
	ctx.f13.u64 = f0.u64 ^ 0x8000000000000000;
	// lfs f0,0(r22)
	temp.u32 = PPC_LOAD_U32(r22.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f13,8(r22)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r22.u32 + 8, temp.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x820d5b80
	if (!cr6.getEQ()) goto loc_820D5B80;
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// bne cr6,0x820d5b80
	if (!cr6.getEQ()) goto loc_820D5B80;
	// stfs f30,8(r22)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r22.u32 + 8, temp.u32);
	// b 0x820d5bbc
	goto loc_820D5BBC;
loc_820D5B80:
	// lfs f12,4(r22)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r22.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
	// lfs f13,8(r22)
	temp.u32 = PPC_LOAD_U32(r22.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fmadds f13,f0,f0,f13
	ctx.f13.f64 = double(float(f0.f64 * f0.f64 + ctx.f13.f64));
	// fsqrts f13,f13
	ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
	// fdivs f13,f30,f13
	ctx.f13.f64 = double(float(f30.f64 / ctx.f13.f64));
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,0(r22)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r22.u32 + 0, temp.u32);
	// lfs f0,4(r22)
	temp.u32 = PPC_LOAD_U32(r22.u32 + 4);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,4(r22)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r22.u32 + 4, temp.u32);
	// lfs f0,8(r22)
	temp.u32 = PPC_LOAD_U32(r22.u32 + 8);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,8(r22)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r22.u32 + 8, temp.u32);
loc_820D5BBC:
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r21,17308(r11)
	PPC_STORE_U32(r11.u32 + 17308, r21.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r11,19404(r10)
	PPC_STORE_U32(ctx.r10.u32 + 19404, r11.u32);
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// stw r11,12508(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12508, r11.u32);
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// stw r11,17232(r10)
	PPC_STORE_U32(ctx.r10.u32 + 17232, r11.u32);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// lfd f30,-120(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// lfd f31,-112(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// b 0x823ed168
	return;
loc_820D5BF4:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// lfd f30,-120(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// lfd f31,-112(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// b 0x823ed168
	return;
}

__attribute__((alias("__imp__sub_820D5C08"))) PPC_WEAK_FUNC(sub_820D5C08);
PPC_FUNC_IMPL(__imp__sub_820D5C08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed124
	// stfd f30,-96(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -96, f30.u64);
	// stfd f31,-88(r1)
	PPC_STORE_U64(ctx.r1.u32 + -88, f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r25,r8
	r25.u64 = ctx.r8.u64;
	// lwz r26,20(r31)
	r26.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r24,r9
	r24.u64 = ctx.r9.u64;
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82119330
	sub_82119330(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r27,16(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lfs f30,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f30.f64 = double(temp.f32);
	// lwz r11,32(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 32);
	// fmr f0,f30
	f0.f64 = f30.f64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d5ca0
	if (!cr6.getEQ()) goto loc_820D5CA0;
	// lfs f13,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,92(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,96(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f9,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,88(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// lfs f9,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f0,f0,f11
	f0.f64 = double(float(f0.f64 * ctx.f11.f64));
	// fmadds f0,f13,f12,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + f0.f64));
	// fmadds f0,f10,f9,f0
	f0.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 + f0.f64));
loc_820D5CA0:
	// fneg f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = ctx.f1.u64 ^ 0x8000000000000000;
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820d5dd0
	if (cr6.getLT()) goto loc_820D5DD0;
	// fadds f13,f1,f31
	ctx.f13.f64 = double(float(ctx.f1.f64 + f31.f64));
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x820d5dd0
	if (cr6.getGT()) goto loc_820D5DD0;
	// lbz r11,1(r27)
	r11.u64 = PPC_LOAD_U8(r27.u32 + 1);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d5d58
	if (cr6.getEQ()) goto loc_820D5D58;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// lwz r9,284(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// lwz r8,276(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// lwz r7,260(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d55c0
	sub_820D55C0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d5dd0
	if (cr6.getEQ()) goto loc_820D5DD0;
	// lfs f13,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,4(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 4);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,8(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f9,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,0(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// lfs f9,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f0,f0,f11
	f0.f64 = double(float(f0.f64 * ctx.f11.f64));
	// fmadds f0,f13,f12,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + f0.f64));
	// fmadds f0,f10,f9,f0
	f0.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 + f0.f64));
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// blt cr6,0x820d5dd0
	if (cr6.getLT()) goto loc_820D5DD0;
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bgt cr6,0x820d5dd0
	if (cr6.getGT()) goto loc_820D5DD0;
	// lwz r11,268(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// li r3,1
	ctx.r3.s64 = 1;
	// stfs f0,0(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f30,-96(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// lfd f31,-88(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// b 0x823ed174
	return;
loc_820D5D58:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x82119330
	sub_82119330(ctx, base);
	// addi r5,r31,88
	ctx.r5.s64 = r31.s64 + 88;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820d5530
	sub_820D5530(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d5dd0
	if (cr6.getEQ()) goto loc_820D5DD0;
	// lwz r9,268(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// lwz r8,260(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stfs f31,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// bl 0x820d58e0
	sub_820D58E0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d5dd0
	if (cr6.getEQ()) goto loc_820D5DD0;
	// lwz r11,276(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r10,284(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// stw r26,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r26.u32);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f30,-96(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// lfd f31,-88(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// b 0x823ed174
	return;
loc_820D5DD0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f30,-96(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// lfd f31,-88(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// b 0x823ed174
	return;
}

__attribute__((alias("__imp__sub_820D5DE8"))) PPC_WEAK_FUNC(sub_820D5DE8);
PPC_FUNC_IMPL(__imp__sub_820D5DE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed11c
	// stfd f31,-104(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -104, f31.u64);
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r11,r1,120
	r11.s64 = ctx.r1.s64 + 120;
	// addi r7,r1,116
	ctx.r7.s64 = ctx.r1.s64 + 116;
	// mr r31,r10
	r31.u64 = ctx.r10.u64;
	// stw r5,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r5.u32);
	// stw r4,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r4.u32);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// lwz r21,16(r30)
	r21.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// stw r7,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r7.u32);
	// mr r24,r8
	r24.u64 = ctx.r8.u64;
	// mr r23,r9
	r23.u64 = ctx.r9.u64;
	// li r22,0
	r22.s64 = 0;
	// bl 0x820d5c08
	sub_820D5C08(ctx, base);
	// lwz r29,356(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// lwz r28,364(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// beq cr6,0x820d5ed8
	if (cr6.getEQ()) goto loc_820D5ED8;
	// lfs f13,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820d5ed8
	if (!cr6.getLT()) goto loc_820D5ED8;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// stfs f0,0(r28)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// li r22,1
	r22.s64 = 1;
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// lfs f0,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	f0.f64 = double(temp.f32);
	// stw r11,17308(r10)
	PPC_STORE_U32(ctx.r10.u32 + 17308, r11.u32);
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// li r11,-1
	r11.s64 = -1;
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// lfs f13,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	f0.f64 = double(temp.f32);
	// stfs f13,4(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// stfs f0,0(r29)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// lfs f13,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	f0.f64 = double(temp.f32);
	// stfs f13,4(r29)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r29.u32 + 4, temp.u32);
	// stfs f0,8(r29)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r29.u32 + 8, temp.u32);
	// stw r11,19404(r10)
	PPC_STORE_U32(ctx.r10.u32 + 19404, r11.u32);
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// stw r11,12508(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12508, r11.u32);
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// stw r11,17232(r10)
	PPC_STORE_U32(ctx.r10.u32 + 17232, r11.u32);
loc_820D5ED8:
	// lbz r11,1(r21)
	r11.u64 = PPC_LOAD_U8(r21.u32 + 1);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d5f48
	if (cr6.getEQ()) goto loc_820D5F48;
	// lwz r30,36(r21)
	r30.u64 = PPC_LOAD_U32(r21.u32 + 36);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820d5f48
	if (cr6.getEQ()) goto loc_820D5F48;
loc_820D5EF4:
	// lbz r11,1(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 1);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d5f3c
	if (cr6.getEQ()) goto loc_820D5F3C;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// lwz r3,8(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r28.u32);
	// mr r8,r24
	ctx.r8.u64 = r24.u64;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r29.u32);
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x820d5de8
	sub_820D5DE8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d5f3c
	if (cr6.getEQ()) goto loc_820D5F3C;
	// li r22,1
	r22.s64 = 1;
loc_820D5F3C:
	// lwz r30,40(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x820d5ef4
	if (!cr6.getEQ()) goto loc_820D5EF4;
loc_820D5F48:
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// lfd f31,-104(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// b 0x823ed16c
	return;
}

__attribute__((alias("__imp__sub_820D5F58"))) PPC_WEAK_FUNC(sub_820D5F58);
PPC_FUNC_IMPL(__imp__sub_820D5F58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed114
	// stfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -120, f31.u64);
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r22,r7
	r22.u64 = ctx.r7.u64;
	// mr r21,r8
	r21.u64 = ctx.r8.u64;
	// lwz r29,28(r23)
	r29.u64 = PPC_LOAD_U32(r23.u32 + 28);
	// mr r24,r9
	r24.u64 = ctx.r9.u64;
	// lwz r27,24(r23)
	r27.u64 = PPC_LOAD_U32(r23.u32 + 24);
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82119330
	sub_82119330(ctx, base);
	// lfs f13,8(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,20(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 20);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,12(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f9,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,16(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// lfs f9,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f0,f0,f11
	f0.f64 = double(float(f0.f64 * ctx.f11.f64));
	// fmadds f0,f13,f12,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + f0.f64));
	// fneg f13,f1
	ctx.f13.u64 = ctx.f1.u64 ^ 0x8000000000000000;
	// fmadds f0,f10,f9,f0
	f0.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 + f0.f64));
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820d6264
	if (cr6.getLT()) goto loc_820D6264;
	// fadds f13,f1,f31
	ctx.f13.f64 = double(float(ctx.f1.f64 + f31.f64));
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x820d6264
	if (cr6.getGT()) goto loc_820D6264;
	// lbz r11,1(r27)
	r11.u64 = PPC_LOAD_U8(r27.u32 + 1);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d6264
	if (cr6.getEQ()) goto loc_820D6264;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// lbz r11,-8431(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + -8431);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d6030
	if (cr6.getEQ()) goto loc_820D6030;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r3,36(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// bl 0x8209c578
	sub_8209C578(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d6030
	if (cr6.getEQ()) goto loc_820D6030;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r25,36(r11)
	r25.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// b 0x820d6038
	goto loc_820D6038;
loc_820D6030:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r25,44(r11)
	r25.u64 = PPC_LOAD_U32(r11.u32 + 44);
loc_820D6038:
	// lis r11,-32013
	r11.s64 = -2098003968;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r26,r11,19424
	r26.s64 = r11.s64 + 19424;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,33
	ctx.r5.s64 = 33;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8209a600
	sub_8209A600(ctx, base);
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,120(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// addi r20,r1,120
	r20.s64 = ctx.r1.s64 + 120;
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// addi r19,r1,120
	r19.s64 = ctx.r1.s64 + 120;
	// stfs f0,124(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// bl 0x8210d820
	sub_8210D820(ctx, base);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// bl 0x8238aec0
	sub_8238AEC0(ctx, base);
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f13,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addi r20,r1,104
	r20.s64 = ctx.r1.s64 + 104;
	// lfs f12,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f0,f0,f31,f13
	f0.f64 = double(float(f0.f64 * f31.f64 + ctx.f13.f64));
	// lfs f11,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// addi r19,r1,104
	r19.s64 = ctx.r1.s64 + 104;
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmadds f0,f12,f31,f11
	f0.f64 = double(float(ctx.f12.f64 * f31.f64 + ctx.f11.f64));
	// lfs f10,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// stfs f0,108(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmadds f0,f10,f31,f9
	f0.f64 = double(float(ctx.f10.f64 * f31.f64 + ctx.f9.f64));
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// bl 0x8210d820
	sub_8210D820(ctx, base);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// mr r5,r20
	ctx.r5.u64 = r20.u64;
	// bl 0x8238aec0
	sub_8238AEC0(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r9,r1,152
	ctx.r9.s64 = ctx.r1.s64 + 152;
	// addi r8,r1,136
	ctx.r8.s64 = ctx.r1.s64 + 136;
	// stw r6,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r6.u32);
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// lwz r7,48(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8209c1e8
	sub_8209C1E8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d6264
	if (cr6.getEQ()) goto loc_820D6264;
	// lfs f13,140(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,372(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// lfs f0,4(r22)
	temp.u32 = PPC_LOAD_U32(r22.u32 + 4);
	f0.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// lfs f11,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,8(r22)
	temp.u32 = PPC_LOAD_U32(r22.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r21)
	temp.u32 = PPC_LOAD_U32(r21.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// lfs f9,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f9.f64 = double(temp.f32);
	// lfs f11,8(r21)
	temp.u32 = PPC_LOAD_U32(r21.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,0(r22)
	temp.u32 = PPC_LOAD_U32(r22.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f10,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f10.f64));
	// lfs f9,0(r21)
	temp.u32 = PPC_LOAD_U32(r21.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f0,f0,f12
	f0.f64 = double(float(f0.f64 * ctx.f12.f64));
	// fmadds f0,f13,f11,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 + f0.f64));
	// fmadds f0,f10,f9,f0
	f0.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 + f0.f64));
	// fcmpu cr6,f0,f8
	cr6.compare(f0.f64, ctx.f8.f64);
	// bge cr6,0x820d6264
	if (!cr6.getLT()) goto loc_820D6264;
	// stfs f0,0(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f11,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f12,f12,f0,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f11.f64));
	// stfs f12,0(r24)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r24.u32 + 0, temp.u32);
	// lfs f11,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f12,f12,f0,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f11.f64));
	// stfs f12,4(r24)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r24.u32 + 4, temp.u32);
	// lfs f12,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f0,f12,f0,f11
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f11.f64));
	// stfs f0,8(r24)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r24.u32 + 8, temp.u32);
	// lfs f0,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f13,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f13.f64 = double(temp.f32);
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// stfs f0,0(r28)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// stfs f13,4(r28)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r28.u32 + 4, temp.u32);
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// fneg f12,f0
	ctx.f12.u64 = f0.u64 ^ 0x8000000000000000;
	// lfs f0,0(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f12,8(r28)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r28.u32 + 8, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x820d61d8
	if (!cr6.getEQ()) goto loc_820D61D8;
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// bne cr6,0x820d61d8
	if (!cr6.getEQ()) goto loc_820D61D8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// b 0x820d6218
	goto loc_820D6218;
loc_820D61D8:
	// lfs f12,4(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f12,f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
	// lfs f13,8(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fmadds f13,f0,f0,f13
	ctx.f13.f64 = double(float(f0.f64 * f0.f64 + ctx.f13.f64));
	// fsqrts f12,f13
	ctx.f12.f64 = double(float(sqrt(ctx.f13.f64)));
	// lfs f13,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 / ctx.f12.f64));
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,0(r28)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// lfs f0,4(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 4);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,4(r28)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r28.u32 + 4, temp.u32);
	// lfs f0,8(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 8);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
loc_820D6218:
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// stfs f0,8(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r28.u32 + 8, temp.u32);
	// stw r27,17308(r11)
	PPC_STORE_U32(r11.u32 + 17308, r27.u32);
	// bl 0x8211f6f8
	sub_8211F6F8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r4,19404(r11)
	PPC_STORE_U32(r11.u32 + 19404, ctx.r4.u32);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// stw r29,12508(r11)
	PPC_STORE_U32(r11.u32 + 12508, r29.u32);
	// bl 0x820d4378
	sub_820D4378(ctx, base);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// stw r3,17232(r11)
	PPC_STORE_U32(r11.u32 + 17232, ctx.r3.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// lfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// b 0x823ed164
	return;
loc_820D6264:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// lfd f31,-120(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -120);
	// b 0x823ed164
	return;
}

__attribute__((alias("__imp__sub_820D6278"))) PPC_WEAK_FUNC(sub_820D6278);
PPC_FUNC_IMPL(__imp__sub_820D6278) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed110
	// stfd f31,-128(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -128, f31.u64);
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r24,r6
	r24.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// mr r26,r8
	r26.u64 = ctx.r8.u64;
	// mr r31,r9
	r31.u64 = ctx.r9.u64;
	// li r18,0
	r18.s64 = 0;
	// li r23,0
	r23.s64 = 0;
	// bl 0x820b1020
	sub_820B1020(ctx, base);
	// lfs f0,4(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + 4);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f10,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// fsubs f13,f0,f10
	ctx.f13.f64 = double(float(f0.f64 - ctx.f10.f64));
	// lfs f9,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,8(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// lfs f8,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f8.f64 = double(temp.f32);
	// lfs f11,0(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f8
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// fmuls f0,f13,f13
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// fmadds f0,f12,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + f0.f64));
	// fmadds f0,f11,f11,f0
	f0.f64 = double(float(ctx.f11.f64 * ctx.f11.f64 + f0.f64));
	// fsqrts f31,f0
	f31.f64 = double(float(sqrt(f0.f64)));
	// lfs f0,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f31,f0
	cr6.compare(f31.f64, f0.f64);
	// bne cr6,0x820d6308
	if (!cr6.getEQ()) goto loc_820D6308;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// lfd f31,-128(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -128);
	// b 0x823ed160
	return;
loc_820D6308:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f8,136(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// stfs f10,140(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// addi r30,r1,136
	r30.s64 = ctx.r1.s64 + 136;
	// stfs f9,144(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f0,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// fdivs f0,f0,f31
	f0.f64 = double(float(f0.f64 / f31.f64));
	// fmuls f11,f0,f11
	ctx.f11.f64 = double(float(f0.f64 * ctx.f11.f64));
	// stfs f11,104(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmuls f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f13,108(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// fmuls f0,f0,f12
	f0.f64 = double(float(f0.f64 * ctx.f12.f64));
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// bl 0x8210d820
	sub_8210D820(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8210b6e0
	sub_8210B6E0(ctx, base);
	// lfs f0,104(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	f0.f64 = double(temp.f32);
	// stfs f0,120(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// addi r30,r1,120
	r30.s64 = ctx.r1.s64 + 120;
	// lfs f0,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	f0.f64 = double(temp.f32);
	// stfs f0,124(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// lfs f0,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	f0.f64 = double(temp.f32);
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// bl 0x8210d820
	sub_8210D820(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// stfs f31,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x820d65d0
	if (cr6.getEQ()) goto loc_820D65D0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cef38
	sub_820CEF38(ctx, base);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r20,-2304(r11)
	r20.u64 = PPC_LOAD_U32(r11.u32 + -2304);
	// lhz r11,0(r20)
	r11.u64 = PPC_LOAD_U16(r20.u32 + 0);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x820d65d0
	if (cr6.getLT()) goto loc_820D65D0;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// addi r21,r10,-1384
	r21.s64 = ctx.r10.s64 + -1384;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// addi r25,r10,-784
	r25.s64 = ctx.r10.s64 + -784;
loc_820D63AC:
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r31,r11,r25
	r31.u64 = r11.u64 + r25.u64;
	// cmplw cr6,r31,r22
	cr6.compare<uint32_t>(r31.u32, r22.u32, xer);
	// beq cr6,0x820d6570
	if (cr6.getEQ()) goto loc_820D6570;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820d64c8
	if (cr6.getEQ()) goto loc_820D64C8;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x820d64c8
	if (cr6.getEQ()) goto loc_820D64C8;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x820d64c8
	if (cr6.getEQ()) goto loc_820D64C8;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x820d6444
	if (cr6.getEQ()) goto loc_820D6444;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820d6570
	if (!cr6.getEQ()) goto loc_820D6570;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820d6444
	if (!cr6.getEQ()) goto loc_820D6444;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820d6570
	if (!cr6.getEQ()) goto loc_820D6570;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820c9b90
	sub_820C9B90(ctx, base);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r21
	r11.u64 = PPC_LOAD_U32(r11.u32 + r21.u32);
	// lwz r11,432(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 432);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820d6570
	if (cr6.getEQ()) goto loc_820D6570;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// addi r6,r1,104
	ctx.r6.s64 = ctx.r1.s64 + 104;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d58e0
	sub_820D58E0(ctx, base);
	// b 0x820d6564
	goto loc_820D6564;
loc_820D6444:
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820d6474
	if (!cr6.getEQ()) goto loc_820D6474;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820c9b90
	sub_820C9B90(ctx, base);
	// rlwinm r11,r3,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r21
	r11.u64 = PPC_LOAD_U32(r11.u32 + r21.u32);
	// lwz r11,432(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 432);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820d6570
	if (cr6.getEQ()) goto loc_820D6570;
	// rlwinm r11,r24,0,29,29
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 0) & 0x4;
	// b 0x820d6490
	goto loc_820D6490;
loc_820D6474:
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x820d6498
	if (!cr6.getEQ()) goto loc_820D6498;
	// lhz r11,18(r30)
	r11.u64 = PPC_LOAD_U16(r30.u32 + 18);
	// rlwinm r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d6570
	if (!cr6.getEQ()) goto loc_820D6570;
	// rlwinm r11,r24,0,28,28
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 0) & 0x8;
loc_820D6490:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d6570
	if (cr6.getEQ()) goto loc_820D6570;
loc_820D6498:
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// addi r8,r1,120
	ctx.r8.s64 = ctx.r1.s64 + 120;
	// addi r7,r1,136
	ctx.r7.s64 = ctx.r1.s64 + 136;
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820d5f58
	sub_820D5F58(ctx, base);
	// b 0x820d6564
	goto loc_820D6564;
loc_820D64C8:
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,100(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 100);
	// rlwinm r10,r10,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820d6570
	if (!cr6.getEQ()) goto loc_820D6570;
	// lwz r10,12(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// rlwinm r10,r10,0,6,6
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2000000;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820d6570
	if (!cr6.getEQ()) goto loc_820D6570;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x820d6510
	if (!cr6.getEQ()) goto loc_820D6510;
	// rlwinm r11,r24,0,30,30
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d651c
	if (!cr6.getEQ()) goto loc_820D651C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ce7e0
	sub_820CE7E0(ctx, base);
	// and r11,r3,r24
	r11.u64 = ctx.r3.u64 & r24.u64;
	// b 0x820d6514
	goto loc_820D6514;
loc_820D6510:
	// clrlwi r11,r24,31
	r11.u64 = r24.u32 & 0x1;
loc_820D6514:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d6570
	if (cr6.getEQ()) goto loc_820D6570;
loc_820D651C:
	// cmplw cr6,r31,r19
	cr6.compare<uint32_t>(r31.u32, r19.u32, xer);
	// bne cr6,0x820d6534
	if (!cr6.getEQ()) goto loc_820D6534;
	// lbz r11,2(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 2);
	// rlwinm r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d6570
	if (!cr6.getEQ()) goto loc_820D6570;
loc_820D6534:
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r26.u32);
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// addi r9,r1,120
	ctx.r9.s64 = ctx.r1.s64 + 120;
	// addi r8,r1,136
	ctx.r8.s64 = ctx.r1.s64 + 136;
	// addi r6,r1,104
	ctx.r6.s64 = ctx.r1.s64 + 104;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820d5de8
	sub_820D5DE8(ctx, base);
loc_820D6564:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d6570
	if (cr6.getEQ()) goto loc_820D6570;
	// li r23,1
	r23.s64 = 1;
loc_820D6570:
	// addi r20,r20,2
	r20.s64 = r20.s64 + 2;
	// lhz r11,0(r20)
	r11.u64 = PPC_LOAD_U16(r20.u32 + 0);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820d63ac
	if (!cr6.getLT()) goto loc_820D63AC;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// beq cr6,0x820d65d0
	if (cr6.getEQ()) goto loc_820D65D0;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lfs f0,104(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	f0.f64 = double(temp.f32);
	// li r18,1
	r18.s64 = 1;
	// addi r11,r11,5404
	r11.s64 = r11.s64 + 5404;
	// stfs f0,0(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// lfs f0,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	f0.f64 = double(temp.f32);
	// stfs f0,4(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4, temp.u32);
	// lfs f0,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8, temp.u32);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lfs f0,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	f0.f64 = double(temp.f32);
	// addi r11,r11,5532
	r11.s64 = r11.s64 + 5532;
	// stfs f0,0(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// lfs f0,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	f0.f64 = double(temp.f32);
	// stfs f0,4(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4, temp.u32);
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8, temp.u32);
loc_820D65D0:
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// lfd f31,-128(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -128);
	// b 0x823ed160
	return;
}

__attribute__((alias("__imp__sub_820D65E0"))) PPC_WEAK_FUNC(sub_820D65E0);
PPC_FUNC_IMPL(__imp__sub_820D65E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed11c
	// stfd f30,-112(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -112, f30.u64);
	// stfd f31,-104(r1)
	PPC_STORE_U64(ctx.r1.u32 + -104, f31.u64);
	// stwu r1,-800(r1)
	ea = -800 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r21,0
	r21.s64 = 0;
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// lwz r30,16(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r24,r7
	r24.u64 = ctx.r7.u64;
	// mr r23,r8
	r23.u64 = ctx.r8.u64;
	// li r22,1
	r22.s64 = 1;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
	// mr r11,r21
	r11.u64 = r21.u64;
	// stw r11,17308(r10)
	PPC_STORE_U32(ctx.r10.u32 + 17308, r11.u32);
	// bl 0x820ae360
	sub_820AE360(ctx, base);
	// cmpwi cr6,r3,33
	cr6.compare<int32_t>(ctx.r3.s32, 33, xer);
	// bne cr6,0x820d663c
	if (!cr6.getEQ()) goto loc_820D663C;
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
loc_820D663C:
	// lfs f0,0(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r28,r31,88
	r28.s64 = r31.s64 + 88;
	// lfs f13,88(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x820d6670
	if (!cr6.getEQ()) goto loc_820D6670;
	// lfs f13,4(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,92(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f13,f12
	cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// bne cr6,0x820d6670
	if (!cr6.getEQ()) goto loc_820D6670;
	// lfs f13,8(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,96(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f13,f12
	cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// beq cr6,0x820d6b4c
	if (cr6.getEQ()) goto loc_820D6B4C;
loc_820D6670:
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// lfs f13,4(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,108(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// lfs f13,8(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,112(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d6b4c
	if (cr6.getEQ()) goto loc_820D6B4C;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820d6b4c
	if (cr6.getEQ()) goto loc_820D6B4C;
	// li r9,20
	ctx.r9.s64 = 20;
	// stw r21,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r21.u32);
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// addi r7,r1,192
	ctx.r7.s64 = ctx.r1.s64 + 192;
	// addi r6,r1,120
	ctx.r6.s64 = ctx.r1.s64 + 120;
	// addi r5,r11,204
	ctx.r5.s64 = r11.s64 + 204;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x821159b8
	sub_821159B8(ctx, base);
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmpwi cr6,r4,20
	cr6.compare<int32_t>(ctx.r4.s32, 20, xer);
	// ble cr6,0x820d66f0
	if (!cr6.getGT()) goto loc_820D66F0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r5,20
	ctx.r5.s64 = 20;
	// addi r3,r11,17684
	ctx.r3.s64 = r11.s64 + 17684;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// li r4,20
	ctx.r4.s64 = 20;
	// stw r4,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r4.u32);
loc_820D66F0:
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// li r4,100
	ctx.r4.s64 = 100;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x82113740
	sub_82113740(ctx, base);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// li r8,-1
	ctx.r8.s64 = -1;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// lis r11,-32015
	r11.s64 = -2098135040;
	// stwx r8,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, ctx.r8.u32);
	// lbz r3,-8431(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + -8431);
	// bl 0x821131a8
	sub_821131A8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x820d68f4
	if (cr6.getEQ()) goto loc_820D68F4;
	// bl 0x821130e0
	sub_821130E0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// li r10,0
	ctx.r10.s64 = 0;
	// lfs f12,92(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// li r9,0
	ctx.r9.s64 = 0;
	// lfs f11,96(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 96);
	ctx.f11.f64 = double(temp.f32);
	// addi r8,r1,160
	ctx.r8.s64 = ctx.r1.s64 + 160;
	// addi r7,r1,144
	ctx.r7.s64 = ctx.r1.s64 + 144;
	// stw r21,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r21.u32);
	// lfs f0,3904(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3904);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f31,f1,f0
	f31.f64 = double(float(ctx.f1.f64 * f0.f64));
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lfs f30,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f30.f64 = double(temp.f32);
	// fdivs f1,f30,f31
	ctx.f1.f64 = double(float(f30.f64 / f31.f64));
	// fmuls f0,f13,f1
	f0.f64 = double(float(ctx.f13.f64 * ctx.f1.f64));
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fmuls f0,f1,f12
	f0.f64 = double(float(ctx.f1.f64 * ctx.f12.f64));
	// stfs f0,132(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// fmuls f0,f1,f11
	f0.f64 = double(float(ctx.f1.f64 * ctx.f11.f64));
	// stfs f0,136(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f0,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	f0.f64 = double(temp.f32);
	// fmuls f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 * f0.f64));
	// stfs f0,176(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f0,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	f0.f64 = double(temp.f32);
	// fmuls f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 * f0.f64));
	// stfs f0,180(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f0,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	f0.f64 = double(temp.f32);
	// fmuls f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 * f0.f64));
	// stfs f0,184(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// bl 0x8209c058
	sub_8209C058(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d68f4
	if (cr6.getEQ()) goto loc_820D68F4;
	// lfs f0,144(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// stfs f0,0(r25)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r25.u32 + 0, temp.u32);
	// lfs f13,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f13.f64 = double(temp.f32);
	// mr r22,r21
	r22.u64 = r21.u64;
	// lfs f0,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	f0.f64 = double(temp.f32);
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * f31.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// stfs f13,4(r25)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r25.u32 + 4, temp.u32);
	// stfs f0,8(r25)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r25.u32 + 8, temp.u32);
	// lfs f0,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	f0.f64 = double(temp.f32);
	// lfs f13,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// lfs f11,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f11.f64 = double(temp.f32);
	// stfs f0,0(r26)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r26.u32 + 0, temp.u32);
	// stfs f12,4(r26)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r26.u32 + 4, temp.u32);
	// stfs f11,8(r26)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r26.u32 + 8, temp.u32);
	// bne cr6,0x820d6834
	if (!cr6.getEQ()) goto loc_820D6834;
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// bne cr6,0x820d6834
	if (!cr6.getEQ()) goto loc_820D6834;
	// fcmpu cr6,f11,f13
	cr6.compare(ctx.f11.f64, ctx.f13.f64);
	// bne cr6,0x820d6834
	if (!cr6.getEQ()) goto loc_820D6834;
	// stfs f30,8(r26)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r26.u32 + 8, temp.u32);
	// b 0x820d6870
	goto loc_820D6870;
loc_820D6834:
	// lfs f13,8(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r26.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// lfs f12,4(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f12,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + ctx.f13.f64));
	// fmadds f13,f0,f0,f13
	ctx.f13.f64 = double(float(f0.f64 * f0.f64 + ctx.f13.f64));
	// fsqrts f13,f13
	ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
	// fdivs f13,f30,f13
	ctx.f13.f64 = double(float(f30.f64 / ctx.f13.f64));
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,0(r26)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r26.u32 + 0, temp.u32);
	// lfs f0,4(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 4);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,4(r26)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r26.u32 + 4, temp.u32);
	// lfs f0,8(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 8);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,8(r26)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r26.u32 + 8, temp.u32);
loc_820D6870:
	// lfs f0,4(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + 4);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,92(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f0,f13
	ctx.f12.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f0,96(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 96);
	f0.f64 = double(temp.f32);
	// lfs f11,8(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 - f0.f64));
	// lfs f0,0(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f13,0(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f10,13964(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13964);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f0,f12,f12
	f0.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
	// fmadds f0,f11,f11,f0
	f0.f64 = double(float(ctx.f11.f64 * ctx.f11.f64 + f0.f64));
	// fmadds f0,f13,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// fsqrts f0,f0
	f0.f64 = double(float(sqrt(f0.f64)));
	// fcmpu cr6,f0,f10
	cr6.compare(f0.f64, ctx.f10.f64);
	// ble cr6,0x820d68bc
	if (!cr6.getGT()) goto loc_820D68BC;
	// fdivs f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 / f0.f64));
	// b 0x820d68c4
	goto loc_820D68C4;
loc_820D68BC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2692(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
loc_820D68C4:
	// lfs f10,0(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r25.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,4(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fnmsubs f13,f0,f13,f10
	ctx.f13.f64 = double(float(-(f0.f64 * ctx.f13.f64 - ctx.f10.f64)));
	// lfs f8,8(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// fnmsubs f12,f0,f12,f9
	ctx.f12.f64 = double(float(-(f0.f64 * ctx.f12.f64 - ctx.f9.f64)));
	// fnmsubs f0,f0,f11,f8
	f0.f64 = double(float(-(f0.f64 * ctx.f11.f64 - ctx.f8.f64)));
	// stfs f13,0(r25)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r25.u32 + 0, temp.u32);
	// stfs f13,104(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stfs f12,4(r25)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r25.u32 + 4, temp.u32);
	// stfs f12,108(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f0,8(r25)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r25.u32 + 8, temp.u32);
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
loc_820D68F4:
	// addi r9,r1,192
	ctx.r9.s64 = ctx.r1.s64 + 192;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// li r6,31
	ctx.r6.s64 = 31;
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820d6278
	sub_820D6278(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820d6a24
	if (!cr6.getEQ()) goto loc_820D6A24;
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// bne cr6,0x820d6960
	if (!cr6.getEQ()) goto loc_820D6960;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// beq cr6,0x820d6968
	if (cr6.getEQ()) goto loc_820D6968;
	// li r22,2
	r22.s64 = 2;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x820d6b4c
	if (!cr6.getEQ()) goto loc_820D6B4C;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// li r9,20
	ctx.r9.s64 = 20;
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// addi r7,r1,192
	ctx.r7.s64 = ctx.r1.s64 + 192;
	// addi r6,r1,120
	ctx.r6.s64 = ctx.r1.s64 + 120;
	// addi r5,r11,204
	ctx.r5.s64 = r11.s64 + 204;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x821159b8
	sub_821159B8(ctx, base);
	// b 0x820d69c4
	goto loc_820D69C4;
loc_820D6960:
	// cmpwi cr6,r22,1
	cr6.compare<int32_t>(r22.s32, 1, xer);
	// beq cr6,0x820d6994
	if (cr6.getEQ()) goto loc_820D6994;
loc_820D6968:
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x820d69b4
	if (!cr6.getEQ()) goto loc_820D69B4;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// li r9,20
	ctx.r9.s64 = 20;
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// addi r7,r1,192
	ctx.r7.s64 = ctx.r1.s64 + 192;
	// addi r6,r1,120
	ctx.r6.s64 = ctx.r1.s64 + 120;
	// addi r5,r11,204
	ctx.r5.s64 = r11.s64 + 204;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x821159b8
	sub_821159B8(ctx, base);
loc_820D6994:
	// lfs f0,104(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r28)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// lfs f0,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	f0.f64 = double(temp.f32);
	// stfs f0,96(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 96, temp.u32);
	// lfs f0,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	f0.f64 = double(temp.f32);
	// stfs f0,16(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 16, temp.u32);
	// lfs f0,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	f0.f64 = double(temp.f32);
	// stfs f0,92(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 92, temp.u32);
loc_820D69B4:
	// cmpwi cr6,r22,1
	cr6.compare<int32_t>(r22.s32, 1, xer);
	// beq cr6,0x820d69c4
	if (cr6.getEQ()) goto loc_820D69C4;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x820d6b4c
	if (!cr6.getEQ()) goto loc_820D6B4C;
loc_820D69C4:
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d6a9c
	if (!cr6.getEQ()) goto loc_820D6A9C;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// lfs f4,96(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 96);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,0(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
	// lfs f2,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x820d6a80
	if (!cr6.getEQ()) goto loc_820D6A80;
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d6a80
	if (cr6.getEQ()) goto loc_820D6A80;
	// stw r11,24(r30)
	PPC_STORE_U32(r30.u32 + 24, r11.u32);
	// lfs f0,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,12(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 12, temp.u32);
	// lfs f0,96(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 96);
	f0.f64 = double(temp.f32);
	// stfs f0,20(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 20, temp.u32);
	// b 0x820d6a9c
	goto loc_820D6A9C;
loc_820D6A24:
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x820d69b4
	if (!cr6.getEQ()) goto loc_820D69B4;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lfs f0,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// li r9,20
	ctx.r9.s64 = 20;
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// lfs f0,96(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 96);
	f0.f64 = double(temp.f32);
	// addi r7,r1,192
	ctx.r7.s64 = ctx.r1.s64 + 192;
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// addi r6,r1,120
	ctx.r6.s64 = ctx.r1.s64 + 120;
	// addi r5,r11,204
	ctx.r5.s64 = r11.s64 + 204;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x821159b8
	sub_821159B8(ctx, base);
	// subfic r11,r24,0
	xer.ca = r24.u32 <= 0;
	r11.s64 = 0 - r24.s64;
	// lfs f0,108(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	f0.f64 = double(temp.f32);
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// stfs f0,16(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 16, temp.u32);
	// lfs f0,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	f0.f64 = double(temp.f32);
	// stfs f0,92(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 92, temp.u32);
	// rlwinm r22,r11,0,30,30
	r22.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// b 0x820d69c4
	goto loc_820D69C4;
loc_820D6A80:
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 8;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lbz r11,1(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 1);
	// ori r11,r11,8
	r11.u64 = r11.u64 | 8;
	// stb r11,1(r30)
	PPC_STORE_U8(r30.u32 + 1, r11.u8);
loc_820D6A9C:
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d6afc
	if (cr6.getEQ()) goto loc_820D6AFC;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x821117b0
	sub_821117B0(ctx, base);
	// stw r3,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820d6afc
	if (cr6.getEQ()) goto loc_820D6AFC;
	// stw r3,24(r30)
	PPC_STORE_U32(r30.u32 + 24, ctx.r3.u32);
	// lfs f0,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,12(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 12, temp.u32);
	// lfs f0,96(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 96);
	f0.f64 = double(temp.f32);
	// stfs f0,20(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 20, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r10,r10,0,29,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF7;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lbz r11,1(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 1);
	// andi. r11,r11,247
	r11.u64 = r11.u64 & 247;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stb r11,1(r30)
	PPC_STORE_U8(r30.u32 + 1, r11.u8);
loc_820D6AFC:
	// lbz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 120);
	// mr r11,r21
	r11.u64 = r21.u64;
	// cmplwi cr6,r10,255
	cr6.compare<uint32_t>(ctx.r10.u32, 255, xer);
	// beq cr6,0x820d6b3c
	if (cr6.getEQ()) goto loc_820D6B3C;
loc_820D6B0C:
	// cmpwi cr6,r11,7
	cr6.compare<int32_t>(r11.s32, 7, xer);
	// bge cr6,0x820d6b3c
	if (!cr6.getLT()) goto loc_820D6B3C;
	// addi r9,r1,120
	ctx.r9.s64 = ctx.r1.s64 + 120;
	// lwz r10,108(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// addi r8,r1,120
	ctx.r8.s64 = ctx.r1.s64 + 120;
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lbzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + ctx.r9.u32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stb r9,204(r10)
	PPC_STORE_U8(ctx.r10.u32 + 204, ctx.r9.u8);
	// lbzx r10,r11,r8
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + ctx.r8.u32);
	// cmplwi cr6,r10,255
	cr6.compare<uint32_t>(ctx.r10.u32, 255, xer);
	// bne cr6,0x820d6b0c
	if (!cr6.getEQ()) goto loc_820D6B0C;
loc_820D6B3C:
	// lwz r10,108(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// li r9,255
	ctx.r9.s64 = 255;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stb r9,204(r11)
	PPC_STORE_U8(r11.u32 + 204, ctx.r9.u8);
loc_820D6B4C:
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// addi r1,r1,800
	ctx.r1.s64 = ctx.r1.s64 + 800;
	// lfd f30,-112(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -112);
	// lfd f31,-104(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// b 0x823ed16c
	return;
}

__attribute__((alias("__imp__sub_820D6B60"))) PPC_WEAK_FUNC(sub_820D6B60);
PPC_FUNC_IMPL(__imp__sub_820D6B60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// addi r12,r1,-56
	r12.s64 = ctx.r1.s64 + -56;
	// bl 0x823ed538
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// lwz r31,16(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// lbz r11,3(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 3);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// bne cr6,0x820d6ba4
	if (!cr6.getEQ()) goto loc_820D6BA4;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f24,2948(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2948);
	f24.f64 = double(temp.f32);
	// b 0x820d6bac
	goto loc_820D6BAC;
loc_820D6BA4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f24,2952(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2952);
	f24.f64 = double(temp.f32);
loc_820D6BAC:
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// lfs f30,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	f30.f64 = double(temp.f32);
	// li r11,0
	r11.s64 = 0;
	// li r28,1
	r28.s64 = 1;
	// addi r29,r31,12
	r29.s64 = r31.s64 + 12;
	// stw r11,17308(r10)
	PPC_STORE_U32(ctx.r10.u32 + 17308, r11.u32);
	// lfs f1,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fcmpu cr6,f30,f1
	cr6.compare(f30.f64, ctx.f1.f64);
	// bne cr6,0x820d6bf0
	if (!cr6.getEQ()) goto loc_820D6BF0;
	// lfs f0,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x820d6bf0
	if (!cr6.getEQ()) goto loc_820D6BF0;
	// lfs f0,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f13,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// beq cr6,0x820d6cf0
	if (cr6.getEQ()) goto loc_820D6CF0;
loc_820D6BF0:
	// lwz r11,100(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 100);
	// lfs f31,4(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	f31.f64 = double(temp.f32);
	// lfs f27,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	f27.f64 = double(temp.f32);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d6cf0
	if (cr6.getEQ()) goto loc_820D6CF0;
	// lfs f2,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// lwz r3,24(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// bl 0x821108b0
	sub_821108B0(ctx, base);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lfs f25,2776(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	f25.f64 = double(temp.f32);
	// rlwinm r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f26,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f26.f64 = double(temp.f32);
	// bne cr6,0x820d6c44
	if (!cr6.getEQ()) goto loc_820D6C44;
	// fmr f29,f26
	f29.f64 = f26.f64;
	// fmr f28,f25
	f28.f64 = f25.f64;
	// b 0x820d6c64
	goto loc_820D6C64;
loc_820D6C44:
	// lfs f0,16(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x820d6c5c
	if (!cr6.getGT()) goto loc_820D6C5C;
	// fsubs f29,f0,f1
	f29.f64 = double(float(f0.f64 - ctx.f1.f64));
	// fsubs f28,f31,f1
	f28.f64 = double(float(f31.f64 - ctx.f1.f64));
	// b 0x820d6c64
	goto loc_820D6C64;
loc_820D6C5C:
	// fsubs f29,f31,f1
	ctx.fpscr.disableFlushMode();
	f29.f64 = double(float(f31.f64 - ctx.f1.f64));
	// fsubs f28,f0,f1
	f28.f64 = double(float(f0.f64 - ctx.f1.f64));
loc_820D6C64:
	// bl 0x8210f8f0
	sub_8210F8F0(ctx, base);
	// li r8,31
	ctx.r8.s64 = 31;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f2,20(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmr f8,f25
	ctx.f8.f64 = f25.f64;
	// fmr f7,f26
	ctx.f7.f64 = f26.f64;
	// fmr f6,f28
	ctx.f6.f64 = f28.f64;
	// fmr f5,f29
	ctx.f5.f64 = f29.f64;
	// fmr f4,f27
	ctx.f4.f64 = f27.f64;
	// fmr f3,f30
	ctx.f3.f64 = f30.f64;
	// bl 0x82112020
	sub_82112020(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d6d04
	if (cr6.getEQ()) goto loc_820D6D04;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d6d04
	if (cr6.getEQ()) goto loc_820D6D04;
	// li r7,31
	ctx.r7.s64 = 31;
	// fmr f5,f28
	ctx.fpscr.disableFlushMode();
	ctx.f5.f64 = f28.f64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// fmr f4,f29
	ctx.f4.f64 = f29.f64;
	// fmr f3,f24
	ctx.f3.f64 = f24.f64;
	// fmr f2,f27
	ctx.f2.f64 = f27.f64;
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// bl 0x821126c0
	sub_821126C0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge cr6,0x820d6d04
	if (!cr6.getLT()) goto loc_820D6D04;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stfs f30,88(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r30.u32 + 88, temp.u32);
	// stfs f27,96(r30)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r30.u32 + 96, temp.u32);
	// stfs f30,0(r29)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// stfs f27,20(r31)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// stfs f31,16(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 16, temp.u32);
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// stfs f31,92(r30)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r30.u32 + 92, temp.u32);
loc_820D6CF0:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// addi r12,r1,-56
	r12.s64 = ctx.r1.s64 + -56;
	// bl 0x823ed584
	// b 0x823ed180
	return;
loc_820D6D04:
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82110500
	sub_82110500(ctx, base);
	// lfs f13,136(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// stfs f26,4(r27)
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r27.u32 + 4, temp.u32);
	// stfs f0,0(r27)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r27.u32 + 0, temp.u32);
	// stfs f13,8(r27)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r27.u32 + 8, temp.u32);
	// fcmpu cr6,f0,f26
	cr6.compare(f0.f64, f26.f64);
	// bne cr6,0x820d6d4c
	if (!cr6.getEQ()) goto loc_820D6D4C;
	// fcmpu cr6,f13,f26
	cr6.compare(ctx.f13.f64, f26.f64);
	// bne cr6,0x820d6d4c
	if (!cr6.getEQ()) goto loc_820D6D4C;
	// stfs f25,8(r27)
	temp.f32 = float(f25.f64);
	PPC_STORE_U32(r27.u32 + 8, temp.u32);
	// b 0x820d6d88
	goto loc_820D6D88;
loc_820D6D4C:
	// lfs f13,8(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// lfs f12,4(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f12,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + ctx.f13.f64));
	// fmadds f13,f0,f0,f13
	ctx.f13.f64 = double(float(f0.f64 * f0.f64 + ctx.f13.f64));
	// fsqrts f13,f13
	ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
	// fdivs f13,f25,f13
	ctx.f13.f64 = double(float(f25.f64 / ctx.f13.f64));
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,0(r27)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r27.u32 + 0, temp.u32);
	// lfs f0,4(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 4);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,4(r27)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r27.u32 + 4, temp.u32);
	// lfs f0,8(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 8);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,8(r27)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r27.u32 + 8, temp.u32);
loc_820D6D88:
	// lfs f0,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f30,f0
	cr6.compare(f30.f64, f0.f64);
	// bne cr6,0x820d6dd8
	if (!cr6.getEQ()) goto loc_820D6DD8;
	// lfs f13,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f31,f13
	cr6.compare(f31.f64, ctx.f13.f64);
	// bne cr6,0x820d6dd8
	if (!cr6.getEQ()) goto loc_820D6DD8;
	// lfs f13,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f27,f13
	cr6.compare(f27.f64, ctx.f13.f64);
	// bne cr6,0x820d6dd8
	if (!cr6.getEQ()) goto loc_820D6DD8;
	// stfs f27,8(r26)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r26.u32 + 8, temp.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// lfs f27,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	f27.f64 = double(temp.f32);
	// stfs f30,0(r26)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r26.u32 + 0, temp.u32);
	// stfs f31,4(r26)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r26.u32 + 4, temp.u32);
	// stfs f27,16(r31)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r31.u32 + 16, temp.u32);
	// stfs f27,92(r30)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r30.u32 + 92, temp.u32);
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// addi r12,r1,-56
	r12.s64 = ctx.r1.s64 + -56;
	// bl 0x823ed584
	// b 0x823ed180
	return;
loc_820D6DD8:
	// fsubs f0,f30,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f30.f64 - f0.f64));
	// stfs f0,160(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f0,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	f0.f64 = double(temp.f32);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// fsubs f0,f31,f0
	f0.f64 = double(float(f31.f64 - f0.f64));
	// stfs f0,164(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// lfs f0,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	f0.f64 = double(temp.f32);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// fsubs f0,f27,f0
	f0.f64 = double(float(f27.f64 - f0.f64));
	// stfs f0,168(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// bl 0x82121c20
	sub_82121C20(ctx, base);
	// lfs f12,128(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,112(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// addi r6,r1,104
	ctx.r6.s64 = ctx.r1.s64 + 104;
	// lfs f0,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// lfs f12,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// stfs f12,116(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// stfs f0,180(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fsubs f0,f30,f0
	f0.f64 = double(float(f30.f64 - f0.f64));
	// lfs f13,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,120(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fsubs f0,f27,f13
	f0.f64 = double(float(f27.f64 - ctx.f13.f64));
	// lfs f12,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f12.f64 = double(temp.f32);
	// stfs f24,176(r1)
	temp.f32 = float(f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// stfs f12,124(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// stfs f13,184(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// stfs f0,108(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// bl 0x8210aa98
	sub_8210AA98(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lfs f12,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f12.f64 = double(temp.f32);
	// fmr f27,f31
	f27.f64 = f31.f64;
	// lfs f11,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f11.f64 = double(temp.f32);
	// li r8,31
	ctx.r8.s64 = 31;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// fmr f8,f25
	ctx.f8.f64 = f25.f64;
	// fmr f7,f26
	ctx.f7.f64 = f26.f64;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmr f6,f28
	ctx.f6.f64 = f28.f64;
	// lfs f2,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// fmr f5,f29
	ctx.f5.f64 = f29.f64;
	// fmuls f12,f0,f12
	ctx.f12.f64 = double(float(f0.f64 * ctx.f12.f64));
	// lfs f13,14480(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14480);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f11
	f0.f64 = double(float(f0.f64 * ctx.f11.f64));
	// fmadds f31,f12,f13,f1
	f31.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + ctx.f1.f64));
	// fmadds f30,f0,f13,f2
	f30.f64 = double(float(f0.f64 * ctx.f13.f64 + ctx.f2.f64));
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f4,f30
	ctx.f4.f64 = f30.f64;
	// bl 0x82112020
	sub_82112020(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d6f10
	if (cr6.getEQ()) goto loc_820D6F10;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d6f10
	if (cr6.getEQ()) goto loc_820D6F10;
	// li r7,31
	ctx.r7.s64 = 31;
	// fmr f5,f28
	ctx.fpscr.disableFlushMode();
	ctx.f5.f64 = f28.f64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// fmr f4,f29
	ctx.f4.f64 = f29.f64;
	// fmr f3,f24
	ctx.f3.f64 = f24.f64;
	// fmr f2,f30
	ctx.f2.f64 = f30.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x821126c0
	sub_821126C0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge cr6,0x820d6f10
	if (!cr6.getLT()) goto loc_820D6F10;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stfs f31,88(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r30.u32 + 88, temp.u32);
	// stfs f30,96(r30)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r30.u32 + 96, temp.u32);
	// stfs f31,0(r29)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// stfs f30,20(r31)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
loc_820D6F10:
	// stfs f27,16(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r31.u32 + 16, temp.u32);
	// li r3,0
	ctx.r3.s64 = 0;
	// stfs f27,92(r30)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r30.u32 + 92, temp.u32);
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// addi r12,r1,-56
	r12.s64 = ctx.r1.s64 + -56;
	// bl 0x823ed584
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820D6F30"))) PPC_WEAK_FUNC(sub_820D6F30);
PPC_FUNC_IMPL(__imp__sub_820D6F30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r9,-32014
	ctx.r9.s64 = -2098069504;
	// lfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	f0.f64 = double(temp.f32);
	// li r11,0
	r11.s64 = 0;
	// lwz r10,-6384(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + -6384);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// ble cr6,0x820d6fd8
	if (!cr6.getGT()) goto loc_820D6FD8;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lfs f13,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f11,2688(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 2688);
	ctx.f11.f64 = double(temp.f32);
	// fdivs f8,f13,f3
	ctx.f8.f64 = double(float(ctx.f13.f64 / ctx.f3.f64));
	// lfs f9,2692(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2692);
	ctx.f9.f64 = double(temp.f32);
loc_820D6F64:
	// fmuls f13,f8,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f8.f64 * f0.f64));
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f12,f1,f10
	ctx.f12.f64 = double(float(ctx.f1.f64 - ctx.f10.f64));
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fcmpu cr6,f12,f11
	cr6.compare(ctx.f12.f64, ctx.f11.f64);
	// fmuls f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// ble cr6,0x820d6fe0
	if (!cr6.getGT()) goto loc_820D6FE0;
	// fcmpu cr6,f0,f11
	cr6.compare(f0.f64, ctx.f11.f64);
	// ble cr6,0x820d6fa4
	if (!cr6.getGT()) goto loc_820D6FA4;
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// bgt cr6,0x820d6fa4
	if (cr6.getGT()) goto loc_820D6FA4;
	// fsubs f0,f0,f3
	f0.f64 = double(float(f0.f64 - ctx.f3.f64));
	// fcmpu cr6,f0,f3
	cr6.compare(f0.f64, ctx.f3.f64);
	// bge cr6,0x820d6fcc
	if (!cr6.getLT()) goto loc_820D6FCC;
	// fmr f0,f3
	f0.f64 = ctx.f3.f64;
	// b 0x820d6fcc
	goto loc_820D6FCC;
loc_820D6FA4:
	// fcmpu cr6,f0,f4
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f4.f64);
	// bge cr6,0x820d6fcc
	if (!cr6.getLT()) goto loc_820D6FCC;
	// fcmpu cr6,f0,f11
	cr6.compare(f0.f64, ctx.f11.f64);
	// bge cr6,0x820d6fbc
	if (!cr6.getLT()) goto loc_820D6FBC;
	// fadds f0,f0,f3
	f0.f64 = double(float(f0.f64 + ctx.f3.f64));
	// b 0x820d6fc0
	goto loc_820D6FC0;
loc_820D6FBC:
	// fadds f0,f0,f2
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f0.f64 + ctx.f2.f64));
loc_820D6FC0:
	// fcmpu cr6,f0,f4
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f4.f64);
	// ble cr6,0x820d6fcc
	if (!cr6.getGT()) goto loc_820D6FCC;
	// fmr f0,f4
	f0.f64 = ctx.f4.f64;
loc_820D6FCC:
	// fcmpu cr6,f0,f12
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f12.f64);
	// blt cr6,0x820d703c
	if (cr6.getLT()) goto loc_820D703C;
loc_820D6FD4:
	// stfs f1,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
loc_820D6FD8:
	// stfs f0,0(r5)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
loc_820D6FE0:
	// fcmpu cr6,f0,f11
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f11.f64);
	// bge cr6,0x820d7008
	if (!cr6.getLT()) goto loc_820D7008;
	// fneg f7,f12
	ctx.f7.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// fcmpu cr6,f7,f13
	cr6.compare(ctx.f7.f64, ctx.f13.f64);
	// bgt cr6,0x820d7008
	if (cr6.getGT()) goto loc_820D7008;
	// fadds f0,f0,f3
	f0.f64 = double(float(f0.f64 + ctx.f3.f64));
	// fneg f13,f3
	ctx.f13.u64 = ctx.f3.u64 ^ 0x8000000000000000;
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820d7034
	if (!cr6.getGT()) goto loc_820D7034;
	// b 0x820d7030
	goto loc_820D7030;
loc_820D7008:
	// fneg f13,f4
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = ctx.f4.u64 ^ 0x8000000000000000;
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820d7034
	if (!cr6.getGT()) goto loc_820D7034;
	// fcmpu cr6,f0,f11
	cr6.compare(f0.f64, ctx.f11.f64);
	// ble cr6,0x820d7024
	if (!cr6.getGT()) goto loc_820D7024;
	// fsubs f0,f0,f3
	f0.f64 = double(float(f0.f64 - ctx.f3.f64));
	// b 0x820d7028
	goto loc_820D7028;
loc_820D7024:
	// fsubs f0,f0,f2
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f0.f64 - ctx.f2.f64));
loc_820D7028:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820d7034
	if (!cr6.getLT()) goto loc_820D7034;
loc_820D7030:
	// fmr f0,f13
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f13.f64;
loc_820D7034:
	// fcmpu cr6,f0,f12
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f12.f64);
	// ble cr6,0x820d6fd4
	if (!cr6.getGT()) goto loc_820D6FD4;
loc_820D703C:
	// fadds f13,f10,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f10.f64 + f0.f64));
	// stfs f13,0(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lwz r10,-6384(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + -6384);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// blt cr6,0x820d6f64
	if (cr6.getLT()) goto loc_820D6F64;
	// stfs f0,0(r5)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D7060"))) PPC_WEAK_FUNC(sub_820D7060);
PPC_FUNC_IMPL(__imp__sub_820D7060) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 - f0.f64));
	// lfs f13,14444(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14444);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f6,6588(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6588);
	ctx.f6.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820d7094
	if (!cr6.getLT()) goto loc_820D7094;
	// fadds f1,f1,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 + ctx.f6.f64));
	// b 0x820d70a8
	goto loc_820D70A8;
loc_820D7094:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,14032(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14032);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820d70a8
	if (cr6.getLT()) goto loc_820D70A8;
	// fsubs f1,f1,f6
	ctx.f1.f64 = double(float(ctx.f1.f64 - ctx.f6.f64));
loc_820D70A8:
	// bl 0x820d6f30
	sub_820D6F30(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f13,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820d70c8
	if (!cr6.getLT()) goto loc_820D70C8;
	// fadds f0,f0,f6
	f0.f64 = double(float(f0.f64 + ctx.f6.f64));
	// stfs f0,0(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
loc_820D70C8:
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f6
	cr6.compare(f0.f64, ctx.f6.f64);
	// blt cr6,0x820d70dc
	if (cr6.getLT()) goto loc_820D70DC;
	// fsubs f0,f0,f6
	f0.f64 = double(float(f0.f64 - ctx.f6.f64));
	// stfs f0,0(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
loc_820D70DC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D70F0"))) PPC_WEAK_FUNC(sub_820D70F0);
PPC_FUNC_IMPL(__imp__sub_820D70F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stfd f29,-80(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -80, f29.u64);
	// stfd f30,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, f30.u64);
	// stfd f31,-64(r1)
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// lwz r11,100(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 100);
	// rlwinm r11,r11,0,16,14
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFEFFFF;
	// rlwinm r10,r11,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// stw r11,100(r30)
	PPC_STORE_U32(r30.u32 + 100, r11.u32);
	// beq cr6,0x820d744c
	if (cr6.getEQ()) goto loc_820D744C;
	// lbz r11,3(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 3);
	// lwz r31,108(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x820d7168
	if (!cr6.getEQ()) goto loc_820D7168;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d4870
	sub_820D4870(ctx, base);
	// lwz r11,100(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 100);
	// li r10,0
	ctx.r10.s64 = 0;
	// rlwinm r11,r11,0,25,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFF7F;
	// stw r10,108(r30)
	PPC_STORE_U32(r30.u32 + 108, ctx.r10.u32);
	// stw r11,100(r30)
	PPC_STORE_U32(r30.u32 + 100, r11.u32);
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// lfd f29,-80(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// lfd f30,-72(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f31,-64(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x823ed180
	return;
loc_820D7168:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r28,r30,24
	r28.s64 = r30.s64 + 24;
	// rlwinm r11,r11,0,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// rlwinm r11,r11,0,30,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// stw r10,136(r31)
	PPC_STORE_U32(r31.u32 + 136, ctx.r10.u32);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8210bb30
	sub_8210BB30(ctx, base);
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x8210ba08
	sub_8210BA08(ctx, base);
	// addi r27,r31,104
	r27.s64 = r31.s64 + 104;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x8210c888
	sub_8210C888(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x8210c350
	sub_8210C350(ctx, base);
	// addi r5,r1,160
	ctx.r5.s64 = ctx.r1.s64 + 160;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8210b350
	sub_8210B350(ctx, base);
	// lfs f13,164(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f13,f13
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// lfs f0,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	f0.f64 = double(temp.f32);
	// lfs f13,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// fmadds f0,f0,f0,f12
	f0.f64 = double(float(f0.f64 * f0.f64 + ctx.f12.f64));
	// fmadds f0,f13,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// fsqrts f0,f0
	f0.f64 = double(float(sqrt(f0.f64)));
	// stfs f0,192(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 192, temp.u32);
	// lfs f13,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f13,f13
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// lfs f0,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	f0.f64 = double(temp.f32);
	// lfs f13,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f0,f0,f12
	f0.f64 = double(float(f0.f64 * f0.f64 + ctx.f12.f64));
	// fmadds f0,f13,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// fsqrts f0,f0
	f0.f64 = double(float(sqrt(f0.f64)));
	// stfs f0,196(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 196, temp.u32);
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f13,f13
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// lfs f0,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	f0.f64 = double(temp.f32);
	// lfs f13,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f0,f0,f12
	f0.f64 = double(float(f0.f64 * f0.f64 + ctx.f12.f64));
	// fmadds f0,f13,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// fsqrts f0,f0
	f0.f64 = double(float(sqrt(f0.f64)));
	// stfs f0,200(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 200, temp.u32);
	// lfs f0,24(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 24);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// lfs f13,32(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// bne cr6,0x820d7260
	if (!cr6.getEQ()) goto loc_820D7260;
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// bne cr6,0x820d7260
	if (!cr6.getEQ()) goto loc_820D7260;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f0,f31
	f0.f64 = f31.f64;
	// addi r11,r11,2776
	r11.s64 = r11.s64 + 2776;
	// lfs f29,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	f29.f64 = double(temp.f32);
	// fmr f13,f29
	ctx.f13.f64 = f29.f64;
	// b 0x820d7284
	goto loc_820D7284;
loc_820D7260:
	// fmuls f12,f0,f0
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(f0.f64 * f0.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r11,r11,2776
	r11.s64 = r11.s64 + 2776;
	// lfs f29,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	f29.f64 = double(temp.f32);
	// fmadds f12,f13,f13,f12
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fsqrts f12,f12
	ctx.f12.f64 = double(float(sqrt(ctx.f12.f64)));
	// fdivs f12,f29,f12
	ctx.f12.f64 = double(float(f29.f64 / ctx.f12.f64));
	// fmuls f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * f0.f64));
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
loc_820D7284:
	// lfs f12,44(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 44);
	ctx.f12.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fcmpu cr6,f12,f31
	cr6.compare(ctx.f12.f64, f31.f64);
	// stfs f31,84(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f13,88(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f31,92(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// stfs f31,96(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f31,104(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stfs f31,108(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f31,116(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f31,124(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// blt cr6,0x820d72c0
	if (cr6.getLT()) goto loc_820D72C0;
	// stfs f29,100(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fneg f13,f13
	ctx.f13.u64 = ctx.f13.u64 ^ 0x8000000000000000;
	// b 0x820d72d0
	goto loc_820D72D0;
loc_820D72C0:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fneg f0,f0
	ctx.fpscr.disableFlushMode();
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// lfs f12,6580(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6580);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,100(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
loc_820D72D0:
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// stfs f0,120(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stfs f13,112(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f31,128(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f31,132(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// stfs f31,136(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// stfs f29,140(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// bl 0x8210bb30
	sub_8210BB30(ctx, base);
	// addi r29,r31,120
	r29.s64 = r31.s64 + 120;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8210c888
	sub_8210C888(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8210cda0
	sub_8210CDA0(ctx, base);
	// stfs f31,96(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 96, temp.u32);
	// lfs f11,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,228(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 228);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// lfs f0,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	f0.f64 = double(temp.f32);
	// lfs f13,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f0,f0,f13,f12
	f0.f64 = double(float(f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fmadds f1,f11,f10,f0
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f10.f64 + f0.f64));
	// bl 0x8210acb8
	sub_8210ACB8(ctx, base);
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// fcmpu cr6,f30,f31
	cr6.compare(f30.f64, f31.f64);
	// ble cr6,0x820d73b4
	if (!cr6.getGT()) goto loc_820D73B4;
	// lfs f0,28(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 28);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x820d7380
	if (!cr6.getGT()) goto loc_820D7380;
	// lfs f13,4(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820d7380
	if (!cr6.getGT()) goto loc_820D7380;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,17728(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17728);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f13,f30,f0
	ctx.f13.f64 = double(float(f30.f64 * f0.f64));
	// lfs f0,14116(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14116);
	f0.f64 = double(temp.f32);
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// stfs f0,100(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 100, temp.u32);
	// b 0x820d7410
	goto loc_820D7410;
loc_820D7380:
	// fcmpu cr6,f0,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f31.f64);
	// bge cr6,0x820d73b4
	if (!cr6.getLT()) goto loc_820D73B4;
	// lfs f13,4(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820d73b4
	if (!cr6.getLT()) goto loc_820D73B4;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,17728(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17728);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f13,f30,f0
	ctx.f13.f64 = double(float(f30.f64 * f0.f64));
	// lfs f0,14116(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14116);
	f0.f64 = double(temp.f32);
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// stfs f0,100(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 100, temp.u32);
	// b 0x820d7410
	goto loc_820D7410;
loc_820D73B4:
	// lfs f0,8(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r26.u32 + 8);
	f0.f64 = double(temp.f32);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lfs f13,32(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 32);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 * ctx.f13.f64));
	// lfs f12,28(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 28);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,4(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,0(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f0,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	f0.f64 = double(temp.f32);
	// lfs f9,0(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f0,f0,f0
	f0.f64 = double(float(f0.f64 * f0.f64));
	// fmadds f13,f12,f11,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f11.f64 + ctx.f13.f64));
	// fmadds f13,f10,f9,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f9.f64 + ctx.f13.f64));
	// fdivs f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 / f0.f64));
	// bl 0x8210acb8
	sub_8210ACB8(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// fcmpu cr6,f30,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f30.f64, f31.f64);
	// lfs f0,-6368(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fdivs f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 / f0.f64));
	// beq cr6,0x820d740c
	if (cr6.getEQ()) goto loc_820D740C;
	// fdivs f0,f0,f30
	f0.f64 = double(float(f0.f64 / f30.f64));
	// stfs f0,100(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 100, temp.u32);
	// b 0x820d7410
	goto loc_820D7410;
loc_820D740C:
	// stfs f29,100(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r31.u32 + 100, temp.u32);
loc_820D7410:
	// lfs f0,100(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 100);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bge cr6,0x820d7424
	if (!cr6.getLT()) goto loc_820D7424;
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// stfs f0,100(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 100, temp.u32);
loc_820D7424:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,100(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 100);
	f0.f64 = double(temp.f32);
	// lfs f13,14392(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14392);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820d7448
	if (cr6.getLT()) goto loc_820D7448;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,14396(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14396);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820d744c
	if (!cr6.getGT()) goto loc_820D744C;
loc_820D7448:
	// stfs f13,100(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 100, temp.u32);
loc_820D744C:
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// lfd f29,-80(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// lfd f30,-72(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f31,-64(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820D7460"))) PPC_WEAK_FUNC(sub_820D7460);
PPC_FUNC_IMPL(__imp__sub_820D7460) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// addi r12,r1,-16
	r12.s64 = ctx.r1.s64 + -16;
	// bl 0x823ed548
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lfs f13,4(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f11,f13
	ctx.f11.f64 = ctx.f13.f64;
	// lfs f0,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	f0.f64 = double(temp.f32);
	// fmuls f13,f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// lfs f12,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fmr f9,f12
	ctx.f9.f64 = ctx.f12.f64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lfs f10,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f10.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmadds f13,f0,f0,f13
	ctx.f13.f64 = double(float(f0.f64 * f0.f64 + ctx.f13.f64));
	// fmadds f13,f12,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + ctx.f13.f64));
	// lfs f12,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f12.f64 = double(temp.f32);
	// fsqrts f13,f13
	ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
	// fdivs f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 / ctx.f13.f64));
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmuls f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f9.f64));
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bne cr6,0x820d74e0
	if (!cr6.getEQ()) goto loc_820D74E0;
	// fcmpu cr6,f13,f12
	cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// bne cr6,0x820d74e0
	if (!cr6.getEQ()) goto loc_820D74E0;
	// fmr f30,f12
	f30.f64 = ctx.f12.f64;
	// fmr f31,f12
	f31.f64 = ctx.f12.f64;
	// fmr f29,f11
	f29.f64 = ctx.f11.f64;
	// b 0x820d750c
	goto loc_820D750C;
loc_820D74E0:
	// fmuls f12,f0,f0
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(f0.f64 * f0.f64));
	// fmadds f12,f13,f13,f12
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fsqrts f12,f12
	ctx.f12.f64 = double(float(sqrt(ctx.f12.f64)));
	// fdivs f10,f10,f12
	ctx.f10.f64 = double(float(ctx.f10.f64 / ctx.f12.f64));
	// fneg f31,f12
	f31.u64 = ctx.f12.u64 ^ 0x8000000000000000;
	// fmuls f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fmuls f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fneg f12,f0
	ctx.f12.u64 = f0.u64 ^ 0x8000000000000000;
	// fmr f10,f13
	ctx.f10.f64 = ctx.f13.f64;
	// fmuls f30,f0,f11
	f30.f64 = double(float(f0.f64 * ctx.f11.f64));
	// fmuls f29,f13,f11
	f29.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
loc_820D750C:
	// fmr f2,f12
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = ctx.f12.f64;
	// fmr f1,f10
	ctx.f1.f64 = ctx.f10.f64;
	// bl 0x8210ae20
	sub_8210AE20(ctx, base);
	// fmr f28,f1
	ctx.fpscr.disableFlushMode();
	f28.f64 = ctx.f1.f64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// fneg f1,f28
	ctx.f1.u64 = f28.u64 ^ 0x8000000000000000;
	// bl 0x8210b8c8
	sub_8210B8C8(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stfs f30,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stfs f31,84(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f29,88(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// lfs f2,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210ae20
	sub_8210AE20(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// lfs f0,11980(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 11980);
	f0.f64 = double(temp.f32);
	// fsubs f1,f28,f0
	ctx.f1.f64 = double(float(f28.f64 - f0.f64));
	// bl 0x8210b8c8
	sub_8210B8C8(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// lfs f0,11976(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 11976);
	f0.f64 = double(temp.f32);
	// fsubs f1,f0,f31
	ctx.f1.f64 = double(float(f0.f64 - f31.f64));
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x8210b350
	sub_8210B350(ctx, base);
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// addi r12,r1,-16
	r12.s64 = ctx.r1.s64 + -16;
	// bl 0x823ed594
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D75A8"))) PPC_WEAK_FUNC(sub_820D75A8);
PPC_FUNC_IMPL(__imp__sub_820D75A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// bl 0x820d7460
	sub_820D7460(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lfs f1,20(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d4fd8
	sub_820D4FD8(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// bl 0x820d4a60
	sub_820D4A60(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lfs f13,88(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,40(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 40);
	ctx.f10.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f12,92(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// lfs f9,44(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 44);
	ctx.f9.f64 = double(temp.f32);
	// lfs f11,96(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 96);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,12(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12);
	f0.f64 = double(temp.f32);
	// fnmsubs f13,f10,f0,f13
	ctx.f13.f64 = double(float(-(ctx.f10.f64 * f0.f64 - ctx.f13.f64)));
	// lfs f8,48(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// stfs f13,88(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 88, temp.u32);
	// fnmsubs f13,f9,f0,f12
	ctx.f13.f64 = double(float(-(ctx.f9.f64 * f0.f64 - ctx.f12.f64)));
	// fnmsubs f0,f8,f0,f11
	f0.f64 = double(float(-(ctx.f8.f64 * f0.f64 - ctx.f11.f64)));
	// stfs f13,92(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 92, temp.u32);
	// stfs f0,96(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 96, temp.u32);
	// bl 0x820d4d08
	sub_820D4D08(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820D7648"))) PPC_WEAK_FUNC(sub_820D7648);
PPC_FUNC_IMPL(__imp__sub_820D7648) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-336(r1)
	ea = -336 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// lbz r11,1(r26)
	r11.u64 = PPC_LOAD_U8(r26.u32 + 1);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d773c
	if (cr6.getEQ()) goto loc_820D773C;
	// lwz r31,8(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// bl 0x820d4968
	sub_820D4968(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,108(r31)
	PPC_STORE_U32(r31.u32 + 108, ctx.r3.u32);
	// beq cr6,0x820d773c
	if (cr6.getEQ()) goto loc_820D773C;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82118bc8
	sub_82118BC8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x820d773c
	if (cr6.getEQ()) goto loc_820D773C;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820ced38
	sub_820CED38(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820ccbb0
	sub_820CCBB0(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820cca28
	sub_820CCA28(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r28,24(r11)
	PPC_STORE_U32(r11.u32 + 24, r28.u32);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// stw r27,28(r11)
	PPC_STORE_U32(r11.u32 + 28, r27.u32);
	// bl 0x820ccc18
	sub_820CCC18(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r31,88
	ctx.r3.s64 = r31.s64 + 88;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// addi r30,r1,144
	r30.s64 = ctx.r1.s64 + 144;
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x8210b450
	sub_8210B450(ctx, base);
	// addi r4,r1,208
	ctx.r4.s64 = ctx.r1.s64 + 208;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x8210c4e8
	sub_8210C4E8(ctx, base);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r5,r11,4
	ctx.r5.s64 = r11.s64 + 4;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x8210b450
	sub_8210B450(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// b 0x823ed180
	return;
loc_820D773C:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,336
	ctx.r1.s64 = ctx.r1.s64 + 336;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820D7748"))) PPC_WEAK_FUNC(sub_820D7748);
PPC_FUNC_IMPL(__imp__sub_820D7748) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// lwz r29,8(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r30,32(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// lwz r11,100(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 100);
	// rlwinm r27,r11,15,30,31
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 15) & 0x3;
	// beq cr6,0x820d78a8
	if (cr6.getEQ()) goto loc_820D78A8;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d7790
	if (cr6.getEQ()) goto loc_820D7790;
loc_820D7780:
	// mr r30,r11
	r30.u64 = r11.u64;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d7780
	if (!cr6.getEQ()) goto loc_820D7780;
loc_820D7790:
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// lwz r10,24(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// beq cr6,0x820d77dc
	if (cr6.getEQ()) goto loc_820D77DC;
	// lwz r3,20(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// bl 0x82118c20
	sub_82118C20(ctx, base);
	// lfs f0,48(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	f0.f64 = double(temp.f32);
	// addi r26,r1,104
	r26.s64 = ctx.r1.s64 + 104;
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f0,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	f0.f64 = double(temp.f32);
	// stfs f0,108(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f0,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	f0.f64 = double(temp.f32);
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x8210b6e0
	sub_8210B6E0(ctx, base);
	// b 0x820d77f4
	goto loc_820D77F4;
loc_820D77DC:
	// lfs f0,12(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f0,16(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 16);
	f0.f64 = double(temp.f32);
	// stfs f0,108(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lfs f0,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	f0.f64 = double(temp.f32);
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
loc_820D77F4:
	// lbz r11,1(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 1);
	// rlwinm r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d786c
	if (!cr6.getEQ()) goto loc_820D786C;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f2,20(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// lfs f4,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f4.f64 = double(temp.f32);
	// lfs f1,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// lfs f3,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f3.f64 = double(temp.f32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d786c
	if (cr6.getEQ()) goto loc_820D786C;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r6,64(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// li r10,0
	ctx.r10.s64 = 0;
	// rlwinm r11,r11,0,28,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xE;
	// lwz r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r9,r30,48
	ctx.r9.s64 = r30.s64 + 48;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// stb r7,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, ctx.r7.u8);
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// stw r6,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r6.u32);
	// rlwinm r7,r11,27,31,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// extsh r6,r28
	ctx.r6.s64 = r28.s16;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821427b8
	sub_821427B8(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed180
	return;
loc_820D786C:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r11,64(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// li r10,1
	ctx.r10.s64 = 1;
	// addi r9,r30,48
	ctx.r9.s64 = r30.s64 + 48;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// extsh r6,r28
	ctx.r6.s64 = r28.s16;
	// stb r5,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, ctx.r5.u8);
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// lwz r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bl 0x821427b8
	sub_821427B8(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed180
	return;
loc_820D78A8:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm r11,r11,0,28,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xE;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d78cc
	if (!cr6.getEQ()) goto loc_820D78CC;
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// li r7,1
	ctx.r7.s64 = 1;
	// rlwinm r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d78d0
	if (cr6.getEQ()) goto loc_820D78D0;
loc_820D78CC:
	// li r7,0
	ctx.r7.s64 = 0;
loc_820D78D0:
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,64(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// lbz r10,1(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// addi r9,r31,48
	ctx.r9.s64 = r31.s64 + 48;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// lwz r5,24(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// rlwinm r10,r10,29,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1;
	// extsh r6,r28
	ctx.r6.s64 = r28.s16;
	// stb r4,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, ctx.r4.u8);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r4,r29,88
	ctx.r4.s64 = r29.s64 + 88;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bl 0x821427b8
	sub_821427B8(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820D7910"))) PPC_WEAK_FUNC(sub_820D7910);
PPC_FUNC_IMPL(__imp__sub_820D7910) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stfd f30,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, f30.u64);
	// stfd f31,-64(r1)
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// ble cr6,0x820d79d8
	if (!cr6.getGT()) goto loc_820D79D8;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r30,r27
	r30.u64 = r27.u64;
	// lfs f30,2688(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	f30.f64 = double(temp.f32);
	// lfd f31,2752(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + 2752);
loc_820D7954:
	// addi r29,r10,1
	r29.s64 = ctx.r10.s64 + 1;
	// lfs f0,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmr f13,f31
	ctx.f13.f64 = f31.f64;
	// rotlwi r11,r29,1
	r11.u64 = __builtin_rotateleft32(r29.u32, 1);
	// divw r9,r29,r31
	ctx.r9.s32 = r29.s32 / r31.s32;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// mullw r9,r9,r31
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(r31.s32);
	// andc r11,r31,r11
	r11.u64 = r31.u64 & ~r11.u64;
	// subf r9,r9,r29
	ctx.r9.s64 = r29.s64 - ctx.r9.s64;
	// twlgei r11,-1
	// rlwinm r11,r9,3,0,28
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// twllei r31,0
	// add r11,r11,r27
	r11.u64 = r11.u64 + r27.u64;
	// lfs f11,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// fsub f11,f11,f0
	ctx.f11.f64 = ctx.f11.f64 - f0.f64;
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	f0.f64 = double(temp.f32);
	// fsub f10,f12,f0
	ctx.f10.f64 = ctx.f12.f64 - f0.f64;
	// fcmpu cr6,f11,f31
	cr6.compare(ctx.f11.f64, f31.f64);
	// bne cr6,0x820d79ec
	if (!cr6.getEQ()) goto loc_820D79EC;
	// fcmpu cr6,f10,f31
	cr6.compare(ctx.f10.f64, f31.f64);
	// bne cr6,0x820d79ec
	if (!cr6.getEQ()) goto loc_820D79EC;
	// fmr f0,f12
	f0.f64 = ctx.f12.f64;
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stfs f30,84(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// bl 0x820ce060
	sub_820CE060(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d7c18
	if (cr6.getEQ()) goto loc_820D7C18;
loc_820D79D8:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f30,-72(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f31,-64(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x823ed180
	return;
loc_820D79EC:
	// lfs f0,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// addi r11,r9,1
	r11.s64 = ctx.r9.s64 + 1;
	// fmul f0,f0,f10
	f0.f64 = f0.f64 * ctx.f10.f64;
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// divw r8,r11,r31
	ctx.r8.s32 = r11.s32 / r31.s32;
	// rotlwi r9,r11,1
	ctx.r9.u64 = __builtin_rotateleft32(r11.u32, 1);
	// mullw r8,r8,r31
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(r31.s32);
	// fmadd f0,f12,f11,f0
	f0.f64 = ctx.f12.f64 * ctx.f11.f64 + f0.f64;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// subf r11,r8,r11
	r11.s64 = r11.s64 - ctx.r8.s64;
	// andc r9,r31,r9
	ctx.r9.u64 = r31.u64 & ~ctx.r9.u64;
	// twllei r31,0
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// twlgei r9,-1
	// beq cr6,0x820d7a74
	if (cr6.getEQ()) goto loc_820D7A74;
loc_820D7A28:
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r9,r9,r27
	ctx.r9.u64 = ctx.r9.u64 + r27.u64;
	// lfs f13,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmul f13,f13,f11
	ctx.f13.f64 = ctx.f13.f64 * ctx.f11.f64;
	// lfs f12,4(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fmadd f13,f12,f10,f13
	ctx.f13.f64 = ctx.f12.f64 * ctx.f10.f64 + ctx.f13.f64;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x820d7a74
	if (!cr6.getEQ()) goto loc_820D7A74;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// twllei r31,0
	// divw r8,r11,r31
	ctx.r8.s32 = r11.s32 / r31.s32;
	// rotlwi r9,r11,1
	ctx.r9.u64 = __builtin_rotateleft32(r11.u32, 1);
	// mullw r8,r8,r31
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(r31.s32);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// subf r11,r8,r11
	r11.s64 = r11.s64 - ctx.r8.s64;
	// andc r9,r31,r9
	ctx.r9.u64 = r31.u64 & ~ctx.r9.u64;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// twlgei r9,-1
	// bne cr6,0x820d7a28
	if (!cr6.getEQ()) goto loc_820D7A28;
loc_820D7A74:
	// li r11,0
	r11.s64 = 0;
	// cmpwi cr6,r28,4
	cr6.compare<int32_t>(r28.s32, 4, xer);
	// blt cr6,0x820d7b98
	if (cr6.getLT()) goto loc_820D7B98;
	// addi r10,r26,12
	ctx.r10.s64 = r26.s64 + 12;
loc_820D7A84:
	// lfs f12,-12(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -12);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// fmul f12,f12,f11
	ctx.f12.f64 = ctx.f12.f64 * ctx.f11.f64;
	// lfs f9,-8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -8);
	ctx.f9.f64 = double(temp.f32);
	// fmadd f12,f9,f10,f12
	ctx.f12.f64 = ctx.f9.f64 * ctx.f10.f64 + ctx.f12.f64;
	// bne cr6,0x820d7aa4
	if (!cr6.getEQ()) goto loc_820D7AA4;
	// fsub f13,f0,f12
	ctx.f13.f64 = f0.f64 - ctx.f12.f64;
	// fadd f13,f13,f0
	ctx.f13.f64 = ctx.f13.f64 + f0.f64;
loc_820D7AA4:
	// fcmpu cr6,f12,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f12.f64, f0.f64);
	// bge cr6,0x820d7ab4
	if (!cr6.getLT()) goto loc_820D7AB4;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x820d7c10
	if (cr6.getLT()) goto loc_820D7C10;
loc_820D7AB4:
	// fcmpu cr6,f12,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f12.f64, f0.f64);
	// ble cr6,0x820d7ac4
	if (!cr6.getGT()) goto loc_820D7AC4;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bgt cr6,0x820d7c10
	if (cr6.getGT()) goto loc_820D7C10;
loc_820D7AC4:
	// lfs f12,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// fmul f12,f12,f10
	ctx.f12.f64 = ctx.f12.f64 * ctx.f10.f64;
	// lfs f9,-4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	ctx.f9.f64 = double(temp.f32);
	// fmadd f12,f9,f11,f12
	ctx.f12.f64 = ctx.f9.f64 * ctx.f11.f64 + ctx.f12.f64;
	// bne cr6,0x820d7ae4
	if (!cr6.getEQ()) goto loc_820D7AE4;
	// fsub f13,f0,f12
	ctx.f13.f64 = f0.f64 - ctx.f12.f64;
	// fadd f13,f13,f0
	ctx.f13.f64 = ctx.f13.f64 + f0.f64;
loc_820D7AE4:
	// fcmpu cr6,f12,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f12.f64, f0.f64);
	// bge cr6,0x820d7af4
	if (!cr6.getLT()) goto loc_820D7AF4;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x820d7bfc
	if (cr6.getLT()) goto loc_820D7BFC;
loc_820D7AF4:
	// fcmpu cr6,f12,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f12.f64, f0.f64);
	// ble cr6,0x820d7b04
	if (!cr6.getGT()) goto loc_820D7B04;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bgt cr6,0x820d7bfc
	if (cr6.getGT()) goto loc_820D7BFC;
loc_820D7B04:
	// lfs f12,4(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// fmul f12,f12,f11
	ctx.f12.f64 = ctx.f12.f64 * ctx.f11.f64;
	// lfs f9,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fmadd f12,f9,f10,f12
	ctx.f12.f64 = ctx.f9.f64 * ctx.f10.f64 + ctx.f12.f64;
	// bne cr6,0x820d7b24
	if (!cr6.getEQ()) goto loc_820D7B24;
	// fsub f13,f0,f12
	ctx.f13.f64 = f0.f64 - ctx.f12.f64;
	// fadd f13,f13,f0
	ctx.f13.f64 = ctx.f13.f64 + f0.f64;
loc_820D7B24:
	// fcmpu cr6,f12,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f12.f64, f0.f64);
	// bge cr6,0x820d7b34
	if (!cr6.getLT()) goto loc_820D7B34;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x820d7c04
	if (cr6.getLT()) goto loc_820D7C04;
loc_820D7B34:
	// fcmpu cr6,f12,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f12.f64, f0.f64);
	// ble cr6,0x820d7b44
	if (!cr6.getGT()) goto loc_820D7B44;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bgt cr6,0x820d7c04
	if (cr6.getGT()) goto loc_820D7C04;
loc_820D7B44:
	// lfs f12,12(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// fmul f12,f12,f11
	ctx.f12.f64 = ctx.f12.f64 * ctx.f11.f64;
	// lfs f9,16(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// fmadd f12,f9,f10,f12
	ctx.f12.f64 = ctx.f9.f64 * ctx.f10.f64 + ctx.f12.f64;
	// bne cr6,0x820d7b64
	if (!cr6.getEQ()) goto loc_820D7B64;
	// fsub f13,f0,f12
	ctx.f13.f64 = f0.f64 - ctx.f12.f64;
	// fadd f13,f13,f0
	ctx.f13.f64 = ctx.f13.f64 + f0.f64;
loc_820D7B64:
	// fcmpu cr6,f12,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f12.f64, f0.f64);
	// bge cr6,0x820d7b74
	if (!cr6.getLT()) goto loc_820D7B74;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x820d7c0c
	if (cr6.getLT()) goto loc_820D7C0C;
loc_820D7B74:
	// fcmpu cr6,f12,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f12.f64, f0.f64);
	// ble cr6,0x820d7b84
	if (!cr6.getGT()) goto loc_820D7B84;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bgt cr6,0x820d7c0c
	if (cr6.getGT()) goto loc_820D7C0C;
loc_820D7B84:
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r9,r28,-3
	ctx.r9.s64 = r28.s64 + -3;
	// addi r10,r10,32
	ctx.r10.s64 = ctx.r10.s64 + 32;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// blt cr6,0x820d7a84
	if (cr6.getLT()) goto loc_820D7A84;
loc_820D7B98:
	// cmpw cr6,r11,r28
	cr6.compare<int32_t>(r11.s32, r28.s32, xer);
	// bge cr6,0x820d7c14
	if (!cr6.getLT()) goto loc_820D7C14;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r26
	ctx.r10.u64 = ctx.r10.u64 + r26.u64;
loc_820D7BA8:
	// lfs f12,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// fmul f12,f12,f11
	ctx.f12.f64 = ctx.f12.f64 * ctx.f11.f64;
	// lfs f9,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fmadd f12,f9,f10,f12
	ctx.f12.f64 = ctx.f9.f64 * ctx.f10.f64 + ctx.f12.f64;
	// bne cr6,0x820d7bc8
	if (!cr6.getEQ()) goto loc_820D7BC8;
	// fsub f13,f0,f12
	ctx.f13.f64 = f0.f64 - ctx.f12.f64;
	// fadd f13,f13,f0
	ctx.f13.f64 = ctx.f13.f64 + f0.f64;
loc_820D7BC8:
	// fcmpu cr6,f12,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f12.f64, f0.f64);
	// bge cr6,0x820d7bd8
	if (!cr6.getLT()) goto loc_820D7BD8;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x820d7c10
	if (cr6.getLT()) goto loc_820D7C10;
loc_820D7BD8:
	// fcmpu cr6,f12,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f12.f64, f0.f64);
	// ble cr6,0x820d7be8
	if (!cr6.getGT()) goto loc_820D7BE8;
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bgt cr6,0x820d7c10
	if (cr6.getGT()) goto loc_820D7C10;
loc_820D7BE8:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// cmpw cr6,r11,r28
	cr6.compare<int32_t>(r11.s32, r28.s32, xer);
	// blt cr6,0x820d7ba8
	if (cr6.getLT()) goto loc_820D7BA8;
	// b 0x820d7c10
	goto loc_820D7C10;
loc_820D7BFC:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// b 0x820d7c10
	goto loc_820D7C10;
loc_820D7C04:
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// b 0x820d7c10
	goto loc_820D7C10;
loc_820D7C0C:
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
loc_820D7C10:
	// cmpw cr6,r11,r28
	cr6.compare<int32_t>(r11.s32, r28.s32, xer);
loc_820D7C14:
	// beq cr6,0x820d7c3c
	if (cr6.getEQ()) goto loc_820D7C3C;
loc_820D7C18:
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// cmpw cr6,r10,r31
	cr6.compare<int32_t>(ctx.r10.s32, r31.s32, xer);
	// blt cr6,0x820d7954
	if (cr6.getLT()) goto loc_820D7954;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f30,-72(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f31,-64(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x823ed180
	return;
loc_820D7C3C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f30,-72(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f31,-64(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820D7C50"))) PPC_WEAK_FUNC(sub_820D7C50);
PPC_FUNC_IMPL(__imp__sub_820D7C50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// lfs f31,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// li r30,0
	r30.s64 = 0;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// ble cr6,0x820d7cc4
	if (!cr6.getGT()) goto loc_820D7CC4;
	// mr r31,r27
	r31.u64 = r27.u64;
loc_820D7C88:
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f31,84(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// bl 0x820ce060
	sub_820CE060(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820d7d3c
	if (!cr6.getEQ()) goto loc_820D7D3C;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r31,r31,8
	r31.s64 = r31.s64 + 8;
	// cmpw cr6,r30,r29
	cr6.compare<int32_t>(r30.s32, r29.s32, xer);
	// blt cr6,0x820d7c88
	if (cr6.getLT()) goto loc_820D7C88;
loc_820D7CC4:
	// li r30,0
	r30.s64 = 0;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// ble cr6,0x820d7d10
	if (!cr6.getGT()) goto loc_820D7D10;
	// mr r31,r26
	r31.u64 = r26.u64;
loc_820D7CD4:
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f31,84(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// bl 0x820ce060
	sub_820CE060(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820d7d3c
	if (!cr6.getEQ()) goto loc_820D7D3C;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r31,r31,8
	r31.s64 = r31.s64 + 8;
	// cmpw cr6,r30,r28
	cr6.compare<int32_t>(r30.s32, r28.s32, xer);
	// blt cr6,0x820d7cd4
	if (cr6.getLT()) goto loc_820D7CD4;
loc_820D7D10:
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x820d7910
	sub_820D7910(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d7d4c
	if (cr6.getEQ()) goto loc_820D7D4C;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x823ed180
	return;
loc_820D7D3C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x823ed180
	return;
loc_820D7D4C:
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820d7910
	sub_820D7910(ctx, base);
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820D7D78"))) PPC_WEAK_FUNC(sub_820D7D78);
PPC_FUNC_IMPL(__imp__sub_820D7D78) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed540
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// lfs f30,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	f30.f64 = double(temp.f32);
	// lfs f29,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	f29.f64 = double(temp.f32);
	// fmr f27,f1
	f27.f64 = ctx.f1.f64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// li r31,0
	r31.s64 = 0;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// ble cr6,0x820d7e84
	if (!cr6.getGT()) goto loc_820D7E84;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r29,r27
	r29.u64 = r27.u64;
	// lfs f26,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f26.f64 = double(temp.f32);
loc_820D7DB8:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// lfs f2,4(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmr f6,f29
	ctx.f6.f64 = f29.f64;
	// divw r11,r31,r28
	r11.s32 = r31.s32 / r28.s32;
	// fmr f5,f30
	ctx.f5.f64 = f30.f64;
	// rotlwi r10,r31,1
	ctx.r10.u64 = __builtin_rotateleft32(r31.u32, 1);
	// mullw r11,r11,r28
	r11.s64 = int64_t(r11.s32) * int64_t(r28.s32);
	// subf r11,r11,r31
	r11.s64 = r31.s64 - r11.s64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// rlwinm r11,r11,3,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// andc r10,r28,r10
	ctx.r10.u64 = r28.u64 & ~ctx.r10.u64;
	// add r30,r11,r27
	r30.u64 = r11.u64 + r27.u64;
	// twllei r28,0
	// twlgei r10,-1
	// lfs f4,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// bl 0x8210f828
	sub_8210F828(ctx, base);
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// fcmpu cr6,f31,f26
	cr6.compare(f31.f64, f26.f64);
	// bge cr6,0x820d7e10
	if (!cr6.getLT()) goto loc_820D7E10;
	// fneg f31,f31
	f31.u64 = f31.u64 ^ 0x8000000000000000;
loc_820D7E10:
	// lfs f2,4(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	ctx.f2.f64 = double(temp.f32);
	// fmr f4,f29
	ctx.f4.f64 = f29.f64;
	// lfs f1,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmr f3,f30
	ctx.f3.f64 = f30.f64;
	// bl 0x8210f880
	sub_8210F880(ctx, base);
	// fmr f28,f1
	ctx.fpscr.disableFlushMode();
	f28.f64 = ctx.f1.f64;
	// lfs f2,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f2.f64 = double(temp.f32);
	// fmr f4,f29
	ctx.f4.f64 = f29.f64;
	// lfs f1,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmr f3,f30
	ctx.f3.f64 = f30.f64;
	// bl 0x8210f880
	sub_8210F880(ctx, base);
	// fcmpu cr6,f31,f27
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f27.f64);
	// bge cr6,0x820d7e78
	if (!cr6.getLT()) goto loc_820D7E78;
	// fcmpu cr6,f28,f27
	cr6.compare(f28.f64, f27.f64);
	// blt cr6,0x820d7e98
	if (cr6.getLT()) goto loc_820D7E98;
	// fcmpu cr6,f1,f27
	cr6.compare(ctx.f1.f64, f27.f64);
	// blt cr6,0x820d7e98
	if (cr6.getLT()) goto loc_820D7E98;
	// lfs f4,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f4.f64 = double(temp.f32);
	// fmr f6,f29
	ctx.f6.f64 = f29.f64;
	// lfs f3,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmr f5,f30
	ctx.f5.f64 = f30.f64;
	// lfs f2,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210f898
	sub_8210F898(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820d7e98
	if (!cr6.getEQ()) goto loc_820D7E98;
loc_820D7E78:
	// addi r29,r29,8
	r29.s64 = r29.s64 + 8;
	// cmpw cr6,r31,r28
	cr6.compare<int32_t>(r31.s32, r28.s32, xer);
	// blt cr6,0x820d7db8
	if (cr6.getLT()) goto loc_820D7DB8;
loc_820D7E84:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed58c
	// b 0x823ed184
	return;
loc_820D7E98:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed58c
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820D7EB0"))) PPC_WEAK_FUNC(sub_820D7EB0);
PPC_FUNC_IMPL(__imp__sub_820D7EB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r7,r1,100
	ctx.r7.s64 = ctx.r1.s64 + 100;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x820cdf80
	sub_820CDF80(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820d80a4
	if (!cr6.getGT()) goto loc_820D80A4;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820cdf78
	sub_820CDF78(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x820cef38
	sub_820CEF38(ctx, base);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r27,-2304(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + -2304);
	// lhz r11,0(r27)
	r11.u64 = PPC_LOAD_U16(r27.u32 + 0);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x820d80a4
	if (cr6.getLT()) goto loc_820D80A4;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// addi r28,r10,-784
	r28.s64 = ctx.r10.s64 + -784;
loc_820D7F14:
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// add r31,r11,r28
	r31.u64 = r11.u64 + r28.u64;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// beq cr6,0x820d8090
	if (cr6.getEQ()) goto loc_820D8090;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// beq cr6,0x820d7fe4
	if (cr6.getEQ()) goto loc_820D7FE4;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x820d7fe4
	if (cr6.getEQ()) goto loc_820D7FE4;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x820d7f58
	if (cr6.getEQ()) goto loc_820D7F58;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x820d7f58
	if (cr6.getEQ()) goto loc_820D7F58;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x820d8090
	if (!cr6.getEQ()) goto loc_820D8090;
loc_820D7F58:
	// lbz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// bne cr6,0x820d7f84
	if (!cr6.getEQ()) goto loc_820D7F84;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x820d8090
	if (cr6.getEQ()) goto loc_820D8090;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lbz r11,3(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmplwi cr6,r11,43
	cr6.compare<uint32_t>(r11.u32, 43, xer);
	// beq cr6,0x820d8090
	if (cr6.getEQ()) goto loc_820D8090;
	// cmplwi cr6,r11,40
	cr6.compare<uint32_t>(r11.u32, 40, xer);
	// beq cr6,0x820d8090
	if (cr6.getEQ()) goto loc_820D8090;
loc_820D7F84:
	// addi r7,r1,108
	ctx.r7.s64 = ctx.r1.s64 + 108;
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// addi r4,r1,116
	ctx.r4.s64 = ctx.r1.s64 + 116;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cdf80
	sub_820CDF80(ctx, base);
	// lwz r4,104(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// ble cr6,0x820d8090
	if (!cr6.getGT()) goto loc_820D8090;
	// lfs f0,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	f0.f64 = double(temp.f32);
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820d8090
	if (cr6.getLT()) goto loc_820D8090;
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	f0.f64 = double(temp.f32);
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x820d8090
	if (cr6.getGT()) goto loc_820D8090;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r3,116(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// bl 0x820d7c50
	sub_820D7C50(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820d80d8
	if (!cr6.getEQ()) goto loc_820D80D8;
	// b 0x820d8090
	goto loc_820D8090;
loc_820D7FE4:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d800c
	if (cr6.getEQ()) goto loc_820D800C;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwinm r10,r11,0,21,21
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820d800c
	if (cr6.getEQ()) goto loc_820D800C;
	// rlwinm r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d8090
	if (!cr6.getEQ()) goto loc_820D8090;
loc_820D800C:
	// addi r6,r1,88
	ctx.r6.s64 = ctx.r1.s64 + 88;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ce148
	sub_820CE148(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ce178
	sub_820CE178(ctx, base);
	// lfs f0,88(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	f0.f64 = double(temp.f32);
	// fadds f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 + f0.f64));
	// lfs f13,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// fadds f13,f1,f13
	ctx.f13.f64 = double(float(ctx.f1.f64 + ctx.f13.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f13,92(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fcmpu cr6,f12,f0
	cr6.compare(ctx.f12.f64, f0.f64);
	// blt cr6,0x820d8090
	if (cr6.getLT()) goto loc_820D8090;
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x820d8090
	if (cr6.getGT()) goto loc_820D8090;
	// addi r30,r31,12
	r30.s64 = r31.s64 + 12;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820ce060
	sub_820CE060(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820d80b0
	if (!cr6.getEQ()) goto loc_820D80B0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lfs f1,120(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x820d7d78
	sub_820D7D78(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820d80b0
	if (!cr6.getEQ()) goto loc_820D80B0;
loc_820D8090:
	// addi r27,r27,2
	r27.s64 = r27.s64 + 2;
	// lhz r11,0(r27)
	r11.u64 = PPC_LOAD_U16(r27.u32 + 0);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820d7f14
	if (!cr6.getLT()) goto loc_820D7F14;
loc_820D80A4:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed184
	return;
loc_820D80B0:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bne cr6,0x820d80d8
	if (!cr6.getEQ()) goto loc_820D80D8;
	// lbz r11,0(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x820d80d8
	if (!cr6.getEQ()) goto loc_820D80D8;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lhz r10,18(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 18);
	// ori r10,r10,16
	ctx.r10.u64 = ctx.r10.u64 | 16;
	// sth r10,18(r11)
	PPC_STORE_U16(r11.u32 + 18, ctx.r10.u16);
loc_820D80D8:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820D80E8"))) PPC_WEAK_FUNC(sub_820D80E8);
PPC_FUNC_IMPL(__imp__sub_820D80E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed124
	// addi r12,r1,-80
	r12.s64 = ctx.r1.s64 + -80;
	// bl 0x823ed540
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// li r27,1
	r27.s64 = 1;
	// lwz r29,20(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lfs f1,172(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 172);
	ctx.f1.f64 = double(temp.f32);
	// lwz r30,16(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r8,12(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r7,16(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r26,4(r10)
	r26.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r28,4(r9)
	r28.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// lwz r25,4(r8)
	r25.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// lwz r24,4(r7)
	r24.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// lwz r23,4(r11)
	r23.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// bl 0x8210b8c8
	sub_8210B8C8(ctx, base);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// lfs f1,20(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// addi r3,r31,88
	ctx.r3.s64 = r31.s64 + 88;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8210b630
	sub_8210B630(ctx, base);
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8210b630
	sub_8210B630(ctx, base);
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8210b630
	sub_8210B630(ctx, base);
	// addi r5,r1,136
	ctx.r5.s64 = ctx.r1.s64 + 136;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8210b630
	sub_8210B630(ctx, base);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f4,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f3.f64 = double(temp.f32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// lfs f2,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d81e0
	if (cr6.getEQ()) goto loc_820D81E0;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lfs f2,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x821108b0
	sub_821108B0(ctx, base);
	// stfs f1,108(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// b 0x820d81e4
	goto loc_820D81E4;
loc_820D81E0:
	// li r27,0
	r27.s64 = 0;
loc_820D81E4:
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f4,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f3.f64 = double(temp.f32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// lfs f2,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d8224
	if (cr6.getEQ()) goto loc_820D8224;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lfs f2,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x821108b0
	sub_821108B0(ctx, base);
	// stfs f1,92(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// b 0x820d8228
	goto loc_820D8228;
loc_820D8224:
	// li r27,0
	r27.s64 = 0;
loc_820D8228:
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f4,128(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f3.f64 = double(temp.f32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// lfs f2,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d8268
	if (cr6.getEQ()) goto loc_820D8268;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lfs f2,128(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x821108b0
	sub_821108B0(ctx, base);
	// stfs f1,124(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// b 0x820d826c
	goto loc_820D826C;
loc_820D8268:
	// li r27,0
	r27.s64 = 0;
loc_820D826C:
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f4,144(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f3.f64 = double(temp.f32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// lfs f2,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820d83e4
	if (cr6.getEQ()) goto loc_820D83E4;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lfs f2,144(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x821108b0
	sub_821108B0(ctx, base);
	// stfs f1,140(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x820d83e8
	if (cr6.getEQ()) goto loc_820D83E8;
	// lfs f9,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f9.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f3,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f3.f64 = double(temp.f32);
	// fsubs f10,f9,f3
	ctx.f10.f64 = double(float(ctx.f9.f64 - ctx.f3.f64));
	// lfs f2,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	ctx.f2.f64 = double(temp.f32);
	// fsubs f9,f1,f9
	ctx.f9.f64 = double(float(ctx.f1.f64 - ctx.f9.f64));
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	f0.f64 = double(temp.f32);
	// fsubs f8,f2,f1
	ctx.f8.f64 = double(float(ctx.f2.f64 - ctx.f1.f64));
	// lfs f4,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f4.f64 = double(temp.f32);
	// lfs f11,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f13,f0,f4
	ctx.f13.f64 = double(float(f0.f64 - ctx.f4.f64));
	// fsubs f12,f11,f0
	ctx.f12.f64 = double(float(ctx.f11.f64 - f0.f64));
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	f0.f64 = double(temp.f32);
	// fsubs f3,f3,f2
	ctx.f3.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// lfs f1,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f1.f64 = double(temp.f32);
	// fsubs f11,f0,f11
	ctx.f11.f64 = double(float(f0.f64 - ctx.f11.f64));
	// lfs f6,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f7,f6,f1
	ctx.f7.f64 = double(float(ctx.f6.f64 - ctx.f1.f64));
	// fsubs f4,f4,f0
	ctx.f4.f64 = double(float(ctx.f4.f64 - f0.f64));
	// lfs f31,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	f31.f64 = double(temp.f32);
	// fsubs f6,f5,f6
	ctx.f6.f64 = double(float(ctx.f5.f64 - ctx.f6.f64));
	// fmuls f30,f10,f10
	f30.f64 = double(float(ctx.f10.f64 * ctx.f10.f64));
	// fmuls f29,f9,f9
	f29.f64 = double(float(ctx.f9.f64 * ctx.f9.f64));
	// fmuls f28,f8,f8
	f28.f64 = double(float(ctx.f8.f64 * ctx.f8.f64));
	// fsubs f5,f31,f5
	ctx.f5.f64 = double(float(f31.f64 - ctx.f5.f64));
	// fsubs f2,f1,f31
	ctx.f2.f64 = double(float(ctx.f1.f64 - f31.f64));
	// fmuls f0,f3,f3
	f0.f64 = double(float(ctx.f3.f64 * ctx.f3.f64));
	// fmadds f30,f13,f13,f30
	f30.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f30.f64));
	// fmadds f29,f12,f12,f29
	f29.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + f29.f64));
	// fmadds f28,f11,f11,f28
	f28.f64 = double(float(ctx.f11.f64 * ctx.f11.f64 + f28.f64));
	// fmadds f1,f7,f7,f30
	ctx.f1.f64 = double(float(ctx.f7.f64 * ctx.f7.f64 + f30.f64));
	// fmadds f31,f6,f6,f29
	f31.f64 = double(float(ctx.f6.f64 * ctx.f6.f64 + f29.f64));
	// fmadds f29,f4,f4,f0
	f29.f64 = double(float(ctx.f4.f64 * ctx.f4.f64 + f0.f64));
	// lfs f0,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// fmadds f30,f5,f5,f28
	f30.f64 = double(float(ctx.f5.f64 * ctx.f5.f64 + f28.f64));
	// fsqrts f1,f1
	ctx.f1.f64 = double(float(sqrt(ctx.f1.f64)));
	// fmadds f29,f2,f2,f29
	f29.f64 = double(float(ctx.f2.f64 * ctx.f2.f64 + f29.f64));
	// fsqrts f31,f31
	f31.f64 = double(float(sqrt(f31.f64)));
	// fsqrts f30,f30
	f30.f64 = double(float(sqrt(f30.f64)));
	// fsqrts f29,f29
	f29.f64 = double(float(sqrt(f29.f64)));
	// fdivs f1,f0,f1
	ctx.f1.f64 = double(float(f0.f64 / ctx.f1.f64));
	// fdivs f31,f0,f31
	f31.f64 = double(float(f0.f64 / f31.f64));
	// fdivs f30,f0,f30
	f30.f64 = double(float(f0.f64 / f30.f64));
	// fdivs f0,f0,f29
	f0.f64 = double(float(f0.f64 / f29.f64));
	// fmuls f29,f1,f13
	f29.f64 = double(float(ctx.f1.f64 * ctx.f13.f64));
	// fmuls f7,f1,f7
	ctx.f7.f64 = double(float(ctx.f1.f64 * ctx.f7.f64));
	// fmuls f12,f31,f12
	ctx.f12.f64 = double(float(f31.f64 * ctx.f12.f64));
	// fmuls f13,f31,f6
	ctx.f13.f64 = double(float(f31.f64 * ctx.f6.f64));
	// fmuls f11,f30,f11
	ctx.f11.f64 = double(float(f30.f64 * ctx.f11.f64));
	// fmuls f6,f30,f5
	ctx.f6.f64 = double(float(f30.f64 * ctx.f5.f64));
	// fmuls f28,f1,f10
	f28.f64 = double(float(ctx.f1.f64 * ctx.f10.f64));
	// fmuls f1,f31,f9
	ctx.f1.f64 = double(float(f31.f64 * ctx.f9.f64));
	// fmuls f9,f0,f4
	ctx.f9.f64 = double(float(f0.f64 * ctx.f4.f64));
	// fmuls f10,f0,f2
	ctx.f10.f64 = double(float(f0.f64 * ctx.f2.f64));
	// fmuls f27,f30,f8
	f27.f64 = double(float(f30.f64 * ctx.f8.f64));
	// fmuls f0,f0,f3
	f0.f64 = double(float(f0.f64 * ctx.f3.f64));
	// fmuls f5,f12,f7
	ctx.f5.f64 = double(float(ctx.f12.f64 * ctx.f7.f64));
	// fmuls f26,f11,f13
	f26.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmuls f4,f9,f6
	ctx.f4.f64 = double(float(ctx.f9.f64 * ctx.f6.f64));
	// fmuls f2,f10,f29
	ctx.f2.f64 = double(float(ctx.f10.f64 * f29.f64));
	// fmsubs f8,f13,f29,f5
	ctx.f8.f64 = double(float(ctx.f13.f64 * f29.f64 - ctx.f5.f64));
	// fmsubs f5,f6,f12,f26
	ctx.f5.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 - f26.f64));
	// fmsubs f4,f10,f11,f4
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 - ctx.f4.f64));
	// fmsubs f31,f9,f7,f2
	f31.f64 = double(float(ctx.f9.f64 * ctx.f7.f64 - ctx.f2.f64));
	// fcmpu cr6,f8,f5
	cr6.compare(ctx.f8.f64, ctx.f5.f64);
	// blt cr6,0x820d8444
	if (cr6.getLT()) goto loc_820D8444;
	// fcmpu cr6,f8,f4
	cr6.compare(ctx.f8.f64, ctx.f4.f64);
	// blt cr6,0x820d8444
	if (cr6.getLT()) goto loc_820D8444;
	// fcmpu cr6,f8,f31
	cr6.compare(ctx.f8.f64, f31.f64);
	// blt cr6,0x820d8444
	if (cr6.getLT()) goto loc_820D8444;
	// fmuls f0,f1,f29
	f0.f64 = double(float(ctx.f1.f64 * f29.f64));
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * f28.f64));
	// fmr f31,f8
	f31.f64 = ctx.f8.f64;
	// fmsubs f30,f12,f28,f0
	f30.f64 = double(float(ctx.f12.f64 * f28.f64 - f0.f64));
	// fmsubs f29,f1,f7,f13
	f29.f64 = double(float(ctx.f1.f64 * ctx.f7.f64 - ctx.f13.f64));
	// b 0x820d849c
	goto loc_820D849C;
loc_820D83E4:
	// li r27,0
	r27.s64 = 0;
loc_820D83E8:
	// addi r28,r31,24
	r28.s64 = r31.s64 + 24;
	// lfs f1,172(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 172);
	ctx.f1.f64 = double(temp.f32);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x8210b8c8
	sub_8210B8C8(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lfs f1,20(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// lfs f31,12(r23)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r23.u32 + 12);
	f31.f64 = double(temp.f32);
	// lfs f2,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// lwz r3,24(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// lfs f1,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x821108b0
	sub_821108B0(ctx, base);
	// lfs f0,4(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r26.u32 + 4);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f31
	f0.f64 = double(float(f0.f64 + f31.f64));
	// lfs f13,20(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f0,f0,f13,f1
	f0.f64 = double(float(-(f0.f64 * ctx.f13.f64 - ctx.f1.f64)));
loc_820D8428:
	// stfs f0,16(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 16, temp.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stfs f0,92(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 92, temp.u32);
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// addi r12,r1,-80
	r12.s64 = ctx.r1.s64 + -80;
	// bl 0x823ed58c
	// b 0x823ed174
	return;
loc_820D8444:
	// fcmpu cr6,f5,f4
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f5.f64, ctx.f4.f64);
	// blt cr6,0x820d846c
	if (cr6.getLT()) goto loc_820D846C;
	// fcmpu cr6,f5,f31
	cr6.compare(ctx.f5.f64, f31.f64);
	// blt cr6,0x820d846c
	if (cr6.getLT()) goto loc_820D846C;
	// fmuls f0,f27,f12
	f0.f64 = double(float(f27.f64 * ctx.f12.f64));
	// fmuls f12,f6,f1
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f1.f64));
	// fmr f31,f5
	f31.f64 = ctx.f5.f64;
	// fmsubs f30,f11,f1,f0
	f30.f64 = double(float(ctx.f11.f64 * ctx.f1.f64 - f0.f64));
	// fmsubs f29,f27,f13,f12
	f29.f64 = double(float(f27.f64 * ctx.f13.f64 - ctx.f12.f64));
	// b 0x820d849c
	goto loc_820D849C;
loc_820D846C:
	// fcmpu cr6,f4,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f4.f64, f31.f64);
	// blt cr6,0x820d848c
	if (cr6.getLT()) goto loc_820D848C;
	// fmuls f13,f0,f11
	ctx.f13.f64 = double(float(f0.f64 * ctx.f11.f64));
	// fmuls f12,f10,f27
	ctx.f12.f64 = double(float(ctx.f10.f64 * f27.f64));
	// fmr f31,f4
	f31.f64 = ctx.f4.f64;
	// fmsubs f30,f9,f27,f13
	f30.f64 = double(float(ctx.f9.f64 * f27.f64 - ctx.f13.f64));
	// fmsubs f29,f0,f6,f12
	f29.f64 = double(float(f0.f64 * ctx.f6.f64 - ctx.f12.f64));
	// b 0x820d849c
	goto loc_820D849C;
loc_820D848C:
	// fmuls f13,f9,f28
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f9.f64 * f28.f64));
	// fmuls f12,f0,f7
	ctx.f12.f64 = double(float(f0.f64 * ctx.f7.f64));
	// fmsubs f30,f0,f29,f13
	f30.f64 = double(float(f0.f64 * f29.f64 - ctx.f13.f64));
	// fmsubs f29,f10,f28,f12
	f29.f64 = double(float(ctx.f10.f64 * f28.f64 - ctx.f12.f64));
loc_820D849C:
	// lfs f1,172(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 172);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// lfs f0,172(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 172);
	f0.f64 = double(temp.f32);
	// frsp f28,f1
	f28.f64 = double(float(ctx.f1.f64));
	// fmr f1,f0
	ctx.f1.f64 = f0.f64;
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// addi r28,r31,24
	r28.s64 = r31.s64 + 24;
	// frsp f27,f1
	ctx.fpscr.disableFlushMode();
	f27.f64 = double(float(ctx.f1.f64));
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f13,f27,f30
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(f27.f64 * f30.f64));
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// fmuls f11,f28,f31
	ctx.f11.f64 = double(float(f28.f64 * f31.f64));
	// stfs f30,40(r31)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 40, temp.u32);
	// stfs f31,44(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 44, temp.u32);
	// stfs f29,48(r31)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r31.u32 + 48, temp.u32);
	// lfs f12,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f0,f29,f12
	f0.f64 = double(float(f29.f64 * ctx.f12.f64));
	// fmsubs f13,f28,f29,f13
	ctx.f13.f64 = double(float(f28.f64 * f29.f64 - ctx.f13.f64));
	// stfs f13,28(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 28, temp.u32);
	// fmsubs f12,f30,f12,f11
	ctx.f12.f64 = double(float(f30.f64 * ctx.f12.f64 - ctx.f11.f64));
	// stfs f12,32(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r31.u32 + 32, temp.u32);
	// fmsubs f0,f27,f31,f0
	f0.f64 = double(float(f27.f64 * f31.f64 - f0.f64));
	// stfs f0,24(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 24, temp.u32);
	// fmuls f10,f13,f30
	ctx.f10.f64 = double(float(ctx.f13.f64 * f30.f64));
	// fmuls f9,f12,f31
	ctx.f9.f64 = double(float(ctx.f12.f64 * f31.f64));
	// fmuls f11,f0,f29
	ctx.f11.f64 = double(float(f0.f64 * f29.f64));
	// fmsubs f0,f0,f31,f10
	f0.f64 = double(float(f0.f64 * f31.f64 - ctx.f10.f64));
	// stfs f0,64(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 64, temp.u32);
	// fmsubs f0,f13,f29,f9
	f0.f64 = double(float(ctx.f13.f64 * f29.f64 - ctx.f9.f64));
	// stfs f0,56(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 56, temp.u32);
	// fmsubs f0,f12,f30,f11
	f0.f64 = double(float(ctx.f12.f64 * f30.f64 - ctx.f11.f64));
	// stfs f0,60(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 60, temp.u32);
	// lfs f1,20(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8210b630
	sub_8210B630(ctx, base);
	// lfs f13,20(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,12(r23)
	temp.u32 = PPC_LOAD_U32(r23.u32 + 12);
	f0.f64 = double(temp.f32);
	// lfs f12,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f0,f0,f13,f12
	f0.f64 = double(float(-(f0.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// lfs f13,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// b 0x820d8428
	goto loc_820D8428;
}

__attribute__((alias("__imp__sub_820D8558"))) PPC_WEAK_FUNC(sub_820D8558);
PPC_FUNC_IMPL(__imp__sub_820D8558) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f29,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, f29.u64);
	// stfd f30,-32(r1)
	PPC_STORE_U64(ctx.r1.u32 + -32, f30.u64);
	// stfd f31,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// fmr f29,f2
	f29.f64 = ctx.f2.f64;
	// fmr f30,f3
	f30.f64 = ctx.f3.f64;
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// lfs f11,16(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f11
	f0.f64 = double(float(f0.f64 - ctx.f11.f64));
	// lfs f13,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// lfs f12,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// fmuls f0,f0,f0
	f0.f64 = double(float(f0.f64 * f0.f64));
	// fmadds f0,f13,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// fmadds f0,f12,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + f0.f64));
	// fsqrts f0,f0
	f0.f64 = double(float(sqrt(f0.f64)));
	// fcmpu cr6,f0,f29
	cr6.compare(f0.f64, f29.f64);
	// ble cr6,0x820d85cc
	if (!cr6.getGT()) goto loc_820D85CC;
	// li r3,255
	ctx.r3.s64 = 255;
	// b 0x820d862c
	goto loc_820D862C;
loc_820D85CC:
	// fcmpu cr6,f0,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f31.f64);
	// bge cr6,0x820d85f0
	if (!cr6.getLT()) goto loc_820D85F0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,6596(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6596);
	f0.f64 = double(temp.f32);
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// fmuls f0,f30,f0
	f0.f64 = double(float(f30.f64 * f0.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// b 0x820d8628
	goto loc_820D8628;
loc_820D85F0:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f13,f0,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(f0.f64 - f31.f64));
	// fsubs f12,f29,f31
	ctx.f12.f64 = double(float(f29.f64 - f31.f64));
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lfs f0,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f0,f0,f30
	f0.f64 = double(float(f0.f64 - f30.f64));
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fdivs f0,f0,f12
	f0.f64 = double(float(f0.f64 / ctx.f12.f64));
	// fadds f13,f0,f30
	ctx.f13.f64 = double(float(f0.f64 + f30.f64));
	// lfs f0,6596(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6596);
	f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, f0.u32);
loc_820D8628:
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_820D862C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f29,-40(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// lfd f30,-32(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// lfd f31,-24(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D8650"))) PPC_WEAK_FUNC(sub_820D8650);
PPC_FUNC_IMPL(__imp__sub_820D8650) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r11,200(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 200);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
loc_820D8664:
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lhz r9,6(r11)
	ctx.r9.u64 = PPC_LOAD_U16(r11.u32 + 6);
	// lhz r8,6(r10)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r10.u32 + 6);
	// extsh r9,r9
	ctx.r9.s64 = ctx.r9.s16;
	// extsh r8,r8
	ctx.r8.s64 = ctx.r8.s16;
	// cmpw cr6,r9,r8
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r8.s32, xer);
	// bgt cr6,0x820d8694
	if (cr6.getGT()) goto loc_820D8694;
	// lwz r11,200(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 200);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d8664
	if (!cr6.getEQ()) goto loc_820D8664;
	// blr 
	return;
loc_820D8694:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D86A0"))) PPC_WEAK_FUNC(sub_820D86A0);
PPC_FUNC_IMPL(__imp__sub_820D86A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820cca38
	sub_820CCA38(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820d8744
	if (cr6.getEQ()) goto loc_820D8744;
loc_820D86C4:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x820d871c
	if (cr6.getEQ()) goto loc_820D871C;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x820d86f0
	if (!cr6.getEQ()) goto loc_820D86F0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// cmplwi cr6,r10,13
	cr6.compare<uint32_t>(ctx.r10.u32, 13, xer);
	// bne cr6,0x820d8738
	if (!cr6.getEQ()) goto loc_820D8738;
	// lwz r3,204(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 204);
	// b 0x820d8730
	goto loc_820D8730;
loc_820D86F0:
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820d8738
	if (!cr6.getEQ()) goto loc_820D8738;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d8738
	if (cr6.getEQ()) goto loc_820D8738;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820c9b90
	sub_820C9B90(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// cmpw cr6,r30,r3
	cr6.compare<int32_t>(r30.s32, ctx.r3.s32, xer);
	// beq cr6,0x820d8738
	if (cr6.getEQ()) goto loc_820D8738;
loc_820D871C:
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r4,1
	ctx.r4.s64 = 1;
	// addi r3,r30,384
	ctx.r3.s64 = r30.s64 + 384;
	// bl 0x820a28a8
	sub_820A28A8(ctx, base);
	// addi r3,r30,428
	ctx.r3.s64 = r30.s64 + 428;
loc_820D8730:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x820a28a8
	sub_820A28A8(ctx, base);
loc_820D8738:
	// lwz r31,40(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x820d86c4
	if (!cr6.getEQ()) goto loc_820D86C4;
loc_820D8744:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D8760"))) PPC_WEAK_FUNC(sub_820D8760);
PPC_FUNC_IMPL(__imp__sub_820D8760) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// cmplwi cr6,r4,51
	cr6.compare<uint32_t>(ctx.r4.u32, 51, xer);
	// addi r11,r11,19432
	r11.s64 = r11.s64 + 19432;
	// bgt cr6,0x820d8d10
	if (cr6.getGT()) goto loc_820D8D10;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-30840
	r12.s64 = r12.s64 + -30840;
	// rlwinm r0,r4,2,0,29
	r0.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r4.u64) {
	case 0:
		goto loc_820D8D10;
	case 1:
		goto loc_820D8858;
	case 2:
		goto loc_820D8870;
	case 3:
		goto loc_820D8888;
	case 4:
		goto loc_820D88A0;
	case 5:
		goto loc_820D88B8;
	case 6:
		goto loc_820D88D0;
	case 7:
		goto loc_820D88E8;
	case 8:
		goto loc_820D8900;
	case 9:
		goto loc_820D8918;
	case 10:
		goto loc_820D8930;
	case 11:
		goto loc_820D8948;
	case 12:
		goto loc_820D8960;
	case 13:
		goto loc_820D8978;
	case 14:
		goto loc_820D8990;
	case 15:
		goto loc_820D89A8;
	case 16:
		goto loc_820D89C0;
	case 17:
		goto loc_820D89D8;
	case 18:
		goto loc_820D89F0;
	case 19:
		goto loc_820D8A08;
	case 20:
		goto loc_820D8A20;
	case 21:
		goto loc_820D8A38;
	case 22:
		goto loc_820D8A50;
	case 23:
		goto loc_820D8A68;
	case 24:
		goto loc_820D8A80;
	case 25:
		goto loc_820D8A98;
	case 26:
		goto loc_820D8AB0;
	case 27:
		goto loc_820D8AC8;
	case 28:
		goto loc_820D8AE0;
	case 29:
		goto loc_820D8AF8;
	case 30:
		goto loc_820D8B10;
	case 31:
		goto loc_820D8B28;
	case 32:
		goto loc_820D8B40;
	case 33:
		goto loc_820D8B58;
	case 34:
		goto loc_820D8B70;
	case 35:
		goto loc_820D8B88;
	case 36:
		goto loc_820D8BA0;
	case 37:
		goto loc_820D8BB8;
	case 38:
		goto loc_820D8BD0;
	case 39:
		goto loc_820D8BE8;
	case 40:
		goto loc_820D8C00;
	case 41:
		goto loc_820D8C18;
	case 42:
		goto loc_820D8C30;
	case 43:
		goto loc_820D8C48;
	case 44:
		goto loc_820D8C60;
	case 45:
		goto loc_820D8C78;
	case 46:
		goto loc_820D8C90;
	case 47:
		goto loc_820D8CA8;
	case 48:
		goto loc_820D8CC0;
	case 49:
		goto loc_820D8CD8;
	case 50:
		goto loc_820D8CF0;
	case 51:
		goto loc_820D8D08;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-29424(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29424);
	// lwz r16,-30632(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30632);
	// lwz r16,-30608(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30608);
	// lwz r16,-30584(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30584);
	// lwz r16,-30560(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30560);
	// lwz r16,-30536(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30536);
	// lwz r16,-30512(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30512);
	// lwz r16,-30488(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30488);
	// lwz r16,-30464(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30464);
	// lwz r16,-30440(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30440);
	// lwz r16,-30416(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30416);
	// lwz r16,-30392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30392);
	// lwz r16,-30368(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30368);
	// lwz r16,-30344(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30344);
	// lwz r16,-30320(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30320);
	// lwz r16,-30296(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30296);
	// lwz r16,-30272(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30272);
	// lwz r16,-30248(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30248);
	// lwz r16,-30224(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30224);
	// lwz r16,-30200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30200);
	// lwz r16,-30176(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30176);
	// lwz r16,-30152(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30152);
	// lwz r16,-30128(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30128);
	// lwz r16,-30104(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30104);
	// lwz r16,-30080(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30080);
	// lwz r16,-30056(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30056);
	// lwz r16,-30032(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30032);
	// lwz r16,-30008(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -30008);
	// lwz r16,-29984(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29984);
	// lwz r16,-29960(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29960);
	// lwz r16,-29936(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29936);
	// lwz r16,-29912(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29912);
	// lwz r16,-29888(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29888);
	// lwz r16,-29864(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29864);
	// lwz r16,-29840(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29840);
	// lwz r16,-29816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29816);
	// lwz r16,-29792(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29792);
	// lwz r16,-29768(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29768);
	// lwz r16,-29744(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29744);
	// lwz r16,-29720(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29720);
	// lwz r16,-29696(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29696);
	// lwz r16,-29672(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29672);
	// lwz r16,-29648(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29648);
	// lwz r16,-29624(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29624);
	// lwz r16,-29600(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29600);
	// lwz r16,-29576(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29576);
	// lwz r16,-29552(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29552);
	// lwz r16,-29528(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29528);
	// lwz r16,-29504(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29504);
	// lwz r16,-29480(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29480);
	// lwz r16,-29456(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29456);
	// lwz r16,-29432(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29432);
loc_820D8858:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,19616
	r11.s64 = r11.s64 + 19616;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8870:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,20208
	r11.s64 = r11.s64 + 20208;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8888:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,20560
	r11.s64 = r11.s64 + 20560;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D88A0:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,20816
	r11.s64 = r11.s64 + 20816;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D88B8:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,20928
	r11.s64 = r11.s64 + 20928;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D88D0:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,21080
	r11.s64 = r11.s64 + 21080;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D88E8:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,21264
	r11.s64 = r11.s64 + 21264;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8900:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,19572
	r11.s64 = r11.s64 + 19572;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8918:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,20164
	r11.s64 = r11.s64 + 20164;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8930:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,20372
	r11.s64 = r11.s64 + 20372;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8948:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,21052
	r11.s64 = r11.s64 + 21052;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8960:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,21408
	r11.s64 = r11.s64 + 21408;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8978:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,21792
	r11.s64 = r11.s64 + 21792;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8990:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,21896
	r11.s64 = r11.s64 + 21896;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D89A8:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,20416
	r11.s64 = r11.s64 + 20416;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D89C0:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,21488
	r11.s64 = r11.s64 + 21488;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D89D8:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,22040
	r11.s64 = r11.s64 + 22040;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D89F0:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,22136
	r11.s64 = r11.s64 + 22136;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8A08:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,22800
	r11.s64 = r11.s64 + 22800;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8A20:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,22880
	r11.s64 = r11.s64 + 22880;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8A38:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,22912
	r11.s64 = r11.s64 + 22912;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8A50:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23908
	r11.s64 = r11.s64 + 23908;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8A68:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23960
	r11.s64 = r11.s64 + 23960;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8A80:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23628
	r11.s64 = r11.s64 + 23628;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8A98:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23656
	r11.s64 = r11.s64 + 23656;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8AB0:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23684
	r11.s64 = r11.s64 + 23684;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8AC8:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23712
	r11.s64 = r11.s64 + 23712;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8AE0:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23740
	r11.s64 = r11.s64 + 23740;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8AF8:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23768
	r11.s64 = r11.s64 + 23768;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8B10:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23796
	r11.s64 = r11.s64 + 23796;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8B28:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23824
	r11.s64 = r11.s64 + 23824;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8B40:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23852
	r11.s64 = r11.s64 + 23852;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8B58:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23880
	r11.s64 = r11.s64 + 23880;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8B70:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23572
	r11.s64 = r11.s64 + 23572;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8B88:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23012
	r11.s64 = r11.s64 + 23012;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8BA0:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23532
	r11.s64 = r11.s64 + 23532;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8BB8:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23552
	r11.s64 = r11.s64 + 23552;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8BD0:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23448
	r11.s64 = r11.s64 + 23448;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8BE8:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,21236
	r11.s64 = r11.s64 + 21236;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8C00:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,22012
	r11.s64 = r11.s64 + 22012;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8C18:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,22772
	r11.s64 = r11.s64 + 22772;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8C30:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23152
	r11.s64 = r11.s64 + 23152;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8C48:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23272
	r11.s64 = r11.s64 + 23272;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8C60:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23112
	r11.s64 = r11.s64 + 23112;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8C78:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,23032
	r11.s64 = r11.s64 + 23032;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8C90:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,24096
	r11.s64 = r11.s64 + 24096;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8CA8:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,24176
	r11.s64 = r11.s64 + 24176;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8CC0:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,24252
	r11.s64 = r11.s64 + 24252;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8CD8:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,24308
	r11.s64 = r11.s64 + 24308;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8CF0:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,24364
	r11.s64 = r11.s64 + 24364;
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_820D8D08:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,24420
	r11.s64 = r11.s64 + 24420;
loc_820D8D10:
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// sth r10,4(r3)
	PPC_STORE_U16(ctx.r3.u32 + 4, ctx.r10.u16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D8D20"))) PPC_WEAK_FUNC(sub_820D8D20);
PPC_FUNC_IMPL(__imp__sub_820D8D20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed124
	// addi r12,r1,-80
	r12.s64 = ctx.r1.s64 + -80;
	// bl 0x823ed53c
	// stwu r1,-560(r1)
	ea = -560 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r24,r6
	r24.u64 = ctx.r6.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x820d96c4
	if (cr6.getEQ()) goto loc_820D96C4;
	// lbz r11,1(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 1);
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// bne cr6,0x820d96c4
	if (!cr6.getEQ()) goto loc_820D96C4;
	// lis r7,-32256
	ctx.r7.s64 = -2113929216;
	// lwz r26,4(r4)
	r26.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f29,6588(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 6588);
	f29.f64 = double(temp.f32);
	// lis r27,-32014
	r27.s64 = -2098069504;
	// lfs f28,16716(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 16716);
	f28.f64 = double(temp.f32);
	// lis r28,-32014
	r28.s64 = -2098069504;
	// lfs f30,17732(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 17732);
	f30.f64 = double(temp.f32);
	// li r25,0
	r25.s64 = 0;
	// lfs f31,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	f31.f64 = double(temp.f32);
	// lfs f26,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f26.f64 = double(temp.f32);
loc_820D8D8C:
	// lhz r11,4(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 4);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rotlwi r10,r11,2
	ctx.r10.u64 = __builtin_rotateleft32(r11.u32, 2);
	// add r30,r10,r9
	r30.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r10,15
	cr6.compare<uint32_t>(ctx.r10.u32, 15, xer);
	// bgt cr6,0x820d8d8c
	if (cr6.getGT()) goto loc_820D8D8C;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-29248
	r12.s64 = r12.s64 + -29248;
	// rlwinm r0,r10,2,0,29
	r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_820D8E00;
	case 1:
		goto loc_820D8E14;
	case 2:
		goto loc_820D8E68;
	case 3:
		goto loc_820D8EBC;
	case 4:
		goto loc_820D8F10;
	case 5:
		goto loc_820D8F64;
	case 6:
		goto loc_820D8FB8;
	case 7:
		goto loc_820D900C;
	case 8:
		goto loc_820D9020;
	case 9:
		goto loc_820D9078;
	case 10:
		goto loc_820D9054;
	case 11:
		goto loc_820D9080;
	case 12:
		goto loc_820D9194;
	case 13:
		goto loc_820D9098;
	case 14:
		goto loc_820D9104;
	case 15:
		goto loc_820D9130;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-29184(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29184);
	// lwz r16,-29164(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29164);
	// lwz r16,-29080(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -29080);
	// lwz r16,-28996(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -28996);
	// lwz r16,-28912(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -28912);
	// lwz r16,-28828(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -28828);
	// lwz r16,-28744(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -28744);
	// lwz r16,-28660(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -28660);
	// lwz r16,-28640(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -28640);
	// lwz r16,-28552(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -28552);
	// lwz r16,-28588(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -28588);
	// lwz r16,-28544(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -28544);
	// lwz r16,-28268(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -28268);
	// lwz r16,-28520(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -28520);
	// lwz r16,-28412(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -28412);
	// lwz r16,-28368(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -28368);
loc_820D8E00:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stfs f26,64(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r31.u32 + 64, temp.u32);
	// stfs f26,84(r31)
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r31.u32 + 84, temp.u32);
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// b 0x820d8d8c
	goto loc_820D8D8C;
loc_820D8E14:
	// stfs f26,60(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r31.u32 + 60, temp.u32);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// lfs f0,56(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 56);
	f0.f64 = double(temp.f32);
	// stfs f0,68(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 68, temp.u32);
	// std r10,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, ctx.r10.u64);
	// lfd f13,176(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fdivs f13,f31,f13
	ctx.f13.f64 = double(float(f31.f64 / ctx.f13.f64));
	// stfs f13,64(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 64, temp.u32);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// extsw r11,r10
	r11.s64 = ctx.r10.s32;
	// std r11,352(r1)
	PPC_STORE_U64(ctx.r1.u32 + 352, r11.u64);
	// lfd f13,352(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 352);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmadds f0,f13,f30,f0
	f0.f64 = double(float(ctx.f13.f64 * f30.f64 + f0.f64));
	// stfs f0,72(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 72, temp.u32);
	// b 0x820d8d8c
	goto loc_820D8D8C;
loc_820D8E68:
	// stfs f26,80(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r31.u32 + 80, temp.u32);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// lfs f0,76(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 76);
	f0.f64 = double(temp.f32);
	// stfs f0,88(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 88, temp.u32);
	// std r10,344(r1)
	PPC_STORE_U64(ctx.r1.u32 + 344, ctx.r10.u64);
	// lfd f13,344(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 344);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fdivs f13,f31,f13
	ctx.f13.f64 = double(float(f31.f64 / ctx.f13.f64));
	// stfs f13,84(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 84, temp.u32);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// extsw r11,r10
	r11.s64 = ctx.r10.s32;
	// std r11,360(r1)
	PPC_STORE_U64(ctx.r1.u32 + 360, r11.u64);
	// lfd f13,360(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 360);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmadds f0,f13,f30,f0
	f0.f64 = double(float(ctx.f13.f64 * f30.f64 + f0.f64));
	// stfs f0,92(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 92, temp.u32);
	// b 0x820d8d8c
	goto loc_820D8D8C;
loc_820D8EBC:
	// stfs f26,60(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r31.u32 + 60, temp.u32);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lfs f0,56(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 56);
	f0.f64 = double(temp.f32);
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// stfs f0,68(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 68, temp.u32);
	// std r10,376(r1)
	PPC_STORE_U64(ctx.r1.u32 + 376, ctx.r10.u64);
	// lfd f0,376(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 376);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fdivs f0,f31,f0
	f0.f64 = double(float(f31.f64 / f0.f64));
	// stfs f0,64(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 64, temp.u32);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// extsw r11,r10
	r11.s64 = ctx.r10.s32;
	// std r11,392(r1)
	PPC_STORE_U64(ctx.r1.u32 + 392, r11.u64);
	// lfd f0,392(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 392);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// stfs f0,72(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 72, temp.u32);
	// b 0x820d8d8c
	goto loc_820D8D8C;
loc_820D8F10:
	// stfs f26,80(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r31.u32 + 80, temp.u32);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lfs f0,76(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 76);
	f0.f64 = double(temp.f32);
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// stfs f0,88(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 88, temp.u32);
	// std r10,408(r1)
	PPC_STORE_U64(ctx.r1.u32 + 408, ctx.r10.u64);
	// lfd f0,408(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 408);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fdivs f0,f31,f0
	f0.f64 = double(float(f31.f64 / f0.f64));
	// stfs f0,84(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 84, temp.u32);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// extsw r11,r10
	r11.s64 = ctx.r10.s32;
	// std r11,336(r1)
	PPC_STORE_U64(ctx.r1.u32 + 336, r11.u64);
	// lfd f0,336(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 336);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// stfs f0,92(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 92, temp.u32);
	// b 0x820d8d8c
	goto loc_820D8D8C;
loc_820D8F64:
	// stfs f26,20(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lfs f0,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	f0.f64 = double(temp.f32);
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// stfs f0,28(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 28, temp.u32);
	// std r10,384(r1)
	PPC_STORE_U64(ctx.r1.u32 + 384, ctx.r10.u64);
	// lfd f0,384(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 384);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fdivs f0,f31,f0
	f0.f64 = double(float(f31.f64 / f0.f64));
	// stfs f0,24(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 24, temp.u32);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// extsw r11,r10
	r11.s64 = ctx.r10.s32;
	// std r11,368(r1)
	PPC_STORE_U64(ctx.r1.u32 + 368, r11.u64);
	// lfd f0,368(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 368);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// stfs f0,32(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 32, temp.u32);
	// b 0x820d8d8c
	goto loc_820D8D8C;
loc_820D8FB8:
	// stfs f26,40(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r31.u32 + 40, temp.u32);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lfs f0,36(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 36);
	f0.f64 = double(temp.f32);
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// stfs f0,48(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 48, temp.u32);
	// std r10,400(r1)
	PPC_STORE_U64(ctx.r1.u32 + 400, ctx.r10.u64);
	// lfd f0,400(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 400);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fdivs f0,f31,f0
	f0.f64 = double(float(f31.f64 / f0.f64));
	// stfs f0,44(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 44, temp.u32);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// extsw r11,r10
	r11.s64 = ctx.r10.s32;
	// std r11,184(r1)
	PPC_STORE_U64(ctx.r1.u32 + 184, r11.u64);
	// lfd f0,184(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 184);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// stfs f0,52(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 52, temp.u32);
	// b 0x820d8d8c
	goto loc_820D8D8C;
loc_820D900C:
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r10,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r10.u32);
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// b 0x820d8d8c
	goto loc_820D8D8C;
loc_820D9020:
	// lhz r10,6(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 6);
	// extsh r9,r10
	ctx.r9.s64 = ctx.r10.s16;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// blt cr6,0x820d918c
	if (cr6.getLT()) goto loc_820D918C;
	// lwz r10,-6384(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + -6384);
	// subf r10,r10,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r10.s64;
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// sth r10,6(r31)
	PPC_STORE_U16(r31.u32 + 6, ctx.r10.u16);
	// bge cr6,0x820d9194
	if (!cr6.getLT()) goto loc_820D9194;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// b 0x820d8d8c
	goto loc_820D8D8C;
loc_820D9054:
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// rlwinm r11,r11,16,16,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x820d9088
	if (!cr6.getLT()) goto loc_820D9088;
loc_820D9078:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_820D9080:
	// sth r25,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r25.u16);
	// b 0x820d8d8c
	goto loc_820D8D8C;
loc_820D9088:
	// lhz r11,4(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 4);
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// b 0x820d8d8c
	goto loc_820D8D8C;
loc_820D9098:
	// stfs f26,108(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r31.u32 + 108, temp.u32);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lbz r9,96(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 96);
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// lbz r8,99(r31)
	ctx.r8.u64 = PPC_LOAD_U8(r31.u32 + 99);
	// lbz r7,102(r31)
	ctx.r7.u64 = PPC_LOAD_U8(r31.u32 + 102);
	// lbz r6,105(r31)
	ctx.r6.u64 = PPC_LOAD_U8(r31.u32 + 105);
	// std r10,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, ctx.r10.u64);
	// stb r9,97(r31)
	PPC_STORE_U8(r31.u32 + 97, ctx.r9.u8);
	// lfd f0,192(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fdivs f0,f31,f0
	f0.f64 = double(float(f31.f64 / f0.f64));
	// stfs f0,112(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 112, temp.u32);
	// lbz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U8(r30.u32 + 4);
	// stb r8,100(r31)
	PPC_STORE_U8(r31.u32 + 100, ctx.r8.u8);
	// stb r10,98(r31)
	PPC_STORE_U8(r31.u32 + 98, ctx.r10.u8);
	// lbz r10,5(r30)
	ctx.r10.u64 = PPC_LOAD_U8(r30.u32 + 5);
	// stb r7,103(r31)
	PPC_STORE_U8(r31.u32 + 103, ctx.r7.u8);
	// stb r10,101(r31)
	PPC_STORE_U8(r31.u32 + 101, ctx.r10.u8);
	// lbz r10,6(r30)
	ctx.r10.u64 = PPC_LOAD_U8(r30.u32 + 6);
	// stb r6,106(r31)
	PPC_STORE_U8(r31.u32 + 106, ctx.r6.u8);
	// stb r10,104(r31)
	PPC_STORE_U8(r31.u32 + 104, ctx.r10.u8);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// stb r10,107(r31)
	PPC_STORE_U8(r31.u32 + 107, ctx.r10.u8);
	// b 0x820d8d8c
	goto loc_820D8D8C;
loc_820D9104:
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// std r10,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, ctx.r10.u64);
	// lfd f0,200(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 200);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,12(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
	// b 0x820d8d8c
	goto loc_820D8D8C;
loc_820D9130:
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lfs f13,12(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r10,208(r1)
	PPC_STORE_U64(ctx.r1.u32 + 208, ctx.r10.u64);
	// lfd f0,208(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 208);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f12,f0
	ctx.f12.f64 = double(float(f0.f64));
	// lfs f0,-6380(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + -6380);
	f0.f64 = double(temp.f32);
	// fmuls f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * f0.f64));
	// fmadds f0,f0,f28,f13
	f0.f64 = double(float(f0.f64 * f28.f64 + ctx.f13.f64));
	// stfs f0,12(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
	// fcmpu cr6,f0,f29
	cr6.compare(f0.f64, f29.f64);
	// blt cr6,0x820d916c
	if (cr6.getLT()) goto loc_820D916C;
	// fsubs f0,f0,f29
	f0.f64 = double(float(f0.f64 - f29.f64));
	// stfs f0,12(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
loc_820D916C:
	// lfs f0,12(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f26
	cr6.compare(f0.f64, f26.f64);
	// bge cr6,0x820d9180
	if (!cr6.getLT()) goto loc_820D9180;
	// fadds f0,f0,f29
	f0.f64 = double(float(f0.f64 + f29.f64));
	// stfs f0,12(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
loc_820D9180:
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// sth r11,4(r31)
	PPC_STORE_U16(r31.u32 + 4, r11.u16);
	// b 0x820d8d8c
	goto loc_820D8D8C;
loc_820D918C:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// sth r11,6(r31)
	PPC_STORE_U16(r31.u32 + 6, r11.u16);
loc_820D9194:
	// lfs f13,24(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 24);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f26
	cr6.compare(ctx.f13.f64, f26.f64);
	// ble cr6,0x820d91dc
	if (!cr6.getGT()) goto loc_820D91DC;
	// lfs f0,-6380(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + -6380);
	f0.f64 = double(temp.f32);
	// lfs f12,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f0,f13,f0,f12
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f0,20(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bge cr6,0x820d91cc
	if (!cr6.getLT()) goto loc_820D91CC;
	// lfs f13,28(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,32(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// fmadds f0,f12,f0,f13
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// b 0x820d91d8
	goto loc_820D91D8;
loc_820D91CC:
	// lfs f0,32(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	f0.f64 = double(temp.f32);
	// stfs f31,20(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// stfs f26,24(r31)
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r31.u32 + 24, temp.u32);
loc_820D91D8:
	// stfs f0,16(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 16, temp.u32);
loc_820D91DC:
	// lfs f13,44(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 44);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f26
	cr6.compare(ctx.f13.f64, f26.f64);
	// ble cr6,0x820d9224
	if (!cr6.getGT()) goto loc_820D9224;
	// lfs f0,-6380(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + -6380);
	f0.f64 = double(temp.f32);
	// lfs f12,40(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 40);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f0,f13,f0,f12
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f0,40(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 40, temp.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bge cr6,0x820d9214
	if (!cr6.getLT()) goto loc_820D9214;
	// lfs f13,48(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,52(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 52);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// fmadds f0,f12,f0,f13
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// b 0x820d9220
	goto loc_820D9220;
loc_820D9214:
	// lfs f0,52(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 52);
	f0.f64 = double(temp.f32);
	// stfs f31,40(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 40, temp.u32);
	// stfs f26,44(r31)
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r31.u32 + 44, temp.u32);
loc_820D9220:
	// stfs f0,36(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 36, temp.u32);
loc_820D9224:
	// lfs f13,64(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 64);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f26
	cr6.compare(ctx.f13.f64, f26.f64);
	// ble cr6,0x820d926c
	if (!cr6.getGT()) goto loc_820D926C;
	// lfs f0,-6380(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + -6380);
	f0.f64 = double(temp.f32);
	// lfs f12,60(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 60);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f0,f13,f0,f12
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f0,60(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 60, temp.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bge cr6,0x820d925c
	if (!cr6.getLT()) goto loc_820D925C;
	// lfs f13,68(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 68);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,72(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 72);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// fmadds f0,f12,f0,f13
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// b 0x820d9268
	goto loc_820D9268;
loc_820D925C:
	// lfs f0,72(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 72);
	f0.f64 = double(temp.f32);
	// stfs f31,60(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 60, temp.u32);
	// stfs f26,64(r31)
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r31.u32 + 64, temp.u32);
loc_820D9268:
	// stfs f0,56(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 56, temp.u32);
loc_820D926C:
	// lfs f13,84(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 84);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f26
	cr6.compare(ctx.f13.f64, f26.f64);
	// ble cr6,0x820d92b4
	if (!cr6.getGT()) goto loc_820D92B4;
	// lfs f0,-6380(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + -6380);
	f0.f64 = double(temp.f32);
	// lfs f12,80(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 80);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f0,f13,f0,f12
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f0,80(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 80, temp.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bge cr6,0x820d92a4
	if (!cr6.getLT()) goto loc_820D92A4;
	// lfs f13,88(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,92(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// fmadds f0,f12,f0,f13
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// b 0x820d92b0
	goto loc_820D92B0;
loc_820D92A4:
	// lfs f0,92(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	f0.f64 = double(temp.f32);
	// stfs f31,80(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 80, temp.u32);
	// stfs f26,84(r31)
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r31.u32 + 84, temp.u32);
loc_820D92B0:
	// stfs f0,76(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 76, temp.u32);
loc_820D92B4:
	// lfs f13,112(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f26
	cr6.compare(ctx.f13.f64, f26.f64);
	// ble cr6,0x820d9400
	if (!cr6.getGT()) goto loc_820D9400;
	// lfs f0,-6380(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + -6380);
	f0.f64 = double(temp.f32);
	// lfs f12,108(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 108);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f0,f13,f0,f12
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f0,108(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 108, temp.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bge cr6,0x820d93d8
	if (!cr6.getLT()) goto loc_820D93D8;
	// lbz r11,97(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 97);
	// fmr f13,f0
	ctx.f13.f64 = f0.f64;
	// lbz r7,98(r31)
	ctx.r7.u64 = PPC_LOAD_U8(r31.u32 + 98);
	// fmr f12,f0
	ctx.f12.f64 = f0.f64;
	// lbz r10,100(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 100);
	// fmr f11,f0
	ctx.f11.f64 = f0.f64;
	// subf r7,r11,r7
	ctx.r7.s64 = ctx.r7.s64 - r11.s64;
	// lbz r5,101(r31)
	ctx.r5.u64 = PPC_LOAD_U8(r31.u32 + 101);
	// addi r6,r1,176
	ctx.r6.s64 = ctx.r1.s64 + 176;
	// lbz r9,103(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 103);
	// extsw r7,r7
	ctx.r7.s64 = ctx.r7.s32;
	// lbz r4,104(r31)
	ctx.r4.u64 = PPC_LOAD_U8(r31.u32 + 104);
	// subf r5,r10,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r10.s64;
	// lbz r8,106(r31)
	ctx.r8.u64 = PPC_LOAD_U8(r31.u32 + 106);
	// subf r4,r9,r4
	ctx.r4.s64 = ctx.r4.s64 - ctx.r9.s64;
	// lbz r3,107(r31)
	ctx.r3.u64 = PPC_LOAD_U8(r31.u32 + 107);
	// extsw r5,r5
	ctx.r5.s64 = ctx.r5.s32;
	// extsw r4,r4
	ctx.r4.s64 = ctx.r4.s32;
	// std r7,208(r1)
	PPC_STORE_U64(ctx.r1.u32 + 208, ctx.r7.u64);
	// subf r7,r8,r3
	ctx.r7.s64 = ctx.r3.s64 - ctx.r8.s64;
	// extsw r7,r7
	ctx.r7.s64 = ctx.r7.s32;
	// std r5,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, ctx.r5.u64);
	// std r4,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, ctx.r4.u64);
	// std r7,184(r1)
	PPC_STORE_U64(ctx.r1.u32 + 184, ctx.r7.u64);
	// lfd f10,208(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 208);
	// fcfid f10,f10
	ctx.f10.f64 = double(ctx.f10.s64);
	// lfd f9,200(r1)
	ctx.f9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 200);
	// fcfid f9,f9
	ctx.f9.f64 = double(ctx.f9.s64);
	// lfd f8,192(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fcfid f8,f8
	ctx.f8.f64 = double(ctx.f8.s64);
	// lfd f7,184(r1)
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r1.u32 + 184);
	// fcfid f7,f7
	ctx.f7.f64 = double(ctx.f7.s64);
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// frsp f9,f9
	ctx.f9.f64 = double(float(ctx.f9.f64));
	// frsp f8,f8
	ctx.f8.f64 = double(float(ctx.f8.f64));
	// frsp f7,f7
	ctx.f7.f64 = double(float(ctx.f7.f64));
	// fmuls f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fmuls f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// fmuls f12,f8,f12
	ctx.f12.f64 = double(float(ctx.f8.f64 * ctx.f12.f64));
	// fmuls f11,f7,f11
	ctx.f11.f64 = double(float(ctx.f7.f64 * ctx.f11.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r6
	PPC_STORE_U32(ctx.r6.u32, f0.u32);
	// fctiwz f0,f13
	f0.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f13.f64));
	// fctiwz f13,f12
	ctx.f13.s64 = (ctx.f12.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f12.f64));
	// fctiwz f12,f11
	ctx.f12.s64 = (ctx.f11.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f11.f64));
	// lwz r7,176(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// addi r6,r1,176
	ctx.r6.s64 = ctx.r1.s64 + 176;
	// add r11,r7,r11
	r11.u64 = ctx.r7.u64 + r11.u64;
	// stfiwx f0,0,r6
	PPC_STORE_U32(ctx.r6.u32, f0.u32);
	// stb r11,96(r31)
	PPC_STORE_U8(r31.u32 + 96, r11.u8);
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// addi r7,r1,176
	ctx.r7.s64 = ctx.r1.s64 + 176;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stfiwx f13,0,r7
	PPC_STORE_U32(ctx.r7.u32, ctx.f13.u32);
	// stb r11,99(r31)
	PPC_STORE_U8(r31.u32 + 99, r11.u8);
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// stfiwx f12,0,r10
	PPC_STORE_U32(ctx.r10.u32, ctx.f12.u32);
	// stb r11,102(r31)
	PPC_STORE_U8(r31.u32 + 102, r11.u8);
	// lwz r11,176(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// add r11,r11,r8
	r11.u64 = r11.u64 + ctx.r8.u64;
	// stb r11,105(r31)
	PPC_STORE_U8(r31.u32 + 105, r11.u8);
	// b 0x820d9400
	goto loc_820D9400;
loc_820D93D8:
	// lbz r11,98(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 98);
	// stfs f31,108(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 108, temp.u32);
	// lbz r10,101(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 101);
	// stfs f26,112(r31)
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r31.u32 + 112, temp.u32);
	// lbz r9,104(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 104);
	// lbz r8,107(r31)
	ctx.r8.u64 = PPC_LOAD_U8(r31.u32 + 107);
	// stb r11,96(r31)
	PPC_STORE_U8(r31.u32 + 96, r11.u8);
	// stb r10,99(r31)
	PPC_STORE_U8(r31.u32 + 99, ctx.r10.u8);
	// stb r9,102(r31)
	PPC_STORE_U8(r31.u32 + 102, ctx.r9.u8);
	// stb r8,105(r31)
	PPC_STORE_U8(r31.u32 + 105, ctx.r8.u8);
loc_820D9400:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// addi r10,r1,224
	ctx.r10.s64 = ctx.r1.s64 + 224;
	// li r9,7
	ctx.r9.s64 = 7;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_820D9410:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x820d9410
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820D9410;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// addi r10,r1,252
	ctx.r10.s64 = ctx.r1.s64 + 252;
	// li r9,7
	ctx.r9.s64 = 7;
	// addi r11,r11,28
	r11.s64 = r11.s64 + 28;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_820D9438:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x820d9438
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820D9438;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// addi r10,r1,280
	ctx.r10.s64 = ctx.r1.s64 + 280;
	// li r9,7
	ctx.r9.s64 = 7;
	// addi r11,r11,56
	r11.s64 = r11.s64 + 56;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_820D9460:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x820d9460
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820D9460;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// addi r10,r1,308
	ctx.r10.s64 = ctx.r1.s64 + 308;
	// li r9,7
	ctx.r9.s64 = 7;
	// addi r11,r11,84
	r11.s64 = r11.s64 + 84;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_820D9488:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x820d9488
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820D9488;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,100
	cr6.compare<uint32_t>(r11.u32, 100, xer);
	// bge cr6,0x820d94bc
	if (!cr6.getLT()) goto loc_820D94BC;
	// lis r10,-31994
	ctx.r10.s64 = -2096758784;
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r10,r10,26616
	ctx.r10.s64 = ctx.r10.s64 + 26616;
	// add r30,r11,r10
	r30.u64 = r11.u64 + ctx.r10.u64;
	// b 0x820d94c0
	goto loc_820D94C0;
loc_820D94BC:
	// mr r30,r11
	r30.u64 = r11.u64;
loc_820D94C0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820d9584
	if (cr6.getEQ()) goto loc_820D9584;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,16(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,36(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 36);
	ctx.f12.f64 = double(temp.f32);
	// lfs f1,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fcmpu cr6,f1,f26
	cr6.compare(ctx.f1.f64, f26.f64);
	// lfs f0,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
	// fmuls f30,f13,f0
	f30.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fmuls f29,f12,f0
	f29.f64 = double(float(ctx.f12.f64 * f0.f64));
	// fmr f27,f30
	f27.f64 = f30.f64;
	// fmr f28,f29
	f28.f64 = f29.f64;
	// beq cr6,0x820d952c
	if (cr6.getEQ()) goto loc_820D952C;
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// frsp f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	f0.f64 = double(temp.f32);
	// fmr f1,f0
	ctx.f1.f64 = f0.f64;
	// lfs f26,14068(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14068);
	f26.f64 = double(temp.f32);
	// fmuls f25,f13,f26
	f25.f64 = double(float(ctx.f13.f64 * f26.f64));
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmuls f30,f25,f30
	f30.f64 = double(float(f25.f64 * f30.f64));
	// fmuls f28,f25,f28
	f28.f64 = double(float(f25.f64 * f28.f64));
	// fmuls f0,f0,f26
	f0.f64 = double(float(f0.f64 * f26.f64));
	// fmuls f29,f0,f29
	f29.f64 = double(float(f0.f64 * f29.f64));
	// fmuls f27,f0,f27
	f27.f64 = double(float(f0.f64 * f27.f64));
loc_820D952C:
	// lfs f0,76(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 76);
	f0.f64 = double(temp.f32);
	// fadds f12,f0,f29
	ctx.f12.f64 = double(float(f0.f64 + f29.f64));
	// lfs f13,56(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// fadds f11,f0,f28
	ctx.f11.f64 = double(float(f0.f64 + f28.f64));
	// fsubs f10,f0,f29
	ctx.f10.f64 = double(float(f0.f64 - f29.f64));
	// fadds f9,f13,f30
	ctx.f9.f64 = double(float(ctx.f13.f64 + f30.f64));
	// stfs f9,240(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// fsubs f0,f0,f28
	f0.f64 = double(float(f0.f64 - f28.f64));
	// fsubs f9,f13,f27
	ctx.f9.f64 = double(float(ctx.f13.f64 - f27.f64));
	// stfs f9,268(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 268, temp.u32);
	// fsubs f9,f13,f30
	ctx.f9.f64 = double(float(ctx.f13.f64 - f30.f64));
	// stfs f9,296(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// fadds f13,f13,f27
	ctx.f13.f64 = double(float(ctx.f13.f64 + f27.f64));
	// stfs f13,324(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// fsubs f13,f31,f12
	ctx.f13.f64 = double(float(f31.f64 - ctx.f12.f64));
	// stfs f13,244(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// fsubs f13,f31,f11
	ctx.f13.f64 = double(float(f31.f64 - ctx.f11.f64));
	// stfs f13,272(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// fsubs f13,f31,f10
	ctx.f13.f64 = double(float(f31.f64 - ctx.f10.f64));
	// stfs f13,300(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// fsubs f0,f31,f0
	f0.f64 = double(float(f31.f64 - f0.f64));
	// stfs f0,328(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
loc_820D9584:
	// lbz r11,96(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 96);
	// lbz r8,105(r31)
	ctx.r8.u64 = PPC_LOAD_U8(r31.u32 + 105);
	// lbz r10,99(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 99);
	// lbz r9,102(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 102);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// stb r11,332(r1)
	PPC_STORE_U8(ctx.r1.u32 + 332, r11.u8);
	// stb r11,304(r1)
	PPC_STORE_U8(ctx.r1.u32 + 304, r11.u8);
	// stb r11,276(r1)
	PPC_STORE_U8(ctx.r1.u32 + 276, r11.u8);
	// stb r11,248(r1)
	PPC_STORE_U8(ctx.r1.u32 + 248, r11.u8);
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
	// stb r10,333(r1)
	PPC_STORE_U8(ctx.r1.u32 + 333, ctx.r10.u8);
	// stb r9,334(r1)
	PPC_STORE_U8(ctx.r1.u32 + 334, ctx.r9.u8);
	// stb r10,305(r1)
	PPC_STORE_U8(ctx.r1.u32 + 305, ctx.r10.u8);
	// stb r10,277(r1)
	PPC_STORE_U8(ctx.r1.u32 + 277, ctx.r10.u8);
	// stb r10,249(r1)
	PPC_STORE_U8(ctx.r1.u32 + 249, ctx.r10.u8);
	// stb r9,306(r1)
	PPC_STORE_U8(ctx.r1.u32 + 306, ctx.r9.u8);
	// stb r9,278(r1)
	PPC_STORE_U8(ctx.r1.u32 + 278, ctx.r9.u8);
	// stb r9,250(r1)
	PPC_STORE_U8(ctx.r1.u32 + 250, ctx.r9.u8);
	// stb r11,335(r1)
	PPC_STORE_U8(ctx.r1.u32 + 335, r11.u8);
	// stb r11,307(r1)
	PPC_STORE_U8(ctx.r1.u32 + 307, r11.u8);
	// stb r11,279(r1)
	PPC_STORE_U8(ctx.r1.u32 + 279, r11.u8);
	// stb r11,251(r1)
	PPC_STORE_U8(ctx.r1.u32 + 251, r11.u8);
	// beq cr6,0x820d96c4
	if (cr6.getEQ()) goto loc_820D96C4;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lis r31,-31991
	r31.s64 = -2096562176;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,24672(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 24672);
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82194ca8
	sub_82194CA8(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82192f50
	sub_82192F50(ctx, base);
	// cmpwi cr6,r24,8
	cr6.compare<int32_t>(r24.s32, 8, xer);
	// bne cr6,0x820d962c
	if (!cr6.getEQ()) goto loc_820D962C;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// lwz r4,24668(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 24668);
	// bl 0x82193b40
	sub_82193B40(ctx, base);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// lwz r4,24664(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 24664);
	// bl 0x82193a78
	sub_82193A78(ctx, base);
loc_820D962C:
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820979e8
	sub_820979E8(ctx, base);
	// addi r29,r1,224
	r29.s64 = ctx.r1.s64 + 224;
	// bl 0x8210d7d0
	sub_8210D7D0(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r30,12(r23)
	r30.u64 = PPC_LOAD_U32(r23.u32 + 12);
	// bl 0x821463f0
	sub_821463F0(ctx, base);
	// li r10,3
	ctx.r10.s64 = 3;
	// li r11,2
	r11.s64 = 2;
	// stw r25,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r25.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r25,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r25.u32);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// stw r25,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r25.u32);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// stw r25,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r25.u32);
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// li r11,4
	r11.s64 = 4;
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r25,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r25.u32);
	// li r8,1
	ctx.r8.s64 = 1;
	// stw r25,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r25.u32);
	// li r9,2
	ctx.r9.s64 = 2;
	// stw r25,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r25.u32);
	// stw r10,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, ctx.r10.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r11.u32);
	// bl 0x82098e58
	sub_82098E58(ctx, base);
	// bl 0x82097a90
	sub_82097A90(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82193b40
	sub_82193B40(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82193a78
	sub_82193A78(ctx, base);
loc_820D96C4:
	// addi r1,r1,560
	ctx.r1.s64 = ctx.r1.s64 + 560;
	// addi r12,r1,-80
	r12.s64 = ctx.r1.s64 + -80;
	// bl 0x823ed588
	// b 0x823ed174
	return;
}

__attribute__((alias("__imp__sub_820D96D8"))) PPC_WEAK_FUNC(sub_820D96D8);
PPC_FUNC_IMPL(__imp__sub_820D96D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x820d976c
	if (!cr6.getEQ()) goto loc_820D976C;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r9,r1,-12
	ctx.r9.s64 = ctx.r1.s64 + -12;
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// lfs f0,112(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 112);
	f0.f64 = double(temp.f32);
	// rlwinm r10,r10,0,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820d9718
	if (!cr6.getEQ()) goto loc_820D9718;
	// lfs f12,116(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 116);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,3908(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3908);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 * ctx.f13.f64));
	// fdivs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 / ctx.f12.f64));
	// b 0x820d9724
	goto loc_820D9724;
loc_820D9718:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,12468(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12468);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 + ctx.f13.f64));
loc_820D9724:
	// fctiwz f13,f13
	ctx.fpscr.disableFlushMode();
	ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f13.f64));
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// stfiwx f13,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f13.u32);
	// bne cr6,0x820d973c
	if (!cr6.getEQ()) goto loc_820D973C;
	// li r11,0
	r11.s64 = 0;
	// b 0x820d9754
	goto loc_820D9754;
loc_820D973C:
	// addi r11,r1,-16
	r11.s64 = ctx.r1.s64 + -16;
	// fctiwz f0,f0
	ctx.fpscr.disableFlushMode();
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,-16(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// srawi r11,r11,2
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x3) != 0);
	r11.s64 = r11.s32 >> 2;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_820D9754:
	// lwz r10,-12(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -12);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = r11.u64 ^ 1;
	// blr 
	return;
loc_820D976C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D9778"))) PPC_WEAK_FUNC(sub_820D9778);
PPC_FUNC_IMPL(__imp__sub_820D9778) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed11c
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r23,r4
	r23.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// mr r24,r7
	r24.u64 = ctx.r7.u64;
	// lbz r11,1(r27)
	r11.u64 = PPC_LOAD_U8(r27.u32 + 1);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d9e9c
	if (cr6.getEQ()) goto loc_820D9E9C;
	// lwz r30,8(r27)
	r30.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r26,20(r30)
	r26.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d97d0
	if (cr6.getEQ()) goto loc_820D97D0;
	// bl 0x8210d7f0
	sub_8210D7F0(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// li r22,1
	r22.s64 = 1;
	// bne cr6,0x820d97d4
	if (!cr6.getEQ()) goto loc_820D97D4;
loc_820D97D0:
	// li r22,0
	r22.s64 = 0;
loc_820D97D4:
	// lis r11,-32015
	r11.s64 = -2098135040;
	// lbz r11,-13408(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + -13408);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820d9bdc
	if (!cr6.getEQ()) goto loc_820D9BDC;
	// lbz r9,0(r27)
	ctx.r9.u64 = PPC_LOAD_U8(r27.u32 + 0);
	// cmplwi cr6,r9,2
	cr6.compare<uint32_t>(ctx.r9.u32, 2, xer);
	// bne cr6,0x820d9944
	if (!cr6.getEQ()) goto loc_820D9944;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lbz r11,572(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 572);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d9e9c
	if (cr6.getEQ()) goto loc_820D9E9C;
	// lwz r29,8(r27)
	r29.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lhz r11,152(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 152);
	// rlwinm r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d9818
	if (cr6.getEQ()) goto loc_820D9818;
	// ori r24,r24,1
	r24.u64 = r24.u64 | 1;
loc_820D9818:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lbz r11,577(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 577);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d9918
	if (cr6.getEQ()) goto loc_820D9918;
	// lhz r11,152(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 152);
	// rlwinm r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d9918
	if (cr6.getEQ()) goto loc_820D9918;
	// lis r31,-31991
	r31.s64 = -2096562176;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82193748
	sub_82193748(ctx, base);
	// li r4,2
	ctx.r4.s64 = 2;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82193860
	sub_82193860(ctx, base);
	// li r4,128
	ctx.r4.s64 = 128;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82193960
	sub_82193960(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x821936e0
	sub_821936E0(ctx, base);
	// bl 0x8210d7d0
	sub_8210D7D0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// addi r3,r29,204
	ctx.r3.s64 = r29.s64 + 204;
	// lfs f4,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f4.f64 = double(temp.f32);
	// lwz r8,12(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
	// bl 0x82098188
	sub_82098188(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x821936e0
	sub_821936E0(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82193748
	sub_82193748(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82193860
	sub_82193860(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82193960
	sub_82193960(ctx, base);
	// li r4,5
	ctx.r4.s64 = 5;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x821937c0
	sub_821937C0(ctx, base);
	// cntlzw r11,r28
	r11.u64 = r28.u32 == 0 ? 32 : __builtin_clz(r28.u32);
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,255
	ctx.r5.s64 = 255;
	// xori r4,r11,1
	ctx.r4.u64 = r11.u64 ^ 1;
	// bl 0x8209ab98
	sub_8209AB98(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82193748
	sub_82193748(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x821937c0
	sub_821937C0(ctx, base);
	// b 0x820d9cac
	goto loc_820D9CAC;
loc_820D9918:
	// cntlzw r11,r28
	r11.u64 = r28.u32 == 0 ? 32 : __builtin_clz(r28.u32);
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// xori r4,r11,1
	ctx.r4.u64 = r11.u64 ^ 1;
	// bl 0x8209ab98
	sub_8209AB98(ctx, base);
	// b 0x820d9cac
	goto loc_820D9CAC;
loc_820D9944:
	// cmplwi cr6,r9,4
	cr6.compare<uint32_t>(ctx.r9.u32, 4, xer);
	// bne cr6,0x820d99c0
	if (!cr6.getEQ()) goto loc_820D99C0;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lis r10,-32164
	ctx.r10.s64 = -2107899904;
	// addi r10,r10,3456
	ctx.r10.s64 = ctx.r10.s64 + 3456;
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r8,r10
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, xer);
	// bne cr6,0x820d99c0
	if (!cr6.getEQ()) goto loc_820D99C0;
	// lis r10,-32185
	ctx.r10.s64 = -2109276160;
	// addi r10,r10,28796
	ctx.r10.s64 = ctx.r10.s64 + 28796;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x820d99c0
	if (cr6.getEQ()) goto loc_820D99C0;
	// lis r10,-32183
	ctx.r10.s64 = -2109145088;
	// addi r10,r10,-4976
	ctx.r10.s64 = ctx.r10.s64 + -4976;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x820d99c0
	if (cr6.getEQ()) goto loc_820D99C0;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lbz r11,573(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 573);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d9e9c
	if (cr6.getEQ()) goto loc_820D9E9C;
	// cntlzw r11,r28
	r11.u64 = r28.u32 == 0 ? 32 : __builtin_clz(r28.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// xori r4,r11,1
	ctx.r4.u64 = r11.u64 ^ 1;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8209b5f0
	sub_8209B5F0(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8211c460
	sub_8211C460(ctx, base);
	// b 0x820d9cac
	goto loc_820D9CAC;
loc_820D99C0:
	// lwz r10,8(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lis r11,-32164
	r11.s64 = -2107899904;
	// addi r11,r11,3496
	r11.s64 = r11.s64 + 3496;
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x820d99f8
	if (!cr6.getEQ()) goto loc_820D99F8;
	// cntlzw r11,r28
	r11.u64 = r28.u32 == 0 ? 32 : __builtin_clz(r28.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// li r5,255
	ctx.r5.s64 = 255;
	// xori r4,r11,1
	ctx.r4.u64 = r11.u64 ^ 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8209b220
	sub_8209B220(ctx, base);
	// b 0x820d9cac
	goto loc_820D9CAC;
loc_820D99F8:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lbz r11,574(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 574);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d9e9c
	if (cr6.getEQ()) goto loc_820D9E9C;
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// bne cr6,0x820d9ba4
	if (!cr6.getEQ()) goto loc_820D9BA4;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x820d96d8
	sub_820D96D8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d9ba4
	if (cr6.getEQ()) goto loc_820D9BA4;
	// lis r31,-31991
	r31.s64 = -2096562176;
	// lfs f13,68(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + 68);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f12,72(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 72);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,100(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f13,96(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// lfs f0,2688(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2688);
	f0.f64 = double(temp.f32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stfs f0,108(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// rldicr r9,r10,61,63
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u64, 61) & 0xFFFFFFFFFFFFFFFF;
	// stfs f13,2048(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 2048, temp.u32);
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	f0.f64 = double(temp.f32);
	// stfs f0,2052(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2052, temp.u32);
	// lfs f0,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	f0.f64 = double(temp.f32);
	// stfs f0,2056(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2056, temp.u32);
	// lfs f0,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	f0.f64 = double(temp.f32);
	// stfs f0,2060(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2060, temp.u32);
	// ld r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// std r10,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r10.u64);
	// lwz r3,8(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// bl 0x820d49c8
	sub_820D49C8(ctx, base);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r11,24708(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24708);
	// mullw r11,r3,r11
	r11.s64 = int64_t(ctx.r3.s32) * int64_t(r11.s32);
	// subfic r11,r11,255
	xer.ca = r11.u32 <= 255;
	r11.s64 = 255 - r11.s64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820d9aa0
	if (!cr6.getLT()) goto loc_820D9AA0;
	// li r11,0
	r11.s64 = 0;
loc_820D9AA0:
	// extsw r10,r11
	ctx.r10.s64 = r11.s32;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// mr r29,r9
	r29.u64 = ctx.r9.u64;
	// mr r21,r9
	r21.u64 = ctx.r9.u64;
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// cntlzw r10,r28
	ctx.r10.u64 = r28.u32 == 0 ? 32 : __builtin_clz(r28.u32);
	// lfs f0,2776(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// stfs f0,124(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 124, temp.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// li r9,4
	ctx.r9.s64 = 4;
	// xori r4,r10,1
	ctx.r4.u64 = ctx.r10.u64 ^ 1;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// lfd f0,80(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f13,f0
	ctx.f13.f64 = double(float(f0.f64));
	// lfs f0,6592(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6592);
	f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f0,116(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f0,120(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// stfs f0,6144(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6144, temp.u32);
	// lfs f0,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	f0.f64 = double(temp.f32);
	// stfs f0,6148(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6148, temp.u32);
	// lfs f0,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	f0.f64 = double(temp.f32);
	// stfs f0,6152(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6152, temp.u32);
	// lfs f0,124(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	f0.f64 = double(temp.f32);
	// stfs f0,6156(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6156, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// or r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 | ctx.r3.u64;
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// addi r10,r10,24692
	ctx.r10.s64 = ctx.r10.s64 + 24692;
	// lfs f0,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,6160(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6160, temp.u32);
	// lfs f0,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,6164(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6164, temp.u32);
	// lfs f0,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,6168(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6168, temp.u32);
	// lfs f0,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,6172(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6172, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// or r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 | r29.u64;
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// addi r10,r10,24676
	ctx.r10.s64 = ctx.r10.s64 + 24676;
	// lfs f0,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,6176(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6176, temp.u32);
	// lfs f0,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,6180(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6180, temp.u32);
	// lfs f0,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,6184(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6184, temp.u32);
	// lfs f0,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,6188(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6188, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// or r10,r10,r21
	ctx.r10.u64 = ctx.r10.u64 | r21.u64;
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// b 0x820d9bc4
	goto loc_820D9BC4;
loc_820D9BA4:
	// cntlzw r11,r28
	r11.u64 = r28.u32 == 0 ? 32 : __builtin_clz(r28.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// xori r4,r11,1
	ctx.r4.u64 = r11.u64 ^ 1;
loc_820D9BC4:
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// bl 0x8209ab98
	sub_8209AB98(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8211c460
	sub_8211C460(ctx, base);
	// b 0x820d9cac
	goto loc_820D9CAC;
loc_820D9BDC:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// bne cr6,0x820d9cac
	if (!cr6.getEQ()) goto loc_820D9CAC;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// lbz r11,-8431(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + -8431);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d9c20
	if (cr6.getEQ()) goto loc_820D9C20;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r3,36(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// bl 0x8209c578
	sub_8209C578(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d9c20
	if (cr6.getEQ()) goto loc_820D9C20;
	// lwz r4,20(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r29,36(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// b 0x820d9c2c
	goto loc_820D9C2C;
loc_820D9C20:
	// lwz r4,20(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lwz r29,44(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 44);
loc_820D9C2C:
	// lis r11,-32013
	r11.s64 = -2098003968;
	// li r6,33
	ctx.r6.s64 = 33;
	// addi r31,r11,21536
	r31.s64 = r11.s64 + 21536;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x8209b548
	sub_8209B548(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8209a590
	sub_8209A590(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d9c98
	if (cr6.getEQ()) goto loc_820D9C98;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8209c558
	sub_8209C558(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x820d9c98
	if (!cr6.getGT()) goto loc_820D9C98;
	// bl 0x8210d7d0
	sub_8210D7D0(ctx, base);
	// lwz r10,20(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lis r11,-32250
	r11.s64 = -2113536000;
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// addi r6,r11,11952
	ctx.r6.s64 = r11.s64 + 11952;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r5,48(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// bl 0x8209c4b0
	sub_8209C4B0(ctx, base);
	// b 0x820d9cac
	goto loc_820D9CAC;
loc_820D9C98:
	// bl 0x8210d7d0
	sub_8210D7D0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8209c450
	sub_8209C450(ctx, base);
loc_820D9CAC:
	// li r10,1
	ctx.r10.s64 = 1;
	// lbz r11,2(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 2);
	// slw r10,r10,r28
	ctx.r10.u64 = r28.u8 & 0x20 ? 0 : (ctx.r10.u32 << (r28.u8 & 0x3F));
	// and r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820d9cd0
	if (cr6.getEQ()) goto loc_820D9CD0;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x821423a0
	sub_821423A0(ctx, base);
loc_820D9CD0:
	// lbz r11,3(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 3);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// bne cr6,0x820d9d44
	if (!cr6.getEQ()) goto loc_820D9D44;
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// clrlwi r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820d9e3c
	if (cr6.getEQ()) goto loc_820D9E3C;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// rlwinm r11,r11,0,15,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d9d18
	if (cr6.getEQ()) goto loc_820D9D18;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r10,128
	ctx.r5.s64 = ctx.r10.s64 + 128;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// b 0x820d9e30
	goto loc_820D9E30;
loc_820D9D18:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r5,r10,128
	ctx.r5.s64 = ctx.r10.s64 + 128;
	// rlwinm r11,r11,0,3,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	// subfic r11,r11,0
	xer.ca = r11.u32 <= 0;
	r11.s64 = 0 - r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// clrlwi r11,r11,29
	r11.u64 = r11.u32 & 0x7;
	// addi r6,r11,1
	ctx.r6.s64 = r11.s64 + 1;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// b 0x820d9e30
	goto loc_820D9E30;
loc_820D9D44:
	// cmplwi cr6,r11,11
	cr6.compare<uint32_t>(r11.u32, 11, xer);
	// bne cr6,0x820d9e3c
	if (!cr6.getEQ()) goto loc_820D9E3C;
	// lwz r11,8(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 8);
	// clrlwi r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820d9e3c
	if (cr6.getEQ()) goto loc_820D9E3C;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lwz r29,8(r27)
	r29.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// rlwinm r11,r11,0,15,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d9d78
	if (cr6.getEQ()) goto loc_820D9D78;
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x820d9d90
	goto loc_820D9D90;
loc_820D9D78:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,3,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000000;
	// subfic r11,r11,0
	xer.ca = r11.u32 <= 0;
	r11.s64 = 0 - r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// clrlwi r11,r11,29
	r11.u64 = r11.u32 & 0x7;
	// addi r6,r11,1
	ctx.r6.s64 = r11.s64 + 1;
loc_820D9D90:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r5,r29,128
	ctx.r5.s64 = r29.s64 + 128;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// bl 0x820d8d20
	sub_820D8D20(ctx, base);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// rlwinm r11,r11,0,15,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820d9dc4
	if (cr6.getEQ()) goto loc_820D9DC4;
	// li r31,0
	r31.s64 = 0;
	// b 0x820d9ddc
	goto loc_820D9DDC;
loc_820D9DC4:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,2,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x30000000;
	// subfic r11,r11,0
	xer.ca = r11.u32 <= 0;
	r11.s64 = 0 - r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// clrlwi r11,r11,29
	r11.u64 = r11.u32 & 0x7;
	// addi r31,r11,1
	r31.s64 = r11.s64 + 1;
loc_820D9DDC:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// addi r5,r29,244
	ctx.r5.s64 = r29.s64 + 244;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// bl 0x820d8d20
	sub_820D8D20(ctx, base);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// addi r5,r29,360
	ctx.r5.s64 = r29.s64 + 360;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r4,8(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// bl 0x820d8d20
	sub_820D8D20(ctx, base);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// addi r5,r29,476
	ctx.r5.s64 = r29.s64 + 476;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r4,12(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 12);
loc_820D9E30:
	// li r7,1
	ctx.r7.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820d8d20
	sub_820D8D20(ctx, base);
loc_820D9E3C:
	// lwz r31,36(r27)
	r31.u64 = PPC_LOAD_U32(r27.u32 + 36);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820d9e6c
	if (cr6.getEQ()) goto loc_820D9E6C;
loc_820D9E48:
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d9778
	sub_820D9778(ctx, base);
	// lwz r31,40(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x820d9e48
	if (!cr6.getEQ()) goto loc_820D9E48;
loc_820D9E6C:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x820d9e9c
	if (cr6.getEQ()) goto loc_820D9E9C;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// lwz r3,12(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// lhz r11,14(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 14);
	// extsh r4,r11
	ctx.r4.s64 = r11.s16;
	// beq cr6,0x820d9e98
	if (cr6.getEQ()) goto loc_820D9E98;
	// bl 0x820b5768
	sub_820B5768(ctx, base);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x823ed16c
	return;
loc_820D9E98:
	// bl 0x823d22e0
	sub_823D22E0(ctx, base);
loc_820D9E9C:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x823ed16c
	return;
}

__attribute__((alias("__imp__sub_820D9EA8"))) PPC_WEAK_FUNC(sub_820D9EA8);
PPC_FUNC_IMPL(__imp__sub_820D9EA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,255
	ctx.r3.s64 = 255;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r3,-16(r1)
	PPC_STORE_U32(ctx.r1.u32 + -16, ctx.r3.u32);
	// lbz r10,3(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// cmplwi cr6,r10,47
	cr6.compare<uint32_t>(ctx.r10.u32, 47, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// lfs f0,24712(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 24712);
	f0.f64 = double(temp.f32);
	// ble cr6,0x820d9f10
	if (!cr6.getGT()) goto loc_820D9F10;
	// cmpwi cr6,r11,60
	cr6.compare<int32_t>(r11.s32, 60, xer);
	// bge cr6,0x820d9f10
	if (!cr6.getLT()) goto loc_820D9F10;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,-8(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// lfs f13,13960(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13960);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f12,f13,f12
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f13,6576(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6576);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
loc_820D9F10:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,6596(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6596);
	ctx.f13.f64 = double(temp.f32);
	// addi r11,r1,-16
	r11.s64 = ctx.r1.s64 + -16;
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r3,-16(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820D9F30"))) PPC_WEAK_FUNC(sub_820D9F30);
PPC_FUNC_IMPL(__imp__sub_820D9F30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r8,1
	ctx.r8.s64 = 1;
	// lbz r6,76(r3)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r3.u32 + 76);
	// li r11,0
	r11.s64 = 0;
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r9,r1,156
	ctx.r9.s64 = ctx.r1.s64 + 156;
	// cmpwi cr6,r6,255
	cr6.compare<int32_t>(ctx.r6.s32, 255, xer);
	// stw r8,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r8.u32);
	// li r8,3
	ctx.r8.s64 = 3;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r11.u32);
	// stw r11,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r11.u32);
	// stw r11,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r11.u32);
	// stw r8,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r8.u32);
	// stw r11,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r11.u32);
	// stw r11,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r11.u32);
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r11.u32);
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r11.u32);
	// stw r11,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r11.u32);
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// blt cr6,0x820d9fb0
	if (cr6.getLT()) goto loc_820D9FB0;
	// lwz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// rlwinm r9,r9,0,15,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x10000;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820d9fb0
	if (!cr6.getEQ()) goto loc_820D9FB0;
	// cntlzw r9,r4
	ctx.r9.u64 = ctx.r4.u32 == 0 ? 32 : __builtin_clz(ctx.r4.u32);
	// rlwinm r9,r9,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// xori r9,r9,1
	ctx.r9.u64 = ctx.r9.u64 ^ 1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// b 0x820d9fc0
	goto loc_820D9FC0;
loc_820D9FB0:
	// clrlwi r9,r5,24
	ctx.r9.u64 = ctx.r5.u32 & 0xFF;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820da0f0
	if (cr6.getEQ()) goto loc_820DA0F0;
	// li r9,3
	ctx.r9.s64 = 3;
loc_820D9FC0:
	// stw r9,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r9.u32);
	// cmpwi cr6,r6,255
	cr6.compare<int32_t>(ctx.r6.s32, 255, xer);
	// lhz r9,12(r10)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + 12);
	// not r9,r9
	ctx.r9.u64 = ~ctx.r9.u64;
	// clrlwi r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	// stw r9,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r9.u32);
	// bge cr6,0x820d9fec
	if (!cr6.getLT()) goto loc_820D9FEC;
	// li r11,5
	r11.s64 = 5;
	// stw r6,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, ctx.r6.u32);
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r11.u32);
	// b 0x820da030
	goto loc_820DA030;
loc_820D9FEC:
	// li r9,9
	ctx.r9.s64 = 9;
	// stw r9,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r9.u32);
	// lbz r9,3(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// cmplwi cr6,r9,47
	cr6.compare<uint32_t>(ctx.r9.u32, 47, xer);
	// bne cr6,0x820da008
	if (!cr6.getEQ()) goto loc_820DA008;
	// lwz r11,136(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 136);
	// b 0x820da028
	goto loc_820DA028;
loc_820DA008:
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// bne cr6,0x820da02c
	if (!cr6.getEQ()) goto loc_820DA02C;
	// lhz r9,152(r10)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + 152);
	// rlwinm r9,r9,0,30,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820da02c
	if (cr6.getEQ()) goto loc_820DA02C;
	// lhz r11,190(r10)
	r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 190);
	// extsh r11,r11
	r11.s64 = r11.s16;
loc_820DA028:
	// rlwinm r11,r11,8,0,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 8) & 0xFFFFFF00;
loc_820DA02C:
	// stw r11,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r11.u32);
loc_820DA030:
	// lbz r9,120(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 120);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// li r12,1
	r12.s64 = 1;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// rldicr r12,r12,62,63
	r12.u64 = __builtin_rotateleft64(r12.u64, 62) & 0xFFFFFFFFFFFFFFFF;
	// li r7,64
	ctx.r7.s64 = 64;
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lwz r11,13356(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 13356);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f13,f0
	ctx.f13.f64 = double(float(f0.f64));
	// lfs f0,6592(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 6592);
	f0.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,96(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lbz r9,121(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 121);
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// lfd f12,80(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * f0.f64));
	// stfs f12,100(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lbz r9,122(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 122);
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// lfd f12,80(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * f0.f64));
	// stfs f12,104(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lbz r10,123(r10)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + 123);
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f12,80(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// fmuls f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * f0.f64));
	// stfs f0,108(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// stfs f13,6128(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 6128, temp.u32);
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	f0.f64 = double(temp.f32);
	// stfs f0,6132(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6132, temp.u32);
	// lfs f0,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	f0.f64 = double(temp.f32);
	// stfs f0,6136(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6136, temp.u32);
	// lfs f0,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	f0.f64 = double(temp.f32);
	// stfs f0,6140(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6140, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// or r10,r10,r12
	ctx.r10.u64 = ctx.r10.u64 | r12.u64;
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// bl 0x820d9778
	sub_820D9778(ctx, base);
loc_820DA0F0:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DA100"))) PPC_WEAK_FUNC(sub_820DA100);
PPC_FUNC_IMPL(__imp__sub_820DA100) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820da1f0
	if (cr6.getEQ()) goto loc_820DA1F0;
loc_820DA12C:
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// addi r11,r11,-8
	r11.s64 = r11.s64 + -8;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// bgt cr6,0x820da1c4
	if (cr6.getGT()) goto loc_820DA1C4;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-24236
	r12.s64 = r12.s64 + -24236;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820DA198;
	case 1:
		goto loc_820DA1C4;
	case 2:
		goto loc_820DA1C4;
	case 3:
		goto loc_820DA1C4;
	case 4:
		goto loc_820DA1C4;
	case 5:
		goto loc_820DA1C4;
	case 6:
		goto loc_820DA1C4;
	case 7:
		goto loc_820DA1C4;
	case 8:
		goto loc_820DA1C4;
	case 9:
		goto loc_820DA1C4;
	case 10:
		goto loc_820DA1A8;
	case 11:
		goto loc_820DA1C4;
	case 12:
		goto loc_820DA1C4;
	case 13:
		goto loc_820DA1C4;
	case 14:
		goto loc_820DA1C4;
	case 15:
		goto loc_820DA1B8;
	case 16:
		goto loc_820DA21C;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-24168(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24168);
	// lwz r16,-24124(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24124);
	// lwz r16,-24124(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24124);
	// lwz r16,-24124(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24124);
	// lwz r16,-24124(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24124);
	// lwz r16,-24124(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24124);
	// lwz r16,-24124(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24124);
	// lwz r16,-24124(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24124);
	// lwz r16,-24124(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24124);
	// lwz r16,-24124(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24124);
	// lwz r16,-24152(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24152);
	// lwz r16,-24124(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24124);
	// lwz r16,-24124(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24124);
	// lwz r16,-24124(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24124);
	// lwz r16,-24124(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24124);
	// lwz r16,-24136(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24136);
	// lwz r16,-24036(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -24036);
loc_820DA198:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// bl 0x8211ab80
	sub_8211AB80(ctx, base);
	// b 0x820da1c4
	goto loc_820DA1C4;
loc_820DA1A8:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// bl 0x8211abd8
	sub_8211ABD8(ctx, base);
	// b 0x820da1c4
	goto loc_820DA1C4;
loc_820DA1B8:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,20(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// bl 0x8211ac30
	sub_8211AC30(ctx, base);
loc_820DA1C4:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820da1d8
	if (cr6.getEQ()) goto loc_820DA1D8;
	// mr r31,r11
	r31.u64 = r11.u64;
	// b 0x820da210
	goto loc_820DA210;
loc_820DA1D8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820da20c
	if (!cr6.getEQ()) goto loc_820DA20C;
	// lwz r31,8(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x820da1d8
	if (!cr6.getEQ()) goto loc_820DA1D8;
loc_820DA1F0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_820DA1F4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_820DA20C:
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
loc_820DA210:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x820da12c
	if (!cr6.getEQ()) goto loc_820DA12C;
	// b 0x820da1f0
	goto loc_820DA1F0;
loc_820DA21C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x820da1f4
	goto loc_820DA1F4;
}

__attribute__((alias("__imp__sub_820DA228"))) PPC_WEAK_FUNC(sub_820DA228);
PPC_FUNC_IMPL(__imp__sub_820DA228) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r10,-32164
	ctx.r10.s64 = -2107899904;
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// addi r10,r10,3968
	ctx.r10.s64 = ctx.r10.s64 + 3968;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x820da254
	if (!cr6.getEQ()) goto loc_820DA254;
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// bne cr6,0x820da254
	if (!cr6.getEQ()) goto loc_820DA254;
loc_820DA24C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_820DA254:
	// lis r10,-32164
	ctx.r10.s64 = -2107899904;
	// addi r10,r10,3940
	ctx.r10.s64 = ctx.r10.s64 + 3940;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x820da298
	if (!cr6.getEQ()) goto loc_820DA298;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// beq cr6,0x820da24c
	if (cr6.getEQ()) goto loc_820DA24C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// beq cr6,0x820da24c
	if (cr6.getEQ()) goto loc_820DA24C;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// beq cr6,0x820da24c
	if (cr6.getEQ()) goto loc_820DA24C;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// beq cr6,0x820da24c
	if (cr6.getEQ()) goto loc_820DA24C;
loc_820DA298:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DA2A0"))) PPC_WEAK_FUNC(sub_820DA2A0);
PPC_FUNC_IMPL(__imp__sub_820DA2A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lis r31,1
	r31.s64 = 65536;
	// lis r30,-2
	r30.s64 = -131072;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// ori r31,r31,34463
	r31.u64 = r31.u64 | 34463;
	// lhz r11,4(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 4);
	// ori r30,r30,31073
	r30.u64 = r30.u64 | 31073;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// addi r11,r11,-76
	r11.s64 = r11.s64 + -76;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r27,r11,27,31,31
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// bl 0x820da100
	sub_820DA100(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lwz r8,4(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x820da570
	if (cr6.getEQ()) goto loc_820DA570;
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// bl 0x820da228
	sub_820DA228(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820da570
	if (cr6.getEQ()) goto loc_820DA570;
	// lhz r11,12(r8)
	r11.u64 = PPC_LOAD_U16(ctx.r8.u32 + 12);
	// li r7,0
	ctx.r7.s64 = 0;
	// extsh r6,r11
	ctx.r6.s64 = r11.s16;
	// cmpwi cr6,r6,4
	cr6.compare<int32_t>(ctx.r6.s32, 4, xer);
	// blt cr6,0x820da3ec
	if (cr6.getLT()) goto loc_820DA3EC;
	// addi r10,r6,-4
	ctx.r10.s64 = ctx.r6.s64 + -4;
	// lwz r11,8(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// addi r9,r11,32
	ctx.r9.s64 = r11.s64 + 32;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// rlwinm r7,r10,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
loc_820DA32C:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lfs f0,-28(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -28);
	f0.f64 = double(temp.f32);
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpw cr6,r11,r31
	cr6.compare<int32_t>(r11.s32, r31.s32, xer);
	// bge cr6,0x820da34c
	if (!cr6.getLT()) goto loc_820DA34C;
	// mr r31,r11
	r31.u64 = r11.u64;
loc_820DA34C:
	// cmpw cr6,r11,r30
	cr6.compare<int32_t>(r11.s32, r30.s32, xer);
	// ble cr6,0x820da358
	if (!cr6.getGT()) goto loc_820DA358;
	// mr r30,r11
	r30.u64 = r11.u64;
loc_820DA358:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lfs f0,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	f0.f64 = double(temp.f32);
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpw cr6,r11,r31
	cr6.compare<int32_t>(r11.s32, r31.s32, xer);
	// bge cr6,0x820da378
	if (!cr6.getLT()) goto loc_820DA378;
	// mr r31,r11
	r31.u64 = r11.u64;
loc_820DA378:
	// cmpw cr6,r11,r30
	cr6.compare<int32_t>(r11.s32, r30.s32, xer);
	// ble cr6,0x820da384
	if (!cr6.getGT()) goto loc_820DA384;
	// mr r30,r11
	r30.u64 = r11.u64;
loc_820DA384:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lfs f0,28(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 28);
	f0.f64 = double(temp.f32);
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpw cr6,r11,r31
	cr6.compare<int32_t>(r11.s32, r31.s32, xer);
	// bge cr6,0x820da3a4
	if (!cr6.getLT()) goto loc_820DA3A4;
	// mr r31,r11
	r31.u64 = r11.u64;
loc_820DA3A4:
	// cmpw cr6,r11,r30
	cr6.compare<int32_t>(r11.s32, r30.s32, xer);
	// ble cr6,0x820da3b0
	if (!cr6.getGT()) goto loc_820DA3B0;
	// mr r30,r11
	r30.u64 = r11.u64;
loc_820DA3B0:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lfs f0,56(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 56);
	f0.f64 = double(temp.f32);
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpw cr6,r11,r31
	cr6.compare<int32_t>(r11.s32, r31.s32, xer);
	// bge cr6,0x820da3d0
	if (!cr6.getLT()) goto loc_820DA3D0;
	// mr r31,r11
	r31.u64 = r11.u64;
loc_820DA3D0:
	// cmpw cr6,r11,r30
	cr6.compare<int32_t>(r11.s32, r30.s32, xer);
	// ble cr6,0x820da3dc
	if (!cr6.getGT()) goto loc_820DA3DC;
	// mr r30,r11
	r30.u64 = r11.u64;
loc_820DA3DC:
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r9,r9,112
	ctx.r9.s64 = ctx.r9.s64 + 112;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820da32c
	if (!cr6.getEQ()) goto loc_820DA32C;
loc_820DA3EC:
	// cmpw cr6,r7,r6
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r6.s32, xer);
	// bge cr6,0x820da444
	if (!cr6.getLT()) goto loc_820DA444;
	// lwz r10,8(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// mulli r11,r7,28
	r11.s64 = ctx.r7.s64 * 28;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// subf r9,r7,r6
	ctx.r9.s64 = ctx.r6.s64 - ctx.r7.s64;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
loc_820DA408:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpw cr6,r11,r31
	cr6.compare<int32_t>(r11.s32, r31.s32, xer);
	// bge cr6,0x820da428
	if (!cr6.getLT()) goto loc_820DA428;
	// mr r31,r11
	r31.u64 = r11.u64;
loc_820DA428:
	// cmpw cr6,r11,r30
	cr6.compare<int32_t>(r11.s32, r30.s32, xer);
	// ble cr6,0x820da434
	if (!cr6.getGT()) goto loc_820DA434;
	// mr r30,r11
	r30.u64 = r11.u64;
loc_820DA434:
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// addi r10,r10,28
	ctx.r10.s64 = ctx.r10.s64 + 28;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820da408
	if (!cr6.getEQ()) goto loc_820DA408;
loc_820DA444:
	// lwz r3,20(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// bl 0x82118ea8
	sub_82118EA8(ctx, base);
	// extsw r8,r30
	ctx.r8.s64 = r30.s32;
	// lwz r10,20(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// extsw r9,r31
	ctx.r9.s64 = r31.s32;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// std r8,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r8.u64);
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// lfd f13,80(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f10,f13
	ctx.f10.f64 = double(ctx.f13.s64);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lfs f12,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	ctx.f12.f64 = double(temp.f32);
	// addi r11,r28,-1
	r11.s64 = r28.s64 + -1;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// lfs f0,24(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 24);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// lfs f13,2944(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2944);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 / f0.f64));
	// lfs f13,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// fadds f10,f10,f13
	ctx.f10.f64 = double(float(ctx.f10.f64 + ctx.f13.f64));
	// lfd f11,88(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// frsp f11,f11
	ctx.f11.f64 = double(float(ctx.f11.f64));
	// fadds f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f13.f64));
	// fmuls f13,f10,f0
	ctx.f13.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fmuls f0,f11,f0
	f0.f64 = double(float(ctx.f11.f64 * f0.f64));
	// bgt cr6,0x820da508
	if (cr6.getGT()) goto loc_820DA508;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-23336
	r12.s64 = r12.s64 + -23336;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820DA4E8;
	case 1:
		goto loc_820DA4F4;
	case 2:
		goto loc_820DA508;
	case 3:
		goto loc_820DA500;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-23320(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -23320);
	// lwz r16,-23308(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -23308);
	// lwz r16,-23288(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -23288);
	// lwz r16,-23296(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -23296);
loc_820DA4E8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,14112(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14112);
	ctx.f12.f64 = double(temp.f32);
	// b 0x820da508
	goto loc_820DA508;
loc_820DA4F4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,17736(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17736);
	ctx.f12.f64 = double(temp.f32);
	// b 0x820da508
	goto loc_820DA508;
loc_820DA500:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,14016(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14016);
	ctx.f12.f64 = double(temp.f32);
loc_820DA508:
	// fsubs f0,f0,f13
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lhz r11,4(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 4);
	// cmplwi cr6,r11,98
	cr6.compare<uint32_t>(r11.u32, 98, xer);
	// fmadds f0,f0,f12,f13
	f0.f64 = double(float(f0.f64 * ctx.f12.f64 + ctx.f13.f64));
	// bne cr6,0x820da544
	if (!cr6.getEQ()) goto loc_820DA544;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r10,16(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// lfs f12,24716(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 24716);
	ctx.f12.f64 = double(temp.f32);
	// fadds f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 + f0.f64));
	// stfs f0,68(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 68, temp.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// stfs f13,72(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 72, temp.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed184
	return;
loc_820DA544:
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x820da564
	if (cr6.getEQ()) goto loc_820DA564;
	// stfs f0,68(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 68, temp.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// stfs f13,72(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 72, temp.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed184
	return;
loc_820DA564:
	// stfs f13,68(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 68, temp.u32);
	// lwz r11,16(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 16);
	// stfs f0,72(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 72, temp.u32);
loc_820DA570:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820DA578"))) PPC_WEAK_FUNC(sub_820DA578);
PPC_FUNC_IMPL(__imp__sub_820DA578) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r28,32(r30)
	r28.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x820da634
	if (cr6.getEQ()) goto loc_820DA634;
	// lwz r31,8(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r29,20(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// bl 0x820ccc48
	sub_820CCC48(ctx, base);
	// li r27,0
	r27.s64 = 0;
	// stw r27,28(r29)
	PPC_STORE_U32(r29.u32 + 28, r27.u32);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,13,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFF7FFFF;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// lbz r11,0(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x820da5c8
	if (cr6.getEQ()) goto loc_820DA5C8;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x820da634
	if (!cr6.getEQ()) goto loc_820DA634;
loc_820DA5C8:
	// lwz r31,8(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820da634
	if (cr6.getEQ()) goto loc_820DA634;
	// lwz r11,472(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 472);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// bne cr6,0x820da5ec
	if (!cr6.getEQ()) goto loc_820DA5EC;
	// stw r27,472(r31)
	PPC_STORE_U32(r31.u32 + 472, r27.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820DA5EC:
	// lwz r11,352(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 352);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// bne cr6,0x820da614
	if (!cr6.getEQ()) goto loc_820DA614;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82124078
	sub_82124078(ctx, base);
	// stw r27,352(r31)
	PPC_STORE_U32(r31.u32 + 352, r27.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820DA614:
	// lwz r11,356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 356);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// bne cr6,0x820da634
	if (!cr6.getEQ()) goto loc_820DA634;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82124078
	sub_82124078(ctx, base);
	// stw r27,356(r31)
	PPC_STORE_U32(r31.u32 + 356, r27.u32);
loc_820DA634:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820DA640"))) PPC_WEAK_FUNC(sub_820DA640);
PPC_FUNC_IMPL(__imp__sub_820DA640) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed12c
	// addi r12,r1,-64
	r12.s64 = ctx.r1.s64 + -64;
	// bl 0x823ed544
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// lwz r28,8(r26)
	r28.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwz r30,32(r26)
	r30.u64 = PPC_LOAD_U32(r26.u32 + 32);
	// lwz r11,100(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 100);
	// rlwinm r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820da6a0
	if (cr6.getEQ()) goto loc_820DA6A0;
	// lwz r11,108(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 108);
	// lwz r10,68(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820da6a0
	if (cr6.getEQ()) goto loc_820DA6A0;
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// li r9,1
	ctx.r9.s64 = 1;
	// ori r8,r8,1
	ctx.r8.u64 = ctx.r8.u64 | 1;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// lwz r11,100(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 100);
	// stw r10,108(r28)
	PPC_STORE_U32(r28.u32 + 108, ctx.r10.u32);
	// rlwimi r11,r9,7,24,25
	r11.u64 = (__builtin_rotateleft32(ctx.r9.u32, 7) & 0xC0) | (r11.u64 & 0xFFFFFFFFFFFFFF3F);
	// stw r11,100(r28)
	PPC_STORE_U32(r28.u32 + 100, r11.u32);
loc_820DA6A0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820dad44
	if (cr6.getEQ()) goto loc_820DAD44;
	// lwz r11,100(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 100);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dad44
	if (cr6.getEQ()) goto loc_820DAD44;
	// lwz r31,108(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 108);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lwz r25,20(r28)
	r25.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// mr r27,r30
	r27.u64 = r30.u64;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f31,2688(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	f31.f64 = double(temp.f32);
	// lwz r11,184(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 184);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// stw r30,136(r31)
	PPC_STORE_U32(r31.u32 + 136, r30.u32);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f27,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	f27.f64 = double(temp.f32);
	// bne cr6,0x820da844
	if (!cr6.getEQ()) goto loc_820DA844;
	// lbz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bne cr6,0x820da844
	if (!cr6.getEQ()) goto loc_820DA844;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// stfs f31,112(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f31,116(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f31,120(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// bl 0x82119128
	sub_82119128(ctx, base);
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f29,14160(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14160);
	f29.f64 = double(temp.f32);
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// stfs f0,4(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,14028(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14028);
	f30.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f13,f0,f30
	ctx.f13.f64 = double(float(f0.f64 * f30.f64));
	// lfs f0,17760(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17760);
	f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// stfs f0,12(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f29,17756(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 17756);
	f29.f64 = double(temp.f32);
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f28,17752(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17752);
	f28.f64 = double(temp.f32);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// fmsubs f0,f0,f29,f28
	f0.f64 = double(float(f0.f64 * f29.f64 - f28.f64));
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// fmsubs f0,f0,f29,f28
	f0.f64 = double(float(f0.f64 * f29.f64 - f28.f64));
	// stfs f0,116(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r4,r31,32
	ctx.r4.s64 = r31.s64 + 32;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// fmsubs f0,f0,f29,f28
	f0.f64 = double(float(f0.f64 * f29.f64 - f28.f64));
	// stfs f0,120(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// bl 0x8210ba08
	sub_8210BA08(ctx, base);
	// b 0x820dab4c
	goto loc_820DAB4C;
loc_820DA844:
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x820da980
	if (!cr6.getEQ()) goto loc_820DA980;
	// lbz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bne cr6,0x820da980
	if (!cr6.getEQ()) goto loc_820DA980;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// stfs f31,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f31,116(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f31,120(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// bl 0x82119128
	sub_82119128(ctx, base);
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// fmr f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = ctx.f1.f64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// lfs f0,14296(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14296);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// frsp f0,f13
	f0.f64 = double(float(ctx.f13.f64));
	// lfs f30,17748(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17748);
	f30.f64 = double(temp.f32);
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// stfs f0,4(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// stfs f0,12(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f30,17756(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 17756);
	f30.f64 = double(temp.f32);
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f29,14028(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14028);
	f29.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f28,17752(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17752);
	f28.f64 = double(temp.f32);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// fmsubs f0,f0,f30,f28
	f0.f64 = double(float(f0.f64 * f30.f64 - f28.f64));
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// fmsubs f0,f0,f30,f28
	f0.f64 = double(float(f0.f64 * f30.f64 - f28.f64));
	// stfs f0,116(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r4,r31,32
	ctx.r4.s64 = r31.s64 + 32;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// fmsubs f0,f0,f30,f28
	f0.f64 = double(float(f0.f64 * f30.f64 - f28.f64));
	// stfs f0,120(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// bl 0x8210ba08
	sub_8210BA08(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x820dab4c
	goto loc_820DAB4C;
loc_820DA980:
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bne cr6,0x820dab40
	if (!cr6.getEQ()) goto loc_820DAB40;
	// stfs f31,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f31,116(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f31,120(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// lfs f0,12(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	f0.f64 = double(temp.f32);
	// lfs f13,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f1,f0,f12
	ctx.f1.f64 = double(float(f0.f64 - ctx.f12.f64));
	// fsubs f2,f13,f11
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// bl 0x8210ae20
	sub_8210AE20(ctx, base);
	// fmr f28,f1
	ctx.fpscr.disableFlushMode();
	f28.f64 = ctx.f1.f64;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// fmr f1,f28
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f28.f64;
	// add r29,r11,r29
	r29.u64 = r11.u64 + r29.u64;
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// clrldi r10,r29,32
	ctx.r10.u64 = r29.u64 & 0xFFFFFFFF;
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// std r10,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r10.u64);
	// lfs f30,14028(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14028);
	f30.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f29,15528(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15528);
	f29.f64 = double(temp.f32);
	// lfd f13,104(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmadds f13,f13,f30,f27
	ctx.f13.f64 = double(float(ctx.f13.f64 * f30.f64 + f27.f64));
	// fmuls f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 * f29.f64));
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,4(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// fmr f1,f28
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f28.f64;
	// add r29,r11,r29
	r29.u64 = r11.u64 + r29.u64;
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// clrldi r11,r29,32
	r11.u64 = r29.u64 & 0xFFFFFFFF;
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f13,104(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmadds f13,f13,f30,f27
	ctx.f13.f64 = double(float(ctx.f13.f64 * f30.f64 + f27.f64));
	// fmuls f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 * f29.f64));
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,12(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f29,17744(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 17744);
	f29.f64 = double(temp.f32);
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f28,17740(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17740);
	f28.f64 = double(temp.f32);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// fmsubs f0,f0,f29,f28
	f0.f64 = double(float(f0.f64 * f29.f64 - f28.f64));
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// fmsubs f0,f0,f29,f28
	f0.f64 = double(float(f0.f64 * f29.f64 - f28.f64));
	// stfs f0,116(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r4,r31,32
	ctx.r4.s64 = r31.s64 + 32;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// fmsubs f0,f0,f29,f28
	f0.f64 = double(float(f0.f64 * f29.f64 - f28.f64));
	// stfs f0,120(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// bl 0x8210ba08
	sub_8210BA08(ctx, base);
	// b 0x820dab4c
	goto loc_820DAB4C;
loc_820DAB40:
	// addi r4,r31,32
	ctx.r4.s64 = r31.s64 + 32;
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// bl 0x82136da8
	sub_82136DA8(ctx, base);
loc_820DAB4C:
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dab68
	if (cr6.getEQ()) goto loc_820DAB68;
loc_820DAB58:
	// mr r27,r11
	r27.u64 = r11.u64;
	// lwz r11,32(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820dab58
	if (!cr6.getEQ()) goto loc_820DAB58;
loc_820DAB68:
	// lbz r11,1(r26)
	r11.u64 = PPC_LOAD_U8(r26.u32 + 1);
	// lwz r10,24(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// beq cr6,0x820dac80
	if (cr6.getEQ()) goto loc_820DAC80;
	// lbz r11,3(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 3);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bne cr6,0x820dab98
	if (!cr6.getEQ()) goto loc_820DAB98;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,2948(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2948);
	f30.f64 = double(temp.f32);
	// b 0x820daba0
	goto loc_820DABA0;
loc_820DAB98:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,2952(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2952);
	f30.f64 = double(temp.f32);
loc_820DABA0:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82118c20
	sub_82118C20(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r30,31
	r30.s64 = 31;
	// addi r25,r1,128
	r25.s64 = ctx.r1.s64 + 128;
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// bl 0x8210b450
	sub_8210B450(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dabd8
	if (cr6.getEQ()) goto loc_820DABD8;
	// li r30,29
	r30.s64 = 29;
loc_820DABD8:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x820ce1f0
	sub_820CE1F0(ctx, base);
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f2,20(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmr f8,f27
	ctx.f8.f64 = f27.f64;
	// lfs f4,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f4.f64 = double(temp.f32);
	// fmr f7,f31
	ctx.f7.f64 = f31.f64;
	// lfs f3,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f3.f64 = double(temp.f32);
	// fmr f6,f27
	ctx.f6.f64 = f27.f64;
	// fmr f5,f31
	ctx.f5.f64 = f31.f64;
	// bl 0x82112020
	sub_82112020(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820dac4c
	if (cr6.getEQ()) goto loc_820DAC4C;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lfs f2,184(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f2.f64 = double(temp.f32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f1,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f1.f64 = double(temp.f32);
	// fmr f5,f27
	ctx.f5.f64 = f27.f64;
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// fmr f3,f30
	ctx.f3.f64 = f30.f64;
	// bl 0x821126c0
	sub_821126C0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge cr6,0x820dac4c
	if (!cr6.getLT()) goto loc_820DAC4C;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,24(r26)
	PPC_STORE_U32(r26.u32 + 24, r11.u32);
	// b 0x820dac64
	goto loc_820DAC64;
loc_820DAC4C:
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// stw r11,24(r26)
	PPC_STORE_U32(r26.u32 + 24, r11.u32);
	// lfs f0,12(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,176(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f0,20(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 20);
	f0.f64 = double(temp.f32);
	// stfs f0,184(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
loc_820DAC64:
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x820ce1f0
	sub_820CE1F0(ctx, base);
	// lfs f0,56(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 56);
	f0.f64 = double(temp.f32);
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// stfs f0,28(r26)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r26.u32 + 28, temp.u32);
	// b 0x820daca8
	goto loc_820DACA8;
loc_820DAC80:
	// lwz r11,24(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stw r11,24(r26)
	PPC_STORE_U32(r26.u32 + 24, r11.u32);
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lfs f1,20(r25)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r25.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r27,12
	ctx.r3.s64 = r27.s64 + 12;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
loc_820DACA8:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820da578
	sub_820DA578(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820ccb20
	sub_820CCB20(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820cca18
	sub_820CCA18(ctx, base);
	// lfs f0,176(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	f0.f64 = double(temp.f32);
	// stfs f0,12(r26)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r26.u32 + 12, temp.u32);
	// addi r4,r28,24
	ctx.r4.s64 = r28.s64 + 24;
	// stfs f0,88(r28)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r28.u32 + 88, temp.u32);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lfs f0,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	f0.f64 = double(temp.f32);
	// stfs f0,16(r26)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r26.u32 + 16, temp.u32);
	// lfs f13,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,92(r28)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r28.u32 + 92, temp.u32);
	// stfs f13,20(r26)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r26.u32 + 20, temp.u32);
	// stfs f13,96(r28)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r28.u32 + 96, temp.u32);
	// stfs f31,176(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// stfs f31,180(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// stfs f31,184(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// addi r4,r28,124
	ctx.r4.s64 = r28.s64 + 124;
	// lwz r3,16(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 16);
	// bl 0x820d4c20
	sub_820D4C20(ctx, base);
	// lbz r11,124(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 124);
	// lbz r10,125(r28)
	ctx.r10.u64 = PPC_LOAD_U8(r28.u32 + 125);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lbz r9,126(r28)
	ctx.r9.u64 = PPC_LOAD_U8(r28.u32 + 126);
	// lbz r8,127(r28)
	ctx.r8.u64 = PPC_LOAD_U8(r28.u32 + 127);
	// stb r11,120(r28)
	PPC_STORE_U8(r28.u32 + 120, r11.u8);
	// stb r10,121(r28)
	PPC_STORE_U8(r28.u32 + 121, ctx.r10.u8);
	// stb r9,122(r28)
	PPC_STORE_U8(r28.u32 + 122, ctx.r9.u8);
	// stb r8,123(r28)
	PPC_STORE_U8(r28.u32 + 123, ctx.r8.u8);
	// bl 0x820d0458
	sub_820D0458(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// addi r12,r1,-64
	r12.s64 = ctx.r1.s64 + -64;
	// bl 0x823ed590
	// b 0x823ed17c
	return;
loc_820DAD44:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// addi r12,r1,-64
	r12.s64 = ctx.r1.s64 + -64;
	// bl 0x823ed590
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_820DAD58"))) PPC_WEAK_FUNC(sub_820DAD58);
PPC_FUNC_IMPL(__imp__sub_820DAD58) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r29,16(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r3,8(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// bl 0x820d4a60
	sub_820D4A60(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821414d8
	sub_821414D8(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821414d8
	sub_821414D8(ctx, base);
	// addi r6,r31,56
	ctx.r6.s64 = r31.s64 + 56;
	// addi r5,r31,40
	ctx.r5.s64 = r31.s64 + 40;
	// lfs f6,24(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 24);
	ctx.f6.f64 = double(temp.f32);
	// addi r4,r31,24
	ctx.r4.s64 = r31.s64 + 24;
	// lfs f5,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f5.f64 = double(temp.f32);
	// addi r3,r31,88
	ctx.r3.s64 = r31.s64 + 88;
	// lfs f4,16(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82146040
	sub_82146040(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r10,100(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// lbz r11,2(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// stfs f0,112(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 112, temp.u32);
	// ori r11,r11,128
	r11.u64 = r11.u64 | 128;
	// stw r10,100(r31)
	PPC_STORE_U32(r31.u32 + 100, ctx.r10.u32);
	// stb r11,2(r31)
	PPC_STORE_U8(r31.u32 + 2, r11.u8);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820DADF0"))) PPC_WEAK_FUNC(sub_820DADF0);
PPC_FUNC_IMPL(__imp__sub_820DADF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	// lbz r11,3(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 3);
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// cmplwi cr6,r11,17
	cr6.compare<uint32_t>(r11.u32, 17, xer);
	// bgt cr6,0x820dae68
	if (cr6.getGT()) goto loc_820DAE68;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-20968
	r12.s64 = r12.s64 + -20968;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820DAE60;
	case 1:
		goto loc_820DAE68;
	case 2:
		goto loc_820DAE68;
	case 3:
		goto loc_820DAE60;
	case 4:
		goto loc_820DAE60;
	case 5:
		goto loc_820DAE68;
	case 6:
		goto loc_820DAE68;
	case 7:
		goto loc_820DAE68;
	case 8:
		goto loc_820DAE68;
	case 9:
		goto loc_820DAE68;
	case 10:
		goto loc_820DAE68;
	case 11:
		goto loc_820DAE68;
	case 12:
		goto loc_820DAE68;
	case 13:
		goto loc_820DAE60;
	case 14:
		goto loc_820DAE68;
	case 15:
		goto loc_820DAE68;
	case 16:
		goto loc_820DAE60;
	case 17:
		goto loc_820DAE60;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-20896(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20896);
	// lwz r16,-20888(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20888);
	// lwz r16,-20888(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20888);
	// lwz r16,-20896(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20896);
	// lwz r16,-20896(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20896);
	// lwz r16,-20888(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20888);
	// lwz r16,-20888(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20888);
	// lwz r16,-20888(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20888);
	// lwz r16,-20888(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20888);
	// lwz r16,-20888(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20888);
	// lwz r16,-20888(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20888);
	// lwz r16,-20888(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20888);
	// lwz r16,-20888(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20888);
	// lwz r16,-20896(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20896);
	// lwz r16,-20888(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20888);
	// lwz r16,-20888(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20888);
	// lwz r16,-20896(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20896);
	// lwz r16,-20896(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -20896);
loc_820DAE60:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_820DAE68:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DAE70"))) PPC_WEAK_FUNC(sub_820DAE70);
PPC_FUNC_IMPL(__imp__sub_820DAE70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// lbz r9,3(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// beq cr6,0x820daeb0
	if (cr6.getEQ()) goto loc_820DAEB0;
	// bl 0x820dadf0
	sub_820DADF0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820daec4
	if (cr6.getEQ()) goto loc_820DAEC4;
	// cmplwi cr6,r9,21
	cr6.compare<uint32_t>(ctx.r9.u32, 21, xer);
	// beq cr6,0x820daec4
	if (cr6.getEQ()) goto loc_820DAEC4;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// rlwinm r11,r11,0,15,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820daed8
	if (!cr6.getEQ()) goto loc_820DAED8;
loc_820DAEB0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820DAEC4:
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// li r3,0
	ctx.r3.s64 = 0;
	// rlwinm r11,r11,0,14,14
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820daedc
	if (!cr6.getEQ()) goto loc_820DAEDC;
loc_820DAED8:
	// li r3,1
	ctx.r3.s64 = 1;
loc_820DAEDC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DAEF0"))) PPC_WEAK_FUNC(sub_820DAEF0);
PPC_FUNC_IMPL(__imp__sub_820DAEF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// stwu r1,-400(r1)
	ea = -400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// lwz r25,8(r24)
	r25.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// lwz r11,100(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 100);
	// rlwinm r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820db2e4
	if (!cr6.getEQ()) goto loc_820DB2E4;
	// lbz r11,1(r24)
	r11.u64 = PPC_LOAD_U8(r24.u32 + 1);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820db2e4
	if (cr6.getEQ()) goto loc_820DB2E4;
	// lwz r3,36(r24)
	ctx.r3.u64 = PPC_LOAD_U32(r24.u32 + 36);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820daf4c
	if (cr6.getEQ()) goto loc_820DAF4C;
loc_820DAF34:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// lwz r31,40(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// bl 0x820daef0
	sub_820DAEF0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x820daf34
	if (!cr6.getEQ()) goto loc_820DAF34;
loc_820DAF4C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r27,20(r25)
	r27.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// li r30,0
	r30.s64 = 0;
	// addi r10,r1,180
	ctx.r10.s64 = ctx.r1.s64 + 180;
	// lis r28,-32015
	r28.s64 = -2098135040;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// addi r11,r1,188
	r11.s64 = ctx.r1.s64 + 188;
	// stfs f0,176(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// stw r30,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r30.u32);
	// stw r30,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r30.u32);
	// lbz r9,-8431(r28)
	ctx.r9.u64 = PPC_LOAD_U8(r28.u32 + -8431);
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// stw r30,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r30.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// stw r30,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r30.u32);
	// stw r30,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r30.u32);
	// stw r30,16(r11)
	PPC_STORE_U32(r11.u32 + 16, r30.u32);
	// beq cr6,0x820dafb8
	if (cr6.getEQ()) goto loc_820DAFB8;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwz r3,36(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// bl 0x8209c578
	sub_8209C578(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dafb8
	if (cr6.getEQ()) goto loc_820DAFB8;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwz r31,36(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// b 0x820dafc0
	goto loc_820DAFC0;
loc_820DAFB8:
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// lwz r31,44(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 44);
loc_820DAFC0:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,0(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r26.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,12(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// li r6,33
	ctx.r6.s64 = 33;
	// stfs f13,160(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// lfs f12,4(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// lfs f9,16(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// lfs f0,16156(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16156);
	f0.f64 = double(temp.f32);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// fmadds f13,f10,f0,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 * f0.f64 + ctx.f13.f64));
	// lfs f11,8(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// addi r29,r11,23648
	r29.s64 = r11.s64 + 23648;
	// lfs f8,20(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 20);
	ctx.f8.f64 = double(temp.f32);
	// stfs f13,144(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// fmadds f13,f9,f0,f12
	ctx.f13.f64 = double(float(ctx.f9.f64 * f0.f64 + ctx.f12.f64));
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// fmadds f0,f8,f0,f11
	f0.f64 = double(float(ctx.f8.f64 * f0.f64 + ctx.f11.f64));
	// stfs f12,164(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// stfs f11,168(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// stfs f13,148(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f0,152(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// bl 0x8209b548
	sub_8209B548(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8209c558
	sub_8209C558(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x820db084
	if (!cr6.getGT()) goto loc_820DB084;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8209a590
	sub_8209A590(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820db084
	if (cr6.getEQ()) goto loc_820DB084;
	// addi r5,r1,124
	ctx.r5.s64 = ctx.r1.s64 + 124;
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// addi r10,r1,240
	ctx.r10.s64 = ctx.r1.s64 + 240;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// addi r9,r1,112
	ctx.r9.s64 = ctx.r1.s64 + 112;
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// lwz r7,48(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8209c1e8
	sub_8209C1E8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x820db138
	goto loc_820DB138;
loc_820DB084:
	// addi r4,r1,256
	ctx.r4.s64 = ctx.r1.s64 + 256;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8210c4e8
	sub_8210C4E8(ctx, base);
	// lfs f0,160(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	f0.f64 = double(temp.f32);
	// stfs f0,208(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// addi r4,r1,208
	ctx.r4.s64 = ctx.r1.s64 + 208;
	// lfs f0,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	f0.f64 = double(temp.f32);
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// stfs f0,212(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// lfs f0,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	f0.f64 = double(temp.f32);
	// stfs f0,216(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// bl 0x8210b6e0
	sub_8210B6E0(ctx, base);
	// lfs f0,144(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	f0.f64 = double(temp.f32);
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// stfs f0,224(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// lfs f0,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	f0.f64 = double(temp.f32);
	// stfs f0,228(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// lfs f0,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	f0.f64 = double(temp.f32);
	// stfs f0,232(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// bl 0x8210b6e0
	sub_8210B6E0(ctx, base);
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r9,r1,124
	ctx.r9.s64 = ctx.r1.s64 + 124;
	// addi r8,r1,240
	ctx.r8.s64 = ctx.r1.s64 + 240;
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// addi r6,r1,128
	ctx.r6.s64 = ctx.r1.s64 + 128;
	// addi r5,r1,224
	ctx.r5.s64 = ctx.r1.s64 + 224;
	// addi r4,r1,208
	ctx.r4.s64 = ctx.r1.s64 + 208;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8209bed8
	sub_8209BED8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// clrlwi r11,r31,24
	r11.u64 = r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820db138
	if (cr6.getEQ()) goto loc_820DB138;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8238aec0
	sub_8238AEC0(ctx, base);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8238b010
	sub_8238B010(ctx, base);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8238c750
	sub_8238C750(ctx, base);
loc_820DB138:
	// clrlwi r11,r31,24
	r11.u64 = r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820db2e4
	if (cr6.getEQ()) goto loc_820DB2E4;
	// lbz r11,-8431(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + -8431);
	// mr r31,r30
	r31.u64 = r30.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// beq cr6,0x820db160
	if (cr6.getEQ()) goto loc_820DB160;
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// b 0x820db164
	goto loc_820DB164;
loc_820DB160:
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 56);
loc_820DB164:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820db1a4
	if (cr6.getEQ()) goto loc_820DB1A4;
	// lwz r9,48(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// mr r11,r30
	r11.u64 = r30.u64;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// ble cr6,0x820db1a4
	if (!cr6.getGT()) goto loc_820DB1A4;
	// lwz r8,124(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
loc_820DB180:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpw cr6,r7,r8
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r8.s32, xer);
	// beq cr6,0x820db1a0
	if (cr6.getEQ()) goto loc_820DB1A0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// blt cr6,0x820db180
	if (cr6.getLT()) goto loc_820DB180;
	// b 0x820db1a4
	goto loc_820DB1A4;
loc_820DB1A0:
	// mr r31,r11
	r31.u64 = r11.u64;
loc_820DB1A4:
	// lfs f0,128(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	f0.f64 = double(temp.f32);
	// rlwinm r11,r31,6,0,25
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 6) & 0xFFFFFFC0;
	// stfs f0,176(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// addi r4,r1,256
	ctx.r4.s64 = ctx.r1.s64 + 256;
	// lfs f0,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	f0.f64 = double(temp.f32);
	// add r3,r11,r29
	ctx.r3.u64 = r11.u64 + r29.u64;
	// stfs f0,180(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f0,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	f0.f64 = double(temp.f32);
	// stfs f0,184(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// lfs f0,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	f0.f64 = double(temp.f32);
	// stfs f0,188(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfs f0,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	f0.f64 = double(temp.f32);
	// stfs f0,192(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// lfs f0,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	f0.f64 = double(temp.f32);
	// stfs f0,196(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// bl 0x8210c4e8
	sub_8210C4E8(ctx, base);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// bl 0x8210b6e0
	sub_8210B6E0(ctx, base);
	// addi r4,r1,188
	ctx.r4.s64 = ctx.r1.s64 + 188;
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// lfs f12,192(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f0,f12,f12
	f0.f64 = double(float(ctx.f12.f64 * ctx.f12.f64));
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	ctx.f11.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f9,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f9.f64 = double(temp.f32);
	// fneg f1,f9
	ctx.f1.u64 = ctx.f9.u64 ^ 0x8000000000000000;
	// lfs f10,52(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 52);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f0,f13,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// fcmpu cr6,f1,f10
	cr6.compare(ctx.f1.f64, ctx.f10.f64);
	// fmadds f0,f11,f11,f0
	f0.f64 = double(float(ctx.f11.f64 * ctx.f11.f64 + f0.f64));
	// fsqrts f9,f0
	ctx.f9.f64 = double(float(sqrt(f0.f64)));
	// lfs f0,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// fdivs f0,f0,f9
	f0.f64 = double(float(f0.f64 / ctx.f9.f64));
	// fmuls f11,f0,f11
	ctx.f11.f64 = double(float(f0.f64 * ctx.f11.f64));
	// stfs f11,188(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// fmuls f12,f0,f12
	ctx.f12.f64 = double(float(f0.f64 * ctx.f12.f64));
	// stfs f12,192(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,196(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// bgt cr6,0x820db2e4
	if (cr6.getGT()) goto loc_820DB2E4;
	// lwz r11,8(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 8);
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r11,r11,0,14,14
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820db2a8
	if (!cr6.getEQ()) goto loc_820DB2A8;
	// lbz r11,3(r25)
	r11.u64 = PPC_LOAD_U8(r25.u32 + 3);
	// cmplwi cr6,r11,42
	cr6.compare<uint32_t>(r11.u32, 42, xer);
	// beq cr6,0x820db2a4
	if (cr6.getEQ()) goto loc_820DB2A4;
	// cmplwi cr6,r11,47
	cr6.compare<uint32_t>(r11.u32, 47, xer);
	// beq cr6,0x820db2a4
	if (cr6.getEQ()) goto loc_820DB2A4;
	// lwz r8,20(r25)
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + 20);
	// lis r11,-32164
	r11.s64 = -2107899904;
	// addi r10,r11,3568
	ctx.r10.s64 = r11.s64 + 3568;
	// lwz r11,8(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r8,r10
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, xer);
	// bne cr6,0x820db2a8
	if (!cr6.getEQ()) goto loc_820DB2A8;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820db2a8
	if (!cr6.getEQ()) goto loc_820DB2A8;
loc_820DB2A4:
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
loc_820DB2A8:
	// lwz r11,12(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 12);
	// addi r6,r1,240
	ctx.r6.s64 = ctx.r1.s64 + 240;
	// stw r9,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r9.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// rlwinm r11,r11,12,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 12) & 0x1;
	// stw r27,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r27.u32);
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
	// addi r8,r1,176
	ctx.r8.s64 = ctx.r1.s64 + 176;
	// stw r6,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r6.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820cd6c0
	sub_820CD6C0(ctx, base);
loc_820DB2E4:
	// addi r1,r1,400
	ctx.r1.s64 = ctx.r1.s64 + 400;
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_820DB2F0"))) PPC_WEAK_FUNC(sub_820DB2F0);
PPC_FUNC_IMPL(__imp__sub_820DB2F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// mr r7,r4
	ctx.r7.u64 = ctx.r4.u64;
	// lbz r10,1(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 1);
	// lwz r11,8(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8);
	// rlwinm r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// beq cr6,0x820db370
	if (cr6.getEQ()) goto loc_820DB370;
	// lwz r9,100(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 100);
	// rlwinm r9,r9,0,19,19
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x1000;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820db370
	if (!cr6.getEQ()) goto loc_820DB370;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwinm r11,r11,0,16,16
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820db370
	if (!cr6.getEQ()) goto loc_820DB370;
	// lwz r4,12(r10)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lwz r3,8(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// bl 0x820d4a60
	sub_820D4A60(ctx, base);
	// bl 0x820d3b80
	sub_820D3B80(ctx, base);
	// lfs f0,56(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 56);
	f0.f64 = double(temp.f32);
	// fadds f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 + f0.f64));
	// lfs f13,52(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x820db370
	if (cr6.getGT()) goto loc_820DB370;
	// mr r4,r7
	ctx.r4.u64 = ctx.r7.u64;
	// mr r3,r8
	ctx.r3.u64 = ctx.r8.u64;
	// bl 0x820daef0
	sub_820DAEF0(ctx, base);
loc_820DB370:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DB380"))) PPC_WEAK_FUNC(sub_820DB380);
PPC_FUNC_IMPL(__imp__sub_820DB380) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lbz r11,2(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 2);
	// rlwinm r11,r11,0,0,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820db39c
	if (!cr6.getEQ()) goto loc_820DB39C;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// blr 
	return;
loc_820DB39C:
	// addi r11,r1,-16
	r11.s64 = ctx.r1.s64 + -16;
	// lfs f0,112(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	f0.f64 = double(temp.f32);
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,-16(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// srawi r11,r11,2
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x3) != 0);
	r11.s64 = r11.s32 >> 2;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DB3C8"))) PPC_WEAK_FUNC(sub_820DB3C8);
PPC_FUNC_IMPL(__imp__sub_820DB3C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stfd f30,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, f30.u64);
	// stfd f31,-40(r1)
	PPC_STORE_U64(ctx.r1.u32 + -40, f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r31,8(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// beq cr6,0x820db410
	if (cr6.getEQ()) goto loc_820DB410;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,12,12
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820db410
	if (!cr6.getEQ()) goto loc_820DB410;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// andi. r11,r11,19
	r11.u64 = r11.u64 & 19;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820db58c
	if (cr6.getEQ()) goto loc_820DB58C;
loc_820DB410:
	// lbz r11,1(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 1);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820db58c
	if (cr6.getEQ()) goto loc_820DB58C;
	// lbz r11,2(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// rlwinm r11,r11,0,0,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820db454
	if (cr6.getEQ()) goto loc_820DB454;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lfs f0,112(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 112);
	f0.f64 = double(temp.f32);
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// srawi r11,r11,2
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x3) != 0);
	r11.s64 = r11.s32 >> 2;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820db58c
	if (!cr6.getEQ()) goto loc_820DB58C;
loc_820DB454:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,6,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820db58c
	if (!cr6.getEQ()) goto loc_820DB58C;
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lfs f0,88(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 88);
	f0.f64 = double(temp.f32);
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// lfs f12,92(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,96(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// cmplwi cr6,r11,40
	cr6.compare<uint32_t>(r11.u32, 40, xer);
	// lfs f11,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// fsubs f1,f0,f11
	ctx.f1.f64 = double(float(f0.f64 - ctx.f11.f64));
	// lfs f0,16(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 16);
	f0.f64 = double(temp.f32);
	// lfs f10,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 - f0.f64));
	// fsubs f2,f13,f10
	ctx.f2.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// fmuls f0,f1,f1
	f0.f64 = double(float(ctx.f1.f64 * ctx.f1.f64));
	// fmadds f11,f2,f2,f0
	ctx.f11.f64 = double(float(ctx.f2.f64 * ctx.f2.f64 + f0.f64));
	// bne cr6,0x820db4d8
	if (!cr6.getEQ()) goto loc_820DB4D8;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820db4d8
	if (cr6.getEQ()) goto loc_820DB4D8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,16180(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16180);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,17772(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17772);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,17768(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17768);
	f31.f64 = double(temp.f32);
	// b 0x820db4f0
	goto loc_820DB4F0;
loc_820DB4D8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2940(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2940);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,17764(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17764);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,14152(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14152);
	f31.f64 = double(temp.f32);
loc_820DB4F0:
	// fcmpu cr6,f11,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f11.f64, ctx.f13.f64);
	// bge cr6,0x820db58c
	if (!cr6.getLT()) goto loc_820DB58C;
	// fcmpu cr6,f12,f0
	cr6.compare(ctx.f12.f64, f0.f64);
	// bge cr6,0x820db58c
	if (!cr6.getLT()) goto loc_820DB58C;
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// fcmpu cr6,f12,f0
	cr6.compare(ctx.f12.f64, f0.f64);
	// ble cr6,0x820db58c
	if (!cr6.getGT()) goto loc_820DB58C;
	// bl 0x8210ae20
	sub_8210AE20(ctx, base);
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// bl 0x820b3ce0
	sub_820B3CE0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f0,f30,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f30.f64 - ctx.f1.f64));
	// lfs f13,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// lfs f13,6588(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6588);
	ctx.f13.f64 = double(temp.f32);
	// bge cr6,0x820db538
	if (!cr6.getLT()) goto loc_820DB538;
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
loc_820DB538:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,14032(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14032);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// ble cr6,0x820db54c
	if (!cr6.getGT()) goto loc_820DB54C;
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
loc_820DB54C:
	// fcmpu cr6,f0,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f31.f64);
	// bgt cr6,0x820db58c
	if (cr6.getGT()) goto loc_820DB58C;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820db584
	if (cr6.getEQ()) goto loc_820DB584;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f4,20(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,12(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820db58c
	if (cr6.getEQ()) goto loc_820DB58C;
loc_820DB584:
	// lis r11,-32013
	r11.s64 = -2098003968;
	// stw r29,904(r11)
	PPC_STORE_U32(r11.u32 + 904, r29.u32);
loc_820DB58C:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f30,-48(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// lfd f31,-40(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820DB5A0"))) PPC_WEAK_FUNC(sub_820DB5A0);
PPC_FUNC_IMPL(__imp__sub_820DB5A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq cr6,0x820db5bc
	if (cr6.getEQ()) goto loc_820DB5BC;
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// andi. r10,r10,223
	ctx.r10.u64 = ctx.r10.u64 & 223;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stb r10,2(r11)
	PPC_STORE_U8(r11.u32 + 2, ctx.r10.u8);
	// blr 
	return;
loc_820DB5BC:
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// stb r10,2(r11)
	PPC_STORE_U8(r11.u32 + 2, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DB5D0"))) PPC_WEAK_FUNC(sub_820DB5D0);
PPC_FUNC_IMPL(__imp__sub_820DB5D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,104(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 104);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820db634
	if (cr6.getEQ()) goto loc_820DB634;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r10,r10,0,23,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x100;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820db634
	if (cr6.getEQ()) goto loc_820DB634;
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// rlwinm r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820db634
	if (!cr6.getEQ()) goto loc_820DB634;
	// lwz r10,104(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 104);
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r10,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r10.u32);
	// lwz r10,104(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 104);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// lwz r10,104(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 104);
	// lfs f0,72(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 72);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// lwz r11,104(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 104);
	// lfs f0,68(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 68);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r6)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r6.u32 + 0, temp.u32);
	// blr 
	return;
loc_820DB634:
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DB640"))) PPC_WEAK_FUNC(sub_820DB640);
PPC_FUNC_IMPL(__imp__sub_820DB640) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r5,-1
	r11.s64 = ctx.r5.s64 + -1;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// cmplwi cr6,r11,28
	cr6.compare<uint32_t>(r11.u32, 28, xer);
	// bgt cr6,0x820db74c
	if (cr6.getGT()) goto loc_820DB74C;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-18816
	r12.s64 = r12.s64 + -18816;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820DB730;
	case 1:
		goto loc_820DB730;
	case 2:
		goto loc_820DB730;
	case 3:
		goto loc_820DB6F4;
	case 4:
		goto loc_820DB6F4;
	case 5:
		goto loc_820DB6F4;
	case 6:
		goto loc_820DB6F4;
	case 7:
		goto loc_820DB6F4;
	case 8:
		goto loc_820DB6F4;
	case 9:
		goto loc_820DB6F4;
	case 10:
		goto loc_820DB6F4;
	case 11:
		goto loc_820DB6F4;
	case 12:
		goto loc_820DB6F4;
	case 13:
		goto loc_820DB6F4;
	case 14:
		goto loc_820DB708;
	case 15:
		goto loc_820DB708;
	case 16:
		goto loc_820DB6F4;
	case 17:
		goto loc_820DB6F4;
	case 18:
		goto loc_820DB6F4;
	case 19:
		goto loc_820DB6F4;
	case 20:
		goto loc_820DB6F4;
	case 21:
		goto loc_820DB71C;
	case 22:
		goto loc_820DB730;
	case 23:
		goto loc_820DB74C;
	case 24:
		goto loc_820DB74C;
	case 25:
		goto loc_820DB74C;
	case 26:
		goto loc_820DB74C;
	case 27:
		goto loc_820DB74C;
	case 28:
		goto loc_820DB71C;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-18640(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18640);
	// lwz r16,-18640(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18640);
	// lwz r16,-18640(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18640);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18680(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18680);
	// lwz r16,-18680(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18680);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18700(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18700);
	// lwz r16,-18660(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18660);
	// lwz r16,-18640(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18640);
	// lwz r16,-18612(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18612);
	// lwz r16,-18612(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18612);
	// lwz r16,-18612(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18612);
	// lwz r16,-18612(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18612);
	// lwz r16,-18612(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18612);
	// lwz r16,-18660(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18660);
loc_820DB6F4:
	// cmpwi cr6,r6,1
	cr6.compare<int32_t>(ctx.r6.s32, 1, xer);
	// lis r3,0
	ctx.r3.s64 = 0;
	// bne cr6,0x820db734
	if (!cr6.getEQ()) goto loc_820DB734;
	// ori r3,r3,41986
	ctx.r3.u64 = ctx.r3.u64 | 41986;
	// b 0x820db738
	goto loc_820DB738;
loc_820DB708:
	// cmpwi cr6,r6,1
	cr6.compare<int32_t>(ctx.r6.s32, 1, xer);
	// lis r3,0
	ctx.r3.s64 = 0;
	// bne cr6,0x820db734
	if (!cr6.getEQ()) goto loc_820DB734;
	// ori r3,r3,41987
	ctx.r3.u64 = ctx.r3.u64 | 41987;
	// b 0x820db738
	goto loc_820DB738;
loc_820DB71C:
	// cmpwi cr6,r6,1
	cr6.compare<int32_t>(ctx.r6.s32, 1, xer);
	// bne cr6,0x820db730
	if (!cr6.getEQ()) goto loc_820DB730;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41988
	ctx.r3.u64 = ctx.r3.u64 | 41988;
	// b 0x820db738
	goto loc_820DB738;
loc_820DB730:
	// lis r3,0
	ctx.r3.s64 = 0;
loc_820DB734:
	// ori r3,r3,41985
	ctx.r3.u64 = ctx.r3.u64 | 41985;
loc_820DB738:
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ee840
	sub_823EE840(ctx, base);
loc_820DB74C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DB768"))) PPC_WEAK_FUNC(sub_820DB768);
PPC_FUNC_IMPL(__imp__sub_820DB768) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// cmpwi cr6,r5,1
	cr6.compare<int32_t>(ctx.r5.s32, 1, xer);
	// beq cr6,0x820db9ac
	if (cr6.getEQ()) goto loc_820DB9AC;
	// cmpwi cr6,r5,2
	cr6.compare<int32_t>(ctx.r5.s32, 2, xer);
	// beq cr6,0x820db9ac
	if (cr6.getEQ()) goto loc_820DB9AC;
	// cmpwi cr6,r5,3
	cr6.compare<int32_t>(ctx.r5.s32, 3, xer);
	// beq cr6,0x820db9ac
	if (cr6.getEQ()) goto loc_820DB9AC;
	// cmpwi cr6,r5,10
	cr6.compare<int32_t>(ctx.r5.s32, 10, xer);
	// bne cr6,0x820db7d8
	if (!cr6.getEQ()) goto loc_820DB7D8;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41999
	ctx.r3.u64 = ctx.r3.u64 | 41999;
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ee840
	sub_823EE840(ctx, base);
	// cmpwi cr6,r29,1
	cr6.compare<int32_t>(r29.s32, 1, xer);
	// lis r3,0
	ctx.r3.s64 = 0;
	// bne cr6,0x820db7d0
	if (!cr6.getEQ()) goto loc_820DB7D0;
	// ori r3,r3,42000
	ctx.r3.u64 = ctx.r3.u64 | 42000;
	// b 0x820db9b4
	goto loc_820DB9B4;
loc_820DB7D0:
	// ori r3,r3,42001
	ctx.r3.u64 = ctx.r3.u64 | 42001;
	// b 0x820db9b4
	goto loc_820DB9B4;
loc_820DB7D8:
	// cmpwi cr6,r5,19
	cr6.compare<int32_t>(ctx.r5.s32, 19, xer);
	// bne cr6,0x820db818
	if (!cr6.getEQ()) goto loc_820DB818;
	// cmpwi cr6,r29,1
	cr6.compare<int32_t>(r29.s32, 1, xer);
	// lis r3,0
	ctx.r3.s64 = 0;
	// bne cr6,0x820db7f4
	if (!cr6.getEQ()) goto loc_820DB7F4;
	// ori r3,r3,42009
	ctx.r3.u64 = ctx.r3.u64 | 42009;
	// b 0x820db7f8
	goto loc_820DB7F8;
loc_820DB7F4:
	// ori r3,r3,42010
	ctx.r3.u64 = ctx.r3.u64 | 42010;
loc_820DB7F8:
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ee840
	sub_823EE840(ctx, base);
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42008
	ctx.r3.u64 = ctx.r3.u64 | 42008;
	// b 0x820db9b4
	goto loc_820DB9B4;
loc_820DB818:
	// addi r11,r5,-4
	r11.s64 = ctx.r5.s64 + -4;
	// cmplwi cr6,r11,25
	cr6.compare<uint32_t>(r11.u32, 25, xer);
	// bgt cr6,0x820db998
	if (cr6.getGT()) goto loc_820DB998;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-18372
	r12.s64 = r12.s64 + -18372;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820DB8A4;
	case 1:
		goto loc_820DB8C8;
	case 2:
		goto loc_820DB8E0;
	case 3:
		goto loc_820DB8EC;
	case 4:
		goto loc_820DB8F8;
	case 5:
		goto loc_820DB904;
	case 6:
		goto loc_820DB998;
	case 7:
		goto loc_820DB8D4;
	case 8:
		goto loc_820DB8B0;
	case 9:
		goto loc_820DB8BC;
	case 10:
		goto loc_820DB910;
	case 11:
		goto loc_820DB91C;
	case 12:
		goto loc_820DB928;
	case 13:
		goto loc_820DB934;
	case 14:
		goto loc_820DB940;
	case 15:
		goto loc_820DB998;
	case 16:
		goto loc_820DB94C;
	case 17:
		goto loc_820DB958;
	case 18:
		goto loc_820DB964;
	case 19:
		goto loc_820DB97C;
	case 20:
		goto loc_820DB998;
	case 21:
		goto loc_820DB998;
	case 22:
		goto loc_820DB998;
	case 23:
		goto loc_820DB998;
	case 24:
		goto loc_820DB998;
	case 25:
		goto loc_820DB970;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-18268(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18268);
	// lwz r16,-18232(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18232);
	// lwz r16,-18208(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18208);
	// lwz r16,-18196(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18196);
	// lwz r16,-18184(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18184);
	// lwz r16,-18172(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18172);
	// lwz r16,-18024(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18024);
	// lwz r16,-18220(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18220);
	// lwz r16,-18256(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18256);
	// lwz r16,-18244(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18244);
	// lwz r16,-18160(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18160);
	// lwz r16,-18148(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18148);
	// lwz r16,-18136(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18136);
	// lwz r16,-18124(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18124);
	// lwz r16,-18112(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18112);
	// lwz r16,-18024(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18024);
	// lwz r16,-18100(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18100);
	// lwz r16,-18088(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18088);
	// lwz r16,-18076(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18076);
	// lwz r16,-18052(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18052);
	// lwz r16,-18024(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18024);
	// lwz r16,-18024(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18024);
	// lwz r16,-18024(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18024);
	// lwz r16,-18024(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18024);
	// lwz r16,-18024(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18024);
	// lwz r16,-18064(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -18064);
loc_820DB8A4:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41990
	ctx.r3.u64 = ctx.r3.u64 | 41990;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB8B0:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41991
	ctx.r3.u64 = ctx.r3.u64 | 41991;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB8BC:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41992
	ctx.r3.u64 = ctx.r3.u64 | 41992;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB8C8:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41993
	ctx.r3.u64 = ctx.r3.u64 | 41993;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB8D4:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41994
	ctx.r3.u64 = ctx.r3.u64 | 41994;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB8E0:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41995
	ctx.r3.u64 = ctx.r3.u64 | 41995;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB8EC:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41996
	ctx.r3.u64 = ctx.r3.u64 | 41996;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB8F8:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41997
	ctx.r3.u64 = ctx.r3.u64 | 41997;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB904:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41998
	ctx.r3.u64 = ctx.r3.u64 | 41998;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB910:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42003
	ctx.r3.u64 = ctx.r3.u64 | 42003;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB91C:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42004
	ctx.r3.u64 = ctx.r3.u64 | 42004;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB928:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42005
	ctx.r3.u64 = ctx.r3.u64 | 42005;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB934:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42006
	ctx.r3.u64 = ctx.r3.u64 | 42006;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB940:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42007
	ctx.r3.u64 = ctx.r3.u64 | 42007;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB94C:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42011
	ctx.r3.u64 = ctx.r3.u64 | 42011;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB958:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42012
	ctx.r3.u64 = ctx.r3.u64 | 42012;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB964:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42013
	ctx.r3.u64 = ctx.r3.u64 | 42013;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB970:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42014
	ctx.r3.u64 = ctx.r3.u64 | 42014;
	// b 0x820db984
	goto loc_820DB984;
loc_820DB97C:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42015
	ctx.r3.u64 = ctx.r3.u64 | 42015;
loc_820DB984:
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ee840
	sub_823EE840(ctx, base);
loc_820DB998:
	// cmpwi cr6,r29,1
	cr6.compare<int32_t>(r29.s32, 1, xer);
	// ble cr6,0x820db9c8
	if (!cr6.getGT()) goto loc_820DB9C8;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42002
	ctx.r3.u64 = ctx.r3.u64 | 42002;
	// b 0x820db9b4
	goto loc_820DB9B4;
loc_820DB9AC:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41989
	ctx.r3.u64 = ctx.r3.u64 | 41989;
loc_820DB9B4:
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ee840
	sub_823EE840(ctx, base);
loc_820DB9C8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820DB9D0"))) PPC_WEAK_FUNC(sub_820DB9D0);
PPC_FUNC_IMPL(__imp__sub_820DB9D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	// addi r11,r3,-1
	r11.s64 = ctx.r3.s64 + -1;
	// cmplwi cr6,r11,28
	cr6.compare<uint32_t>(r11.u32, 28, xer);
	// bgtlr cr6
	if (cr6.getGT()) return;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-17932
	r12.s64 = r12.s64 + -17932;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820DBA68;
	case 1:
		goto loc_820DBA68;
	case 2:
		goto loc_820DBA68;
	case 3:
		goto loc_820DBA68;
	case 4:
		goto loc_820DBA68;
	case 5:
		goto loc_820DBA68;
	case 6:
		goto loc_820DBA90;
	case 7:
		goto loc_820DBA90;
	case 8:
		goto loc_820DBA90;
	case 9:
		goto loc_820DBAB8;
	case 10:
		goto loc_820DBA68;
	case 11:
		goto loc_820DBA68;
	case 12:
		goto loc_820DBA68;
	case 13:
		goto loc_820DBA68;
	case 14:
		goto loc_820DBA68;
	case 15:
		goto loc_820DBA90;
	case 16:
		goto loc_820DBA68;
	case 17:
		goto loc_820DBA68;
	case 18:
		goto loc_820DBA68;
	case 19:
		goto loc_820DBA90;
	case 20:
		goto loc_820DBA90;
	case 21:
		goto loc_820DBA68;
	case 22:
		goto loc_820DBA90;
	case 23:
		goto loc_820DBAE0;
	case 24:
		goto loc_820DBAE0;
	case 25:
		goto loc_820DBAE0;
	case 26:
		goto loc_820DBAE0;
	case 27:
		goto loc_820DBAE0;
	case 28:
		goto loc_820DBA68;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
	// lwz r16,-17776(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17776);
	// lwz r16,-17776(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17776);
	// lwz r16,-17776(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17776);
	// lwz r16,-17736(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17736);
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
	// lwz r16,-17776(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17776);
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
	// lwz r16,-17776(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17776);
	// lwz r16,-17776(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17776);
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
	// lwz r16,-17776(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17776);
	// lwz r16,-17696(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17696);
	// lwz r16,-17696(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17696);
	// lwz r16,-17696(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17696);
	// lwz r16,-17696(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17696);
	// lwz r16,-17696(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17696);
	// lwz r16,-17816(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -17816);
loc_820DBA68:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,10113
	ctx.r8.s64 = 10113;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,234
	ctx.r4.s64 = 234;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// b 0x82144920
	sub_82144920(ctx, base);
	return;
loc_820DBA90:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,10123
	ctx.r8.s64 = 10123;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,235
	ctx.r4.s64 = 235;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// b 0x82144920
	sub_82144920(ctx, base);
	return;
loc_820DBAB8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,10127
	ctx.r8.s64 = 10127;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,233
	ctx.r4.s64 = 233;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// b 0x82144920
	sub_82144920(ctx, base);
	return;
loc_820DBAE0:
	// blr 
	return;
	// .long 0x0
}

__attribute__((alias("__imp__sub_820DBAE8"))) PPC_WEAK_FUNC(sub_820DBAE8);
PPC_FUNC_IMPL(__imp__sub_820DBAE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// beq cr6,0x820dbbd4
	if (cr6.getEQ()) goto loc_820DBBD4;
	// cmpwi cr6,r3,3
	cr6.compare<int32_t>(ctx.r3.s32, 3, xer);
	// beq cr6,0x820dbbd4
	if (cr6.getEQ()) goto loc_820DBBD4;
	// cmpwi cr6,r3,29
	cr6.compare<int32_t>(ctx.r3.s32, 29, xer);
	// beq cr6,0x820dbbac
	if (cr6.getEQ()) goto loc_820DBBAC;
	// cmpwi cr6,r3,28
	cr6.compare<int32_t>(ctx.r3.s32, 28, xer);
	// beq cr6,0x820dbbac
	if (cr6.getEQ()) goto loc_820DBBAC;
	// cmpwi cr6,r3,27
	cr6.compare<int32_t>(ctx.r3.s32, 27, xer);
	// beq cr6,0x820dbbac
	if (cr6.getEQ()) goto loc_820DBBAC;
	// cmpwi cr6,r3,33
	cr6.compare<int32_t>(ctx.r3.s32, 33, xer);
	// beq cr6,0x820dbbac
	if (cr6.getEQ()) goto loc_820DBBAC;
	// cmpwi cr6,r3,47
	cr6.compare<int32_t>(ctx.r3.s32, 47, xer);
	// beq cr6,0x820dbbac
	if (cr6.getEQ()) goto loc_820DBBAC;
	// cmpwi cr6,r3,48
	cr6.compare<int32_t>(ctx.r3.s32, 48, xer);
	// beq cr6,0x820dbbac
	if (cr6.getEQ()) goto loc_820DBBAC;
	// cmpwi cr6,r3,34
	cr6.compare<int32_t>(ctx.r3.s32, 34, xer);
	// beq cr6,0x820dbbac
	if (cr6.getEQ()) goto loc_820DBBAC;
	// cmpwi cr6,r3,26
	cr6.compare<int32_t>(ctx.r3.s32, 26, xer);
	// beq cr6,0x820dbb84
	if (cr6.getEQ()) goto loc_820DBB84;
	// cmpwi cr6,r3,87
	cr6.compare<int32_t>(ctx.r3.s32, 87, xer);
	// beq cr6,0x820dbb84
	if (cr6.getEQ()) goto loc_820DBB84;
	// cmpwi cr6,r3,86
	cr6.compare<int32_t>(ctx.r3.s32, 86, xer);
	// beq cr6,0x820dbb84
	if (cr6.getEQ()) goto loc_820DBB84;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// cmpwi cr6,r3,22
	cr6.compare<int32_t>(ctx.r3.s32, 22, xer);
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bne cr6,0x820dbb78
	if (!cr6.getEQ()) goto loc_820DBB78;
	// li r8,10146
	ctx.r8.s64 = 10146;
	// li r4,242
	ctx.r4.s64 = 242;
	// b 0x82144920
	sub_82144920(ctx, base);
	return;
loc_820DBB78:
	// li r8,10148
	ctx.r8.s64 = 10148;
	// li r4,232
	ctx.r4.s64 = 232;
	// b 0x82144920
	sub_82144920(ctx, base);
	return;
loc_820DBB84:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,10144
	ctx.r8.s64 = 10144;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,234
	ctx.r4.s64 = 234;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// b 0x82144920
	sub_82144920(ctx, base);
	return;
loc_820DBBAC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,10140
	ctx.r8.s64 = 10140;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,235
	ctx.r4.s64 = 235;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// b 0x82144920
	sub_82144920(ctx, base);
	return;
loc_820DBBD4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,10135
	ctx.r8.s64 = 10135;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,233
	ctx.r4.s64 = 233;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// b 0x82144920
	sub_82144920(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820DBC00"))) PPC_WEAK_FUNC(sub_820DBC00);
PPC_FUNC_IMPL(__imp__sub_820DBC00) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,0
	r11.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// sth r11,0(r31)
	PPC_STORE_U16(r31.u32 + 0, r11.u16);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r11,11488(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 11488);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820dbc80
	if (cr6.getEQ()) goto loc_820DBC80;
	// bl 0x820db768
	sub_820DB768(ctx, base);
	// bl 0x820b30a8
	sub_820B30A8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dbc64
	if (cr6.getEQ()) goto loc_820DBC64;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41984
	ctx.r3.u64 = ctx.r3.u64 | 41984;
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ee840
	sub_823EE840(ctx, base);
loc_820DBC64:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r5,r11,15972
	ctx.r5.s64 = r11.s64 + 15972;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ee840
	sub_823EE840(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_820DBC80:
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// bgt cr6,0x820dbcbc
	if (cr6.getGT()) goto loc_820DBCBC;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41984
	ctx.r3.u64 = ctx.r3.u64 | 41984;
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ee840
	sub_823EE840(ctx, base);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820db640
	sub_820DB640(ctx, base);
loc_820DBCBC:
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820db768
	sub_820DB768(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r5,r11,17800
	ctx.r5.s64 = r11.s64 + 17800;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ee840
	sub_823EE840(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820DBCF0"))) PPC_WEAK_FUNC(sub_820DBCF0);
PPC_FUNC_IMPL(__imp__sub_820DBCF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r5,198
	ctx.r5.s64 = 198;
	// li r4,0
	ctx.r4.s64 = 0;
	// lhz r11,3292(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 3292);
	// addi r3,r1,82
	ctx.r3.s64 = ctx.r1.s64 + 82;
	// sth r11,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, r11.u16);
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,100
	ctx.r4.s64 = 100;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820dbc00
	sub_820DBC00(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820b4260
	sub_820B4260(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DBD60"))) PPC_WEAK_FUNC(sub_820DBD60);
PPC_FUNC_IMPL(__imp__sub_820DBD60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// ble cr6,0x820dbee0
	if (!cr6.getGT()) goto loc_820DBEE0;
	// bl 0x820a5590
	sub_820A5590(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820a55a8
	sub_820A55A8(ctx, base);
	// cmpw cr6,r27,r3
	cr6.compare<int32_t>(r27.s32, ctx.r3.s32, xer);
	// bge cr6,0x820dbdb4
	if (!cr6.getLT()) goto loc_820DBDB4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820a5590
	sub_820A5590(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r4,r11,r30
	ctx.r4.u64 = r11.u64 + r30.u64;
	// bl 0x820aa8e8
	sub_820AA8E8(ctx, base);
loc_820DBDB4:
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x820dbdc8
	if (cr6.getEQ()) goto loc_820DBDC8;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820dbcf0
	sub_820DBCF0(ctx, base);
loc_820DBDC8:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x820dbdd8
	if (cr6.getEQ()) goto loc_820DBDD8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820db9d0
	sub_820DB9D0(ctx, base);
loc_820DBDD8:
	// cmpwi cr6,r31,5
	cr6.compare<int32_t>(r31.s32, 5, xer);
	// bne cr6,0x820dbdf0
	if (!cr6.getEQ()) goto loc_820DBDF0;
	// li r3,26
	ctx.r3.s64 = 26;
	// bl 0x820c0e00
	sub_820C0E00(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820DBDF0:
	// cmpwi cr6,r31,7
	cr6.compare<int32_t>(r31.s32, 7, xer);
	// bne cr6,0x820dbe10
	if (!cr6.getEQ()) goto loc_820DBE10;
	// li r3,29
	ctx.r3.s64 = 29;
	// bl 0x820c0e00
	sub_820C0E00(ctx, base);
	// li r3,30
	ctx.r3.s64 = 30;
	// bl 0x820c0e00
	sub_820C0E00(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820DBE10:
	// cmpwi cr6,r31,8
	cr6.compare<int32_t>(r31.s32, 8, xer);
	// bne cr6,0x820dbe28
	if (!cr6.getEQ()) goto loc_820DBE28;
	// li r3,28
	ctx.r3.s64 = 28;
	// bl 0x820c0e00
	sub_820C0E00(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820DBE28:
	// cmpwi cr6,r31,9
	cr6.compare<int32_t>(r31.s32, 9, xer);
	// bne cr6,0x820dbe40
	if (!cr6.getEQ()) goto loc_820DBE40;
	// li r3,27
	ctx.r3.s64 = 27;
	// bl 0x820c0e00
	sub_820C0E00(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820DBE40:
	// cmpwi cr6,r31,10
	cr6.compare<int32_t>(r31.s32, 10, xer);
	// bne cr6,0x820dbe58
	if (!cr6.getEQ()) goto loc_820DBE58;
	// li r3,3
	ctx.r3.s64 = 3;
	// bl 0x820c0e00
	sub_820C0E00(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820DBE58:
	// cmpwi cr6,r31,16
	cr6.compare<int32_t>(r31.s32, 16, xer);
	// bne cr6,0x820dbe70
	if (!cr6.getEQ()) goto loc_820DBE70;
	// li r3,33
	ctx.r3.s64 = 33;
	// bl 0x820c0e00
	sub_820C0E00(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820DBE70:
	// cmpwi cr6,r31,20
	cr6.compare<int32_t>(r31.s32, 20, xer);
	// bne cr6,0x820dbe88
	if (!cr6.getEQ()) goto loc_820DBE88;
	// li r3,47
	ctx.r3.s64 = 47;
	// bl 0x820c0e00
	sub_820C0E00(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820DBE88:
	// cmpwi cr6,r31,21
	cr6.compare<int32_t>(r31.s32, 21, xer);
	// bne cr6,0x820dbea0
	if (!cr6.getEQ()) goto loc_820DBEA0;
	// li r3,48
	ctx.r3.s64 = 48;
	// bl 0x820c0e00
	sub_820C0E00(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820DBEA0:
	// cmpwi cr6,r31,22
	cr6.compare<int32_t>(r31.s32, 22, xer);
	// bne cr6,0x820dbeb8
	if (!cr6.getEQ()) goto loc_820DBEB8;
	// li r3,61
	ctx.r3.s64 = 61;
	// bl 0x820c0e00
	sub_820C0E00(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820DBEB8:
	// cmpwi cr6,r31,29
	cr6.compare<int32_t>(r31.s32, 29, xer);
	// bne cr6,0x820dbed0
	if (!cr6.getEQ()) goto loc_820DBED0;
	// li r3,88
	ctx.r3.s64 = 88;
	// bl 0x820c0e00
	sub_820C0E00(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820DBED0:
	// cmpwi cr6,r31,23
	cr6.compare<int32_t>(r31.s32, 23, xer);
	// bne cr6,0x820dbee0
	if (!cr6.getEQ()) goto loc_820DBEE0;
	// li r3,34
	ctx.r3.s64 = 34;
	// bl 0x820c0e00
	sub_820C0E00(ctx, base);
loc_820DBEE0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820DBEE8"))) PPC_WEAK_FUNC(sub_820DBEE8);
PPC_FUNC_IMPL(__imp__sub_820DBEE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,128(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 128);
	// li r31,1
	r31.s64 = 1;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplwi cr6,r11,13
	cr6.compare<uint32_t>(r11.u32, 13, xer);
	// bgt cr6,0x820dbfb8
	if (cr6.getGT()) goto loc_820DBFB8;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-16604
	r12.s64 = r12.s64 + -16604;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820DBF5C;
	case 1:
		goto loc_820DBF5C;
	case 2:
		goto loc_820DBF5C;
	case 3:
		goto loc_820DBF64;
	case 4:
		goto loc_820DBFB8;
	case 5:
		goto loc_820DBFB8;
	case 6:
		goto loc_820DBFB8;
	case 7:
		goto loc_820DBFB8;
	case 8:
		goto loc_820DBFB8;
	case 9:
		goto loc_820DBFB8;
	case 10:
		goto loc_820DBFB8;
	case 11:
		goto loc_820DBF64;
	case 12:
		goto loc_820DBF6C;
	case 13:
		goto loc_820DBF74;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-16548(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16548);
	// lwz r16,-16548(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16548);
	// lwz r16,-16548(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16548);
	// lwz r16,-16540(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16540);
	// lwz r16,-16456(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16456);
	// lwz r16,-16456(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16456);
	// lwz r16,-16456(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16456);
	// lwz r16,-16456(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16456);
	// lwz r16,-16456(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16456);
	// lwz r16,-16456(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16456);
	// lwz r16,-16456(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16456);
	// lwz r16,-16540(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16540);
	// lwz r16,-16532(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16532);
	// lwz r16,-16524(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16524);
loc_820DBF5C:
	// li r31,10
	r31.s64 = 10;
	// b 0x820dbf78
	goto loc_820DBF78;
loc_820DBF64:
	// li r31,5
	r31.s64 = 5;
	// b 0x820dbf78
	goto loc_820DBF78;
loc_820DBF6C:
	// li r31,3
	r31.s64 = 3;
	// b 0x820dbf78
	goto loc_820DBF78;
loc_820DBF74:
	// li r31,4
	r31.s64 = 4;
loc_820DBF78:
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x820dbfb8
	if (!cr6.getEQ()) goto loc_820DBFB8;
	// extsw r11,r31
	r11.s64 = r31.s32;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f13,f0
	ctx.f13.f64 = double(float(f0.f64));
	// lfs f0,19428(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 19428);
	f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, f0.u32);
	// lwz r31,80(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_820DBFB8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DBFD0"))) PPC_WEAK_FUNC(sub_820DBFD0);
PPC_FUNC_IMPL(__imp__sub_820DBFD0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lbz r11,128(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 128);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x820a55e0
	sub_820A55E0(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r31,1
	r31.s64 = 1;
	// rlwinm r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dc01c
	if (cr6.getEQ()) goto loc_820DC01C;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_820DC01C:
	// addi r11,r3,-1
	r11.s64 = ctx.r3.s64 + -1;
	// cmplwi cr6,r11,13
	cr6.compare<uint32_t>(r11.u32, 13, xer);
	// bgt cr6,0x820dc0d4
	if (cr6.getGT()) goto loc_820DC0D4;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-16320
	r12.s64 = r12.s64 + -16320;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820DC078;
	case 1:
		goto loc_820DC078;
	case 2:
		goto loc_820DC078;
	case 3:
		goto loc_820DC080;
	case 4:
		goto loc_820DC0D4;
	case 5:
		goto loc_820DC0D4;
	case 6:
		goto loc_820DC0D4;
	case 7:
		goto loc_820DC0D4;
	case 8:
		goto loc_820DC0D4;
	case 9:
		goto loc_820DC0D4;
	case 10:
		goto loc_820DC090;
	case 11:
		goto loc_820DC080;
	case 12:
		goto loc_820DC090;
	case 13:
		goto loc_820DC088;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-16264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16264);
	// lwz r16,-16264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16264);
	// lwz r16,-16264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16264);
	// lwz r16,-16256(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16256);
	// lwz r16,-16172(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16172);
	// lwz r16,-16172(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16172);
	// lwz r16,-16172(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16172);
	// lwz r16,-16172(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16172);
	// lwz r16,-16172(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16172);
	// lwz r16,-16172(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16172);
	// lwz r16,-16240(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16240);
	// lwz r16,-16256(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16256);
	// lwz r16,-16240(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16240);
	// lwz r16,-16248(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -16248);
loc_820DC078:
	// li r31,10
	r31.s64 = 10;
	// b 0x820dc094
	goto loc_820DC094;
loc_820DC080:
	// li r31,5
	r31.s64 = 5;
	// b 0x820dc094
	goto loc_820DC094;
loc_820DC088:
	// li r31,4
	r31.s64 = 4;
	// b 0x820dc094
	goto loc_820DC094;
loc_820DC090:
	// li r31,3
	r31.s64 = 3;
loc_820DC094:
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x820dc0d4
	if (!cr6.getEQ()) goto loc_820DC0D4;
	// extsw r11,r31
	r11.s64 = r31.s32;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lfd f0,88(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f13,f0
	ctx.f13.f64 = double(float(f0.f64));
	// lfs f0,19428(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 19428);
	f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, f0.u32);
	// lwz r31,80(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_820DC0D4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DC0F0"))) PPC_WEAK_FUNC(sub_820DC0F0);
PPC_FUNC_IMPL(__imp__sub_820DC0F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r27,0
	r27.s64 = 0;
	// lwz r11,11488(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 11488);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820dc140
	if (cr6.getEQ()) goto loc_820DC140;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r5,r11,3292
	ctx.r5.s64 = r11.s64 + 3292;
	// bl 0x823edad0
	sub_823EDAD0(ctx, base);
	// bl 0x820b30a8
	sub_820B30A8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820dc178
	if (!cr6.getEQ()) goto loc_820DC178;
	// li r27,1
	r27.s64 = 1;
	// b 0x820dc178
	goto loc_820DC178;
loc_820DC140:
	// bl 0x820b30a8
	sub_820B30A8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dc164
	if (cr6.getEQ()) goto loc_820DC164;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41984
	ctx.r3.u64 = ctx.r3.u64 | 41984;
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// b 0x820dc16c
	goto loc_820DC16C;
loc_820DC164:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r5,r11,3292
	ctx.r5.s64 = r11.s64 + 3292;
loc_820DC16C:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823edad0
	sub_823EDAD0(ctx, base);
loc_820DC178:
	// addi r11,r29,-2
	r11.s64 = r29.s64 + -2;
	// cmplwi cr6,r11,86
	cr6.compare<uint32_t>(r11.u32, 86, xer);
	// bgt cr6,0x820dc460
	if (cr6.getGT()) goto loc_820DC460;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-15972
	r12.s64 = r12.s64 + -15972;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820DC31C;
	case 1:
		goto loc_820DC2F8;
	case 2:
		goto loc_820DC328;
	case 3:
		goto loc_820DC334;
	case 4:
		goto loc_820DC340;
	case 5:
		goto loc_820DC34C;
	case 6:
		goto loc_820DC358;
	case 7:
		goto loc_820DC364;
	case 8:
		goto loc_820DC370;
	case 9:
		goto loc_820DC37C;
	case 10:
		goto loc_820DC388;
	case 11:
		goto loc_820DC394;
	case 12:
		goto loc_820DC3A0;
	case 13:
		goto loc_820DC3AC;
	case 14:
		goto loc_820DC3B8;
	case 15:
		goto loc_820DC3C4;
	case 16:
		goto loc_820DC3E8;
	case 17:
		goto loc_820DC3F4;
	case 18:
		goto loc_820DC424;
	case 19:
		goto loc_820DC430;
	case 20:
		goto loc_820DC400;
	case 21:
		goto loc_820DC460;
	case 22:
		goto loc_820DC3D0;
	case 23:
		goto loc_820DC3DC;
	case 24:
		goto loc_820DC2F8;
	case 25:
		goto loc_820DC2F8;
	case 26:
		goto loc_820DC2F8;
	case 27:
		goto loc_820DC2F8;
	case 28:
		goto loc_820DC460;
	case 29:
		goto loc_820DC460;
	case 30:
		goto loc_820DC460;
	case 31:
		goto loc_820DC2F8;
	case 32:
		goto loc_820DC2F8;
	case 33:
		goto loc_820DC40C;
	case 34:
		goto loc_820DC418;
	case 35:
		goto loc_820DC460;
	case 36:
		goto loc_820DC460;
	case 37:
		goto loc_820DC460;
	case 38:
		goto loc_820DC460;
	case 39:
		goto loc_820DC460;
	case 40:
		goto loc_820DC460;
	case 41:
		goto loc_820DC460;
	case 42:
		goto loc_820DC460;
	case 43:
		goto loc_820DC460;
	case 44:
		goto loc_820DC460;
	case 45:
		goto loc_820DC2F8;
	case 46:
		goto loc_820DC2F8;
	case 47:
		goto loc_820DC460;
	case 48:
		goto loc_820DC460;
	case 49:
		goto loc_820DC460;
	case 50:
		goto loc_820DC460;
	case 51:
		goto loc_820DC460;
	case 52:
		goto loc_820DC460;
	case 53:
		goto loc_820DC460;
	case 54:
		goto loc_820DC460;
	case 55:
		goto loc_820DC460;
	case 56:
		goto loc_820DC460;
	case 57:
		goto loc_820DC460;
	case 58:
		goto loc_820DC460;
	case 59:
		goto loc_820DC2F8;
	case 60:
		goto loc_820DC460;
	case 61:
		goto loc_820DC460;
	case 62:
		goto loc_820DC460;
	case 63:
		goto loc_820DC460;
	case 64:
		goto loc_820DC460;
	case 65:
		goto loc_820DC460;
	case 66:
		goto loc_820DC460;
	case 67:
		goto loc_820DC460;
	case 68:
		goto loc_820DC460;
	case 69:
		goto loc_820DC460;
	case 70:
		goto loc_820DC460;
	case 71:
		goto loc_820DC460;
	case 72:
		goto loc_820DC460;
	case 73:
		goto loc_820DC460;
	case 74:
		goto loc_820DC460;
	case 75:
		goto loc_820DC460;
	case 76:
		goto loc_820DC460;
	case 77:
		goto loc_820DC460;
	case 78:
		goto loc_820DC460;
	case 79:
		goto loc_820DC43C;
	case 80:
		goto loc_820DC448;
	case 81:
		goto loc_820DC454;
	case 82:
		goto loc_820DC460;
	case 83:
		goto loc_820DC460;
	case 84:
		goto loc_820DC2F8;
	case 85:
		goto loc_820DC2F8;
	case 86:
		goto loc_820DC2F8;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-15588(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15588);
	// lwz r16,-15624(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15624);
	// lwz r16,-15576(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15576);
	// lwz r16,-15564(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15564);
	// lwz r16,-15552(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15552);
	// lwz r16,-15540(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15540);
	// lwz r16,-15528(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15528);
	// lwz r16,-15516(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15516);
	// lwz r16,-15504(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15504);
	// lwz r16,-15492(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15492);
	// lwz r16,-15480(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15480);
	// lwz r16,-15468(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15468);
	// lwz r16,-15456(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15456);
	// lwz r16,-15444(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15444);
	// lwz r16,-15432(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15432);
	// lwz r16,-15420(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15420);
	// lwz r16,-15384(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15384);
	// lwz r16,-15372(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15372);
	// lwz r16,-15324(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15324);
	// lwz r16,-15312(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15312);
	// lwz r16,-15360(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15360);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15408(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15408);
	// lwz r16,-15396(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15396);
	// lwz r16,-15624(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15624);
	// lwz r16,-15624(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15624);
	// lwz r16,-15624(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15624);
	// lwz r16,-15624(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15624);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15624(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15624);
	// lwz r16,-15624(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15624);
	// lwz r16,-15348(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15348);
	// lwz r16,-15336(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15336);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15624(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15624);
	// lwz r16,-15624(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15624);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15624(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15624);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15300(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15300);
	// lwz r16,-15288(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15288);
	// lwz r16,-15276(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15276);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15264(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15264);
	// lwz r16,-15624(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15624);
	// lwz r16,-15624(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15624);
	// lwz r16,-15624(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -15624);
loc_820DC2F8:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820a55e0
	sub_820A55E0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// bl 0x820dbc00
	sub_820DBC00(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820DC31C:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42016
	ctx.r3.u64 = ctx.r3.u64 | 42016;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC328:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42017
	ctx.r3.u64 = ctx.r3.u64 | 42017;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC334:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42018
	ctx.r3.u64 = ctx.r3.u64 | 42018;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC340:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42019
	ctx.r3.u64 = ctx.r3.u64 | 42019;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC34C:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42020
	ctx.r3.u64 = ctx.r3.u64 | 42020;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC358:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42021
	ctx.r3.u64 = ctx.r3.u64 | 42021;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC364:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42022
	ctx.r3.u64 = ctx.r3.u64 | 42022;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC370:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42023
	ctx.r3.u64 = ctx.r3.u64 | 42023;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC37C:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42024
	ctx.r3.u64 = ctx.r3.u64 | 42024;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC388:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42025
	ctx.r3.u64 = ctx.r3.u64 | 42025;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC394:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42026
	ctx.r3.u64 = ctx.r3.u64 | 42026;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC3A0:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42027
	ctx.r3.u64 = ctx.r3.u64 | 42027;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC3AC:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42028
	ctx.r3.u64 = ctx.r3.u64 | 42028;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC3B8:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42029
	ctx.r3.u64 = ctx.r3.u64 | 42029;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC3C4:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42030
	ctx.r3.u64 = ctx.r3.u64 | 42030;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC3D0:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42031
	ctx.r3.u64 = ctx.r3.u64 | 42031;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC3DC:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42032
	ctx.r3.u64 = ctx.r3.u64 | 42032;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC3E8:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42033
	ctx.r3.u64 = ctx.r3.u64 | 42033;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC3F4:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42034
	ctx.r3.u64 = ctx.r3.u64 | 42034;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC400:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42035
	ctx.r3.u64 = ctx.r3.u64 | 42035;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC40C:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42036
	ctx.r3.u64 = ctx.r3.u64 | 42036;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC418:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42037
	ctx.r3.u64 = ctx.r3.u64 | 42037;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC424:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42038
	ctx.r3.u64 = ctx.r3.u64 | 42038;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC430:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42039
	ctx.r3.u64 = ctx.r3.u64 | 42039;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC43C:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42040
	ctx.r3.u64 = ctx.r3.u64 | 42040;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC448:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42041
	ctx.r3.u64 = ctx.r3.u64 | 42041;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC454:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42042
	ctx.r3.u64 = ctx.r3.u64 | 42042;
	// b 0x820dc468
	goto loc_820DC468;
loc_820DC460:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42043
	ctx.r3.u64 = ctx.r3.u64 | 42043;
loc_820DC468:
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ee840
	sub_823EE840(ctx, base);
	// lwz r11,11488(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 11488);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820dc4f4
	if (cr6.getEQ()) goto loc_820DC4F4;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x820dc4f4
	if (!cr6.getEQ()) goto loc_820DC4F4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823edbb8
	sub_823EDBB8(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lhz r11,-2(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + -2);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// bne cr6,0x820dc4c4
	if (!cr6.getEQ()) goto loc_820DC4C4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823edbb8
	sub_823EDBB8(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// li r10,0
	ctx.r10.s64 = 0;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// sth r10,-2(r11)
	PPC_STORE_U16(r11.u32 + -2, ctx.r10.u16);
loc_820DC4C4:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,41984
	ctx.r3.u64 = ctx.r3.u64 | 41984;
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ee840
	sub_823EE840(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r5,r11,15972
	ctx.r5.s64 = r11.s64 + 15972;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ee840
	sub_823EE840(ctx, base);
loc_820DC4F4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820DC500"))) PPC_WEAK_FUNC(sub_820DC500);
PPC_FUNC_IMPL(__imp__sub_820DC500) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,100
	ctx.r4.s64 = 100;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820dc0f0
	sub_820DC0F0(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820b4260
	sub_820B4260(ctx, base);
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DC538"))) PPC_WEAK_FUNC(sub_820DC538);
PPC_FUNC_IMPL(__imp__sub_820DC538) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,1(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1);
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dc5e0
	if (cr6.getEQ()) goto loc_820DC5E0;
	// lwz r28,8(r3)
	r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r3,20(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// bl 0x82118c20
	sub_82118C20(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,56(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,8(r29)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r29.u32 + 8, temp.u32);
	// lfs f0,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820dc5e0
	if (!cr6.getLT()) goto loc_820DC5E0;
	// lfs f13,48(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// lwz r28,20(r28)
	r28.u64 = PPC_LOAD_U32(r28.u32 + 20);
	// stfs f13,0(r29)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// addi r4,r31,4
	ctx.r4.s64 = r31.s64 + 4;
	// lfs f13,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// stfs f13,4(r29)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r29.u32 + 4, temp.u32);
	// li r6,0
	ctx.r6.s64 = 0;
	// stfs f0,4(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 4, temp.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// stfs f0,0(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 0, temp.u32);
	// stfs f0,4(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// stfs f0,0(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// addi r31,r30,4
	r31.s64 = r30.s64 + 4;
	// bl 0x820d43e8
	sub_820D43E8(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x820d43e8
	sub_820D43E8(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_820DC5E0:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820DC5F0"))) PPC_WEAK_FUNC(sub_820DC5F0);
PPC_FUNC_IMPL(__imp__sub_820DC5F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820dc69c
	if (cr6.getEQ()) goto loc_820DC69C;
loc_820DC618:
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// beq cr6,0x820dc654
	if (cr6.getEQ()) goto loc_820DC654;
	// cmpwi cr6,r11,18
	cr6.compare<int32_t>(r11.s32, 18, xer);
	// beq cr6,0x820dc644
	if (cr6.getEQ()) goto loc_820DC644;
	// cmpwi cr6,r11,23
	cr6.compare<int32_t>(r11.s32, 23, xer);
	// bne cr6,0x820dc660
	if (!cr6.getEQ()) goto loc_820DC660;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8211ac30
	sub_8211AC30(ctx, base);
	// b 0x820dc660
	goto loc_820DC660;
loc_820DC644:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8211abd8
	sub_8211ABD8(ctx, base);
	// b 0x820dc660
	goto loc_820DC660;
loc_820DC654:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8211ab80
	sub_8211AB80(ctx, base);
loc_820DC660:
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dc674
	if (cr6.getEQ()) goto loc_820DC674;
	// mr r31,r11
	r31.u64 = r11.u64;
	// b 0x820dc694
	goto loc_820DC694;
loc_820DC674:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820dc690
	if (!cr6.getEQ()) goto loc_820DC690;
	// lwz r31,8(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x820dc674
	if (!cr6.getEQ()) goto loc_820DC674;
	// b 0x820dc69c
	goto loc_820DC69C;
loc_820DC690:
	// lwz r31,12(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 12);
loc_820DC694:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x820dc618
	if (!cr6.getEQ()) goto loc_820DC618;
loc_820DC69C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DC6B8"))) PPC_WEAK_FUNC(sub_820DC6B8);
PPC_FUNC_IMPL(__imp__sub_820DC6B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// mr r6,r7
	ctx.r6.u64 = ctx.r7.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x820d4df0
	sub_820D4DF0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820dc75c
	if (cr6.getEQ()) goto loc_820DC75C;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dc75c
	if (cr6.getEQ()) goto loc_820DC75C;
	// lhz r11,0(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 0);
	// lwz r3,20(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// lfs f13,20(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,80(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f12,f0
	ctx.f12.f64 = double(float(f0.f64));
	// lfs f0,16604(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16604);
	f0.f64 = double(temp.f32);
	// fmuls f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * f0.f64));
	// fmuls f1,f0,f13
	ctx.f1.f64 = double(float(f0.f64 * ctx.f13.f64));
	// bl 0x823ada90
	sub_823ADA90(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r10,28(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// stw r10,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r10.u32);
	// lwz r11,28(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// stw r11,28(r10)
	PPC_STORE_U32(ctx.r10.u32 + 28, r11.u32);
	// lwz r4,24(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 24);
	// bl 0x820ccc18
	sub_820CCC18(ctx, base);
	// stw r30,472(r29)
	PPC_STORE_U32(r29.u32 + 472, r30.u32);
loc_820DC75C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820DC768"))) PPC_WEAK_FUNC(sub_820DC768);
PPC_FUNC_IMPL(__imp__sub_820DC768) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r11,116(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 116);
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 4);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// extsh r30,r10
	r30.s64 = ctx.r10.s16;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f13,f0
	ctx.f13.f64 = double(float(f0.f64));
	// lfs f0,15620(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15620);
	f0.f64 = double(temp.f32);
	// lis r11,-32142
	r11.s64 = -2106458112;
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,116(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 116, temp.u32);
	// lwz r11,30148(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 30148);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x820dc7c0
	if (cr6.getEQ()) goto loc_820DC7C0;
	// mr r30,r11
	r30.u64 = r11.u64;
loc_820DC7C0:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820d03e8
	sub_820D03E8(ctx, base);
	// lis r11,-32164
	r11.s64 = -2107899904;
	// rlwinm r10,r30,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r11,r11,-3616
	r11.s64 = r11.s64 + -3616;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r5,r10,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// bl 0x820dc6b8
	sub_820DC6B8(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820DC7F8"))) PPC_WEAK_FUNC(sub_820DC7F8);
PPC_FUNC_IMPL(__imp__sub_820DC7F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r9,1
	ctx.r9.s64 = 1;
	// li r8,11241
	ctx.r8.s64 = 11241;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,229
	ctx.r4.s64 = 229;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// slw r9,r9,r10
	ctx.r9.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r10.u8 & 0x3F));
	// lwz r10,17284(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 17284);
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// stw r10,17284(r11)
	PPC_STORE_U32(r11.u32 + 17284, ctx.r10.u32);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DC860"))) PPC_WEAK_FUNC(sub_820DC860);
PPC_FUNC_IMPL(__imp__sub_820DC860) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bne cr6,0x820dc898
	if (!cr6.getEQ()) goto loc_820DC898;
	// lwz r3,8(r4)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// lbz r11,128(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 128);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpw cr6,r11,r30
	cr6.compare<int32_t>(r11.s32, r30.s32, xer);
	// beq cr6,0x820dc8c8
	if (cr6.getEQ()) goto loc_820DC8C8;
loc_820DC898:
	// lwz r31,36(r4)
	r31.u64 = PPC_LOAD_U32(ctx.r4.u32 + 36);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820dc8c4
	if (cr6.getEQ()) goto loc_820DC8C4;
loc_820DC8A4:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820dc860
	sub_820DC860(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x820dc8c8
	if (!cr6.getEQ()) goto loc_820DC8C8;
	// lwz r31,40(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x820dc8a4
	if (!cr6.getEQ()) goto loc_820DC8A4;
loc_820DC8C4:
	// li r3,0
	ctx.r3.s64 = 0;
loc_820DC8C8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DC8E0"))) PPC_WEAK_FUNC(sub_820DC8E0);
PPC_FUNC_IMPL(__imp__sub_820DC8E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x820cca38
	sub_820CCA38(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820dc934
	if (cr6.getEQ()) goto loc_820DC934;
loc_820DC904:
	// mr r4,r10
	ctx.r4.u64 = ctx.r10.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820dc860
	sub_820DC860(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820dc928
	if (cr6.getEQ()) goto loc_820DC928;
	// lwz r11,100(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 100);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dc938
	if (cr6.getEQ()) goto loc_820DC938;
loc_820DC928:
	// lwz r10,40(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820dc904
	if (!cr6.getEQ()) goto loc_820DC904;
loc_820DC934:
	// li r3,0
	ctx.r3.s64 = 0;
loc_820DC938:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DC950"))) PPC_WEAK_FUNC(sub_820DC950);
PPC_FUNC_IMPL(__imp__sub_820DC950) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32013
	r11.s64 = -2098003968;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r11,2288
	ctx.r8.s64 = r11.s64 + 2288;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r10,r8,4
	ctx.r10.s64 = ctx.r8.s64 + 4;
	// lfs f0,17808(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17808);
	f0.f64 = double(temp.f32);
loc_820DC968:
	// lwz r11,-4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dc9bc
	if (cr6.getEQ()) goto loc_820DC9BC;
	// lhz r7,130(r11)
	ctx.r7.u64 = PPC_LOAD_U16(r11.u32 + 130);
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// bne cr6,0x820dc9bc
	if (!cr6.getEQ()) goto loc_820DC9BC;
	// lfs f12,92(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f11,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,96(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// lfs f10,88(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fmuls f13,f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// fmadds f13,f12,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + ctx.f13.f64));
	// fmadds f13,f11,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f11.f64 + ctx.f13.f64));
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820dc9bc
	if (!cr6.getLT()) goto loc_820DC9BC;
	// sth r9,130(r11)
	PPC_STORE_U16(r11.u32 + 130, ctx.r9.u16);
loc_820DC9BC:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dca10
	if (cr6.getEQ()) goto loc_820DCA10;
	// lhz r7,130(r11)
	ctx.r7.u64 = PPC_LOAD_U16(r11.u32 + 130);
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// bne cr6,0x820dca10
	if (!cr6.getEQ()) goto loc_820DCA10;
	// lfs f12,92(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f11,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,96(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// lfs f10,88(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fmuls f13,f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// fmadds f13,f12,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + ctx.f13.f64));
	// fmadds f13,f11,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f11.f64 + ctx.f13.f64));
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820dca10
	if (!cr6.getLT()) goto loc_820DCA10;
	// sth r9,130(r11)
	PPC_STORE_U16(r11.u32 + 130, ctx.r9.u16);
loc_820DCA10:
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dca64
	if (cr6.getEQ()) goto loc_820DCA64;
	// lhz r7,130(r11)
	ctx.r7.u64 = PPC_LOAD_U16(r11.u32 + 130);
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// bne cr6,0x820dca64
	if (!cr6.getEQ()) goto loc_820DCA64;
	// lfs f12,92(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f11,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,96(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// lfs f10,88(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fmuls f13,f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// fmadds f13,f12,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + ctx.f13.f64));
	// fmadds f13,f11,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f11.f64 + ctx.f13.f64));
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820dca64
	if (!cr6.getLT()) goto loc_820DCA64;
	// sth r9,130(r11)
	PPC_STORE_U16(r11.u32 + 130, ctx.r9.u16);
loc_820DCA64:
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dcab8
	if (cr6.getEQ()) goto loc_820DCAB8;
	// lhz r7,130(r11)
	ctx.r7.u64 = PPC_LOAD_U16(r11.u32 + 130);
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// bne cr6,0x820dcab8
	if (!cr6.getEQ()) goto loc_820DCAB8;
	// lfs f12,92(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f11,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,96(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// lfs f10,88(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fmuls f13,f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// fmadds f13,f12,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + ctx.f13.f64));
	// fmadds f13,f11,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f11.f64 + ctx.f13.f64));
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820dcab8
	if (!cr6.getLT()) goto loc_820DCAB8;
	// sth r9,130(r11)
	PPC_STORE_U16(r11.u32 + 130, ctx.r9.u16);
loc_820DCAB8:
	// lwz r11,12(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dcb0c
	if (cr6.getEQ()) goto loc_820DCB0C;
	// lhz r7,130(r11)
	ctx.r7.u64 = PPC_LOAD_U16(r11.u32 + 130);
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// bne cr6,0x820dcb0c
	if (!cr6.getEQ()) goto loc_820DCB0C;
	// lfs f12,92(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f11,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,96(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// lfs f10,88(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fmuls f13,f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// fmadds f13,f12,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + ctx.f13.f64));
	// fmadds f13,f11,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f11.f64 + ctx.f13.f64));
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820dcb0c
	if (!cr6.getLT()) goto loc_820DCB0C;
	// sth r9,130(r11)
	PPC_STORE_U16(r11.u32 + 130, ctx.r9.u16);
loc_820DCB0C:
	// lwz r11,16(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dcb60
	if (cr6.getEQ()) goto loc_820DCB60;
	// lhz r7,130(r11)
	ctx.r7.u64 = PPC_LOAD_U16(r11.u32 + 130);
	// cmplwi cr6,r7,1
	cr6.compare<uint32_t>(ctx.r7.u32, 1, xer);
	// bne cr6,0x820dcb60
	if (!cr6.getEQ()) goto loc_820DCB60;
	// lfs f12,92(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f11,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,96(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// lfs f10,88(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 88);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// fmuls f13,f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// fmadds f13,f12,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + ctx.f13.f64));
	// fmadds f13,f11,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f11.f64 + ctx.f13.f64));
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820dcb60
	if (!cr6.getLT()) goto loc_820DCB60;
	// sth r9,130(r11)
	PPC_STORE_U16(r11.u32 + 130, ctx.r9.u16);
loc_820DCB60:
	// addi r10,r10,24
	ctx.r10.s64 = ctx.r10.s64 + 24;
	// addi r11,r8,124
	r11.s64 = ctx.r8.s64 + 124;
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// blt cr6,0x820dc968
	if (cr6.getLT()) goto loc_820DC968;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DCB78"))) PPC_WEAK_FUNC(sub_820DCB78);
PPC_FUNC_IMPL(__imp__sub_820DCB78) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x8211dd88
	sub_8211DD88(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x820dcbe0
	if (!cr6.getGT()) goto loc_820DCBE0;
	// li r31,0
	r31.s64 = 0;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lis r29,-31994
	r29.s64 = -2096758784;
loc_820DCB9C:
	// lwz r11,4852(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4852);
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// lwz r11,28(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dcbd0
	if (cr6.getEQ()) goto loc_820DCBD0;
	// lhz r11,18(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 18);
	// rlwinm r11,r11,0,22,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dcbd0
	if (cr6.getEQ()) goto loc_820DCBD0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82122a58
	sub_82122A58(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820dc950
	sub_820DC950(ctx, base);
loc_820DCBD0:
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// addi r31,r31,676
	r31.s64 = r31.s64 + 676;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x820dcb9c
	if (!cr6.getEQ()) goto loc_820DCB9C;
loc_820DCBE0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820DCBE8"))) PPC_WEAK_FUNC(sub_820DCBE8);
PPC_FUNC_IMPL(__imp__sub_820DCBE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lbz r11,128(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 128);
	// lbz r10,128(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 128);
	// stw r4,132(r3)
	PPC_STORE_U32(ctx.r3.u32 + 132, ctx.r4.u32);
	// stb r11,129(r3)
	PPC_STORE_U8(ctx.r3.u32 + 129, r11.u8);
	// stb r10,129(r4)
	PPC_STORE_U8(ctx.r4.u32 + 129, ctx.r10.u8);
	// stw r3,132(r4)
	PPC_STORE_U32(ctx.r4.u32 + 132, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DCC08"))) PPC_WEAK_FUNC(sub_820DCC08);
PPC_FUNC_IMPL(__imp__sub_820DCC08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r10,16(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// rlwinm r9,r11,4,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820dccd8
	if (cr6.getEQ()) goto loc_820DCCD8;
	// lwz r10,20(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820dccd8
	if (cr6.getEQ()) goto loc_820DCCD8;
	// rlwinm r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820dcccc
	if (!cr6.getEQ()) goto loc_820DCCCC;
	// addi r11,r9,88
	r11.s64 = ctx.r9.s64 + 88;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r11,r4
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820dccec
	if (!cr6.getEQ()) goto loc_820DCCEC;
	// lwz r8,28(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// stw r8,24(r10)
	PPC_STORE_U32(ctx.r10.u32 + 24, ctx.r8.u32);
	// lwz r10,28(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 28);
	// lwz r8,20(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// bne cr6,0x820dcc7c
	if (!cr6.getEQ()) goto loc_820DCC7C;
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// b 0x820dcc80
	goto loc_820DCC80;
loc_820DCC7C:
	// lwz r10,20(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
loc_820DCC80:
	// stw r10,28(r8)
	PPC_STORE_U32(ctx.r8.u32 + 28, ctx.r10.u32);
	// lwz r10,16(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// stwx r10,r11,r4
	PPC_STORE_U32(r11.u32 + ctx.r4.u32, ctx.r10.u32);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// rlwinm r11,r11,0,0,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dcccc
	if (cr6.getEQ()) goto loc_820DCCCC;
	// subfic r11,r9,89
	xer.ca = ctx.r9.u32 <= 89;
	r11.s64 = 89 - ctx.r9.s64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r4
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dcccc
	if (cr6.getEQ()) goto loc_820DCCCC;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lbz r10,128(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 128);
	// lbz r9,128(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 128);
	// stw r11,132(r3)
	PPC_STORE_U32(ctx.r3.u32 + 132, r11.u32);
	// stb r9,129(r3)
	PPC_STORE_U8(ctx.r3.u32 + 129, ctx.r9.u8);
	// stb r10,129(r11)
	PPC_STORE_U8(r11.u32 + 129, ctx.r10.u8);
	// stw r3,132(r11)
	PPC_STORE_U32(r11.u32 + 132, ctx.r3.u32);
loc_820DCCCC:
	// lwz r4,24(r4)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r4.u32 + 24);
	// lwz r3,16(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	// bl 0x820ccc18
	sub_820CCC18(ctx, base);
loc_820DCCD8:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820DCCEC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r11,17812
	ctx.r3.s64 = r11.s64 + 17812;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DCD10"))) PPC_WEAK_FUNC(sub_820DCD10);
PPC_FUNC_IMPL(__imp__sub_820DCD10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// addi r11,r4,88
	r11.s64 = ctx.r4.s64 + 88;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r11,r3
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// rotlwi r11,r10,0
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,100(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 100);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// stw r10,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DCD40"))) PPC_WEAK_FUNC(sub_820DCD40);
PPC_FUNC_IMPL(__imp__sub_820DCD40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r31,8(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82120290
	sub_82120290(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820dce58
	if (cr6.getEQ()) goto loc_820DCE58;
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// lwz r9,100(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 100);
	// rlwinm r9,r9,0,20,20
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x800;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820dce4c
	if (!cr6.getEQ()) goto loc_820DCE4C;
	// lwz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwinm r9,r9,0,12,12
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x80000;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820dce4c
	if (!cr6.getEQ()) goto loc_820DCE4C;
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// lwz r31,20(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// li r11,0
	r11.s64 = 0;
	// lbz r8,1(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// addi r9,r1,124
	ctx.r9.s64 = ctx.r1.s64 + 124;
	// li r5,0
	ctx.r5.s64 = 0;
	// ori r8,r8,2
	ctx.r8.u64 = ctx.r8.u64 | 2;
	// stw r7,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r7.u32);
	// li r7,3
	ctx.r7.s64 = 3;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// stw r7,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r7.u32);
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r11.u32);
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// stb r8,1(r10)
	PPC_STORE_U8(ctx.r10.u32 + 1, ctx.r8.u8);
	// lwz r4,28(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// bl 0x82118bc8
	sub_82118BC8(ctx, base);
	// stw r3,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r3.u32);
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// bne cr6,0x820dce24
	if (!cr6.getEQ()) goto loc_820DCE24;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lfs f1,14032(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14032);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210b968
	sub_8210B968(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
loc_820DCE24:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lhz r11,14(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 14);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// rlwinm r3,r11,6,0,25
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0xFFFFFFC0;
	// bl 0x8209cd50
	sub_8209CD50(ctx, base);
	// stw r3,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r3.u32);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8211d300
	sub_8211D300(ctx, base);
	// b 0x820dce58
	goto loc_820DCE58;
loc_820DCE4C:
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// andi. r11,r11,253
	r11.u64 = r11.u64 & 253;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stb r11,1(r10)
	PPC_STORE_U8(ctx.r10.u32 + 1, r11.u8);
loc_820DCE58:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DCE70"))) PPC_WEAK_FUNC(sub_820DCE70);
PPC_FUNC_IMPL(__imp__sub_820DCE70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r31,20(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820dcef4
	if (cr6.getEQ()) goto loc_820DCEF4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lis r10,-32164
	ctx.r10.s64 = -2107899904;
	// addi r10,r10,3456
	ctx.r10.s64 = ctx.r10.s64 + 3456;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x820dcef4
	if (!cr6.getEQ()) goto loc_820DCEF4;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820dced0
	if (cr6.getEQ()) goto loc_820DCED0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// sth r30,0(r3)
	PPC_STORE_U16(ctx.r3.u32 + 0, r30.u16);
loc_820DCED0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820dcef4
	if (cr6.getEQ()) goto loc_820DCEF4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_820DCEF4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DCF10"))) PPC_WEAK_FUNC(sub_820DCF10);
PPC_FUNC_IMPL(__imp__sub_820DCF10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lhz r11,4(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 4);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// addi r11,r11,-212
	r11.s64 = r11.s64 + -212;
	// cmplwi cr6,r11,11
	cr6.compare<uint32_t>(r11.u32, 11, xer);
	// bgt cr6,0x820dcfa0
	if (cr6.getGT()) goto loc_820DCFA0;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-12480
	r12.s64 = r12.s64 + -12480;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820DCF70;
	case 1:
		goto loc_820DCF70;
	case 2:
		goto loc_820DCF70;
	case 3:
		goto loc_820DCF78;
	case 4:
		goto loc_820DCF78;
	case 5:
		goto loc_820DCF80;
	case 6:
		goto loc_820DCF80;
	case 7:
		goto loc_820DCF88;
	case 8:
		goto loc_820DCF90;
	case 9:
		goto loc_820DCF90;
	case 10:
		goto loc_820DCF90;
	case 11:
		goto loc_820DCF98;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-12432(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -12432);
	// lwz r16,-12432(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -12432);
	// lwz r16,-12432(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -12432);
	// lwz r16,-12424(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -12424);
	// lwz r16,-12424(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -12424);
	// lwz r16,-12416(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -12416);
	// lwz r16,-12416(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -12416);
	// lwz r16,-12408(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -12408);
	// lwz r16,-12400(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -12400);
	// lwz r16,-12400(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -12400);
	// lwz r16,-12400(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -12400);
	// lwz r16,-12392(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -12392);
loc_820DCF70:
	// li r3,4
	ctx.r3.s64 = 4;
	// blr 
	return;
loc_820DCF78:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_820DCF80:
	// li r3,3
	ctx.r3.s64 = 3;
	// blr 
	return;
loc_820DCF88:
	// li r3,5
	ctx.r3.s64 = 5;
	// blr 
	return;
loc_820DCF90:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_820DCF98:
	// li r3,2
	ctx.r3.s64 = 2;
	// blr 
	return;
loc_820DCFA0:
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DCFA8"))) PPC_WEAK_FUNC(sub_820DCFA8);
PPC_FUNC_IMPL(__imp__sub_820DCFA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lhz r11,154(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 154);
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// beq cr6,0x820dd050
	if (cr6.getEQ()) goto loc_820DD050;
	// cmplwi cr6,r11,9
	cr6.compare<uint32_t>(r11.u32, 9, xer);
	// beq cr6,0x820dd050
	if (cr6.getEQ()) goto loc_820DD050;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// beq cr6,0x820dd034
	if (cr6.getEQ()) goto loc_820DD034;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// beq cr6,0x820dd034
	if (cr6.getEQ()) goto loc_820DD034;
	// lfs f0,180(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 180);
	f0.f64 = double(temp.f32);
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// lfs f13,168(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 168);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,88(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 88);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,172(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 172);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// lfs f10,92(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,176(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 176);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,96(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 96);
	ctx.f8.f64 = double(temp.f32);
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmadds f13,f11,f0,f10
	ctx.f13.f64 = double(float(ctx.f11.f64 * f0.f64 + ctx.f10.f64));
	// fmadds f0,f9,f0,f8
	f0.f64 = double(float(ctx.f9.f64 * f0.f64 + ctx.f8.f64));
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// b 0x820dd23c
	goto loc_820DD23C;
loc_820DD034:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r31,88
	ctx.r3.s64 = r31.s64 + 88;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// b 0x820dd23c
	goto loc_820DD23C;
loc_820DD050:
	// lhz r10,6(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 6);
	// cmplwi cr6,r11,9
	cr6.compare<uint32_t>(r11.u32, 9, xer);
	// extsh r11,r10
	r11.s64 = ctx.r10.s16;
	// mulli r10,r11,68
	ctx.r10.s64 = r11.s64 * 68;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lfs f9,20(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,28(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 28);
	ctx.f8.f64 = double(temp.f32);
	// lfs f0,12(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12);
	f0.f64 = double(temp.f32);
	// fmuls f5,f9,f8
	ctx.f5.f64 = double(float(ctx.f9.f64 * ctx.f8.f64));
	// lfs f11,32(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 32);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,16(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f6,f0,f11
	ctx.f6.f64 = double(float(f0.f64 * ctx.f11.f64));
	// lfs f7,24(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 24);
	ctx.f7.f64 = double(temp.f32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f4,f7,f10
	ctx.f4.f64 = double(float(ctx.f7.f64 * ctx.f10.f64));
	// lfs f13,52(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 52);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f0,f13,f12
	ctx.f13.f64 = double(float(f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f3,52(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 52);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f2.f64 = double(temp.f32);
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f12,f12,f3,f2
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f3.f64 + ctx.f2.f64));
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmsubs f11,f10,f11,f5
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 - ctx.f5.f64));
	// lfs f3,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,52(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 52);
	ctx.f2.f64 = double(temp.f32);
	// fmsubs f10,f7,f9,f6
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f9.f64 - ctx.f6.f64));
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmadds f9,f3,f2,f5
	ctx.f9.f64 = double(float(ctx.f3.f64 * ctx.f2.f64 + ctx.f5.f64));
	// stfs f9,88(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fmsubs f0,f0,f8,f4
	f0.f64 = double(float(f0.f64 * ctx.f8.f64 - ctx.f4.f64));
	// bne cr6,0x820dd0fc
	if (!cr6.getEQ()) goto loc_820DD0FC;
	// lfs f8,48(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f13,f8,f11,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f11.f64 + ctx.f13.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f11,48(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 48);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f12,f11,f10,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f10.f64 + ctx.f12.f64));
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f11,48(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 48);
	ctx.f11.f64 = double(temp.f32);
	// b 0x820dd148
	goto loc_820DD148;
loc_820DD0FC:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r10,r10,0,2,2
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20000000;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820dd12c
	if (cr6.getEQ()) goto loc_820DD12C;
	// lfs f8,48(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 48);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f13,f8,f11,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f11.f64 + ctx.f13.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f11,48(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 48);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f12,f11,f10,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f10.f64 + ctx.f12.f64));
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f11,48(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 48);
	ctx.f11.f64 = double(temp.f32);
	// b 0x820dd148
	goto loc_820DD148;
loc_820DD12C:
	// lfs f8,44(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 44);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f13,f8,f11,f13
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f11.f64 + ctx.f13.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f11,44(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 44);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f12,f11,f10,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f10.f64 + ctx.f12.f64));
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f11,44(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 44);
	ctx.f11.f64 = double(temp.f32);
loc_820DD148:
	// fmadds f0,f11,f0,f9
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f11.f64 * f0.f64 + ctx.f9.f64));
	// lfs f11,88(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 88);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,92(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 - ctx.f13.f64));
	// lfs f9,96(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 96);
	ctx.f9.f64 = double(temp.f32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// stfs f13,96(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fsubs f13,f10,f12
	ctx.f13.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// stfs f13,100(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// fsubs f0,f9,f0
	f0.f64 = double(float(ctx.f9.f64 - f0.f64));
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8210c818
	sub_8210C818(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// lhz r11,154(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 154);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// cmplwi cr6,r11,9
	cr6.compare<uint32_t>(r11.u32, 9, xer);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	// bne cr6,0x820dd1e8
	if (!cr6.getEQ()) goto loc_820DD1E8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,13980(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13980);
	f0.f64 = double(temp.f32);
	// beq cr6,0x820dd1d8
	if (cr6.getEQ()) goto loc_820DD1D8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,180(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 180);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,6588(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6588);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f1,f12,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f12.f64 * f0.f64 - ctx.f13.f64)));
	// bl 0x8210b968
	sub_8210B968(ctx, base);
	// b 0x820dd218
	goto loc_820DD218;
loc_820DD1D8:
	// lfs f13,180(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 180);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x8210b968
	sub_8210B968(ctx, base);
	// b 0x820dd218
	goto loc_820DD218;
loc_820DD1E8:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,13980(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13980);
	f0.f64 = double(temp.f32);
	// beq cr6,0x820dd20c
	if (cr6.getEQ()) goto loc_820DD20C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,180(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 180);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,6588(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6588);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f1,f12,f0,f13
	ctx.f1.f64 = double(float(-(ctx.f12.f64 * f0.f64 - ctx.f13.f64)));
	// b 0x820dd214
	goto loc_820DD214;
loc_820DD20C:
	// lfs f13,180(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 180);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * f0.f64));
loc_820DD214:
	// bl 0x8210b8c8
	sub_8210B8C8(ctx, base);
loc_820DD218:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8210c818
	sub_8210C818(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
loc_820DD23C:
	// lhz r11,152(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 152);
	// rlwinm r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dd25c
	if (cr6.getEQ()) goto loc_820DD25C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lfs f1,6580(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6580);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210bca0
	sub_8210BCA0(ctx, base);
loc_820DD25C:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DD278"))) PPC_WEAK_FUNC(sub_820DD278);
PPC_FUNC_IMPL(__imp__sub_820DD278) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r8,7
	ctx.r8.s64 = 7;
	// addi r30,r31,204
	r30.s64 = r31.s64 + 204;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
loc_820DD2B8:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x820dd2b8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820DD2B8;
	// lhz r11,152(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 152);
	// rlwinm r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dd318
	if (cr6.getEQ()) goto loc_820DD318;
	// lhz r11,154(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 154);
	// lfs f12,180(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 180);
	ctx.f12.f64 = double(temp.f32);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bne cr6,0x820dd304
	if (!cr6.getEQ()) goto loc_820DD304;
	// lfs f0,16(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	f0.f64 = double(temp.f32);
	// lfs f13,12(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 - f0.f64));
	// fmadds f0,f13,f12,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + f0.f64));
	// stfs f0,220(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 220, temp.u32);
	// b 0x820dd318
	goto loc_820DD318;
loc_820DD304:
	// lfs f0,4(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 - f0.f64));
	// fmadds f0,f13,f12,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + f0.f64));
	// stfs f0,208(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 208, temp.u32);
loc_820DD318:
	// lfs f0,180(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 180);
	f0.f64 = double(temp.f32);
	// lfs f13,136(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820dd338
	if (cr6.getLT()) goto loc_820DD338;
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x820dd4ac
	goto loc_820DD4AC;
loc_820DD338:
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820dcfa8
	sub_820DCFA8(ctx, base);
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// lfs f6,24(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 24);
	ctx.f6.f64 = double(temp.f32);
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// lfs f5,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,16(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 16);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// lfs f1,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x820d3be8
	sub_820D3BE8(ctx, base);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lhz r11,154(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 154);
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// lfs f10,14108(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14108);
	ctx.f10.f64 = double(temp.f32);
	// bne cr6,0x820dd3a0
	if (!cr6.getEQ()) goto loc_820DD3A0;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820d3a48
	sub_820D3A48(ctx, base);
	// lfs f0,92(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	f0.f64 = double(temp.f32);
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// fadds f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 + f0.f64));
	// b 0x820dd3fc
	goto loc_820DD3FC;
loc_820DD3A0:
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bne cr6,0x820dd3c4
	if (!cr6.getEQ()) goto loc_820DD3C4;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r10,104(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// lfs f13,92(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,14056(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14056);
	f0.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// stfs f0,72(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 72, temp.u32);
	// b 0x820dd400
	goto loc_820DD400;
loc_820DD3C4:
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820d3a48
	sub_820D3A48(ctx, base);
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// lfs f0,148(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	f0.f64 = double(temp.f32);
	// fadds f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 + f0.f64));
	// stfs f0,72(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 72, temp.u32);
	// lhz r11,152(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 152);
	// clrlwi r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dd400
	if (cr6.getEQ()) goto loc_820DD400;
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// lfs f0,72(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 72);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f10
	f0.f64 = double(float(f0.f64 - ctx.f10.f64));
loc_820DD3FC:
	// stfs f0,72(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 72, temp.u32);
loc_820DD400:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lhz r11,154(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 154);
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// lfs f0,14484(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14484);
	f0.f64 = double(temp.f32);
	// bne cr6,0x820dd428
	if (!cr6.getEQ()) goto loc_820DD428;
	// lfs f13,132(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f12,180(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 180);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// bgt cr6,0x820dd444
	if (cr6.getGT()) goto loc_820DD444;
loc_820DD428:
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// bne cr6,0x820dd45c
	if (!cr6.getEQ()) goto loc_820DD45C;
	// lfs f13,132(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f13,180(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 180);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820dd45c
	if (!cr6.getGT()) goto loc_820DD45C;
loc_820DD444:
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,72(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 72);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,2960(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2960);
	f0.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// b 0x820dd4a8
	goto loc_820DD4A8;
loc_820DD45C:
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bne cr6,0x820dd470
	if (!cr6.getEQ()) goto loc_820DD470;
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// lfs f0,92(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	f0.f64 = double(temp.f32);
	// b 0x820dd4a4
	goto loc_820DD4A4;
loc_820DD470:
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820d3ab0
	sub_820D3AB0(ctx, base);
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// lfs f0,148(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	f0.f64 = double(temp.f32);
	// fadds f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 + f0.f64));
	// stfs f0,68(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 68, temp.u32);
	// lhz r11,152(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 152);
	// clrlwi r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820dd4ac
	if (cr6.getEQ()) goto loc_820DD4AC;
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// lfs f0,68(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 68);
	f0.f64 = double(temp.f32);
loc_820DD4A4:
	// fadds f0,f0,f10
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f0.f64 + ctx.f10.f64));
loc_820DD4A8:
	// stfs f0,68(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 68, temp.u32);
loc_820DD4AC:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DD4C8"))) PPC_WEAK_FUNC(sub_820DD4C8);
PPC_FUNC_IMPL(__imp__sub_820DD4C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	// lwz r3,236(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 236);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bltlr cr6
	if (cr6.getLT()) return;
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x821143f8
	sub_821143F8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820DD4DC"))) PPC_WEAK_FUNC(sub_820DD4DC);
PPC_FUNC_IMPL(__imp__sub_820DD4DC) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DD4E0"))) PPC_WEAK_FUNC(sub_820DD4E0);
PPC_FUNC_IMPL(__imp__sub_820DD4E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	// lwz r3,236(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 236);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bltlr cr6
	if (cr6.getLT()) return;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x821143f8
	sub_821143F8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820DD4F4"))) PPC_WEAK_FUNC(sub_820DD4F4);
PPC_FUNC_IMPL(__imp__sub_820DD4F4) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DD4F8"))) PPC_WEAK_FUNC(sub_820DD4F8);
PPC_FUNC_IMPL(__imp__sub_820DD4F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// stfd f31,-80(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -80, f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32164
	r11.s64 = -2107899904;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// addi r30,r11,-3616
	r30.s64 = r11.s64 + -3616;
	// mr r24,r6
	r24.u64 = ctx.r6.u64;
	// lhz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 4);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// extsh r11,r10
	r11.s64 = ctx.r10.s16;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// mr r26,r8
	r26.u64 = ctx.r8.u64;
	// lwzx r4,r11,r30
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + r30.u32);
	// bl 0x820d4df0
	sub_820D4DF0(ctx, base);
	// lhz r11,4(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 4);
	// addi r10,r30,8
	ctx.r10.s64 = r30.s64 + 8;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// li r4,1
	ctx.r4.s64 = 1;
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// li r3,80
	ctx.r3.s64 = 80;
	// lfsx f31,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	f31.f64 = double(temp.f32);
	// bl 0x8209cbc8
	sub_8209CBC8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r28,r31,24
	r28.s64 = r31.s64 + 24;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// stw r11,104(r31)
	PPC_STORE_U32(r31.u32 + 104, r11.u32);
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lfs f0,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	f0.f64 = double(temp.f32);
	// rlwinm r11,r11,0,0,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	// stfs f0,168(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 168, temp.u32);
	// lfs f0,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stfs f0,172(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 172, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,176(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 176, temp.u32);
	// lfs f0,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// beq cr6,0x820dd5c8
	if (cr6.getEQ()) goto loc_820DD5C8;
	// lfs f13,132(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,180(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 180, temp.u32);
	// b 0x820dd5cc
	goto loc_820DD5CC;
loc_820DD5C8:
	// stfs f0,180(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 180, temp.u32);
loc_820DD5CC:
	// li r11,0
	r11.s64 = 0;
	// stfs f0,184(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 184, temp.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// li r9,2
	ctx.r9.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stb r11,188(r31)
	PPC_STORE_U8(r31.u32 + 188, r11.u8);
	// stb r11,189(r31)
	PPC_STORE_U8(r31.u32 + 189, r11.u8);
	// stw r11,200(r31)
	PPC_STORE_U32(r31.u32 + 200, r11.u32);
	// stw r11,240(r31)
	PPC_STORE_U32(r31.u32 + 240, r11.u32);
	// stw r11,244(r31)
	PPC_STORE_U32(r31.u32 + 244, r11.u32);
	// stw r10,236(r31)
	PPC_STORE_U32(r31.u32 + 236, ctx.r10.u32);
	// stb r9,0(r30)
	PPC_STORE_U8(r30.u32 + 0, ctx.r9.u8);
	// stw r31,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r31.u32);
	// lfs f0,0(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,12(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 12, temp.u32);
	// lfs f0,4(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,16(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 16, temp.u32);
	// lfs f0,8(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 8);
	f0.f64 = double(temp.f32);
	// stw r24,24(r30)
	PPC_STORE_U32(r30.u32 + 24, r24.u32);
	// stfs f0,20(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 20, temp.u32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lfs f0,0(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 0);
	f0.f64 = double(temp.f32);
	// ori r11,r11,256
	r11.u64 = r11.u64 | 256;
	// stfs f0,88(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 88, temp.u32);
	// lfs f0,4(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,92(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 92, temp.u32);
	// lfs f0,8(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,96(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 96, temp.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// bl 0x820dd278
	sub_820DD278(ctx, base);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r29,r31,124
	r29.s64 = r31.s64 + 124;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// rlwinm r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820dd68c
	if (!cr6.getEQ()) goto loc_820DD68C;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x820d4ad0
	sub_820D4AD0(ctx, base);
	// lbz r11,0(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// lbz r10,1(r29)
	ctx.r10.u64 = PPC_LOAD_U8(r29.u32 + 1);
	// lbz r9,2(r29)
	ctx.r9.u64 = PPC_LOAD_U8(r29.u32 + 2);
	// rlwinm r11,r11,31,1,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r9,r9,31,1,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 31) & 0x7FFFFFFF;
	// stb r11,0(r29)
	PPC_STORE_U8(r29.u32 + 0, r11.u8);
	// stb r10,1(r29)
	PPC_STORE_U8(r29.u32 + 1, ctx.r10.u8);
	// stb r9,2(r29)
	PPC_STORE_U8(r29.u32 + 2, ctx.r9.u8);
loc_820DD68C:
	// lbz r11,0(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lbz r10,125(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 125);
	// lbz r9,126(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 126);
	// lbz r8,127(r31)
	ctx.r8.u64 = PPC_LOAD_U8(r31.u32 + 127);
	// stb r11,120(r31)
	PPC_STORE_U8(r31.u32 + 120, r11.u8);
	// stb r10,121(r31)
	PPC_STORE_U8(r31.u32 + 121, ctx.r10.u8);
	// stb r9,122(r31)
	PPC_STORE_U8(r31.u32 + 122, ctx.r9.u8);
	// stb r8,123(r31)
	PPC_STORE_U8(r31.u32 + 123, ctx.r8.u8);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f31,-80(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_820DD6C0"))) PPC_WEAK_FUNC(sub_820DD6C0);
PPC_FUNC_IMPL(__imp__sub_820DD6C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2940(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2940);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// bgt cr6,0x820dd6d8
	if (cr6.getGT()) goto loc_820DD6D8;
	// li r3,32767
	ctx.r3.s64 = 32767;
	// blr 
	return;
loc_820DD6D8:
	// fcmpu cr6,f1,f3
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, ctx.f3.f64);
	// blt cr6,0x820dd6e8
	if (cr6.getLT()) goto loc_820DD6E8;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_820DD6E8:
	// fcmpu cr6,f1,f2
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, ctx.f2.f64);
	// blt cr6,0x820dd71c
	if (cr6.getLT()) goto loc_820DD71C;
	// fsubs f13,f3,f1
	ctx.f13.f64 = double(float(ctx.f3.f64 - ctx.f1.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f12,f3,f2
	ctx.f12.f64 = double(float(ctx.f3.f64 - ctx.f2.f64));
	// addi r10,r1,-16
	ctx.r10.s64 = ctx.r1.s64 + -16;
	// lfs f0,14056(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14056);
	f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fdivs f0,f0,f12
	f0.f64 = double(float(f0.f64 / ctx.f12.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, f0.u32);
	// lwz r3,-16(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// blr 
	return;
loc_820DD71C:
	// fsubs f13,f1,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64 - f0.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f12,f2,f0
	ctx.f12.f64 = double(float(ctx.f2.f64 - f0.f64));
	// addi r10,r1,-16
	ctx.r10.s64 = ctx.r1.s64 + -16;
	// lfs f0,17844(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17844);
	f0.f64 = double(temp.f32);
	// fsqrts f13,f13
	ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fsqrts f13,f12
	ctx.f13.f64 = double(float(sqrt(ctx.f12.f64)));
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, f0.u32);
	// lwz r11,-16(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// subfic r3,r11,32767
	xer.ca = r11.u32 <= 32767;
	ctx.r3.s64 = 32767 - r11.s64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DD758"))) PPC_WEAK_FUNC(sub_820DD758);
PPC_FUNC_IMPL(__imp__sub_820DD758) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f29,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, f29.u64);
	// stfd f30,-32(r1)
	PPC_STORE_U64(ctx.r1.u32 + -32, f30.u64);
	// stfd f31,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f30,f2
	f30.f64 = ctx.f2.f64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// fmr f29,f1
	f29.f64 = ctx.f1.f64;
	// fmr f31,f30
	f31.f64 = f30.f64;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// ble cr6,0x820dd7f4
	if (!cr6.getGT()) goto loc_820DD7F4;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f11,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// addi r11,r11,-1384
	r11.s64 = r11.s64 + -1384;
loc_820DD7A8:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r10,428(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 428);
	// lfs f0,16(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f10
	f0.f64 = double(float(f0.f64 - ctx.f10.f64));
	// lfs f13,20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// lfs f12,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// fmuls f0,f0,f0
	f0.f64 = double(float(f0.f64 * f0.f64));
	// fmadds f0,f13,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// fmadds f0,f12,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + f0.f64));
	// fsqrts f0,f0
	f0.f64 = double(float(sqrt(f0.f64)));
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bge cr6,0x820dd7e4
	if (!cr6.getLT()) goto loc_820DD7E4;
	// fmr f31,f0
	f31.f64 = f0.f64;
loc_820DD7E4:
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820dd7a8
	if (!cr6.getEQ()) goto loc_820DD7A8;
loc_820DD7F4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2940(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2940);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f31,f0
	cr6.compare(f31.f64, f0.f64);
	// bgt cr6,0x820dd80c
	if (cr6.getGT()) goto loc_820DD80C;
	// li r3,32767
	ctx.r3.s64 = 32767;
	// b 0x820dd884
	goto loc_820DD884;
loc_820DD80C:
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// blt cr6,0x820dd81c
	if (cr6.getLT()) goto loc_820DD81C;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x820dd884
	goto loc_820DD884;
loc_820DD81C:
	// fcmpu cr6,f31,f29
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f29.f64);
	// blt cr6,0x820dd850
	if (cr6.getLT()) goto loc_820DD850;
	// fsubs f13,f30,f31
	ctx.f13.f64 = double(float(f30.f64 - f31.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f12,f30,f29
	ctx.f12.f64 = double(float(f30.f64 - f29.f64));
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lfs f0,14056(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14056);
	f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fdivs f0,f0,f12
	f0.f64 = double(float(f0.f64 / ctx.f12.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, f0.u32);
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// b 0x820dd884
	goto loc_820DD884;
loc_820DD850:
	// fsubs f13,f31,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(f31.f64 - f0.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f12,f29,f0
	ctx.f12.f64 = double(float(f29.f64 - f0.f64));
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lfs f0,17844(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17844);
	f0.f64 = double(temp.f32);
	// fsqrts f13,f13
	ctx.f13.f64 = double(float(sqrt(ctx.f13.f64)));
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fsqrts f13,f12
	ctx.f13.f64 = double(float(sqrt(ctx.f12.f64)));
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, f0.u32);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// subfic r3,r11,32767
	xer.ca = r11.u32 <= 32767;
	ctx.r3.s64 = 32767 - r11.s64;
loc_820DD884:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f29,-40(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// lfd f30,-32(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// lfd f31,-24(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DD8A8"))) PPC_WEAK_FUNC(sub_820DD8A8);
PPC_FUNC_IMPL(__imp__sub_820DD8A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f3,17852(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17852);
	ctx.f3.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f2,17848(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17848);
	ctx.f2.f64 = double(temp.f32);
	// b 0x820dd6c0
	sub_820DD6C0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820DD8C0"))) PPC_WEAK_FUNC(sub_820DD8C0);
PPC_FUNC_IMPL(__imp__sub_820DD8C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f2,17852(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17852);
	ctx.f2.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,17848(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17848);
	ctx.f1.f64 = double(temp.f32);
	// b 0x820dd758
	sub_820DD758(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820DD8D8"))) PPC_WEAK_FUNC(sub_820DD8D8);
PPC_FUNC_IMPL(__imp__sub_820DD8D8) {
	PPC_FUNC_PROLOGUE();
	// b 0x821448f8
	sub_821448F8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820DD8E0"))) PPC_WEAK_FUNC(sub_820DD8E0);
PPC_FUNC_IMPL(__imp__sub_820DD8E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,240(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 240);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820dd90c
	if (cr6.getEQ()) goto loc_820DD90C;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r28,1
	r28.s64 = 1;
	// bne cr6,0x820dd910
	if (!cr6.getEQ()) goto loc_820DD910;
loc_820DD90C:
	// li r28,0
	r28.s64 = 0;
loc_820DD910:
	// lwz r3,244(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 244);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820dd92c
	if (cr6.getEQ()) goto loc_820DD92C;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r29,1
	r29.s64 = 1;
	// bne cr6,0x820dd930
	if (!cr6.getEQ()) goto loc_820DD930;
loc_820DD92C:
	// li r29,0
	r29.s64 = 0;
loc_820DD930:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// bne cr6,0x820dd940
	if (!cr6.getEQ()) goto loc_820DD940;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x820dd9a4
	if (cr6.getEQ()) goto loc_820DD9A4;
loc_820DD940:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r3,r11,12
	ctx.r3.s64 = r11.s64 + 12;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f2,17852(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 17852);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,17848(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17848);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x820dd758
	sub_820DD758(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8209f588
	sub_8209F588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820dd9a4
	if (!cr6.getEQ()) goto loc_820DD9A4;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// ble cr6,0x820dd9a4
	if (!cr6.getGT()) goto loc_820DD9A4;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x820dd98c
	if (cr6.getEQ()) goto loc_820DD98C;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r3,240(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 240);
	// addi r4,r11,12
	ctx.r4.s64 = r11.s64 + 12;
	// bl 0x821448f8
	sub_821448F8(ctx, base);
loc_820DD98C:
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x820dd9a4
	if (cr6.getEQ()) goto loc_820DD9A4;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// lwz r3,244(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 244);
	// addi r4,r11,12
	ctx.r4.s64 = r11.s64 + 12;
	// bl 0x821448f8
	sub_821448F8(ctx, base);
loc_820DD9A4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820DD9B0"))) PPC_WEAK_FUNC(sub_820DD9B0);
PPC_FUNC_IMPL(__imp__sub_820DD9B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,240(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 240);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820dd9e4
	if (cr6.getEQ()) goto loc_820DD9E4;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820dd9e4
	if (cr6.getEQ()) goto loc_820DD9E4;
	// lwz r3,240(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 240);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820DD9E4:
	// lwz r3,244(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 244);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820dda04
	if (cr6.getEQ()) goto loc_820DDA04;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820dda04
	if (cr6.getEQ()) goto loc_820DDA04;
	// lwz r3,244(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 244);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820DDA04:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DDA18"))) PPC_WEAK_FUNC(sub_820DDA18);
PPC_FUNC_IMPL(__imp__sub_820DDA18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r31,0
	r31.s64 = 0;
	// addi r29,r26,240
	r29.s64 = r26.s64 + 240;
	// lwz r3,240(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 240);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820dda50
	if (cr6.getEQ()) goto loc_820DDA50;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820dda50
	if (cr6.getEQ()) goto loc_820DDA50;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820DDA50:
	// lwz r3,244(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 244);
	// addi r30,r26,244
	r30.s64 = r26.s64 + 244;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820dda74
	if (cr6.getEQ()) goto loc_820DDA74;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820dda74
	if (cr6.getEQ()) goto loc_820DDA74;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820DDA74:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820dda88
	if (!cr6.getEQ()) goto loc_820DDA88;
	// mr r31,r29
	r31.u64 = r29.u64;
	// b 0x820dda98
	goto loc_820DDA98;
loc_820DDA88:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820dda98
	if (!cr6.getEQ()) goto loc_820DDA98;
	// mr r31,r30
	r31.u64 = r30.u64;
loc_820DDA98:
	// lwz r11,164(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 164);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// bgt cr6,0x820ddf58
	if (cr6.getGT()) goto loc_820DDF58;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-9536
	r12.s64 = r12.s64 + -9536;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820DDB04;
	case 1:
		goto loc_820DDB48;
	case 2:
		goto loc_820DDB8C;
	case 3:
		goto loc_820DDBCC;
	case 4:
		goto loc_820DDC10;
	case 5:
		goto loc_820DDC40;
	case 6:
		goto loc_820DDC70;
	case 7:
		goto loc_820DDCB4;
	case 8:
		goto loc_820DDCF8;
	case 9:
		goto loc_820DDD38;
	case 10:
		goto loc_820DDD68;
	case 11:
		goto loc_820DDD98;
	case 12:
		goto loc_820DDDC8;
	case 13:
		goto loc_820DDE0C;
	case 14:
		goto loc_820DDE4C;
	case 15:
		goto loc_820DDE8C;
	case 16:
		goto loc_820DDEBC;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-9468(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -9468);
	// lwz r16,-9400(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -9400);
	// lwz r16,-9332(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -9332);
	// lwz r16,-9268(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -9268);
	// lwz r16,-9200(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -9200);
	// lwz r16,-9152(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -9152);
	// lwz r16,-9104(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -9104);
	// lwz r16,-9036(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -9036);
	// lwz r16,-8968(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -8968);
	// lwz r16,-8904(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -8904);
	// lwz r16,-8856(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -8856);
	// lwz r16,-8808(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -8808);
	// lwz r16,-8760(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -8760);
	// lwz r16,-8692(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -8692);
	// lwz r16,-8628(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -8628);
	// lwz r16,-8564(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -8564);
	// lwz r16,-8516(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -8516);
loc_820DDB04:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12171
	ctx.r8.s64 = 12171;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,210
	ctx.r4.s64 = 210;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820ddf40
	if (cr6.getEQ()) goto loc_820DDF40;
	// li r8,12173
	ctx.r8.s64 = 12173;
	// li r4,211
	ctx.r4.s64 = 211;
	// b 0x820ddf2c
	goto loc_820DDF2C;
loc_820DDB48:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12176
	ctx.r8.s64 = 12176;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,210
	ctx.r4.s64 = 210;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820ddf40
	if (cr6.getEQ()) goto loc_820DDF40;
	// li r8,12178
	ctx.r8.s64 = 12178;
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x820ddf2c
	goto loc_820DDF2C;
loc_820DDB8C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12181
	ctx.r8.s64 = 12181;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,202
	ctx.r4.s64 = 202;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820ddf40
	if (cr6.getEQ()) goto loc_820DDF40;
	// li r8,12183
	ctx.r8.s64 = 12183;
	// b 0x820ddf28
	goto loc_820DDF28;
loc_820DDBCC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12186
	ctx.r8.s64 = 12186;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,214
	ctx.r4.s64 = 214;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820ddf40
	if (cr6.getEQ()) goto loc_820DDF40;
	// li r8,12188
	ctx.r8.s64 = 12188;
	// li r4,216
	ctx.r4.s64 = 216;
	// b 0x820ddf2c
	goto loc_820DDF2C;
loc_820DDC10:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,12191
	ctx.r8.s64 = 12191;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,188
	ctx.r4.s64 = 188;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x820ddf40
	goto loc_820DDF40;
loc_820DDC40:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,12194
	ctx.r8.s64 = 12194;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,7
	ctx.r4.s64 = 7;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x820ddf40
	goto loc_820DDF40;
loc_820DDC70:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12197
	ctx.r8.s64 = 12197;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,192
	ctx.r4.s64 = 192;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820ddf40
	if (cr6.getEQ()) goto loc_820DDF40;
	// li r8,12199
	ctx.r8.s64 = 12199;
	// li r4,191
	ctx.r4.s64 = 191;
	// b 0x820ddf2c
	goto loc_820DDF2C;
loc_820DDCB4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12202
	ctx.r8.s64 = 12202;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,188
	ctx.r4.s64 = 188;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820ddf40
	if (cr6.getEQ()) goto loc_820DDF40;
	// li r8,12204
	ctx.r8.s64 = 12204;
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x820ddf2c
	goto loc_820DDF2C;
loc_820DDCF8:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820ddf58
	if (cr6.getEQ()) goto loc_820DDF58;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,12208
	ctx.r8.s64 = 12208;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,194
	ctx.r4.s64 = 194;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820dd8e0
	sub_820DD8E0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
loc_820DDD38:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,12211
	ctx.r8.s64 = 12211;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,196
	ctx.r4.s64 = 196;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x820ddf40
	goto loc_820DDF40;
loc_820DDD68:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,12214
	ctx.r8.s64 = 12214;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,7
	ctx.r4.s64 = 7;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x820ddf40
	goto loc_820DDF40;
loc_820DDD98:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,12217
	ctx.r8.s64 = 12217;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,200
	ctx.r4.s64 = 200;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x820ddf40
	goto loc_820DDF40;
loc_820DDDC8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12220
	ctx.r8.s64 = 12220;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,7
	ctx.r4.s64 = 7;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820ddf40
	if (cr6.getEQ()) goto loc_820DDF40;
	// li r8,12222
	ctx.r8.s64 = 12222;
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x820ddf2c
	goto loc_820DDF2C;
loc_820DDE0C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820ddf58
	if (cr6.getEQ()) goto loc_820DDF58;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,12226
	ctx.r8.s64 = 12226;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,218
	ctx.r4.s64 = 218;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820dd8e0
	sub_820DD8E0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
loc_820DDE4C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820ddf58
	if (cr6.getEQ()) goto loc_820DDF58;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,12230
	ctx.r8.s64 = 12230;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,225
	ctx.r4.s64 = 225;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820dd8e0
	sub_820DD8E0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
loc_820DDE8C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,12233
	ctx.r8.s64 = 12233;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,214
	ctx.r4.s64 = 214;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x820ddf40
	goto loc_820DDF40;
loc_820DDEBC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12236
	ctx.r8.s64 = 12236;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,7
	ctx.r4.s64 = 7;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820ddefc
	if (cr6.getEQ()) goto loc_820DDEFC;
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// addi r4,r11,12
	ctx.r4.s64 = r11.s64 + 12;
	// bl 0x821448f8
	sub_821448F8(ctx, base);
loc_820DDEFC:
	// li r8,12240
	ctx.r8.s64 = 12240;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,202
	ctx.r4.s64 = 202;
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820ddf40
	if (cr6.getEQ()) goto loc_820DDF40;
	// li r8,12242
	ctx.r8.s64 = 12242;
loc_820DDF28:
	// li r4,204
	ctx.r4.s64 = 204;
loc_820DDF2C:
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
loc_820DDF40:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820ddf58
	if (cr6.getEQ()) goto loc_820DDF58;
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r4,r11,12
	ctx.r4.s64 = r11.s64 + 12;
	// bl 0x821448f8
	sub_821448F8(ctx, base);
loc_820DDF58:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820dd8e0
	sub_820DD8E0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820DDF68"))) PPC_WEAK_FUNC(sub_820DDF68);
PPC_FUNC_IMPL(__imp__sub_820DDF68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// li r31,0
	r31.s64 = 0;
	// addi r29,r26,240
	r29.s64 = r26.s64 + 240;
	// lwz r3,240(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 240);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820ddfa0
	if (cr6.getEQ()) goto loc_820DDFA0;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ddfa0
	if (cr6.getEQ()) goto loc_820DDFA0;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820DDFA0:
	// lwz r3,244(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 244);
	// addi r30,r26,244
	r30.s64 = r26.s64 + 244;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820ddfc4
	if (cr6.getEQ()) goto loc_820DDFC4;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ddfc4
	if (cr6.getEQ()) goto loc_820DDFC4;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820DDFC4:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820ddfd8
	if (!cr6.getEQ()) goto loc_820DDFD8;
	// mr r31,r29
	r31.u64 = r29.u64;
	// b 0x820ddfe8
	goto loc_820DDFE8;
loc_820DDFD8:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820ddfe8
	if (!cr6.getEQ()) goto loc_820DDFE8;
	// mr r31,r30
	r31.u64 = r30.u64;
loc_820DDFE8:
	// lwz r11,164(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 164);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// bgt cr6,0x820de3b8
	if (cr6.getGT()) goto loc_820DE3B8;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-8176
	r12.s64 = r12.s64 + -8176;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820DE054;
	case 1:
		goto loc_820DE098;
	case 2:
		goto loc_820DE0DC;
	case 3:
		goto loc_820DE11C;
	case 4:
		goto loc_820DE3B8;
	case 5:
		goto loc_820DE3B8;
	case 6:
		goto loc_820DE160;
	case 7:
		goto loc_820DE1A4;
	case 8:
		goto loc_820DE1E8;
	case 9:
		goto loc_820DE3B8;
	case 10:
		goto loc_820DE3B8;
	case 11:
		goto loc_820DE3B8;
	case 12:
		goto loc_820DE228;
	case 13:
		goto loc_820DE26C;
	case 14:
		goto loc_820DE2AC;
	case 15:
		goto loc_820DE2EC;
	case 16:
		goto loc_820DE31C;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-8108(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -8108);
	// lwz r16,-8040(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -8040);
	// lwz r16,-7972(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7972);
	// lwz r16,-7908(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7908);
	// lwz r16,-7240(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7240);
	// lwz r16,-7240(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7240);
	// lwz r16,-7840(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7840);
	// lwz r16,-7772(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7772);
	// lwz r16,-7704(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7704);
	// lwz r16,-7240(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7240);
	// lwz r16,-7240(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7240);
	// lwz r16,-7240(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7240);
	// lwz r16,-7640(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7640);
	// lwz r16,-7572(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7572);
	// lwz r16,-7508(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7508);
	// lwz r16,-7444(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7444);
	// lwz r16,-7396(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7396);
loc_820DE054:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12268
	ctx.r8.s64 = 12268;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,210
	ctx.r4.s64 = 210;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820de3a0
	if (cr6.getEQ()) goto loc_820DE3A0;
	// li r8,12270
	ctx.r8.s64 = 12270;
	// li r4,211
	ctx.r4.s64 = 211;
	// b 0x820de38c
	goto loc_820DE38C;
loc_820DE098:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12273
	ctx.r8.s64 = 12273;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,210
	ctx.r4.s64 = 210;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820de3a0
	if (cr6.getEQ()) goto loc_820DE3A0;
	// li r8,12275
	ctx.r8.s64 = 12275;
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x820de38c
	goto loc_820DE38C;
loc_820DE0DC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12278
	ctx.r8.s64 = 12278;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,202
	ctx.r4.s64 = 202;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820de3a0
	if (cr6.getEQ()) goto loc_820DE3A0;
	// li r8,12280
	ctx.r8.s64 = 12280;
	// b 0x820de388
	goto loc_820DE388;
loc_820DE11C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12283
	ctx.r8.s64 = 12283;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,214
	ctx.r4.s64 = 214;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820de3a0
	if (cr6.getEQ()) goto loc_820DE3A0;
	// li r8,12285
	ctx.r8.s64 = 12285;
	// li r4,216
	ctx.r4.s64 = 216;
	// b 0x820de38c
	goto loc_820DE38C;
loc_820DE160:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12292
	ctx.r8.s64 = 12292;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,192
	ctx.r4.s64 = 192;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820de3a0
	if (cr6.getEQ()) goto loc_820DE3A0;
	// li r8,12294
	ctx.r8.s64 = 12294;
	// li r4,191
	ctx.r4.s64 = 191;
	// b 0x820de38c
	goto loc_820DE38C;
loc_820DE1A4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12297
	ctx.r8.s64 = 12297;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,188
	ctx.r4.s64 = 188;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820de3a0
	if (cr6.getEQ()) goto loc_820DE3A0;
	// li r8,12299
	ctx.r8.s64 = 12299;
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x820de38c
	goto loc_820DE38C;
loc_820DE1E8:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820de3b8
	if (cr6.getEQ()) goto loc_820DE3B8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,12303
	ctx.r8.s64 = 12303;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,194
	ctx.r4.s64 = 194;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820dd8e0
	sub_820DD8E0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
loc_820DE228:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12312
	ctx.r8.s64 = 12312;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,7
	ctx.r4.s64 = 7;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820de3a0
	if (cr6.getEQ()) goto loc_820DE3A0;
	// li r8,12314
	ctx.r8.s64 = 12314;
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x820de38c
	goto loc_820DE38C;
loc_820DE26C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820de3b8
	if (cr6.getEQ()) goto loc_820DE3B8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,12318
	ctx.r8.s64 = 12318;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,218
	ctx.r4.s64 = 218;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820dd8e0
	sub_820DD8E0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
loc_820DE2AC:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820de3b8
	if (cr6.getEQ()) goto loc_820DE3B8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,12322
	ctx.r8.s64 = 12322;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,225
	ctx.r4.s64 = 225;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820dd8e0
	sub_820DD8E0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
loc_820DE2EC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,12325
	ctx.r8.s64 = 12325;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,214
	ctx.r4.s64 = 214;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x820de3a0
	goto loc_820DE3A0;
loc_820DE31C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,17776
	r29.s64 = r11.s64 + 17776;
	// li r8,12328
	ctx.r8.s64 = 12328;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// li r4,7
	ctx.r4.s64 = 7;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820de35c
	if (cr6.getEQ()) goto loc_820DE35C;
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// addi r4,r11,12
	ctx.r4.s64 = r11.s64 + 12;
	// bl 0x821448f8
	sub_821448F8(ctx, base);
loc_820DE35C:
	// li r8,12332
	ctx.r8.s64 = 12332;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,202
	ctx.r4.s64 = 202;
	// bl 0x82144920
	sub_82144920(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820de3a0
	if (cr6.getEQ()) goto loc_820DE3A0;
	// li r8,12334
	ctx.r8.s64 = 12334;
loc_820DE388:
	// li r4,204
	ctx.r4.s64 = 204;
loc_820DE38C:
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r6,19944(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 19944);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
loc_820DE3A0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820de3b8
	if (cr6.getEQ()) goto loc_820DE3B8;
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r4,r11,12
	ctx.r4.s64 = r11.s64 + 12;
	// bl 0x821448f8
	sub_821448F8(ctx, base);
loc_820DE3B8:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820dd8e0
	sub_820DD8E0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820DE3C8"))) PPC_WEAK_FUNC(sub_820DE3C8);
PPC_FUNC_IMPL(__imp__sub_820DE3C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,240(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 240);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820de3fc
	if (cr6.getEQ()) goto loc_820DE3FC;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820de3fc
	if (cr6.getEQ()) goto loc_820DE3FC;
	// lwz r3,240(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 240);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820DE3FC:
	// lwz r3,244(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 244);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820de41c
	if (cr6.getEQ()) goto loc_820DE41C;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820de41c
	if (cr6.getEQ()) goto loc_820DE41C;
	// lwz r3,244(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 244);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820DE41C:
	// lwz r11,164(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 164);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// bgt cr6,0x820de544
	if (cr6.getGT()) goto loc_820DE544;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-7100
	r12.s64 = r12.s64 + -7100;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820DE488;
	case 1:
		goto loc_820DE494;
	case 2:
		goto loc_820DE4A0;
	case 3:
		goto loc_820DE4A8;
	case 4:
		goto loc_820DE544;
	case 5:
		goto loc_820DE544;
	case 6:
		goto loc_820DE4B4;
	case 7:
		goto loc_820DE4C0;
	case 8:
		goto loc_820DE4CC;
	case 9:
		goto loc_820DE544;
	case 10:
		goto loc_820DE544;
	case 11:
		goto loc_820DE544;
	case 12:
		goto loc_820DE4D8;
	case 13:
		goto loc_820DE4E4;
	case 14:
		goto loc_820DE4F0;
	case 15:
		goto loc_820DE4FC;
	case 16:
		goto loc_820DE508;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-7032(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7032);
	// lwz r16,-7020(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7020);
	// lwz r16,-7008(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7008);
	// lwz r16,-7000(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -7000);
	// lwz r16,-6844(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6844);
	// lwz r16,-6844(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6844);
	// lwz r16,-6988(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6988);
	// lwz r16,-6976(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6976);
	// lwz r16,-6964(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6964);
	// lwz r16,-6844(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6844);
	// lwz r16,-6844(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6844);
	// lwz r16,-6844(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6844);
	// lwz r16,-6952(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6952);
	// lwz r16,-6940(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6940);
	// lwz r16,-6928(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6928);
	// lwz r16,-6916(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6916);
	// lwz r16,-6904(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6904);
loc_820DE488:
	// li r8,12360
	ctx.r8.s64 = 12360;
	// li r4,210
	ctx.r4.s64 = 210;
	// b 0x820de510
	goto loc_820DE510;
loc_820DE494:
	// li r8,12363
	ctx.r8.s64 = 12363;
	// li r4,210
	ctx.r4.s64 = 210;
	// b 0x820de510
	goto loc_820DE510;
loc_820DE4A0:
	// li r8,12366
	ctx.r8.s64 = 12366;
	// b 0x820de50c
	goto loc_820DE50C;
loc_820DE4A8:
	// li r8,12369
	ctx.r8.s64 = 12369;
	// li r4,215
	ctx.r4.s64 = 215;
	// b 0x820de510
	goto loc_820DE510;
loc_820DE4B4:
	// li r8,12376
	ctx.r8.s64 = 12376;
	// li r4,210
	ctx.r4.s64 = 210;
	// b 0x820de510
	goto loc_820DE510;
loc_820DE4C0:
	// li r8,12379
	ctx.r8.s64 = 12379;
	// li r4,187
	ctx.r4.s64 = 187;
	// b 0x820de510
	goto loc_820DE510;
loc_820DE4CC:
	// li r8,12382
	ctx.r8.s64 = 12382;
	// li r4,195
	ctx.r4.s64 = 195;
	// b 0x820de510
	goto loc_820DE510;
loc_820DE4D8:
	// li r8,12391
	ctx.r8.s64 = 12391;
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x820de510
	goto loc_820DE510;
loc_820DE4E4:
	// li r8,12394
	ctx.r8.s64 = 12394;
	// li r4,219
	ctx.r4.s64 = 219;
	// b 0x820de510
	goto loc_820DE510;
loc_820DE4F0:
	// li r8,12397
	ctx.r8.s64 = 12397;
	// li r4,226
	ctx.r4.s64 = 226;
	// b 0x820de510
	goto loc_820DE510;
loc_820DE4FC:
	// li r8,12400
	ctx.r8.s64 = 12400;
	// li r4,215
	ctx.r4.s64 = 215;
	// b 0x820de510
	goto loc_820DE510;
loc_820DE508:
	// li r8,12403
	ctx.r8.s64 = 12403;
loc_820DE50C:
	// li r4,203
	ctx.r4.s64 = 203;
loc_820DE510:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820de544
	if (cr6.getEQ()) goto loc_820DE544;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r4,r11,12
	ctx.r4.s64 = r11.s64 + 12;
	// bl 0x821448f8
	sub_821448F8(ctx, base);
loc_820DE544:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820dd8e0
	sub_820DD8E0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DE560"))) PPC_WEAK_FUNC(sub_820DE560);
PPC_FUNC_IMPL(__imp__sub_820DE560) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,240(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 240);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820de594
	if (cr6.getEQ()) goto loc_820DE594;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820de594
	if (cr6.getEQ()) goto loc_820DE594;
	// lwz r3,240(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 240);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820DE594:
	// lwz r3,244(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 244);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820de5b4
	if (cr6.getEQ()) goto loc_820DE5B4;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820de5b4
	if (cr6.getEQ()) goto loc_820DE5B4;
	// lwz r3,244(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 244);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820DE5B4:
	// lwz r11,164(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 164);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// bgt cr6,0x820de718
	if (cr6.getGT()) goto loc_820DE718;
	// lis r12,-32242
	r12.s64 = -2113011712;
	// addi r12,r12,-6692
	r12.s64 = r12.s64 + -6692;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820DE620;
	case 1:
		goto loc_820DE62C;
	case 2:
		goto loc_820DE638;
	case 3:
		goto loc_820DE640;
	case 4:
		goto loc_820DE64C;
	case 5:
		goto loc_820DE658;
	case 6:
		goto loc_820DE664;
	case 7:
		goto loc_820DE670;
	case 8:
		goto loc_820DE67C;
	case 9:
		goto loc_820DE688;
	case 10:
		goto loc_820DE694;
	case 11:
		goto loc_820DE6A0;
	case 12:
		goto loc_820DE6AC;
	case 13:
		goto loc_820DE6B8;
	case 14:
		goto loc_820DE6C4;
	case 15:
		goto loc_820DE6D0;
	case 16:
		goto loc_820DE6DC;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-6624(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6624);
	// lwz r16,-6612(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6612);
	// lwz r16,-6600(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6600);
	// lwz r16,-6592(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6592);
	// lwz r16,-6580(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6580);
	// lwz r16,-6568(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6568);
	// lwz r16,-6556(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6556);
	// lwz r16,-6544(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6544);
	// lwz r16,-6532(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6532);
	// lwz r16,-6520(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6520);
	// lwz r16,-6508(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6508);
	// lwz r16,-6496(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6496);
	// lwz r16,-6484(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6484);
	// lwz r16,-6472(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6472);
	// lwz r16,-6460(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6460);
	// lwz r16,-6448(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6448);
	// lwz r16,-6436(r13)
	r16.u64 = PPC_LOAD_U32(ctx.r13.u32 + -6436);
loc_820DE620:
	// li r8,12427
	ctx.r8.s64 = 12427;
	// li r4,210
	ctx.r4.s64 = 210;
	// b 0x820de6e4
	goto loc_820DE6E4;
loc_820DE62C:
	// li r8,12430
	ctx.r8.s64 = 12430;
	// li r4,210
	ctx.r4.s64 = 210;
	// b 0x820de6e4
	goto loc_820DE6E4;
loc_820DE638:
	// li r8,12433
	ctx.r8.s64 = 12433;
	// b 0x820de6e0
	goto loc_820DE6E0;
loc_820DE640:
	// li r8,12436
	ctx.r8.s64 = 12436;
	// li r4,215
	ctx.r4.s64 = 215;
	// b 0x820de6e4
	goto loc_820DE6E4;
loc_820DE64C:
	// li r8,12439
	ctx.r8.s64 = 12439;
	// li r4,187
	ctx.r4.s64 = 187;
	// b 0x820de6e4
	goto loc_820DE6E4;
loc_820DE658:
	// li r8,12442
	ctx.r8.s64 = 12442;
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x820de6e4
	goto loc_820DE6E4;
loc_820DE664:
	// li r8,12445
	ctx.r8.s64 = 12445;
	// li r4,210
	ctx.r4.s64 = 210;
	// b 0x820de6e4
	goto loc_820DE6E4;
loc_820DE670:
	// li r8,12448
	ctx.r8.s64 = 12448;
	// li r4,187
	ctx.r4.s64 = 187;
	// b 0x820de6e4
	goto loc_820DE6E4;
loc_820DE67C:
	// li r8,12451
	ctx.r8.s64 = 12451;
	// li r4,195
	ctx.r4.s64 = 195;
	// b 0x820de6e4
	goto loc_820DE6E4;
loc_820DE688:
	// li r8,12454
	ctx.r8.s64 = 12454;
	// li r4,197
	ctx.r4.s64 = 197;
	// b 0x820de6e4
	goto loc_820DE6E4;
loc_820DE694:
	// li r8,12457
	ctx.r8.s64 = 12457;
	// li r4,199
	ctx.r4.s64 = 199;
	// b 0x820de6e4
	goto loc_820DE6E4;
loc_820DE6A0:
	// li r8,12460
	ctx.r8.s64 = 12460;
	// li r4,201
	ctx.r4.s64 = 201;
	// b 0x820de6e4
	goto loc_820DE6E4;
loc_820DE6AC:
	// li r8,12463
	ctx.r8.s64 = 12463;
	// li r4,7
	ctx.r4.s64 = 7;
	// b 0x820de6e4
	goto loc_820DE6E4;
loc_820DE6B8:
	// li r8,12466
	ctx.r8.s64 = 12466;
	// li r4,219
	ctx.r4.s64 = 219;
	// b 0x820de6e4
	goto loc_820DE6E4;
loc_820DE6C4:
	// li r8,12469
	ctx.r8.s64 = 12469;
	// li r4,226
	ctx.r4.s64 = 226;
	// b 0x820de6e4
	goto loc_820DE6E4;
loc_820DE6D0:
	// li r8,12472
	ctx.r8.s64 = 12472;
	// li r4,215
	ctx.r4.s64 = 215;
	// b 0x820de6e4
	goto loc_820DE6E4;
loc_820DE6DC:
	// li r8,12475
	ctx.r8.s64 = 12475;
loc_820DE6E0:
	// li r4,203
	ctx.r4.s64 = 203;
loc_820DE6E4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r7,r11,17776
	ctx.r7.s64 = r11.s64 + 17776;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820de718
	if (cr6.getEQ()) goto loc_820DE718;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r4,r11,12
	ctx.r4.s64 = r11.s64 + 12;
	// bl 0x821448f8
	sub_821448F8(ctx, base);
loc_820DE718:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820dd8e0
	sub_820DD8E0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DE738"))) PPC_WEAK_FUNC(sub_820DE738);
PPC_FUNC_IMPL(__imp__sub_820DE738) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,100(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// clrlwi r11,r11,1
	r11.u64 = r11.u32 & 0x7FFFFFFF;
	// ori r10,r10,512
	ctx.r10.u64 = ctx.r10.u64 | 512;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r10,100(r31)
	PPC_STORE_U32(r31.u32 + 100, ctx.r10.u32);
	// bl 0x820dda18
	sub_820DDA18(ctx, base);
	// lwz r3,236(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 236);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x820de77c
	if (cr6.getLT()) goto loc_820DE77C;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x821143f8
	sub_821143F8(ctx, base);
loc_820DE77C:
	// lhz r11,154(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 154);
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bne cr6,0x820de7c0
	if (!cr6.getEQ()) goto loc_820DE7C0;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,104(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 104);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lfs f0,2688(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2688);
	f0.f64 = double(temp.f32);
	// oris r10,r9,512
	ctx.r10.u64 = ctx.r9.u64 | 33554432;
	// stfs f0,136(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 136, temp.u32);
	// stw r10,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r10.u32);
	// beq cr6,0x820de7b4
	if (cr6.getEQ()) goto loc_820DE7B4;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_820DE7B4:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,24,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFEFF;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
loc_820DE7C0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DE7D8"))) PPC_WEAK_FUNC(sub_820DE7D8);
PPC_FUNC_IMPL(__imp__sub_820DE7D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -24, f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r4,1
	cr6.compare<int32_t>(ctx.r4.s32, 1, xer);
	// bne cr6,0x820de824
	if (!cr6.getEQ()) goto loc_820DE824;
	// lbz r11,188(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 188);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820de810
	if (cr6.getEQ()) goto loc_820DE810;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x820de818
	if (!cr6.getEQ()) goto loc_820DE818;
loc_820DE810:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820de738
	sub_820DE738(ctx, base);
loc_820DE818:
	// li r11,1
	r11.s64 = 1;
	// stb r11,188(r31)
	PPC_STORE_U8(r31.u32 + 188, r11.u8);
	// b 0x820de8a8
	goto loc_820DE8A8;
loc_820DE824:
	// cmpwi cr6,r4,2
	cr6.compare<int32_t>(ctx.r4.s32, 2, xer);
	// bne cr6,0x820de8a4
	if (!cr6.getEQ()) goto loc_820DE8A4;
	// lbz r11,188(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 188);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// bne cr6,0x820de860
	if (!cr6.getEQ()) goto loc_820DE860;
	// lfs f0,180(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 180);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x820de860
	if (!cr6.getGT()) goto loc_820DE860;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// clrlwi r11,r11,1
	r11.u64 = r11.u32 & 0x7FFFFFFF;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// bl 0x820ddf68
	sub_820DDF68(ctx, base);
loc_820DE860:
	// lbz r11,188(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 188);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820de878
	if (cr6.getEQ()) goto loc_820DE878;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x820de884
	if (!cr6.getEQ()) goto loc_820DE884;
loc_820DE878:
	// lfs f0,180(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 180);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x820de890
	if (!cr6.getGT()) goto loc_820DE890;
loc_820DE884:
	// li r11,2
	r11.s64 = 2;
	// stb r11,188(r31)
	PPC_STORE_U8(r31.u32 + 188, r11.u8);
	// b 0x820de8a8
	goto loc_820DE8A8;
loc_820DE890:
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x820de8a8
	if (!cr6.getEQ()) goto loc_820DE8A8;
	// li r11,0
	r11.s64 = 0;
	// stb r11,188(r31)
	PPC_STORE_U8(r31.u32 + 188, r11.u8);
	// b 0x820de8a8
	goto loc_820DE8A8;
loc_820DE8A4:
	// stb r4,188(r31)
	PPC_STORE_U8(r31.u32 + 188, ctx.r4.u8);
loc_820DE8A8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DE8C0"))) PPC_WEAK_FUNC(sub_820DE8C0);
PPC_FUNC_IMPL(__imp__sub_820DE8C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// rlwinm r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820de900
	if (cr6.getEQ()) goto loc_820DE900;
	// cmpwi cr6,r4,1
	cr6.compare<int32_t>(ctx.r4.s32, 1, xer);
	// bne cr6,0x820de900
	if (!cr6.getEQ()) goto loc_820DE900;
	// lbz r11,188(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 188);
	// li r29,2
	r29.s64 = 2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820de900
	if (!cr6.getEQ()) goto loc_820DE900;
	// li r4,3
	ctx.r4.s64 = 3;
loc_820DE900:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820de7d8
	sub_820DE7D8(ctx, base);
	// lwz r31,200(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 200);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820de934
	if (cr6.getEQ()) goto loc_820DE934;
loc_820DE914:
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// beq cr6,0x820de934
	if (cr6.getEQ()) goto loc_820DE934;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820de7d8
	sub_820DE7D8(ctx, base);
	// lwz r31,200(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 200);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x820de914
	if (!cr6.getEQ()) goto loc_820DE914;
loc_820DE934:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820DE940"))) PPC_WEAK_FUNC(sub_820DE940);
PPC_FUNC_IMPL(__imp__sub_820DE940) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// li r30,0
	r30.s64 = 0;
	// bl 0x820cdf78
	sub_820CDF78(ctx, base);
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r29,r1,96
	r29.s64 = ctx.r1.s64 + 96;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x820dea04
	if (cr6.getLT()) goto loc_820DEA04;
loc_820DE96C:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82113040
	sub_82113040(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820de9f4
	if (cr6.getEQ()) goto loc_820DE9F4;
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x820de9d4
	if (cr6.getEQ()) goto loc_820DE9D4;
	// lfs f13,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820de998
	if (!cr6.getLT()) goto loc_820DE998;
	// stfs f0,0(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
loc_820DE998:
	// lfs f13,4(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820de9ac
	if (!cr6.getLT()) goto loc_820DE9AC;
	// stfs f0,4(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
loc_820DE9AC:
	// lfs f13,8(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820de9c0
	if (!cr6.getGT()) goto loc_820DE9C0;
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
loc_820DE9C0:
	// lfs f13,12(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820de9f0
	if (!cr6.getGT()) goto loc_820DE9F0;
	// b 0x820de9ec
	goto loc_820DE9EC;
loc_820DE9D4:
	// stfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// lfs f0,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
	// stfs f0,4(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// lfs f0,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// lfs f0,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	f0.f64 = double(temp.f32);
loc_820DE9EC:
	// stfs f0,12(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
loc_820DE9F0:
	// li r30,1
	r30.s64 = 1;
loc_820DE9F4:
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge cr6,0x820de96c
	if (!cr6.getLT()) goto loc_820DE96C;
loc_820DEA04:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820DEA10"))) PPC_WEAK_FUNC(sub_820DEA10);
PPC_FUNC_IMPL(__imp__sub_820DEA10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f29.u64);
	// stfd f30,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, f30.u64);
	// stfd f31,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// fmr f29,f1
	f29.f64 = ctx.f1.f64;
	// li r28,1
	r28.s64 = 1;
	// bl 0x821183a0
	sub_821183A0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x820deac8
	if (cr6.getEQ()) goto loc_820DEAC8;
	// bl 0x820b3dc0
	sub_820B3DC0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8210d820
	sub_8210D820(ctx, base);
	// lfs f13,4(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// lfs f13,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// lfs f11,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f9,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// lfs f11,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 * f0.f64));
	// lfs f10,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f0,f9,f13,f0
	f0.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 + f0.f64));
	// fmadds f30,f10,f12,f0
	f30.f64 = double(float(ctx.f10.f64 * ctx.f12.f64 + f0.f64));
	// fcmpu cr6,f30,f11
	cr6.compare(f30.f64, ctx.f11.f64);
	// ble cr6,0x820deac8
	if (!cr6.getGT()) goto loc_820DEAC8;
	// fmr f31,f11
	f31.f64 = ctx.f11.f64;
	// bl 0x8210d890
	sub_8210D890(ctx, base);
	// fsubs f13,f30,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(f30.f64 - f31.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// li r3,0
	ctx.r3.s64 = 0;
	// lfs f0,2944(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2944);
	f0.f64 = double(temp.f32);
	// fdivs f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 / f29.f64));
	// fmadds f0,f13,f0,f31
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 + f31.f64));
	// fmuls f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 * f0.f64));
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bge cr6,0x820deacc
	if (!cr6.getLT()) goto loc_820DEACC;
loc_820DEAC8:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
loc_820DEACC:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f30,-56(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820DEAE0"))) PPC_WEAK_FUNC(sub_820DEAE0);
PPC_FUNC_IMPL(__imp__sub_820DEAE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// li r29,0
	r29.s64 = 0;
	// bl 0x820cdf78
	sub_820CDF78(ctx, base);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x820deb44
	if (cr6.getLT()) goto loc_820DEB44;
	// lis r9,-32009
	ctx.r9.s64 = -2097741824;
	// addi r9,r9,-9856
	ctx.r9.s64 = ctx.r9.s64 + -9856;
loc_820DEB24:
	// mulli r11,r11,156
	r11.s64 = r11.s64 * 156;
	// lbzx r11,r11,r9
	r11.u64 = PPC_LOAD_U8(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820deb54
	if (!cr6.getEQ()) goto loc_820DEB54;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820deb24
	if (!cr6.getLT()) goto loc_820DEB24;
loc_820DEB44:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
loc_820DEB54:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x821182f0
	sub_821182F0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820deb44
	if (cr6.getEQ()) goto loc_820DEB44;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x820deb84
	if (cr6.getEQ()) goto loc_820DEB84;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x820dea10
	sub_820DEA10(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820deb44
	if (cr6.getEQ()) goto loc_820DEB44;
loc_820DEB84:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820de940
	sub_820DE940(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// beq cr6,0x820debac
	if (cr6.getEQ()) goto loc_820DEBAC;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// bl 0x8210dc70
	sub_8210DC70(ctx, base);
	// b 0x820debb0
	goto loc_820DEBB0;
loc_820DEBAC:
	// bl 0x8210db48
	sub_8210DB48(ctx, base);
loc_820DEBB0:
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x820dec10
	if (cr6.getEQ()) goto loc_820DEC10;
	// bl 0x820b3dc0
	sub_820B3DC0(ctx, base);
	// lfs f11,4(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f0,f0,f11
	f0.f64 = double(float(f0.f64 - ctx.f11.f64));
	// lfs f13,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// lfs f12,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// fmuls f0,f0,f0
	f0.f64 = double(float(f0.f64 * f0.f64));
	// fmadds f0,f13,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// fmadds f13,f12,f12,f0
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + f0.f64));
	// lfs f0,17856(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17856);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820dec10
	if (!cr6.getGT()) goto loc_820DEC10;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f31,-48(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
loc_820DEC10:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820DEC20"))) PPC_WEAK_FUNC(sub_820DEC20);
PPC_FUNC_IMPL(__imp__sub_820DEC20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// lbz r11,188(r7)
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 188);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x820dec98
	if (!cr6.getEQ()) goto loc_820DEC98;
	// addi r3,r7,180
	ctx.r3.s64 = ctx.r7.s64 + 180;
	// lfs f4,148(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 148);
	ctx.f4.f64 = double(temp.f32);
	// addi r5,r7,184
	ctx.r5.s64 = ctx.r7.s64 + 184;
	// lfs f3,144(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 144);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,140(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 140);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,132(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 132);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x820d6f30
	sub_820D6F30(ctx, base);
	// lfs f0,180(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 180);
	f0.f64 = double(temp.f32);
	// lfs f13,132(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820dec80
	if (!cr6.getLT()) goto loc_820DEC80;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x820decdc
	if (cr6.getGT()) goto loc_820DECDC;
loc_820DEC80:
	// stfs f13,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820DEC98:
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x820dece0
	if (!cr6.getEQ()) goto loc_820DECE0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f4,148(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 148);
	ctx.f4.f64 = double(temp.f32);
	// addi r3,r7,180
	ctx.r3.s64 = ctx.r7.s64 + 180;
	// lfs f3,144(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 144);
	ctx.f3.f64 = double(temp.f32);
	// addi r5,r7,184
	ctx.r5.s64 = ctx.r7.s64 + 184;
	// lfs f2,140(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 140);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x820d6f30
	sub_820D6F30(ctx, base);
	// lfs f0,180(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 180);
	f0.f64 = double(temp.f32);
	// lfs f13,132(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820dec80
	if (!cr6.getLT()) goto loc_820DEC80;
	// fcmpu cr6,f0,f1
	cr6.compare(f0.f64, ctx.f1.f64);
	// bgt cr6,0x820decdc
	if (cr6.getGT()) goto loc_820DECDC;
	// stfs f1,0(r3)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
loc_820DECDC:
	// li r3,1
	ctx.r3.s64 = 1;
loc_820DECE0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DECF0"))) PPC_WEAK_FUNC(sub_820DECF0);
PPC_FUNC_IMPL(__imp__sub_820DECF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f19{};
	PPCRegister f20{};
	PPCRegister f21{};
	PPCRegister f22{};
	PPCRegister f23{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed524
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// lhz r11,6(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 6);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// mulli r10,r11,68
	ctx.r10.s64 = r11.s64 * 68;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// add r31,r10,r11
	r31.u64 = ctx.r10.u64 + r11.u64;
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f11,12(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// lfs f0,17860(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17860);
	f0.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lfs f13,1472(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1472);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,1480(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1480);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f23,f13,f0,f11
	f23.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f11.f64));
	// fmadds f22,f12,f0,f10
	f22.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f10.f64));
	// beq cr6,0x820ded98
	if (cr6.getEQ()) goto loc_820DED98;
	// lfs f0,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	f0.f64 = double(temp.f32);
	// lfs f13,28(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,24(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 24);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * f0.f64));
	// lfs f10,32(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// lfs f28,44(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 44);
	f28.f64 = double(temp.f32);
	// lfs f24,48(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 48);
	f24.f64 = double(temp.f32);
	// fmsubs f31,f10,f0,f12
	f31.f64 = double(float(ctx.f10.f64 * f0.f64 - ctx.f12.f64));
	// fmsubs f30,f9,f13,f11
	f30.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 - ctx.f11.f64));
	// b 0x820deda8
	goto loc_820DEDA8;
loc_820DED98:
	// lfs f28,52(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 52);
	f28.f64 = double(temp.f32);
	// lfs f24,56(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 56);
	f24.f64 = double(temp.f32);
	// lfs f31,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	f31.f64 = double(temp.f32);
	// lfs f30,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	f30.f64 = double(temp.f32);
loc_820DEDA8:
	// fmuls f26,f31,f28
	ctx.fpscr.disableFlushMode();
	f26.f64 = double(float(f31.f64 * f28.f64));
	// lfs f0,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// fmuls f25,f30,f28
	f25.f64 = double(float(f30.f64 * f28.f64));
	// lfs f13,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f26
	f0.f64 = double(float(f0.f64 + f26.f64));
	// fadds f13,f25,f13
	ctx.f13.f64 = double(float(f25.f64 + ctx.f13.f64));
	// fsubs f1,f0,f23
	ctx.f1.f64 = double(float(f0.f64 - f23.f64));
	// fsubs f2,f13,f22
	ctx.f2.f64 = double(float(ctx.f13.f64 - f22.f64));
	// bl 0x8210ae20
	sub_8210AE20(ctx, base);
	// fmr f29,f1
	ctx.fpscr.disableFlushMode();
	f29.f64 = ctx.f1.f64;
	// bl 0x820b3ce0
	sub_820B3CE0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f21,f29,f1
	ctx.fpscr.disableFlushMode();
	f21.f64 = double(float(f29.f64 - ctx.f1.f64));
	// lfs f27,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f27.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f20,6588(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6588);
	f20.f64 = double(temp.f32);
	// fcmpu cr6,f21,f27
	cr6.compare(f21.f64, f27.f64);
	// bge cr6,0x820dedf4
	if (!cr6.getLT()) goto loc_820DEDF4;
	// fadds f21,f21,f20
	f21.f64 = double(float(f21.f64 + f20.f64));
loc_820DEDF4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f19,14032(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14032);
	f19.f64 = double(temp.f32);
	// fcmpu cr6,f21,f19
	cr6.compare(f21.f64, f19.f64);
	// ble cr6,0x820dee08
	if (!cr6.getGT()) goto loc_820DEE08;
	// fsubs f21,f21,f20
	f21.f64 = double(float(f21.f64 - f20.f64));
loc_820DEE08:
	// lhz r11,154(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 154);
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// bne cr6,0x820dee8c
	if (!cr6.getEQ()) goto loc_820DEE8C;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lfs f13,180(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 180);
	ctx.f13.f64 = double(temp.f32);
	// rlwinm r10,r11,0,2,2
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lfs f0,13980(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13980);
	f0.f64 = double(temp.f32);
	// fmuls f29,f13,f0
	f29.f64 = double(float(ctx.f13.f64 * f0.f64));
	// beq cr6,0x820dee38
	if (cr6.getEQ()) goto loc_820DEE38;
	// fsubs f29,f20,f29
	f29.f64 = double(float(f20.f64 - f29.f64));
loc_820DEE38:
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f29.f64;
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// fmr f1,f29
	ctx.f1.f64 = f29.f64;
	// frsp f29,f0
	f29.f64 = double(float(f0.f64));
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64));
	// lfs f12,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f10,f29,f31
	ctx.f10.f64 = double(float(f29.f64 * f31.f64));
	// lfs f11,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f0,f24,f28
	f0.f64 = double(float(f24.f64 - f28.f64));
	// fmuls f9,f13,f31
	ctx.f9.f64 = double(float(ctx.f13.f64 * f31.f64));
	// fmadds f13,f13,f30,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * f30.f64 + ctx.f10.f64));
	// fmsubs f10,f29,f30,f9
	ctx.f10.f64 = double(float(f29.f64 * f30.f64 - ctx.f9.f64));
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// fmadds f0,f10,f0,f25
	f0.f64 = double(float(ctx.f10.f64 * f0.f64 + f25.f64));
	// fadds f13,f13,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 + f26.f64));
	// fadds f0,f0,f11
	f0.f64 = double(float(f0.f64 + ctx.f11.f64));
	// fsubs f1,f13,f23
	ctx.f1.f64 = double(float(ctx.f13.f64 - f23.f64));
	// fsubs f2,f0,f22
	ctx.f2.f64 = double(float(f0.f64 - f22.f64));
	// b 0x820deea4
	goto loc_820DEEA4;
loc_820DEE8C:
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f31,f24,f0
	f0.f64 = double(float(f31.f64 * f24.f64 + f0.f64));
	// fmadds f13,f30,f24,f13
	ctx.f13.f64 = double(float(f30.f64 * f24.f64 + ctx.f13.f64));
	// fsubs f1,f0,f23
	ctx.f1.f64 = double(float(f0.f64 - f23.f64));
	// fsubs f2,f13,f22
	ctx.f2.f64 = double(float(ctx.f13.f64 - f22.f64));
loc_820DEEA4:
	// bl 0x8210ae20
	sub_8210AE20(ctx, base);
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// bl 0x820b3ce0
	sub_820B3CE0(ctx, base);
	// fsubs f0,f31,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f31.f64 - ctx.f1.f64));
	// fcmpu cr6,f0,f27
	cr6.compare(f0.f64, f27.f64);
	// bge cr6,0x820deec0
	if (!cr6.getLT()) goto loc_820DEEC0;
	// fadds f0,f0,f20
	f0.f64 = double(float(f0.f64 + f20.f64));
loc_820DEEC0:
	// fcmpu cr6,f0,f19
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f19.f64);
	// ble cr6,0x820deecc
	if (!cr6.getGT()) goto loc_820DEECC;
	// fsubs f0,f0,f20
	f0.f64 = double(float(f0.f64 - f20.f64));
loc_820DEECC:
	// fcmpu cr6,f21,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(f21.f64, f0.f64);
	// bge cr6,0x820deeec
	if (!cr6.getLT()) goto loc_820DEEEC;
	// stfs f21,0(r28)
	temp.f32 = float(f21.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// stfs f0,0(r27)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r27.u32 + 0, temp.u32);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed570
	// b 0x823ed184
	return;
loc_820DEEEC:
	// stfs f0,0(r28)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r28.u32 + 0, temp.u32);
	// stfs f21,0(r27)
	temp.f32 = float(f21.f64);
	PPC_STORE_U32(r27.u32 + 0, temp.u32);
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed570
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820DEF08"))) PPC_WEAK_FUNC(sub_820DEF08);
PPC_FUNC_IMPL(__imp__sub_820DEF08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stfd f29,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, f29.u64);
	// stfd f30,-64(r1)
	PPC_STORE_U64(ctx.r1.u32 + -64, f30.u64);
	// stfd f31,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, f31.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r28,-32013
	r28.s64 = -2098003968;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// li r27,1
	r27.s64 = 1;
	// lwz r11,904(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 904);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820df044
	if (!cr6.getEQ()) goto loc_820DF044;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x820decf0
	sub_820DECF0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f31.f64 = double(temp.f32);
	// lfs f30,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f30.f64 = double(temp.f32);
	// lfs f0,17868(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17868);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f31,f0
	cr6.compare(f31.f64, f0.f64);
	// blt cr6,0x820defa4
	if (cr6.getLT()) goto loc_820DEFA4;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,17864(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17864);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f31,f13
	cr6.compare(f31.f64, ctx.f13.f64);
	// bgt cr6,0x820defa4
	if (cr6.getGT()) goto loc_820DEFA4;
	// fcmpu cr6,f30,f0
	cr6.compare(f30.f64, f0.f64);
	// blt cr6,0x820defa4
	if (cr6.getLT()) goto loc_820DEFA4;
	// fcmpu cr6,f30,f13
	cr6.compare(f30.f64, ctx.f13.f64);
	// bgt cr6,0x820defa4
	if (cr6.getGT()) goto loc_820DEFA4;
loc_820DEF84:
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,904(r28)
	PPC_STORE_U32(r28.u32 + 904, r11.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f29,-72(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f30,-64(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f31,-56(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x823ed184
	return;
loc_820DEFA4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r31,200(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 200);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// lfs f29,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f29.f64 = double(temp.f32);
	// beq cr6,0x820df020
	if (cr6.getEQ()) goto loc_820DF020;
loc_820DEFB8:
	// cmplw cr6,r31,r30
	cr6.compare<uint32_t>(r31.u32, r30.u32, xer);
	// beq cr6,0x820df020
	if (cr6.getEQ()) goto loc_820DF020;
	// fcmpu cr6,f31,f29
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f29.f64);
	// bge cr6,0x820defd0
	if (!cr6.getLT()) goto loc_820DEFD0;
	// fcmpu cr6,f30,f29
	cr6.compare(f30.f64, f29.f64);
	// bge cr6,0x820df020
	if (!cr6.getLT()) goto loc_820DF020;
loc_820DEFD0:
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820decf0
	sub_820DECF0(ctx, base);
	// fcmpu cr6,f31,f29
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f29.f64);
	// ble cr6,0x820deffc
	if (!cr6.getGT()) goto loc_820DEFFC;
	// lfs f0,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bge cr6,0x820deffc
	if (!cr6.getLT()) goto loc_820DEFFC;
	// fmr f31,f0
	f31.f64 = f0.f64;
loc_820DEFFC:
	// fcmpu cr6,f30,f29
	ctx.fpscr.disableFlushMode();
	cr6.compare(f30.f64, f29.f64);
	// bge cr6,0x820df014
	if (!cr6.getLT()) goto loc_820DF014;
	// lfs f0,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// ble cr6,0x820df014
	if (!cr6.getGT()) goto loc_820DF014;
	// fmr f30,f0
	f30.f64 = f0.f64;
loc_820DF014:
	// lwz r31,200(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 200);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x820defb8
	if (!cr6.getEQ()) goto loc_820DEFB8;
loc_820DF020:
	// fsubs f13,f30,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(f30.f64 - f31.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,14032(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14032);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820df044
	if (!cr6.getLT()) goto loc_820DF044;
	// fcmpu cr6,f31,f29
	cr6.compare(f31.f64, f29.f64);
	// bge cr6,0x820df044
	if (!cr6.getLT()) goto loc_820DF044;
	// fcmpu cr6,f30,f29
	cr6.compare(f30.f64, f29.f64);
	// bgt cr6,0x820def84
	if (cr6.getGT()) goto loc_820DEF84;
loc_820DF044:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// lfd f29,-72(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f30,-64(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f31,-56(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820DF060"))) PPC_WEAK_FUNC(sub_820DF060);
PPC_FUNC_IMPL(__imp__sub_820DF060) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r27,1
	r27.s64 = 1;
	// lwz r31,8(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,6,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820df1ac
	if (!cr6.getEQ()) goto loc_820DF1AC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,132(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820df1ac
	if (!cr6.getGT()) goto loc_820DF1AC;
	// lbz r11,1(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 1);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820df1ac
	if (cr6.getEQ()) goto loc_820DF1AC;
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lfs f0,88(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 88);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,96(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// addi r29,r30,12
	r29.s64 = r30.s64 + 12;
	// lfs f12,92(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f0,f0,f11
	f0.f64 = double(float(f0.f64 - ctx.f11.f64));
	// lfs f10,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// lfs f11,16(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// fmuls f0,f0,f0
	f0.f64 = double(float(f0.f64 * f0.f64));
	// fmadds f13,f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// lfs f0,17764(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17764);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820df114
	if (!cr6.getLT()) goto loc_820DF114;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2940(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2940);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f12,f0
	cr6.compare(ctx.f12.f64, f0.f64);
	// bge cr6,0x820df114
	if (!cr6.getLT()) goto loc_820DF114;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,3452(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3452);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f12,f0
	cr6.compare(ctx.f12.f64, f0.f64);
	// bgt cr6,0x820df174
	if (cr6.getGT()) goto loc_820DF174;
loc_820DF114:
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x820cdf78
	sub_820CDF78(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820cdf78
	sub_820CDF78(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x820ce950
	sub_820CE950(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820df1ac
	if (cr6.getEQ()) goto loc_820DF1AC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lhz r10,6(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 6);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lfs f1,3032(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3032);
	ctx.f1.f64 = double(temp.f32);
	// extsh r11,r10
	r11.s64 = ctx.r10.s16;
	// mulli r10,r11,68
	ctx.r10.s64 = r11.s64 * 68;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// add r5,r10,r11
	ctx.r5.u64 = ctx.r10.u64 + r11.u64;
	// bl 0x820d4280
	sub_820D4280(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820df1ac
	if (cr6.getEQ()) goto loc_820DF1AC;
loc_820DF174:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820def08
	sub_820DEF08(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820df1b0
	if (cr6.getEQ()) goto loc_820DF1B0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r11,r11,0,0,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820df1b0
	if (cr6.getEQ()) goto loc_820DF1B0;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820def08
	sub_820DEF08(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x823ed184
	return;
loc_820DF1AC:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
loc_820DF1B0:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820DF1B8"))) PPC_WEAK_FUNC(sub_820DF1B8);
PPC_FUNC_IMPL(__imp__sub_820DF1B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lwz r31,8(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820df288
	if (cr6.getEQ()) goto loc_820DF288;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820df288
	if (cr6.getEQ()) goto loc_820DF288;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r30,r11,3,31,31
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0x1;
	// bl 0x820d8650
	sub_820D8650(ctx, base);
	// lbz r11,188(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 188);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x820df264
	if (cr6.getEQ()) goto loc_820DF264;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x820df264
	if (cr6.getEQ()) goto loc_820DF264;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x820df240
	if (!cr6.getEQ()) goto loc_820DF240;
	// lwz r31,56(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 56);
loc_820DF220:
	// bl 0x8215cb90
	sub_8215CB90(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// bl 0x8215ccb8
	sub_8215CCB8(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_820DF240:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820df374
	if (!cr6.getEQ()) goto loc_820DF374;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,180(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 180);
	ctx.f13.f64 = double(temp.f32);
	// lwz r31,56(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 56);
	// lfs f0,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820df220
	if (!cr6.getGT()) goto loc_820DF220;
	// b 0x820df268
	goto loc_820DF268;
loc_820DF264:
	// lwz r31,56(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 56);
loc_820DF268:
	// bl 0x8215cb90
	sub_8215CB90(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// bl 0x8215ccb8
	sub_8215CCB8(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_820DF288:
	// lbz r11,188(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 188);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x820df31c
	if (cr6.getEQ()) goto loc_820DF31C;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x820df31c
	if (cr6.getEQ()) goto loc_820DF31C;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x820df2b8
	if (!cr6.getEQ()) goto loc_820DF2B8;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820de8c0
	sub_820DE8C0(ctx, base);
	// b 0x820df354
	goto loc_820DF354;
loc_820DF2B8:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820df354
	if (!cr6.getEQ()) goto loc_820DF354;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,180(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 180);
	ctx.f13.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f0,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820df310
	if (!cr6.getGT()) goto loc_820DF310;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x820de7d8
	sub_820DE7D8(ctx, base);
	// lwz r30,200(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 200);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820df354
	if (cr6.getEQ()) goto loc_820DF354;
loc_820DF2EC:
	// cmplw cr6,r30,r31
	cr6.compare<uint32_t>(r30.u32, r31.u32, xer);
	// beq cr6,0x820df354
	if (cr6.getEQ()) goto loc_820DF354;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820de7d8
	sub_820DE7D8(ctx, base);
	// lwz r30,200(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 200);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x820df2ec
	if (!cr6.getEQ()) goto loc_820DF2EC;
	// b 0x820df354
	goto loc_820DF354;
loc_820DF310:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x820de8c0
	sub_820DE8C0(ctx, base);
	// b 0x820df354
	goto loc_820DF354;
loc_820DF31C:
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820de7d8
	sub_820DE7D8(ctx, base);
	// lwz r30,200(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 200);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820df354
	if (cr6.getEQ()) goto loc_820DF354;
loc_820DF334:
	// cmplw cr6,r30,r31
	cr6.compare<uint32_t>(r30.u32, r31.u32, xer);
	// beq cr6,0x820df354
	if (cr6.getEQ()) goto loc_820DF354;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820de7d8
	sub_820DE7D8(ctx, base);
	// lwz r30,200(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 200);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x820df334
	if (!cr6.getEQ()) goto loc_820DF334;
loc_820DF354:
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// ori r11,r11,16384
	r11.u64 = r11.u64 | 16384;
	// rlwinm r10,r10,0,29,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF7;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// stw r10,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r10.u32);
	// bl 0x820d3878
	sub_820D3878(ctx, base);
loc_820DF374:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820DF380"))) PPC_WEAK_FUNC(sub_820DF380);
PPC_FUNC_IMPL(__imp__sub_820DF380) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lhz r11,6(r4)
	r11.u64 = PPC_LOAD_U16(ctx.r4.u32 + 6);
	// lfs f8,16(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// lhz r10,152(r4)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r4.u32 + 152);
	// lfs f7,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// lfs f6,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// rlwinm r9,r10,0,28,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	// mulli r10,r11,68
	ctx.r10.s64 = r11.s64 * 68;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// addi r11,r11,928
	r11.s64 = r11.s64 + 928;
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lfs f5,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f8,f8,f5
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f5.f64));
	// lfs f5,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fsubs f7,f7,f5
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f5.f64));
	// lfs f5,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// lfs f0,32(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 32);
	f0.f64 = double(temp.f32);
	// fsubs f6,f6,f5
	ctx.f6.f64 = double(float(ctx.f6.f64 - ctx.f5.f64));
	// lfs f9,12(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f5,f9,f0
	ctx.f5.f64 = double(float(ctx.f9.f64 * f0.f64));
	// lfs f12,28(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 28);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,16(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f3,f11,f12
	ctx.f3.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f10,24(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f4,f10,f13
	ctx.f4.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmsubs f11,f10,f11,f5
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f11.f64 - ctx.f5.f64));
	// fmsubs f0,f13,f0,f3
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 - ctx.f3.f64));
	// fmsubs f12,f9,f12,f4
	ctx.f12.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 - ctx.f4.f64));
	// fmuls f13,f8,f11
	ctx.f13.f64 = double(float(ctx.f8.f64 * ctx.f11.f64));
	// fmadds f13,f7,f12,f13
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f13.f64));
	// fmadds f0,f6,f0,f13
	f0.f64 = double(float(ctx.f6.f64 * f0.f64 + ctx.f13.f64));
	// beq cr6,0x820df410
	if (cr6.getEQ()) goto loc_820DF410;
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
loc_820DF410:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r3,0
	ctx.r3.s64 = 0;
	// lfs f13,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bltlr cr6
	if (cr6.getLT()) return;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DF430"))) PPC_WEAK_FUNC(sub_820DF430);
PPC_FUNC_IMPL(__imp__sub_820DF430) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r8,8(r4)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// rlwinm r11,r8,0,4,4
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0x8000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820df4d0
	if (cr6.getEQ()) goto loc_820DF4D0;
	// lbz r11,188(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 188);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820df4d0
	if (!cr6.getEQ()) goto loc_820DF4D0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,180(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 180);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bne cr6,0x820df4d0
	if (!cr6.getEQ()) goto loc_820DF4D0;
	// bl 0x820df380
	sub_820DF380(ctx, base);
	// lhz r11,152(r4)
	r11.u64 = PPC_LOAD_U16(ctx.r4.u32 + 152);
	// rlwinm r10,r11,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820df490
	if (!cr6.getEQ()) goto loc_820DF490;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820df49c
	if (!cr6.getEQ()) goto loc_820DF49C;
	// b 0x820df498
	goto loc_820DF498;
loc_820DF490:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820df49c
	if (cr6.getEQ()) goto loc_820DF49C;
loc_820DF498:
	// lis r11,8192
	r11.s64 = 536870912;
loc_820DF49C:
	// xor r11,r8,r11
	r11.u64 = ctx.r8.u64 ^ r11.u64;
	// rlwinm r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820df4d0
	if (cr6.getEQ()) goto loc_820DF4D0;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
loc_820DF4B0:
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// xoris r10,r10,8192
	ctx.r10.u64 = ctx.r10.u64 ^ 536870912;
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// lwz r11,200(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 200);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820df4d0
	if (cr6.getEQ()) goto loc_820DF4D0;
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// bne cr6,0x820df4b0
	if (!cr6.getEQ()) goto loc_820DF4B0;
loc_820DF4D0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DF4E0"))) PPC_WEAK_FUNC(sub_820DF4E0);
PPC_FUNC_IMPL(__imp__sub_820DF4E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r10,17236(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 17236);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bgtlr cr6
	if (cr6.getGT()) return;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r10,17236(r11)
	PPC_STORE_U32(r11.u32 + 17236, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DF500"))) PPC_WEAK_FUNC(sub_820DF500);
PPC_FUNC_IMPL(__imp__sub_820DF500) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32013
	r31.s64 = -2098003968;
	// lwz r3,17240(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 17240);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820df534
	if (cr6.getEQ()) goto loc_820DF534;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820df534
	if (cr6.getEQ()) goto loc_820DF534;
	// lwz r3,17240(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 17240);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820DF534:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DF548"))) PPC_WEAK_FUNC(sub_820DF548);
PPC_FUNC_IMPL(__imp__sub_820DF548) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32013
	r31.s64 = -2098003968;
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// li r11,0
	r11.s64 = 0;
	// lwz r3,17240(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 17240);
	// stw r11,17236(r10)
	PPC_STORE_U32(ctx.r10.u32 + 17236, r11.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820df588
	if (cr6.getEQ()) goto loc_820DF588;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820df588
	if (cr6.getEQ()) goto loc_820DF588;
	// lwz r3,17240(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 17240);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820DF588:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DF5A0"))) PPC_WEAK_FUNC(sub_820DF5A0);
PPC_FUNC_IMPL(__imp__sub_820DF5A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32013
	r11.s64 = -2098003968;
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r11,17236(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 17236);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgtlr cr6
	if (cr6.getGT()) return;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DF5C0"))) PPC_WEAK_FUNC(sub_820DF5C0);
PPC_FUNC_IMPL(__imp__sub_820DF5C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// li r11,1
	r11.s64 = 1;
	// stw r11,17248(r10)
	PPC_STORE_U32(ctx.r10.u32 + 17248, r11.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// stfs f0,17268(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 17268, temp.u32);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lfs f0,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r11,r11,17252
	r11.s64 = r11.s64 + 17252;
	// stfs f0,0(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// lfs f0,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,4(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4, temp.u32);
	// lfs f0,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8, temp.u32);
	// bl 0x820ae360
	sub_820AE360(ctx, base);
	// cmpwi cr6,r3,32
	cr6.compare<int32_t>(ctx.r3.s32, 32, xer);
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// bne cr6,0x820df640
	if (!cr6.getEQ()) goto loc_820DF640;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,12464(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12464);
	f0.f64 = double(temp.f32);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// stfs f0,5660(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 5660, temp.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r11,12504(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12504, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820DF640:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2704(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2704);
	f0.f64 = double(temp.f32);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// stfs f0,5660(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 5660, temp.u32);
	// li r11,1
	r11.s64 = 1;
	// stw r11,12504(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12504, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DF668"))) PPC_WEAK_FUNC(sub_820DF668);
PPC_FUNC_IMPL(__imp__sub_820DF668) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32013
	r31.s64 = -2098003968;
	// lwz r3,17272(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 17272);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820df69c
	if (cr6.getEQ()) goto loc_820DF69C;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820df69c
	if (cr6.getEQ()) goto loc_820DF69C;
	// lwz r3,17272(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 17272);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820DF69C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DF6B0"))) PPC_WEAK_FUNC(sub_820DF6B0);
PPC_FUNC_IMPL(__imp__sub_820DF6B0) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32013
	r11.s64 = -2098003968;
	// li r3,1
	ctx.r3.s64 = 1;
	// lfs f0,17244(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17244);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgtlr cr6
	if (cr6.getGT()) return;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DF6D8"))) PPC_WEAK_FUNC(sub_820DF6D8);
PPC_FUNC_IMPL(__imp__sub_820DF6D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lis r26,-32013
	r26.s64 = -2098003968;
	// lis r27,-32014
	r27.s64 = -2098069504;
	// lis r31,-32013
	r31.s64 = -2098003968;
	// lwz r10,17248(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 17248);
	// lfs f12,5660(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 5660);
	ctx.f12.f64 = double(temp.f32);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x820df734
	if (cr6.getEQ()) goto loc_820DF734;
	// lfs f13,17244(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 17244);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-6368(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,17244(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 17244, temp.u32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// blt cr6,0x820df738
	if (cr6.getLT()) goto loc_820DF738;
	// li r10,0
	ctx.r10.s64 = 0;
	// fmr f0,f12
	f0.f64 = ctx.f12.f64;
	// stfs f0,17244(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 17244, temp.u32);
	// stw r10,17248(r11)
	PPC_STORE_U32(r11.u32 + 17248, ctx.r10.u32);
	// b 0x820df738
	goto loc_820DF738;
loc_820DF734:
	// lfs f0,17244(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 17244);
	f0.f64 = double(temp.f32);
loc_820DF738:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// ble cr6,0x820df8a4
	if (!cr6.getGT()) goto loc_820DF8A4;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1736(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1736);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820df8a4
	if (!cr6.getEQ()) goto loc_820DF8A4;
	// fdivs f1,f0,f12
	ctx.f1.f64 = double(float(f0.f64 / ctx.f12.f64));
	// bl 0x82117f10
	sub_82117F10(ctx, base);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lwz r11,12504(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12504);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820df8a4
	if (cr6.getEQ()) goto loc_820DF8A4;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r10,-32013
	ctx.r10.s64 = -2098003968;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// lis r29,-31994
	r29.s64 = -2096758784;
	// lwz r11,-6376(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -6376);
	// lwz r9,17264(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 17264);
	// addi r8,r11,-225
	ctx.r8.s64 = r11.s64 + -225;
	// cmpw cr6,r9,r8
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r8.s32, xer);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r30,r9,17776
	r30.s64 = ctx.r9.s64 + 17776;
	// bge cr6,0x820df800
	if (!cr6.getLT()) goto loc_820DF800;
	// stw r11,17264(r10)
	PPC_STORE_U32(ctx.r10.u32 + 17264, r11.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,17244(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 17244);
	f0.f64 = double(temp.f32);
	// lfs f13,15152(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15152);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820df7d4
	if (cr6.getLT()) goto loc_820DF7D4;
	// li r8,13301
	ctx.r8.s64 = 13301;
	// lwz r6,19944(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + 19944);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,98
	ctx.r4.s64 = 98;
	// bl 0x82144920
	sub_82144920(ctx, base);
	// lfs f0,17244(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 17244);
	f0.f64 = double(temp.f32);
loc_820DF7D4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,17876(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17876);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820df800
	if (cr6.getLT()) goto loc_820DF800;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// li r7,0
	ctx.r7.s64 = 0;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// li r6,-1
	ctx.r6.s64 = -1;
	// lfs f1,17872(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17872);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x820bed38
	sub_820BED38(ctx, base);
loc_820DF800:
	// lis r11,-32013
	r11.s64 = -2098003968;
	// lfs f13,5660(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r26.u32 + 5660);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,17268(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 17268);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820df880
	if (!cr6.getLT()) goto loc_820DF880;
	// lfs f13,-6368(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + -6368);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,17268(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 17268, temp.u32);
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r31,r11,17272
	r31.s64 = r11.s64 + 17272;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x820df868
	if (!cr6.getEQ()) goto loc_820DF868;
	// bl 0x8209f588
	sub_8209F588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820df85c
	if (!cr6.getEQ()) goto loc_820DF85C;
	// li r8,13314
	ctx.r8.s64 = 13314;
	// lwz r6,19944(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + 19944);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lwz r3,19936(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 19936);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,102
	ctx.r4.s64 = 102;
	// bl 0x82144920
	sub_82144920(ctx, base);
loc_820DF85C:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820df8a4
	if (cr6.getEQ()) goto loc_820DF8A4;
loc_820DF868:
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r4,r11,17252
	ctx.r4.s64 = r11.s64 + 17252;
	// bl 0x821448f8
	sub_821448F8(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x823ed180
	return;
loc_820DF880:
	// lis r31,-32013
	r31.s64 = -2098003968;
	// lwz r3,17272(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 17272);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820df8a4
	if (cr6.getEQ()) goto loc_820DF8A4;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820df8a4
	if (cr6.getEQ()) goto loc_820DF8A4;
	// lwz r3,17272(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 17272);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820DF8A4:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f31,-64(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820DF8B0"))) PPC_WEAK_FUNC(sub_820DF8B0);
PPC_FUNC_IMPL(__imp__sub_820DF8B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// lwz r10,19400(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 19400);
	// beq cr6,0x820df8cc
	if (cr6.getEQ()) goto loc_820DF8CC;
	// andc r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r3.u64;
	// stw r10,19400(r11)
	PPC_STORE_U32(r11.u32 + 19400, ctx.r10.u32);
	// blr 
	return;
loc_820DF8CC:
	// or r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 | ctx.r3.u64;
	// stw r10,19400(r11)
	PPC_STORE_U32(r11.u32 + 19400, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820DF8D8"))) PPC_WEAK_FUNC(sub_820DF8D8);
PPC_FUNC_IMPL(__imp__sub_820DF8D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r11,19400(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19400);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// blr 
	return;
}

