#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_82183850"))) PPC_WEAK_FUNC(sub_82183850);
PPC_FUNC_IMPL(__imp__sub_82183850) {
	PPC_FUNC_PROLOGUE();
	// addi r3,r3,1276
	ctx.r3.s64 = ctx.r3.s64 + 1276;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183858"))) PPC_WEAK_FUNC(sub_82183858);
PPC_FUNC_IMPL(__imp__sub_82183858) {
	PPC_FUNC_PROLOGUE();
	// ld r3,1288(r3)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r3.u32 + 1288);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183860"))) PPC_WEAK_FUNC(sub_82183860);
PPC_FUNC_IMPL(__imp__sub_82183860) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82183890
	if (cr6.getEQ()) goto loc_82183890;
	// addi r3,r31,652
	ctx.r3.s64 = r31.s64 + 652;
	// li r5,232
	ctx.r5.s64 = 232;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// b 0x82183894
	goto loc_82183894;
loc_82183890:
	// li r11,0
	r11.s64 = 0;
loc_82183894:
	// stb r11,1358(r31)
	PPC_STORE_U8(r31.u32 + 1358, r11.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821838B0"))) PPC_WEAK_FUNC(sub_821838B0);
PPC_FUNC_IMPL(__imp__sub_821838B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-31991
	r11.s64 = -2096562176;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r11,-32216
	ctx.r8.s64 = r11.s64 + -32216;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
loc_821838C0:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821838e4
	if (cr6.getEQ()) goto loc_821838E4;
	// lbz r7,1358(r11)
	ctx.r7.u64 = PPC_LOAD_U8(r11.u32 + 1358);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x821838e4
	if (cr6.getEQ()) goto loc_821838E4;
	// lwz r11,1368(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1368);
	// cmplw cr6,r11,r3
	cr6.compare<uint32_t>(r11.u32, ctx.r3.u32, xer);
	// beq cr6,0x821838fc
	if (cr6.getEQ()) goto loc_821838FC;
loc_821838E4:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r9,8
	cr6.compare<uint32_t>(ctx.r9.u32, 8, xer);
	// blt cr6,0x821838c0
	if (cr6.getLT()) goto loc_821838C0;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_821838FC:
	// rlwinm r11,r9,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r8
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183908"))) PPC_WEAK_FUNC(sub_82183908);
PPC_FUNC_IMPL(__imp__sub_82183908) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820ca110
	sub_820CA110(ctx, base);
	// bl 0x821838b0
	sub_821838B0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183930"))) PPC_WEAK_FUNC(sub_82183930);
PPC_FUNC_IMPL(__imp__sub_82183930) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r4,r11
	r11.u64 = ctx.r4.u64 + r11.u64;
	// rlwinm r11,r11,3,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lwz r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// rlwinm r10,r10,4,28,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xF;
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// beq cr6,0x82183984
	if (cr6.getEQ()) goto loc_82183984;
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// beq cr6,0x8218397c
	if (cr6.getEQ()) goto loc_8218397C;
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x82183974
	if (!cr6.getEQ()) goto loc_82183974;
	// lwz r11,44(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82183974
	if (cr6.getEQ()) goto loc_82183974;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// blr 
	return;
loc_82183974:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_8218397C:
	// ld r3,40(r11)
	ctx.r3.u64 = PPC_LOAD_U64(r11.u32 + 40);
	// blr 
	return;
loc_82183984:
	// lwz r3,40(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183990"))) PPC_WEAK_FUNC(sub_82183990);
PPC_FUNC_IMPL(__imp__sub_82183990) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,1368(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1368);
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bgelr cr6
	if (!cr6.getLT()) return;
	// lis r10,-31991
	ctx.r10.s64 = -2096562176;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,-31872
	ctx.r10.s64 = ctx.r10.s64 + -31872;
	// addi r9,r10,-32
	ctx.r9.s64 = ctx.r10.s64 + -32;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x821839e0
	if (!cr6.getEQ()) goto loc_821839E0;
	// lis r11,21
	r11.s64 = 1376256;
	// ori r9,r11,4336
	ctx.r9.u64 = r11.u64 | 4336;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// li r11,1
	r11.s64 = 1;
	// beq cr6,0x821839e4
	if (cr6.getEQ()) goto loc_821839E4;
loc_821839E0:
	// li r11,0
	r11.s64 = 0;
loc_821839E4:
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821839F0"))) PPC_WEAK_FUNC(sub_821839F0);
PPC_FUNC_IMPL(__imp__sub_821839F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// lis r6,2
	ctx.r6.s64 = 131072;
	// addi r8,r10,1620
	ctx.r8.s64 = ctx.r10.s64 + 1620;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r9,7
	ctx.r9.s64 = 7;
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_82183A18:
	// stw r7,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r7.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82183a18
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82183A18;
	// addi r7,r10,1616
	ctx.r7.s64 = ctx.r10.s64 + 1616;
	// lwz r3,1368(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1368);
	// li r5,512
	ctx.r5.s64 = 512;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8235d7b0
	sub_8235D7B0(ctx, base);
	// addi r11,r3,-5
	r11.s64 = ctx.r3.s64 + -5;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = r11.u64 ^ 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183A58"))) PPC_WEAK_FUNC(sub_82183A58);
PPC_FUNC_IMPL(__imp__sub_82183A58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82183a90
	if (!cr6.getEQ()) goto loc_82183A90;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8209dbd8
	sub_8209DBD8(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stb r11,1(r31)
	PPC_STORE_U8(r31.u32 + 1, r11.u8);
loc_82183A90:
	// bl 0x8209dbf8
	sub_8209DBF8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82183ab8
	if (cr6.getEQ()) goto loc_82183AB8;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82183AB8:
	// li r11,0
	r11.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r11,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r11.u8);
	// stb r11,1(r31)
	PPC_STORE_U8(r31.u32 + 1, r11.u8);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183AE0"))) PPC_WEAK_FUNC(sub_82183AE0);
PPC_FUNC_IMPL(__imp__sub_82183AE0) {
	PPC_FUNC_PROLOGUE();
	// lbz r3,1359(r3)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1359);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183AE8"))) PPC_WEAK_FUNC(sub_82183AE8);
PPC_FUNC_IMPL(__imp__sub_82183AE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r10,0
	ctx.r10.s64 = 0;
	// add r11,r4,r3
	r11.u64 = ctx.r4.u64 + ctx.r3.u64;
	// ori r10,r10,42518
	ctx.r10.u64 = ctx.r10.u64 | 42518;
	// lbzx r3,r11,r10
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183B00"))) PPC_WEAK_FUNC(sub_82183B00);
PPC_FUNC_IMPL(__imp__sub_82183B00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r24{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r29,0
	r29.s64 = 0;
	// addis r28,r30,1
	r28.s64 = r30.s64 + 65536;
	// mr r31,r29
	r31.u64 = r29.u64;
	// addi r28,r28,-23018
	r28.s64 = r28.s64 + -23018;
loc_82183B20:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// bl 0x82183990
	sub_82183990(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82183bf0
	if (cr6.getEQ()) goto loc_82183BF0;
	// li r4,254
	ctx.r4.s64 = 254;
	// cmplwi cr6,r31,9
	cr6.compare<uint32_t>(r31.u32, 9, xer);
	// bgt cr6,0x82183bd0
	if (cr6.getGT()) goto loc_82183BD0;
	// lis r12,-32232
	r12.s64 = -2112356352;
	// addi r12,r12,15196
	r12.s64 = r12.s64 + 15196;
	// rlwinm r0,r31,2,0,29
	r0.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r31.u64) {
	case 0:
		goto loc_82183B84;
	case 1:
		goto loc_82183B8C;
	case 2:
		goto loc_82183B94;
	case 3:
		goto loc_82183B9C;
	case 4:
		goto loc_82183BA4;
	case 5:
		goto loc_82183BAC;
	case 6:
		goto loc_82183BB4;
	case 7:
		goto loc_82183BBC;
	case 8:
		goto loc_82183BC4;
	case 9:
		goto loc_82183BCC;
	default:
		__builtin_unreachable();
	}
	// lwz r16,15236(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15236);
	// lwz r16,15244(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15244);
	// lwz r16,15252(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15252);
	// lwz r16,15260(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15260);
	// lwz r16,15268(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15268);
	// lwz r16,15276(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15276);
	// lwz r16,15284(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15284);
	// lwz r16,15292(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15292);
	// lwz r16,15300(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15300);
	// lwz r16,15308(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15308);
loc_82183B84:
	// li r4,254
	ctx.r4.s64 = 254;
	// b 0x82183bd0
	goto loc_82183BD0;
loc_82183B8C:
	// li r4,252
	ctx.r4.s64 = 252;
	// b 0x82183bd0
	goto loc_82183BD0;
loc_82183B94:
	// li r4,249
	ctx.r4.s64 = 249;
	// b 0x82183bd0
	goto loc_82183BD0;
loc_82183B9C:
	// li r4,247
	ctx.r4.s64 = 247;
	// b 0x82183bd0
	goto loc_82183BD0;
loc_82183BA4:
	// li r4,245
	ctx.r4.s64 = 245;
	// b 0x82183bd0
	goto loc_82183BD0;
loc_82183BAC:
	// li r4,244
	ctx.r4.s64 = 244;
	// b 0x82183bd0
	goto loc_82183BD0;
loc_82183BB4:
	// li r4,251
	ctx.r4.s64 = 251;
	// b 0x82183bd0
	goto loc_82183BD0;
loc_82183BBC:
	// li r4,248
	ctx.r4.s64 = 248;
	// b 0x82183bd0
	goto loc_82183BD0;
loc_82183BC4:
	// li r4,246
	ctx.r4.s64 = 246;
	// b 0x82183bd0
	goto loc_82183BD0;
loc_82183BCC:
	// li r4,243
	ctx.r4.s64 = 243;
loc_82183BD0:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r3,1368(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1368);
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// bl 0x8235da10
	sub_8235DA10(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r8,r11,1
	ctx.r8.u64 = r11.u64 ^ 1;
loc_82183BF0:
	// stbx r8,r28,r31
	PPC_STORE_U8(r28.u32 + r31.u32, ctx.r8.u8);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmpwi cr6,r31,10
	cr6.compare<int32_t>(r31.s32, 10, xer);
	// blt cr6,0x82183b20
	if (cr6.getLT()) goto loc_82183B20;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_82183C08"))) PPC_WEAK_FUNC(sub_82183C08);
PPC_FUNC_IMPL(__imp__sub_82183C08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r9,r11,-20432
	ctx.r9.s64 = r11.s64 + -20432;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_82183C18:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplw cr6,r8,r4
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r4.u32, xer);
	// beq cr6,0x82183c3c
	if (cr6.getEQ()) goto loc_82183C3C;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r8,r9,36
	ctx.r8.s64 = ctx.r9.s64 + 36;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// blt cr6,0x82183c18
	if (cr6.getLT()) goto loc_82183C18;
	// blr 
	return;
loc_82183C3C:
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// rlwinm r9,r3,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 3) & 0xFFFFFFF8;
	// lis r11,-31992
	r11.s64 = -2096627712;
	// add r9,r3,r9
	ctx.r9.u64 = ctx.r3.u64 + ctx.r9.u64;
	// addi r11,r11,31880
	r11.s64 = r11.s64 + 31880;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpw cr6,r9,r5
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r5.s32, xer);
	// bne cr6,0x82183c80
	if (!cr6.getEQ()) goto loc_82183C80;
	// addi r9,r11,5
	ctx.r9.s64 = r11.s64 + 5;
	// lbzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
loc_82183C80:
	// addi r9,r11,4
	ctx.r9.s64 = r11.s64 + 4;
	// stwx r5,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r5.u32);
	// addi r7,r11,5
	ctx.r7.s64 = r11.s64 + 5;
	// li r8,1
	ctx.r8.s64 = 1;
	// li r11,0
	r11.s64 = 0;
	// stbx r8,r10,r9
	PPC_STORE_U8(ctx.r10.u32 + ctx.r9.u32, ctx.r8.u8);
	// stbx r11,r10,r7
	PPC_STORE_U8(ctx.r10.u32 + ctx.r7.u32, r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183CA0"))) PPC_WEAK_FUNC(sub_82183CA0);
PPC_FUNC_IMPL(__imp__sub_82183CA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// lis r4,0
	ctx.r4.s64 = 0;
	// ori r4,r4,32769
	ctx.r4.u64 = ctx.r4.u64 | 32769;
	// lwz r3,1368(r6)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r6.u32 + 1368);
	// bl 0x82183c08
	sub_82183C08(ctx, base);
	// lis r11,-31992
	r11.s64 = -2096627712;
	// lwz r10,1368(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 1368);
	// addi r11,r11,31880
	r11.s64 = r11.s64 + 31880;
	// mulli r10,r10,360
	ctx.r10.s64 = ctx.r10.s64 * 360;
	// addi r9,r11,240
	ctx.r9.s64 = r11.s64 + 240;
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// cmpw cr6,r9,r5
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r5.s32, xer);
	// bne cr6,0x82183cf4
	if (!cr6.getEQ()) goto loc_82183CF4;
	// addi r9,r11,245
	ctx.r9.s64 = r11.s64 + 245;
	// lbzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r9.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82183d2c
	if (cr6.getEQ()) goto loc_82183D2C;
loc_82183CF4:
	// lwz r10,1368(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 1368);
	// addi r9,r11,240
	ctx.r9.s64 = r11.s64 + 240;
	// li r8,1
	ctx.r8.s64 = 1;
	// mulli r10,r10,360
	ctx.r10.s64 = ctx.r10.s64 * 360;
	// stwx r5,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, ctx.r5.u32);
	// lwz r9,1368(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 1368);
	// addi r10,r11,244
	ctx.r10.s64 = r11.s64 + 244;
	// mulli r9,r9,360
	ctx.r9.s64 = ctx.r9.s64 * 360;
	// stbx r8,r9,r10
	PPC_STORE_U8(ctx.r9.u32 + ctx.r10.u32, ctx.r8.u8);
	// lwz r10,1368(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 1368);
	// addi r11,r11,245
	r11.s64 = r11.s64 + 245;
	// li r7,0
	ctx.r7.s64 = 0;
	// mulli r10,r10,360
	ctx.r10.s64 = ctx.r10.s64 * 360;
	// stbx r7,r10,r11
	PPC_STORE_U8(ctx.r10.u32 + r11.u32, ctx.r7.u8);
loc_82183D2C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183D40"))) PPC_WEAK_FUNC(sub_82183D40);
PPC_FUNC_IMPL(__imp__sub_82183D40) {
	PPC_FUNC_PROLOGUE();
	// lbz r3,661(r3)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + 661);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183D48"))) PPC_WEAK_FUNC(sub_82183D48);
PPC_FUNC_IMPL(__imp__sub_82183D48) {
	PPC_FUNC_PROLOGUE();
	// lbz r3,660(r3)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + 660);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183D50"))) PPC_WEAK_FUNC(sub_82183D50);
PPC_FUNC_IMPL(__imp__sub_82183D50) {
	PPC_FUNC_PROLOGUE();
	// lbz r3,880(r3)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r3.u32 + 880);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183D58"))) PPC_WEAK_FUNC(sub_82183D58);
PPC_FUNC_IMPL(__imp__sub_82183D58) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r24{};
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r3,3
	cr6.compare<uint32_t>(ctx.r3.u32, 3, xer);
	// bgt cr6,0x82183db4
	if (cr6.getGT()) goto loc_82183DB4;
	// lis r12,-32232
	r12.s64 = -2112356352;
	// addi r12,r12,15740
	r12.s64 = r12.s64 + 15740;
	// rlwinm r0,r3,2,0,29
	r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82183D8C;
	case 1:
		goto loc_82183D98;
	case 2:
		goto loc_82183DA4;
	case 3:
		goto loc_82183DB0;
	default:
		__builtin_unreachable();
	}
	// lwz r16,15756(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15756);
	// lwz r16,15768(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15768);
	// lwz r16,15780(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15780);
	// lwz r16,15792(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15792);
loc_82183D8C:
	// li r11,0
	r11.s64 = 0;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183D98:
	// li r11,1
	r11.s64 = 1;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183DA4:
	// li r11,2
	r11.s64 = 2;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183DB0:
	// li r11,3
	r11.s64 = 3;
loc_82183DB4:
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
	// .long 0x0
}

__attribute__((alias("__imp__sub_82183DC0"))) PPC_WEAK_FUNC(sub_82183DC0);
PPC_FUNC_IMPL(__imp__sub_82183DC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r24{};
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r3,19
	cr6.compare<uint32_t>(ctx.r3.u32, 19, xer);
	// bgt cr6,0x82183f1c
	if (cr6.getGT()) goto loc_82183F1C;
	// lis r12,-32232
	r12.s64 = -2112356352;
	// addi r12,r12,15844
	r12.s64 = r12.s64 + 15844;
	// rlwinm r0,r3,2,0,29
	r0.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r3.u64) {
	case 0:
		goto loc_82183E34;
	case 1:
		goto loc_82183E40;
	case 2:
		goto loc_82183E4C;
	case 3:
		goto loc_82183E58;
	case 4:
		goto loc_82183E64;
	case 5:
		goto loc_82183E70;
	case 6:
		goto loc_82183E7C;
	case 7:
		goto loc_82183E88;
	case 8:
		goto loc_82183E94;
	case 9:
		goto loc_82183EA0;
	case 10:
		goto loc_82183EAC;
	case 11:
		goto loc_82183EB8;
	case 12:
		goto loc_82183EC4;
	case 13:
		goto loc_82183ED0;
	case 14:
		goto loc_82183EDC;
	case 15:
		goto loc_82183EE8;
	case 16:
		goto loc_82183EF4;
	case 17:
		goto loc_82183F00;
	case 18:
		goto loc_82183F0C;
	case 19:
		goto loc_82183F18;
	default:
		__builtin_unreachable();
	}
	// lwz r16,15924(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15924);
	// lwz r16,15936(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15936);
	// lwz r16,15948(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15948);
	// lwz r16,15960(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15960);
	// lwz r16,15972(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15972);
	// lwz r16,15984(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15984);
	// lwz r16,15996(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 15996);
	// lwz r16,16008(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 16008);
	// lwz r16,16020(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 16020);
	// lwz r16,16032(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 16032);
	// lwz r16,16044(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 16044);
	// lwz r16,16056(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 16056);
	// lwz r16,16068(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 16068);
	// lwz r16,16080(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 16080);
	// lwz r16,16092(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 16092);
	// lwz r16,16104(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 16104);
	// lwz r16,16116(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 16116);
	// lwz r16,16128(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 16128);
	// lwz r16,16140(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 16140);
	// lwz r16,16152(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 16152);
loc_82183E34:
	// li r11,0
	r11.s64 = 0;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183E40:
	// li r11,1
	r11.s64 = 1;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183E4C:
	// li r11,2
	r11.s64 = 2;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183E58:
	// li r11,3
	r11.s64 = 3;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183E64:
	// li r11,4
	r11.s64 = 4;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183E70:
	// li r11,5
	r11.s64 = 5;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183E7C:
	// li r11,6
	r11.s64 = 6;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183E88:
	// li r11,7
	r11.s64 = 7;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183E94:
	// li r11,8
	r11.s64 = 8;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183EA0:
	// li r11,9
	r11.s64 = 9;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183EAC:
	// li r11,10
	r11.s64 = 10;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183EB8:
	// li r11,11
	r11.s64 = 11;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183EC4:
	// li r11,12
	r11.s64 = 12;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183ED0:
	// li r11,13
	r11.s64 = 13;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183EDC:
	// li r11,14
	r11.s64 = 14;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183EE8:
	// li r11,15
	r11.s64 = 15;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183EF4:
	// li r11,16
	r11.s64 = 16;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183F00:
	// li r11,17
	r11.s64 = 17;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183F0C:
	// li r11,18
	r11.s64 = 18;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
loc_82183F18:
	// li r11,19
	r11.s64 = 19;
loc_82183F1C:
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
	// .long 0x0
}

__attribute__((alias("__imp__sub_82183F28"))) PPC_WEAK_FUNC(sub_82183F28);
PPC_FUNC_IMPL(__imp__sub_82183F28) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister r11{};
	PPCRegister temp{};
	// srawi r11,r4,5
	xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0x1F) != 0);
	r11.s64 = ctx.r4.s32 >> 5;
	// li r10,1
	ctx.r10.s64 = 1;
	// addze r11,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	r11.s64 = temp.s64;
	// srawi r9,r4,5
	xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0x1F) != 0);
	ctx.r9.s64 = ctx.r4.s32 >> 5;
	// rlwinm r8,r11,5,0,26
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// addze r11,r9
	temp.s64 = ctx.r9.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r9.u32;
	r11.s64 = temp.s64;
	// subf r9,r8,r4
	ctx.r9.s64 = ctx.r4.s64 - ctx.r8.s64;
	// addi r11,r11,166
	r11.s64 = r11.s64 + 166;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r3
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// slw r10,r10,r9
	ctx.r10.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r9.u8 & 0x3F));
	// and r11,r10,r11
	r11.u64 = ctx.r10.u64 & r11.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = r11.u64 ^ 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183F68"))) PPC_WEAK_FUNC(sub_82183F68);
PPC_FUNC_IMPL(__imp__sub_82183F68) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,1604(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1604);
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// beq cr6,0x82183fb8
	if (cr6.getEQ()) goto loc_82183FB8;
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82183fb8
	if (cr6.getEQ()) goto loc_82183FB8;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82183fb8
	if (cr6.getEQ()) goto loc_82183FB8;
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82183fb8
	if (cr6.getEQ()) goto loc_82183FB8;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x82183fb8
	if (cr6.getEQ()) goto loc_82183FB8;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// beq cr6,0x82183fb8
	if (cr6.getEQ()) goto loc_82183FB8;
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// beq cr6,0x82183fb8
	if (cr6.getEQ()) goto loc_82183FB8;
	// cmpwi cr6,r11,16
	cr6.compare<int32_t>(r11.s32, 16, xer);
	// beq cr6,0x82183fb8
	if (cr6.getEQ()) goto loc_82183FB8;
	// cmpwi cr6,r11,17
	cr6.compare<int32_t>(r11.s32, 17, xer);
	// li r11,1
	r11.s64 = 1;
	// bne cr6,0x82183fbc
	if (!cr6.getEQ()) goto loc_82183FBC;
loc_82183FB8:
	// li r11,0
	r11.s64 = 0;
loc_82183FBC:
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183FC8"))) PPC_WEAK_FUNC(sub_82183FC8);
PPC_FUNC_IMPL(__imp__sub_82183FC8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,1359(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1359);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// li r11,1
	r11.s64 = 1;
	// stb r11,1600(r3)
	PPC_STORE_U8(ctx.r3.u32 + 1600, r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183FE0"))) PPC_WEAK_FUNC(sub_82183FE0);
PPC_FUNC_IMPL(__imp__sub_82183FE0) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,3276(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 3276);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82183FE8"))) PPC_WEAK_FUNC(sub_82183FE8);
PPC_FUNC_IMPL(__imp__sub_82183FE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// bltlr cr6
	if (cr6.getLT()) return;
	// lwz r10,3276(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3276);
	// cmpw cr6,r4,r10
	cr6.compare<int32_t>(ctx.r4.s32, ctx.r10.s32, xer);
	// bgelr cr6
	if (!cr6.getLT()) return;
	// lwz r11,3272(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 3272);
	// mulli r10,r4,196
	ctx.r10.s64 = ctx.r4.s64 * 196;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82184018"))) PPC_WEAK_FUNC(sub_82184018);
PPC_FUNC_IMPL(__imp__sub_82184018) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// li r11,0
	r11.s64 = 0;
	// lwz r9,3276(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3276);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// blelr cr6
	if (!cr6.getGT()) return;
	// lwz r10,3272(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3272);
loc_82184034:
	// ld r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// cmpld cr6,r8,r4
	cr6.compare<uint64_t>(ctx.r8.u64, ctx.r4.u64, xer);
	// beq cr6,0x82184054
	if (cr6.getEQ()) goto loc_82184054;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,196
	ctx.r10.s64 = ctx.r10.s64 + 196;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// blt cr6,0x82184034
	if (cr6.getLT()) goto loc_82184034;
	// blr 
	return;
loc_82184054:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82184060"))) PPC_WEAK_FUNC(sub_82184060);
PPC_FUNC_IMPL(__imp__sub_82184060) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r11,1616(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1616);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821840c4
	if (cr6.getEQ()) goto loc_821840C4;
	// addi r4,r9,1620
	ctx.r4.s64 = ctx.r9.s64 + 1620;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r10,7
	ctx.r10.s64 = 7;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_82184094:
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82184094
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82184094;
	// lwz r3,1616(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1616);
	// bl 0x8235d698
	sub_8235D698(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x821840bc
	if (cr6.getEQ()) goto loc_821840BC;
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x821840c0
	if (!cr6.getEQ()) goto loc_821840C0;
loc_821840BC:
	// li r11,1
	r11.s64 = 1;
loc_821840C0:
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
loc_821840C4:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821840D8"))) PPC_WEAK_FUNC(sub_821840D8);
PPC_FUNC_IMPL(__imp__sub_821840D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,997
	ctx.r3.s64 = 997;
	// addi r31,r11,1620
	r31.s64 = r11.s64 + 1620;
	// lwz r10,1620(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1620);
	// cmplwi cr6,r10,997
	cr6.compare<uint32_t>(ctx.r10.u32, 997, xer);
	// beq cr6,0x82184140
	if (cr6.getEQ()) goto loc_82184140;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8235d6e0
	sub_8235D6E0(ctx, base);
	// cmplwi cr6,r3,1627
	cr6.compare<uint32_t>(ctx.r3.u32, 1627, xer);
	// bne cr6,0x82184124
	if (!cr6.getEQ()) goto loc_82184124;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8235de98
	sub_8235DE98(ctx, base);
	// clrlwi r3,r3,16
	ctx.r3.u64 = ctx.r3.u32 & 0xFFFF;
loc_82184124:
	// mr r11,r31
	r11.u64 = r31.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,7
	ctx.r9.s64 = 7;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_82184134:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82184134
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82184134;
loc_82184140:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82184158"))) PPC_WEAK_FUNC(sub_82184158);
PPC_FUNC_IMPL(__imp__sub_82184158) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// mr r8,r3
	ctx.r8.u64 = ctx.r3.u64;
	// addi r9,r11,-32216
	ctx.r9.s64 = r11.s64 + -32216;
	// li r3,0
	ctx.r3.s64 = 0;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
loc_82184178:
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x821841d0
	if (!cr6.getEQ()) goto loc_821841D0;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821841c0
	if (cr6.getEQ()) goto loc_821841C0;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x821841c0
	if (cr6.getEQ()) goto loc_821841C0;
	// lbz r7,1358(r11)
	ctx.r7.u64 = PPC_LOAD_U8(r11.u32 + 1358);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x821841c0
	if (cr6.getEQ()) goto loc_821841C0;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x82183f68
	sub_82183F68(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
loc_821841C0:
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r11,r9,32
	r11.s64 = ctx.r9.s64 + 32;
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// blt cr6,0x82184178
	if (cr6.getLT()) goto loc_82184178;
loc_821841D0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821841E0"))) PPC_WEAK_FUNC(sub_821841E0);
PPC_FUNC_IMPL(__imp__sub_821841E0) {
	PPC_FUNC_PROLOGUE();
	// li r3,19
	ctx.r3.s64 = 19;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821841E8"))) PPC_WEAK_FUNC(sub_821841E8);
PPC_FUNC_IMPL(__imp__sub_821841E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// addi r10,r10,-20344
	ctx.r10.s64 = ctx.r10.s64 + -20344;
	// li r9,-1
	ctx.r9.s64 = -1;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// li r6,15
	ctx.r6.s64 = 15;
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// addi r5,r11,768
	ctx.r5.s64 = r11.s64 + 768;
	// stw r30,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r30.u32);
	// li r4,16
	ctx.r4.s64 = 16;
	// stw r9,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r9.u32);
	// addi r3,r31,44
	ctx.r3.s64 = r31.s64 + 44;
	// stb r30,16(r31)
	PPC_STORE_U8(r31.u32 + 16, r30.u8);
	// sth r30,18(r31)
	PPC_STORE_U16(r31.u32 + 18, r30.u16);
	// stw r30,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r30.u32);
	// stw r30,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r30.u32);
	// stw r30,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r30.u32);
	// stw r30,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r30.u32);
	// stw r30,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r30.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lwz r11,104(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 104);
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// bl 0x823ecf88
	sub_823ECF88(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stb r30,59(r31)
	PPC_STORE_U8(r31.u32 + 59, r30.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82184280"))) PPC_WEAK_FUNC(sub_82184280);
PPC_FUNC_IMPL(__imp__sub_82184280) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x8215c528
	sub_8215C528(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x821842f8
	if (cr6.getEQ()) goto loc_821842F8;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r9,-1
	ctx.r9.s64 = -1;
	// addi r10,r11,-20344
	ctx.r10.s64 = r11.s64 + -20344;
	// li r11,0
	r11.s64 = 0;
	// stw r9,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r9.u32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stb r11,16(r3)
	PPC_STORE_U8(ctx.r3.u32 + 16, r11.u8);
	// sth r11,18(r3)
	PPC_STORE_U16(ctx.r3.u32 + 18, r11.u16);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r11,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, r11.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// lwz r10,-26072(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -26072);
	// stb r11,44(r3)
	PPC_STORE_U8(ctx.r3.u32 + 44, r11.u8);
	// stw r10,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_821842F8:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82184310"))) PPC_WEAK_FUNC(sub_82184310);
PPC_FUNC_IMPL(__imp__sub_82184310) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r5,8
	ctx.r5.s64 = 8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823b2af8
	sub_823B2AF8(ctx, base);
	// li r5,7
	ctx.r5.s64 = 7;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,40(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// bl 0x823b2af8
	sub_823B2AF8(ctx, base);
	// addi r29,r31,44
	r29.s64 = r31.s64 + 44;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_82184360:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82184360
	if (!cr6.getEQ()) goto loc_82184360;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// rotlwi r31,r11,0
	r31.u64 = __builtin_rotateleft32(r11.u32, 0);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823b2af8
	sub_823B2AF8(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823b2fb0
	sub_823B2FB0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_821843A8"))) PPC_WEAK_FUNC(sub_821843A8);
PPC_FUNC_IMPL(__imp__sub_821843A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r4,8
	ctx.r4.s64 = 8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823b2d28
	sub_823B2D28(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823b2d28
	sub_823B2D28(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,40(r30)
	PPC_STORE_U32(r30.u32 + 40, r11.u32);
	// bl 0x823b2d28
	sub_823B2D28(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r4,r30,44
	ctx.r4.s64 = r30.s64 + 44;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x823b2e98
	sub_823B2E98(ctx, base);
	// add r11,r29,r30
	r11.u64 = r29.u64 + r30.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r10,44(r11)
	PPC_STORE_U8(r11.u32 + 44, ctx.r10.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82184410"))) PPC_WEAK_FUNC(sub_82184410);
PPC_FUNC_IMPL(__imp__sub_82184410) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,40(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// bl 0x82158ab8
	sub_82158AB8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82184458
	if (cr6.getEQ()) goto loc_82184458;
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82184458
	if (cr6.getEQ()) goto loc_82184458;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bne cr6,0x82184458
	if (!cr6.getEQ()) goto loc_82184458;
	// addi r4,r31,44
	ctx.r4.s64 = r31.s64 + 44;
	// bl 0x82157fd8
	sub_82157FD8(ctx, base);
loc_82184458:
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82184470"))) PPC_WEAK_FUNC(sub_82184470);
PPC_FUNC_IMPL(__imp__sub_82184470) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lbz r11,1359(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1359);
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8218452c
	if (cr6.getEQ()) goto loc_8218452C;
	// lis r11,25576
	r11.s64 = 1676148736;
	// lwz r4,1368(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// li r9,0
	ctx.r9.s64 = 0;
	// ori r29,r11,16383
	r29.u64 = r11.u64 | 16383;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r29.u32);
	// bl 0x823bd0a8
	sub_823BD0A8(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82184528
	if (cr6.getEQ()) goto loc_82184528;
	// cmplwi cr6,r3,122
	cr6.compare<uint32_t>(ctx.r3.u32, 122, xer);
	// bne cr6,0x82184528
	if (!cr6.getEQ()) goto loc_82184528;
	// addi r5,r31,1400
	ctx.r5.s64 = r31.s64 + 1400;
	// li r11,2
	r11.s64 = 2;
	// addi r6,r31,1372
	ctx.r6.s64 = r31.s64 + 1372;
	// li r4,1
	ctx.r4.s64 = 1;
	// std r30,0(r5)
	PPC_STORE_U64(ctx.r5.u32 + 0, r30.u64);
	// std r30,8(r5)
	PPC_STORE_U64(ctx.r5.u32 + 8, r30.u64);
	// std r30,16(r5)
	PPC_STORE_U64(ctx.r5.u32 + 16, r30.u64);
	// std r30,24(r5)
	PPC_STORE_U64(ctx.r5.u32 + 24, r30.u64);
	// std r30,32(r5)
	PPC_STORE_U64(ctx.r5.u32 + 32, r30.u64);
	// lwz r3,1368(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// ld r10,1288(r31)
	ctx.r10.u64 = PPC_LOAD_U64(r31.u32 + 1288);
	// stw r11,1400(r31)
	PPC_STORE_U32(r31.u32 + 1400, r11.u32);
	// stw r29,1416(r31)
	PPC_STORE_U32(r31.u32 + 1416, r29.u32);
	// stw r3,1408(r31)
	PPC_STORE_U32(r31.u32 + 1408, ctx.r3.u32);
	// std r10,1408(r31)
	PPC_STORE_U64(r31.u32 + 1408, ctx.r10.u64);
	// bl 0x823bd110
	sub_823BD110(ctx, base);
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// beq cr6,0x82184524
	if (cr6.getEQ()) goto loc_82184524;
	// cmplwi cr6,r3,996
	cr6.compare<uint32_t>(ctx.r3.u32, 996, xer);
	// bne cr6,0x82184528
	if (!cr6.getEQ()) goto loc_82184528;
loc_82184524:
	// li r30,1
	r30.s64 = 1;
loc_82184528:
	// clrlwi r3,r30,24
	ctx.r3.u64 = r30.u32 & 0xFF;
loc_8218452C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82184538"))) PPC_WEAK_FUNC(sub_82184538);
PPC_FUNC_IMPL(__imp__sub_82184538) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,1372(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1372);
	// addi r31,r3,1372
	r31.s64 = ctx.r3.s64 + 1372;
	// cmplwi cr6,r11,997
	cr6.compare<uint32_t>(r11.u32, 997, xer);
	// beq cr6,0x82184598
	if (cr6.getEQ()) goto loc_82184598;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8235de98
	sub_8235DE98(ctx, base);
	// cntlzw r10,r3
	ctx.r10.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// mr r11,r31
	r11.u64 = r31.u64;
	// rlwinm r3,r10,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r10,7
	ctx.r10.s64 = 7;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_82184578:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82184578
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82184578;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82184598:
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821845B0"))) PPC_WEAK_FUNC(sub_821845B0);
PPC_FUNC_IMPL(__imp__sub_821845B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed120
	// stfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -104, f30.u64);
	// stfd f31,-96(r1)
	PPC_STORE_U64(ctx.r1.u32 + -96, f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r3,-1
	ctx.r3.s64 = -1;
	// addi r23,r28,1372
	r23.s64 = r28.s64 + 1372;
	// lwz r11,1372(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 1372);
	// cmplwi cr6,r11,997
	cr6.compare<uint32_t>(r11.u32, 997, xer);
	// beq cr6,0x82184770
	if (cr6.getEQ()) goto loc_82184770;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8235de98
	sub_8235DE98(ctx, base);
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// rlwinm r22,r11,27,31,31
	r22.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// li r24,0
	r24.s64 = 0;
	// bne cr6,0x82184750
	if (!cr6.getEQ()) goto loc_82184750;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r29,r11,-20464
	r29.s64 = r11.s64 + -20464;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r31,r28,40
	r31.s64 = r28.s64 + 40;
	// subfic r27,r28,-40
	xer.ca = r28.u32 <= 4294967256;
	r27.s64 = -40 - r28.s64;
	// lfs f30,2688(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2688);
	f30.f64 = double(temp.f32);
	// li r26,8
	r26.s64 = 8;
	// li r25,1000
	r25.s64 = 1000;
	// lfd f31,2752(r11)
	f31.u64 = PPC_LOAD_U64(r11.u32 + 2752);
loc_82184620:
	// lwz r11,648(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 648);
	// addi r10,r31,4
	ctx.r10.s64 = r31.s64 + 4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// add r11,r11,r27
	r11.u64 = r11.u64 + r27.u64;
	// add r30,r11,r31
	r30.u64 = r11.u64 + r31.u64;
	// ld r11,8(r30)
	r11.u64 = PPC_LOAD_U64(r30.u32 + 8);
	// std r11,-24(r31)
	PPC_STORE_U64(r31.u32 + -24, r11.u64);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// stw r11,-32(r31)
	PPC_STORE_U32(r31.u32 + -32, r11.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r9,r11,4,28,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xF;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// stw r11,-16(r31)
	PPC_STORE_U32(r31.u32 + -16, r11.u32);
	// cmplwi cr6,r9,5
	cr6.compare<uint32_t>(ctx.r9.u32, 5, xer);
	// bgt cr6,0x8218473c
	if (cr6.getGT()) goto loc_8218473C;
	// lis r12,-32232
	r12.s64 = -2112356352;
	// addi r12,r12,18036
	r12.s64 = r12.s64 + 18036;
	// rlwinm r0,r9,2,0,29
	r0.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_8218468C;
	case 1:
		goto loc_821846A8;
	case 2:
		goto loc_821846C4;
	case 3:
		goto loc_8218473C;
	case 4:
		goto loc_821846E8;
	case 5:
		goto loc_8218470C;
	default:
		__builtin_unreachable();
	}
	// lwz r16,18060(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 18060);
	// lwz r16,18088(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 18088);
	// lwz r16,18116(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 18116);
	// lwz r16,18236(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 18236);
	// lwz r16,18152(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 18152);
	// lwz r16,18188(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 18188);
loc_8218468C:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r24
	r11.u64 = r24.u64;
	// beq cr6,0x821846a0
	if (cr6.getEQ()) goto loc_821846A0;
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
loc_821846A0:
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x8218473c
	goto loc_8218473C;
loc_821846A8:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r24
	r11.u64 = r24.u64;
	// beq cr6,0x821846bc
	if (cr6.getEQ()) goto loc_821846BC;
	// ld r11,32(r30)
	r11.u64 = PPC_LOAD_U64(r30.u32 + 32);
loc_821846BC:
	// std r11,0(r31)
	PPC_STORE_U64(r31.u32 + 0, r11.u64);
	// b 0x8218473c
	goto loc_8218473C;
loc_821846C4:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x821846dc
	if (!cr6.getEQ()) goto loc_821846DC;
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = f31.f64;
	// stfd f0,0(r31)
	PPC_STORE_U64(r31.u32 + 0, f0.u64);
	// b 0x8218473c
	goto loc_8218473C;
loc_821846DC:
	// lfd f0,32(r30)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(r30.u32 + 32);
	// stfd f0,0(r31)
	PPC_STORE_U64(r31.u32 + 0, f0.u64);
	// b 0x8218473c
	goto loc_8218473C;
loc_821846E8:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82184700
	if (!cr6.getEQ()) goto loc_82184700;
	// fmr f0,f30
	ctx.fpscr.disableFlushMode();
	f0.f64 = f30.f64;
	// stfs f0,0(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// b 0x8218473c
	goto loc_8218473C;
loc_82184700:
	// lfs f0,32(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 32);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// b 0x8218473c
	goto loc_8218473C;
loc_8218470C:
	// lwz r4,36(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82184730
	if (cr6.getEQ()) goto loc_82184730;
	// lwz r5,32(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// lwz r3,0(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lwz r11,32(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x8218473c
	goto loc_8218473C;
loc_82184730:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r24,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r24.u32);
	// stw r25,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r25.u32);
loc_8218473C:
	// addi r26,r26,-1
	r26.s64 = r26.s64 + -1;
	// addi r31,r31,40
	r31.s64 = r31.s64 + 40;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x82184620
	if (!cr6.getEQ()) goto loc_82184620;
loc_82184750:
	// mr r11,r23
	r11.u64 = r23.u64;
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
	// li r10,7
	ctx.r10.s64 = 7;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_82184760:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82184760
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82184760;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
loc_82184770:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f30,-104(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f31,-96(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x823ed170
	return;
}

__attribute__((alias("__imp__sub_82184780"))) PPC_WEAK_FUNC(sub_82184780);
PPC_FUNC_IMPL(__imp__sub_82184780) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,0
	r11.s64 = 0;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// ori r11,r11,42520
	r11.u64 = r11.u64 | 42520;
	// lbzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
	// lis r11,0
	r11.s64 = 0;
	// ori r11,r11,42525
	r11.u64 = r11.u64 | 42525;
	// lbzx r11,r10,r11
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lwz r9,3276(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3276);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r11,0
	r11.s64 = 0;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// ble cr6,0x821847e8
	if (!cr6.getGT()) goto loc_821847E8;
	// lwz r10,3272(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3272);
loc_821847C4:
	// ld r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r10.u32 + 0);
	// cmpld cr6,r7,r4
	cr6.compare<uint64_t>(ctx.r7.u64, ctx.r4.u64, xer);
	// beq cr6,0x821847e4
	if (cr6.getEQ()) goto loc_821847E4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,196
	ctx.r10.s64 = ctx.r10.s64 + 196;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// blt cr6,0x821847c4
	if (cr6.getLT()) goto loc_821847C4;
	// b 0x821847e8
	goto loc_821847E8;
loc_821847E4:
	// li r8,1
	ctx.r8.s64 = 1;
loc_821847E8:
	// clrlwi r11,r8,24
	r11.u64 = ctx.r8.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82184800"))) PPC_WEAK_FUNC(sub_82184800);
PPC_FUNC_IMPL(__imp__sub_82184800) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-1680(r1)
	ea = -1680 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r29,0
	r29.s64 = 0;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// li r7,5
	ctx.r7.s64 = 5;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,1368(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 1368);
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r29,3188(r30)
	PPC_STORE_U32(r30.u32 + 3188, r29.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r29,1616(r30)
	PPC_STORE_U32(r30.u32 + 1616, r29.u32);
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// bl 0x8235d690
	sub_8235D690(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82184954
	if (!cr6.getEQ()) goto loc_82184954;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// li r5,1540
	ctx.r5.s64 = 1540;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// bl 0x8235de80
	sub_8235DE80(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82184954
	if (!cr6.getEQ()) goto loc_82184954;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82184954
	if (cr6.getEQ()) goto loc_82184954;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// li r31,-1
	r31.s64 = -1;
	// addi r3,r11,-31832
	ctx.r3.s64 = r11.s64 + -31832;
	// bl 0x823edbb8
	sub_823EDBB8(ctx, base);
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82184954
	if (cr6.getEQ()) goto loc_82184954;
	// lis r11,-32019
	r11.s64 = -2098397184;
	// addi r6,r1,360
	ctx.r6.s64 = ctx.r1.s64 + 360;
	// addi r5,r11,26504
	ctx.r5.s64 = r11.s64 + 26504;
loc_821848A0:
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
loc_821848A8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r8,r8,r9
	ctx.r8.s64 = ctx.r9.s64 - ctx.r8.s64;
	// beq cr6,0x821848cc
	if (cr6.getEQ()) goto loc_821848CC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x821848a8
	if (cr6.getEQ()) goto loc_821848A8;
loc_821848CC:
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x821848fc
	if (!cr6.getEQ()) goto loc_821848FC;
	// cntlzw r11,r31
	r11.u64 = r31.u32 == 0 ? 32 : __builtin_clz(r31.u32);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x821848ec
	if (!cr6.getEQ()) goto loc_821848EC;
	// mr r11,r29
	r11.u64 = r29.u64;
loc_821848EC:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821848fc
	if (cr6.getEQ()) goto loc_821848FC;
	// mr r31,r7
	r31.u64 = ctx.r7.u64;
loc_821848FC:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,308
	ctx.r6.s64 = ctx.r6.s64 + 308;
	// cmplw cr6,r7,r4
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r4.u32, xer);
	// blt cr6,0x821848a0
	if (cr6.getLT()) goto loc_821848A0;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// blt cr6,0x82184954
	if (cr6.getLT()) goto loc_82184954;
	// addi r11,r1,104
	r11.s64 = ctx.r1.s64 + 104;
	// mulli r31,r31,308
	r31.s64 = r31.s64 * 308;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,-1
	ctx.r5.s64 = -1;
	// addi r3,r30,1344
	ctx.r3.s64 = r30.s64 + 1344;
	// add r4,r31,r11
	ctx.r4.u64 = r31.u64 + r11.u64;
	// bl 0x82183080
	sub_82183080(ctx, base);
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// addi r11,r1,360
	r11.s64 = ctx.r1.s64 + 360;
	// li r5,42
	ctx.r5.s64 = 42;
	// add r4,r31,r11
	ctx.r4.u64 = r31.u64 + r11.u64;
	// addi r3,r30,1300
	ctx.r3.s64 = r30.s64 + 1300;
	// lwzx r11,r31,r10
	r11.u64 = PPC_LOAD_U32(r31.u32 + ctx.r10.u32);
	// stw r11,1616(r30)
	PPC_STORE_U32(r30.u32 + 1616, r11.u32);
	// bl 0x82183490
	sub_82183490(ctx, base);
	// li r29,1
	r29.s64 = 1;
loc_82184954:
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82184964
	if (cr6.getEQ()) goto loc_82184964;
	// bl 0x8235d388
	sub_8235D388(ctx, base);
loc_82184964:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,1680
	ctx.r1.s64 = ctx.r1.s64 + 1680;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82184970"))) PPC_WEAK_FUNC(sub_82184970);
PPC_FUNC_IMPL(__imp__sub_82184970) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r30,-31991
	r30.s64 = -2096562176;
	// lbz r11,-31576(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + -31576);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82184a1c
	if (!cr6.getEQ()) goto loc_82184A1C;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r31,r11,-32184
	r31.s64 = r11.s64 + -32184;
	// li r11,0
	r11.s64 = 0;
	// li r10,8
	ctx.r10.s64 = 8;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// li r11,1
	r11.s64 = 1;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// li r11,128
	r11.s64 = 128;
	// stb r11,8(r31)
	PPC_STORE_U8(r31.u32 + 8, r11.u8);
	// stb r11,9(r31)
	PPC_STORE_U8(r31.u32 + 9, r11.u8);
	// addi r11,r31,12
	r11.s64 = r31.s64 + 12;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_821849C8:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x821849c8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_821849C8;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r3,r31,140
	ctx.r3.s64 = r31.s64 + 140;
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// ori r11,r11,16
	r11.u64 = r11.u64 | 16;
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
	// ori r11,r11,128
	r11.u64 = r11.u64 | 128;
	// ori r11,r11,256
	r11.u64 = r11.u64 | 256;
	// oris r11,r11,4
	r11.u64 = r11.u64 | 262144;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// bl 0x820e8fa0
	sub_820E8FA0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,140
	ctx.r3.s64 = r31.s64 + 140;
	// bl 0x820e9138
	sub_820E9138(ctx, base);
	// li r11,255
	r11.s64 = 255;
	// stb r11,228(r31)
	PPC_STORE_U8(r31.u32 + 228, r11.u8);
	// li r11,1
	r11.s64 = 1;
	// stb r11,-31576(r30)
	PPC_STORE_U8(r30.u32 + -31576, r11.u8);
loc_82184A1C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82184A38"))) PPC_WEAK_FUNC(sub_82184A38);
PPC_FUNC_IMPL(__imp__sub_82184A38) {
	PPC_FUNC_PROLOGUE();
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x821838b0
	sub_821838B0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82184A40"))) PPC_WEAK_FUNC(sub_82184A40);
PPC_FUNC_IMPL(__imp__sub_82184A40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821838b0
	sub_821838B0(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82184ac4
	if (cr6.getEQ()) goto loc_82184AC4;
	// lwz r11,1368(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1368);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bge cr6,0x82184ab4
	if (!cr6.getLT()) goto loc_82184AB4;
	// lis r10,-31991
	ctx.r10.s64 = -2096562176;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r10,-31872
	ctx.r10.s64 = ctx.r10.s64 + -31872;
	// addi r8,r10,-32
	ctx.r8.s64 = ctx.r10.s64 + -32;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x82184ab4
	if (!cr6.getEQ()) goto loc_82184AB4;
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x82184aac
	if (!cr6.getEQ()) goto loc_82184AAC;
	// lis r11,21
	r11.s64 = 1376256;
	// ori r9,r11,4336
	ctx.r9.u64 = r11.u64 | 4336;
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// li r11,1
	r11.s64 = 1;
	// beq cr6,0x82184ab0
	if (cr6.getEQ()) goto loc_82184AB0;
loc_82184AAC:
	// li r11,0
	r11.s64 = 0;
loc_82184AB0:
	// clrlwi r9,r11,24
	ctx.r9.u64 = r11.u32 & 0xFF;
loc_82184AB4:
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82184ac4
	if (!cr6.getEQ()) goto loc_82184AC4;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82184AC4:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82184AD8"))) PPC_WEAK_FUNC(sub_82184AD8);
PPC_FUNC_IMPL(__imp__sub_82184AD8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r30,r31,4
	r30.s64 = r31.s64 + 4;
	// lbz r11,1359(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1359);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// beq cr6,0x82184bb8
	if (cr6.getEQ()) goto loc_82184BB8;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r29,r31,1372
	r29.s64 = r31.s64 + 1372;
	// addi r28,r11,-20464
	r28.s64 = r11.s64 + -20464;
	// li r8,0
	ctx.r8.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// li r5,8
	ctx.r5.s64 = 8;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// bl 0x823bd0a8
	sub_823BD0A8(ctx, base);
	// lwz r11,648(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 648);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82184b50
	if (!cr6.getEQ()) goto loc_82184B50;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x8209d088
	sub_8209D088(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lis r10,-31991
	ctx.r10.s64 = -2096562176;
	// stw r3,648(r31)
	PPC_STORE_U32(r31.u32 + 648, ctx.r3.u32);
	// stw r11,-31864(r10)
	PPC_STORE_U32(ctx.r10.u32 + -31864, r11.u32);
loc_82184B50:
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r3,648(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 648);
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// mr r11,r29
	r11.u64 = r29.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r10,7
	ctx.r10.s64 = 7;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_82184B70:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82184b70
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82184B70;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// lwz r8,648(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 648);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lwz r4,1368(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// li r5,8
	ctx.r5.s64 = 8;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x823bd0a8
	sub_823BD0A8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82184bb0
	if (cr6.getEQ()) goto loc_82184BB0;
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x82184bb4
	if (!cr6.getEQ()) goto loc_82184BB4;
loc_82184BB0:
	// li r11,1
	r11.s64 = 1;
loc_82184BB4:
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
loc_82184BB8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_82184BC0"))) PPC_WEAK_FUNC(sub_82184BC0);
PPC_FUNC_IMPL(__imp__sub_82184BC0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-31991
	r11.s64 = -2096562176;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r11,-32216
	ctx.r7.s64 = r11.s64 + -32216;
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
loc_82184BD0:
	// lwz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82184c60
	if (cr6.getEQ()) goto loc_82184C60;
	// lbz r11,1358(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1358);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82184c60
	if (cr6.getEQ()) goto loc_82184C60;
	// lwz r11,1368(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1368);
	// cmpwi cr6,r11,-1313
	cr6.compare<int32_t>(r11.s32, -1313, xer);
	// bne cr6,0x82184c60
	if (!cr6.getEQ()) goto loc_82184C60;
	// lwz r11,1604(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1604);
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// beq cr6,0x82184c44
	if (cr6.getEQ()) goto loc_82184C44;
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82184c44
	if (cr6.getEQ()) goto loc_82184C44;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82184c44
	if (cr6.getEQ()) goto loc_82184C44;
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x82184c44
	if (cr6.getEQ()) goto loc_82184C44;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x82184c44
	if (cr6.getEQ()) goto loc_82184C44;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// beq cr6,0x82184c44
	if (cr6.getEQ()) goto loc_82184C44;
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// beq cr6,0x82184c44
	if (cr6.getEQ()) goto loc_82184C44;
	// cmpwi cr6,r11,16
	cr6.compare<int32_t>(r11.s32, 16, xer);
	// beq cr6,0x82184c44
	if (cr6.getEQ()) goto loc_82184C44;
	// cmpwi cr6,r11,17
	cr6.compare<int32_t>(r11.s32, 17, xer);
	// li r11,1
	r11.s64 = 1;
	// bne cr6,0x82184c48
	if (!cr6.getEQ()) goto loc_82184C48;
loc_82184C44:
	// li r11,0
	r11.s64 = 0;
loc_82184C48:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82184c60
	if (!cr6.getEQ()) goto loc_82184C60;
	// lwz r11,1604(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1604);
	// cmpwi cr6,r11,31
	cr6.compare<int32_t>(r11.s32, 31, xer);
	// bne cr6,0x82184c78
	if (!cr6.getEQ()) goto loc_82184C78;
loc_82184C60:
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplwi cr6,r8,8
	cr6.compare<uint32_t>(ctx.r8.u32, 8, xer);
	// blt cr6,0x82184bd0
	if (cr6.getLT()) goto loc_82184BD0;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_82184C78:
	// rlwinm r11,r8,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r7
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82184C88"))) PPC_WEAK_FUNC(sub_82184C88);
PPC_FUNC_IMPL(__imp__sub_82184C88) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// clrlwi r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lbz r11,1359(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1359);
	// beq cr6,0x82184d08
	if (cr6.getEQ()) goto loc_82184D08;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82184cfc
	if (!cr6.getEQ()) goto loc_82184CFC;
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r10,1
	ctx.r10.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82184cf8
	if (cr6.getEQ()) goto loc_82184CF8;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82184ce0
	if (cr6.getEQ()) goto loc_82184CE0;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82184cf8
	if (!cr6.getEQ()) goto loc_82184CF8;
loc_82184CE0:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
loc_82184CF8:
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
loc_82184CFC:
	// li r11,0
	r11.s64 = 0;
	// stb r11,3260(r31)
	PPC_STORE_U8(r31.u32 + 3260, r11.u8);
	// b 0x82184d74
	goto loc_82184D74;
loc_82184D08:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82184d78
	if (cr6.getEQ()) goto loc_82184D78;
	// bl 0x82184bc0
	sub_82184BC0(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82184d24
	if (cr6.getEQ()) goto loc_82184D24;
	// lwz r11,1368(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// stw r11,1368(r3)
	PPC_STORE_U32(ctx.r3.u32 + 1368, r11.u32);
loc_82184D24:
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,1604(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1604);
	// li r9,-1313
	ctx.r9.s64 = -1313;
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// std r10,1288(r31)
	PPC_STORE_U64(r31.u32 + 1288, ctx.r10.u64);
	// stw r9,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, ctx.r9.u32);
	// beq cr6,0x82184d54
	if (cr6.getEQ()) goto loc_82184D54;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x82184d54
	if (cr6.getEQ()) goto loc_82184D54;
	// li r11,1
	r11.s64 = 1;
	// stb r11,3260(r31)
	PPC_STORE_U8(r31.u32 + 3260, r11.u8);
	// b 0x82184d74
	goto loc_82184D74;
loc_82184D54:
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r4,30
	ctx.r4.s64 = 30;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821855e8
	sub_821855E8(ctx, base);
	// li r11,30
	r11.s64 = 30;
	// stw r11,1604(r31)
	PPC_STORE_U32(r31.u32 + 1604, r11.u32);
loc_82184D74:
	// stb r30,1359(r31)
	PPC_STORE_U8(r31.u32 + 1359, r30.u8);
loc_82184D78:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82184D90"))) PPC_WEAK_FUNC(sub_82184D90);
PPC_FUNC_IMPL(__imp__sub_82184D90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r5,392
	ctx.r5.s64 = 392;
	// addi r29,r31,884
	r29.s64 = r31.s64 + 884;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// lis r11,-31992
	r11.s64 = -2096627712;
	// li r5,232
	ctx.r5.s64 = 232;
	// addi r30,r11,31856
	r30.s64 = r11.s64 + 31856;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r11,1804(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 1804);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,1804(r30)
	PPC_STORE_U32(r30.u32 + 1804, r11.u32);
	// lwzx r11,r10,r30
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r30.u32);
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// stw r11,888(r31)
	PPC_STORE_U32(r31.u32 + 888, r11.u32);
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// lwz r11,1800(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 1800);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r10,1616(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1616);
	// addi r4,r31,1300
	ctx.r4.s64 = r31.s64 + 1300;
	// lwz r9,1368(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// lwz r3,1344(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 1344);
	// stw r11,892(r31)
	PPC_STORE_U32(r31.u32 + 892, r11.u32);
	// stw r10,952(r31)
	PPC_STORE_U32(r31.u32 + 952, ctx.r10.u32);
	// stw r9,884(r31)
	PPC_STORE_U32(r31.u32 + 884, ctx.r9.u32);
	// bl 0x82187d38
	sub_82187D38(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82184E18"))) PPC_WEAK_FUNC(sub_82184E18);
PPC_FUNC_IMPL(__imp__sub_82184E18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,661(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 661);
	// clrlwi r10,r4,24
	ctx.r10.u64 = ctx.r4.u32 & 0xFF;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lbz r11,1359(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1359);
	// stb r4,661(r3)
	PPC_STORE_U8(ctx.r3.u32 + 661, ctx.r4.u8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// li r11,1
	r11.s64 = 1;
	// stb r11,1600(r3)
	PPC_STORE_U8(ctx.r3.u32 + 1600, r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82184E48"))) PPC_WEAK_FUNC(sub_82184E48);
PPC_FUNC_IMPL(__imp__sub_82184E48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,660(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 660);
	// clrlwi r10,r4,24
	ctx.r10.u64 = ctx.r4.u32 & 0xFF;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lbz r11,1359(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1359);
	// stb r4,660(r3)
	PPC_STORE_U8(ctx.r3.u32 + 660, ctx.r4.u8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// li r11,1
	r11.s64 = 1;
	// stb r11,1600(r3)
	PPC_STORE_U8(ctx.r3.u32 + 1600, r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82184E78"))) PPC_WEAK_FUNC(sub_82184E78);
PPC_FUNC_IMPL(__imp__sub_82184E78) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lbz r11,880(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 880);
	// cmpw cr6,r11,r4
	cr6.compare<int32_t>(r11.s32, ctx.r4.s32, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lbz r10,1359(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1359);
	// stb r4,880(r3)
	PPC_STORE_U8(ctx.r3.u32 + 880, ctx.r4.u8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// li r11,1
	r11.s64 = 1;
	// stb r11,1600(r3)
	PPC_STORE_U8(ctx.r3.u32 + 1600, r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82184EA0"))) PPC_WEAK_FUNC(sub_82184EA0);
PPC_FUNC_IMPL(__imp__sub_82184EA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x820ae370
	sub_820AE370(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82184ef0
	if (cr6.getEQ()) goto loc_82184EF0;
	// bl 0x8215fc88
	sub_8215FC88(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x82184ee4
	if (!cr6.getEQ()) goto loc_82184EE4;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x82183ca0
	sub_82183CA0(ctx, base);
	// b 0x82184f7c
	goto loc_82184F7C;
loc_82184EE4:
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82183ca0
	sub_82183CA0(ctx, base);
	// b 0x82184f7c
	goto loc_82184F7C;
loc_82184EF0:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82184f44
	if (cr6.getEQ()) goto loc_82184F44;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x82183ca0
	sub_82183CA0(ctx, base);
	// lis r11,-31993
	r11.s64 = -2096693248;
	// lwz r11,29100(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 29100);
	// addi r3,r11,596
	ctx.r3.s64 = r11.s64 + 596;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r30,1368(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8215f9e0
	sub_8215F9E0(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// clrlwi r5,r31,24
	ctx.r5.u64 = r31.u32 & 0xFF;
	// bl 0x821550e0
	sub_821550E0(ctx, base);
	// b 0x82184f7c
	goto loc_82184F7C;
loc_82184F44:
	// li r4,4
	ctx.r4.s64 = 4;
	// bl 0x82183ca0
	sub_82183CA0(ctx, base);
	// bl 0x820ae360
	sub_820AE360(ctx, base);
	// bl 0x82183dc0
	sub_82183DC0(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,4
	ctx.r4.s64 = 4;
	// lwz r3,1368(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// bl 0x82183c08
	sub_82183C08(ctx, base);
	// bl 0x8209f598
	sub_8209F598(ctx, base);
	// bl 0x82183d58
	sub_82183D58(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,5
	ctx.r4.s64 = 5;
	// lwz r3,1368(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// bl 0x82183c08
	sub_82183C08(ctx, base);
loc_82184F7C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82184F98"))) PPC_WEAK_FUNC(sub_82184F98);
PPC_FUNC_IMPL(__imp__sub_82184F98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister temp{};
	// srawi r10,r4,5
	xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0x1F) != 0);
	ctx.r10.s64 = ctx.r4.s32 >> 5;
	// li r11,1
	r11.s64 = 1;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// srawi r9,r4,5
	xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0x1F) != 0);
	ctx.r9.s64 = ctx.r4.s32 >> 5;
	// rlwinm r7,r10,5,0,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// addze r10,r9
	temp.s64 = ctx.r9.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r9.u32;
	ctx.r10.s64 = temp.s64;
	// subf r9,r7,r4
	ctx.r9.s64 = ctx.r4.s64 - ctx.r7.s64;
	// addi r7,r10,166
	ctx.r7.s64 = ctx.r10.s64 + 166;
	// clrlwi r8,r5,24
	ctx.r8.u64 = ctx.r5.u32 & 0xFF;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r7,r7,r3
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + ctx.r3.u32);
	// slw r9,r11,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r9.u8 & 0x3F));
	// and r7,r7,r9
	ctx.r7.u64 = ctx.r7.u64 & ctx.r9.u64;
	// cntlzw r7,r7
	ctx.r7.u64 = ctx.r7.u32 == 0 ? 32 : __builtin_clz(ctx.r7.u32);
	// rlwinm r7,r7,27,31,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x1;
	// xori r7,r7,1
	ctx.r7.u64 = ctx.r7.u64 ^ 1;
	// cmplw cr6,r8,r7
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r7.u32, xer);
	// beq cr6,0x82184ff0
	if (cr6.getEQ()) goto loc_82184FF0;
	// lbz r7,1359(r3)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1359);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beq cr6,0x82184ff0
	if (cr6.getEQ()) goto loc_82184FF0;
	// stb r11,1600(r3)
	PPC_STORE_U8(ctx.r3.u32 + 1600, r11.u8);
loc_82184FF0:
	// addi r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 + 3;
	// addi r11,r3,652
	r11.s64 = ctx.r3.s64 + 652;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// beq cr6,0x82185014
	if (cr6.getEQ()) goto loc_82185014;
	// or r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 | ctx.r9.u64;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// blr 
	return;
loc_82185014:
	// andc r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 & ~ctx.r9.u64;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82185020"))) PPC_WEAK_FUNC(sub_82185020);
PPC_FUNC_IMPL(__imp__sub_82185020) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r6,0
	ctx.r6.s64 = 0;
	// bl 0x82184a40
	sub_82184A40(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82185054
	if (cr6.getEQ()) goto loc_82185054;
	// lis r11,0
	r11.s64 = 0;
	// ori r11,r11,42523
	r11.u64 = r11.u64 | 42523;
	// lbzx r11,r3,r11
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + r11.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185058
	if (cr6.getEQ()) goto loc_82185058;
loc_82185054:
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
loc_82185058:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82185068"))) PPC_WEAK_FUNC(sub_82185068);
PPC_FUNC_IMPL(__imp__sub_82185068) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// addi r3,r31,652
	ctx.r3.s64 = r31.s64 + 652;
	// addi r4,r11,-32184
	ctx.r4.s64 = r11.s64 + -32184;
	// li r5,232
	ctx.r5.s64 = 232;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// li r30,0
	r30.s64 = 0;
	// li r5,320
	ctx.r5.s64 = 320;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,8
	ctx.r3.s64 = r31.s64 + 8;
	// stb r30,1300(r31)
	PPC_STORE_U8(r31.u32 + 1300, r30.u8);
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// stb r30,1440(r31)
	PPC_STORE_U8(r31.u32 + 1440, r30.u8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// std r30,1288(r31)
	PPC_STORE_U64(r31.u32 + 1288, r30.u64);
	// stw r30,1296(r31)
	PPC_STORE_U32(r31.u32 + 1296, r30.u32);
	// stb r30,1358(r31)
	PPC_STORE_U8(r31.u32 + 1358, r30.u8);
	// stb r30,1600(r31)
	PPC_STORE_U8(r31.u32 + 1600, r30.u8);
	// stb r30,1601(r31)
	PPC_STORE_U8(r31.u32 + 1601, r30.u8);
	// stw r30,648(r31)
	PPC_STORE_U32(r31.u32 + 648, r30.u32);
	// stw r30,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r30.u32);
	// stw r30,1604(r31)
	PPC_STORE_U32(r31.u32 + 1604, r30.u32);
	// stw r30,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r30.u32);
	// stw r30,1608(r31)
	PPC_STORE_U32(r31.u32 + 1608, r30.u32);
	// bl 0x82184c88
	sub_82184C88(ctx, base);
	// lis r11,0
	r11.s64 = 0;
	// lwz r3,1444(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 1444);
	// stb r30,3260(r31)
	PPC_STORE_U8(r31.u32 + 3260, r30.u8);
	// ori r11,r11,42517
	r11.u64 = r11.u64 | 42517;
	// stb r30,3261(r31)
	PPC_STORE_U8(r31.u32 + 3261, r30.u8);
	// stw r30,3264(r31)
	PPC_STORE_U32(r31.u32 + 3264, r30.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r30,3268(r31)
	PPC_STORE_U32(r31.u32 + 3268, r30.u32);
	// stb r30,1360(r31)
	PPC_STORE_U8(r31.u32 + 1360, r30.u8);
	// stb r30,1361(r31)
	PPC_STORE_U8(r31.u32 + 1361, r30.u8);
	// stbx r30,r31,r11
	PPC_STORE_U8(r31.u32 + r11.u32, r30.u8);
	// beq cr6,0x82185120
	if (cr6.getEQ()) goto loc_82185120;
	// li r5,4000
	ctx.r5.s64 = 4000;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
loc_82185120:
	// lis r11,0
	r11.s64 = 0;
	// stw r30,3276(r31)
	PPC_STORE_U32(r31.u32 + 3276, r30.u32);
	// li r8,1
	ctx.r8.s64 = 1;
	// ori r11,r11,42512
	r11.u64 = r11.u64 | 42512;
	// lbzx r11,r31,r11
	r11.u64 = PPC_LOAD_U8(r31.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185148
	if (cr6.getEQ()) goto loc_82185148;
	// lis r11,0
	r11.s64 = 0;
	// ori r11,r11,42513
	r11.u64 = r11.u64 | 42513;
	// stbx r8,r31,r11
	PPC_STORE_U8(r31.u32 + r11.u32, ctx.r8.u8);
loc_82185148:
	// lis r11,0
	r11.s64 = 0;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// ori r7,r11,42514
	ctx.r7.u64 = r11.u64 | 42514;
	// addis r11,r31,1
	r11.s64 = r31.s64 + 65536;
	// li r10,10
	ctx.r10.s64 = 10;
	// addi r11,r11,-23018
	r11.s64 = r11.s64 + -23018;
	// stbx r8,r31,r7
	PPC_STORE_U8(r31.u32 + ctx.r7.u32, ctx.r8.u8);
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_82185168:
	// stb r9,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r9.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// bdnz 0x82185168
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82185168;
	// lis r11,0
	r11.s64 = 0;
	// stb r30,1364(r31)
	PPC_STORE_U8(r31.u32 + 1364, r30.u8);
	// lis r10,0
	ctx.r10.s64 = 0;
	// stb r30,1365(r31)
	PPC_STORE_U8(r31.u32 + 1365, r30.u8);
	// ori r11,r11,42515
	r11.u64 = r11.u64 | 42515;
	// stb r8,1357(r31)
	PPC_STORE_U8(r31.u32 + 1357, ctx.r8.u8);
	// ori r10,r10,42516
	ctx.r10.u64 = ctx.r10.u64 | 42516;
	// stb r30,1356(r31)
	PPC_STORE_U8(r31.u32 + 1356, r30.u8);
	// stbx r30,r31,r11
	PPC_STORE_U8(r31.u32 + r11.u32, r30.u8);
	// stbx r30,r31,r10
	PPC_STORE_U8(r31.u32 + ctx.r10.u32, r30.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821851B8"))) PPC_WEAK_FUNC(sub_821851B8);
PPC_FUNC_IMPL(__imp__sub_821851B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r30,0
	r30.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// bl 0x82185068
	sub_82185068(ctx, base);
	// li r4,4
	ctx.r4.s64 = 4;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823bc550
	sub_823BC550(ctx, base);
	// lis r11,12633
	r11.s64 = 827916288;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r4,16
	ctx.r4.s64 = 16;
	// ori r9,r11,29215
	ctx.r9.u64 = r11.u64 | 29215;
	// lis r11,-32019
	r11.s64 = -2098397184;
	// mulhwu r9,r10,r9
	ctx.r9.u64 = (uint64_t(ctx.r10.u32) * uint64_t(ctx.r9.u32)) >> 32;
	// rlwinm r8,r9,27,5,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x7FFFFFF;
	// lis r9,-32254
	ctx.r9.s64 = -2113798144;
	// addi r11,r11,26520
	r11.s64 = r11.s64 + 26520;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// addi r5,r9,-20264
	ctx.r5.s64 = ctx.r9.s64 + -20264;
	// mulli r9,r8,166
	ctx.r9.s64 = ctx.r8.s64 * 166;
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r6,r10,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// bl 0x823eea88
	sub_823EEA88(ctx, base);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// stb r30,111(r1)
	PPC_STORE_U8(ctx.r1.u32 + 111, r30.u8);
	// addi r3,r31,652
	ctx.r3.s64 = r31.s64 + 652;
	// stb r30,1360(r31)
	PPC_STORE_U8(r31.u32 + 1360, r30.u8);
	// addi r4,r11,-32184
	ctx.r4.s64 = r11.s64 + -32184;
	// li r5,232
	ctx.r5.s64 = 232;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// li r28,1
	r28.s64 = 1;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r31,1276
	ctx.r3.s64 = r31.s64 + 1276;
	// stb r28,1358(r31)
	PPC_STORE_U8(r31.u32 + 1358, r28.u8);
	// bl 0x82182fe0
	sub_82182FE0(ctx, base);
	// lis r11,0
	r11.s64 = 0;
	// stw r29,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r29.u32);
	// std r30,1288(r31)
	PPC_STORE_U64(r31.u32 + 1288, r30.u64);
	// ori r11,r11,42512
	r11.u64 = r11.u64 | 42512;
	// stw r30,3276(r31)
	PPC_STORE_U32(r31.u32 + 3276, r30.u32);
	// lbzx r11,r31,r11
	r11.u64 = PPC_LOAD_U8(r31.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185284
	if (cr6.getEQ()) goto loc_82185284;
	// lis r11,0
	r11.s64 = 0;
	// ori r11,r11,42513
	r11.u64 = r11.u64 | 42513;
	// stbx r28,r31,r11
	PPC_STORE_U8(r31.u32 + r11.u32, r28.u8);
loc_82185284:
	// lis r11,0
	r11.s64 = 0;
	// ori r11,r11,42514
	r11.u64 = r11.u64 | 42514;
	// stbx r28,r31,r11
	PPC_STORE_U8(r31.u32 + r11.u32, r28.u8);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_82185298"))) PPC_WEAK_FUNC(sub_82185298);
PPC_FUNC_IMPL(__imp__sub_82185298) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed12c
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r29,1
	r29.s64 = 1;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r25,r29
	r25.u64 = r29.u64;
	// bl 0x821838b0
	sub_821838B0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8235dc48
	sub_8235DC48(ctx, base);
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// li r26,0
	r26.s64 = 0;
	// rldicl r11,r11,16,48
	r11.u64 = __builtin_rotateleft64(r11.u64, 16) & 0xFFFF;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// clrlwi r10,r11,28
	ctx.r10.u64 = r11.u32 & 0xF;
	// cmplwi cr6,r10,9
	cr6.compare<uint32_t>(ctx.r10.u32, 9, xer);
	// bne cr6,0x821852f0
	if (!cr6.getEQ()) goto loc_821852F0;
	// rlwinm r11,r11,0,24,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xC0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r11,r29
	r11.u64 = r29.u64;
	// bne cr6,0x821852f4
	if (!cr6.getEQ()) goto loc_821852F4;
loc_821852F0:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_821852F4:
	// li r5,16
	ctx.r5.s64 = 16;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// clrlwi r27,r11,24
	r27.u64 = r11.u32 & 0xFF;
	// bl 0x8235da00
	sub_8235DA00(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82183280
	sub_82183280(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82185440
	if (cr6.getEQ()) goto loc_82185440;
	// addi r30,r31,1276
	r30.s64 = r31.s64 + 1276;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82182ae0
	sub_82182AE0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185360
	if (cr6.getEQ()) goto loc_82185360;
	// mr r25,r26
	r25.u64 = r26.u64;
loc_8218533C:
	// lbz r11,1359(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1359);
	// addi r30,r31,1368
	r30.s64 = r31.s64 + 1368;
	// stw r28,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r28.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x821854d0
	if (!cr6.getEQ()) goto loc_821854D0;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82184c88
	sub_82184C88(ctx, base);
	// b 0x821854d0
	goto loc_821854D0;
loc_82185360:
	// lbz r11,1360(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1360);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185434
	if (cr6.getEQ()) goto loc_82185434;
	// clrlwi r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185434
	if (cr6.getEQ()) goto loc_82185434;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r25,r26
	r25.u64 = r26.u64;
	// bl 0x82182fe0
	sub_82182FE0(ctx, base);
	// lwz r3,1368(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// bl 0x82158600
	sub_82158600(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8218533c
	if (cr6.getEQ()) goto loc_8218533C;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x82157fd8
	sub_82157FD8(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r4,1
	ctx.r4.s64 = 1;
	// stb r26,124(r1)
	PPC_STORE_U8(ctx.r1.u32 + 124, r26.u8);
	// addi r11,r11,-30556
	r11.s64 = r11.s64 + -30556;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// bl 0x82152c88
	sub_82152C88(ctx, base);
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185424
	if (cr6.getEQ()) goto loc_82185424;
loc_821853CC:
	// li r3,60
	ctx.r3.s64 = 60;
	// bl 0x8215c528
	sub_8215C528(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x821853ec
	if (cr6.getEQ()) goto loc_821853EC;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x821841e8
	sub_821841E8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// b 0x821853f0
	goto loc_821853F0;
loc_821853EC:
	// mr r29,r26
	r29.u64 = r26.u64;
loc_821853F0:
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r4,300
	ctx.r4.s64 = 300;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823b7198
	sub_823B7198(ctx, base);
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r4,16(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// bl 0x823b7430
	sub_823B7430(ctx, base);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82152d08
	sub_82152D08(ctx, base);
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x821853cc
	if (!cr6.getEQ()) goto loc_821853CC;
loc_82185424:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r11,r11,-30572
	r11.s64 = r11.s64 + -30572;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// b 0x8218533c
	goto loc_8218533C;
loc_82185434:
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82184c88
	sub_82184C88(ctx, base);
loc_82185440:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x821838b0
	sub_821838B0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8218547c
	if (cr6.getEQ()) goto loc_8218547C;
	// bl 0x82185068
	sub_82185068(ctx, base);
	// lis r11,-32019
	r11.s64 = -2098397184;
	// li r5,42
	ctx.r5.s64 = 42;
	// stb r29,1358(r31)
	PPC_STORE_U8(r31.u32 + 1358, r29.u8);
	// addi r4,r11,26504
	ctx.r4.s64 = r11.s64 + 26504;
	// addi r3,r31,1300
	ctx.r3.s64 = r31.s64 + 1300;
	// bl 0x82183490
	sub_82183490(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r31,1276
	ctx.r3.s64 = r31.s64 + 1276;
	// bl 0x82182fe0
	sub_82182FE0(ctx, base);
loc_8218547C:
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r28,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r28.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r30,r31,1368
	r30.s64 = r31.s64 + 1368;
	// bl 0x82184c88
	sub_82184C88(ctx, base);
	// lis r11,-31992
	r11.s64 = -2096627712;
	// mulli r9,r28,360
	ctx.r9.s64 = r28.s64 * 360;
	// addi r10,r11,31880
	ctx.r10.s64 = r11.s64 + 31880;
	// li r11,9
	r11.s64 = 9;
	// addi r10,r10,5
	ctx.r10.s64 = ctx.r10.s64 + 5;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
loc_821854A8:
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stb r29,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, r29.u8);
	// addi r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 + 40;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x821854a8
	if (!cr6.getEQ()) goto loc_821854A8;
	// clrlwi r11,r27,24
	r11.u64 = r27.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821854d0
	if (cr6.getEQ()) goto loc_821854D0;
	// stb r29,1360(r31)
	PPC_STORE_U8(r31.u32 + 1360, r29.u8);
	// stb r26,1361(r31)
	PPC_STORE_U8(r31.u32 + 1361, r26.u8);
loc_821854D0:
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r31,1276
	ctx.r3.s64 = r31.s64 + 1276;
	// bl 0x82182fe0
	sub_82182FE0(ctx, base);
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// stw r28,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r28.u32);
	// std r11,1288(r31)
	PPC_STORE_U64(r31.u32 + 1288, r11.u64);
	// bl 0x82182ba0
	sub_82182BA0(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_82185500"))) PPC_WEAK_FUNC(sub_82185500);
PPC_FUNC_IMPL(__imp__sub_82185500) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r5,392
	ctx.r5.s64 = 392;
	// addi r29,r31,884
	r29.s64 = r31.s64 + 884;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r6,r31,652
	ctx.r6.s64 = r31.s64 + 652;
	// bl 0x82184f98
	sub_82184F98(ctx, base);
	// lis r11,-31992
	r11.s64 = -2096627712;
	// li r5,232
	ctx.r5.s64 = 232;
	// addi r30,r11,31856
	r30.s64 = r11.s64 + 31856;
	// lis r11,24605
	r11.s64 = 1612513280;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// ori r10,r11,59872
	ctx.r10.u64 = r11.u64 | 59872;
	// lwz r11,1804(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 1804);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r10,4(r6)
	PPC_STORE_U32(ctx.r6.u32 + 4, ctx.r10.u32);
	// stw r11,1804(r30)
	PPC_STORE_U32(r30.u32 + 1804, r11.u32);
	// lwzx r11,r9,r30
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r30.u32);
	// rotlwi r3,r11,0
	ctx.r3.u64 = __builtin_rotateleft32(r11.u32, 0);
	// stw r11,888(r31)
	PPC_STORE_U32(r31.u32 + 888, r11.u32);
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lwz r28,888(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 888);
	// li r4,228
	ctx.r4.s64 = 228;
	// addi r3,r28,4
	ctx.r3.s64 = r28.s64 + 4;
	// bl 0x821828f0
	sub_821828F0(ctx, base);
	// addi r11,r31,1344
	r11.s64 = r31.s64 + 1344;
	// lis r10,-31991
	ctx.r10.s64 = -2096562176;
	// stw r3,0(r28)
	PPC_STORE_U32(r28.u32 + 0, ctx.r3.u32);
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// addi r4,r10,-31832
	ctx.r4.s64 = ctx.r10.s64 + -31832;
	// bl 0x82183308
	sub_82183308(ctx, base);
	// lis r11,-32019
	r11.s64 = -2098397184;
	// addi r28,r31,1300
	r28.s64 = r31.s64 + 1300;
	// addi r4,r11,26504
	ctx.r4.s64 = r11.s64 + 26504;
	// li r5,42
	ctx.r5.s64 = 42;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82183490
	sub_82183490(ctx, base);
	// lwz r10,1616(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1616);
	// lwz r11,1800(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 1800);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r9,1368(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r3,1344(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 1344);
	// stw r10,952(r31)
	PPC_STORE_U32(r31.u32 + 952, ctx.r10.u32);
	// stw r11,892(r31)
	PPC_STORE_U32(r31.u32 + 892, r11.u32);
	// stw r9,884(r31)
	PPC_STORE_U32(r31.u32 + 884, ctx.r9.u32);
	// bl 0x82187c10
	sub_82187C10(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_821855E8"))) PPC_WEAK_FUNC(sub_821855E8);
PPC_FUNC_IMPL(__imp__sub_821855E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185644
	if (cr6.getEQ()) goto loc_82185644;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x8218562c
	if (cr6.getEQ()) goto loc_8218562C;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// beq cr6,0x8218562c
	if (cr6.getEQ()) goto loc_8218562C;
	// cmpwi cr6,r4,30
	cr6.compare<int32_t>(ctx.r4.s32, 30, xer);
	// beq cr6,0x8218562c
	if (cr6.getEQ()) goto loc_8218562C;
	// cmpwi cr6,r4,29
	cr6.compare<int32_t>(ctx.r4.s32, 29, xer);
	// bne cr6,0x82185644
	if (!cr6.getEQ()) goto loc_82185644;
loc_8218562C:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r4,30
	ctx.r4.s64 = 30;
loc_82185644:
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r4,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r4.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82185660"))) PPC_WEAK_FUNC(sub_82185660);
PPC_FUNC_IMPL(__imp__sub_82185660) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// bl 0x821838b0
	sub_821838B0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8218570c
	if (cr6.getEQ()) goto loc_8218570C;
	// lwz r11,664(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 664);
	// rlwinm r11,r11,30,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x821856d8
	if (!cr6.getEQ()) goto loc_821856D8;
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r10,9
	ctx.r10.s64 = 9;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821856d0
	if (cr6.getEQ()) goto loc_821856D0;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x821856b8
	if (cr6.getEQ()) goto loc_821856B8;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x821856d0
	if (!cr6.getEQ()) goto loc_821856D0;
loc_821856B8:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
loc_821856D0:
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82185704
	goto loc_82185704;
loc_821856D8:
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r11,29
	r11.s64 = 29;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82185700
	if (cr6.getEQ()) goto loc_82185700;
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r11,30
	r11.s64 = 30;
loc_82185700:
	// stw r11,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r11.u32);
loc_82185704:
	// li r11,1
	r11.s64 = 1;
	// stb r11,1361(r31)
	PPC_STORE_U8(r31.u32 + 1361, r11.u8);
loc_8218570C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82185720"))) PPC_WEAK_FUNC(sub_82185720);
PPC_FUNC_IMPL(__imp__sub_82185720) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,1604(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1604);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// bne cr6,0x82185780
	if (!cr6.getEQ()) goto loc_82185780;
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r10,9
	ctx.r10.s64 = 9;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8218577c
	if (cr6.getEQ()) goto loc_8218577C;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82185764
	if (cr6.getEQ()) goto loc_82185764;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x8218577c
	if (!cr6.getEQ()) goto loc_8218577C;
loc_82185764:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
loc_8218577C:
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
loc_82185780:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82185798"))) PPC_WEAK_FUNC(sub_82185798);
PPC_FUNC_IMPL(__imp__sub_82185798) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r3,r30,1276
	ctx.r3.s64 = r30.s64 + 1276;
	// bl 0x82183230
	sub_82183230(ctx, base);
	// li r31,0
	r31.s64 = 0;
	// addi r3,r30,1344
	ctx.r3.s64 = r30.s64 + 1344;
	// stb r31,1300(r30)
	PPC_STORE_U8(r30.u32 + 1300, r31.u8);
	// bl 0x82183230
	sub_82183230(ctx, base);
	// addi r3,r30,1452
	ctx.r3.s64 = r30.s64 + 1452;
	// bl 0x823bc450
	sub_823BC450(ctx, base);
	// addi r3,r30,3236
	ctx.r3.s64 = r30.s64 + 3236;
	// stb r31,3192(r30)
	PPC_STORE_U8(r30.u32 + 3192, r31.u8);
	// bl 0x82183230
	sub_82183230(ctx, base);
	// addi r3,r30,3248
	ctx.r3.s64 = r30.s64 + 3248;
	// bl 0x82183230
	sub_82183230(ctx, base);
	// lis r11,-31992
	r11.s64 = -2096627712;
	// li r27,1
	r27.s64 = 1;
	// addi r28,r11,31856
	r28.s64 = r11.s64 + 31856;
	// lbz r11,1793(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 1793);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x821858b0
	if (!cr6.getEQ()) goto loc_821858B0;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,40344
	ctx.r3.u64 = ctx.r3.u64 | 40344;
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r11,-31832
	ctx.r3.s64 = r11.s64 + -31832;
	// li r5,128
	ctx.r5.s64 = 128;
	// bl 0x821834e0
	sub_821834E0(ctx, base);
	// mr r29,r28
	r29.u64 = r28.u64;
loc_82185818:
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,512
	ctx.r3.s64 = 512;
	// bl 0x8209cbc8
	sub_8209CBC8(ctx, base);
	// li r5,512
	ctx.r5.s64 = 512;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r3,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r3.u32);
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// addi r11,r28,16
	r11.s64 = r28.s64 + 16;
	// cmpw cr6,r29,r11
	cr6.compare<int32_t>(r29.s32, r11.s32, xer);
	// blt cr6,0x82185818
	if (cr6.getLT()) goto loc_82185818;
	// li r11,512
	r11.s64 = 512;
	// addi r10,r28,24
	ctx.r10.s64 = r28.s64 + 24;
	// stw r11,1800(r28)
	PPC_STORE_U32(r28.u32 + 1800, r11.u32);
	// mr r11,r27
	r11.u64 = r27.u64;
	// stb r11,1793(r28)
	PPC_STORE_U8(r28.u32 + 1793, r11.u8);
	// mr r11,r31
	r11.u64 = r31.u64;
	// stw r11,1804(r28)
	PPC_STORE_U32(r28.u32 + 1804, r11.u32);
	// addi r11,r10,5
	r11.s64 = ctx.r10.s64 + 5;
loc_82185864:
	// li r7,9
	ctx.r7.s64 = 9;
loc_82185868:
	// stb r31,-1(r11)
	PPC_STORE_U8(r11.u32 + -1, r31.u8);
	// addi r10,r11,3
	ctx.r10.s64 = r11.s64 + 3;
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// stb r27,0(r11)
	PPC_STORE_U8(r11.u32 + 0, r27.u8);
	// li r9,7
	ctx.r9.s64 = 7;
	// stb r31,31(r11)
	PPC_STORE_U8(r11.u32 + 31, r31.u8);
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_82185884:
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x82185884
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82185884;
	// addi r7,r7,-1
	ctx.r7.s64 = ctx.r7.s64 + -1;
	// addi r11,r11,40
	r11.s64 = r11.s64 + 40;
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x82185868
	if (!cr6.getEQ()) goto loc_82185868;
	// addi r10,r28,24
	ctx.r10.s64 = r28.s64 + 24;
	// addi r10,r10,1445
	ctx.r10.s64 = ctx.r10.s64 + 1445;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// blt cr6,0x82185864
	if (cr6.getLT()) goto loc_82185864;
loc_821858B0:
	// bl 0x82184970
	sub_82184970(ctx, base);
	// addi r4,r28,1496
	ctx.r4.s64 = r28.s64 + 1496;
	// addi r3,r30,652
	ctx.r3.s64 = r30.s64 + 652;
	// li r5,232
	ctx.r5.s64 = 232;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lis r9,0
	ctx.r9.s64 = 0;
	// addi r11,r30,3280
	r11.s64 = r30.s64 + 3280;
	// stb r31,1358(r30)
	PPC_STORE_U8(r30.u32 + 1358, r31.u8);
	// ori r9,r9,42513
	ctx.r9.u64 = ctx.r9.u64 | 42513;
	// stw r31,648(r30)
	PPC_STORE_U32(r30.u32 + 648, r31.u32);
	// lis r10,0
	ctx.r10.s64 = 0;
	// stw r31,1368(r30)
	PPC_STORE_U32(r30.u32 + 1368, r31.u32);
	// lis r8,0
	ctx.r8.s64 = 0;
	// stw r31,1604(r30)
	PPC_STORE_U32(r30.u32 + 1604, r31.u32);
	// ori r10,r10,42512
	ctx.r10.u64 = ctx.r10.u64 | 42512;
	// stw r31,1612(r30)
	PPC_STORE_U32(r30.u32 + 1612, r31.u32);
	// ori r8,r8,42514
	ctx.r8.u64 = ctx.r8.u64 | 42514;
	// stw r11,3272(r30)
	PPC_STORE_U32(r30.u32 + 3272, r11.u32);
	// stbx r31,r30,r9
	PPC_STORE_U8(r30.u32 + ctx.r9.u32, r31.u8);
	// addis r11,r30,1
	r11.s64 = r30.s64 + 65536;
	// addis r9,r30,1
	ctx.r9.s64 = r30.s64 + 65536;
	// stw r31,1608(r30)
	PPC_STORE_U32(r30.u32 + 1608, r31.u32);
	// stw r31,3188(r30)
	PPC_STORE_U32(r30.u32 + 3188, r31.u32);
	// addi r11,r11,-22956
	r11.s64 = r11.s64 + -22956;
	// stbx r31,r30,r10
	PPC_STORE_U8(r30.u32 + ctx.r10.u32, r31.u8);
	// addi r9,r9,-22968
	ctx.r9.s64 = ctx.r9.s64 + -22968;
	// stw r31,1616(r30)
	PPC_STORE_U32(r30.u32 + 1616, r31.u32);
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// stw r31,3276(r30)
	PPC_STORE_U32(r30.u32 + 3276, r31.u32);
	// stbx r27,r30,r8
	PPC_STORE_U8(r30.u32 + ctx.r8.u32, r27.u8);
	// stb r27,1362(r30)
	PPC_STORE_U8(r30.u32 + 1362, r27.u8);
	// stb r31,1361(r30)
	PPC_STORE_U8(r30.u32 + 1361, r31.u8);
loc_82185930:
	// stbx r31,r9,r10
	PPC_STORE_U8(ctx.r9.u32 + ctx.r10.u32, r31.u8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r31,-52(r11)
	PPC_STORE_U32(r11.u32 + -52, r31.u32);
	// stw r31,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r31.u32);
	// cmpwi cr6,r10,10
	cr6.compare<int32_t>(ctx.r10.s32, 10, xer);
	// stw r31,40(r11)
	PPC_STORE_U32(r11.u32 + 40, r31.u32);
	// stw r31,80(r11)
	PPC_STORE_U32(r11.u32 + 80, r31.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// blt cr6,0x82185930
	if (cr6.getLT()) goto loc_82185930;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82184c88
	sub_82184C88(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r31,1444(r30)
	PPC_STORE_U32(r30.u32 + 1444, r31.u32);
	// bl 0x82185068
	sub_82185068(ctx, base);
	// li r3,4000
	ctx.r3.s64 = 4000;
	// bl 0x8209d088
	sub_8209D088(ctx, base);
	// li r5,4000
	ctx.r5.s64 = 4000;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r3,1444(r30)
	PPC_STORE_U32(r30.u32 + 1444, ctx.r3.u32);
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// lis r11,0
	r11.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stb r31,0(r30)
	PPC_STORE_U8(r30.u32 + 0, r31.u8);
	// ori r11,r11,42517
	r11.u64 = r11.u64 | 42517;
	// stb r31,1(r30)
	PPC_STORE_U8(r30.u32 + 1, r31.u8);
	// stb r31,2(r30)
	PPC_STORE_U8(r30.u32 + 2, r31.u8);
	// stbx r31,r30,r11
	PPC_STORE_U8(r30.u32 + r11.u32, r31.u8);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_821859A8"))) PPC_WEAK_FUNC(sub_821859A8);
PPC_FUNC_IMPL(__imp__sub_821859A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r3,111
	ctx.r3.s64 = 111;
	// bl 0x8235dec0
	sub_8235DEC0(ctx, base);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// li r31,8
	r31.s64 = 8;
	// addi r26,r11,-32216
	r26.s64 = r11.s64 + -32216;
	// mr r30,r26
	r30.u64 = r26.u64;
	// stw r3,-1448(r26)
	PPC_STORE_U32(r26.u32 + -1448, ctx.r3.u32);
loc_821859D0:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,42704
	ctx.r3.u64 = ctx.r3.u64 | 42704;
	// bl 0x8209d088
	sub_8209D088(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x821859ec
	if (cr6.getEQ()) goto loc_821859EC;
	// bl 0x82185798
	sub_82185798(ctx, base);
	// b 0x821859f0
	goto loc_821859F0;
loc_821859EC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_821859F0:
	// addi r31,r31,-1
	r31.s64 = r31.s64 + -1;
	// stw r3,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r3.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x821859d0
	if (!cr6.getEQ()) goto loc_821859D0;
	// mr r29,r26
	r29.u64 = r26.u64;
	// li r27,-1313
	r27.s64 = -1313;
	// li r28,30
	r28.s64 = 30;
loc_82185A10:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// lwz r30,0(r29)
	r30.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lbz r11,3260(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 3260);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185a3c
	if (cr6.getEQ()) goto loc_82185A3C;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// stw r27,1368(r30)
	PPC_STORE_U32(r30.u32 + 1368, r27.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821851b8
	sub_821851B8(ctx, base);
loc_82185A3C:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// stw r28,1612(r30)
	PPC_STORE_U32(r30.u32 + 1612, r28.u32);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmplwi cr6,r31,4
	cr6.compare<uint32_t>(r31.u32, 4, xer);
	// blt cr6,0x82185a10
	if (cr6.getLT()) goto loc_82185A10;
	// cmplwi cr6,r31,8
	cr6.compare<uint32_t>(r31.u32, 8, xer);
	// bge cr6,0x82185aa4
	if (!cr6.getLT()) goto loc_82185AA4;
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// subfic r29,r31,8
	xer.ca = r31.u32 <= 8;
	r29.s64 = 8 - r31.s64;
	// add r31,r11,r26
	r31.u64 = r11.u64 + r26.u64;
loc_82185A64:
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// lwz r30,0(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lbz r11,3260(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 3260);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185a90
	if (cr6.getEQ()) goto loc_82185A90;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// stw r27,1368(r30)
	PPC_STORE_U32(r30.u32 + 1368, r27.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821851b8
	sub_821851B8(ctx, base);
loc_82185A90:
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// stw r28,1612(r30)
	PPC_STORE_U32(r30.u32 + 1612, r28.u32);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x82185a64
	if (!cr6.getEQ()) goto loc_82185A64;
loc_82185AA4:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_82185AB0"))) PPC_WEAK_FUNC(sub_82185AB0);
PPC_FUNC_IMPL(__imp__sub_82185AB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r11,-20248
	ctx.r3.s64 = r11.s64 + -20248;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// lbz r11,1600(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1600);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82185af4
	if (!cr6.getEQ()) goto loc_82185AF4;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82185AF4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82185720
	sub_82185720(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82185B18"))) PPC_WEAK_FUNC(sub_82185B18);
PPC_FUNC_IMPL(__imp__sub_82185B18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lbz r11,1363(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1363);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82185b48
	if (!cr6.getEQ()) goto loc_82185B48;
	// lbz r11,1360(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1360);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// li r11,0
	r11.s64 = 0;
	// beq cr6,0x82185b4c
	if (cr6.getEQ()) goto loc_82185B4C;
loc_82185B48:
	// li r11,1
	r11.s64 = 1;
loc_82185B4C:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82185c00
	if (!cr6.getEQ()) goto loc_82185C00;
	// lwz r11,1604(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1604);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82185b74
	if (cr6.getEQ()) goto loc_82185B74;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x82185b74
	if (cr6.getEQ()) goto loc_82185B74;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x82185c00
	if (!cr6.getEQ()) goto loc_82185C00;
loc_82185B74:
	// lwz r4,1616(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 1616);
	// li r7,42
	ctx.r7.s64 = 42;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r31,3236
	ctx.r5.s64 = r31.s64 + 3236;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r4,3188(r31)
	PPC_STORE_U32(r31.u32 + 3188, ctx.r4.u32);
	// bl 0x82183718
	sub_82183718(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185bb0
	if (cr6.getEQ()) goto loc_82185BB0;
	// li r5,42
	ctx.r5.s64 = 42;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r31,3192
	ctx.r3.s64 = r31.s64 + 3192;
	// bl 0x82183490
	sub_82183490(ctx, base);
	// b 0x82185bb8
	goto loc_82185BB8;
loc_82185BB0:
	// li r11,0
	r11.s64 = 0;
	// stw r11,3188(r31)
	PPC_STORE_U32(r31.u32 + 3188, r11.u32);
loc_82185BB8:
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r10,17
	ctx.r10.s64 = 17;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// stb r11,1361(r31)
	PPC_STORE_U8(r31.u32 + 1361, r11.u8);
	// beq cr6,0x82185bfc
	if (cr6.getEQ()) goto loc_82185BFC;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82185be4
	if (cr6.getEQ()) goto loc_82185BE4;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185bfc
	if (!cr6.getEQ()) goto loc_82185BFC;
loc_82185BE4:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
loc_82185BFC:
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
loc_82185C00:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82185C18"))) PPC_WEAK_FUNC(sub_82185C18);
PPC_FUNC_IMPL(__imp__sub_82185C18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x82183230
	sub_82183230(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// addi r4,r11,-20396
	ctx.r4.s64 = r11.s64 + -20396;
	// bl 0x821832c0
	sub_821832C0(ctx, base);
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// lwz r5,1276(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 1276);
	// addi r29,r31,1276
	r29.s64 = r31.s64 + 1276;
	// bl 0x82183170
	sub_82183170(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82182ba0
	sub_82182BA0(ctx, base);
	// lwz r10,1604(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1604);
	// li r24,1
	r24.s64 = 1;
	// li r25,0
	r25.s64 = 0;
	// cmplwi cr6,r10,30
	cr6.compare<uint32_t>(ctx.r10.u32, 30, xer);
	// bgt cr6,0x82187048
	if (cr6.getGT()) goto loc_82187048;
	// li r26,-1313
	r26.s64 = -1313;
	// lis r12,-32232
	r12.s64 = -2112356352;
	// addi r12,r12,23692
	r12.s64 = r12.s64 + 23692;
	// rlwinm r0,r10,2,0,29
	r0.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_82187070;
	case 1:
		goto loc_82185D08;
	case 2:
		goto loc_82186ECC;
	case 3:
		goto loc_82187048;
	case 4:
		goto loc_82186EF8;
	case 5:
		goto loc_82187048;
	case 6:
		goto loc_82186F30;
	case 7:
		goto loc_821865A4;
	case 8:
		goto loc_821865A4;
	case 9:
		goto loc_82186280;
	case 10:
		goto loc_82186280;
	case 11:
		goto loc_82186440;
	case 12:
		goto loc_82186440;
	case 13:
		goto loc_82186F44;
	case 14:
		goto loc_82186FBC;
	case 15:
		goto loc_82187048;
	case 16:
		goto loc_8218619C;
	case 17:
		goto loc_8218619C;
	case 18:
		goto loc_82186E50;
	case 19:
		goto loc_82185D78;
	case 20:
		goto loc_82185F68;
	case 21:
		goto loc_82186D64;
	case 22:
		goto loc_82186C68;
	case 23:
		goto loc_82185F68;
	case 24:
		goto loc_82186A84;
	case 25:
		goto loc_82186B98;
	case 26:
		goto loc_82186AA0;
	case 27:
		goto loc_82186F1C;
	case 28:
		goto loc_82187048;
	case 29:
		goto loc_82186740;
	case 30:
		goto loc_8218682C;
	default:
		__builtin_unreachable();
	}
	// lwz r16,28784(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 28784);
	// lwz r16,23816(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 23816);
	// lwz r16,28364(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 28364);
	// lwz r16,28744(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 28744);
	// lwz r16,28408(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 28408);
	// lwz r16,28744(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 28744);
	// lwz r16,28464(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 28464);
	// lwz r16,26020(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 26020);
	// lwz r16,26020(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 26020);
	// lwz r16,25216(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 25216);
	// lwz r16,25216(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 25216);
	// lwz r16,25664(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 25664);
	// lwz r16,25664(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 25664);
	// lwz r16,28484(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 28484);
	// lwz r16,28604(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 28604);
	// lwz r16,28744(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 28744);
	// lwz r16,24988(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 24988);
	// lwz r16,24988(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 24988);
	// lwz r16,28240(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 28240);
	// lwz r16,23928(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 23928);
	// lwz r16,24424(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 24424);
	// lwz r16,28004(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 28004);
	// lwz r16,27752(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 27752);
	// lwz r16,24424(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 24424);
	// lwz r16,27268(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 27268);
	// lwz r16,27544(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 27544);
	// lwz r16,27296(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 27296);
	// lwz r16,28444(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 28444);
	// lwz r16,28744(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 28744);
	// lwz r16,26432(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 26432);
	// lwz r16,26668(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 26668);
loc_82185D08:
	// lbz r11,1359(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1359);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187070
	if (cr6.getEQ()) goto loc_82187070;
	// lbz r11,1360(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1360);
	// stb r24,1356(r31)
	PPC_STORE_U8(r31.u32 + 1356, r24.u8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stb r24,1361(r31)
	PPC_STORE_U8(r31.u32 + 1361, r24.u8);
	// stb r25,1363(r31)
	PPC_STORE_U8(r31.u32 + 1363, r25.u8);
	// beq cr6,0x82185d30
	if (cr6.getEQ()) goto loc_82185D30;
	// stb r25,1361(r31)
	PPC_STORE_U8(r31.u32 + 1361, r25.u8);
loc_82185D30:
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r10,20
	ctx.r10.s64 = 20;
	// stb r24,1357(r31)
	PPC_STORE_U8(r31.u32 + 1357, r24.u8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185d70
	if (cr6.getEQ()) goto loc_82185D70;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82185d58
	if (cr6.getEQ()) goto loc_82185D58;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185d70
	if (!cr6.getEQ()) goto loc_82185D70;
loc_82185D58:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
loc_82185D70:
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_82185D78:
	// lwz r11,1608(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1608);
	// mr r30,r25
	r30.u64 = r25.u64;
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// beq cr6,0x82185de0
	if (cr6.getEQ()) goto loc_82185DE0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82184d90
	sub_82184D90(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82185f40
	if (!cr6.getEQ()) goto loc_82185F40;
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r11,4
	r11.s64 = 4;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82185dd8
	if (cr6.getEQ()) goto loc_82185DD8;
	// lwz r10,1612(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r10,30
	cr6.compare<int32_t>(ctx.r10.s32, 30, xer);
	// beq cr6,0x82185dc0
	if (cr6.getEQ()) goto loc_82185DC0;
	// cmpwi cr6,r10,29
	cr6.compare<int32_t>(ctx.r10.s32, 29, xer);
	// bne cr6,0x82185dd8
	if (!cr6.getEQ()) goto loc_82185DD8;
loc_82185DC0:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r11,30
	r11.s64 = 30;
loc_82185DD8:
	// mr r30,r24
	r30.u64 = r24.u64;
	// b 0x82185f3c
	goto loc_82185F3C;
loc_82185DE0:
	// addi r3,r31,884
	ctx.r3.s64 = r31.s64 + 884;
	// bl 0x82187e30
	sub_82187E30(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82185ef4
	if (!cr6.getEQ()) goto loc_82185EF4;
	// lwz r30,888(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 888);
	// li r4,228
	ctx.r4.s64 = 228;
	// addi r29,r30,4
	r29.s64 = r30.s64 + 4;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x821828f0
	sub_821828F0(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// beq cr6,0x82185e58
	if (cr6.getEQ()) goto loc_82185E58;
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r10,4
	ctx.r10.s64 = 4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185ea8
	if (cr6.getEQ()) goto loc_82185EA8;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82185e34
	if (cr6.getEQ()) goto loc_82185E34;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185ea8
	if (!cr6.getEQ()) goto loc_82185EA8;
loc_82185E34:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
	// mr r30,r24
	r30.u64 = r24.u64;
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82185f40
	goto loc_82185F40;
loc_82185E58:
	// lis r10,24605
	ctx.r10.s64 = 1612513280;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// ori r10,r10,59872
	ctx.r10.u64 = ctx.r10.u64 | 59872;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82185eb4
	if (cr6.getEQ()) goto loc_82185EB4;
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r10,4
	ctx.r10.s64 = 4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185ea8
	if (cr6.getEQ()) goto loc_82185EA8;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82185e90
	if (cr6.getEQ()) goto loc_82185E90;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185ea8
	if (!cr6.getEQ()) goto loc_82185EA8;
loc_82185E90:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
loc_82185EA8:
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// mr r30,r24
	r30.u64 = r24.u64;
	// b 0x82185f40
	goto loc_82185F40;
loc_82185EB4:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82183860
	sub_82183860(ctx, base);
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r11,29
	r11.s64 = 29;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82185ee8
	if (cr6.getEQ()) goto loc_82185EE8;
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r11,30
	r11.s64 = 30;
loc_82185EE8:
	// stw r11,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r11.u32);
	// mr r30,r24
	r30.u64 = r24.u64;
	// b 0x82185f40
	goto loc_82185F40;
loc_82185EF4:
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// beq cr6,0x82185f40
	if (cr6.getEQ()) goto loc_82185F40;
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// mr r30,r24
	r30.u64 = r24.u64;
	// li r11,4
	r11.s64 = 4;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82185f3c
	if (cr6.getEQ()) goto loc_82185F3C;
	// lwz r10,1612(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r10,30
	cr6.compare<int32_t>(ctx.r10.s32, 30, xer);
	// beq cr6,0x82185f24
	if (cr6.getEQ()) goto loc_82185F24;
	// cmpwi cr6,r10,29
	cr6.compare<int32_t>(ctx.r10.s32, 29, xer);
	// bne cr6,0x82185f3c
	if (!cr6.getEQ()) goto loc_82185F3C;
loc_82185F24:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r11,30
	r11.s64 = 30;
loc_82185F3C:
	// stw r11,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r11.u32);
loc_82185F40:
	// clrlwi r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187070
	if (cr6.getEQ()) goto loc_82187070;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// stw r25,888(r31)
	PPC_STORE_U32(r31.u32 + 888, r25.u32);
	// addi r11,r11,-31880
	r11.s64 = r11.s64 + -31880;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_82185F68:
	// lwz r11,1608(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1608);
	// mr r29,r25
	r29.u64 = r25.u64;
	// mr r27,r25
	r27.u64 = r25.u64;
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// li r26,-1313
	r26.s64 = -1313;
	// addi r28,r11,-31880
	r28.s64 = r11.s64 + -31880;
	// beq cr6,0x82186054
	if (cr6.getEQ()) goto loc_82186054;
	// lbz r11,1359(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1359);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185fe4
	if (cr6.getEQ()) goto loc_82185FE4;
	// lbz r11,1361(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1361);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185fe4
	if (cr6.getEQ()) goto loc_82185FE4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82184ad8
	sub_82184AD8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82186080
	if (!cr6.getEQ()) goto loc_82186080;
	// lwz r11,1604(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1604);
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// beq cr6,0x82185fdc
	if (cr6.getEQ()) goto loc_82185FDC;
	// addi r10,r28,-72
	ctx.r10.s64 = r28.s64 + -72;
	// lwz r11,1368(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stbx r24,r11,r9
	PPC_STORE_U8(r11.u32 + ctx.r9.u32, r24.u8);
loc_82185FDC:
	// mr r29,r24
	r29.u64 = r24.u64;
	// b 0x8218607c
	goto loc_8218607C;
loc_82185FE4:
	// cmpwi cr6,r10,23
	cr6.compare<int32_t>(ctx.r10.s32, 23, xer);
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// bne cr6,0x8218602c
	if (!cr6.getEQ()) goto loc_8218602C;
	// li r11,24
	r11.s64 = 24;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8218604c
	if (cr6.getEQ()) goto loc_8218604C;
	// lwz r10,1612(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r10,30
	cr6.compare<int32_t>(ctx.r10.s32, 30, xer);
	// beq cr6,0x82186010
	if (cr6.getEQ()) goto loc_82186010;
	// cmpwi cr6,r10,29
	cr6.compare<int32_t>(ctx.r10.s32, 29, xer);
	// bne cr6,0x8218604c
	if (!cr6.getEQ()) goto loc_8218604C;
loc_82186010:
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// stw r26,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r26.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r11,30
	r11.s64 = 30;
	// stw r11,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r11.u32);
	// b 0x82186080
	goto loc_82186080;
loc_8218602C:
	// li r11,29
	r11.s64 = 29;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8218604c
	if (cr6.getEQ()) goto loc_8218604C;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// stw r26,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r26.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r11,30
	r11.s64 = 30;
loc_8218604C:
	// stw r11,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r11.u32);
	// b 0x82186080
	goto loc_82186080;
loc_82186054:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821845b0
	sub_821845B0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,-1
	cr6.compare<int32_t>(r30.s32, -1, xer);
	// beq cr6,0x82186080
	if (cr6.getEQ()) goto loc_82186080;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82183b00
	sub_82183B00(ctx, base);
	// mr r29,r24
	r29.u64 = r24.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x82186080
	if (!cr6.getEQ()) goto loc_82186080;
loc_8218607C:
	// mr r27,r24
	r27.u64 = r24.u64;
loc_82186080:
	// clrlwi r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187070
	if (cr6.getEQ()) goto loc_82187070;
	// lwz r11,1604(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1604);
	// cmpwi cr6,r11,23
	cr6.compare<int32_t>(r11.s32, 23, xer);
	// bne cr6,0x821860c4
	if (!cr6.getEQ()) goto loc_821860C4;
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r11,24
	r11.s64 = 24;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8218706c
	if (cr6.getEQ()) goto loc_8218706C;
	// lwz r10,1612(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r10,30
	cr6.compare<int32_t>(ctx.r10.s32, 30, xer);
	// beq cr6,0x821860bc
	if (cr6.getEQ()) goto loc_821860BC;
	// cmpwi cr6,r10,29
	cr6.compare<int32_t>(ctx.r10.s32, 29, xer);
	// bne cr6,0x8218706c
	if (!cr6.getEQ()) goto loc_8218706C;
loc_821860BC:
	// stw r26,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r26.u32);
	// b 0x8218705c
	goto loc_8218705C;
loc_821860C4:
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// bne cr6,0x82186134
	if (!cr6.getEQ()) goto loc_82186134;
	// lwz r11,1368(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// addi r10,r28,-24
	ctx.r10.s64 = r28.s64 + -24;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x82186134
	if (cr6.getEQ()) goto loc_82186134;
	// clrlwi r9,r27,24
	ctx.r9.u64 = r27.u32 & 0xFF;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82186134
	if (cr6.getEQ()) goto loc_82186134;
	// stwx r25,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r25.u32);
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82186628
	if (cr6.getEQ()) goto loc_82186628;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82186118
	if (cr6.getEQ()) goto loc_82186118;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82186628
	if (!cr6.getEQ()) goto loc_82186628;
loc_82186118:
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// stw r26,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r26.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r9,30
	ctx.r9.s64 = 30;
	// stw r9,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r9.u32);
	// b 0x82187070
	goto loc_82187070;
loc_82186134:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82184800
	sub_82184800(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82186174
	if (cr6.getEQ()) goto loc_82186174;
	// li r11,10
	r11.s64 = 10;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8218706c
	if (cr6.getEQ()) goto loc_8218706C;
	// lwz r10,1612(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r10,30
	cr6.compare<int32_t>(ctx.r10.s32, 30, xer);
	// beq cr6,0x821860bc
	if (cr6.getEQ()) goto loc_821860BC;
	// cmpwi cr6,r10,29
	cr6.compare<int32_t>(ctx.r10.s32, 29, xer);
	// bne cr6,0x8218706c
	if (!cr6.getEQ()) goto loc_8218706C;
	// stw r26,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r26.u32);
	// b 0x8218705c
	goto loc_8218705C;
loc_82186174:
	// li r11,2
	r11.s64 = 2;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8218706c
	if (cr6.getEQ()) goto loc_8218706C;
	// lwz r10,1612(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r10,30
	cr6.compare<int32_t>(ctx.r10.s32, 30, xer);
	// beq cr6,0x821860bc
	if (cr6.getEQ()) goto loc_821860BC;
	// cmpwi cr6,r10,29
	cr6.compare<int32_t>(ctx.r10.s32, 29, xer);
	// bne cr6,0x8218706c
	if (!cr6.getEQ()) goto loc_8218706C;
	// stw r26,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r26.u32);
	// b 0x8218705c
	goto loc_8218705C;
loc_8218619C:
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821861b8
	if (cr6.getEQ()) goto loc_821861B8;
	// li r11,-1313
	r11.s64 = -1313;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// b 0x82187060
	goto loc_82187060;
loc_821861B8:
	// bl 0x82184158
	sub_82184158(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82187070
	if (!cr6.getEQ()) goto loc_82187070;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lwz r11,-31884(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -31884);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82187070
	if (!cr6.getEQ()) goto loc_82187070;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r25,1616(r31)
	PPC_STORE_U32(r31.u32 + 1616, r25.u32);
	// bl 0x821839f0
	sub_821839F0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187070
	if (cr6.getEQ()) goto loc_82187070;
	// lwz r11,1604(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1604);
	// cmpwi cr6,r11,16
	cr6.compare<int32_t>(r11.s32, 16, xer);
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// bne cr6,0x82186240
	if (!cr6.getEQ()) goto loc_82186240;
	// li r10,7
	ctx.r10.s64 = 7;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185d70
	if (cr6.getEQ()) goto loc_82185D70;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82186220
	if (cr6.getEQ()) goto loc_82186220;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185d70
	if (!cr6.getEQ()) goto loc_82185D70;
loc_82186220:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_82186240:
	// li r10,8
	ctx.r10.s64 = 8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185d70
	if (cr6.getEQ()) goto loc_82185D70;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82186260
	if (cr6.getEQ()) goto loc_82186260;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185d70
	if (!cr6.getEQ()) goto loc_82185D70;
loc_82186260:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_82186280:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82184158
	sub_82184158(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82187070
	if (!cr6.getEQ()) goto loc_82187070;
	// lbz r11,1359(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1359);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8218642c
	if (cr6.getEQ()) goto loc_8218642C;
	// lbz r11,1361(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1361);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8218642c
	if (cr6.getEQ()) goto loc_8218642C;
	// lwz r11,1616(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1616);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x821862fc
	if (!cr6.getEQ()) goto loc_821862FC;
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r10,6
	ctx.r10.s64 = 6;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185d70
	if (cr6.getEQ()) goto loc_82185D70;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x821862dc
	if (cr6.getEQ()) goto loc_821862DC;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185d70
	if (!cr6.getEQ()) goto loc_82185D70;
loc_821862DC:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_821862FC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82184060
	sub_82184060(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r11,1604(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1604);
	// bne cr6,0x821863a0
	if (!cr6.getEQ()) goto loc_821863A0;
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// bne cr6,0x82186360
	if (!cr6.getEQ()) goto loc_82186360;
	// li r10,17
	ctx.r10.s64 = 17;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185d70
	if (cr6.getEQ()) goto loc_82185D70;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82186340
	if (cr6.getEQ()) goto loc_82186340;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185d70
	if (!cr6.getEQ()) goto loc_82185D70;
loc_82186340:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_82186360:
	// li r10,16
	ctx.r10.s64 = 16;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185d70
	if (cr6.getEQ()) goto loc_82185D70;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82186380
	if (cr6.getEQ()) goto loc_82186380;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185d70
	if (!cr6.getEQ()) goto loc_82185D70;
loc_82186380:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_821863A0:
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// bne cr6,0x821863ec
	if (!cr6.getEQ()) goto loc_821863EC;
	// li r10,11
	ctx.r10.s64 = 11;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185d70
	if (cr6.getEQ()) goto loc_82185D70;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x821863cc
	if (cr6.getEQ()) goto loc_821863CC;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185d70
	if (!cr6.getEQ()) goto loc_82185D70;
loc_821863CC:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_821863EC:
	// li r10,12
	ctx.r10.s64 = 12;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185d70
	if (cr6.getEQ()) goto loc_82185D70;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x8218640c
	if (cr6.getEQ()) goto loc_8218640C;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185d70
	if (!cr6.getEQ()) goto loc_82185D70;
loc_8218640C:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_8218642C:
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r11,29
	r11.s64 = 29;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8218706c
	if (cr6.getEQ()) goto loc_8218706C;
	// b 0x82187054
	goto loc_82187054;
loc_82186440:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821840d8
	sub_821840D8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x8218650c
	if (!cr6.getEQ()) goto loc_8218650C;
	// lwz r11,1604(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1604);
	// stb r25,1365(r31)
	PPC_STORE_U8(r31.u32 + 1365, r25.u8);
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x821864c8
	if (!cr6.getEQ()) goto loc_821864C8;
	// lis r10,-31991
	ctx.r10.s64 = -2096562176;
	// lwz r11,1368(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// li r9,22
	ctx.r9.s64 = 22;
	// addi r10,r10,-31880
	ctx.r10.s64 = ctx.r10.s64 + -31880;
	// addi r10,r10,-72
	ctx.r10.s64 = ctx.r10.s64 + -72;
	// addi r8,r10,10
	ctx.r8.s64 = ctx.r10.s64 + 10;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stbx r24,r11,r8
	PPC_STORE_U8(r11.u32 + ctx.r8.u32, r24.u8);
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82186628
	if (cr6.getEQ()) goto loc_82186628;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x821864a8
	if (cr6.getEQ()) goto loc_821864A8;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82186628
	if (!cr6.getEQ()) goto loc_82186628;
loc_821864A8:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r9,30
	ctx.r9.s64 = 30;
	// stw r9,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r9.u32);
	// b 0x82187070
	goto loc_82187070;
loc_821864C8:
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r10,19
	ctx.r10.s64 = 19;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185d70
	if (cr6.getEQ()) goto loc_82185D70;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x821864ec
	if (cr6.getEQ()) goto loc_821864EC;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185d70
	if (!cr6.getEQ()) goto loc_82185D70;
loc_821864EC:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_8218650C:
	// cmplwi cr6,r3,1627
	cr6.compare<uint32_t>(ctx.r3.u32, 1627, xer);
	// bne cr6,0x82187070
	if (!cr6.getEQ()) goto loc_82187070;
	// lwz r11,1604(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1604);
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// bne cr6,0x82186564
	if (!cr6.getEQ()) goto loc_82186564;
	// li r10,17
	ctx.r10.s64 = 17;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185d70
	if (cr6.getEQ()) goto loc_82185D70;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82186544
	if (cr6.getEQ()) goto loc_82186544;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185d70
	if (!cr6.getEQ()) goto loc_82185D70;
loc_82186544:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_82186564:
	// li r10,16
	ctx.r10.s64 = 16;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185d70
	if (cr6.getEQ()) goto loc_82185D70;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82186584
	if (cr6.getEQ()) goto loc_82186584;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185d70
	if (!cr6.getEQ()) goto loc_82185D70;
loc_82186584:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_821865A4:
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lwz r11,-31884(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -31884);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82187070
	if (!cr6.getEQ()) goto loc_82187070;
	// lwz r11,1620(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1620);
	// cmplwi cr6,r11,997
	cr6.compare<uint32_t>(r11.u32, 997, xer);
	// beq cr6,0x82187070
	if (cr6.getEQ()) goto loc_82187070;
	// lwz r9,1616(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 1616);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82186644
	if (!cr6.getEQ()) goto loc_82186644;
	// lwz r11,3188(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 3188);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82186630
	if (!cr6.getEQ()) goto loc_82186630;
	// lis r10,-31991
	ctx.r10.s64 = -2096562176;
	// lwz r11,1368(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// stb r25,1361(r31)
	PPC_STORE_U8(r31.u32 + 1361, r25.u8);
	// li r9,29
	ctx.r9.s64 = 29;
	// addi r10,r10,-31880
	ctx.r10.s64 = ctx.r10.s64 + -31880;
	// addi r10,r10,-72
	ctx.r10.s64 = ctx.r10.s64 + -72;
	// addi r8,r10,8
	ctx.r8.s64 = ctx.r10.s64 + 8;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stbx r24,r11,r8
	PPC_STORE_U8(r11.u32 + ctx.r8.u32, r24.u8);
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82186628
	if (cr6.getEQ()) goto loc_82186628;
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r9,30
	ctx.r9.s64 = 30;
loc_82186628:
	// stw r9,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r9.u32);
	// b 0x82187070
	goto loc_82187070;
loc_82186630:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82186644
	if (!cr6.getEQ()) goto loc_82186644;
	// lwz r11,3188(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 3188);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82186650
	if (!cr6.getEQ()) goto loc_82186650;
loc_82186644:
	// lwz r11,3188(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 3188);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bne cr6,0x821866b0
	if (!cr6.getEQ()) goto loc_821866B0;
loc_82186650:
	// stw r11,1616(r31)
	PPC_STORE_U32(r31.u32 + 1616, r11.u32);
	// stb r24,1361(r31)
	PPC_STORE_U8(r31.u32 + 1361, r24.u8);
	// stw r25,3188(r31)
	PPC_STORE_U32(r31.u32 + 3188, r25.u32);
	// lwz r11,664(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 664);
	// rlwinm r11,r11,30,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8218642c
	if (!cr6.getEQ()) goto loc_8218642C;
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r10,9
	ctx.r10.s64 = 9;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185d70
	if (cr6.getEQ()) goto loc_82185D70;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82186690
	if (cr6.getEQ()) goto loc_82186690;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185d70
	if (!cr6.getEQ()) goto loc_82185D70;
loc_82186690:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_821866B0:
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// cmpwi cr6,r10,8
	cr6.compare<int32_t>(ctx.r10.s32, 8, xer);
	// bne cr6,0x82186700
	if (!cr6.getEQ()) goto loc_82186700;
	// li r10,13
	ctx.r10.s64 = 13;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821866f4
	if (cr6.getEQ()) goto loc_821866F4;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x821866dc
	if (cr6.getEQ()) goto loc_821866DC;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x821866f4
	if (!cr6.getEQ()) goto loc_821866F4;
loc_821866DC:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
loc_821866F4:
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// stb r24,1361(r31)
	PPC_STORE_U8(r31.u32 + 1361, r24.u8);
	// b 0x82187070
	goto loc_82187070;
loc_82186700:
	// li r10,10
	ctx.r10.s64 = 10;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185d70
	if (cr6.getEQ()) goto loc_82185D70;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82186720
	if (cr6.getEQ()) goto loc_82186720;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185d70
	if (!cr6.getEQ()) goto loc_82185D70;
loc_82186720:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_82186740:
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// stb r25,1357(r31)
	PPC_STORE_U8(r31.u32 + 1357, r25.u8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82186760
	if (cr6.getEQ()) goto loc_82186760;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// stw r26,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r26.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821851b8
	sub_821851B8(ctx, base);
loc_82186760:
	// li r11,30
	r11.s64 = 30;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r11.u32);
	// bl 0x821838b0
	sub_821838B0(ctx, base);
	// cmplw cr6,r31,r3
	cr6.compare<uint32_t>(r31.u32, ctx.r3.u32, xer);
	// bne cr6,0x82186784
	if (!cr6.getEQ()) goto loc_82186784;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821838b0
	sub_821838B0(ctx, base);
	// bl 0x820e9158
	sub_820E9158(ctx, base);
loc_82186784:
	// lwz r11,664(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 664);
	// rlwinm r11,r11,30,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8218682c
	if (cr6.getEQ()) goto loc_8218682C;
	// lbz r11,1359(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1359);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8218682c
	if (cr6.getEQ()) goto loc_8218682C;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82183930
	sub_82183930(ctx, base);
	// addi r11,r3,-1
	r11.s64 = ctx.r3.s64 + -1;
	// li r4,3
	ctx.r4.s64 = 3;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r5,r11,27,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// bl 0x82184f98
	sub_82184F98(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x82184f98
	sub_82184F98(ctx, base);
	// lbz r11,1361(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1361);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8218681c
	if (cr6.getEQ()) goto loc_8218681C;
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r11,9
	r11.s64 = 9;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82186814
	if (cr6.getEQ()) goto loc_82186814;
	// lwz r10,1612(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r10,30
	cr6.compare<int32_t>(ctx.r10.s32, 30, xer);
	// beq cr6,0x82186800
	if (cr6.getEQ()) goto loc_82186800;
	// cmpwi cr6,r10,29
	cr6.compare<int32_t>(ctx.r10.s32, 29, xer);
	// bne cr6,0x82186814
	if (!cr6.getEQ()) goto loc_82186814;
loc_82186800:
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// stw r26,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r26.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r11,30
	r11.s64 = 30;
loc_82186814:
	// stw r11,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r11.u32);
	// b 0x8218682c
	goto loc_8218682C;
loc_8218681C:
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82184f98
	sub_82184F98(ctx, base);
loc_8218682C:
	// lbz r11,1356(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1356);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821869a0
	if (cr6.getEQ()) goto loc_821869A0;
	// bl 0x8215fc88
	sub_8215FC88(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// bne cr6,0x821869a0
	if (!cr6.getEQ()) goto loc_821869A0;
	// bl 0x82151c68
	sub_82151C68(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x821869a0
	if (cr6.getEQ()) goto loc_821869A0;
	// bl 0x8215fc88
	sub_8215FC88(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// bne cr6,0x8218686c
	if (!cr6.getEQ()) goto loc_8218686C;
	// bl 0x8217f200
	sub_8217F200(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82186890
	if (cr6.getEQ()) goto loc_82186890;
loc_8218686C:
	// bl 0x82151c68
	sub_82151C68(ctx, base);
	// addi r3,r3,728
	ctx.r3.s64 = ctx.r3.s64 + 728;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821869a0
	if (cr6.getEQ()) goto loc_821869A0;
loc_82186890:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r6,2
	ctx.r6.s64 = 2;
	// addi r11,r11,14756
	r11.s64 = r11.s64 + 14756;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// mr r30,r25
	r30.u64 = r25.u64;
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r11.u32);
	// bl 0x8216c178
	sub_8216C178(ctx, base);
loc_821868B4:
	// lwz r9,156(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// lwz r11,160(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// beq cr6,0x821868d0
	if (cr6.getEQ()) goto loc_821868D0;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// mr r11,r25
	r11.u64 = r25.u64;
	// bne cr6,0x821868d4
	if (!cr6.getEQ()) goto loc_821868D4;
loc_821868D0:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_821868D4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82186964
	if (!cr6.getEQ()) goto loc_82186964;
	// lwz r11,1368(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// lwz r10,820(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 820);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// bne cr6,0x82186908
	if (!cr6.getEQ()) goto loc_82186908;
	// ld r8,784(r9)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r9.u32 + 784);
	// ld r7,1288(r31)
	ctx.r7.u64 = PPC_LOAD_U64(r31.u32 + 1288);
	// cmpld cr6,r8,r7
	cr6.compare<uint64_t>(ctx.r8.u64, ctx.r7.u64, xer);
	// bne cr6,0x82186918
	if (!cr6.getEQ()) goto loc_82186918;
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// beq cr6,0x82186940
	if (cr6.getEQ()) goto loc_82186940;
loc_82186908:
	// ld r8,784(r9)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r9.u32 + 784);
	// ld r7,1288(r31)
	ctx.r7.u64 = PPC_LOAD_U64(r31.u32 + 1288);
	// cmpld cr6,r8,r7
	cr6.compare<uint64_t>(ctx.r8.u64, ctx.r7.u64, xer);
	// bne cr6,0x82186938
	if (!cr6.getEQ()) goto loc_82186938;
loc_82186918:
	// lbz r11,864(r9)
	r11.u64 = PPC_LOAD_U8(ctx.r9.u32 + 864);
	// mr r30,r24
	r30.u64 = r24.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82186958
	if (!cr6.getEQ()) goto loc_82186958;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// stb r24,864(r9)
	PPC_STORE_U8(ctx.r9.u32 + 864, r24.u8);
	// bl 0x8216c2a8
	sub_8216C2A8(ctx, base);
	// b 0x821868b4
	goto loc_821868B4;
loc_82186938:
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// bne cr6,0x82186958
	if (!cr6.getEQ()) goto loc_82186958;
loc_82186940:
	// ld r11,784(r9)
	r11.u64 = PPC_LOAD_U64(ctx.r9.u32 + 784);
	// ld r10,1288(r31)
	ctx.r10.u64 = PPC_LOAD_U64(r31.u32 + 1288);
	// cmpld cr6,r11,r10
	cr6.compare<uint64_t>(r11.u64, ctx.r10.u64, xer);
	// bne cr6,0x82186958
	if (!cr6.getEQ()) goto loc_82186958;
	// mr r30,r24
	r30.u64 = r24.u64;
	// stb r25,1356(r31)
	PPC_STORE_U8(r31.u32 + 1356, r25.u8);
loc_82186958:
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x8216c2a8
	sub_8216C2A8(ctx, base);
	// b 0x821868b4
	goto loc_821868B4;
loc_82186964:
	// clrlwi r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82186990
	if (!cr6.getEQ()) goto loc_82186990;
	// li r5,16
	ctx.r5.s64 = 16;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82182938
	sub_82182938(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,1368(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// bl 0x82159418
	sub_82159418(ctx, base);
	// stb r25,1356(r31)
	PPC_STORE_U8(r31.u32 + 1356, r25.u8);
loc_82186990:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r11,r11,14748
	r11.s64 = r11.s64 + 14748;
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r11.u32);
	// b 0x821869a4
	goto loc_821869A4;
loc_821869A0:
	// stb r25,1356(r31)
	PPC_STORE_U8(r31.u32 + 1356, r25.u8);
loc_821869A4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82183990
	sub_82183990(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821869cc
	if (cr6.getEQ()) goto loc_821869CC;
	// lbz r11,1360(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1360);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x821869cc
	if (!cr6.getEQ()) goto loc_821869CC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82184ea0
	sub_82184EA0(ctx, base);
loc_821869CC:
	// lis r11,0
	r11.s64 = 0;
	// ori r11,r11,42515
	r11.u64 = r11.u64 | 42515;
	// lbzx r11,r31,r11
	r11.u64 = PPC_LOAD_U8(r31.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82186a0c
	if (cr6.getEQ()) goto loc_82186A0C;
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r11,23
	r11.s64 = 23;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8218706c
	if (cr6.getEQ()) goto loc_8218706C;
	// lwz r10,1612(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r10,30
	cr6.compare<int32_t>(ctx.r10.s32, 30, xer);
	// beq cr6,0x821860bc
	if (cr6.getEQ()) goto loc_821860BC;
	// cmpwi cr6,r10,29
	cr6.compare<int32_t>(ctx.r10.s32, 29, xer);
	// bne cr6,0x8218706c
	if (!cr6.getEQ()) goto loc_8218706C;
	// stw r26,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r26.u32);
	// b 0x8218705c
	goto loc_8218705C;
loc_82186A0C:
	// lis r11,0
	r11.s64 = 0;
	// ori r11,r11,42516
	r11.u64 = r11.u64 | 42516;
	// lbzx r11,r31,r11
	r11.u64 = PPC_LOAD_U8(r31.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82186a4c
	if (cr6.getEQ()) goto loc_82186A4C;
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r11,26
	r11.s64 = 26;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8218706c
	if (cr6.getEQ()) goto loc_8218706C;
	// lwz r10,1612(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r10,30
	cr6.compare<int32_t>(ctx.r10.s32, 30, xer);
	// beq cr6,0x821860bc
	if (cr6.getEQ()) goto loc_821860BC;
	// cmpwi cr6,r10,29
	cr6.compare<int32_t>(ctx.r10.s32, 29, xer);
	// bne cr6,0x8218706c
	if (!cr6.getEQ()) goto loc_8218706C;
	// stw r26,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r26.u32);
	// b 0x8218705c
	goto loc_8218705C;
loc_82186A4C:
	// lbz r11,1364(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1364);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187070
	if (cr6.getEQ()) goto loc_82187070;
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r11,25
	r11.s64 = 25;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8218706c
	if (cr6.getEQ()) goto loc_8218706C;
	// lwz r10,1612(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r10,30
	cr6.compare<int32_t>(ctx.r10.s32, 30, xer);
	// beq cr6,0x821860bc
	if (cr6.getEQ()) goto loc_821860BC;
	// cmpwi cr6,r10,29
	cr6.compare<int32_t>(ctx.r10.s32, 29, xer);
	// bne cr6,0x8218706c
	if (!cr6.getEQ()) goto loc_8218706C;
	// stw r26,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r26.u32);
	// b 0x8218705c
	goto loc_8218705C;
loc_82186A84:
	// lis r11,0
	r11.s64 = 0;
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// ori r11,r11,42515
	r11.u64 = r11.u64 | 42515;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// stbx r25,r31,r11
	PPC_STORE_U8(r31.u32 + r11.u32, r25.u8);
	// beq cr6,0x82187068
	if (cr6.getEQ()) goto loc_82187068;
	// b 0x82187054
	goto loc_82187054;
loc_82186AA0:
	// lwz r11,1608(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1608);
	// mr r30,r25
	r30.u64 = r25.u64;
	// lbz r29,1362(r31)
	r29.u64 = PPC_LOAD_U8(r31.u32 + 1362);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmpwi cr6,r11,26
	cr6.compare<int32_t>(r11.s32, 26, xer);
	// beq cr6,0x82186ad0
	if (cr6.getEQ()) goto loc_82186AD0;
	// bl 0x82184470
	sub_82184470(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82186af0
	if (!cr6.getEQ()) goto loc_82186AF0;
	// stb r25,1362(r31)
	PPC_STORE_U8(r31.u32 + 1362, r25.u8);
	// b 0x82186aec
	goto loc_82186AEC;
loc_82186AD0:
	// bl 0x82184538
	sub_82184538(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82186af0
	if (cr6.getEQ()) goto loc_82186AF0;
	// addi r11,r3,-1
	r11.s64 = ctx.r3.s64 + -1;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// stb r11,1362(r31)
	PPC_STORE_U8(r31.u32 + 1362, r11.u8);
loc_82186AEC:
	// mr r30,r24
	r30.u64 = r24.u64;
loc_82186AF0:
	// clrlwi r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187070
	if (cr6.getEQ()) goto loc_82187070;
	// lis r11,0
	r11.s64 = 0;
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// ori r11,r11,42516
	r11.u64 = r11.u64 | 42516;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// stbx r25,r31,r11
	PPC_STORE_U8(r31.u32 + r11.u32, r25.u8);
	// beq cr6,0x82186b28
	if (cr6.getEQ()) goto loc_82186B28;
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
loc_82186B28:
	// li r11,30
	r11.s64 = 30;
	// lbz r10,1362(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 1362);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// stw r11,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r11.u32);
	// bne cr6,0x82186b64
	if (!cr6.getEQ()) goto loc_82186B64;
	// lis r10,-31991
	ctx.r10.s64 = -2096562176;
	// lwz r11,1368(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// addi r10,r10,-31880
	ctx.r10.s64 = ctx.r10.s64 + -31880;
	// addi r10,r10,-72
	ctx.r10.s64 = ctx.r10.s64 + -72;
	// addi r9,r10,4
	ctx.r9.s64 = ctx.r10.s64 + 4;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stbx r29,r11,r9
	PPC_STORE_U8(r11.u32 + ctx.r9.u32, r29.u8);
	// b 0x82187070
	goto loc_82187070;
loc_82186B64:
	// clrlwi r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82187070
	if (!cr6.getEQ()) goto loc_82187070;
	// lis r10,-31991
	ctx.r10.s64 = -2096562176;
	// lwz r11,1368(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// addi r10,r10,-31880
	ctx.r10.s64 = ctx.r10.s64 + -31880;
	// addi r10,r10,-72
	ctx.r10.s64 = ctx.r10.s64 + -72;
	// addi r9,r10,6
	ctx.r9.s64 = ctx.r10.s64 + 6;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stbx r24,r11,r9
	PPC_STORE_U8(r11.u32 + ctx.r9.u32, r24.u8);
	// b 0x82187070
	goto loc_82187070;
loc_82186B98:
	// lwz r11,1608(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1608);
	// mr r30,r25
	r30.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmpwi cr6,r11,25
	cr6.compare<int32_t>(r11.s32, 25, xer);
	// bne cr6,0x82186c0c
	if (!cr6.getEQ()) goto loc_82186C0C;
	// bl 0x821840d8
	sub_821840D8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82186bf8
	if (!cr6.getEQ()) goto loc_82186BF8;
	// lbz r11,1365(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1365);
	// mr r30,r24
	r30.u64 = r24.u64;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x82186c48
	if (!cr6.getEQ()) goto loc_82186C48;
	// lis r10,-31991
	ctx.r10.s64 = -2096562176;
	// lwz r11,1368(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// addi r10,r10,-31880
	ctx.r10.s64 = ctx.r10.s64 + -31880;
	// addi r10,r10,-72
	ctx.r10.s64 = ctx.r10.s64 + -72;
	// addi r9,r10,2
	ctx.r9.s64 = ctx.r10.s64 + 2;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stbx r24,r11,r9
	PPC_STORE_U8(r11.u32 + ctx.r9.u32, r24.u8);
	// stb r24,1361(r31)
	PPC_STORE_U8(r31.u32 + 1361, r24.u8);
	// stb r25,1365(r31)
	PPC_STORE_U8(r31.u32 + 1365, r25.u8);
	// b 0x82186c48
	goto loc_82186C48;
loc_82186BF8:
	// cmplwi cr6,r3,1167
	cr6.compare<uint32_t>(ctx.r3.u32, 1167, xer);
	// beq cr6,0x82186c1c
	if (cr6.getEQ()) goto loc_82186C1C;
	// cmplwi cr6,r3,1627
	cr6.compare<uint32_t>(ctx.r3.u32, 1627, xer);
	// bne cr6,0x82186c48
	if (!cr6.getEQ()) goto loc_82186C48;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82186C0C:
	// bl 0x82184060
	sub_82184060(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82186c48
	if (!cr6.getEQ()) goto loc_82186C48;
loc_82186C1C:
	// lis r10,-31991
	ctx.r10.s64 = -2096562176;
	// lwz r11,1368(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// mr r30,r24
	r30.u64 = r24.u64;
	// addi r10,r10,-31880
	ctx.r10.s64 = ctx.r10.s64 + -31880;
	// addi r9,r10,-72
	ctx.r9.s64 = ctx.r10.s64 + -72;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stbx r24,r11,r9
	PPC_STORE_U8(r11.u32 + ctx.r9.u32, r24.u8);
	// stb r25,1361(r31)
	PPC_STORE_U8(r31.u32 + 1361, r25.u8);
	// stb r24,1365(r31)
	PPC_STORE_U8(r31.u32 + 1365, r24.u8);
loc_82186C48:
	// clrlwi r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187070
	if (cr6.getEQ()) goto loc_82187070;
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// stb r25,1364(r31)
	PPC_STORE_U8(r31.u32 + 1364, r25.u8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187068
	if (cr6.getEQ()) goto loc_82187068;
	// b 0x82187054
	goto loc_82187054;
loc_82186C68:
	// lwz r11,1608(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1608);
	// mr r30,r25
	r30.u64 = r25.u64;
	// mr r29,r25
	r29.u64 = r25.u64;
	// li r26,-1313
	r26.s64 = -1313;
	// cmpwi cr6,r11,22
	cr6.compare<int32_t>(r11.s32, 22, xer);
	// beq cr6,0x82186ca0
	if (cr6.getEQ()) goto loc_82186CA0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82185500
	sub_82185500(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82186d04
	if (!cr6.getEQ()) goto loc_82186D04;
	// lbz r11,1268(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1268);
	// stb r11,1363(r31)
	PPC_STORE_U8(r31.u32 + 1363, r11.u8);
	// b 0x82186d00
	goto loc_82186D00;
loc_82186CA0:
	// addi r3,r31,884
	ctx.r3.s64 = r31.s64 + 884;
	// bl 0x82188270
	sub_82188270(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82186cf4
	if (!cr6.getEQ()) goto loc_82186CF4;
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r11,21
	r11.s64 = 21;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82186ce8
	if (cr6.getEQ()) goto loc_82186CE8;
	// lwz r10,1612(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r10,30
	cr6.compare<int32_t>(ctx.r10.s32, 30, xer);
	// beq cr6,0x82186cd4
	if (cr6.getEQ()) goto loc_82186CD4;
	// cmpwi cr6,r10,29
	cr6.compare<int32_t>(ctx.r10.s32, 29, xer);
	// bne cr6,0x82186ce8
	if (!cr6.getEQ()) goto loc_82186CE8;
loc_82186CD4:
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// stw r26,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r26.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r11,30
	r11.s64 = 30;
loc_82186CE8:
	// mr r30,r24
	r30.u64 = r24.u64;
	// stw r11,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r11.u32);
	// b 0x82186d04
	goto loc_82186D04;
loc_82186CF4:
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// beq cr6,0x82186d04
	if (cr6.getEQ()) goto loc_82186D04;
	// mr r30,r24
	r30.u64 = r24.u64;
loc_82186D00:
	// mr r29,r24
	r29.u64 = r24.u64;
loc_82186D04:
	// clrlwi r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82186d3c
	if (cr6.getEQ()) goto loc_82186D3C;
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82186d2c
	if (cr6.getEQ()) goto loc_82186D2C;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// stw r26,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r26.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821851b8
	sub_821851B8(ctx, base);
loc_82186D2C:
	// li r11,30
	r11.s64 = 30;
	// stb r25,1361(r31)
	PPC_STORE_U8(r31.u32 + 1361, r25.u8);
	// mr r30,r24
	r30.u64 = r24.u64;
	// stw r11,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r11.u32);
loc_82186D3C:
	// clrlwi r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187070
	if (cr6.getEQ()) goto loc_82187070;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// stw r25,888(r31)
	PPC_STORE_U32(r31.u32 + 888, r25.u32);
	// addi r11,r11,-31880
	r11.s64 = r11.s64 + -31880;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_82186D64:
	// lwz r10,1608(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1608);
	// mr r11,r25
	r11.u64 = r25.u64;
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// cmpwi cr6,r10,21
	cr6.compare<int32_t>(ctx.r10.s32, 21, xer);
	// beq cr6,0x82186da4
	if (cr6.getEQ()) goto loc_82186DA4;
	// lwz r10,3188(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 3188);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82186d98
	if (cr6.getEQ()) goto loc_82186D98;
	// lwz r8,1616(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 1616);
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// beq cr6,0x82186d98
	if (cr6.getEQ()) goto loc_82186D98;
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
	// mr r11,r24
	r11.u64 = r24.u64;
loc_82186D98:
	// clrlwi r10,r9,24
	ctx.r10.u64 = ctx.r9.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82186da8
	if (!cr6.getEQ()) goto loc_82186DA8;
loc_82186DA4:
	// mr r11,r24
	r11.u64 = r24.u64;
loc_82186DA8:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187070
	if (cr6.getEQ()) goto loc_82187070;
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// stb r25,1600(r31)
	PPC_STORE_U8(r31.u32 + 1600, r25.u8);
	// stb r25,1601(r31)
	PPC_STORE_U8(r31.u32 + 1601, r25.u8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// beq cr6,0x82186e0c
	if (cr6.getEQ()) goto loc_82186E0C;
	// li r10,18
	ctx.r10.s64 = 18;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82186e04
	if (cr6.getEQ()) goto loc_82186E04;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82186dec
	if (cr6.getEQ()) goto loc_82186DEC;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82186e04
	if (!cr6.getEQ()) goto loc_82186E04;
loc_82186DEC:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
loc_82186E04:
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82186e30
	goto loc_82186E30;
loc_82186E0C:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82186e28
	if (cr6.getEQ()) goto loc_82186E28;
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
loc_82186E28:
	// li r11,30
	r11.s64 = 30;
	// stw r11,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r11.u32);
loc_82186E30:
	// addi r11,r31,1372
	r11.s64 = r31.s64 + 1372;
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// li r10,7
	ctx.r10.s64 = 7;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_82186E40:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82186e40
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82186E40;
	// b 0x82187070
	goto loc_82187070;
loc_82186E50:
	// lwz r11,1608(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1608);
	// cmpwi cr6,r11,18
	cr6.compare<int32_t>(r11.s32, 18, xer);
	// beq cr6,0x82186ea8
	if (cr6.getEQ()) goto loc_82186EA8;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lwz r10,3188(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 3188);
	// lwz r9,1368(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// addi r5,r31,884
	ctx.r5.s64 = r31.s64 + 884;
	// addi r4,r31,3192
	ctx.r4.s64 = r31.s64 + 3192;
	// lwz r3,3236(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 3236);
	// stw r25,888(r31)
	PPC_STORE_U32(r31.u32 + 888, r25.u32);
	// lwz r11,-31880(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -31880);
	// stw r10,952(r31)
	PPC_STORE_U32(r31.u32 + 952, ctx.r10.u32);
	// stw r9,884(r31)
	PPC_STORE_U32(r31.u32 + 884, ctx.r9.u32);
	// stw r11,892(r31)
	PPC_STORE_U32(r31.u32 + 892, r11.u32);
	// bl 0x82188108
	sub_82188108(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82187070
	if (!cr6.getEQ()) goto loc_82187070;
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187068
	if (cr6.getEQ()) goto loc_82187068;
	// b 0x82187054
	goto loc_82187054;
loc_82186EA8:
	// addi r3,r31,884
	ctx.r3.s64 = r31.s64 + 884;
	// bl 0x821881f0
	sub_821881F0(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187070
	if (cr6.getEQ()) goto loc_82187070;
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187068
	if (cr6.getEQ()) goto loc_82187068;
	// b 0x82187054
	goto loc_82187054;
loc_82186ECC:
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82186ee8
	if (cr6.getEQ()) goto loc_82186EE8;
	// li r11,-1313
	r11.s64 = -1313;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// b 0x82187060
	goto loc_82187060;
loc_82186EE8:
	// li r11,3
	r11.s64 = 3;
	// stw r11,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r11.u32);
	// bl 0x82185b18
	sub_82185B18(ctx, base);
	// b 0x82187070
	goto loc_82187070;
loc_82186EF8:
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82187054
	if (!cr6.getEQ()) goto loc_82187054;
	// li r11,5
	r11.s64 = 5;
	// lwz r4,1368(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// clrlwi r3,r4,24
	ctx.r3.u64 = ctx.r4.u32 & 0xFF;
	// stw r11,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r11.u32);
	// bl 0x82185660
	sub_82185660(ctx, base);
	// b 0x82187070
	goto loc_82187070;
loc_82186F1C:
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82187054
	if (!cr6.getEQ()) goto loc_82187054;
	// li r11,28
	r11.s64 = 28;
	// b 0x8218706c
	goto loc_8218706C;
loc_82186F30:
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82187054
	if (!cr6.getEQ()) goto loc_82187054;
	// li r11,29
	r11.s64 = 29;
	// b 0x8218706c
	goto loc_8218706C;
loc_82186F44:
	// li r7,42
	ctx.r7.s64 = 42;
	// lwz r4,1616(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 1616);
	// addi r6,r1,176
	ctx.r6.s64 = ctx.r1.s64 + 176;
	// addi r5,r31,3248
	ctx.r5.s64 = r31.s64 + 3248;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82183718
	sub_82183718(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82186fac
	if (cr6.getEQ()) goto loc_82186FAC;
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r10,14
	ctx.r10.s64 = 14;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82185d70
	if (cr6.getEQ()) goto loc_82185D70;
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x82186f8c
	if (cr6.getEQ()) goto loc_82186F8C;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x82185d70
	if (!cr6.getEQ()) goto loc_82185D70;
loc_82186F8C:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r10,30
	ctx.r10.s64 = 30;
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// b 0x82187070
	goto loc_82187070;
loc_82186FAC:
	// lwz r4,1368(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// clrlwi r3,r4,24
	ctx.r3.u64 = ctx.r4.u32 & 0xFF;
	// bl 0x82185660
	sub_82185660(ctx, base);
	// b 0x82187070
	goto loc_82187070;
loc_82186FBC:
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82187054
	if (!cr6.getEQ()) goto loc_82187054;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// addi r3,r11,-31832
	ctx.r3.s64 = r11.s64 + -31832;
	// bl 0x823edbb8
	sub_823EDBB8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r10,3248(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 3248);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r4,r10,r11
	ctx.r4.u64 = ctx.r10.u64 + r11.u64;
	// bl 0x821832c0
	sub_821832C0(ctx, base);
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82183230
	sub_82183230(ctx, base);
	// lbz r10,3260(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// li r11,15
	r11.s64 = 15;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82187030
	if (cr6.getEQ()) goto loc_82187030;
	// lwz r10,1612(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r10,30
	cr6.compare<int32_t>(ctx.r10.s32, 30, xer);
	// beq cr6,0x82187018
	if (cr6.getEQ()) goto loc_82187018;
	// cmpwi cr6,r10,29
	cr6.compare<int32_t>(ctx.r10.s32, 29, xer);
	// bne cr6,0x82187030
	if (!cr6.getEQ()) goto loc_82187030;
loc_82187018:
	// li r11,-1313
	r11.s64 = -1313;
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
	// bl 0x821851b8
	sub_821851B8(ctx, base);
	// li r11,30
	r11.s64 = 30;
loc_82187030:
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// stw r11,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r11.u32);
	// bl 0x82182ba0
	sub_82182BA0(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x82182ba0
	sub_82182BA0(ctx, base);
	// b 0x82187070
	goto loc_82187070;
loc_82187048:
	// lbz r11,3260(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3260);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187070
	if (cr6.getEQ()) goto loc_82187070;
loc_82187054:
	// li r11,-1313
	r11.s64 = -1313;
	// stw r11,1368(r31)
	PPC_STORE_U32(r31.u32 + 1368, r11.u32);
loc_8218705C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82187060:
	// li r4,-1313
	ctx.r4.s64 = -1313;
	// bl 0x821851b8
	sub_821851B8(ctx, base);
loc_82187068:
	// li r11,30
	r11.s64 = 30;
loc_8218706C:
	// stw r11,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, r11.u32);
loc_82187070:
	// lwz r11,3264(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 3264);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187094
	if (cr6.getEQ()) goto loc_82187094;
	// bl 0x823b3600
	sub_823B3600(ctx, base);
	// lwz r11,3264(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 3264);
	// subf r11,r11,r3
	r11.s64 = ctx.r3.s64 - r11.s64;
	// cmplwi cr6,r11,5000
	cr6.compare<uint32_t>(r11.u32, 5000, xer);
	// ble cr6,0x82187094
	if (!cr6.getGT()) goto loc_82187094;
	// stw r25,3264(r31)
	PPC_STORE_U32(r31.u32 + 3264, r25.u32);
loc_82187094:
	// lwz r11,3268(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 3268);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821870c8
	if (cr6.getEQ()) goto loc_821870C8;
	// bl 0x823b3600
	sub_823B3600(ctx, base);
	// lwz r11,3268(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 3268);
	// subf r11,r11,r3
	r11.s64 = ctx.r3.s64 - r11.s64;
	// cmplwi cr6,r11,5000
	cr6.compare<uint32_t>(r11.u32, 5000, xer);
	// ble cr6,0x821870c8
	if (!cr6.getGT()) goto loc_821870C8;
	// lbz r11,3261(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3261);
	// stw r25,3268(r31)
	PPC_STORE_U32(r31.u32 + 3268, r25.u32);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// stb r11,3261(r31)
	PPC_STORE_U8(r31.u32 + 3261, r11.u8);
loc_821870C8:
	// lwz r10,1604(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 1604);
	// lwz r11,1612(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1612);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// stw r10,1608(r31)
	PPC_STORE_U32(r31.u32 + 1608, ctx.r10.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// beq cr6,0x821870f4
	if (cr6.getEQ()) goto loc_821870F4;
	// lwz r9,1608(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 1608);
	// stw r11,1604(r31)
	PPC_STORE_U32(r31.u32 + 1604, r11.u32);
	// cmpw cr6,r9,r11
	cr6.compare<int32_t>(ctx.r9.s32, r11.s32, xer);
	// bne cr6,0x821870f4
	if (!cr6.getEQ()) goto loc_821870F4;
	// stw r10,1608(r31)
	PPC_STORE_U32(r31.u32 + 1608, ctx.r10.u32);
loc_821870F4:
	// lbz r11,1360(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1360);
	// stw r10,1612(r31)
	PPC_STORE_U32(r31.u32 + 1612, ctx.r10.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x821872a0
	if (!cr6.getEQ()) goto loc_821872A0;
	// addi r30,r31,1452
	r30.s64 = r31.s64 + 1452;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823bc3a8
	sub_823BC3A8(ctx, base);
	// lwz r11,1588(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1588);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x82187124
	if (!cr6.getEQ()) goto loc_82187124;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823bc338
	sub_823BC338(ctx, base);
loc_82187124:
	// addis r28,r31,1
	r28.s64 = r31.s64 + 65536;
	// addi r28,r28,-23024
	r28.s64 = r28.s64 + -23024;
	// lbz r11,0(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821871bc
	if (cr6.getEQ()) goto loc_821871BC;
	// addis r3,r31,1
	ctx.r3.s64 = r31.s64 + 65536;
	// addi r3,r3,-23056
	ctx.r3.s64 = ctx.r3.s64 + -23056;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplwi cr6,r11,997
	cr6.compare<uint32_t>(r11.u32, 997, xer);
	// beq cr6,0x821872a0
	if (cr6.getEQ()) goto loc_821872A0;
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x8235d6e0
	sub_8235D6E0(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82187198
	if (!cr6.getEQ()) goto loc_82187198;
	// lis r11,0
	r11.s64 = 0;
	// ori r11,r11,42513
	r11.u64 = r11.u64 | 42513;
	// lbzx r11,r31,r11
	r11.u64 = PPC_LOAD_U8(r31.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82187198
	if (!cr6.getEQ()) goto loc_82187198;
	// lwz r10,3272(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 3272);
	// addi r11,r31,3280
	r11.s64 = r31.s64 + 3280;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x8218718c
	if (!cr6.getEQ()) goto loc_8218718C;
	// addi r11,r31,22880
	r11.s64 = r31.s64 + 22880;
loc_8218718C:
	// stw r11,3272(r31)
	PPC_STORE_U32(r31.u32 + 3272, r11.u32);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,3276(r31)
	PPC_STORE_U32(r31.u32 + 3276, r11.u32);
loc_82187198:
	// lis r11,0
	r11.s64 = 0;
	// ori r11,r11,42508
	r11.u64 = r11.u64 | 42508;
	// lwzx r3,r31,r11
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// stb r25,0(r28)
	PPC_STORE_U8(r28.u32 + 0, r25.u8);
	// bl 0x82182ba0
	sub_82182BA0(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x823ed178
	return;
loc_821871BC:
	// addis r29,r31,1
	r29.s64 = r31.s64 + 65536;
	// addi r29,r29,-23022
	r29.s64 = r29.s64 + -23022;
	// lbz r11,0(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821872a0
	if (cr6.getEQ()) goto loc_821872A0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82183990
	sub_82183990(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821872a0
	if (cr6.getEQ()) goto loc_821872A0;
	// addis r30,r31,1
	r30.s64 = r31.s64 + 65536;
	// lwz r3,1368(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 1368);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stw r25,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r25.u32);
	// addi r30,r30,-23028
	r30.s64 = r30.s64 + -23028;
	// li r5,100
	ctx.r5.s64 = 100;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// stw r25,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r25.u32);
	// bl 0x823bd188
	sub_823BD188(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x8218728c
	if (!cr6.getEQ()) goto loc_8218728C;
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r5,19600
	cr6.compare<uint32_t>(ctx.r5.u32, 19600, xer);
	// bgt cr6,0x821872a0
	if (cr6.getGT()) goto loc_821872A0;
	// lwz r11,3272(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 3272);
	// addi r4,r31,3280
	ctx.r4.s64 = r31.s64 + 3280;
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// bne cr6,0x82187234
	if (!cr6.getEQ()) goto loc_82187234;
	// addi r4,r31,22880
	ctx.r4.s64 = r31.s64 + 22880;
loc_82187234:
	// addis r7,r31,1
	ctx.r7.s64 = r31.s64 + 65536;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r7,r7,-23056
	ctx.r7.s64 = ctx.r7.s64 + -23056;
	// std r25,0(r7)
	PPC_STORE_U64(ctx.r7.u32 + 0, r25.u64);
	// std r25,8(r7)
	PPC_STORE_U64(ctx.r7.u32 + 8, r25.u64);
	// std r25,16(r7)
	PPC_STORE_U64(ctx.r7.u32 + 16, r25.u64);
	// stw r25,24(r7)
	PPC_STORE_U32(ctx.r7.u32 + 24, r25.u32);
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x8235de80
	sub_8235DE80(ctx, base);
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// bne cr6,0x82187284
	if (!cr6.getEQ()) goto loc_82187284;
	// lis r11,0
	r11.s64 = 0;
	// stb r24,0(r28)
	PPC_STORE_U8(r28.u32 + 0, r24.u8);
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// stb r25,0(r29)
	PPC_STORE_U8(r29.u32 + 0, r25.u8);
	// ori r11,r11,42513
	r11.u64 = r11.u64 | 42513;
	// stbx r25,r31,r11
	PPC_STORE_U8(r31.u32 + r11.u32, r25.u8);
	// bl 0x82182ba0
	sub_82182BA0(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x823ed178
	return;
loc_82187284:
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// b 0x82187298
	goto loc_82187298;
loc_8218728C:
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x821872a0
	if (cr6.getEQ()) goto loc_821872A0;
loc_82187298:
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// stw r25,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r25.u32);
loc_821872A0:
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x82182ba0
	sub_82182BA0(ctx, base);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_821872B0"))) PPC_WEAK_FUNC(sub_821872B0);
PPC_FUNC_IMPL(__imp__sub_821872B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed108
	// stfd f30,-152(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -152, f30.u64);
	// stfd f31,-144(r1)
	PPC_STORE_U64(ctx.r1.u32 + -144, f31.u64);
	// stwu r1,-400(r1)
	ea = -400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r19,r11,-31904
	r19.s64 = r11.s64 + -31904;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r11,r19,-48
	r11.s64 = r19.s64 + -48;
	// li r17,0
	r17.s64 = 0;
	// addi r30,r11,11
	r30.s64 = r11.s64 + 11;
	// lfs f31,2780(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2780);
	f31.f64 = double(temp.f32);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// lfs f30,3908(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3908);
	f30.f64 = double(temp.f32);
	// mr r16,r17
	r16.u64 = r17.u64;
	// mr r29,r17
	r29.u64 = r17.u64;
	// mr r27,r17
	r27.u64 = r17.u64;
	// addi r28,r11,-20396
	r28.s64 = r11.s64 + -20396;
	// li r18,1
	r18.s64 = 1;
loc_82187300:
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82183230
	sub_82183230(ctx, base);
	// addi r10,r19,-312
	ctx.r10.s64 = r19.s64 + -312;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
loc_82187310:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187334
	if (cr6.getEQ()) goto loc_82187334;
	// lbz r8,1358(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 1358);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82187334
	if (cr6.getEQ()) goto loc_82187334;
	// lwz r11,1368(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1368);
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// beq cr6,0x821873bc
	if (cr6.getEQ()) goto loc_821873BC;
loc_82187334:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r9,8
	cr6.compare<uint32_t>(ctx.r9.u32, 8, xer);
	// blt cr6,0x82187310
	if (cr6.getLT()) goto loc_82187310;
	// mr r31,r17
	r31.u64 = r17.u64;
loc_82187348:
	// addi r3,r1,136
	ctx.r3.s64 = ctx.r1.s64 + 136;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x821832c0
	sub_821832C0(ctx, base);
	// addi r4,r1,136
	ctx.r4.s64 = ctx.r1.s64 + 136;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r5,1276(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 1276);
	// bl 0x82183170
	sub_82183170(ctx, base);
	// addi r3,r1,136
	ctx.r3.s64 = ctx.r1.s64 + 136;
	// bl 0x82182ba0
	sub_82182BA0(ctx, base);
	// lbz r11,-1(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + -1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821873e0
	if (cr6.getEQ()) goto loc_821873E0;
	// lbz r11,0(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x821873a0
	if (!cr6.getEQ()) goto loc_821873A0;
	// lis r3,0
	ctx.r3.s64 = 0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// ori r3,r3,40352
	ctx.r3.u64 = ctx.r3.u64 | 40352;
	// bl 0x8209dbd8
	sub_8209DBD8(ctx, base);
	// stb r18,0(r30)
	PPC_STORE_U8(r30.u32 + 0, r18.u8);
loc_821873A0:
	// bl 0x8209dbf8
	sub_8209DBF8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821873cc
	if (cr6.getEQ()) goto loc_821873CC;
	// mr r11,r17
	r11.u64 = r17.u64;
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// b 0x82187474
	goto loc_82187474;
loc_821873BC:
	// addi r11,r19,-312
	r11.s64 = r19.s64 + -312;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x82187348
	goto loc_82187348;
loc_821873CC:
	// mr r11,r18
	r11.u64 = r18.u64;
	// stb r17,-1(r30)
	PPC_STORE_U8(r30.u32 + -1, r17.u8);
	// stb r17,0(r30)
	PPC_STORE_U8(r30.u32 + 0, r17.u8);
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// b 0x82187474
	goto loc_82187474;
loc_821873E0:
	// lbz r11,-7(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + -7);
	// addi r3,r30,-7
	ctx.r3.s64 = r30.s64 + -7;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821873fc
	if (cr6.getEQ()) goto loc_821873FC;
	// lis r4,0
	ctx.r4.s64 = 0;
	// ori r4,r4,40347
	ctx.r4.u64 = ctx.r4.u64 | 40347;
	// b 0x82187468
	goto loc_82187468;
loc_821873FC:
	// lbz r11,-5(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + -5);
	// addi r3,r30,-5
	ctx.r3.s64 = r30.s64 + -5;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187418
	if (cr6.getEQ()) goto loc_82187418;
	// lis r4,0
	ctx.r4.s64 = 0;
	// ori r4,r4,40348
	ctx.r4.u64 = ctx.r4.u64 | 40348;
	// b 0x82187468
	goto loc_82187468;
loc_82187418:
	// lbz r11,-9(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + -9);
	// addi r3,r30,-9
	ctx.r3.s64 = r30.s64 + -9;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187434
	if (cr6.getEQ()) goto loc_82187434;
	// lis r4,0
	ctx.r4.s64 = 0;
	// ori r4,r4,40350
	ctx.r4.u64 = ctx.r4.u64 | 40350;
	// b 0x82187468
	goto loc_82187468;
loc_82187434:
	// lbz r11,-11(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + -11);
	// addi r3,r30,-11
	ctx.r3.s64 = r30.s64 + -11;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187450
	if (cr6.getEQ()) goto loc_82187450;
	// lis r4,0
	ctx.r4.s64 = 0;
	// ori r4,r4,40349
	ctx.r4.u64 = ctx.r4.u64 | 40349;
	// b 0x82187468
	goto loc_82187468;
loc_82187450:
	// lbz r11,-3(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + -3);
	// addi r3,r30,-3
	ctx.r3.s64 = r30.s64 + -3;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8218747c
	if (cr6.getEQ()) goto loc_8218747C;
	// lis r4,0
	ctx.r4.s64 = 0;
	// ori r4,r4,40351
	ctx.r4.u64 = ctx.r4.u64 | 40351;
loc_82187468:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x82183a58
	sub_82183A58(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
loc_82187474:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8218749c
	if (!cr6.getEQ()) goto loc_8218749C;
loc_8218747C:
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82182ba0
	sub_82182BA0(ctx, base);
	// addi r27,r27,12
	r27.s64 = r27.s64 + 12;
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r30,r30,12
	r30.s64 = r30.s64 + 12;
	// cmplwi cr6,r27,48
	cr6.compare<uint32_t>(r27.u32, 48, xer);
	// blt cr6,0x82187300
	if (cr6.getLT()) goto loc_82187300;
	// b 0x821874a4
	goto loc_821874A4;
loc_8218749C:
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x82182ba0
	sub_82182BA0(ctx, base);
loc_821874A4:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwz r3,-1760(r19)
	ctx.r3.u64 = PPC_LOAD_U32(r19.u32 + -1760);
	// addi r5,r1,100
	ctx.r5.s64 = ctx.r1.s64 + 100;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240f6cc
	__imp__XNotifyGetNext(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82187768
	if (cr6.getEQ()) goto loc_82187768;
	// lis r11,512
	r11.s64 = 33554432;
	// lis r23,-31991
	r23.s64 = -2096562176;
	// ori r24,r11,1
	r24.u64 = r11.u64 | 1;
	// lis r11,0
	r11.s64 = 0;
	// ori r28,r11,42515
	r28.u64 = r11.u64 | 42515;
	// lis r11,0
	r11.s64 = 0;
	// ori r29,r11,42516
	r29.u64 = r11.u64 | 42516;
	// lis r11,512
	r11.s64 = 33554432;
	// ori r25,r11,3
	r25.u64 = r11.u64 | 3;
	// lis r11,512
	r11.s64 = 33554432;
	// ori r20,r11,2
	r20.u64 = r11.u64 | 2;
	// lis r11,1024
	r11.s64 = 67108864;
	// ori r21,r11,2
	r21.u64 = r11.u64 | 2;
	// lis r11,1024
	r11.s64 = 67108864;
	// ori r22,r11,3
	r22.u64 = r11.u64 | 3;
	// lis r11,21
	r11.s64 = 1376256;
	// ori r26,r11,4336
	r26.u64 = r11.u64 | 4336;
	// lis r11,0
	r11.s64 = 0;
	// ori r27,r11,42514
	r27.u64 = r11.u64 | 42514;
loc_8218750C:
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmplw cr6,r11,r24
	cr6.compare<uint32_t>(r11.u32, r24.u32, xer);
	// bgt cr6,0x82187630
	if (cr6.getGT()) goto loc_82187630;
	// beq cr6,0x82187624
	if (cr6.getEQ()) goto loc_82187624;
	// addi r11,r11,-9
	r11.s64 = r11.s64 + -9;
	// cmplwi cr6,r11,5
	cr6.compare<uint32_t>(r11.u32, 5, xer);
	// bgt cr6,0x8218774c
	if (cr6.getGT()) goto loc_8218774C;
	// lis r12,-32232
	r12.s64 = -2112356352;
	// addi r12,r12,30016
	r12.s64 = r12.s64 + 30016;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_82187618;
	case 1:
		goto loc_82187610;
	case 2:
		goto loc_82187594;
	case 3:
		goto loc_8218774C;
	case 4:
		goto loc_8218774C;
	case 5:
		goto loc_82187558;
	default:
		__builtin_unreachable();
	}
	// lwz r16,30232(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 30232);
	// lwz r16,30224(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 30224);
	// lwz r16,30100(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 30100);
	// lwz r16,30540(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 30540);
	// lwz r16,30540(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 30540);
	// lwz r16,30040(r24)
	r16.u64 = PPC_LOAD_U32(r24.u32 + 30040);
loc_82187558:
	// addi r10,r19,-312
	ctx.r10.s64 = r19.s64 + -312;
	// li r9,8
	ctx.r9.s64 = 8;
loc_82187560:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r8,1368(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 1368);
	// slw r8,r18,r8
	ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (r18.u32 << (ctx.r8.u8 & 0x3F));
	// and r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 & ctx.r7.u64;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82187580
	if (cr6.getEQ()) goto loc_82187580;
	// stbx r18,r11,r28
	PPC_STORE_U8(r11.u32 + r28.u32, r18.u8);
loc_82187580:
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82187560
	if (!cr6.getEQ()) goto loc_82187560;
	// b 0x8218774c
	goto loc_8218774C;
loc_82187594:
	// addi r31,r19,-312
	r31.s64 = r19.s64 + -312;
	// li r30,8
	r30.s64 = 8;
loc_8218759C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lbz r10,1359(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1359);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x821875fc
	if (cr6.getEQ()) goto loc_821875FC;
	// stbx r18,r11,r29
	PPC_STORE_U8(r11.u32 + r29.u32, r18.u8);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lbz r11,1365(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1365);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821875ec
	if (cr6.getEQ()) goto loc_821875EC;
	// bl 0x82184800
	sub_82184800(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821875fc
	if (cr6.getEQ()) goto loc_821875FC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stb r17,1365(r11)
	PPC_STORE_U8(r11.u32 + 1365, r17.u8);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stb r18,1361(r11)
	PPC_STORE_U8(r11.u32 + 1361, r18.u8);
	// mr r11,r18
	r11.u64 = r18.u64;
	// stb r11,-46(r19)
	PPC_STORE_U8(r19.u32 + -46, r11.u8);
	// b 0x821875fc
	goto loc_821875FC;
loc_821875EC:
	// lbz r11,1361(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1361);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821875fc
	if (cr6.getEQ()) goto loc_821875FC;
	// stb r18,1364(r3)
	PPC_STORE_U8(ctx.r3.u32 + 1364, r18.u8);
loc_821875FC:
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8218759c
	if (!cr6.getEQ()) goto loc_8218759C;
	// b 0x8218774c
	goto loc_8218774C;
loc_82187610:
	// li r16,15
	r16.s64 = 15;
	// b 0x8218774c
	goto loc_8218774C;
loc_82187618:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,-31884(r23)
	PPC_STORE_U32(r23.u32 + -31884, r11.u32);
	// b 0x8218774c
	goto loc_8218774C;
loc_82187624:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,32(r19)
	PPC_STORE_U32(r19.u32 + 32, r11.u32);
	// b 0x8218774c
	goto loc_8218774C;
loc_82187630:
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bgt cr6,0x821876c0
	if (cr6.getGT()) goto loc_821876C0;
	// beq cr6,0x821876b4
	if (cr6.getEQ()) goto loc_821876B4;
	// cmplw cr6,r11,r20
	cr6.compare<uint32_t>(r11.u32, r20.u32, xer);
	// bne cr6,0x8218774c
	if (!cr6.getEQ()) goto loc_8218774C;
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x823bd2e8
	sub_823BD2E8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x8218774c
	if (!cr6.getEQ()) goto loc_8218774C;
	// mr r31,r18
	r31.u64 = r18.u64;
	// bl 0x8215f9e0
	sub_8215F9E0(ctx, base);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82187690
	if (cr6.getEQ()) goto loc_82187690;
	// bl 0x8215f9e0
	sub_8215F9E0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r3,r1,180
	ctx.r3.s64 = ctx.r1.s64 + 180;
	// addi r4,r11,17
	ctx.r4.s64 = r11.s64 + 17;
	// bl 0x823bc0a8
	sub_823BC0A8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187690
	if (cr6.getEQ()) goto loc_82187690;
	// mr r31,r17
	r31.u64 = r17.u64;
loc_82187690:
	// clrlwi r11,r31,24
	r11.u64 = r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8218774c
	if (cr6.getEQ()) goto loc_8218774C;
	// addi r5,r1,188
	ctx.r5.s64 = ctx.r1.s64 + 188;
	// ld r6,160(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 160);
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// addi r3,r1,180
	ctx.r3.s64 = ctx.r1.s64 + 180;
	// bl 0x8215fb38
	sub_8215FB38(ctx, base);
	// b 0x8218774c
	goto loc_8218774C;
loc_821876B4:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r11,36(r19)
	PPC_STORE_U32(r19.u32 + 36, r11.u32);
	// b 0x8218774c
	goto loc_8218774C;
loc_821876C0:
	// cmplw cr6,r11,r21
	cr6.compare<uint32_t>(r11.u32, r21.u32, xer);
	// blt cr6,0x8218774c
	if (cr6.getLT()) goto loc_8218774C;
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// bgt cr6,0x8218774c
	if (cr6.getGT()) goto loc_8218774C;
	// lwz r7,32(r19)
	ctx.r7.u64 = PPC_LOAD_U32(r19.u32 + 32);
	// addi r8,r19,-312
	ctx.r8.s64 = r19.s64 + -312;
	// lwz r6,36(r19)
	ctx.r6.u64 = PPC_LOAD_U32(r19.u32 + 36);
loc_821876DC:
	// lwz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// lbz r11,1358(r9)
	r11.u64 = PPC_LOAD_U8(ctx.r9.u32 + 1358);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187738
	if (cr6.getEQ()) goto loc_82187738;
	// lwz r11,1368(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 1368);
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bge cr6,0x82187728
	if (!cr6.getLT()) goto loc_82187728;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r19
	r11.u64 = PPC_LOAD_U32(r11.u32 + r19.u32);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x82187728
	if (!cr6.getEQ()) goto loc_82187728;
	// cmpwi cr6,r6,1
	cr6.compare<int32_t>(ctx.r6.s32, 1, xer);
	// bne cr6,0x82187720
	if (!cr6.getEQ()) goto loc_82187720;
	// cmpw cr6,r7,r26
	cr6.compare<int32_t>(ctx.r7.s32, r26.s32, xer);
	// mr r11,r18
	r11.u64 = r18.u64;
	// beq cr6,0x82187724
	if (cr6.getEQ()) goto loc_82187724;
loc_82187720:
	// mr r11,r17
	r11.u64 = r17.u64;
loc_82187724:
	// clrlwi r10,r11,24
	ctx.r10.u64 = r11.u32 & 0xFF;
loc_82187728:
	// clrlwi r11,r10,24
	r11.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187738
	if (cr6.getEQ()) goto loc_82187738;
	// stbx r18,r9,r27
	PPC_STORE_U8(ctx.r9.u32 + r27.u32, r18.u8);
loc_82187738:
	// addi r11,r19,-312
	r11.s64 = r19.s64 + -312;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// addi r11,r11,32
	r11.s64 = r11.s64 + 32;
	// cmpw cr6,r8,r11
	cr6.compare<int32_t>(ctx.r8.s32, r11.s32, xer);
	// blt cr6,0x821876dc
	if (cr6.getLT()) goto loc_821876DC;
loc_8218774C:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// lwz r3,-1760(r19)
	ctx.r3.u64 = PPC_LOAD_U32(r19.u32 + -1760);
	// addi r5,r1,100
	ctx.r5.s64 = ctx.r1.s64 + 100;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8240f6cc
	__imp__XNotifyGetNext(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x8218750c
	if (!cr6.getEQ()) goto loc_8218750C;
loc_82187768:
	// addi r31,r19,-312
	r31.s64 = r19.s64 + -312;
	// li r30,8
	r30.s64 = 8;
loc_82187770:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lbz r11,1358(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1358);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187784
	if (cr6.getEQ()) goto loc_82187784;
	// bl 0x82185c18
	sub_82185C18(ctx, base);
loc_82187784:
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x82187770
	if (!cr6.getEQ()) goto loc_82187770;
	// lis r10,-32019
	ctx.r10.s64 = -2098397184;
	// lbz r11,27188(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 27188);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821877b0
	if (cr6.getEQ()) goto loc_821877B0;
	// mr r11,r17
	r11.u64 = r17.u64;
	// li r16,15
	r16.s64 = 15;
	// stb r11,27188(r10)
	PPC_STORE_U8(ctx.r10.u32 + 27188, r11.u8);
loc_821877B0:
	// mr r30,r17
	r30.u64 = r17.u64;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x82187be4
	if (cr6.getEQ()) goto loc_82187BE4;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r27,r19
	r27.u64 = r19.u64;
	// addi r25,r11,14748
	r25.s64 = r11.s64 + 14748;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r26,-2
	r26.s64 = -2;
	// addi r24,r11,14756
	r24.s64 = r11.s64 + 14756;
loc_821877D4:
	// cmplwi cr6,r30,4
	cr6.compare<uint32_t>(r30.u32, 4, xer);
	// bge cr6,0x82187be4
	if (!cr6.getLT()) goto loc_82187BE4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r31,r26
	r31.u64 = r26.u64;
	// bl 0x8235da08
	sub_8235DA08(ctx, base);
	// mr r28,r17
	r28.u64 = r17.u64;
	// mr r29,r17
	r29.u64 = r17.u64;
	// stw r3,0(r27)
	PPC_STORE_U32(r27.u32 + 0, ctx.r3.u32);
	// cmplwi cr6,r3,1
	cr6.compare<uint32_t>(ctx.r3.u32, 1, xer);
	// blt cr6,0x821879e4
	if (cr6.getLT()) goto loc_821879E4;
	// beq cr6,0x8218790c
	if (cr6.getEQ()) goto loc_8218790C;
	// cmplwi cr6,r3,3
	cr6.compare<uint32_t>(ctx.r3.u32, 3, xer);
	// bge cr6,0x82187a54
	if (!cr6.getLT()) goto loc_82187A54;
	// mr r11,r18
	r11.u64 = r18.u64;
	// addi r10,r19,-312
	ctx.r10.s64 = r19.s64 + -312;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
	// stw r11,36(r19)
	PPC_STORE_U32(r19.u32 + 36, r11.u32);
loc_82187818:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8218783c
	if (cr6.getEQ()) goto loc_8218783C;
	// lbz r8,1358(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 1358);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x8218783c
	if (cr6.getEQ()) goto loc_8218783C;
	// lwz r11,1368(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1368);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// beq cr6,0x82187850
	if (cr6.getEQ()) goto loc_82187850;
loc_8218783C:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r9,8
	cr6.compare<uint32_t>(ctx.r9.u32, 8, xer);
	// blt cr6,0x82187818
	if (cr6.getLT()) goto loc_82187818;
	// b 0x82187880
	goto loc_82187880;
loc_82187850:
	// addi r11,r19,-312
	r11.s64 = r19.s64 + -312;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187880
	if (cr6.getEQ()) goto loc_82187880;
	// lbz r11,1359(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 1359);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187880
	if (cr6.getEQ()) goto loc_82187880;
	// slw r11,r18,r30
	r11.u64 = r30.u8 & 0x20 ? 0 : (r18.u32 << (r30.u8 & 0x3F));
	// and r11,r11,r16
	r11.u64 = r11.u64 & r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821878a0
	if (cr6.getEQ()) goto loc_821878A0;
loc_82187880:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82185298
	sub_82185298(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821878a0
	if (cr6.getEQ()) goto loc_821878A0;
	// mr r28,r18
	r28.u64 = r18.u64;
	// mr r29,r18
	r29.u64 = r18.u64;
	// mr r31,r30
	r31.u64 = r30.u64;
loc_821878A0:
	// addi r10,r19,-312
	ctx.r10.s64 = r19.s64 + -312;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
loc_821878A8:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821878cc
	if (cr6.getEQ()) goto loc_821878CC;
	// lbz r8,1358(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 1358);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x821878cc
	if (cr6.getEQ()) goto loc_821878CC;
	// lwz r11,1368(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1368);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// beq cr6,0x821878e0
	if (cr6.getEQ()) goto loc_821878E0;
loc_821878CC:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r9,8
	cr6.compare<uint32_t>(ctx.r9.u32, 8, xer);
	// blt cr6,0x821878a8
	if (cr6.getLT()) goto loc_821878A8;
	// b 0x82187a54
	goto loc_82187A54;
loc_821878E0:
	// addi r11,r19,-312
	r11.s64 = r19.s64 + -312;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82187a54
	if (cr6.getEQ()) goto loc_82187A54;
	// slw r11,r18,r30
	r11.u64 = r30.u8 & 0x20 ? 0 : (r18.u32 << (r30.u8 & 0x3F));
	// and r11,r11,r16
	r11.u64 = r11.u64 & r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187a54
	if (cr6.getEQ()) goto loc_82187A54;
	// bl 0x82183b00
	sub_82183B00(ctx, base);
	// b 0x82187a54
	goto loc_82187A54;
loc_8218790C:
	// addi r11,r19,-312
	r11.s64 = r19.s64 + -312;
	// mr r31,r30
	r31.u64 = r30.u64;
	// mr r29,r18
	r29.u64 = r18.u64;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
loc_8218791C:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82187940
	if (cr6.getEQ()) goto loc_82187940;
	// lbz r8,1358(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1358);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82187940
	if (cr6.getEQ()) goto loc_82187940;
	// lwz r10,1368(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1368);
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// beq cr6,0x82187954
	if (cr6.getEQ()) goto loc_82187954;
loc_82187940:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r9,8
	cr6.compare<uint32_t>(ctx.r9.u32, 8, xer);
	// blt cr6,0x8218791c
	if (cr6.getLT()) goto loc_8218791C;
	// b 0x82187984
	goto loc_82187984;
loc_82187954:
	// addi r11,r19,-312
	r11.s64 = r19.s64 + -312;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187984
	if (cr6.getEQ()) goto loc_82187984;
	// lbz r11,1359(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 1359);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187984
	if (cr6.getEQ()) goto loc_82187984;
	// slw r11,r18,r30
	r11.u64 = r30.u8 & 0x20 ? 0 : (r18.u32 << (r30.u8 & 0x3F));
	// and r11,r11,r16
	r11.u64 = r11.u64 & r16.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187a54
	if (cr6.getEQ()) goto loc_82187A54;
loc_82187984:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82185298
	sub_82185298(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187a54
	if (cr6.getEQ()) goto loc_82187A54;
	// addi r11,r19,-312
	r11.s64 = r19.s64 + -312;
	// mr r28,r18
	r28.u64 = r18.u64;
	// mr r29,r18
	r29.u64 = r18.u64;
	// mr r31,r30
	r31.u64 = r30.u64;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
loc_821879AC:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x821879d0
	if (cr6.getEQ()) goto loc_821879D0;
	// lbz r8,1358(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1358);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x821879d0
	if (cr6.getEQ()) goto loc_821879D0;
	// lwz r10,1368(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1368);
	// cmplw cr6,r10,r30
	cr6.compare<uint32_t>(ctx.r10.u32, r30.u32, xer);
	// beq cr6,0x82187a54
	if (cr6.getEQ()) goto loc_82187A54;
loc_821879D0:
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmplwi cr6,r9,32
	cr6.compare<uint32_t>(ctx.r9.u32, 32, xer);
	// blt cr6,0x821879ac
	if (cr6.getLT()) goto loc_821879AC;
	// b 0x82187a54
	goto loc_82187A54;
loc_821879E4:
	// addi r10,r19,-312
	ctx.r10.s64 = r19.s64 + -312;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
loc_821879EC:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187a10
	if (cr6.getEQ()) goto loc_82187A10;
	// lbz r8,1358(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 1358);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82187a10
	if (cr6.getEQ()) goto loc_82187A10;
	// lwz r11,1368(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1368);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// beq cr6,0x82187a24
	if (cr6.getEQ()) goto loc_82187A24;
loc_82187A10:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r9,8
	cr6.compare<uint32_t>(ctx.r9.u32, 8, xer);
	// blt cr6,0x821879ec
	if (cr6.getLT()) goto loc_821879EC;
	// b 0x82187a54
	goto loc_82187A54;
loc_82187A24:
	// addi r11,r19,-312
	r11.s64 = r19.s64 + -312;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82187a54
	if (cr6.getEQ()) goto loc_82187A54;
	// lbz r11,1359(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 1359);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187a54
	if (cr6.getEQ()) goto loc_82187A54;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r31,1368(r3)
	r31.u64 = PPC_LOAD_U32(ctx.r3.u32 + 1368);
	// mr r29,r18
	r29.u64 = r18.u64;
	// bl 0x82184c88
	sub_82184C88(ctx, base);
loc_82187A54:
	// clrlwi r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187a80
	if (cr6.getEQ()) goto loc_82187A80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82158600
	sub_82158600(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187a80
	if (cr6.getEQ()) goto loc_82187A80;
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r18,864(r11)
	PPC_STORE_U8(r11.u32 + 864, r18.u8);
	// bl 0x820ea488
	sub_820EA488(ctx, base);
loc_82187A80:
	// clrlwi r11,r28,24
	r11.u64 = r28.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187bd8
	if (cr6.getEQ()) goto loc_82187BD8;
	// addi r10,r19,-312
	ctx.r10.s64 = r19.s64 + -312;
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
loc_82187A94:
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187ab8
	if (cr6.getEQ()) goto loc_82187AB8;
	// lbz r8,1358(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 1358);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82187ab8
	if (cr6.getEQ()) goto loc_82187AB8;
	// lwz r11,1368(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1368);
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// beq cr6,0x82187ad0
	if (cr6.getEQ()) goto loc_82187AD0;
loc_82187AB8:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r9,8
	cr6.compare<uint32_t>(ctx.r9.u32, 8, xer);
	// blt cr6,0x82187a94
	if (cr6.getLT()) goto loc_82187A94;
	// mr r31,r17
	r31.u64 = r17.u64;
	// b 0x82187b40
	goto loc_82187B40;
loc_82187AD0:
	// addi r11,r19,-312
	r11.s64 = r19.s64 + -312;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82187b40
	if (cr6.getEQ()) goto loc_82187B40;
	// bl 0x8215fc88
	sub_8215FC88(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// bne cr6,0x82187b40
	if (!cr6.getEQ()) goto loc_82187B40;
	// bl 0x82151c68
	sub_82151C68(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82187b40
	if (cr6.getEQ()) goto loc_82187B40;
	// bl 0x8215fc88
	sub_8215FC88(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// bne cr6,0x82187b18
	if (!cr6.getEQ()) goto loc_82187B18;
	// bl 0x8217f200
	sub_8217F200(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187b3c
	if (cr6.getEQ()) goto loc_82187B3C;
loc_82187B18:
	// bl 0x82151c68
	sub_82151C68(ctx, base);
	// addi r3,r3,728
	ctx.r3.s64 = ctx.r3.s64 + 728;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82187b40
	if (cr6.getEQ()) goto loc_82187B40;
loc_82187B3C:
	// stb r18,1356(r31)
	PPC_STORE_U8(r31.u32 + 1356, r18.u8);
loc_82187B40:
	// li r6,2
	ctx.r6.s64 = 2;
	// stw r24,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r24.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8216c178
	sub_8216C178(ctx, base);
loc_82187B58:
	// lwz r11,124(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82187b74
	if (cr6.getEQ()) goto loc_82187B74;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
	// bne cr6,0x82187b78
	if (!cr6.getEQ()) goto loc_82187B78;
loc_82187B74:
	// mr r10,r18
	ctx.r10.u64 = r18.u64;
loc_82187B78:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82187bd4
	if (!cr6.getEQ()) goto loc_82187BD4;
	// lbz r10,864(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 864);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82187bc8
	if (!cr6.getEQ()) goto loc_82187BC8;
	// lwz r10,820(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 820);
	// cmpw cr6,r10,r30
	cr6.compare<int32_t>(ctx.r10.s32, r30.s32, xer);
	// bne cr6,0x82187bb4
	if (!cr6.getEQ()) goto loc_82187BB4;
	// ld r9,784(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 784);
	// ld r8,1288(r31)
	ctx.r8.u64 = PPC_LOAD_U64(r31.u32 + 1288);
	// cmpld cr6,r9,r8
	cr6.compare<uint64_t>(ctx.r9.u64, ctx.r8.u64, xer);
	// bne cr6,0x82187bc4
	if (!cr6.getEQ()) goto loc_82187BC4;
	// cmpw cr6,r10,r30
	cr6.compare<int32_t>(ctx.r10.s32, r30.s32, xer);
	// beq cr6,0x82187bc8
	if (cr6.getEQ()) goto loc_82187BC8;
loc_82187BB4:
	// ld r10,784(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 784);
	// ld r9,1288(r31)
	ctx.r9.u64 = PPC_LOAD_U64(r31.u32 + 1288);
	// cmpld cr6,r10,r9
	cr6.compare<uint64_t>(ctx.r10.u64, ctx.r9.u64, xer);
	// bne cr6,0x82187bc8
	if (!cr6.getEQ()) goto loc_82187BC8;
loc_82187BC4:
	// stb r18,864(r11)
	PPC_STORE_U8(r11.u32 + 864, r18.u8);
loc_82187BC8:
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8216c2a8
	sub_8216C2A8(ctx, base);
	// b 0x82187b58
	goto loc_82187B58;
loc_82187BD4:
	// stw r25,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r25.u32);
loc_82187BD8:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r27,r27,4
	r27.s64 = r27.s64 + 4;
	// b 0x821877d4
	goto loc_821877D4;
loc_82187BE4:
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lbz r10,-31888(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + -31888);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82187bfc
	if (cr6.getEQ()) goto loc_82187BFC;
	// mr r10,r17
	ctx.r10.u64 = r17.u64;
	// stb r10,-31888(r11)
	PPC_STORE_U8(r11.u32 + -31888, ctx.r10.u8);
loc_82187BFC:
	// bl 0x82183600
	sub_82183600(ctx, base);
	// addi r1,r1,400
	ctx.r1.s64 = ctx.r1.s64 + 400;
	// lfd f30,-152(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -152);
	// lfd f31,-144(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -144);
	// b 0x823ed158
	return;
}

__attribute__((alias("__imp__sub_82187C10"))) PPC_WEAK_FUNC(sub_82187C10);
PPC_FUNC_IMPL(__imp__sub_82187C10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// li r26,0
	r26.s64 = 0;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// stb r26,384(r31)
	PPC_STORE_U8(r31.u32 + 384, r26.u8);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8235dec8
	sub_8235DEC8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
	// bne cr6,0x82187c5c
	if (!cr6.getEQ()) goto loc_82187C5C;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
loc_82187C5C:
	// addi r29,r31,20
	r29.s64 = r31.s64 + 20;
	// mr r9,r26
	ctx.r9.u64 = r26.u64;
	// li r10,7
	ctx.r10.s64 = 7;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_82187C70:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82187c70
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82187C70;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r31,72
	r30.s64 = r31.s64 + 72;
	// li r5,308
	ctx.r5.s64 = 308;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,128
	ctx.r5.s64 = 128;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r31,80
	ctx.r3.s64 = r31.s64 + 80;
	// bl 0x821834e0
	sub_821834E0(ctx, base);
	// li r5,42
	ctx.r5.s64 = 42;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r31,336
	ctx.r3.s64 = r31.s64 + 336;
	// bl 0x82183490
	sub_82183490(ctx, base);
	// lwz r10,68(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// li r28,1
	r28.s64 = 1;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r11,-32019
	r11.s64 = -2098397184;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// addi r4,r11,27192
	ctx.r4.s64 = r11.s64 + 27192;
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r10,72(r31)
	PPC_STORE_U32(r31.u32 + 72, ctx.r10.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r28,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r28.u32);
	// li r6,50
	ctx.r6.s64 = 50;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x8235d6a0
	sub_8235D6A0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82187d04
	if (cr6.getEQ()) goto loc_82187D04;
	// cmplwi cr6,r30,997
	cr6.compare<uint32_t>(r30.u32, 997, xer);
	// mr r11,r26
	r11.u64 = r26.u64;
	// bne cr6,0x82187d08
	if (!cr6.getEQ()) goto loc_82187D08;
loc_82187D04:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82187D08:
	// clrlwi r29,r11,24
	r29.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x82187d28
	if (!cr6.getEQ()) goto loc_82187D28;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// cmplwi cr6,r30,5
	cr6.compare<uint32_t>(r30.u32, 5, xer);
	// bne cr6,0x82187d28
	if (!cr6.getEQ()) goto loc_82187D28;
	// stb r28,384(r31)
	PPC_STORE_U8(r31.u32 + 384, r28.u8);
loc_82187D28:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r26,388(r31)
	PPC_STORE_U32(r31.u32 + 388, r26.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_82187D38"))) PPC_WEAK_FUNC(sub_82187D38);
PPC_FUNC_IMPL(__imp__sub_82187D38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8235dec8
	sub_8235DEC8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
	// beq cr6,0x82187e10
	if (cr6.getEQ()) goto loc_82187E10;
	// addi r29,r31,20
	r29.s64 = r31.s64 + 20;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r10,7
	ctx.r10.s64 = 7;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_82187D84:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82187d84
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82187D84;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// addi r30,r31,72
	r30.s64 = r31.s64 + 72;
	// li r5,308
	ctx.r5.s64 = 308;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,128
	ctx.r5.s64 = 128;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r31,80
	ctx.r3.s64 = r31.s64 + 80;
	// bl 0x821834e0
	sub_821834E0(ctx, base);
	// li r5,42
	ctx.r5.s64 = 42;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r31,336
	ctx.r3.s64 = r31.s64 + 336;
	// bl 0x82183490
	sub_82183490(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r10,68(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// lis r11,-32019
	r11.s64 = -2098397184;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r4,r11,27192
	ctx.r4.s64 = r11.s64 + 27192;
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r5,76(r31)
	PPC_STORE_U32(r31.u32 + 76, ctx.r5.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,3
	ctx.r6.s64 = 3;
	// stw r10,72(r31)
	PPC_STORE_U32(r31.u32 + 72, ctx.r10.u32);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x8235d6a0
	sub_8235D6A0(ctx, base);
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// beq cr6,0x82187e1c
	if (cr6.getEQ()) goto loc_82187E1C;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x8235d388
	sub_8235D388(ctx, base);
loc_82187E10:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_82187E1C:
	// li r11,0
	r11.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,388(r31)
	PPC_STORE_U32(r31.u32 + 388, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_82187E30"))) PPC_WEAK_FUNC(sub_82187E30);
PPC_FUNC_IMPL(__imp__sub_82187E30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// li r27,997
	r27.s64 = 997;
	// lwz r11,388(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 388);
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x82187f20
	if (cr6.getLT()) goto loc_82187F20;
	// bne cr6,0x8218801c
	if (!cr6.getEQ()) goto loc_8218801C;
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r31,48
	ctx.r4.s64 = r31.s64 + 48;
	// bl 0x8235df70
	sub_8235DF70(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x82187f00
	if (cr6.getEQ()) goto loc_82187F00;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x82187ec0
	if (cr6.getEQ()) goto loc_82187EC0;
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// lis r11,-32019
	r11.s64 = -2098397184;
	// addi r30,r31,20
	r30.s64 = r31.s64 + 20;
	// addi r3,r11,27192
	ctx.r3.s64 = r11.s64 + 27192;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8235d678
	sub_8235D678(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8235d6e0
	sub_8235D6E0(ctx, base);
	// b 0x82188010
	goto loc_82188010;
loc_82187EC0:
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// lis r11,-32019
	r11.s64 = -2098397184;
	// addi r30,r31,20
	r30.s64 = r31.s64 + 20;
	// addi r3,r11,27192
	ctx.r3.s64 = r11.s64 + 27192;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8235d678
	sub_8235D678(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8235d6e0
	sub_8235D6E0(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed184
	return;
loc_82187F00:
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// beq cr6,0x8218801c
	if (cr6.getEQ()) goto loc_8218801C;
	// cmplwi cr6,r3,996
	cr6.compare<uint32_t>(ctx.r3.u32, 996, xer);
	// beq cr6,0x8218801c
	if (cr6.getEQ()) goto loc_8218801C;
	// li r27,1627
	r27.s64 = 1627;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed184
	return;
loc_82187F20:
	// addi r28,r31,20
	r28.s64 = r31.s64 + 20;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8235d6e0
	sub_8235D6E0(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82188000
	if (!cr6.getEQ()) goto loc_82188000;
	// lis r11,-32019
	r11.s64 = -2098397184;
	// addi r7,r31,336
	ctx.r7.s64 = r31.s64 + 336;
	// addi r29,r11,27192
	r29.s64 = r11.s64 + 27192;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r11,-20196
	ctx.r5.s64 = r11.s64 + -20196;
	// li r4,32
	ctx.r4.s64 = 32;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x823eea88
	sub_823EEA88(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// lis r8,24576
	ctx.r8.s64 = 1610612736;
	// stb r30,127(r1)
	PPC_STORE_U8(ctx.r1.u32 + 127, r30.u8);
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lis r4,-32768
	ctx.r4.s64 = -2147483648;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8235d008
	sub_8235D008(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq cr6,0x82187fe0
	if (cr6.getEQ()) goto loc_82187FE0;
	// addi r7,r31,48
	ctx.r7.s64 = r31.s64 + 48;
	// addi r6,r31,380
	ctx.r6.s64 = r31.s64 + 380;
	// stw r30,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, r30.u32);
	// stw r30,4(r7)
	PPC_STORE_U32(ctx.r7.u32 + 4, r30.u32);
	// stw r30,8(r7)
	PPC_STORE_U32(ctx.r7.u32 + 8, r30.u32);
	// stw r30,12(r7)
	PPC_STORE_U32(ctx.r7.u32 + 12, r30.u32);
	// stw r30,16(r7)
	PPC_STORE_U32(ctx.r7.u32 + 16, r30.u32);
	// lwz r5,8(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x8235d200
	sub_8235D200(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r11,388(r31)
	PPC_STORE_U32(r31.u32 + 388, r11.u32);
	// bne cr6,0x8218801c
	if (!cr6.getEQ()) goto loc_8218801C;
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// cmplwi cr6,r3,996
	cr6.compare<uint32_t>(ctx.r3.u32, 996, xer);
	// beq cr6,0x8218801c
	if (cr6.getEQ()) goto loc_8218801C;
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// beq cr6,0x8218801c
	if (cr6.getEQ()) goto loc_8218801C;
loc_82187FE0:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8235d678
	sub_8235D678(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8235d6e0
	sub_8235D6E0(ctx, base);
	// b 0x82188010
	goto loc_82188010;
loc_82188000:
	// cmplwi cr6,r3,996
	cr6.compare<uint32_t>(ctx.r3.u32, 996, xer);
	// beq cr6,0x8218801c
	if (cr6.getEQ()) goto loc_8218801C;
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// beq cr6,0x8218801c
	if (cr6.getEQ()) goto loc_8218801C;
loc_82188010:
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// li r27,1627
	r27.s64 = 1627;
loc_8218801C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_82188028"))) PPC_WEAK_FUNC(sub_82188028);
PPC_FUNC_IMPL(__imp__sub_82188028) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32019
	r11.s64 = -2098397184;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,3
	ctx.r7.s64 = 3;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r3,27200(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 27200);
	// lis r4,-32768
	ctx.r4.s64 = -2147483648;
	// bl 0x8235d008
	sub_8235D008(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,-1
	cr6.compare<int32_t>(r30.s32, -1, xer);
	// beq cr6,0x8218809c
	if (cr6.getEQ()) goto loc_8218809C;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8235d468
	sub_8235D468(ctx, base);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// addi r31,r11,-31572
	r31.s64 = r11.s64 + -31572;
	// stw r3,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r3.u32);
	// bl 0x8209d088
	sub_8209D088(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// stw r4,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r4.u32);
	// bne cr6,0x821880a4
	if (!cr6.getEQ()) goto loc_821880A4;
	// bl 0x8235d388
	sub_8235D388(ctx, base);
loc_8218809C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x821880ec
	goto loc_821880EC;
loc_821880A4:
	// li r11,0
	r11.s64 = 0;
	// lwz r5,8(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// bl 0x8235d200
	sub_8235D200(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bne cr6,0x821880dc
	if (!cr6.getEQ()) goto loc_821880DC;
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x8209d150
	sub_8209D150(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x821880ec
	goto loc_821880EC;
loc_821880DC:
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r11,4(r31)
	PPC_STORE_U8(r31.u32 + 4, r11.u8);
loc_821880EC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82188108"))) PPC_WEAK_FUNC(sub_82188108);
PPC_FUNC_IMPL(__imp__sub_82188108) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r28,r31,72
	r28.s64 = r31.s64 + 72;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// li r5,308
	ctx.r5.s64 = 308;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,128
	ctx.r5.s64 = 128;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r31,80
	ctx.r3.s64 = r31.s64 + 80;
	// bl 0x821834e0
	sub_821834E0(ctx, base);
	// li r5,42
	ctx.r5.s64 = 42;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r31,336
	ctx.r3.s64 = r31.s64 + 336;
	// bl 0x82183490
	sub_82183490(ctx, base);
	// lwz r11,68(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,72(r31)
	PPC_STORE_U32(r31.u32 + 72, r11.u32);
	// li r11,1
	r11.s64 = 1;
	// stw r11,76(r31)
	PPC_STORE_U32(r31.u32 + 76, r11.u32);
	// bl 0x8235dec8
	sub_8235DEC8(ctx, base);
	// addi r5,r31,20
	ctx.r5.s64 = r31.s64 + 20;
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r10,7
	ctx.r10.s64 = 7;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_82188190:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82188190
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82188190;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// bl 0x8235d670
	sub_8235D670(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x821881c4
	if (cr6.getEQ()) goto loc_821881C4;
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// li r11,0
	r11.s64 = 0;
	// bne cr6,0x821881c8
	if (!cr6.getEQ()) goto loc_821881C8;
loc_821881C4:
	// li r11,1
	r11.s64 = 1;
loc_821881C8:
	// clrlwi r30,r11,24
	r30.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x821881e4
	if (!cr6.getEQ()) goto loc_821881E4;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
loc_821881E4:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_821881F0"))) PPC_WEAK_FUNC(sub_821881F0);
PPC_FUNC_IMPL(__imp__sub_821881F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r30,r29,20
	r30.s64 = r29.s64 + 20;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8235d6e0
	sub_8235D6E0(ctx, base);
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// rlwinm r31,r11,27,31,31
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// beq cr6,0x82188244
	if (cr6.getEQ()) goto loc_82188244;
	// cmplwi cr6,r3,996
	cr6.compare<uint32_t>(ctx.r3.u32, 996, xer);
	// beq cr6,0x82188244
	if (cr6.getEQ()) goto loc_82188244;
	// clrlwi r11,r31,24
	r11.u64 = r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82188244
	if (!cr6.getEQ()) goto loc_82188244;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8235de98
	sub_8235DE98(ctx, base);
	// li r31,1
	r31.s64 = 1;
loc_82188244:
	// clrlwi r11,r31,24
	r11.u64 = r31.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82188260
	if (cr6.getEQ()) goto loc_82188260;
	// lwz r3,12(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 12);
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,12(r29)
	PPC_STORE_U32(r29.u32 + 12, r11.u32);
loc_82188260:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82188270"))) PPC_WEAK_FUNC(sub_82188270);
PPC_FUNC_IMPL(__imp__sub_82188270) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed12c
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r28,0
	r28.s64 = 0;
	// lis r10,-32019
	ctx.r10.s64 = -2098397184;
	// mr r26,r28
	r26.u64 = r28.u64;
	// li r27,997
	r27.s64 = 997;
	// lwz r11,388(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 388);
	// addi r25,r10,27192
	r25.s64 = ctx.r10.s64 + 27192;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x8218840c
	if (cr6.getLT()) goto loc_8218840C;
	// beq cr6,0x821882ec
	if (cr6.getEQ()) goto loc_821882EC;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bge cr6,0x82188510
	if (!cr6.getLT()) goto loc_82188510;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,20
	ctx.r3.s64 = r31.s64 + 20;
	// bl 0x8235d6e0
	sub_8235D6E0(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x821882d0
	if (!cr6.getEQ()) goto loc_821882D0;
	// li r26,1
	r26.s64 = 1;
	// mr r27,r28
	r27.u64 = r28.u64;
	// b 0x82188510
	goto loc_82188510;
loc_821882D0:
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// beq cr6,0x82188510
	if (cr6.getEQ()) goto loc_82188510;
	// cmplwi cr6,r3,996
	cr6.compare<uint32_t>(ctx.r3.u32, 996, xer);
	// beq cr6,0x82188510
	if (cr6.getEQ()) goto loc_82188510;
loc_821882E0:
	// li r26,1
	r26.s64 = 1;
loc_821882E4:
	// li r27,1627
	r27.s64 = 1627;
	// b 0x82188510
	goto loc_82188510;
loc_821882EC:
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// addi r4,r31,48
	ctx.r4.s64 = r31.s64 + 48;
	// bl 0x8235df70
	sub_8235DF70(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x821883f4
	if (cr6.getEQ()) goto loc_821883F4;
	// addi r30,r31,20
	r30.s64 = r31.s64 + 20;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8235d6e0
	sub_8235D6E0(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x821882e4
	if (!cr6.getEQ()) goto loc_821882E4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x821882e4
	if (!cr6.getEQ()) goto loc_821882E4;
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r27,997
	r27.s64 = 997;
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8235dec8
	sub_8235DEC8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r3.u32);
	// bne cr6,0x82188374
	if (!cr6.getEQ()) goto loc_82188374;
	// mr r11,r28
	r11.u64 = r28.u64;
	// b 0x821883d4
	goto loc_821883D4;
loc_82188374:
	// mr r11,r30
	r11.u64 = r30.u64;
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
	// li r10,7
	ctx.r10.s64 = 7;
	// mtctr r10
	ctr.u64 = ctx.r10.u64;
loc_82188384:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x82188384
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82188384;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,-31572
	r11.s64 = r11.s64 + -31572;
	// addi r4,r31,72
	ctx.r4.s64 = r31.s64 + 72;
	// stw r10,32(r31)
	PPC_STORE_U32(r31.u32 + 32, ctx.r10.u32);
	// lwz r6,8(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// bl 0x8235d680
	sub_8235D680(ctx, base);
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// beq cr6,0x821883d0
	if (cr6.getEQ()) goto loc_821883D0;
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// mr r11,r28
	r11.u64 = r28.u64;
	// b 0x821883d4
	goto loc_821883D4;
loc_821883D0:
	// li r11,1
	r11.s64 = 1;
loc_821883D4:
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x821883e8
	if (!cr6.getEQ()) goto loc_821883E8;
	// li r27,1627
	r27.s64 = 1627;
	// b 0x82188510
	goto loc_82188510;
loc_821883E8:
	// li r11,2
	r11.s64 = 2;
	// stw r11,388(r31)
	PPC_STORE_U32(r31.u32 + 388, r11.u32);
	// b 0x82188510
	goto loc_82188510;
loc_821883F4:
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// beq cr6,0x82188510
	if (cr6.getEQ()) goto loc_82188510;
	// cmplwi cr6,r3,996
	cr6.compare<uint32_t>(ctx.r3.u32, 996, xer);
	// beq cr6,0x82188510
	if (cr6.getEQ()) goto loc_82188510;
	// li r27,1627
	r27.s64 = 1627;
	// b 0x82188510
	goto loc_82188510;
loc_8218840C:
	// addi r29,r31,20
	r29.s64 = r31.s64 + 20;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8235d6e0
	sub_8235D6E0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x821884e4
	if (!cr6.getEQ()) goto loc_821884E4;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r7,r31,336
	ctx.r7.s64 = r31.s64 + 336;
	// addi r5,r11,-20196
	ctx.r5.s64 = r11.s64 + -20196;
	// mr r6,r25
	ctx.r6.u64 = r25.u64;
	// li r4,32
	ctx.r4.s64 = 32;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x823eea88
	sub_823EEA88(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// lis r8,24576
	ctx.r8.s64 = 1610612736;
	// stb r28,127(r1)
	PPC_STORE_U8(ctx.r1.u32 + 127, r28.u8);
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// lis r4,16384
	ctx.r4.s64 = 1073741824;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8235d008
	sub_8235D008(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stw r3,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r3.u32);
	// beq cr6,0x821882e0
	if (cr6.getEQ()) goto loc_821882E0;
	// addi r7,r31,48
	ctx.r7.s64 = r31.s64 + 48;
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r28,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, r28.u32);
	// stw r28,4(r7)
	PPC_STORE_U32(ctx.r7.u32 + 4, r28.u32);
	// stw r28,8(r7)
	PPC_STORE_U32(ctx.r7.u32 + 8, r28.u32);
	// stw r28,12(r7)
	PPC_STORE_U32(ctx.r7.u32 + 12, r28.u32);
	// stw r28,16(r7)
	PPC_STORE_U32(ctx.r7.u32 + 16, r28.u32);
	// lwz r5,8(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r4,4(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// bl 0x8235e018
	sub_8235E018(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x821884b8
	if (cr6.getEQ()) goto loc_821884B8;
	// li r11,1
	r11.s64 = 1;
	// stw r11,388(r31)
	PPC_STORE_U32(r31.u32 + 388, r11.u32);
	// b 0x82188510
	goto loc_82188510;
loc_821884B8:
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// bne cr6,0x821884d0
	if (!cr6.getEQ()) goto loc_821884D0;
	// li r11,1
	r11.s64 = 1;
	// stw r11,388(r31)
	PPC_STORE_U32(r31.u32 + 388, r11.u32);
	// b 0x82188510
	goto loc_82188510;
loc_821884D0:
	// lwz r3,16(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r27,1627
	r27.s64 = 1627;
	// li r26,1
	r26.s64 = 1;
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// b 0x82188510
	goto loc_82188510;
loc_821884E4:
	// cmplwi cr6,r30,996
	cr6.compare<uint32_t>(r30.u32, 996, xer);
	// beq cr6,0x82188510
	if (cr6.getEQ()) goto loc_82188510;
	// cmplwi cr6,r30,997
	cr6.compare<uint32_t>(r30.u32, 997, xer);
	// beq cr6,0x82188510
	if (cr6.getEQ()) goto loc_82188510;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8235de98
	sub_8235DE98(ctx, base);
	// li r26,1
	r26.s64 = 1;
	// li r27,1627
	r27.s64 = 1627;
	// cmplwi cr6,r30,5
	cr6.compare<uint32_t>(r30.u32, 5, xer);
	// bne cr6,0x82188510
	if (!cr6.getEQ()) goto loc_82188510;
	// stb r26,384(r31)
	PPC_STORE_U8(r31.u32 + 384, r26.u8);
loc_82188510:
	// clrlwi r11,r26,24
	r11.u64 = r26.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82188530
	if (cr6.getEQ()) goto loc_82188530;
	// addi r4,r31,20
	ctx.r4.s64 = r31.s64 + 20;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8235d678
	sub_8235D678(ctx, base);
	// lwz r3,12(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// bl 0x8235d388
	sub_8235D388(ctx, base);
loc_82188530:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_82188540"))) PPC_WEAK_FUNC(sub_82188540);
PPC_FUNC_IMPL(__imp__sub_82188540) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f18{};
	PPCRegister f19{};
	PPCRegister f20{};
	PPCRegister f21{};
	PPCRegister f22{};
	PPCRegister f23{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// addi r12,r1,-32
	r12.s64 = ctx.r1.s64 + -32;
	// bl 0x823ed520
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f30,f8
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f8.f64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// fmr f20,f1
	f20.f64 = ctx.f1.f64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// fmr f25,f2
	f25.f64 = ctx.f2.f64;
	// fmr f26,f3
	f26.f64 = ctx.f3.f64;
	// fmr f19,f4
	f19.f64 = ctx.f4.f64;
	// lfs f21,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f21.f64 = double(temp.f32);
	// fmr f27,f5
	f27.f64 = ctx.f5.f64;
	// fmr f18,f6
	f18.f64 = ctx.f6.f64;
	// fcmpu cr6,f30,f21
	cr6.compare(f30.f64, f21.f64);
	// ble cr6,0x821888e4
	if (!cr6.getGT()) goto loc_821888E4;
	// fcmpu cr6,f25,f27
	cr6.compare(f25.f64, f27.f64);
	// ble cr6,0x82188598
	if (!cr6.getGT()) goto loc_82188598;
	// fmr f25,f27
	f25.f64 = f27.f64;
	// b 0x821885a8
	goto loc_821885A8;
loc_82188598:
	// fneg f0,f27
	ctx.fpscr.disableFlushMode();
	f0.u64 = f27.u64 ^ 0x8000000000000000;
	// fcmpu cr6,f25,f0
	cr6.compare(f25.f64, f0.f64);
	// bge cr6,0x821885a8
	if (!cr6.getLT()) goto loc_821885A8;
	// fmr f25,f0
	f25.f64 = f0.f64;
loc_821885A8:
	// lfs f29,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f29.f64 = double(temp.f32);
	// li r29,0
	r29.s64 = 0;
	// fsubs f28,f20,f29
	f28.f64 = double(float(f20.f64 - f29.f64));
	// lfs f31,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f31.f64 = double(temp.f32);
	// fcmpu cr6,f28,f21
	cr6.compare(f28.f64, f21.f64);
	// bge cr6,0x821885d8
	if (!cr6.getLT()) goto loc_821885D8;
	// fneg f29,f29
	f29.u64 = f29.u64 ^ 0x8000000000000000;
	// li r29,1
	r29.s64 = 1;
	// fneg f20,f20
	f20.u64 = f20.u64 ^ 0x8000000000000000;
	// fneg f28,f28
	f28.u64 = f28.u64 ^ 0x8000000000000000;
	// fneg f31,f31
	f31.u64 = f31.u64 ^ 0x8000000000000000;
	// fneg f25,f25
	f25.u64 = f25.u64 ^ 0x8000000000000000;
loc_821885D8:
	// fcmpu cr6,f28,f7
	ctx.fpscr.disableFlushMode();
	cr6.compare(f28.f64, ctx.f7.f64);
	// bgt cr6,0x82188630
	if (cr6.getGT()) goto loc_82188630;
	// fsubs f1,f31,f25
	ctx.f1.f64 = double(float(f31.f64 - f25.f64));
	// bl 0x8238cc58
	sub_8238CC58(ctx, base);
	// fcmpu cr6,f1,f18
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f18.f64);
	// bgt cr6,0x82188630
	if (cr6.getGT()) goto loc_82188630;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x82188618
	if (cr6.getEQ()) goto loc_82188618;
	// fneg f0,f20
	f0.u64 = f20.u64 ^ 0x8000000000000000;
	// stfs f0,0(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// fneg f0,f25
	f0.u64 = f25.u64 ^ 0x8000000000000000;
	// stfs f0,0(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 0, temp.u32);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// addi r12,r1,-32
	r12.s64 = ctx.r1.s64 + -32;
	// bl 0x823ed56c
	// b 0x823ed18c
	return;
loc_82188618:
	// stfs f20,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f20.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// stfs f25,0(r30)
	temp.f32 = float(f25.f64);
	PPC_STORE_U32(r30.u32 + 0, temp.u32);
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// addi r12,r1,-32
	r12.s64 = ctx.r1.s64 + -32;
	// bl 0x823ed56c
	// b 0x823ed18c
	return;
loc_82188630:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fcmpu cr6,f25,f27
	ctx.fpscr.disableFlushMode();
	cr6.compare(f25.f64, f27.f64);
	// lfs f23,3060(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3060);
	f23.f64 = double(temp.f32);
	// blt cr6,0x8218864c
	if (cr6.getLT()) goto loc_8218864C;
	// fmr f25,f27
	f25.f64 = f27.f64;
	// fmr f22,f21
	f22.f64 = f21.f64;
	// b 0x8218866c
	goto loc_8218866C;
loc_8218864C:
	// fcmpu cr6,f25,f21
	ctx.fpscr.disableFlushMode();
	cr6.compare(f25.f64, f21.f64);
	// bge cr6,0x82188658
	if (!cr6.getLT()) goto loc_82188658;
	// fmr f25,f21
	f25.f64 = f21.f64;
loc_82188658:
	// fmuls f0,f27,f27
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f27.f64 * f27.f64));
	// fmuls f13,f19,f23
	ctx.f13.f64 = double(float(f19.f64 * f23.f64));
	// fmsubs f0,f25,f25,f0
	f0.f64 = double(float(f25.f64 * f25.f64 - f0.f64));
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// fneg f22,f0
	f22.u64 = f0.u64 ^ 0x8000000000000000;
loc_8218866C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fcmpu cr6,f31,f21
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f21.f64);
	// lfs f24,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f24.f64 = double(temp.f32);
	// bge cr6,0x821886d0
	if (!cr6.getLT()) goto loc_821886D0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,6580(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6580);
	f0.f64 = double(temp.f32);
	// fdivs f0,f0,f26
	f0.f64 = double(float(f0.f64 / f26.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// ble cr6,0x821886b4
	if (!cr6.getGT()) goto loc_821886B4;
	// fmadds f0,f26,f30,f31
	f0.f64 = double(float(f26.f64 * f30.f64 + f31.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	ctx.f13.f64 = double(temp.f32);
	// fadds f12,f0,f31
	ctx.f12.f64 = double(float(f0.f64 + f31.f64));
	// fmr f31,f0
	f31.f64 = f0.f64;
	// fmuls f0,f12,f30
	f0.f64 = double(float(ctx.f12.f64 * f30.f64));
	// fmadds f29,f0,f13,f29
	f29.f64 = double(float(f0.f64 * ctx.f13.f64 + f29.f64));
	// b 0x821888cc
	goto loc_821888CC;
loc_821886B4:
	// fneg f0,f31
	ctx.fpscr.disableFlushMode();
	f0.u64 = f31.u64 ^ 0x8000000000000000;
	// fdivs f0,f0,f26
	f0.f64 = double(float(f0.f64 / f26.f64));
	// fmuls f13,f0,f31
	ctx.f13.f64 = double(float(f0.f64 * f31.f64));
	// fmr f31,f21
	f31.f64 = f21.f64;
	// fsubs f30,f30,f0
	f30.f64 = double(float(f30.f64 - f0.f64));
	// fmadds f29,f13,f24,f29
	f29.f64 = double(float(ctx.f13.f64 * f24.f64 + f29.f64));
	// fsubs f28,f20,f29
	f28.f64 = double(float(f20.f64 - f29.f64));
loc_821886D0:
	// fcmpu cr6,f30,f21
	ctx.fpscr.disableFlushMode();
	cr6.compare(f30.f64, f21.f64);
	// ble cr6,0x821888cc
	if (!cr6.getGT()) goto loc_821888CC;
	// fcmpu cr6,f31,f27
	cr6.compare(f31.f64, f27.f64);
	// bge cr6,0x821887fc
	if (!cr6.getLT()) goto loc_821887FC;
	// fcmpu cr6,f25,f31
	cr6.compare(f25.f64, f31.f64);
	// blt cr6,0x821886f0
	if (cr6.getLT()) goto loc_821886F0;
	// fmr f0,f21
	f0.f64 = f21.f64;
	// b 0x82188704
	goto loc_82188704;
loc_821886F0:
	// fmuls f0,f31,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f31.f64 * f31.f64));
	// fmuls f13,f19,f23
	ctx.f13.f64 = double(float(f19.f64 * f23.f64));
	// fmsubs f0,f25,f25,f0
	f0.f64 = double(float(f25.f64 * f25.f64 - f0.f64));
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
loc_82188704:
	// fcmpu cr6,f0,f28
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f28.f64);
	// bge cr6,0x821887fc
	if (!cr6.getLT()) goto loc_821887FC;
	// fmuls f0,f31,f31
	f0.f64 = double(float(f31.f64 * f31.f64));
	// fmuls f12,f26,f23
	ctx.f12.f64 = double(float(f26.f64 * f23.f64));
	// fmsubs f13,f27,f27,f0
	ctx.f13.f64 = double(float(f27.f64 * f27.f64 - f0.f64));
	// fdivs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 / ctx.f12.f64));
	// fadds f13,f13,f22
	ctx.f13.f64 = double(float(ctx.f13.f64 + f22.f64));
	// fcmpu cr6,f13,f28
	cr6.compare(ctx.f13.f64, f28.f64);
	// bgt cr6,0x8218876c
	if (cr6.getGT()) goto loc_8218876C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f0,f27,f31
	f0.f64 = double(float(f27.f64 - f31.f64));
	// lfs f13,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f13,f13,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 / f26.f64));
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f30
	cr6.compare(ctx.f12.f64, f30.f64);
	// ble cr6,0x8218875c
	if (!cr6.getGT()) goto loc_8218875C;
	// fmadds f0,f26,f30,f31
	f0.f64 = double(float(f26.f64 * f30.f64 + f31.f64));
	// fadds f13,f0,f31
	ctx.f13.f64 = double(float(f0.f64 + f31.f64));
	// fmr f31,f0
	f31.f64 = f0.f64;
	// fmuls f0,f13,f30
	f0.f64 = double(float(ctx.f13.f64 * f30.f64));
	// fmadds f29,f0,f24,f29
	f29.f64 = double(float(f0.f64 * f24.f64 + f29.f64));
	// b 0x821888cc
	goto loc_821888CC;
loc_8218875C:
	// fmuls f0,f0,f13
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// fadds f13,f31,f27
	ctx.f13.f64 = double(float(f31.f64 + f27.f64));
	// fmr f31,f27
	f31.f64 = f27.f64;
	// b 0x821887ec
	goto loc_821887EC;
loc_8218876C:
	// fneg f13,f19
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = f19.u64 ^ 0x8000000000000000;
	// fnmsubs f11,f25,f25,f0
	ctx.f11.f64 = double(float(-(f25.f64 * f25.f64 - f0.f64)));
	// fmuls f10,f13,f28
	ctx.f10.f64 = double(float(ctx.f13.f64 * f28.f64));
	// fmsubs f13,f13,f23,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f23.f64 - ctx.f12.f64));
	// fmadds f11,f10,f23,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * f23.f64 + ctx.f11.f64));
	// fdivs f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 / ctx.f13.f64));
	// fcmpu cr6,f13,f28
	cr6.compare(ctx.f13.f64, f28.f64);
	// bgt cr6,0x821887a8
	if (cr6.getGT()) goto loc_821887A8;
	// fmuls f13,f13,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 * f26.f64));
	// fmadds f1,f13,f23,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * f23.f64 + f0.f64));
	// bl 0x8238ca50
	sub_8238CA50(ctx, base);
	// fcmpu cr6,f1,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f31.f64);
	// bge cr6,0x821887ac
	if (!cr6.getLT()) goto loc_821887AC;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// b 0x821887ac
	goto loc_821887AC;
loc_821887A8:
	// fmr f1,f25
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f25.f64;
loc_821887AC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f0,f1,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 - f31.f64));
	// lfs f13,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f13,f13,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 / f26.f64));
	// fmuls f12,f0,f13
	ctx.f12.f64 = double(float(f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f12,f30
	cr6.compare(ctx.f12.f64, f30.f64);
	// ble cr6,0x821887e0
	if (!cr6.getGT()) goto loc_821887E0;
	// fmadds f0,f26,f30,f31
	f0.f64 = double(float(f26.f64 * f30.f64 + f31.f64));
	// fadds f13,f0,f31
	ctx.f13.f64 = double(float(f0.f64 + f31.f64));
	// fmr f31,f0
	f31.f64 = f0.f64;
	// fmuls f0,f13,f30
	f0.f64 = double(float(ctx.f13.f64 * f30.f64));
	// fmadds f29,f0,f24,f29
	f29.f64 = double(float(f0.f64 * f24.f64 + f29.f64));
	// b 0x821888cc
	goto loc_821888CC;
loc_821887E0:
	// fmuls f0,f0,f13
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// fadds f13,f1,f31
	ctx.f13.f64 = double(float(ctx.f1.f64 + f31.f64));
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
loc_821887EC:
	// fmuls f13,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fsubs f30,f30,f0
	f30.f64 = double(float(f30.f64 - f0.f64));
	// fmadds f29,f13,f24,f29
	f29.f64 = double(float(ctx.f13.f64 * f24.f64 + f29.f64));
	// fsubs f28,f20,f29
	f28.f64 = double(float(f20.f64 - f29.f64));
loc_821887FC:
	// fcmpu cr6,f30,f21
	ctx.fpscr.disableFlushMode();
	cr6.compare(f30.f64, f21.f64);
	// ble cr6,0x821888cc
	if (!cr6.getGT()) goto loc_821888CC;
	// fcmpu cr6,f31,f27
	cr6.compare(f31.f64, f27.f64);
	// ble cr6,0x82188810
	if (!cr6.getGT()) goto loc_82188810;
	// fmr f31,f27
	f31.f64 = f27.f64;
loc_82188810:
	// fcmpu cr6,f31,f27
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f27.f64);
	// bne cr6,0x82188844
	if (!cr6.getEQ()) goto loc_82188844;
	// fcmpu cr6,f22,f28
	cr6.compare(f22.f64, f28.f64);
	// bge cr6,0x82188844
	if (!cr6.getLT()) goto loc_82188844;
	// fsubs f0,f28,f22
	f0.f64 = double(float(f28.f64 - f22.f64));
	// fdivs f0,f0,f27
	f0.f64 = double(float(f0.f64 / f27.f64));
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// ble cr6,0x82188838
	if (!cr6.getGT()) goto loc_82188838;
	// fmadds f29,f27,f30,f29
	f29.f64 = double(float(f27.f64 * f30.f64 + f29.f64));
	// b 0x821888cc
	goto loc_821888CC;
loc_82188838:
	// fsubs f29,f20,f22
	ctx.fpscr.disableFlushMode();
	f29.f64 = double(float(f20.f64 - f22.f64));
	// fmr f28,f22
	f28.f64 = f22.f64;
	// fsubs f30,f30,f0
	f30.f64 = double(float(f30.f64 - f0.f64));
loc_82188844:
	// fcmpu cr6,f30,f21
	ctx.fpscr.disableFlushMode();
	cr6.compare(f30.f64, f21.f64);
	// ble cr6,0x821888cc
	if (!cr6.getGT()) goto loc_821888CC;
	// fmuls f27,f19,f30
	f27.f64 = double(float(f19.f64 * f30.f64));
	// fmuls f0,f27,f30
	f0.f64 = double(float(f27.f64 * f30.f64));
	// fmuls f0,f0,f24
	f0.f64 = double(float(f0.f64 * f24.f64));
	// fmsubs f26,f31,f30,f0
	f26.f64 = double(float(f31.f64 * f30.f64 - f0.f64));
	// fcmpu cr6,f26,f28
	cr6.compare(f26.f64, f28.f64);
	// ble cr6,0x821888a0
	if (!cr6.getGT()) goto loc_821888A0;
	// fmuls f0,f28,f19
	f0.f64 = double(float(f28.f64 * f19.f64));
	// fmuls f0,f0,f23
	f0.f64 = double(float(f0.f64 * f23.f64));
	// fmsubs f1,f31,f31,f0
	ctx.f1.f64 = double(float(f31.f64 * f31.f64 - f0.f64));
	// fcmpu cr6,f1,f21
	cr6.compare(ctx.f1.f64, f21.f64);
	// ble cr6,0x8218888c
	if (!cr6.getGT()) goto loc_8218888C;
	// bl 0x8238ca50
	sub_8238CA50(ctx, base);
	// fsubs f1,f1,f25
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f1.f64 - f25.f64));
	// bl 0x8238cc58
	sub_8238CC58(ctx, base);
	// fcmpu cr6,f1,f18
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f18.f64);
	// b 0x821888b4
	goto loc_821888B4;
loc_8218888C:
	// fmr f1,f21
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f21.f64;
	// fsubs f1,f1,f25
	ctx.f1.f64 = double(float(ctx.f1.f64 - f25.f64));
	// bl 0x8238cc58
	sub_8238CC58(ctx, base);
	// fcmpu cr6,f1,f18
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f18.f64);
	// b 0x821888b4
	goto loc_821888B4;
loc_821888A0:
	// fsubs f0,f31,f25
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f31.f64 - f25.f64));
	// fdivs f0,f0,f19
	f0.f64 = double(float(f0.f64 / f19.f64));
	// fcmpu cr6,f0,f21
	cr6.compare(f0.f64, f21.f64);
	// blt cr6,0x821888c4
	if (cr6.getLT()) goto loc_821888C4;
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
loc_821888B4:
	// bgt cr6,0x821888c4
	if (cr6.getGT()) goto loc_821888C4;
	// fmr f29,f20
	ctx.fpscr.disableFlushMode();
	f29.f64 = f20.f64;
	// fmr f31,f25
	f31.f64 = f25.f64;
	// b 0x821888cc
	goto loc_821888CC;
loc_821888C4:
	// fadds f29,f26,f29
	ctx.fpscr.disableFlushMode();
	f29.f64 = double(float(f26.f64 + f29.f64));
	// fsubs f31,f31,f27
	f31.f64 = double(float(f31.f64 - f27.f64));
loc_821888CC:
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x821888dc
	if (cr6.getEQ()) goto loc_821888DC;
	// fneg f29,f29
	ctx.fpscr.disableFlushMode();
	f29.u64 = f29.u64 ^ 0x8000000000000000;
	// fneg f31,f31
	f31.u64 = f31.u64 ^ 0x8000000000000000;
loc_821888DC:
	// stfs f29,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// stfs f31,0(r30)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r30.u32 + 0, temp.u32);
loc_821888E4:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// addi r12,r1,-32
	r12.s64 = ctx.r1.s64 + -32;
	// bl 0x823ed56c
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_821888F8"))) PPC_WEAK_FUNC(sub_821888F8);
PPC_FUNC_IMPL(__imp__sub_821888F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	PPCVRegister vTemp{};
	// vmsum3fp128 v12,v2,v2
	ctx.fpscr.enableFlushMode();
	_mm_store_ps(ctx.v12.f32, _mm_dp_ps(_mm_load_ps(ctx.v2.f32), _mm_load_ps(ctx.v2.f32), 0xEF));
	// vspltisw v13,-1
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_set1_epi32(int(0xFFFFFFFF)));
	// vspltisw v0,1
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_set1_epi32(int(0x1)));
	// li r11,16
	r11.s64 = 16;
	// vpermwi128 v11,v3,99
	_mm_store_si128((__m128i*)ctx.v11.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v3.u32), 0x9C));
	// li r10,32
	ctx.r10.s64 = 32;
	// vpermwi128 v8,v3,135
	_mm_store_si128((__m128i*)ctx.v8.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v3.u32), 0x78));
	// li r9,48
	ctx.r9.s64 = 48;
	// vslw v13,v13,v13
	ctx.v13.u32[0] = ctx.v13.u32[0] << (ctx.v13.u8[0] & 0x1F);
	ctx.v13.u32[1] = ctx.v13.u32[1] << (ctx.v13.u8[4] & 0x1F);
	ctx.v13.u32[2] = ctx.v13.u32[2] << (ctx.v13.u8[8] & 0x1F);
	ctx.v13.u32[3] = ctx.v13.u32[3] << (ctx.v13.u8[12] & 0x1F);
	// vcfsx v0,v0,1
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_cvtepi32_ps(_mm_load_si128((__m128i*)ctx.v0.u32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x3F000000)))));
	// vxor v10,v1,v13
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_xor_si128(_mm_load_si128((__m128i*)ctx.v1.u8), _mm_load_si128((__m128i*)ctx.v13.u8)));
	// vrsqrtefp v13,v12
	_mm_store_ps(ctx.v13.f32, _mm_div_ps(_mm_set1_ps(1), _mm_sqrt_ps(_mm_load_ps(ctx.v12.f32))));
	// vmulfp128 v12,v12,v0
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v0.f32)));
	// vmulfp128 v9,v13,v13
	_mm_store_ps(ctx.v9.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v13.f32)));
	// vnmsubfp v12,v12,v9,v0
	_mm_store_ps(ctx.v12.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v9.f32)), _mm_load_ps(ctx.v0.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vmaddfp v13,v13,v12,v13
	_mm_store_ps(ctx.v13.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v12.f32)), _mm_load_ps(ctx.v13.f32)));
	// vmulfp128 v13,v2,v13
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v2.f32), _mm_load_ps(ctx.v13.f32)));
	// vpermwi128 v12,v13,135
	_mm_store_si128((__m128i*)ctx.v12.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0x78));
	// vpermwi128 v9,v13,99
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0x9C));
	// vor v6,v12,v12
	_mm_store_si128((__m128i*)ctx.v6.u8, _mm_load_si128((__m128i*)ctx.v12.u8));
	// vmulfp128 v12,v11,v12
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v12.f32)));
	// vnmsubfp v11,v8,v9,v12
	_mm_store_ps(ctx.v11.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v8.f32), _mm_load_ps(ctx.v9.f32)), _mm_load_ps(ctx.v12.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vmsum3fp128 v8,v11,v11
	_mm_store_ps(ctx.v8.f32, _mm_dp_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v11.f32), 0xEF));
	// vrsqrtefp v12,v8
	_mm_store_ps(ctx.v12.f32, _mm_div_ps(_mm_set1_ps(1), _mm_sqrt_ps(_mm_load_ps(ctx.v8.f32))));
	// vmulfp128 v8,v8,v0
	_mm_store_ps(ctx.v8.f32, _mm_mul_ps(_mm_load_ps(ctx.v8.f32), _mm_load_ps(ctx.v0.f32)));
	// vmulfp128 v7,v12,v12
	_mm_store_ps(ctx.v7.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v12.f32)));
	// vnmsubfp v0,v8,v7,v0
	_mm_store_ps(ctx.v0.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v8.f32), _mm_load_ps(ctx.v7.f32)), _mm_load_ps(ctx.v0.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vmaddfp v0,v12,v0,v12
	_mm_store_ps(ctx.v0.f32, _mm_add_ps(_mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v0.f32)), _mm_load_ps(ctx.v12.f32)));
	// vmulfp128 v0,v11,v0
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v0.f32)));
	// vpermwi128 v12,v0,135
	_mm_store_si128((__m128i*)ctx.v12.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x78));
	// vpermwi128 v11,v0,99
	_mm_store_si128((__m128i*)ctx.v11.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x9C));
	// vmulfp128 v12,v9,v12
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v9.f32), _mm_load_ps(ctx.v12.f32)));
	// vnmsubfp v9,v6,v11,v12
	_mm_store_ps(ctx.v9.f32, _mm_xor_ps(_mm_sub_ps(_mm_mul_ps(_mm_load_ps(ctx.v6.f32), _mm_load_ps(ctx.v11.f32)), _mm_load_ps(ctx.v12.f32)), _mm_castsi128_ps(_mm_set1_epi32(int(0x80000000)))));
	// vspltisw v12,0
	_mm_store_si128((__m128i*)ctx.v12.u32, _mm_set1_epi32(int(0x0)));
	// vupkd3d128 v8,v12,4
	temp.f32 = 3.0f;
	temp.s32 += ctx.v12.s16[1];
	vTemp.f32[3] = temp.f32;
	temp.f32 = 3.0f;
	temp.s32 += ctx.v12.s16[0];
	vTemp.f32[2] = temp.f32;
	vTemp.f32[1] = 0.0f;
	vTemp.f32[0] = 1.0f;
	ctx.v8 = vTemp;
	// vmsum3fp128 v12,v0,v10
	_mm_store_ps(ctx.v12.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v10.f32), 0xEF));
	// vpermwi128 v8,v8,171
	_mm_store_si128((__m128i*)ctx.v8.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v8.u32), 0x54));
	// vmsum3fp128 v11,v9,v10
	_mm_store_ps(ctx.v11.f32, _mm_dp_ps(_mm_load_ps(ctx.v9.f32), _mm_load_ps(ctx.v10.f32), 0xEF));
	// vmsum3fp128 v10,v13,v10
	_mm_store_ps(ctx.v10.f32, _mm_dp_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v10.f32), 0xEF));
	// vrlimi128 v12,v0,14,0
	_mm_store_ps(ctx.v12.f32, _mm_blend_ps(_mm_load_ps(ctx.v12.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 228), 14));
	// vrlimi128 v11,v9,14,0
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v9.f32), 228), 14));
	// vrlimi128 v10,v13,14,0
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 228), 14));
	// vmrghw v0,v11,v8
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v8.u32), _mm_load_si128((__m128i*)ctx.v11.u32)));
	// vmrghw v13,v12,v10
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v10.u32), _mm_load_si128((__m128i*)ctx.v12.u32)));
	// vmrglw v12,v12,v10
	_mm_store_si128((__m128i*)ctx.v12.u32, _mm_unpacklo_epi32(_mm_load_si128((__m128i*)ctx.v10.u32), _mm_load_si128((__m128i*)ctx.v12.u32)));
	// vmrglw v11,v11,v8
	_mm_store_si128((__m128i*)ctx.v11.u32, _mm_unpacklo_epi32(_mm_load_si128((__m128i*)ctx.v8.u32), _mm_load_si128((__m128i*)ctx.v11.u32)));
	// vmrghw v10,v13,v0
	_mm_store_si128((__m128i*)ctx.v10.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), _mm_load_si128((__m128i*)ctx.v13.u32)));
	// vmrglw v0,v13,v0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_unpacklo_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), _mm_load_si128((__m128i*)ctx.v13.u32)));
	// vmrghw v13,v12,v11
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v11.u32), _mm_load_si128((__m128i*)ctx.v12.u32)));
	// vmrglw v12,v12,v11
	_mm_store_si128((__m128i*)ctx.v12.u32, _mm_unpacklo_epi32(_mm_load_si128((__m128i*)ctx.v11.u32), _mm_load_si128((__m128i*)ctx.v12.u32)));
	// stvx128 v10,r0,r3
	_mm_store_si128((__m128i*)(base + ((ctx.r3.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v10.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r3,r11
	_mm_store_si128((__m128i*)(base + ((ctx.r3.u32 + r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v13,r3,r10
	_mm_store_si128((__m128i*)(base + ((ctx.r3.u32 + ctx.r10.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v12,r3,r9
	_mm_store_si128((__m128i*)(base + ((ctx.r3.u32 + ctx.r9.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821889D8"))) PPC_WEAK_FUNC(sub_821889D8);
PPC_FUNC_IMPL(__imp__sub_821889D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,292
	r11.s64 = 19136512;
	// stfs f1,-96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + -96, temp.u32);
	// addi r9,r1,-96
	ctx.r9.s64 = ctx.r1.s64 + -96;
	// ori r10,r11,16237
	ctx.r10.u64 = r11.u64 | 16237;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,6588(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6588);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f13,-80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -80, temp.u32);
	// addi r11,r11,2208
	r11.s64 = r11.s64 + 2208;
	// lvx128 v11,r0,r11
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r11,r11,2224
	r11.s64 = r11.s64 + 2224;
	// lvx128 v10,r0,r11
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r11,r11,2160
	r11.s64 = r11.s64 + 2160;
	// lvx128 v9,r0,r11
	_mm_store_si128((__m128i*)ctx.v9.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r11,r11,2176
	r11.s64 = r11.s64 + 2176;
	// lvx128 v8,r0,r11
	_mm_store_si128((__m128i*)ctx.v8.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r11,r11,2192
	r11.s64 = r11.s64 + 2192;
	// lvx128 v7,r0,r11
	_mm_store_si128((__m128i*)ctx.v7.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r11,r11,2144
	r11.s64 = r11.s64 + 2144;
	// lvx128 v6,r0,r11
	_mm_store_si128((__m128i*)ctx.v6.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lwz r11,-96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -96);
	// rlwimi r11,r10,30,1,31
	r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 30) & 0x7FFFFFFF) | (r11.u64 & 0xFFFFFFFF80000000);
	// stw r11,-96(r1)
	PPC_STORE_U32(ctx.r1.u32 + -96, r11.u32);
	// lfs f13,-96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -96);
	ctx.f13.f64 = double(temp.f32);
	// fadds f12,f13,f1
	ctx.f12.f64 = double(float(ctx.f13.f64 + ctx.f1.f64));
	// lis r11,-32254
	r11.s64 = -2113798144;
	// lfs f13,-20188(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -20188);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fctiwz f13,f13
	ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f13.f64));
	// stfiwx f13,0,r9
	PPC_STORE_U32(ctx.r9.u32, ctx.f13.u32);
	// lwz r11,-96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -96);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,-96(r1)
	PPC_STORE_U64(ctx.r1.u32 + -96, r11.u64);
	// lfd f13,-96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fnmsubs f0,f13,f0,f1
	f0.f64 = double(float(-(ctx.f13.f64 * f0.f64 - ctx.f1.f64)));
	// stfs f0,-76(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -76, temp.u32);
	// fmuls f13,f0,f0
	ctx.f13.f64 = double(float(f0.f64 * f0.f64));
	// stfs f13,-72(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + -72, temp.u32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,-68(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + -68, temp.u32);
	// addi r11,r1,-80
	r11.s64 = ctx.r1.s64 + -80;
	// lvx128 v13,r0,r11
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,-32
	r11.s64 = ctx.r1.s64 + -32;
	// vmulfp128 v0,v13,v13
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v13.f32)));
	// vspltw v5,v13,2
	_mm_store_si128((__m128i*)ctx.v5.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0x55));
	// vspltw v13,v13,1
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), 0xAA));
	// vmsum4fp128 v7,v0,v7
	_mm_store_ps(ctx.v7.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v7.f32), 0xFF));
	// vspltw v4,v0,3
	_mm_store_si128((__m128i*)ctx.v4.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), 0x0));
	// vmulfp128 v12,v0,v13
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// vmulfp128 v13,v4,v5
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v4.f32), _mm_load_ps(ctx.v5.f32)));
	// stvx128 v7,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v7.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// vmsum4fp128 v7,v12,v6
	_mm_store_ps(ctx.v7.f32, _mm_dp_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v6.f32), 0xFF));
	// addi r11,r1,-16
	r11.s64 = ctx.r1.s64 + -16;
	// vmulfp128 v0,v0,v13
	_mm_store_ps(ctx.v0.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// vmulfp128 v12,v12,v13
	_mm_store_ps(ctx.v12.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v13.f32)));
	// stvx128 v7,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v7.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// vmulfp128 v7,v0,v13
	_mm_store_ps(ctx.v7.f32, _mm_mul_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v13.f32)));
	// vmsum4fp128 v0,v0,v11
	_mm_store_ps(ctx.v0.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v11.f32), 0xFF));
	// vmulfp128 v13,v12,v13
	_mm_store_ps(ctx.v13.f32, _mm_mul_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v13.f32)));
	// vmsum4fp128 v12,v12,v9
	_mm_store_ps(ctx.v12.f32, _mm_dp_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v9.f32), 0xFF));
	// addi r11,r1,-80
	r11.s64 = ctx.r1.s64 + -80;
	// vmsum4fp128 v11,v7,v10
	_mm_store_ps(ctx.v11.f32, _mm_dp_ps(_mm_load_ps(ctx.v7.f32), _mm_load_ps(ctx.v10.f32), 0xFF));
	// vmsum4fp128 v13,v13,v8
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v8.f32), 0xFF));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,-64
	r11.s64 = ctx.r1.s64 + -64;
	// lfs f0,-80(r1)
	ctx.fpscr.disableFlushModeUnconditional();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -80);
	f0.f64 = double(temp.f32);
	// stvx128 v12,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,-96
	r11.s64 = ctx.r1.s64 + -96;
	// stvx128 v11,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v11.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,-48
	r11.s64 = ctx.r1.s64 + -48;
	// lfs f13,-96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -96);
	ctx.f13.f64 = double(temp.f32);
	// stvx128 v13,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// lfs f12,-48(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -48);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-64(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -64);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// lfs f12,-32(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -32);
	ctx.f12.f64 = double(temp.f32);
	// fadds f0,f0,f12
	f0.f64 = double(float(f0.f64 + ctx.f12.f64));
	// stfs f0,0(r4)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// lfs f0,-16(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	f0.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// stfs f0,0(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82188B48"))) PPC_WEAK_FUNC(sub_82188B48);
PPC_FUNC_IMPL(__imp__sub_82188B48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// bl 0x82099f80
	sub_82099F80(ctx, base);
	// li r27,0
	r27.s64 = 0;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// ble cr6,0x82188d44
	if (!cr6.getGT()) goto loc_82188D44;
	// lis r28,-32014
	r28.s64 = -2098069504;
loc_82188B70:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x820ca0b0
	sub_820CA0B0(ctx, base);
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// lwz r11,-1364(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -1364);
	// lhz r4,2306(r11)
	ctx.r4.u64 = PPC_LOAD_U16(r11.u32 + 2306);
	// lhz r3,2304(r11)
	ctx.r3.u64 = PPC_LOAD_U16(r11.u32 + 2304);
	// bl 0x8210e1a8
	sub_8210E1A8(ctx, base);
	// lwz r11,-1364(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -1364);
	// lhz r4,2310(r11)
	ctx.r4.u64 = PPC_LOAD_U16(r11.u32 + 2310);
	// lhz r3,2308(r11)
	ctx.r3.u64 = PPC_LOAD_U16(r11.u32 + 2308);
	// bl 0x8210e228
	sub_8210E228(ctx, base);
	// lwz r11,-1364(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -1364);
	// lfs f1,4728(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4728);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210e310
	sub_8210E310(ctx, base);
	// lwz r11,-1364(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -1364);
	// lfs f1,4732(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4732);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210e350
	sub_8210E350(ctx, base);
	// bl 0x8210df98
	sub_8210DF98(ctx, base);
	// bl 0x82139320
	sub_82139320(ctx, base);
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// bne cr6,0x82188bc8
	if (!cr6.getEQ()) goto loc_82188BC8;
	// bl 0x820be390
	sub_820BE390(ctx, base);
loc_82188BC8:
	// bl 0x820cca38
	sub_820CCA38(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82188d38
	if (cr6.getEQ()) goto loc_82188D38;
loc_82188BD8:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x82188ce0
	if (cr6.getEQ()) goto loc_82188CE0;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x82188ce0
	if (cr6.getEQ()) goto loc_82188CE0;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// beq cr6,0x82188ce0
	if (cr6.getEQ()) goto loc_82188CE0;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x82188c04
	if (cr6.getEQ()) goto loc_82188C04;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x82188d2c
	if (!cr6.getEQ()) goto loc_82188D2C;
loc_82188C04:
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82188d2c
	if (cr6.getEQ()) goto loc_82188D2C;
	// lbz r11,12(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 12);
	// cmplwi cr6,r11,255
	cr6.compare<uint32_t>(r11.u32, 255, xer);
	// stb r11,76(r31)
	PPC_STORE_U8(r31.u32 + 76, r11.u8);
	// bge cr6,0x82188d2c
	if (!cr6.getLT()) goto loc_82188D2C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820c9b90
	sub_820C9B90(ctx, base);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// rlwinm r10,r11,0,21,21
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82188d2c
	if (!cr6.getEQ()) goto loc_82188D2C;
	// rlwinm r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82188d2c
	if (!cr6.getEQ()) goto loc_82188D2C;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// cmpw cr6,r29,r3
	cr6.compare<int32_t>(r29.s32, ctx.r3.s32, xer);
	// beq cr6,0x82188d2c
	if (cr6.getEQ()) goto loc_82188D2C;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// bne cr6,0x82188c8c
	if (!cr6.getEQ()) goto loc_82188C8C;
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// stb r11,1(r31)
	PPC_STORE_U8(r31.u32 + 1, r11.u8);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// oris r11,r11,128
	r11.u64 = r11.u64 | 8388608;
	// stw r11,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r11.u32);
	// bl 0x820b4d48
	sub_820B4D48(ctx, base);
	// lwz r11,20(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 20);
	// rlwinm r11,r11,0,9,7
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFF7FFFFF;
	// stw r11,20(r30)
	PPC_STORE_U32(r30.u32 + 20, r11.u32);
loc_82188C8C:
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82188d2c
	if (cr6.getEQ()) goto loc_82188D2C;
	// li r8,0
	ctx.r8.s64 = 0;
	// lbz r5,12(r30)
	ctx.r5.u64 = PPC_LOAD_U8(r30.u32 + 12);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8209b5e8
	sub_8209B5E8(ctx, base);
	// lwz r11,472(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 472);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82188d2c
	if (cr6.getEQ()) goto loc_82188D2C;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lbz r5,12(r30)
	ctx.r5.u64 = PPC_LOAD_U8(r30.u32 + 12);
	// lwz r3,20(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// bl 0x8209b220
	sub_8209B220(ctx, base);
	// b 0x82188d2c
	goto loc_82188D2C;
loc_82188CE0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d9ea8
	sub_820D9EA8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,255
	cr6.compare<uint32_t>(r11.u32, 255, xer);
	// stb r11,76(r31)
	PPC_STORE_U8(r31.u32 + 76, r11.u8);
	// bge cr6,0x82188d2c
	if (!cr6.getLT()) goto loc_82188D2C;
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// oris r11,r11,1024
	r11.u64 = r11.u64 | 67108864;
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
	// bl 0x820e4080
	sub_820E4080(ctx, base);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// rlwinm r11,r11,0,6,4
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFBFFFFFF;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
	// bl 0x820d9f30
	sub_820D9F30(ctx, base);
loc_82188D2C:
	// lwz r31,40(r31)
	r31.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82188bd8
	if (!cr6.getEQ()) goto loc_82188BD8;
loc_82188D38:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// cmpw cr6,r27,r26
	cr6.compare<int32_t>(r27.s32, r26.s32, xer);
	// blt cr6,0x82188b70
	if (cr6.getLT()) goto loc_82188B70;
loc_82188D44:
	// bl 0x82099fc0
	sub_82099FC0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_82188D50"))) PPC_WEAK_FUNC(sub_82188D50);
PPC_FUNC_IMPL(__imp__sub_82188D50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed11c
	// addi r12,r1,-96
	r12.s64 = ctx.r1.s64 + -96;
	// bl 0x823ed540
	// stwu r1,-384(r1)
	ea = -384 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820ae0d8
	sub_820AE0D8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x821898c0
	if (!cr6.getEQ()) goto loc_821898C0;
	// li r28,0
	r28.s64 = 0;
	// lis r10,-31991
	ctx.r10.s64 = -2096562176;
	// mr r11,r28
	r11.u64 = r28.u64;
	// stw r11,-31532(r10)
	PPC_STORE_U32(ctx.r10.u32 + -31532, r11.u32);
	// bl 0x820ae360
	sub_820AE360(ctx, base);
	// cmpwi cr6,r3,90
	cr6.compare<int32_t>(ctx.r3.s32, 90, xer);
	// beq cr6,0x82188da0
	if (cr6.getEQ()) goto loc_82188DA0;
	// bl 0x8238d968
	sub_8238D968(ctx, base);
	// bl 0x82188b48
	sub_82188B48(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8238da10
	sub_8238DA10(ctx, base);
loc_82188DA0:
	// bl 0x8238d968
	sub_8238D968(ctx, base);
	// bl 0x8209a090
	sub_8209A090(ctx, base);
	// bl 0x82118168
	sub_82118168(ctx, base);
	// bl 0x82091fc8
	sub_82091FC8(ctx, base);
	// bl 0x820ae320
	sub_820AE320(ctx, base);
	// lis r29,-31991
	r29.s64 = -2096562176;
	// lwz r3,-31560(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// bl 0x8238da10
	sub_8238DA10(ctx, base);
	// lis r31,-31991
	r31.s64 = -2096562176;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82195588
	sub_82195588(ctx, base);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// lwz r5,-31552(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + -31552);
	// bl 0x82196240
	sub_82196240(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82195f68
	sub_82195F68(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82194570
	sub_82194570(ctx, base);
	// lis r11,-32015
	r11.s64 = -2098135040;
	// mr r30,r28
	r30.u64 = r28.u64;
	// lis r22,-32014
	r22.s64 = -2098069504;
	// lbz r11,-8431(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + -8431);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82188e48
	if (cr6.getEQ()) goto loc_82188E48;
	// bl 0x8209ec18
	sub_8209EC18(ctx, base);
	// cmpwi cr6,r3,90
	cr6.compare<int32_t>(ctx.r3.s32, 90, xer);
	// beq cr6,0x82188e48
	if (cr6.getEQ()) goto loc_82188E48;
	// lwz r11,-1364(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + -1364);
	// lwz r10,800(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 800);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x82188e44
	if (cr6.getEQ()) goto loc_82188E44;
	// lwz r11,744(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 744);
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// beq cr6,0x82188e48
	if (cr6.getEQ()) goto loc_82188E48;
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// beq cr6,0x82188e48
	if (cr6.getEQ()) goto loc_82188E48;
loc_82188E44:
	// li r30,1
	r30.s64 = 1;
loc_82188E48:
	// clrlwi r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lis r24,-32015
	r24.s64 = -2098135040;
	// lfs f30,2688(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	f30.f64 = double(temp.f32);
	// lis r25,-32015
	r25.s64 = -2098135040;
	// lfs f31,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	f31.f64 = double(temp.f32);
	// addi r23,r11,27448
	r23.s64 = r11.s64 + 27448;
	// bne cr6,0x8218900c
	if (!cr6.getEQ()) goto loc_8218900C;
	// li r3,78
	ctx.r3.s64 = 78;
	// bl 0x82136fa0
	sub_82136FA0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x8218900c
	if (!cr6.getEQ()) goto loc_8218900C;
	// li r3,79
	ctx.r3.s64 = 79;
	// bl 0x82136fa0
	sub_82136FA0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x82188ff8
	if (cr6.getEQ()) goto loc_82188FF8;
	// addi r4,r1,116
	ctx.r4.s64 = ctx.r1.s64 + 116;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8238d718
	sub_8238D718(ctx, base);
	// lis r26,-31991
	r26.s64 = -2096562176;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lwz r11,-31464(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + -31464);
	// lfs f29,3060(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 3060);
	f29.f64 = double(temp.f32);
	// rlwinm r10,r11,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lis r10,-31991
	ctx.r10.s64 = -2096562176;
	// addi r10,r10,-31480
	ctx.r10.s64 = ctx.r10.s64 + -31480;
	// bne cr6,0x82188efc
	if (!cr6.getEQ()) goto loc_82188EFC;
	// lwz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// stfs f30,4(r10)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// stfs f29,8(r10)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// stfs f31,12(r10)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r10.u32 + 12, temp.u32);
	// stw r11,-31464(r26)
	PPC_STORE_U32(r26.u32 + -31464, r11.u32);
	// std r9,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r9.u64);
	// lfd f0,128(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fdivs f0,f31,f0
	f0.f64 = double(float(f31.f64 / f0.f64));
	// stfs f0,0(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// b 0x82188f00
	goto loc_82188F00;
loc_82188EFC:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
loc_82188F00:
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// li r9,1
	ctx.r9.s64 = 1;
	// lis r27,-32015
	r27.s64 = -2098135040;
	// rldicr r30,r9,63,63
	r30.u64 = __builtin_rotateleft64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// li r5,0
	ctx.r5.s64 = 0;
	// stfs f0,6064(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6064, temp.u32);
	// lfs f0,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,6068(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6068, temp.u32);
	// lfs f0,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,6072(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6072, temp.u32);
	// lfs f0,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,6076(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6076, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// or r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 | r30.u64;
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// lwz r4,-31560(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// lwz r3,-8456(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + -8456);
	// bl 0x82099210
	sub_82099210(ctx, base);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r6,-31560(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// li r8,0
	ctx.r8.s64 = 0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r28.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r28.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82197c48
	sub_82197C48(ctx, base);
	// lwz r10,-31464(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + -31464);
	// rlwinm r11,r10,0,28,28
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// addi r11,r11,-31496
	r11.s64 = r11.s64 + -31496;
	// bne cr6,0x82188fc0
	if (!cr6.getEQ()) goto loc_82188FC0;
	// lwz r9,116(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// ori r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 8;
	// stfs f29,8(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r11.u32 + 8, temp.u32);
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// stfs f31,12(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 12, temp.u32);
	// stw r10,-31464(r26)
	PPC_STORE_U32(r26.u32 + -31464, ctx.r10.u32);
	// std r9,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r9.u64);
	// lfd f0,128(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fdivs f0,f31,f0
	f0.f64 = double(float(f31.f64 / f0.f64));
	// stfs f0,4(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4, temp.u32);
loc_82188FC0:
	// lwz r10,13356(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// lfs f0,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,6064(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 6064, temp.u32);
	// lfs f0,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,6068(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 6068, temp.u32);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,6072(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 6072, temp.u32);
	// lfs f0,12(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,6076(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 6076, temp.u32);
	// ld r11,8(r10)
	r11.u64 = PPC_LOAD_U64(ctx.r10.u32 + 8);
	// or r11,r11,r30
	r11.u64 = r11.u64 | r30.u64;
	// std r11,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, r11.u64);
	// lwz r3,-8456(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + -8456);
	// b 0x821892e4
	goto loc_821892E4;
loc_82188FF8:
	// lis r10,-32019
	ctx.r10.s64 = -2098397184;
	// li r9,1
	ctx.r9.s64 = 1;
	// addi r10,r10,27276
	ctx.r10.s64 = ctx.r10.s64 + 27276;
	// rldicr r30,r9,63,63
	r30.u64 = __builtin_rotateleft64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// b 0x821892b0
	goto loc_821892B0;
loc_8218900C:
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x8238d718
	sub_8238D718(ctx, base);
	// lis r10,-32019
	ctx.r10.s64 = -2098397184;
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// li r9,1
	ctx.r9.s64 = 1;
	// addi r10,r10,27260
	ctx.r10.s64 = ctx.r10.s64 + 27260;
	// rldicr r30,r9,63,63
	r30.u64 = __builtin_rotateleft64(ctx.r9.u64, 63) & 0xFFFFFFFFFFFFFFFF;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,6016(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6016, temp.u32);
	// lfs f0,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,6020(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6020, temp.u32);
	// lfs f0,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,6024(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6024, temp.u32);
	// lfs f0,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,6028(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6028, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// or r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 | r30.u64;
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// bl 0x821463f0
	sub_821463F0(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8239a518
	sub_8239A518(ctx, base);
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r10,1176(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1176);
	// rlwinm r10,r10,0,22,18
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFE3FF;
	// stw r10,1176(r11)
	PPC_STORE_U32(r11.u32 + 1176, ctx.r10.u32);
	// ld r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// oris r10,r10,16384
	ctx.r10.u64 = ctx.r10.u64 | 1073741824;
	// std r10,24(r11)
	PPC_STORE_U64(r11.u32 + 24, ctx.r10.u64);
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// lwz r10,1176(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1176);
	// rlwinm r10,r10,0,19,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFF1FFF;
	// stw r10,1176(r11)
	PPC_STORE_U32(r11.u32 + 1176, ctx.r10.u32);
	// ld r10,24(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// oris r10,r10,16384
	ctx.r10.u64 = ctx.r10.u64 | 1073741824;
	// std r10,24(r11)
	PPC_STORE_U64(r11.u32 + 24, ctx.r10.u64);
	// lwz r4,-31560(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// lwz r3,-8860(r25)
	ctx.r3.u64 = PPC_LOAD_U32(r25.u32 + -8860);
	// bl 0x82099210
	sub_82099210(ctx, base);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r6,-31560(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// li r8,0
	ctx.r8.s64 = 0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r28.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r28.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82197c48
	sub_82197C48(ctx, base);
	// lis r10,-32019
	ctx.r10.s64 = -2098397184;
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// li r12,1
	r12.s64 = 1;
	// addi r10,r10,27244
	ctx.r10.s64 = ctx.r10.s64 + 27244;
	// rldicr r12,r12,62,63
	r12.u64 = __builtin_rotateleft64(r12.u64, 62) & 0xFFFFFFFFFFFFFFFF;
	// lis r27,-31991
	r27.s64 = -2096562176;
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,6080(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6080, temp.u32);
	// lfs f0,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	f0.f64 = double(temp.f32);
	// lwz r9,-31464(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + -31464);
	// stfs f0,6084(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6084, temp.u32);
	// lfs f0,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	f0.f64 = double(temp.f32);
	// clrlwi r8,r9,31
	ctx.r8.u64 = ctx.r9.u32 & 0x1;
	// stfs f0,6088(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6088, temp.u32);
	// lfs f0,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	f0.f64 = double(temp.f32);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// stfs f0,6092(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6092, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// or r10,r10,r12
	ctx.r10.u64 = ctx.r10.u64 | r12.u64;
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// addi r10,r11,-31512
	ctx.r10.s64 = r11.s64 + -31512;
	// bne cr6,0x82189174
	if (!cr6.getEQ()) goto loc_82189174;
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// stfs f30,4(r10)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// stfs f30,8(r10)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// extsw r8,r11
	ctx.r8.s64 = r11.s32;
	// stfs f30,12(r10)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + 12, temp.u32);
	// ori r11,r9,1
	r11.u64 = ctx.r9.u64 | 1;
	// std r8,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r8.u64);
	// lfd f0,128(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// stw r11,-31464(r27)
	PPC_STORE_U32(r27.u32 + -31464, r11.u32);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fdivs f0,f31,f0
	f0.f64 = double(float(f31.f64 / f0.f64));
	// stfs f0,0(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// b 0x82189178
	goto loc_82189178;
loc_82189174:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
loc_82189178:
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// lis r26,-32015
	r26.s64 = -2098135040;
	// li r5,0
	ctx.r5.s64 = 0;
	// stfs f0,6064(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6064, temp.u32);
	// lfs f0,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,6068(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6068, temp.u32);
	// lfs f0,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,6072(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6072, temp.u32);
	// lfs f0,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,6076(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6076, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// or r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 | r30.u64;
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// lwz r4,-31560(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// lwz r3,-8464(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + -8464);
	// bl 0x82099210
	sub_82099210(ctx, base);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r6,-31560(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// li r8,0
	ctx.r8.s64 = 0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r28.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r28.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82197c48
	sub_82197C48(ctx, base);
	// lwz r11,-31464(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + -31464);
	// rlwinm r10,r11,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lis r10,-31991
	ctx.r10.s64 = -2096562176;
	// addi r10,r10,-31528
	ctx.r10.s64 = ctx.r10.s64 + -31528;
	// bne cr6,0x82189238
	if (!cr6.getEQ()) goto loc_82189238;
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// lwz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// stw r11,-31464(r27)
	PPC_STORE_U32(r27.u32 + -31464, r11.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// std r9,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r9.u64);
	// lfs f0,3060(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3060);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lfd f0,128(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// stfs f31,12(r10)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r10.u32 + 12, temp.u32);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fdivs f0,f31,f0
	f0.f64 = double(float(f31.f64 / f0.f64));
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
loc_82189238:
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stfs f0,6064(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6064, temp.u32);
	// lfs f0,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,6068(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6068, temp.u32);
	// lfs f0,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,6072(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6072, temp.u32);
	// lfs f0,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,6076(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6076, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// or r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 | r30.u64;
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// lwz r4,-31560(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// lwz r3,-8464(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + -8464);
	// bl 0x82099210
	sub_82099210(ctx, base);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r6,-31560(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// li r8,0
	ctx.r8.s64 = 0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r28.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r28.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82197c48
	sub_82197C48(ctx, base);
	// lis r10,-32019
	ctx.r10.s64 = -2098397184;
	// addi r10,r10,27228
	ctx.r10.s64 = ctx.r10.s64 + 27228;
loc_821892B0:
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,6016(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6016, temp.u32);
	// lfs f0,4(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,6020(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6020, temp.u32);
	// lfs f0,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,6024(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6024, temp.u32);
	// lfs f0,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,6028(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6028, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// or r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 | r30.u64;
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// lwz r3,-8448(r24)
	ctx.r3.u64 = PPC_LOAD_U32(r24.u32 + -8448);
loc_821892E4:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,-31560(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// bl 0x82099210
	sub_82099210(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82194570
	sub_82194570(ctx, base);
	// bl 0x820ae360
	sub_820AE360(ctx, base);
	// cmpwi cr6,r3,90
	cr6.compare<int32_t>(ctx.r3.s32, 90, xer);
	// beq cr6,0x82189388
	if (cr6.getEQ()) goto loc_82189388;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r27,r28
	r27.u64 = r28.u64;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// ble cr6,0x82189388
	if (!cr6.getGT()) goto loc_82189388;
loc_8218931C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x820ca0b0
	sub_820CA0B0(ctx, base);
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// lwz r11,-1364(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + -1364);
	// lhz r4,2306(r11)
	ctx.r4.u64 = PPC_LOAD_U16(r11.u32 + 2306);
	// lhz r3,2304(r11)
	ctx.r3.u64 = PPC_LOAD_U16(r11.u32 + 2304);
	// bl 0x8210e1a8
	sub_8210E1A8(ctx, base);
	// lwz r11,-1364(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + -1364);
	// lhz r4,2310(r11)
	ctx.r4.u64 = PPC_LOAD_U16(r11.u32 + 2310);
	// lhz r3,2308(r11)
	ctx.r3.u64 = PPC_LOAD_U16(r11.u32 + 2308);
	// bl 0x8210e228
	sub_8210E228(ctx, base);
	// lwz r11,-1364(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + -1364);
	// lfs f1,4728(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4728);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210e310
	sub_8210E310(ctx, base);
	// lwz r11,-1364(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + -1364);
	// lfs f1,4732(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4732);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210e350
	sub_8210E350(ctx, base);
	// bl 0x8210df98
	sub_8210DF98(ctx, base);
	// bl 0x82096180
	sub_82096180(ctx, base);
	// bl 0x82139320
	sub_82139320(ctx, base);
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// bne cr6,0x82189378
	if (!cr6.getEQ()) goto loc_82189378;
	// bl 0x820bf968
	sub_820BF968(ctx, base);
loc_82189378:
	// bl 0x8213c680
	sub_8213C680(ctx, base);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// cmpw cr6,r27,r26
	cr6.compare<int32_t>(r27.s32, r26.s32, xer);
	// blt cr6,0x8218931c
	if (cr6.getLT()) goto loc_8218931C;
loc_82189388:
	// li r4,240
	ctx.r4.s64 = 240;
	// li r3,320
	ctx.r3.s64 = 320;
	// bl 0x8210e1a8
	sub_8210E1A8(ctx, base);
	// li r4,240
	ctx.r4.s64 = 240;
	// li r3,320
	ctx.r3.s64 = 320;
	// bl 0x8210e170
	sub_8210E170(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8210e228
	sub_8210E228(ctx, base);
	// bl 0x8210df98
	sub_8210DF98(ctx, base);
	// bl 0x82096180
	sub_82096180(ctx, base);
	// bl 0x8209c908
	sub_8209C908(ctx, base);
	// fmr f27,f1
	ctx.fpscr.disableFlushMode();
	f27.f64 = ctx.f1.f64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f29,2952(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2952);
	f29.f64 = double(temp.f32);
	// fcmpu cr6,f27,f30
	cr6.compare(f27.f64, f30.f64);
	// ble cr6,0x82189600
	if (!cr6.getGT()) goto loc_82189600;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82194570
	sub_82194570(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x8238d718
	sub_8238D718(ctx, base);
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x821463f0
	sub_821463F0(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8239a518
	sub_8239A518(ctx, base);
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// li r9,0
	ctx.r9.s64 = 0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r28.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r28.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r10,1176(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1176);
	// rlwinm r7,r10,0,22,18
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFE3FF;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r7,1176(r11)
	PPC_STORE_U32(r11.u32 + 1176, ctx.r7.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// oris r6,r6,16384
	ctx.r6.u64 = ctx.r6.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(r11.u32 + 24, ctx.r6.u64);
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// lwz r6,1176(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 1176);
	// rlwinm r6,r6,0,19,15
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFFFFFF1FFF;
	// stw r6,1176(r11)
	PPC_STORE_U32(r11.u32 + 1176, ctx.r6.u32);
	// ld r6,24(r11)
	ctx.r6.u64 = PPC_LOAD_U64(r11.u32 + 24);
	// oris r6,r6,16384
	ctx.r6.u64 = ctx.r6.u64 | 1073741824;
	// std r6,24(r11)
	PPC_STORE_U64(r11.u32 + 24, ctx.r6.u64);
	// lwz r6,-31560(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82197c48
	sub_82197C48(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f29,148(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f30,156(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stfs f29,144(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f0,14392(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14392);
	f0.f64 = double(temp.f32);
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// fmuls f28,f27,f0
	f28.f64 = double(float(f27.f64 * f0.f64));
	// stfs f28,152(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// stfs f29,6016(r11)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r11.u32 + 6016, temp.u32);
	// lfs f0,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	f0.f64 = double(temp.f32);
	// stfs f0,6020(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6020, temp.u32);
	// lfs f0,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	f0.f64 = double(temp.f32);
	// stfs f0,6024(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6024, temp.u32);
	// lfs f0,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	f0.f64 = double(temp.f32);
	// stfs f0,6028(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6028, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// or r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 | r30.u64;
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// lwz r4,-31560(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// lwz r3,-8860(r25)
	ctx.r3.u64 = PPC_LOAD_U32(r25.u32 + -8860);
	// bl 0x82099210
	sub_82099210(ctx, base);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r6,-31560(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// li r8,0
	ctx.r8.s64 = 0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r28.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r28.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82197c48
	sub_82197C48(ctx, base);
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// stfs f29,164(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stfs f30,168(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// stfs f28,172(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// stfs f29,160(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// stfs f29,6016(r11)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r11.u32 + 6016, temp.u32);
	// lfs f0,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	f0.f64 = double(temp.f32);
	// stfs f0,6020(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6020, temp.u32);
	// lfs f0,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	f0.f64 = double(temp.f32);
	// stfs f0,6024(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6024, temp.u32);
	// lfs f0,172(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 172);
	f0.f64 = double(temp.f32);
	// stfs f0,6028(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6028, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// or r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 | r30.u64;
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// lwz r4,-31560(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// lwz r3,-8860(r25)
	ctx.r3.u64 = PPC_LOAD_U32(r25.u32 + -8860);
	// bl 0x82099210
	sub_82099210(ctx, base);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r6,-31560(r29)
	ctx.r6.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// li r8,0
	ctx.r8.s64 = 0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r28.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r28.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82197c48
	sub_82197C48(ctx, base);
	// lis r10,-32019
	ctx.r10.s64 = -2098397184;
	// lwz r11,13356(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// li r5,0
	ctx.r5.s64 = 0;
	// lfs f0,27224(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 27224);
	f0.f64 = double(temp.f32);
	// lis r10,-32019
	ctx.r10.s64 = -2098397184;
	// lfs f13,27220(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 27220);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// fmuls f13,f13,f27
	ctx.f13.f64 = double(float(ctx.f13.f64 * f27.f64));
	// stfs f13,188(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// lfd f13,-20152(r10)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + -20152);
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// fmul f12,f0,f13
	ctx.f12.f64 = f0.f64 * ctx.f13.f64;
	// lfd f13,-20160(r10)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + -20160);
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// fmul f11,f0,f13
	ctx.f11.f64 = f0.f64 * ctx.f13.f64;
	// lfd f13,-20168(r10)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r10.u32 + -20168);
	// fmul f13,f0,f13
	ctx.f13.f64 = f0.f64 * ctx.f13.f64;
	// frsp f0,f12
	f0.f64 = double(float(ctx.f12.f64));
	// stfs f0,176(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// frsp f12,f11
	ctx.f12.f64 = double(float(ctx.f11.f64));
	// stfs f12,180(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// stfs f13,184(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// stfs f0,6016(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6016, temp.u32);
	// lfs f0,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	f0.f64 = double(temp.f32);
	// stfs f0,6020(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6020, temp.u32);
	// lfs f0,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	f0.f64 = double(temp.f32);
	// stfs f0,6024(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6024, temp.u32);
	// lfs f0,188(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 188);
	f0.f64 = double(temp.f32);
	// stfs f0,6028(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 6028, temp.u32);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// or r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 | r30.u64;
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// lwz r4,-31560(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + -31560);
	// lwz r3,-8448(r24)
	ctx.r3.u64 = PPC_LOAD_U32(r24.u32 + -8448);
	// bl 0x82099210
	sub_82099210(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82194570
	sub_82194570(ctx, base);
	// bl 0x8209c808
	sub_8209C808(ctx, base);
loc_82189600:
	// bl 0x8209e0d0
	sub_8209E0D0(ctx, base);
	// bl 0x82091fb8
	sub_82091FB8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82189618
	if (cr6.getEQ()) goto loc_82189618;
	// bl 0x82092030
	sub_82092030(ctx, base);
loc_82189618:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r4,20
	ctx.r4.s64 = 20;
	// addi r30,r11,2334
	r30.s64 = r11.s64 + 2334;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// lfs f1,-31536(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -31536);
	ctx.f1.f64 = double(temp.f32);
	// stfd f1,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.f1.u64);
	// ld r6,40(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 40);
	// bl 0x823eda88
	sub_823EDA88(ctx, base);
	// lis r29,-31991
	r29.s64 = -2096562176;
	// addi r5,r1,192
	ctx.r5.s64 = ctx.r1.s64 + 192;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// lwz r4,-31556(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + -31556);
	// bl 0x8209bcd8
	sub_8209BCD8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// li r5,15
	ctx.r5.s64 = 15;
	// li r6,15
	ctx.r6.s64 = 15;
	// bl 0x820914c0
	sub_820914C0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f29.f64;
	// bl 0x8209bbb8
	sub_8209BBB8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// li r5,128
	ctx.r5.s64 = 128;
	// li r6,255
	ctx.r6.s64 = 255;
	// li r7,128
	ctx.r7.s64 = 128;
	// bl 0x8209baa8
	sub_8209BAA8(ctx, base);
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x8209b890
	sub_8209B890(ctx, base);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8209b890
	sub_8209B890(ctx, base);
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x8209b890
	sub_8209B890(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8209b890
	sub_8209B890(ctx, base);
	// lis r11,-32019
	r11.s64 = -2098397184;
	// addi r11,r11,27204
	r11.s64 = r11.s64 + 27204;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpwi cr6,r10,120
	cr6.compare<int32_t>(ctx.r10.s32, 120, xer);
	// bge cr6,0x8218974c
	if (!cr6.getLT()) goto loc_8218974C;
	// lfs f1,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// li r4,20
	ctx.r4.s64 = 20;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// stfd f1,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.f1.u64);
	// addi r3,r1,192
	ctx.r3.s64 = ctx.r1.s64 + 192;
	// ld r6,40(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 40);
	// bl 0x823eda88
	sub_823EDA88(ctx, base);
	// addi r5,r1,192
	ctx.r5.s64 = ctx.r1.s64 + 192;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// lwz r4,-31556(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + -31556);
	// bl 0x8209bcd8
	sub_8209BCD8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// li r5,15
	ctx.r5.s64 = 15;
	// li r6,30
	ctx.r6.s64 = 30;
	// bl 0x820914c0
	sub_820914C0(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f29.f64;
	// bl 0x8209bbb8
	sub_8209BBB8(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// li r5,255
	ctx.r5.s64 = 255;
	// li r6,128
	ctx.r6.s64 = 128;
	// li r7,128
	ctx.r7.s64 = 128;
	// bl 0x8209baa8
	sub_8209BAA8(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8209b890
	sub_8209B890(ctx, base);
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x8209b890
	sub_8209B890(ctx, base);
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x8209b890
	sub_8209B890(ctx, base);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8209b890
	sub_8209B890(ctx, base);
loc_8218974C:
	// lis r11,-32015
	r11.s64 = -2098135040;
	// lbz r11,-13404(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + -13404);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821898b0
	if (cr6.getEQ()) goto loc_821898B0;
	// lis r30,-32019
	r30.s64 = -2098397184;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,27216(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 27216);
	f0.f64 = double(temp.f32);
	// fsubs f13,f31,f0
	ctx.f13.f64 = double(float(f31.f64 - f0.f64));
	// lfs f0,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
	// fmuls f28,f13,f0
	f28.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x8210e400
	sub_8210E400(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// std r11,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, r11.u64);
	// lfd f0,128(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f29,f0
	f29.f64 = double(float(f0.f64));
	// bl 0x8210e2f0
	sub_8210E2F0(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// std r11,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, r11.u64);
	// lfd f0,128(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f27,f0
	f27.f64 = double(float(f0.f64));
	// bl 0x8210e290
	sub_8210E290(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// std r11,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, r11.u64);
	// lfd f0,128(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f26,f0
	f26.f64 = double(float(f0.f64));
	// bl 0x8210e218
	sub_8210E218(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// lfs f0,27216(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 27216);
	f0.f64 = double(temp.f32);
	// fadds f0,f28,f0
	f0.f64 = double(float(f28.f64 + f0.f64));
	// lis r30,-32019
	r30.s64 = -2098397184;
	// fmadds f30,f26,f28,f29
	f30.f64 = double(float(f26.f64 * f28.f64 + f29.f64));
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r28.u32);
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r28.u32);
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// std r11,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, r11.u64);
	// lfd f13,128(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// fmadds f29,f0,f26,f29
	f29.f64 = double(float(f0.f64 * f26.f64 + f29.f64));
	// fmr f5,f30
	ctx.f5.f64 = f30.f64;
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmr f7,f29
	ctx.f7.f64 = f29.f64;
	// fmadds f28,f13,f28,f27
	f28.f64 = double(float(ctx.f13.f64 * f28.f64 + f27.f64));
	// fmadds f27,f0,f13,f27
	f27.f64 = double(float(f0.f64 * ctx.f13.f64 + f27.f64));
	// lfs f0,27212(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 27212);
	f0.f64 = double(temp.f32);
	// fadds f8,f28,f0
	ctx.f8.f64 = double(float(f28.f64 + f0.f64));
	// fsubs f6,f28,f0
	ctx.f6.f64 = double(float(f28.f64 - f0.f64));
	// bl 0x82096ba8
	sub_82096BA8(ctx, base);
	// lfs f0,27212(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 27212);
	f0.f64 = double(temp.f32);
	// fmr f7,f29
	ctx.f7.f64 = f29.f64;
	// fadds f8,f27,f0
	ctx.f8.f64 = double(float(f27.f64 + f0.f64));
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r28.u32);
	// fsubs f6,f27,f0
	ctx.f6.f64 = double(float(f27.f64 - f0.f64));
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r28.u32);
	// fmr f5,f30
	ctx.f5.f64 = f30.f64;
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x82096ba8
	sub_82096BA8(ctx, base);
	// lfs f0,27212(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 27212);
	f0.f64 = double(temp.f32);
	// fmr f8,f27
	ctx.f8.f64 = f27.f64;
	// fadds f7,f30,f0
	ctx.f7.f64 = double(float(f30.f64 + f0.f64));
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r28.u32);
	// fmr f6,f28
	ctx.f6.f64 = f28.f64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r28.u32);
	// fsubs f5,f30,f0
	ctx.f5.f64 = double(float(f30.f64 - f0.f64));
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x82096ba8
	sub_82096BA8(ctx, base);
	// lfs f0,27212(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 27212);
	f0.f64 = double(temp.f32);
	// fmr f8,f27
	ctx.f8.f64 = f27.f64;
	// fadds f7,f29,f0
	ctx.f7.f64 = double(float(f29.f64 + f0.f64));
	// stw r28,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r28.u32);
	// fmr f6,f28
	ctx.f6.f64 = f28.f64;
	// fsubs f5,f29,f0
	ctx.f5.f64 = double(float(f29.f64 - f0.f64));
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// stw r28,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r28.u32);
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x82096ba8
	sub_82096BA8(ctx, base);
loc_821898B0:
	// bl 0x8214c5a8
	sub_8214C5A8(ctx, base);
	// mr r4,r21
	ctx.r4.u64 = r21.u64;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82195f68
	sub_82195F68(ctx, base);
loc_821898C0:
	// addi r1,r1,384
	ctx.r1.s64 = ctx.r1.s64 + 384;
	// addi r12,r1,-96
	r12.s64 = ctx.r1.s64 + -96;
	// bl 0x823ed58c
	// b 0x823ed16c
	return;
}

__attribute__((alias("__imp__sub_821898D0"))) PPC_WEAK_FUNC(sub_821898D0);
PPC_FUNC_IMPL(__imp__sub_821898D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCVRegister v27{};
	PPCVRegister v28{};
	PPCVRegister v29{};
	PPCVRegister v30{};
	PPCVRegister v31{};
	PPCVRegister v118{};
	PPCVRegister v119{};
	PPCVRegister v120{};
	PPCVRegister v121{};
	PPCVRegister v122{};
	PPCVRegister v123{};
	PPCVRegister v124{};
	PPCVRegister v125{};
	PPCVRegister v126{};
	PPCVRegister v127{};
	PPCRegister temp{};
	PPCVRegister vTemp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed104
	// addi r12,r1,-144
	r12.s64 = ctx.r1.s64 + -144;
	// bl 0x823ed544
	// addi r12,r1,-192
	r12.s64 = ctx.r1.s64 + -192;
	// bl 0x823ef314
	// stwu r1,-672(r1)
	ea = -672 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r1,272
	ctx.r3.s64 = ctx.r1.s64 + 272;
	// lfs f29,2776(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f29.f64 = double(temp.f32);
	// fmr f1,f29
	ctx.f1.f64 = f29.f64;
	// bl 0x8209ea50
	sub_8209EA50(ctx, base);
	// li r3,3
	ctx.r3.s64 = 3;
	// bl 0x8209e1d0
	sub_8209E1D0(ctx, base);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// bl 0x8238d718
	sub_8238D718(ctx, base);
	// li r18,0
	r18.s64 = 0;
	// addi r11,r1,152
	r11.s64 = ctx.r1.s64 + 152;
	// lwz r4,112(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lis r5,6184
	ctx.r5.s64 = 405274624;
	// lwz r3,120(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// addi r7,r1,152
	ctx.r7.s64 = ctx.r1.s64 + 152;
	// li r6,0
	ctx.r6.s64 = 0;
	// ori r5,r5,390
	ctx.r5.u64 = ctx.r5.u64 | 390;
	// std r18,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r18.u64);
	// stw r18,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r18.u32);
	// stw r18,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r18.u32);
	// stw r18,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r18.u32);
	// bl 0x8218bbf8
	sub_8218BBF8(ctx, base);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lwz r4,112(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lis r8,10280
	ctx.r8.s64 = 673710080;
	// li r10,3
	ctx.r10.s64 = 3;
	// li r9,0
	ctx.r9.s64 = 0;
	// ori r8,r8,262
	ctx.r8.u64 = ctx.r8.u64 | 262;
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r3,-31552(r11)
	PPC_STORE_U32(r11.u32 + -31552, ctx.r3.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r3,120(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// li r5,1
	ctx.r5.s64 = 1;
	// bl 0x8218bad8
	sub_8218BAD8(ctx, base);
	// lis r15,-31991
	r15.s64 = -2096562176;
	// lis r8,10280
	ctx.r8.s64 = 673710080;
	// lwz r4,112(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// li r10,3
	ctx.r10.s64 = 3;
	// li r9,0
	ctx.r9.s64 = 0;
	// ori r8,r8,390
	ctx.r8.u64 = ctx.r8.u64 | 390;
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r3,-31548(r15)
	PPC_STORE_U32(r15.u32 + -31548, ctx.r3.u32);
	// li r6,1
	ctx.r6.s64 = 1;
	// lwz r3,120(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// li r5,1
	ctx.r5.s64 = 1;
	// bl 0x8218bad8
	sub_8218BAD8(ctx, base);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// stw r3,-31560(r11)
	PPC_STORE_U32(r11.u32 + -31560, ctx.r3.u32);
	// bl 0x8238ac10
	sub_8238AC10(ctx, base);
	// bl 0x8238db28
	sub_8238DB28(ctx, base);
	// bl 0x8238cf90
	sub_8238CF90(ctx, base);
	// bl 0x823d22e0
	sub_823D22E0(ctx, base);
	// bl 0x823d22e0
	sub_823D22E0(ctx, base);
	// bl 0x82091220
	sub_82091220(ctx, base);
	// bl 0x8209cab8
	sub_8209CAB8(ctx, base);
	// bl 0x82090248
	sub_82090248(ctx, base);
	// bl 0x8209e940
	sub_8209E940(ctx, base);
	// bl 0x8209e120
	sub_8209E120(ctx, base);
	// bl 0x82093478
	sub_82093478(ctx, base);
	// bl 0x820998a8
	sub_820998A8(ctx, base);
	// lwz r4,112(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r3,120(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// bl 0x82099b40
	sub_82099B40(ctx, base);
	// bl 0x82144128
	sub_82144128(ctx, base);
	// bl 0x820ae398
	sub_820AE398(ctx, base);
	// bl 0x8214c2d8
	sub_8214C2D8(ctx, base);
	// bl 0x821859a8
	sub_821859A8(ctx, base);
	// bl 0x82188028
	sub_82188028(ctx, base);
	// li r3,12
	ctx.r3.s64 = 12;
	// bl 0x8209d088
	sub_8209D088(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82189a30
	if (cr6.getEQ()) goto loc_82189A30;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,-20028
	ctx.r4.s64 = r11.s64 + -20028;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,14220(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14220);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8209b690
	sub_8209B690(ctx, base);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// stw r3,-31556(r11)
	PPC_STORE_U32(r11.u32 + -31556, ctx.r3.u32);
	// b 0x82189a3c
	goto loc_82189A3C;
loc_82189A30:
	// lis r10,-31991
	ctx.r10.s64 = -2096562176;
	// mr r11,r18
	r11.u64 = r18.u64;
	// stw r11,-31556(r10)
	PPC_STORE_U32(ctx.r10.u32 + -31556, r11.u32);
loc_82189A3C:
	// li r3,12
	ctx.r3.s64 = 12;
	// bl 0x8209d088
	sub_8209D088(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82189a6c
	if (cr6.getEQ()) goto loc_82189A6C;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,-20072
	ctx.r4.s64 = r11.s64 + -20072;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,2952(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2952);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8209b690
	sub_8209B690(ctx, base);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// stw r3,-31544(r11)
	PPC_STORE_U32(r11.u32 + -31544, ctx.r3.u32);
	// b 0x82189a78
	goto loc_82189A78;
loc_82189A6C:
	// lis r10,-31991
	ctx.r10.s64 = -2096562176;
	// mr r11,r18
	r11.u64 = r18.u64;
	// stw r11,-31544(r10)
	PPC_STORE_U32(ctx.r10.u32 + -31544, r11.u32);
loc_82189A78:
	// lis r11,-31991
	r11.s64 = -2096562176;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r5,r11,-31540
	ctx.r5.s64 = r11.s64 + -31540;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r3,r11,-20124
	ctx.r3.s64 = r11.s64 + -20124;
	// bl 0x82090420
	sub_82090420(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r10,r1,148
	ctx.r10.s64 = ctx.r1.s64 + 148;
	// vspltisw128 v127,0
	_mm_store_si128((__m128i*)v127.u32, _mm_set1_epi32(int(0x0)));
	// addi r9,r1,116
	ctx.r9.s64 = ctx.r1.s64 + 116;
	// addi r8,r1,136
	ctx.r8.s64 = ctx.r1.s64 + 136;
	// addi r7,r1,128
	ctx.r7.s64 = ctx.r1.s64 + 128;
	// lfs f31,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f31,148(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// vupkd3d128 v126,v127,4
	temp.f32 = 3.0f;
	temp.s32 += v127.s16[1];
	vTemp.f32[3] = temp.f32;
	temp.f32 = 3.0f;
	temp.s32 += v127.s16[0];
	vTemp.f32[2] = temp.f32;
	vTemp.f32[1] = 0.0f;
	vTemp.f32[0] = 1.0f;
	v126 = vTemp;
	// lvlx v0,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r10,r1,148
	ctx.r10.s64 = ctx.r1.s64 + 148;
	// stfs f31,136(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// stfs f31,144(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f0,15088(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15088);
	f0.f64 = double(temp.f32);
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// stfs f0,116(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// vpermwi128 v125,v126,234
	_mm_store_si128((__m128i*)v125.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)v126.u32), 0x15));
	// lvlx v13,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r9,r1,116
	ctx.r9.s64 = ctx.r1.s64 + 116;
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// stfs f31,116(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// addi r8,r1,116
	ctx.r8.s64 = ctx.r1.s64 + 116;
	// lvlx v12,0,r11
	temp.u32 = r11.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r11,r1,136
	r11.s64 = ctx.r1.s64 + 136;
	// vrlimi128 v0,v12,4,3
	_mm_store_ps(ctx.v0.f32, _mm_blend_ps(_mm_load_ps(ctx.v0.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// stfs f31,136(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// stfs f31,148(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// vpermwi128 v124,v126,186
	_mm_store_si128((__m128i*)v124.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)v126.u32), 0x45));
	// lvlx v11,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// stfs f31,128(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// vpermwi128 v123,v126,174
	_mm_store_si128((__m128i*)v123.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)v126.u32), 0x51));
	// vor v1,v0,v0
	_mm_store_si128((__m128i*)ctx.v1.u8, _mm_load_si128((__m128i*)ctx.v0.u8));
	// lvlx v0,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvlx v10,0,r11
	temp.u32 = r11.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addi r9,r1,144
	ctx.r9.s64 = ctx.r1.s64 + 144;
	// addi r11,r1,136
	r11.s64 = ctx.r1.s64 + 136;
	// lvlx v12,0,r7
	temp.u32 = ctx.r7.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v11,v12,4,3
	_mm_store_ps(ctx.v11.f32, _mm_blend_ps(_mm_load_ps(ctx.v11.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// stfs f31,128(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// vrlimi128 v1,v13,3,2
	_mm_store_ps(ctx.v1.f32, _mm_blend_ps(_mm_load_ps(ctx.v1.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// stfs f31,136(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// vrlimi128 v10,v0,4,3
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// stfs f29,144(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f31,116(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// vpermwi128 v122,v126,171
	_mm_store_si128((__m128i*)v122.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)v126.u32), 0x54));
	// lvlx v0,0,r10
	temp.u32 = ctx.r10.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvlx v13,0,r11
	temp.u32 = r11.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvlx v12,0,r9
	temp.u32 = ctx.r9.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v13,v0,4,3
	_mm_store_ps(ctx.v13.f32, _mm_blend_ps(_mm_load_ps(ctx.v13.f32), _mm_permute_ps(_mm_load_ps(ctx.v0.f32), 57), 4));
	// lvlx v3,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v3.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vrlimi128 v10,v11,3,2
	_mm_store_ps(ctx.v10.f32, _mm_blend_ps(_mm_load_ps(ctx.v10.f32), _mm_permute_ps(_mm_load_ps(ctx.v11.f32), 78), 3));
	// vrlimi128 v3,v12,4,3
	_mm_store_ps(ctx.v3.f32, _mm_blend_ps(_mm_load_ps(ctx.v3.f32), _mm_permute_ps(_mm_load_ps(ctx.v12.f32), 57), 4));
	// vsubfp v2,v10,v1
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v2.f32, _mm_sub_ps(_mm_load_ps(ctx.v10.f32), _mm_load_ps(ctx.v1.f32)));
	// vrlimi128 v3,v13,3,2
	_mm_store_ps(ctx.v3.f32, _mm_blend_ps(_mm_load_ps(ctx.v3.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 78), 3));
	// bl 0x821888f8
	sub_821888F8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r9,16
	ctx.r9.s64 = 16;
	// vpermwi128 v126,v126,171
	_mm_store_si128((__m128i*)v126.u32, _mm_shuffle_epi32(_mm_load_si128((__m128i*)v126.u32), 0x54));
	// li r8,32
	ctx.r8.s64 = 32;
	// li r7,48
	ctx.r7.s64 = 48;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lvx128 v121,r0,r11
	_mm_store_si128((__m128i*)v121.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r3,r1,136
	ctx.r3.s64 = ctx.r1.s64 + 136;
	// lvx128 v120,r11,r9
	_mm_store_si128((__m128i*)v120.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32 + ctx.r9.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v119,r11,r8
	_mm_store_si128((__m128i*)v119.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32 + ctx.r8.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lvx128 v118,r11,r7
	_mm_store_si128((__m128i*)v118.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32 + ctx.r7.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// lfs f1,14152(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14152);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x821889d8
	sub_821889D8(ctx, base);
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// extsw r10,r11
	ctx.r10.s64 = r11.s32;
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lfs f13,136(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	f0.f64 = double(temp.f32);
	// std r10,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r10.u64);
	// extsw r9,r11
	ctx.r9.s64 = r11.s32;
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// lis r11,-32254
	r11.s64 = -2113798144;
	// stfs f0,180(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// vmrghw128 v11,v120,v118
	_mm_store_si128((__m128i*)ctx.v11.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)v118.u32), _mm_load_si128((__m128i*)v120.u32)));
	// vor128 v8,v127,v127
	_mm_store_si128((__m128i*)ctx.v8.u8, _mm_load_si128((__m128i*)v127.u8));
	// vmrghw128 v12,v121,v119
	_mm_store_si128((__m128i*)ctx.v12.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)v119.u32), _mm_load_si128((__m128i*)v121.u32)));
	// vor128 v7,v127,v127
	_mm_store_si128((__m128i*)ctx.v7.u8, _mm_load_si128((__m128i*)v127.u8));
	// vmrglw128 v10,v121,v119
	_mm_store_si128((__m128i*)ctx.v10.u32, _mm_unpacklo_epi32(_mm_load_si128((__m128i*)v119.u32), _mm_load_si128((__m128i*)v121.u32)));
	// std r9,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r9.u64);
	// lfd f12,136(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// lfs f13,-20128(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -20128);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// stfs f13,184(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// vmrglw128 v9,v120,v118
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_unpacklo_epi32(_mm_load_si128((__m128i*)v118.u32), _mm_load_si128((__m128i*)v120.u32)));
	// vmrghw v0,v12,v11
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v11.u32), _mm_load_si128((__m128i*)ctx.v12.u32)));
	// vmrglw v12,v12,v11
	_mm_store_si128((__m128i*)ctx.v12.u32, _mm_unpacklo_epi32(_mm_load_si128((__m128i*)ctx.v11.u32), _mm_load_si128((__m128i*)ctx.v12.u32)));
	// lfs f13,-20132(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -20132);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,188(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// vmrglw v11,v10,v9
	_mm_store_si128((__m128i*)ctx.v11.u32, _mm_unpacklo_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), _mm_load_si128((__m128i*)ctx.v10.u32)));
	// lfd f13,128(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// vmsum4fp128 v6,v124,v0
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v6.f32, _mm_dp_ps(_mm_load_ps(v124.f32), _mm_load_ps(ctx.v0.f32), 0xFF));
	// fcfid f13,f13
	ctx.fpscr.disableFlushModeUnconditional();
	ctx.f13.f64 = double(ctx.f13.s64);
	// vmsum4fp128 v4,v122,v0
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v4.f32, _mm_dp_ps(_mm_load_ps(v122.f32), _mm_load_ps(ctx.v0.f32), 0xFF));
	// vmsum4fp128 v5,v123,v0
	_mm_store_ps(ctx.v5.f32, _mm_dp_ps(_mm_load_ps(v123.f32), _mm_load_ps(ctx.v0.f32), 0xFF));
	// vmsum4fp128 v2,v125,v12
	_mm_store_ps(ctx.v2.f32, _mm_dp_ps(_mm_load_ps(v125.f32), _mm_load_ps(ctx.v12.f32), 0xFF));
	// frsp f12,f12
	ctx.fpscr.disableFlushModeUnconditional();
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// vmsum4fp128 v31,v125,v11
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(v31.f32, _mm_dp_ps(_mm_load_ps(v125.f32), _mm_load_ps(ctx.v11.f32), 0xFF));
	// vmsum4fp128 v30,v124,v11
	_mm_store_ps(v30.f32, _mm_dp_ps(_mm_load_ps(v124.f32), _mm_load_ps(ctx.v11.f32), 0xFF));
	// vmsum4fp128 v29,v123,v11
	_mm_store_ps(v29.f32, _mm_dp_ps(_mm_load_ps(v123.f32), _mm_load_ps(ctx.v11.f32), 0xFF));
	// vmsum4fp128 v1,v124,v12
	_mm_store_ps(ctx.v1.f32, _mm_dp_ps(_mm_load_ps(v124.f32), _mm_load_ps(ctx.v12.f32), 0xFF));
	// vmsum4fp128 v28,v123,v12
	_mm_store_ps(v28.f32, _mm_dp_ps(_mm_load_ps(v123.f32), _mm_load_ps(ctx.v12.f32), 0xFF));
	// vmsum4fp128 v11,v122,v11
	_mm_store_ps(ctx.v11.f32, _mm_dp_ps(_mm_load_ps(v122.f32), _mm_load_ps(ctx.v11.f32), 0xFF));
	// vmsum4fp128 v12,v122,v12
	_mm_store_ps(ctx.v12.f32, _mm_dp_ps(_mm_load_ps(v122.f32), _mm_load_ps(ctx.v12.f32), 0xFF));
	// frsp f13,f13
	ctx.fpscr.disableFlushModeUnconditional();
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fdivs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 / ctx.f12.f64));
	// vmrghw v11,v12,v11
	_mm_store_si128((__m128i*)ctx.v11.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v11.u32), _mm_load_si128((__m128i*)ctx.v12.u32)));
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// stfs f0,176(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// addi r11,r1,176
	r11.s64 = ctx.r1.s64 + 176;
	// lvx128 v13,r0,r11
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + ((r11.u32) & ~0xF))), _mm_load_si128((__m128i*)VectorMaskL)));
	// vrlimi128 v8,v13,8,0
	_mm_store_ps(ctx.v8.f32, _mm_blend_ps(_mm_load_ps(ctx.v8.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 228), 8));
	// vrlimi128 v7,v13,4,0
	_mm_store_ps(ctx.v7.f32, _mm_blend_ps(_mm_load_ps(ctx.v7.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 228), 4));
	// vrlimi128 v126,v13,2,0
	_mm_store_ps(v126.f32, _mm_blend_ps(_mm_load_ps(v126.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 228), 2));
	// vrlimi128 v127,v13,2,1
	_mm_store_ps(v127.f32, _mm_blend_ps(_mm_load_ps(v127.f32), _mm_permute_ps(_mm_load_ps(ctx.v13.f32), 147), 2));
	// vmrghw v13,v10,v9
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v9.u32), _mm_load_si128((__m128i*)ctx.v10.u32)));
	// vmsum4fp128 v10,v125,v0
	ctx.fpscr.enableFlushModeUnconditional();
	_mm_store_ps(ctx.v10.f32, _mm_dp_ps(_mm_load_ps(v125.f32), _mm_load_ps(ctx.v0.f32), 0xFF));
	// vmrghw128 v9,v8,v126
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)v126.u32), _mm_load_si128((__m128i*)ctx.v8.u32)));
	// vmsum4fp128 v0,v125,v13
	_mm_store_ps(ctx.v0.f32, _mm_dp_ps(_mm_load_ps(v125.f32), _mm_load_ps(ctx.v13.f32), 0xFF));
	// vmsum4fp128 v3,v124,v13
	_mm_store_ps(ctx.v3.f32, _mm_dp_ps(_mm_load_ps(v124.f32), _mm_load_ps(ctx.v13.f32), 0xFF));
	// vmsum4fp128 v27,v123,v13
	_mm_store_ps(v27.f32, _mm_dp_ps(_mm_load_ps(v123.f32), _mm_load_ps(ctx.v13.f32), 0xFF));
	// vmsum4fp128 v13,v122,v13
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(v122.f32), _mm_load_ps(ctx.v13.f32), 0xFF));
	// vmrghw v0,v10,v0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), _mm_load_si128((__m128i*)ctx.v10.u32)));
	// vmrghw v10,v6,v3
	_mm_store_si128((__m128i*)ctx.v10.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v3.u32), _mm_load_si128((__m128i*)ctx.v6.u32)));
	// vmrghw v6,v2,v31
	_mm_store_si128((__m128i*)ctx.v6.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)v31.u32), _mm_load_si128((__m128i*)ctx.v2.u32)));
	// vmrghw v5,v5,v27
	_mm_store_si128((__m128i*)ctx.v5.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)v27.u32), _mm_load_si128((__m128i*)ctx.v5.u32)));
	// vmrghw v2,v28,v29
	_mm_store_si128((__m128i*)ctx.v2.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)v29.u32), _mm_load_si128((__m128i*)v28.u32)));
	// vmrghw v3,v1,v30
	_mm_store_si128((__m128i*)ctx.v3.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)v30.u32), _mm_load_si128((__m128i*)ctx.v1.u32)));
	// vmrghw v0,v0,v6
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v6.u32), _mm_load_si128((__m128i*)ctx.v0.u32)));
	// vmrghw v6,v4,v13
	_mm_store_si128((__m128i*)ctx.v6.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), _mm_load_si128((__m128i*)ctx.v4.u32)));
	// vmrghw v12,v5,v2
	_mm_store_si128((__m128i*)ctx.v12.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v2.u32), _mm_load_si128((__m128i*)ctx.v5.u32)));
	// vmrglw128 v5,v8,v126
	_mm_store_si128((__m128i*)ctx.v5.u32, _mm_unpacklo_epi32(_mm_load_si128((__m128i*)v126.u32), _mm_load_si128((__m128i*)ctx.v8.u32)));
	// vmrghw v13,v10,v3
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v3.u32), _mm_load_si128((__m128i*)ctx.v10.u32)));
	// vmrghw v11,v6,v11
	_mm_store_si128((__m128i*)ctx.v11.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v11.u32), _mm_load_si128((__m128i*)ctx.v6.u32)));
	// vmrghw128 v6,v7,v127
	_mm_store_si128((__m128i*)ctx.v6.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)v127.u32), _mm_load_si128((__m128i*)ctx.v7.u32)));
	// vmrglw128 v7,v7,v127
	_mm_store_si128((__m128i*)ctx.v7.u32, _mm_unpacklo_epi32(_mm_load_si128((__m128i*)v127.u32), _mm_load_si128((__m128i*)ctx.v7.u32)));
	// vmrghw v10,v9,v6
	_mm_store_si128((__m128i*)ctx.v10.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v6.u32), _mm_load_si128((__m128i*)ctx.v9.u32)));
	// vmrglw v9,v9,v6
	_mm_store_si128((__m128i*)ctx.v9.u32, _mm_unpacklo_epi32(_mm_load_si128((__m128i*)ctx.v6.u32), _mm_load_si128((__m128i*)ctx.v9.u32)));
	// vmrghw v8,v5,v7
	_mm_store_si128((__m128i*)ctx.v8.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), _mm_load_si128((__m128i*)ctx.v5.u32)));
	// vmrglw v7,v5,v7
	_mm_store_si128((__m128i*)ctx.v7.u32, _mm_unpacklo_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), _mm_load_si128((__m128i*)ctx.v5.u32)));
	// vmsum4fp128 v6,v0,v10
	_mm_store_ps(ctx.v6.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v10.f32), 0xFF));
	// vmsum4fp128 v5,v0,v9
	_mm_store_ps(ctx.v5.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v9.f32), 0xFF));
	// vmsum4fp128 v2,v0,v8
	_mm_store_ps(ctx.v2.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v8.f32), 0xFF));
	// vmsum4fp128 v4,v13,v9
	_mm_store_ps(ctx.v4.f32, _mm_dp_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v9.f32), 0xFF));
	// vmsum4fp128 v3,v13,v10
	_mm_store_ps(ctx.v3.f32, _mm_dp_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v10.f32), 0xFF));
	// vmsum4fp128 v0,v0,v7
	_mm_store_ps(ctx.v0.f32, _mm_dp_ps(_mm_load_ps(ctx.v0.f32), _mm_load_ps(ctx.v7.f32), 0xFF));
	// vmsum4fp128 v1,v13,v7
	_mm_store_ps(ctx.v1.f32, _mm_dp_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v7.f32), 0xFF));
	// vmrghw v0,v5,v0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), _mm_load_si128((__m128i*)ctx.v5.u32)));
	// vmsum4fp128 v13,v13,v8
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(ctx.v13.f32), _mm_load_ps(ctx.v8.f32), 0xFF));
	// vmrghw v6,v6,v2
	_mm_store_si128((__m128i*)ctx.v6.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v2.u32), _mm_load_si128((__m128i*)ctx.v6.u32)));
	// vmsum4fp128 v31,v12,v7
	_mm_store_ps(v31.f32, _mm_dp_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v7.f32), 0xFF));
	// addi r11,r1,208
	r11.s64 = ctx.r1.s64 + 208;
	// vmsum4fp128 v30,v12,v9
	_mm_store_ps(v30.f32, _mm_dp_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v9.f32), 0xFF));
	// vmsum4fp128 v29,v12,v8
	_mm_store_ps(v29.f32, _mm_dp_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v8.f32), 0xFF));
	// vmsum4fp128 v12,v12,v10
	_mm_store_ps(ctx.v12.f32, _mm_dp_ps(_mm_load_ps(ctx.v12.f32), _mm_load_ps(ctx.v10.f32), 0xFF));
	// vmrghw v0,v6,v0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), _mm_load_si128((__m128i*)ctx.v6.u32)));
	// vmsum4fp128 v7,v11,v7
	_mm_store_ps(ctx.v7.f32, _mm_dp_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v7.f32), 0xFF));
	// vmsum4fp128 v9,v11,v9
	_mm_store_ps(ctx.v9.f32, _mm_dp_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v9.f32), 0xFF));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r1,224
	r11.s64 = ctx.r1.s64 + 224;
	// vmrghw v5,v4,v1
	_mm_store_si128((__m128i*)ctx.v5.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v1.u32), _mm_load_si128((__m128i*)ctx.v4.u32)));
	// vmrghw v13,v3,v13
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), _mm_load_si128((__m128i*)ctx.v3.u32)));
	// vmrghw v4,v30,v31
	_mm_store_si128((__m128i*)ctx.v4.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)v31.u32), _mm_load_si128((__m128i*)v30.u32)));
	// vmrghw v13,v13,v5
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v5.u32), _mm_load_si128((__m128i*)ctx.v13.u32)));
	// vmrghw v12,v12,v29
	_mm_store_si128((__m128i*)ctx.v12.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)v29.u32), _mm_load_si128((__m128i*)ctx.v12.u32)));
	// vmrghw v0,v12,v4
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v4.u32), _mm_load_si128((__m128i*)ctx.v12.u32)));
	// vmsum4fp128 v12,v11,v10
	_mm_store_ps(ctx.v12.f32, _mm_dp_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v10.f32), 0xFF));
	// stvx128 v13,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// vmsum4fp128 v13,v11,v8
	_mm_store_ps(ctx.v13.f32, _mm_dp_ps(_mm_load_ps(ctx.v11.f32), _mm_load_ps(ctx.v8.f32), 0xFF));
	// addi r11,r1,240
	r11.s64 = ctx.r1.s64 + 240;
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// vmrghw v0,v9,v7
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v7.u32), _mm_load_si128((__m128i*)ctx.v9.u32)));
	// addi r11,r1,256
	r11.s64 = ctx.r1.s64 + 256;
	// vmrghw v13,v12,v13
	_mm_store_si128((__m128i*)ctx.v13.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v13.u32), _mm_load_si128((__m128i*)ctx.v12.u32)));
	// vmrghw v0,v13,v0
	_mm_store_si128((__m128i*)ctx.v0.u32, _mm_unpackhi_epi32(_mm_load_si128((__m128i*)ctx.v0.u32), _mm_load_si128((__m128i*)ctx.v13.u32)));
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// bl 0x823b34f8
	sub_823B34F8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x823b34f8
	sub_823B34F8(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r22,r11,-20144
	r22.s64 = r11.s64 + -20144;
	// lis r11,-32019
	r11.s64 = -2098397184;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r26,r11,27204
	r26.s64 = r11.s64 + 27204;
	// lis r11,15
	r11.s64 = 983040;
	// lfs f27,13960(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 13960);
	f27.f64 = double(temp.f32);
	// lis r16,-31991
	r16.s64 = -2096562176;
	// ori r23,r11,16960
	r23.u64 = r11.u64 | 16960;
	// lis r11,-10314
	r11.s64 = -675938304;
	// lfs f28,6576(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6576);
	f28.f64 = double(temp.f32);
	// lis r21,-31994
	r21.s64 = -2096758784;
	// ori r24,r11,13531
	r24.u64 = r11.u64 | 13531;
	// lis r11,17179
	r11.s64 = 1125842944;
	// lis r17,-32015
	r17.s64 = -2098135040;
	// ori r11,r11,56962
	r11.u64 = r11.u64 | 56962;
	// lis r19,-32015
	r19.s64 = -2098135040;
	// rldimi r24,r11,32,0
	r24.u64 = (__builtin_rotateleft64(r11.u64, 32) & 0xFFFFFFFF00000000) | (r24.u64 & 0xFFFFFFFF);
	// lis r11,-11763
	r11.s64 = -770899968;
	// lis r20,-31991
	r20.s64 = -2096562176;
	// lis r28,-31991
	r28.s64 = -2096562176;
	// ori r25,r11,8403
	r25.u64 = r11.u64 | 8403;
loc_82189DE0:
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// subf r11,r31,r27
	r11.s64 = r27.s64 - r31.s64;
	// mulli r11,r11,60
	r11.s64 = r11.s64 * 60;
	// cmpld cr6,r11,r23
	cr6.compare<uint64_t>(r11.u64, r23.u64, xer);
	// bge cr6,0x82189e0c
	if (!cr6.getLT()) goto loc_82189E0C;
loc_82189DF4:
	// bl 0x823b34f8
	sub_823B34F8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// subf r11,r31,r27
	r11.s64 = r27.s64 - r31.s64;
	// mulli r11,r11,60
	r11.s64 = r11.s64 * 60;
	// cmpld cr6,r11,r23
	cr6.compare<uint64_t>(r11.u64, r23.u64, xer);
	// blt cr6,0x82189df4
	if (cr6.getLT()) goto loc_82189DF4;
loc_82189E0C:
	// lwz r10,-31460(r20)
	ctx.r10.u64 = PPC_LOAD_U32(r20.u32 + -31460);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82189e28
	if (!cr6.getEQ()) goto loc_82189E28;
	// mulli r11,r31,60
	r11.s64 = r31.s64 * 60;
	// mulhdu r11,r11,r24
	// rldicl r11,r11,46,18
	r11.u64 = __builtin_rotateleft64(r11.u64, 46) & 0x3FFFFFFFFFFF;
	// rotlwi r10,r11,0
	ctx.r10.u64 = __builtin_rotateleft32(r11.u32, 0);
loc_82189E28:
	// mulli r9,r27,60
	ctx.r9.s64 = r27.s64 * 60;
	// lbz r11,-13403(r19)
	r11.u64 = PPC_LOAD_U8(r19.u32 + -13403);
	// mulhdu r9,r9,r24
	// rldicl r9,r9,46,18
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u64, 46) & 0x3FFFFFFFFFFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// rotlwi r11,r9,0
	r11.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// subf r29,r10,r11
	r29.s64 = r11.s64 - ctx.r10.s64;
	// beq cr6,0x82189e54
	if (cr6.getEQ()) goto loc_82189E54;
	// cmpwi cr6,r29,1
	cr6.compare<int32_t>(r29.s32, 1, xer);
	// ble cr6,0x82189e58
	if (!cr6.getGT()) goto loc_82189E58;
	// b 0x82189e5c
	goto loc_82189E5C;
loc_82189E54:
	// cmpwi cr6,r29,1
	cr6.compare<int32_t>(r29.s32, 1, xer);
loc_82189E58:
	// bge cr6,0x82189e60
	if (!cr6.getLT()) goto loc_82189E60;
loc_82189E5C:
	// li r29,1
	r29.s64 = 1;
loc_82189E60:
	// add r11,r10,r29
	r11.u64 = ctx.r10.u64 + r29.u64;
	// stw r11,-31460(r20)
	PPC_STORE_U32(r20.u32 + -31460, r11.u32);
	// bl 0x820ae108
	sub_820AE108(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x82189e84
	if (!cr6.getGT()) goto loc_82189E84;
	// li r3,-1
	ctx.r3.s64 = -1;
	// mr r29,r11
	r29.u64 = r11.u64;
	// bl 0x820ae0f8
	sub_820AE0F8(ctx, base);
loc_82189E84:
	// extsw r11,r29
	r11.s64 = r29.s32;
	// std r11,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, r11.u64);
	// lfd f0,128(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f30,f0,f28
	f30.f64 = double(float(f0.f64 * f28.f64));
	// fdivs f0,f29,f30
	f0.f64 = double(float(f29.f64 / f30.f64));
	// stfs f0,-31536(r16)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r16.u32 + -31536, temp.u32);
	// fcmpu cr6,f0,f27
	cr6.compare(f0.f64, f27.f64);
	// bge cr6,0x82189ec4
	if (!cr6.getLT()) goto loc_82189EC4;
	// lfs f13,0(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x82189ec4
	if (!cr6.getLT()) goto loc_82189EC4;
	// mr r11,r18
	r11.u64 = r18.u64;
	// stw r11,4(r26)
	PPC_STORE_U32(r26.u32 + 4, r11.u32);
	// b 0x82189ed8
	goto loc_82189ED8;
loc_82189EC4:
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmpwi cr6,r11,120
	cr6.compare<int32_t>(r11.s32, 120, xer);
	// stw r11,4(r26)
	PPC_STORE_U32(r26.u32 + 4, r11.u32);
	// blt cr6,0x82189edc
	if (cr6.getLT()) goto loc_82189EDC;
loc_82189ED8:
	// stfs f0,0(r26)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r26.u32 + 0, temp.u32);
loc_82189EDC:
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x8214c3c0
	sub_8214C3C0(ctx, base);
	// bl 0x821783e8
	sub_821783E8(ctx, base);
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x8217e658
	sub_8217E658(ctx, base);
	// bl 0x82181898
	sub_82181898(ctx, base);
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x8214b898
	sub_8214B898(ctx, base);
	// addi r3,r1,272
	ctx.r3.s64 = ctx.r1.s64 + 272;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x8209eb28
	sub_8209EB28(ctx, base);
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x823b2548
	sub_823B2548(ctx, base);
	// bl 0x821445c0
	sub_821445C0(ctx, base);
	// mr r31,r18
	r31.u64 = r18.u64;
loc_82189F18:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823b1f88
	sub_823B1F88(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// rlwinm r11,r30,0,23,23
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 0) & 0x100;
	// cmplwi cr6,r11,15
	cr6.compare<uint32_t>(r11.u32, 15, xer);
	// beq cr6,0x82189f4c
	if (cr6.getEQ()) goto loc_82189F4C;
	// bl 0x82091fb8
	sub_82091FB8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r4,r11,27,31,31
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// bl 0x82091fa0
	sub_82091FA0(ctx, base);
loc_82189F4C:
	// rlwinm r11,r30,0,22,22
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 0) & 0x200;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82189f68
	if (cr6.getEQ()) goto loc_82189F68;
	// bl 0x820ae360
	sub_820AE360(ctx, base);
	// cmpwi cr6,r3,90
	cr6.compare<int32_t>(ctx.r3.s32, 90, xer);
	// beq cr6,0x82189f68
	if (cr6.getEQ()) goto loc_82189F68;
	// bl 0x82099778
	sub_82099778(ctx, base);
loc_82189F68:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmpwi cr6,r31,3
	cr6.compare<int32_t>(r31.s32, 3, xer);
	// ble cr6,0x82189f18
	if (!cr6.getGT()) goto loc_82189F18;
	// bl 0x82099708
	sub_82099708(ctx, base);
	// lbz r11,-13401(r17)
	r11.u64 = PPC_LOAD_U8(r17.u32 + -13401);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82189fc8
	if (cr6.getEQ()) goto loc_82189FC8;
	// lwz r31,19944(r21)
	r31.u64 = PPC_LOAD_U32(r21.u32 + 19944);
	// bl 0x823ee680
	sub_823EE680(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// mulhw r10,r11,r25
	ctx.r10.s64 = (int64_t(r11.s32) * int64_t(r25.s32)) >> 32;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// srawi r10,r10,5
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1F) != 0);
	ctx.r10.s64 = ctx.r10.s32 >> 5;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// rlwinm r9,r10,1,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// li r8,658
	ctx.r8.s64 = 658;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mulli r10,r10,39
	ctx.r10.s64 = ctx.r10.s64 * 39;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r4,r11,120
	ctx.r4.s64 = r11.s64 + 120;
	// bl 0x82144920
	sub_82144920(ctx, base);
loc_82189FC8:
	// bl 0x82091fc8
	sub_82091FC8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82189fe0
	if (cr6.getEQ()) goto loc_82189FE0;
	// bl 0x8209fee0
	sub_8209FEE0(ctx, base);
	// b 0x82189fec
	goto loc_82189FEC;
loc_82189FE0:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x820ae3f0
	sub_820AE3F0(ctx, base);
loc_82189FEC:
	// bl 0x82091fb8
	sub_82091FB8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8218a000
	if (cr6.getEQ()) goto loc_8218A000;
	// bl 0x820960f8
	sub_820960F8(ctx, base);
loc_8218A000:
	// bl 0x8209c700
	sub_8209C700(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8218a018
	if (cr6.getEQ()) goto loc_8218A018;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x8209c750
	sub_8209C750(ctx, base);
loc_8218A018:
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x8209dc30
	sub_8209DC30(ctx, base);
	// bl 0x8217c108
	sub_8217C108(ctx, base);
	// bl 0x8217d8c0
	sub_8217D8C0(ctx, base);
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x8214c700
	sub_8214C700(ctx, base);
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x821872b0
	sub_821872B0(ctx, base);
	// bl 0x82117908
	sub_82117908(ctx, base);
	// li r6,255
	ctx.r6.s64 = 255;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8238d668
	sub_8238D668(ctx, base);
	// bl 0x8238d4e8
	sub_8238D4E8(ctx, base);
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// bl 0x82188d50
	sub_82188D50(ctx, base);
	// bl 0x8209e1c0
	sub_8209E1C0(ctx, base);
	// rlwinm r11,r3,0,30,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x2;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8218a104
	if (cr6.getEQ()) goto loc_8218A104;
	// lwz r3,13356(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 13356);
	// bl 0x82195588
	sub_82195588(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,13356(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 13356);
	// bl 0x82195f68
	sub_82195F68(ctx, base);
	// lwz r3,13356(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 13356);
	// bl 0x821996f0
	sub_821996F0(ctx, base);
	// stfs f31,192(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// stfs f31,196(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// stfs f31,200(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// stfs f31,204(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// bl 0x820ae0d8
	sub_820AE0D8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8218a0dc
	if (!cr6.getEQ()) goto loc_8218A0DC;
	// addi r10,r1,192
	ctx.r10.s64 = ctx.r1.s64 + 192;
	// lwz r6,-31548(r15)
	ctx.r6.u64 = PPC_LOAD_U32(r15.u32 + -31548);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r3,13356(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 13356);
	// li r8,0
	ctx.r8.s64 = 0;
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f29.f64;
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r18,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r18.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r18,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r18.u32);
	// li r4,256
	ctx.r4.s64 = 256;
	// bl 0x82197c48
	sub_82197C48(ctx, base);
loc_8218A0DC:
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r4,-31548(r15)
	ctx.r4.u64 = PPC_LOAD_U32(r15.u32 + -31548);
	// lwz r3,13356(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 13356);
	// bl 0x821996f8
	sub_821996F8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r3,13356(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 13356);
	// bl 0x82195f68
	sub_82195F68(ctx, base);
	// mr r31,r27
	r31.u64 = r27.u64;
	// bl 0x823b34f8
	sub_823B34F8(ctx, base);
	// b 0x82189de0
	goto loc_82189DE0;
loc_8218A104:
	// bl 0x8238d5a8
	sub_8238D5A8(ctx, base);
	// mr r31,r27
	r31.u64 = r27.u64;
	// bl 0x823b34f8
	sub_823B34F8(ctx, base);
	// b 0x82189de0
	goto loc_82189DE0;
}

__attribute__((alias("__imp__sub_8218A118"))) PPC_WEAK_FUNC(sub_8218A118);
PPC_FUNC_IMPL(__imp__sub_8218A118) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// lwz r9,40(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// rlwinm. r10,r11,23,30,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 23) & 0x3;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// rlwinm r11,r9,2,30,30
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0x2;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// bne 0x8218a14c
	if (!cr0.getEQ()) goto loc_8218A14C;
	// lwz r10,36(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// li r9,1
	ctx.r9.s64 = 1;
	// clrlwi r10,r10,8
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFFFF;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// stw r9,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r9.u32);
	// b 0x8218a1a8
	goto loc_8218A1A8;
loc_8218A14C:
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// lwz r10,36(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// bne cr6,0x8218a188
	if (!cr6.getEQ()) goto loc_8218A188;
	// clrlwi r10,r10,21
	ctx.r10.u64 = ctx.r10.u32 & 0x7FF;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// lwz r10,36(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// rlwinm r10,r10,21,21,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 21) & 0x7FF;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// stw r10,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r10.u32);
	// lwz r10,36(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// rlwinm r10,r10,10,22,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 10) & 0x3FF;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// stw r11,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, r11.u32);
	// blr 
	return;
loc_8218A188:
	// clrlwi r10,r10,19
	ctx.r10.u64 = ctx.r10.u32 & 0x1FFF;
	// li r9,1
	ctx.r9.s64 = 1;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// lwz r10,36(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// rlwinm r10,r10,19,19,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 19) & 0x1FFF;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
loc_8218A1A8:
	// stw r9,0(r6)
	PPC_STORE_U32(ctx.r6.u32 + 0, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218A1B0"))) PPC_WEAK_FUNC(sub_8218A1B0);
PPC_FUNC_IMPL(__imp__sub_8218A1B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,48(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	// lwz r10,32(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	// rlwinm r5,r11,0,0,19
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFF000;
	// rlwinm r4,r10,0,0,19
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFF000;
	// b 0x8219b580
	sub_8219B580(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218A1C8"))) PPC_WEAK_FUNC(sub_8218A1C8);
PPC_FUNC_IMPL(__imp__sub_8218A1C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// rlwinm r11,r11,6,26,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0x3F;
	// addi r3,r11,1
	ctx.r3.s64 = r11.s64 + 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218A1D8"))) PPC_WEAK_FUNC(sub_8218A1D8);
PPC_FUNC_IMPL(__imp__sub_8218A1D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// clrlwi r9,r5,26
	ctx.r9.u64 = ctx.r5.u32 & 0x3F;
	// li r8,4
	ctx.r8.s64 = 4;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r10,r4
	ctx.r10.u64 = ctx.r4.u64;
	// cmpwi cr6,r6,1
	cr6.compare<int32_t>(ctx.r6.s32, 1, xer);
	// blt cr6,0x8218a1f4
	if (cr6.getLT()) goto loc_8218A1F4;
	// rlwinm r10,r4,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 1) & 0xFFFFFFFE;
loc_8218A1F4:
	// cmpwi cr6,r6,2
	cr6.compare<int32_t>(ctx.r6.s32, 2, xer);
	// bne cr6,0x8218a200
	if (!cr6.getEQ()) goto loc_8218A200;
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
loc_8218A200:
	// addi r11,r11,79
	r11.s64 = r11.s64 + 79;
	// li r7,80
	ctx.r7.s64 = 80;
	// addi r10,r10,15
	ctx.r10.s64 = ctx.r10.s64 + 15;
	// divwu r7,r11,r7
	ctx.r7.u32 = r11.u32 / ctx.r7.u32;
	// rlwinm r11,r10,0,0,27
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFF0;
	// mulli r10,r7,80
	ctx.r10.s64 = ctx.r7.s64 * 80;
	// cmpwi cr6,r9,21
	cr6.compare<int32_t>(ctx.r9.s32, 21, xer);
	// beq cr6,0x8218a230
	if (cr6.getEQ()) goto loc_8218A230;
	// cmpwi cr6,r9,32
	cr6.compare<int32_t>(ctx.r9.s32, 32, xer);
	// beq cr6,0x8218a230
	if (cr6.getEQ()) goto loc_8218A230;
	// cmpwi cr6,r9,37
	cr6.compare<int32_t>(ctx.r9.s32, 37, xer);
	// bne cr6,0x8218a234
	if (!cr6.getEQ()) goto loc_8218A234;
loc_8218A230:
	// li r8,8
	ctx.r8.s64 = 8;
loc_8218A234:
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// mullw r11,r11,r8
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r8.s32);
	// li r10,5120
	ctx.r10.s64 = 5120;
	// divwu r3,r11,r10
	ctx.r3.u32 = r11.u32 / ctx.r10.u32;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218A248"))) PPC_WEAK_FUNC(sub_8218A248);
PPC_FUNC_IMPL(__imp__sub_8218A248) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r3,44
	cr6.compare<uint32_t>(ctx.r3.u32, 44, xer);
	// bgt cr6,0x8218a2a0
	if (cr6.getGT()) goto loc_8218A2A0;
	// beq cr6,0x8218a298
	if (cr6.getEQ()) goto loc_8218A298;
	// cmplwi cr6,r3,11
	cr6.compare<uint32_t>(ctx.r3.u32, 11, xer);
	// blt cr6,0x8218a2c8
	if (cr6.getLT()) goto loc_8218A2C8;
	// cmplwi cr6,r3,12
	cr6.compare<uint32_t>(ctx.r3.u32, 12, xer);
	// ble cr6,0x8218a284
	if (!cr6.getGT()) goto loc_8218A284;
	// cmplwi cr6,r3,17
	cr6.compare<uint32_t>(ctx.r3.u32, 17, xer);
	// ble cr6,0x8218a2c8
	if (!cr6.getGT()) goto loc_8218A2C8;
	// cmplwi cr6,r3,20
	cr6.compare<uint32_t>(ctx.r3.u32, 20, xer);
	// ble cr6,0x8218a2d0
	if (!cr6.getGT()) goto loc_8218A2D0;
	// cmplwi cr6,r3,39
	cr6.compare<uint32_t>(ctx.r3.u32, 39, xer);
	// beq cr6,0x8218a298
	if (cr6.getEQ()) goto loc_8218A298;
	// cmplwi cr6,r3,40
	cr6.compare<uint32_t>(ctx.r3.u32, 40, xer);
	// bne cr6,0x8218a2c8
	if (!cr6.getEQ()) goto loc_8218A2C8;
loc_8218A284:
	// li r11,2
	r11.s64 = 2;
loc_8218A288:
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// stw r10,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r10.u32);
	// blr 
	return;
loc_8218A298:
	// li r11,4
	r11.s64 = 4;
	// b 0x8218a288
	goto loc_8218A288;
loc_8218A2A0:
	// cmplwi cr6,r3,49
	cr6.compare<uint32_t>(ctx.r3.u32, 49, xer);
	// beq cr6,0x8218a2d0
	if (cr6.getEQ()) goto loc_8218A2D0;
	// cmplwi cr6,r3,50
	cr6.compare<uint32_t>(ctx.r3.u32, 50, xer);
	// ble cr6,0x8218a2c8
	if (!cr6.getGT()) goto loc_8218A2C8;
	// cmplwi cr6,r3,53
	cr6.compare<uint32_t>(ctx.r3.u32, 53, xer);
	// ble cr6,0x8218a2d0
	if (!cr6.getGT()) goto loc_8218A2D0;
	// cmplwi cr6,r3,57
	cr6.compare<uint32_t>(ctx.r3.u32, 57, xer);
	// ble cr6,0x8218a2c8
	if (!cr6.getGT()) goto loc_8218A2C8;
	// cmplwi cr6,r3,61
	cr6.compare<uint32_t>(ctx.r3.u32, 61, xer);
	// ble cr6,0x8218a2d0
	if (!cr6.getGT()) goto loc_8218A2D0;
loc_8218A2C8:
	// li r11,1
	r11.s64 = 1;
	// b 0x8218a2d4
	goto loc_8218A2D4;
loc_8218A2D0:
	// li r11,4
	r11.s64 = 4;
loc_8218A2D4:
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218A2E0"))) PPC_WEAK_FUNC(sub_8218A2E0);
PPC_FUNC_IMPL(__imp__sub_8218A2E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// rlwinm r11,r6,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// subf r9,r11,r5
	ctx.r9.s64 = ctx.r5.s64 - r11.s64;
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// bgt cr6,0x8218a2f8
	if (cr6.getGT()) goto loc_8218A2F8;
	// li r10,1
	ctx.r10.s64 = 1;
loc_8218A2F8:
	// subf r8,r11,r4
	ctx.r8.s64 = ctx.r4.s64 - r11.s64;
	// cmplw cr6,r8,r10
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r10.u32, xer);
	// ble cr6,0x8218a30c
	if (!cr6.getGT()) goto loc_8218A30C;
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
	// b 0x8218a31c
	goto loc_8218A31C;
loc_8218A30C:
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// bgt cr6,0x8218a31c
	if (cr6.getGT()) goto loc_8218A31C;
	// li r10,1
	ctx.r10.s64 = 1;
loc_8218A31C:
	// subf r11,r11,r3
	r11.s64 = ctx.r3.s64 - r11.s64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8218a358
	if (cr6.getGT()) goto loc_8218A358;
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
	// bgt cr6,0x8218a338
	if (cr6.getGT()) goto loc_8218A338;
	// li r11,1
	r11.s64 = 1;
loc_8218A338:
	// cmplw cr6,r8,r11
	cr6.compare<uint32_t>(ctx.r8.u32, r11.u32, xer);
	// ble cr6,0x8218a348
	if (!cr6.getGT()) goto loc_8218A348;
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
	// b 0x8218a358
	goto loc_8218A358;
loc_8218A348:
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
	// bgt cr6,0x8218a358
	if (cr6.getGT()) goto loc_8218A358;
	// li r11,1
	r11.s64 = 1;
loc_8218A358:
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// subfic r3,r11,32
	xer.ca = r11.u32 <= 32;
	ctx.r3.s64 = 32 - r11.s64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218A368"))) PPC_WEAK_FUNC(sub_8218A368);
PPC_FUNC_IMPL(__imp__sub_8218A368) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed124
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r8
	r28.u64 = ctx.r8.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// subfic r11,r28,0
	xer.ca = r28.u32 <= 0;
	r11.s64 = 0 - r28.s64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r23,r9
	r23.u64 = ctx.r9.u64;
	// li r25,32
	r25.s64 = 32;
	// cmplwi cr6,r28,2
	cr6.compare<uint32_t>(r28.u32, 2, xer);
	// addi r24,r11,1
	r24.s64 = r11.s64 + 1;
	// li r27,4
	r27.s64 = 4;
	// beq cr6,0x8218a3b0
	if (cr6.getEQ()) goto loc_8218A3B0;
	// li r27,1
	r27.s64 = 1;
loc_8218A3B0:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// mr r3,r7
	ctx.r3.u64 = ctx.r7.u64;
	// bl 0x8218a248
	sub_8218A248(ctx, base);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x8218a3f8
	if (!cr6.getEQ()) goto loc_8218A3F8;
	// mullw r9,r11,r10
	ctx.r9.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// mullw r9,r9,r26
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(r26.s32);
	// rlwinm. r9,r9,29,3,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x1FFFFFFF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8218a3f8
	if (cr0.getEQ()) goto loc_8218A3F8;
	// li r8,256
	ctx.r8.s64 = 256;
	// twllei r9,0
	// divwu r9,r8,r9
	ctx.r9.u32 = ctx.r8.u32 / ctx.r9.u32;
	// cmplwi cr6,r9,32
	cr6.compare<uint32_t>(ctx.r9.u32, 32, xer);
	// blt cr6,0x8218a3f8
	if (cr6.getLT()) goto loc_8218A3F8;
	// mr r25,r9
	r25.u64 = ctx.r9.u64;
loc_8218A3F8:
	// mullw r11,r11,r25
	r11.s64 = int64_t(r11.s32) * int64_t(r25.s32);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + r11.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// mullw r10,r10,r24
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(r24.s32);
	// andc r11,r9,r11
	r11.u64 = ctx.r9.u64 & ~r11.u64;
	// addi r9,r10,-1
	ctx.r9.s64 = ctx.r10.s64 + -1;
	// addi r8,r27,-1
	ctx.r8.s64 = r27.s64 + -1;
	// cmplwi cr6,r28,2
	cr6.compare<uint32_t>(r28.u32, 2, xer);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// andc r11,r11,r9
	r11.u64 = r11.u64 & ~ctx.r9.u64;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// add r11,r11,r27
	r11.u64 = r11.u64 + r27.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// andc r11,r11,r8
	r11.u64 = r11.u64 & ~ctx.r8.u64;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mullw r10,r10,r26
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(r26.s32);
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// mullw r10,r10,r9
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
	// beq cr6,0x8218a474
	if (cr6.getEQ()) goto loc_8218A474;
	// addi r10,r10,4095
	ctx.r10.s64 = ctx.r10.s64 + 4095;
	// rlwinm r10,r10,0,0,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFF000;
	// mullw r3,r10,r11
	ctx.r3.s64 = int64_t(ctx.r10.s32) * int64_t(r11.s32);
	// b 0x8218a480
	goto loc_8218A480;
loc_8218A474:
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// addi r11,r11,4095
	r11.s64 = r11.s64 + 4095;
	// rlwinm r3,r11,0,0,19
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFF000;
loc_8218A480:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed174
	return;
}

__attribute__((alias("__imp__sub_8218A488"))) PPC_WEAK_FUNC(sub_8218A488);
PPC_FUNC_IMPL(__imp__sub_8218A488) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed100
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r22,r8
	r22.u64 = ctx.r8.u64;
	// stw r5,292(r1)
	PPC_STORE_U32(ctx.r1.u32 + 292, ctx.r5.u32);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r15,r6
	r15.u64 = ctx.r6.u64;
	// mr r20,r7
	r20.u64 = ctx.r7.u64;
	// mr r16,r9
	r16.u64 = ctx.r9.u64;
	// stw r8,332(r1)
	PPC_STORE_U32(ctx.r1.u32 + 332, ctx.r8.u32);
	// li r19,1
	r19.s64 = 1;
	// li r17,0
	r17.s64 = 0;
	// cmplwi cr6,r22,1
	cr6.compare<uint32_t>(r22.u32, 1, xer);
	// bne cr6,0x8218a4d4
	if (!cr6.getEQ()) goto loc_8218A4D4;
	// cmplwi cr6,r5,1
	cr6.compare<uint32_t>(ctx.r5.u32, 1, xer);
	// ble cr6,0x8218a4d4
	if (!cr6.getGT()) goto loc_8218A4D4;
	// stw r19,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r19.u32);
	// b 0x8218a4e4
	goto loc_8218A4E4;
loc_8218A4D4:
	// stw r17,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r17.u32);
	// cmplwi cr6,r22,3
	cr6.compare<uint32_t>(r22.u32, 3, xer);
	// mr r14,r17
	r14.u64 = r17.u64;
	// bne cr6,0x8218a4e8
	if (!cr6.getEQ()) goto loc_8218A4E8;
loc_8218A4E4:
	// mr r14,r19
	r14.u64 = r19.u64;
loc_8218A4E8:
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// mr r28,r19
	r28.u64 = r19.u64;
	// bne cr6,0x8218a4f8
	if (!cr6.getEQ()) goto loc_8218A4F8;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
loc_8218A4F8:
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lwz r31,340(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// rlwinm r9,r20,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r10,r10,-19608
	ctx.r10.s64 = ctx.r10.s64 + -19608;
	// rlwinm r11,r31,1,0,30
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// subf r23,r11,r3
	r23.s64 = ctx.r3.s64 - r11.s64;
	// subf r26,r11,r25
	r26.s64 = r25.s64 - r11.s64;
	// cmplwi cr6,r22,2
	cr6.compare<uint32_t>(r22.u32, 2, xer);
	// lbzx r21,r9,r10
	r21.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// addi r10,r23,-1
	ctx.r10.s64 = r23.s64 + -1;
	// addi r9,r26,-1
	ctx.r9.s64 = r26.s64 + -1;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// cntlzw r9,r9
	ctx.r9.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// subf r10,r10,r31
	ctx.r10.s64 = r31.s64 - ctx.r10.s64;
	// subf r9,r9,r31
	ctx.r9.s64 = r31.s64 - ctx.r9.s64;
	// addi r29,r10,32
	r29.s64 = ctx.r10.s64 + 32;
	// addi r30,r9,32
	r30.s64 = ctx.r9.s64 + 32;
	// bne cr6,0x8218a55c
	if (!cr6.getEQ()) goto loc_8218A55C;
	// subf r24,r11,r28
	r24.s64 = r28.s64 - r11.s64;
	// addi r11,r24,-1
	r11.s64 = r24.s64 + -1;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// subf r11,r11,r31
	r11.s64 = r31.s64 - r11.s64;
	// addi r11,r11,32
	r11.s64 = r11.s64 + 32;
	// b 0x8218a564
	goto loc_8218A564;
loc_8218A55C:
	// mr r24,r19
	r24.u64 = r19.u64;
	// mr r11,r17
	r11.u64 = r17.u64;
loc_8218A564:
	// slw r10,r19,r29
	ctx.r10.u64 = r29.u8 & 0x20 ? 0 : (r19.u32 << (r29.u8 & 0x3F));
	// lwz r27,356(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// slw r9,r19,r30
	ctx.r9.u64 = r30.u8 & 0x20 ? 0 : (r19.u32 << (r30.u8 & 0x3F));
	// slw r11,r19,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r19.u32 << (r11.u8 & 0x3F));
	// cmplwi cr6,r10,16
	cr6.compare<uint32_t>(ctx.r10.u32, 16, xer);
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// stw r9,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r9.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// ble cr6,0x8218a590
	if (!cr6.getGT()) goto loc_8218A590;
	// cmplwi cr6,r9,16
	cr6.compare<uint32_t>(ctx.r9.u32, 16, xer);
	// bgt cr6,0x8218a598
	if (cr6.getGT()) goto loc_8218A598;
loc_8218A590:
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x8218a5c0
	if (!cr6.getEQ()) goto loc_8218A5C0;
loc_8218A598:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x8218a5a8
	if (!cr6.getEQ()) goto loc_8218A5A8;
	// stw r3,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r3.u32);
	// b 0x8218a5b8
	goto loc_8218A5B8;
loc_8218A5A8:
	// rlwinm r11,r27,3,0,28
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 3) & 0xFFFFFFF8;
	// twllei r21,0
	// divwu r11,r11,r21
	r11.u32 = r11.u32 / r21.u32;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
loc_8218A5B8:
	// stw r25,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r25.u32);
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
loc_8218A5C0:
	// mr r9,r16
	ctx.r9.u64 = r16.u64;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x8218a368
	sub_8218A368(ctx, base);
	// lwz r18,88(r1)
	r18.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x8218a5f4
	if (!cr6.getEQ()) goto loc_8218A5F4;
	// mullw r11,r18,r21
	r11.s64 = int64_t(r18.s32) * int64_t(r21.s32);
	// rlwinm r27,r11,29,3,31
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFF;
loc_8218A5F4:
	// cmpwi cr6,r16,0
	cr6.compare<int32_t>(r16.s32, 0, xer);
	// bne cr6,0x8218a670
	if (!cr6.getEQ()) goto loc_8218A670;
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// bne cr6,0x8218a670
	if (!cr6.getEQ()) goto loc_8218A670;
	// cmplwi cr6,r22,2
	cr6.compare<uint32_t>(r22.u32, 2, xer);
	// beq cr6,0x8218a694
	if (cr6.getEQ()) goto loc_8218A694;
	// cmplwi cr6,r22,1
	cr6.compare<uint32_t>(r22.u32, 1, xer);
	// bne cr6,0x8218a65c
	if (!cr6.getEQ()) goto loc_8218A65C;
	// cmplwi cr6,r15,1
	cr6.compare<uint32_t>(r15.u32, 1, xer);
	// bne cr6,0x8218a65c
	if (!cr6.getEQ()) goto loc_8218A65C;
	// lwz r11,332(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8218a65c
	if (!cr6.getEQ()) goto loc_8218A65C;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8218a65c
	if (!cr6.getEQ()) goto loc_8218A65C;
	// addi r5,r1,92
	ctx.r5.s64 = ctx.r1.s64 + 92;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x8218a248
	sub_8218A248(ctx, base);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// add r10,r11,r25
	ctx.r10.u64 = r11.u64 + r25.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// andc r11,r10,r11
	r11.u64 = ctx.r10.u64 & ~r11.u64;
	// mullw r25,r11,r27
	r25.s64 = int64_t(r11.s32) * int64_t(r27.s32);
	// b 0x8218a7d4
	goto loc_8218A7D4;
loc_8218A65C:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mullw r11,r27,r11
	r11.s64 = int64_t(r27.s32) * int64_t(r11.s32);
	// mullw r25,r11,r10
	r25.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// b 0x8218a6bc
	goto loc_8218A6BC;
loc_8218A670:
	// cmplwi cr6,r22,2
	cr6.compare<uint32_t>(r22.u32, 2, xer);
	// beq cr6,0x8218a694
	if (cr6.getEQ()) goto loc_8218A694;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mullw r11,r27,r11
	r11.s64 = int64_t(r27.s32) * int64_t(r11.s32);
	// addi r11,r11,4095
	r11.s64 = r11.s64 + 4095;
	// rlwinm r11,r11,0,0,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFF000;
	// mullw r25,r11,r10
	r25.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// b 0x8218a6ac
	goto loc_8218A6AC;
loc_8218A694:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// mullw r11,r27,r11
	r11.s64 = int64_t(r27.s32) * int64_t(r11.s32);
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// addi r11,r11,4095
	r11.s64 = r11.s64 + 4095;
	// rlwinm r25,r11,0,0,19
	r25.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFF000;
loc_8218A6AC:
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// beq cr6,0x8218a6bc
	if (cr6.getEQ()) goto loc_8218A6BC;
	// lwz r11,292(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// mullw r25,r25,r11
	r25.s64 = int64_t(r25.s32) * int64_t(r11.s32);
loc_8218A6BC:
	// cmplwi cr6,r15,1
	cr6.compare<uint32_t>(r15.u32, 1, xer);
	// bgt cr6,0x8218a6cc
	if (cr6.getGT()) goto loc_8218A6CC;
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// bne cr6,0x8218a7d4
	if (!cr6.getEQ()) goto loc_8218A7D4;
loc_8218A6CC:
	// cmplw cr6,r26,r24
	cr6.compare<uint32_t>(r26.u32, r24.u32, xer);
	// mr r11,r26
	r11.u64 = r26.u64;
	// bgt cr6,0x8218a6dc
	if (cr6.getGT()) goto loc_8218A6DC;
	// mr r11,r24
	r11.u64 = r24.u64;
loc_8218A6DC:
	// cmplw cr6,r23,r11
	cr6.compare<uint32_t>(r23.u32, r11.u32, xer);
	// ble cr6,0x8218a6ec
	if (!cr6.getGT()) goto loc_8218A6EC;
	// mr r11,r23
	r11.u64 = r23.u64;
	// b 0x8218a6fc
	goto loc_8218A6FC;
loc_8218A6EC:
	// cmplw cr6,r26,r24
	cr6.compare<uint32_t>(r26.u32, r24.u32, xer);
	// mr r11,r26
	r11.u64 = r26.u64;
	// bgt cr6,0x8218a6fc
	if (cr6.getGT()) goto loc_8218A6FC;
	// mr r11,r24
	r11.u64 = r24.u64;
loc_8218A6FC:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// bne cr6,0x8218a70c
	if (!cr6.getEQ()) goto loc_8218A70C;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// subfic r15,r11,32
	xer.ca = r11.u32 <= 32;
	r15.s64 = 32 - r11.s64;
loc_8218A70C:
	// li r11,15
	r11.s64 = 15;
	// addic. r31,r15,-1
	xer.ca = r15.u32 > 0;
	r31.s64 = r15.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// subfic r27,r11,32
	xer.ca = r11.u32 <= 32;
	r27.s64 = 32 - r11.s64;
	// beq 0x8218a7a0
	if (cr0.getEQ()) goto loc_8218A7A0;
loc_8218A720:
	// lwz r11,332(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8218a73c
	if (cr6.getEQ()) goto loc_8218A73C;
	// cmplw cr6,r29,r27
	cr6.compare<uint32_t>(r29.u32, r27.u32, xer);
	// ble cr6,0x8218a7a0
	if (!cr6.getGT()) goto loc_8218A7A0;
	// cmplw cr6,r30,r27
	cr6.compare<uint32_t>(r30.u32, r27.u32, xer);
	// ble cr6,0x8218a7a0
	if (!cr6.getGT()) goto loc_8218A7A0;
loc_8218A73C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8218a748
	if (cr6.getEQ()) goto loc_8218A748;
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
loc_8218A748:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8218a754
	if (cr6.getEQ()) goto loc_8218A754;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
loc_8218A754:
	// cmplwi cr6,r28,1
	cr6.compare<uint32_t>(r28.u32, 1, xer);
	// ble cr6,0x8218a760
	if (!cr6.getGT()) goto loc_8218A760;
	// rlwinm r28,r28,31,1,31
	r28.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 31) & 0x7FFFFFFF;
loc_8218A760:
	// slw r11,r19,r29
	r11.u64 = r29.u8 & 0x20 ? 0 : (r19.u32 << (r29.u8 & 0x3F));
	// stw r28,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r28.u32);
	// mr r9,r16
	ctx.r9.u64 = r16.u64;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// mr r7,r20
	ctx.r7.u64 = r20.u64;
	// mr r6,r21
	ctx.r6.u64 = r21.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// slw r11,r19,r30
	r11.u64 = r30.u8 & 0x20 ? 0 : (r19.u32 << (r30.u8 & 0x3F));
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// bl 0x8218a368
	sub_8218A368(ctx, base);
	// addic. r31,r31,-1
	xer.ca = r31.u32 > 0;
	r31.s64 = r31.s64 + -1;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// add r17,r3,r17
	r17.u64 = ctx.r3.u64 + r17.u64;
	// bne 0x8218a720
	if (!cr0.getEQ()) goto loc_8218A720;
loc_8218A7A0:
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// beq cr6,0x8218a7d4
	if (cr6.getEQ()) goto loc_8218A7D4;
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r10,292(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 292);
	// subfic r11,r11,0
	xer.ca = r11.u32 <= 0;
	r11.s64 = 0 - r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// andc r11,r10,r11
	r11.u64 = ctx.r10.u64 & ~r11.u64;
	// mullw r17,r11,r17
	r17.s64 = int64_t(r11.s32) * int64_t(r17.s32);
loc_8218A7D4:
	// lwz r11,364(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// stw r18,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r18.u32);
	// lwz r11,372(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// stw r25,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r25.u32);
	// lwz r11,380(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	// stw r17,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r17.u32);
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x823ed150
	return;
}

__attribute__((alias("__imp__sub_8218A7F8"))) PPC_WEAK_FUNC(sub_8218A7F8);
PPC_FUNC_IMPL(__imp__sub_8218A7F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r10
	r25.u64 = ctx.r10.u64;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// mr r26,r8
	r26.u64 = ctx.r8.u64;
	// addi r8,r10,-19608
	ctx.r8.s64 = ctx.r10.s64 + -19608;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r1,100
	r11.s64 = ctx.r1.s64 + 100;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// rlwinm r7,r9,1,0,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lbzx r24,r7,r8
	r24.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r8.u32);
	// mr r3,r9
	ctx.r3.u64 = ctx.r9.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// bl 0x8218a248
	sub_8218A248(ctx, base);
	// addi r11,r30,-1
	r11.s64 = r30.s64 + -1;
	// addi r10,r29,-1
	ctx.r10.s64 = r29.s64 + -1;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// li r9,1
	ctx.r9.s64 = 1;
	// subfic r11,r11,32
	xer.ca = r11.u32 <= 32;
	r11.s64 = 32 - r11.s64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// addi r8,r28,-1
	ctx.r8.s64 = r28.s64 + -1;
	// subfic r10,r10,32
	xer.ca = ctx.r10.u32 <= 32;
	ctx.r10.s64 = 32 - ctx.r10.s64;
	// cntlzw r8,r8
	ctx.r8.u64 = ctx.r8.u32 == 0 ? 32 : __builtin_clz(ctx.r8.u32);
	// cmplwi cr6,r31,3
	cr6.compare<uint32_t>(r31.u32, 3, xer);
	// subfic r8,r8,32
	xer.ca = ctx.r8.u32 <= 32;
	ctx.r8.s64 = 32 - ctx.r8.s64;
	// slw r7,r9,r11
	ctx.r7.u64 = r11.u8 & 0x20 ? 0 : (ctx.r9.u32 << (r11.u8 & 0x3F));
	// subfc r11,r11,r10
	xer.ca = ctx.r10.u32 >= r11.u32;
	r11.s64 = ctx.r10.s64 - r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// slw r10,r9,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r10.u8 & 0x3F));
	// clrlwi r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	// stw r7,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r7.u32);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// bge cr6,0x8218a914
	if (!cr6.getLT()) goto loc_8218A914;
	// li r10,16
	ctx.r10.s64 = 16;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// sraw r10,r10,r31
	temp.u32 = r31.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	xer.ca = (ctx.r10.s32 < 0) & (((ctx.r10.s32 >> temp.u32) << temp.u32) != ctx.r10.s32);
	ctx.r10.s64 = ctx.r10.s32 >> temp.u32;
	// stwx r10,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r10.u32);
loc_8218A8B8:
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
loc_8218A8BC:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r9,96(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mullw r8,r10,r24
	ctx.r8.s64 = int64_t(ctx.r10.s32) * int64_t(r24.s32);
	// divwu r7,r9,r10
	ctx.r7.u32 = ctx.r9.u32 / ctx.r10.u32;
	// mullw r8,r8,r9
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r9.s32);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r7,0(r25)
	PPC_STORE_U32(r25.u32 + 0, ctx.r7.u32);
	// twllei r10,0
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// twllei r9,0
	// divwu r6,r10,r9
	ctx.r6.u32 = ctx.r10.u32 / ctx.r9.u32;
	// rlwinm r9,r8,29,3,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x1FFFFFFF;
	// lwz r8,276(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// mullw r10,r10,r27
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(r27.s32);
	// stw r6,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r6.u32);
	// lwz r8,284(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 284);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// stw r11,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r11.u32);
	// mullw r11,r11,r26
	r11.s64 = int64_t(r11.s32) * int64_t(r26.s32);
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + r11.u64;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x823ed178
	return;
loc_8218A914:
	// xori r11,r11,4
	r11.u64 = r11.u64 ^ 4;
	// addi r10,r1,88
	ctx.r10.s64 = ctx.r1.s64 + 88;
	// addi r7,r31,-2
	ctx.r7.s64 = r31.s64 + -2;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// srw r10,r10,r7
	ctx.r10.u64 = ctx.r7.u8 & 0x20 ? 0 : (ctx.r10.u32 >> (ctx.r7.u8 & 0x3F));
	// cmplwi cr6,r10,4
	cr6.compare<uint32_t>(ctx.r10.u32, 4, xer);
	// stwx r10,r11,r6
	PPC_STORE_U32(r11.u32 + ctx.r6.u32, ctx.r10.u32);
	// bge cr6,0x8218a8b8
	if (!cr6.getLT()) goto loc_8218A8B8;
	// subf r11,r31,r8
	r11.s64 = ctx.r8.s64 - r31.s64;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bgt cr6,0x8218a948
	if (cr6.getGT()) goto loc_8218A948;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8218A948:
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// b 0x8218a8bc
	goto loc_8218A8BC;
}

__attribute__((alias("__imp__sub_8218A950"))) PPC_WEAK_FUNC(sub_8218A950);
PPC_FUNC_IMPL(__imp__sub_8218A950) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed100
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r22,r4
	r22.u64 = ctx.r4.u64;
	// addi r11,r11,-19608
	r11.s64 = r11.s64 + -19608;
	// mr r19,r5
	r19.u64 = ctx.r5.u64;
	// lwz r10,32(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// mr r18,r6
	r18.u64 = ctx.r6.u64;
	// clrlwi r21,r10,26
	r21.u64 = ctx.r10.u32 & 0x3F;
	// mr r17,r7
	r17.u64 = ctx.r7.u64;
	// rlwinm r10,r21,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r16,r8
	r16.u64 = ctx.r8.u64;
	// mr r15,r9
	r15.u64 = ctx.r9.u64;
	// lbzx r20,r10,r11
	r20.u64 = PPC_LOAD_U8(ctx.r10.u32 + r11.u32);
	// bl 0x8219b0d0
	sub_8219B0D0(ctx, base);
	// mr r14,r3
	r14.u64 = ctx.r3.u64;
	// addi r6,r1,100
	ctx.r6.s64 = ctx.r1.s64 + 100;
	// cmpwi cr6,r14,4
	cr6.compare<int32_t>(r14.s32, 4, xer);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// addi r4,r1,92
	ctx.r4.s64 = ctx.r1.s64 + 92;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bne cr6,0x8218aa08
	if (!cr6.getEQ()) goto loc_8218AA08;
	// bl 0x8218a118
	sub_8218A118(ctx, base);
	// lwz r10,48(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 48);
	// lwz r11,28(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// rlwinm r8,r10,23,30,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 23) & 0x3;
	// lwz r24,92(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r26,96(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm r10,r11,10,23,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 10) & 0x1FF;
	// lwz r23,100(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// rlwinm r9,r11,1,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// mullw r11,r10,r20
	r11.s64 = int64_t(ctx.r10.s32) * int64_t(r20.s32);
	// stw r24,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r24.u32);
	// stw r26,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r26.u32);
	// stw r23,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r23.u32);
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// rlwinm r31,r11,2,3,29
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x1FFFFFFC;
	// bl 0x8218a368
	sub_8218A368(ctx, base);
	// b 0x8218acb0
	goto loc_8218ACB0;
loc_8218AA08:
	// lwz r11,40(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 40);
	// rlwinm r31,r11,1,31,31
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// rlwinm r8,r31,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// bl 0x8218a118
	sub_8218A118(ctx, base);
	// lwz r24,92(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r26,96(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// subf r9,r8,r24
	ctx.r9.s64 = r24.s64 - ctx.r8.s64;
	// lwz r27,48(r29)
	r27.u64 = PPC_LOAD_U32(r29.u32 + 48);
	// subf r7,r8,r26
	ctx.r7.s64 = r26.s64 - ctx.r8.s64;
	// lwz r23,100(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r11,r9,-1
	r11.s64 = ctx.r9.s64 + -1;
	// addi r10,r7,-1
	ctx.r10.s64 = ctx.r7.s64 + -1;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// cntlzw r6,r10
	ctx.r6.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// subf r10,r11,r31
	ctx.r10.s64 = r31.s64 - r11.s64;
	// subf r11,r6,r31
	r11.s64 = r31.s64 - ctx.r6.s64;
	// addi r10,r10,32
	ctx.r10.s64 = ctx.r10.s64 + 32;
	// addi r11,r11,32
	r11.s64 = r11.s64 + 32;
	// rlwinm r25,r27,23,30,31
	r25.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 23) & 0x3;
	// cmplwi cr6,r25,2
	cr6.compare<uint32_t>(r25.u32, 2, xer);
	// slw r4,r5,r10
	ctx.r4.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r5.u32 << (ctx.r10.u8 & 0x3F));
	// slw r3,r5,r11
	ctx.r3.u64 = r11.u8 & 0x20 ? 0 : (ctx.r5.u32 << (r11.u8 & 0x3F));
	// stw r4,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r4.u32);
	// stw r3,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r3.u32);
	// bne cr6,0x8218aa8c
	if (!cr6.getEQ()) goto loc_8218AA8C;
	// subf r11,r8,r23
	r11.s64 = r23.s64 - ctx.r8.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// subf r11,r11,r31
	r11.s64 = r31.s64 - r11.s64;
	// addi r11,r11,32
	r11.s64 = r11.s64 + 32;
	// slw r30,r5,r11
	r30.u64 = r11.u8 & 0x20 ? 0 : (ctx.r5.u32 << (r11.u8 & 0x3F));
	// b 0x8218aa90
	goto loc_8218AA90;
loc_8218AA8C:
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
loc_8218AA90:
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// bne cr6,0x8218ab58
	if (!cr6.getEQ()) goto loc_8218AB58;
	// cmplwi cr6,r4,16
	cr6.compare<uint32_t>(ctx.r4.u32, 16, xer);
	// ble cr6,0x8218aaac
	if (!cr6.getGT()) goto loc_8218AAAC;
	// cmplwi cr6,r3,16
	cr6.compare<uint32_t>(ctx.r3.u32, 16, xer);
	// bgt cr6,0x8218aab4
	if (cr6.getGT()) goto loc_8218AAB4;
loc_8218AAAC:
	// rlwinm. r11,r27,0,20,20
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8218aac0
	if (!cr0.getEQ()) goto loc_8218AAC0;
loc_8218AAB4:
	// stw r24,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r24.u32);
	// stw r26,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r26.u32);
	// stw r23,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r23.u32);
loc_8218AAC0:
	// lwz r28,28(r29)
	r28.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// rlwinm r30,r28,1,31,31
	r30.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 1) & 0x1;
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// bl 0x8218a368
	sub_8218A368(ctx, base);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8218ab48
	if (!cr6.getEQ()) goto loc_8218AB48;
	// lwz r11,32(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// rlwinm. r10,r11,0,21,21
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218ab48
	if (!cr0.getEQ()) goto loc_8218AB48;
	// rlwinm. r10,r27,0,20,20
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218ab48
	if (!cr0.getEQ()) goto loc_8218AB48;
	// cmplwi cr6,r25,1
	cr6.compare<uint32_t>(r25.u32, 1, xer);
	// bne cr6,0x8218ab48
	if (!cr6.getEQ()) goto loc_8218AB48;
	// lwz r10,44(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 44);
	// rlwinm. r10,r10,0,22,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x3C0;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218ab48
	if (!cr0.getEQ()) goto loc_8218AB48;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8218ab48
	if (!cr6.getEQ()) goto loc_8218AB48;
	// addi r5,r1,100
	ctx.r5.s64 = ctx.r1.s64 + 100;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// clrlwi r3,r11,26
	ctx.r3.u64 = r11.u32 & 0x3F;
	// bl 0x8218a248
	sub_8218A248(ctx, base);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// add r10,r11,r26
	ctx.r10.u64 = r11.u64 + r26.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// andc r11,r10,r11
	r11.u64 = ctx.r10.u64 & ~r11.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
loc_8218AB48:
	// rlwinm r11,r28,10,23,31
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 10) & 0x1FF;
	// mullw r11,r11,r20
	r11.s64 = int64_t(r11.s32) * int64_t(r20.s32);
	// rlwinm r31,r11,2,3,29
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x1FFFFFFC;
	// b 0x8218acb0
	goto loc_8218ACB0;
loc_8218AB58:
	// srw r11,r9,r22
	r11.u64 = r22.u8 & 0x20 ? 0 : (ctx.r9.u32 >> (r22.u8 & 0x3F));
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bgt cr6,0x8218ab70
	if (cr6.getGT()) goto loc_8218AB70;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
loc_8218AB70:
	// srw r10,r7,r22
	ctx.r10.u64 = r22.u8 & 0x20 ? 0 : (ctx.r7.u32 >> (r22.u8 & 0x3F));
	// add r24,r11,r8
	r24.u64 = r11.u64 + ctx.r8.u64;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bgt cr6,0x8218ab84
	if (cr6.getGT()) goto loc_8218AB84;
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
loc_8218AB84:
	// add r26,r10,r8
	r26.u64 = ctx.r10.u64 + ctx.r8.u64;
	// cmplwi cr6,r25,2
	cr6.compare<uint32_t>(r25.u32, 2, xer);
	// bne cr6,0x8218abac
	if (!cr6.getEQ()) goto loc_8218ABAC;
	// subf r11,r8,r23
	r11.s64 = r23.s64 - ctx.r8.s64;
	// srw r11,r11,r22
	r11.u64 = r22.u8 & 0x20 ? 0 : (r11.u32 >> (r22.u8 & 0x3F));
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bgt cr6,0x8218aba4
	if (cr6.getGT()) goto loc_8218ABA4;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
loc_8218ABA4:
	// add r23,r11,r8
	r23.u64 = r11.u64 + ctx.r8.u64;
	// b 0x8218abb0
	goto loc_8218ABB0;
loc_8218ABAC:
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
loc_8218ABB0:
	// rlwinm. r11,r27,0,20,20
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218ac44
	if (cr0.getEQ()) goto loc_8218AC44;
	// subf r10,r8,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r8.s64;
	// subf r11,r8,r6
	r11.s64 = ctx.r6.s64 - ctx.r8.s64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// cntlzw r7,r11
	ctx.r7.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// subf r11,r10,r31
	r11.s64 = r31.s64 - ctx.r10.s64;
	// subf r10,r7,r31
	ctx.r10.s64 = r31.s64 - ctx.r7.s64;
	// addi r11,r11,32
	r11.s64 = r11.s64 + 32;
	// addi r10,r10,32
	ctx.r10.s64 = ctx.r10.s64 + 32;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// blt cr6,0x8218abec
	if (cr6.getLT()) goto loc_8218ABEC;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8218ABEC:
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bgt 0x8218abf8
	if (cr0.getGT()) goto loc_8218ABF8;
	// li r11,0
	r11.s64 = 0;
loc_8218ABF8:
	// cmplw cr6,r22,r11
	cr6.compare<uint32_t>(r22.u32, r11.u32, xer);
	// blt cr6,0x8218ac44
	if (cr6.getLT()) goto loc_8218AC44;
	// subf r10,r8,r9
	ctx.r10.s64 = ctx.r9.s64 - ctx.r8.s64;
	// subf r11,r8,r6
	r11.s64 = ctx.r6.s64 - ctx.r8.s64;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// cntlzw r9,r11
	ctx.r9.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// subf r11,r10,r31
	r11.s64 = r31.s64 - ctx.r10.s64;
	// subf r10,r9,r31
	ctx.r10.s64 = r31.s64 - ctx.r9.s64;
	// addi r11,r11,32
	r11.s64 = r11.s64 + 32;
	// addi r10,r10,32
	ctx.r10.s64 = ctx.r10.s64 + 32;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// blt cr6,0x8218ac34
	if (cr6.getLT()) goto loc_8218AC34;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8218AC34:
	// addic. r11,r11,-4
	xer.ca = r11.u32 > 3;
	r11.s64 = r11.s64 + -4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r22,r11
	r22.u64 = r11.u64;
	// bgt 0x8218ac44
	if (cr0.getGT()) goto loc_8218AC44;
	// li r22,0
	r22.s64 = 0;
loc_8218AC44:
	// srw r11,r4,r22
	r11.u64 = r22.u8 & 0x20 ? 0 : (ctx.r4.u32 >> (r22.u8 & 0x3F));
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// bgt cr6,0x8218ac58
	if (cr6.getGT()) goto loc_8218AC58;
	// stw r5,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r5.u32);
loc_8218AC58:
	// srw r11,r3,r22
	r11.u64 = r22.u8 & 0x20 ? 0 : (ctx.r3.u32 >> (r22.u8 & 0x3F));
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// bgt cr6,0x8218ac6c
	if (cr6.getGT()) goto loc_8218AC6C;
	// stw r5,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r5.u32);
loc_8218AC6C:
	// srw r11,r30,r22
	r11.u64 = r22.u8 & 0x20 ? 0 : (r30.u32 >> (r22.u8 & 0x3F));
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bgt cr6,0x8218ac80
	if (cr6.getGT()) goto loc_8218AC80;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
loc_8218AC80:
	// lwz r11,28(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// mr r8,r25
	ctx.r8.u64 = r25.u64;
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
	// rlwinm r9,r11,1,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x8218a368
	sub_8218A368(ctx, base);
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// mullw r11,r11,r20
	r11.s64 = int64_t(r11.s32) * int64_t(r20.s32);
	// rlwinm r31,r11,29,3,31
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFF;
loc_8218ACB0:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r24,0(r19)
	PPC_STORE_U32(r19.u32 + 0, r24.u32);
	// mullw r11,r31,r11
	r11.s64 = int64_t(r31.s32) * int64_t(r11.s32);
	// stw r26,0(r18)
	PPC_STORE_U32(r18.u32 + 0, r26.u32);
	// stw r23,0(r17)
	PPC_STORE_U32(r17.u32 + 0, r23.u32);
	// stw r31,0(r16)
	PPC_STORE_U32(r16.u32 + 0, r31.u32);
	// stw r11,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r11.u32);
	// lwz r10,28(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 28);
	// rlwinm. r10,r10,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218acf0
	if (!cr0.getEQ()) goto loc_8218ACF0;
	// cmplwi cr6,r22,1
	cr6.compare<uint32_t>(r22.u32, 1, xer);
	// bgt cr6,0x8218acf0
	if (cr6.getGT()) goto loc_8218ACF0;
	// cmpwi cr6,r14,3
	cr6.compare<int32_t>(r14.s32, 3, xer);
	// beq cr6,0x8218ad0c
	if (cr6.getEQ()) goto loc_8218AD0C;
	// cmpwi cr6,r14,20
	cr6.compare<int32_t>(r14.s32, 20, xer);
	// beq cr6,0x8218ad0c
	if (cr6.getEQ()) goto loc_8218AD0C;
loc_8218ACF0:
	// lwz r10,48(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 48);
	// rlwinm r10,r10,0,21,22
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x600;
	// cmplwi cr6,r10,1024
	cr6.compare<uint32_t>(ctx.r10.u32, 1024, xer);
	// beq cr6,0x8218ad0c
	if (cr6.getEQ()) goto loc_8218AD0C;
	// addi r11,r11,4095
	r11.s64 = r11.s64 + 4095;
	// rlwinm r11,r11,0,0,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFF000;
	// stw r11,0(r15)
	PPC_STORE_U32(r15.u32 + 0, r11.u32);
loc_8218AD0C:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x823ed150
	return;
}

__attribute__((alias("__imp__sub_8218AD18"))) PPC_WEAK_FUNC(sub_8218AD18);
PPC_FUNC_IMPL(__imp__sub_8218AD18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// addi r9,r1,88
	ctx.r9.s64 = ctx.r1.s64 + 88;
	// addi r8,r1,92
	ctx.r8.s64 = ctx.r1.s64 + 92;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8218a950
	sub_8218A950(ctx, base);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// rlwinm r7,r11,25,29,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 25) & 0x7;
	// lwz r9,32(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// rlwinm r8,r11,25,26,28
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 25) & 0x38;
	// rlwinm r6,r11,28,29,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 28) & 0x7;
	// or r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 | ctx.r7.u64;
	// rlwinm r7,r11,31,29,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7;
	// rlwinm r8,r8,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r5,r10,26,30,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 26) & 0x3;
	// or r8,r8,r6
	ctx.r8.u64 = ctx.r8.u64 | ctx.r6.u64;
	// rlwinm r6,r10,24,30,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0x3;
	// rlwinm r8,r8,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// or r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 | ctx.r7.u64;
	// rlwinm r7,r10,28,30,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0x3;
	// rlwimi r11,r8,1,0,30
	r11.u64 = (__builtin_rotateleft32(ctx.r8.u32, 1) & 0xFFFFFFFE) | (r11.u64 & 0xFFFFFFFF00000001);
	// rlwinm r8,r10,30,30,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// or r11,r11,r6
	r11.u64 = r11.u64 | ctx.r6.u64;
	// rlwinm r6,r9,26,30,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 26) & 0x3;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// or r11,r11,r5
	r11.u64 = r11.u64 | ctx.r5.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// or r11,r11,r7
	r11.u64 = r11.u64 | ctx.r7.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// or r11,r11,r8
	r11.u64 = r11.u64 | ctx.r8.u64;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// or r11,r11,r6
	r11.u64 = r11.u64 | ctx.r6.u64;
	// rlwimi r9,r11,6,0,25
	ctx.r9.u64 = (__builtin_rotateleft32(r11.u32, 6) & 0xFFFFFFC0) | (ctx.r9.u64 & 0xFFFFFFFF0000003F);
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// bl 0x8219b0d0
	sub_8219B0D0(ctx, base);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,0
	r11.s64 = 0;
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// stw r3,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r3.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r10,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r10.u32);
	// stw r9,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r9.u32);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218AE18"))) PPC_WEAK_FUNC(sub_8218AE18);
PPC_FUNC_IMPL(__imp__sub_8218AE18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// addi r9,r1,92
	ctx.r9.s64 = ctx.r1.s64 + 92;
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8218a950
	sub_8218A950(ctx, base);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// lwz r10,28(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 28);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// rlwinm r7,r11,25,29,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 25) & 0x7;
	// lwz r9,32(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// rlwinm r8,r11,25,26,28
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 25) & 0x38;
	// rlwinm r6,r11,28,29,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 28) & 0x7;
	// or r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 | ctx.r7.u64;
	// rlwinm r7,r11,31,29,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7;
	// rlwinm r8,r8,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// rlwinm r5,r10,26,30,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 26) & 0x3;
	// or r8,r8,r6
	ctx.r8.u64 = ctx.r8.u64 | ctx.r6.u64;
	// rlwinm r6,r10,24,30,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0x3;
	// rlwinm r8,r8,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// or r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 | ctx.r7.u64;
	// rlwinm r7,r10,28,30,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0x3;
	// rlwimi r11,r8,1,0,30
	r11.u64 = (__builtin_rotateleft32(ctx.r8.u32, 1) & 0xFFFFFFFE) | (r11.u64 & 0xFFFFFFFF00000001);
	// rlwinm r8,r10,30,30,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// or r11,r11,r6
	r11.u64 = r11.u64 | ctx.r6.u64;
	// rlwinm r6,r9,26,30,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 26) & 0x3;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// or r11,r11,r5
	r11.u64 = r11.u64 | ctx.r5.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// or r11,r11,r7
	r11.u64 = r11.u64 | ctx.r7.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// or r11,r11,r8
	r11.u64 = r11.u64 | ctx.r8.u64;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// or r11,r11,r6
	r11.u64 = r11.u64 | ctx.r6.u64;
	// rlwimi r9,r11,6,0,25
	ctx.r9.u64 = (__builtin_rotateleft32(r11.u32, 6) & 0xFFFFFFC0) | (ctx.r9.u64 & 0xFFFFFFFF0000003F);
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// bl 0x8219b0d0
	sub_8219B0D0(ctx, base);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r11,0
	r11.s64 = 0;
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r8,88(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stw r3,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r3.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// stw r10,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r10.u32);
	// stw r9,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r9.u32);
	// stw r8,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r8.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218AF18"))) PPC_WEAK_FUNC(sub_8218AF18);
PPC_FUNC_IMPL(__imp__sub_8218AF18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed100
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r9,356(r1)
	PPC_STORE_U32(ctx.r1.u32 + 356, ctx.r9.u32);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// stw r10,364(r1)
	PPC_STORE_U32(ctx.r1.u32 + 364, ctx.r10.u32);
	// stw r7,340(r1)
	PPC_STORE_U32(ctx.r1.u32 + 340, ctx.r7.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r11,r11,-19608
	r11.s64 = r11.s64 + -19608;
	// stw r8,348(r1)
	PPC_STORE_U32(ctx.r1.u32 + 348, ctx.r8.u32);
	// stw r4,316(r1)
	PPC_STORE_U32(ctx.r1.u32 + 316, ctx.r4.u32);
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// lwz r9,32(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwz r10,40(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm r9,r9,1,25,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0x7E;
	// lwz r8,48(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r30,r10,1,31,31
	r30.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// stw r6,332(r1)
	PPC_STORE_U32(ctx.r1.u32 + 332, ctx.r6.u32);
	// rlwinm r25,r8,23,30,31
	r25.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 23) & 0x3;
	// stw r7,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r7.u32);
	// rlwinm r27,r10,1,31,31
	r27.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// rlwinm r29,r30,1,0,30
	r29.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// lbzx r15,r9,r11
	r15.u64 = PPC_LOAD_U8(ctx.r9.u32 + r11.u32);
	// bl 0x8219b0d0
	sub_8219B0D0(ctx, base);
	// addi r6,r1,104
	ctx.r6.s64 = ctx.r1.s64 + 104;
	// addi r5,r1,116
	ctx.r5.s64 = ctx.r1.s64 + 116;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218a118
	sub_8218A118(ctx, base);
	// lwz r7,112(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r24,116(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// li r28,1
	r28.s64 = 1;
	// subf r9,r29,r7
	ctx.r9.s64 = ctx.r7.s64 - r29.s64;
	// subf r8,r29,r24
	ctx.r8.s64 = r24.s64 - r29.s64;
	// addi r11,r9,-1
	r11.s64 = ctx.r9.s64 + -1;
	// addi r10,r8,-1
	ctx.r10.s64 = ctx.r8.s64 + -1;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// cntlzw r6,r10
	ctx.r6.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// subf r10,r11,r30
	ctx.r10.s64 = r30.s64 - r11.s64;
	// subf r11,r6,r30
	r11.s64 = r30.s64 - ctx.r6.s64;
	// addi r10,r10,32
	ctx.r10.s64 = ctx.r10.s64 + 32;
	// addi r11,r11,32
	r11.s64 = r11.s64 + 32;
	// cmplwi cr6,r25,2
	cr6.compare<uint32_t>(r25.u32, 2, xer);
	// slw r26,r28,r10
	r26.u64 = ctx.r10.u8 & 0x20 ? 0 : (r28.u32 << (ctx.r10.u8 & 0x3F));
	// slw r19,r28,r11
	r19.u64 = r11.u8 & 0x20 ? 0 : (r28.u32 << (r11.u8 & 0x3F));
	// bne cr6,0x8218affc
	if (!cr6.getEQ()) goto loc_8218AFFC;
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// subf r11,r29,r11
	r11.s64 = r11.s64 - r29.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// subf r11,r11,r30
	r11.s64 = r30.s64 - r11.s64;
	// addi r11,r11,32
	r11.s64 = r11.s64 + 32;
	// slw r16,r28,r11
	r16.u64 = r11.u8 & 0x20 ? 0 : (r28.u32 << (r11.u8 & 0x3F));
	// b 0x8218b000
	goto loc_8218B000;
loc_8218AFFC:
	// mr r16,r28
	r16.u64 = r28.u64;
loc_8218B000:
	// cmplwi cr6,r26,16
	cr6.compare<uint32_t>(r26.u32, 16, xer);
	// ble cr6,0x8218b010
	if (!cr6.getGT()) goto loc_8218B010;
	// cmplwi cr6,r19,16
	cr6.compare<uint32_t>(r19.u32, 16, xer);
	// bgt cr6,0x8218b020
	if (cr6.getGT()) goto loc_8218B020;
loc_8218B010:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// mr r30,r28
	r30.u64 = r28.u64;
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8218b024
	if (!cr0.getEQ()) goto loc_8218B024;
loc_8218B020:
	// li r30,0
	r30.s64 = 0;
loc_8218B024:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x8218b03c
	if (cr6.getEQ()) goto loc_8218B03C;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x8218b03c
	if (!cr6.getEQ()) goto loc_8218B03C;
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// b 0x8218b040
	goto loc_8218B040;
loc_8218B03C:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
loc_8218B040:
	// rlwinm r14,r11,0,0,19
	r14.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFF000;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// bne cr6,0x8218b128
	if (!cr6.getEQ()) goto loc_8218B128;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x8218b128
	if (!cr6.getEQ()) goto loc_8218B128;
	// lwz r29,48(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// lwz r30,32(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// rlwinm r27,r29,23,30,31
	r27.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 23) & 0x3;
	// clrlwi r28,r30,26
	r28.u64 = r30.u32 & 0x3F;
	// stw r7,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r7.u32);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// stw r24,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r24.u32);
	// addi r4,r1,100
	ctx.r4.s64 = ctx.r1.s64 + 100;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// bl 0x8218a368
	sub_8218A368(ctx, base);
	// lwz r26,28(r31)
	r26.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// rlwinm. r11,r26,0,0,0
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8218b0f8
	if (!cr0.getEQ()) goto loc_8218B0F8;
	// rlwinm. r11,r30,0,21,21
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8218b0f8
	if (!cr0.getEQ()) goto loc_8218B0F8;
	// rlwinm. r11,r29,0,20,20
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8218b0f8
	if (!cr0.getEQ()) goto loc_8218B0F8;
	// cmplwi cr6,r27,1
	cr6.compare<uint32_t>(r27.u32, 1, xer);
	// bne cr6,0x8218b0f8
	if (!cr6.getEQ()) goto loc_8218B0F8;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// rlwinm. r11,r11,0,22,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x3C0;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8218b0f8
	if (!cr0.getEQ()) goto loc_8218B0F8;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// rlwinm. r11,r11,0,0,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8218b0f8
	if (!cr0.getEQ()) goto loc_8218B0F8;
	// addi r5,r1,100
	ctx.r5.s64 = ctx.r1.s64 + 100;
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8218a248
	sub_8218A248(ctx, base);
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// add r10,r11,r24
	ctx.r10.u64 = r11.u64 + r24.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// andc r19,r10,r11
	r19.u64 = ctx.r10.u64 & ~r11.u64;
	// b 0x8218b0fc
	goto loc_8218B0FC;
loc_8218B0F8:
	// lwz r19,100(r1)
	r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
loc_8218B0FC:
	// lwz r16,96(r1)
	r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// bne cr6,0x8218b118
	if (!cr6.getEQ()) goto loc_8218B118;
	// lwz r11,108(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// mullw r11,r11,r15
	r11.s64 = int64_t(r11.s32) * int64_t(r15.s32);
	// rlwinm r30,r11,29,3,31
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFF;
	// b 0x8218b33c
	goto loc_8218B33C;
loc_8218B118:
	// rlwinm r11,r26,10,23,31
	r11.u64 = __builtin_rotateleft64(r26.u32 | (r26.u64 << 32), 10) & 0x1FF;
	// mullw r11,r11,r15
	r11.s64 = int64_t(r11.s32) * int64_t(r15.s32);
	// rlwinm r30,r11,2,3,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x1FFFFFFC;
	// b 0x8218b33c
	goto loc_8218B33C;
loc_8218B128:
	// srw r10,r9,r23
	ctx.r10.u64 = r23.u8 & 0x20 ? 0 : (ctx.r9.u32 >> (r23.u8 & 0x3F));
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bgt cr6,0x8218b138
	if (cr6.getGT()) goto loc_8218B138;
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
loc_8218B138:
	// add r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 + r29.u64;
	// srw r11,r8,r23
	r11.u64 = r23.u8 & 0x20 ? 0 : (ctx.r8.u32 >> (r23.u8 & 0x3F));
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
	// bgt cr6,0x8218b150
	if (cr6.getGT()) goto loc_8218B150;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8218B150:
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// cmplwi cr6,r25,2
	cr6.compare<uint32_t>(r25.u32, 2, xer);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
	// bne cr6,0x8218b184
	if (!cr6.getEQ()) goto loc_8218B184;
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// subf r11,r29,r11
	r11.s64 = r11.s64 - r29.s64;
	// srw r11,r11,r23
	r11.u64 = r23.u8 & 0x20 ? 0 : (r11.u32 >> (r23.u8 & 0x3F));
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bgt cr6,0x8218b178
	if (cr6.getGT()) goto loc_8218B178;
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8218B178:
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// b 0x8218b188
	goto loc_8218B188;
loc_8218B184:
	// stw r28,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r28.u32);
loc_8218B188:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8219b0d0
	sub_8219B0D0(ctx, base);
	// cmpwi cr6,r3,18
	cr6.compare<int32_t>(ctx.r3.s32, 18, xer);
	// beq cr6,0x8218b1a8
	if (cr6.getEQ()) goto loc_8218B1A8;
	// cmpwi cr6,r3,19
	cr6.compare<int32_t>(ctx.r3.s32, 19, xer);
	// beq cr6,0x8218b1a8
	if (cr6.getEQ()) goto loc_8218B1A8;
	// mr r17,r28
	r17.u64 = r28.u64;
	// b 0x8218b1c8
	goto loc_8218B1C8;
loc_8218B1A8:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// rlwinm r11,r11,23,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 23) & 0x2;
	// rlwinm r10,r10,6,26,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0x3F;
	// slw r11,r28,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r28.u32 << (r11.u8 & 0x3F));
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// andc r17,r10,r11
	r17.u64 = ctx.r10.u64 & ~r11.u64;
loc_8218B1C8:
	// cntlzw r11,r26
	r11.u64 = r26.u32 == 0 ? 32 : __builtin_clz(r26.u32);
	// cntlzw r10,r19
	ctx.r10.u64 = r19.u32 == 0 ? 32 : __builtin_clz(r19.u32);
	// cntlzw r9,r16
	ctx.r9.u64 = r16.u32 == 0 ? 32 : __builtin_clz(r16.u32);
	// subfic r24,r11,31
	xer.ca = r11.u32 <= 31;
	r24.s64 = 31 - r11.s64;
	// subfic r25,r10,31
	xer.ca = ctx.r10.u32 <= 31;
	r25.s64 = 31 - ctx.r10.s64;
	// subfic r26,r9,31
	xer.ca = ctx.r9.u32 <= 31;
	r26.s64 = 31 - ctx.r9.s64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x8218b1fc
	if (cr6.getEQ()) goto loc_8218B1FC;
	// mr r20,r23
	r20.u64 = r23.u64;
	// addi r24,r24,1
	r24.s64 = r24.s64 + 1;
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// b 0x8218b200
	goto loc_8218B200;
loc_8218B1FC:
	// addi r20,r23,-1
	r20.s64 = r23.s64 + -1;
loc_8218B200:
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// blt cr6,0x8218b338
	if (cr6.getLT()) goto loc_8218B338;
	// lwz r18,48(r31)
	r18.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// rlwinm r22,r18,23,30,31
	r22.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 23) & 0x3;
	// rlwinm r21,r11,1,31,31
	r21.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// clrlwi r23,r10,26
	r23.u64 = ctx.r10.u32 & 0x3F;
loc_8218B220:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x8218b22c
	if (cr6.getEQ()) goto loc_8218B22C;
	// addi r24,r24,-1
	r24.s64 = r24.s64 + -1;
loc_8218B22C:
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8218b238
	if (cr6.getEQ()) goto loc_8218B238;
	// addi r25,r25,-1
	r25.s64 = r25.s64 + -1;
loc_8218B238:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x8218b244
	if (cr6.getEQ()) goto loc_8218B244;
	// addi r26,r26,-1
	r26.s64 = r26.s64 + -1;
loc_8218B244:
	// slw r11,r28,r26
	r11.u64 = r26.u8 & 0x20 ? 0 : (r28.u32 << (r26.u8 & 0x3F));
	// slw r29,r28,r24
	r29.u64 = r24.u8 & 0x20 ? 0 : (r28.u32 << (r24.u8 & 0x3F));
	// slw r27,r28,r25
	r27.u64 = r25.u8 & 0x20 ? 0 : (r28.u32 << (r25.u8 & 0x3F));
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// mr r7,r23
	ctx.r7.u64 = r23.u64;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// mr r6,r15
	ctx.r6.u64 = r15.u64;
	// stw r29,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r29.u32);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// stw r27,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r27.u32);
	// addi r4,r1,100
	ctx.r4.s64 = ctx.r1.s64 + 100;
	// addi r3,r1,108
	ctx.r3.s64 = ctx.r1.s64 + 108;
	// bl 0x8218a368
	sub_8218A368(ctx, base);
	// lwz r11,108(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// cmplwi cr6,r29,16
	cr6.compare<uint32_t>(r29.u32, 16, xer);
	// mullw r11,r11,r15
	r11.s64 = int64_t(r11.s32) * int64_t(r15.s32);
	// rlwinm r30,r11,29,3,31
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFF;
	// ble cr6,0x8218b298
	if (!cr6.getGT()) goto loc_8218B298;
	// cmplwi cr6,r27,16
	cr6.compare<uint32_t>(r27.u32, 16, xer);
	// bgt cr6,0x8218b2a0
	if (cr6.getGT()) goto loc_8218B2A0;
loc_8218B298:
	// rlwinm. r11,r18,0,20,20
	r11.u64 = __builtin_rotateleft64(r18.u32 | (r18.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8218b2f0
	if (!cr0.getEQ()) goto loc_8218B2F0;
loc_8218B2A0:
	// lwz r19,100(r1)
	r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmpwi cr6,r20,0
	cr6.compare<int32_t>(r20.s32, 0, xer);
	// lwz r16,96(r1)
	r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// ble cr6,0x8218b2e4
	if (!cr6.getGT()) goto loc_8218B2E4;
	// cmplwi cr6,r22,2
	cr6.compare<uint32_t>(r22.u32, 2, xer);
	// beq cr6,0x8218b2cc
	if (cr6.getEQ()) goto loc_8218B2CC;
	// mullw r11,r30,r19
	r11.s64 = int64_t(r30.s32) * int64_t(r19.s32);
	// addi r11,r11,4095
	r11.s64 = r11.s64 + 4095;
	// rlwinm r11,r11,0,0,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFF000;
	// mullw r11,r11,r16
	r11.s64 = int64_t(r11.s32) * int64_t(r16.s32);
	// b 0x8218b2dc
	goto loc_8218B2DC;
loc_8218B2CC:
	// mullw r11,r30,r16
	r11.s64 = int64_t(r30.s32) * int64_t(r16.s32);
	// mullw r11,r11,r19
	r11.s64 = int64_t(r11.s32) * int64_t(r19.s32);
	// addi r11,r11,4095
	r11.s64 = r11.s64 + 4095;
	// rlwinm r11,r11,0,0,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFF000;
loc_8218B2DC:
	// mullw r11,r11,r17
	r11.s64 = int64_t(r11.s32) * int64_t(r17.s32);
	// add r14,r11,r14
	r14.u64 = r11.u64 + r14.u64;
loc_8218B2E4:
	// addic. r20,r20,-1
	xer.ca = r20.u32 > 0;
	r20.s64 = r20.s64 + -1;
	cr0.compare<int32_t>(r20.s32, 0, xer);
	// bge 0x8218b220
	if (!cr0.getLT()) goto loc_8218B220;
	// b 0x8218b33c
	goto loc_8218B33C;
loc_8218B2F0:
	// addi r7,r1,120
	ctx.r7.s64 = ctx.r1.s64 + 120;
	// lwz r19,100(r1)
	r19.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// addi r11,r1,124
	r11.s64 = ctx.r1.s64 + 124;
	// addi r10,r1,108
	ctx.r10.s64 = ctx.r1.s64 + 108;
	// mr r9,r23
	ctx.r9.u64 = r23.u64;
	// mullw r8,r30,r19
	ctx.r8.s64 = int64_t(r30.s32) * int64_t(r19.s32);
	// stw r7,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r7.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// slw r6,r28,r26
	ctx.r6.u64 = r26.u8 & 0x20 ? 0 : (r28.u32 << (r26.u8 & 0x3F));
	// slw r5,r28,r25
	ctx.r5.u64 = r25.u8 & 0x20 ? 0 : (r28.u32 << (r25.u8 & 0x3F));
	// slw r4,r28,r24
	ctx.r4.u64 = r24.u8 & 0x20 ? 0 : (r28.u32 << (r24.u8 & 0x3F));
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x8218a7f8
	sub_8218A7F8(ctx, base);
	// lwz r16,96(r1)
	r16.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r3,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r3.u32);
	// add r14,r14,r3
	r14.u64 = r14.u64 + ctx.r3.u64;
	// b 0x8218b33c
	goto loc_8218B33C;
loc_8218B338:
	// lwz r30,124(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
loc_8218B33C:
	// mullw r11,r30,r19
	r11.s64 = int64_t(r30.s32) * int64_t(r19.s32);
	// lwz r8,316(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 316);
	// addi r10,r11,4095
	ctx.r10.s64 = r11.s64 + 4095;
	// rlwinm r9,r10,0,0,19
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFF000;
	// mullw r9,r9,r8
	ctx.r9.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r8.s32);
	// lwz r8,388(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 388);
	// add r9,r9,r14
	ctx.r9.u64 = ctx.r9.u64 + r14.u64;
	// stw r9,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r9.u32);
	// lwz r9,332(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 332);
	// stw r30,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r30.u32);
	// lwz r9,48(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwinm r9,r9,0,21,22
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x600;
	// cmplwi cr6,r9,1024
	cr6.compare<uint32_t>(ctx.r9.u32, 1024, xer);
	// lwz r9,340(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// beq cr6,0x8218b384
	if (cr6.getEQ()) goto loc_8218B384;
	// rlwinm r11,r10,0,0,19
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFF000;
	// mullw r10,r11,r16
	ctx.r10.s64 = int64_t(r11.s32) * int64_t(r16.s32);
	// b 0x8218b390
	goto loc_8218B390;
loc_8218B384:
	// mullw r10,r11,r16
	ctx.r10.s64 = int64_t(r11.s32) * int64_t(r16.s32);
	// addi r10,r10,4095
	ctx.r10.s64 = ctx.r10.s64 + 4095;
	// rlwinm r10,r10,0,0,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFF000;
loc_8218B390:
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// lwz r11,348(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r10,364(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,372(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,380(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r10,356(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// b 0x823ed150
	return;
}

__attribute__((alias("__imp__sub_8218B3D8"))) PPC_WEAK_FUNC(sub_8218B3D8);
PPC_FUNC_IMPL(__imp__sub_8218B3D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// mr r30,r7
	r30.u64 = ctx.r7.u64;
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// mr r29,r8
	r29.u64 = ctx.r8.u64;
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// mr r7,r9
	ctx.r7.u64 = ctx.r9.u64;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// addi r10,r1,124
	ctx.r10.s64 = ctx.r1.s64 + 124;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
	// addi r8,r1,116
	ctx.r8.s64 = ctx.r1.s64 + 116;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x8218af18
	sub_8218AF18(ctx, base);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r1,124
	ctx.r4.s64 = ctx.r1.s64 + 124;
	// clrlwi r3,r11,26
	ctx.r3.u64 = r11.u32 & 0x3F;
	// bl 0x8218a248
	sub_8218A248(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lis r10,512
	ctx.r10.s64 = 33554432;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mullw r11,r11,r9
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r9.s32);
	// lwz r9,116(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r8,0(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lwz r7,48(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lwz r6,32(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// subf r8,r8,r11
	ctx.r8.s64 = r11.s64 - ctx.r8.s64;
	// rlwinm r7,r7,0,0,19
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0xFFFFF000;
	// rlwinm r6,r6,0,0,19
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFF000;
	// li r4,14
	ctx.r4.s64 = 14;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8219b348
	sub_8219B348(ctx, base);
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// add r11,r3,r11
	r11.u64 = ctx.r3.u64 + r11.u64;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_8218B4A0"))) PPC_WEAK_FUNC(sub_8218B4A0);
PPC_FUNC_IMPL(__imp__sub_8218B4A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r31,r7
	r31.u64 = ctx.r7.u64;
	// mr r6,r8
	ctx.r6.u64 = ctx.r8.u64;
	// addi r10,r1,88
	ctx.r10.s64 = ctx.r1.s64 + 88;
	// addi r9,r1,92
	ctx.r9.s64 = ctx.r1.s64 + 92;
	// addi r8,r1,84
	ctx.r8.s64 = ctx.r1.s64 + 84;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8218b3d8
	sub_8218B3D8(ctx, base);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8218b518
	if (cr6.getEQ()) goto loc_8218B518;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// lwz r10,32(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 32);
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,-19608
	r11.s64 = r11.s64 + -19608;
	// rlwinm r7,r10,1,25,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x7E;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// mullw r10,r10,r9
	ctx.r10.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
	// lbzx r11,r7,r11
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + r11.u32);
	// mullw r11,r11,r8
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r8.s32);
	// rlwinm r11,r11,29,3,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFF;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// b 0x8218b51c
	goto loc_8218B51C;
loc_8218B518:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_8218B51C:
	// stw r9,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r9.u32);
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_8218B530"))) PPC_WEAK_FUNC(sub_8218B530);
PPC_FUNC_IMPL(__imp__sub_8218B530) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed114
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r20,340(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// rlwinm r11,r20,1,0,30
	r11.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r22,r7
	r22.u64 = ctx.r7.u64;
	// mr r24,r8
	r24.u64 = ctx.r8.u64;
	// mr r31,r9
	r31.u64 = ctx.r9.u64;
	// mr r26,r10
	r26.u64 = ctx.r10.u64;
	// cmpwi cr6,r19,3
	cr6.compare<int32_t>(r19.s32, 3, xer);
	// addi r25,r11,1
	r25.s64 = r11.s64 + 1;
	// beq cr6,0x8218b5e0
	if (cr6.getEQ()) goto loc_8218B5E0;
	// cmpwi cr6,r19,17
	cr6.compare<int32_t>(r19.s32, 17, xer);
	// beq cr6,0x8218b5a4
	if (cr6.getEQ()) goto loc_8218B5A4;
	// cmpwi cr6,r19,18
	cr6.compare<int32_t>(r19.s32, 18, xer);
	// beq cr6,0x8218b59c
	if (cr6.getEQ()) goto loc_8218B59C;
	// cmpwi cr6,r19,19
	cr6.compare<int32_t>(r19.s32, 19, xer);
	// beq cr6,0x8218b5e0
	if (cr6.getEQ()) goto loc_8218B5E0;
	// cmpwi cr6,r19,20
	cr6.compare<int32_t>(r19.s32, 20, xer);
	// bne cr6,0x8218b5e8
	if (!cr6.getEQ()) goto loc_8218B5E8;
	// li r30,0
	r30.s64 = 0;
	// li r26,0
	r26.s64 = 0;
	// b 0x8218b5f4
	goto loc_8218B5F4;
loc_8218B59C:
	// li r30,3
	r30.s64 = 3;
	// b 0x8218b5f4
	goto loc_8218B5F4;
loc_8218B5A4:
	// li r30,2
	r30.s64 = 2;
loc_8218B5A8:
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
loc_8218B5AC:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// bne cr6,0x8218b5c8
	if (!cr6.getEQ()) goto loc_8218B5C8;
	// mr r6,r20
	ctx.r6.u64 = r20.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8218a2e0
	sub_8218A2E0(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
loc_8218B5C8:
	// cmpwi cr6,r26,2
	cr6.compare<int32_t>(r26.s32, 2, xer);
	// bne cr6,0x8218b5fc
	if (!cr6.getEQ()) goto loc_8218B5FC;
	// subfic r11,r22,1
	xer.ca = r22.u32 <= 1;
	r11.s64 = 1 - r22.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// clrlwi r23,r11,31
	r23.u64 = r11.u32 & 0x1;
	// b 0x8218b600
	goto loc_8218B600;
loc_8218B5E0:
	// li r30,1
	r30.s64 = 1;
	// b 0x8218b5ec
	goto loc_8218B5EC;
loc_8218B5E8:
	// lwz r30,136(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
loc_8218B5EC:
	// cmpwi cr6,r19,17
	cr6.compare<int32_t>(r19.s32, 17, xer);
	// beq cr6,0x8218b5a8
	if (cr6.getEQ()) goto loc_8218B5A8;
loc_8218B5F4:
	// li r5,1
	ctx.r5.s64 = 1;
	// b 0x8218b5ac
	goto loc_8218B5AC;
loc_8218B5FC:
	// mr r23,r26
	r23.u64 = r26.u64;
loc_8218B600:
	// lwz r11,356(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// addi r7,r1,132
	ctx.r7.s64 = ctx.r1.s64 + 132;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lwz r21,348(r1)
	r21.u64 = PPC_LOAD_U32(ctx.r1.u32 + 348);
	// clrlwi r26,r31,26
	r26.u64 = r31.u32 & 0x3F;
	// stw r20,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r20.u32);
	// mr r10,r23
	ctx.r10.u64 = r23.u64;
	// rlwinm r9,r31,24,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 24) & 0x1;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// addi r11,r1,136
	r11.s64 = ctx.r1.s64 + 136;
	// stw r7,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r7.u32);
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// stw r4,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r4.u32);
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// stw r21,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r21.u32);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r11.u32);
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// bl 0x8218a488
	sub_8218A488(ctx, base);
	// lis r8,16
	ctx.r8.s64 = 1048576;
	// ori r8,r8,3
	ctx.r8.u64 = ctx.r8.u64 | 3;
	// rlwinm. r11,r24,0,29,29
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218b66c
	if (cr0.getEQ()) goto loc_8218B66C;
	// lis r8,48
	ctx.r8.s64 = 3145728;
	// ori r8,r8,3
	ctx.r8.u64 = ctx.r8.u64 | 3;
loc_8218B66C:
	// rlwinm. r11,r24,0,22,22
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218b678
	if (cr0.getEQ()) goto loc_8218B678;
	// oris r8,r8,64
	ctx.r8.u64 = ctx.r8.u64 | 4194304;
loc_8218B678:
	// lwz r11,364(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// lis r9,-1
	ctx.r9.s64 = -65536;
	// cmplwi cr6,r30,1
	cr6.compare<uint32_t>(r30.u32, 1, xer);
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// li r8,1
	ctx.r8.s64 = 1;
	// stw r9,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r9.u32);
	// rlwimi r10,r30,9,21,22
	ctx.r10.u64 = (__builtin_rotateleft32(r30.u32, 9) & 0x600) | (ctx.r10.u64 & 0xFFFFFFFFFFFFF9FF);
	// stw r9,24(r11)
	PPC_STORE_U32(r11.u32 + 24, ctx.r9.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
	// stw r9,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r9.u32);
	// blt cr6,0x8218b73c
	if (cr6.getLT()) goto loc_8218B73C;
	// beq cr6,0x8218b704
	if (cr6.getEQ()) goto loc_8218B704;
	// cmplwi cr6,r30,3
	cr6.compare<uint32_t>(r30.u32, 3, xer);
	// blt cr6,0x8218b6d8
	if (cr6.getLT()) goto loc_8218B6D8;
	// bne cr6,0x8218b74c
	if (!cr6.getEQ()) goto loc_8218B74C;
	// subf r9,r25,r28
	ctx.r9.s64 = r28.s64 - r25.s64;
	// subf r8,r25,r29
	ctx.r8.s64 = r29.s64 - r25.s64;
	// addi r7,r27,-1
	ctx.r7.s64 = r27.s64 + -1;
	// rlwimi r8,r9,13,6,18
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r9.u32, 13) & 0x3FFE000) | (ctx.r8.u64 & 0xFFFFFFFFFC001FFF);
	// rlwimi r8,r7,26,0,5
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r7.u32, 26) & 0xFC000000) | (ctx.r8.u64 & 0xFFFFFFFF03FFFFFF);
	// b 0x8218b748
	goto loc_8218B748;
loc_8218B6D8:
	// lwz r9,36(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// subf r8,r25,r29
	ctx.r8.s64 = r29.s64 - r25.s64;
	// subf r7,r25,r28
	ctx.r7.s64 = r28.s64 - r25.s64;
	// rlwimi r8,r9,0,0,20
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0xFFFFF800) | (ctx.r8.u64 & 0xFFFFFFFF000007FF);
	// subf r9,r25,r27
	ctx.r9.s64 = r27.s64 - r25.s64;
	// rlwinm r7,r7,11,10,20
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 11) & 0x3FF800;
	// rlwinm r9,r9,22,0,9
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 22) & 0xFFC00000;
	// stw r8,36(r11)
	PPC_STORE_U32(r11.u32 + 36, ctx.r8.u32);
	// rotlwi r8,r8,0
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 0);
	// clrlwi r8,r8,21
	ctx.r8.u64 = ctx.r8.u32 & 0x7FF;
	// b 0x8218b72c
	goto loc_8218B72C;
loc_8218B704:
	// lwz r9,36(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// subf r8,r25,r29
	ctx.r8.s64 = r29.s64 - r25.s64;
	// subf r7,r25,r28
	ctx.r7.s64 = r28.s64 - r25.s64;
	// rlwimi r8,r9,0,0,18
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0xFFFFE000) | (ctx.r8.u64 & 0xFFFFFFFF00001FFF);
	// addi r9,r27,-1
	ctx.r9.s64 = r27.s64 + -1;
	// rlwinm r7,r7,13,6,18
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 13) & 0x3FFE000;
	// rlwinm r9,r9,26,0,5
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 26) & 0xFC000000;
	// stw r8,36(r11)
	PPC_STORE_U32(r11.u32 + 36, ctx.r8.u32);
	// rotlwi r8,r8,0
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r8.u32, 0);
	// clrlwi r8,r8,19
	ctx.r8.u64 = ctx.r8.u32 & 0x1FFF;
loc_8218B72C:
	// or r9,r7,r9
	ctx.r9.u64 = ctx.r7.u64 | ctx.r9.u64;
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
	// stw r9,36(r11)
	PPC_STORE_U32(r11.u32 + 36, ctx.r9.u32);
	// b 0x8218b74c
	goto loc_8218B74C;
loc_8218B73C:
	// lwz r9,36(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// subf r8,r25,r29
	ctx.r8.s64 = r29.s64 - r25.s64;
	// rlwimi r8,r9,0,0,7
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0xFF000000) | (ctx.r8.u64 & 0xFFFFFFFF00FFFFFF);
loc_8218B748:
	// stw r8,36(r11)
	PPC_STORE_U32(r11.u32 + 36, ctx.r8.u32);
loc_8218B74C:
	// srawi r6,r31,15
	xer.ca = (r31.s32 < 0) & ((r31.u32 & 0x7FFF) != 0);
	ctx.r6.s64 = r31.s32 >> 15;
	// lwz r9,28(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// srawi r4,r31,13
	xer.ca = (r31.s32 < 0) & ((r31.u32 & 0x1FFF) != 0);
	ctx.r4.s64 = r31.s32 >> 13;
	// lwz r8,32(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// srawi r3,r31,11
	xer.ca = (r31.s32 < 0) & ((r31.u32 & 0x7FF) != 0);
	ctx.r3.s64 = r31.s32 >> 11;
	// lwz r5,40(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// srawi r30,r31,9
	xer.ca = (r31.s32 < 0) & ((r31.u32 & 0x1FF) != 0);
	r30.s64 = r31.s32 >> 9;
	// lwz r7,44(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// srawi r29,r31,8
	xer.ca = (r31.s32 < 0) & ((r31.u32 & 0xFF) != 0);
	r29.s64 = r31.s32 >> 8;
	// srawi r28,r31,6
	xer.ca = (r31.s32 < 0) & ((r31.u32 & 0x3F) != 0);
	r28.s64 = r31.s32 >> 6;
	// srawi r27,r31,27
	xer.ca = (r31.s32 < 0) & ((r31.u32 & 0x7FFFFFF) != 0);
	r27.s64 = r31.s32 >> 27;
	// rlwinm r25,r20,21,0,10
	r25.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 21) & 0xFFE00000;
	// clrlwi r27,r27,29
	r27.u64 = r27.u32 & 0x7;
	// rlwimi r4,r6,2,28,29
	ctx.r4.u64 = (__builtin_rotateleft32(ctx.r6.u32, 2) & 0xC) | (ctx.r4.u64 & 0xFFFFFFFFFFFFFFF3);
	// lwz r6,128(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// or r27,r27,r25
	r27.u64 = r27.u64 | r25.u64;
	// clrlwi r4,r4,28
	ctx.r4.u64 = ctx.r4.u32 & 0xF;
	// srawi r25,r31,24
	xer.ca = (r31.s32 < 0) & ((r31.u32 & 0xFFFFFF) != 0);
	r25.s64 = r31.s32 >> 24;
	// rlwimi r27,r21,3,23,28
	r27.u64 = (__builtin_rotateleft32(r21.u32, 3) & 0x1F8) | (r27.u64 & 0xFFFFFFFFFFFFFE07);
	// rlwimi r6,r29,14,0,17
	ctx.r6.u64 = (__builtin_rotateleft32(r29.u32, 14) & 0xFFFFC000) | (ctx.r6.u64 & 0xFFFFFFFF00003FFF);
	// rlwimi r3,r4,2,0,29
	ctx.r3.u64 = (__builtin_rotateleft32(ctx.r4.u32, 2) & 0xFFFFFFFC) | (ctx.r3.u64 & 0xFFFFFFFF00000003);
	// srawi r4,r31,21
	xer.ca = (r31.s32 < 0) & ((r31.u32 & 0x1FFFFF) != 0);
	ctx.r4.s64 = r31.s32 >> 21;
	// rlwimi r25,r27,3,0,28
	r25.u64 = (__builtin_rotateleft32(r27.u32, 3) & 0xFFFFFFF8) | (r25.u64 & 0xFFFFFFFF00000007);
	// rlwimi r9,r6,17,0,9
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r6.u32, 17) & 0xFFC00000) | (ctx.r9.u64 & 0xFFFFFFFF003FFFFF);
	// rlwimi r4,r25,3,0,28
	ctx.r4.u64 = (__builtin_rotateleft32(r25.u32, 3) & 0xFFFFFFF8) | (ctx.r4.u64 & 0xFFFFFFFF00000007);
	// srawi r6,r31,18
	xer.ca = (r31.s32 < 0) & ((r31.u32 & 0x3FFFF) != 0);
	ctx.r6.s64 = r31.s32 >> 18;
	// rlwimi r30,r3,2,0,29
	r30.u64 = (__builtin_rotateleft32(ctx.r3.u32, 2) & 0xFFFFFFFC) | (r30.u64 & 0xFFFFFFFF00000003);
	// addi r24,r19,-19
	r24.s64 = r19.s64 + -19;
	// rlwimi r6,r4,3,0,28
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r4.u32, 3) & 0xFFFFFFF8) | (ctx.r6.u64 & 0xFFFFFFFF00000007);
	// rlwimi r10,r23,11,20,20
	ctx.r10.u64 = (__builtin_rotateleft32(r23.u32, 11) & 0x800) | (ctx.r10.u64 & 0xFFFFFFFFFFFFF7FF);
	// srawi r4,r31,17
	xer.ca = (r31.s32 < 0) & ((r31.u32 & 0x1FFFF) != 0);
	ctx.r4.s64 = r31.s32 >> 17;
	// rlwinm r9,r9,0,0,21
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFC00;
	// rlwinm r3,r30,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// cntlzw r29,r24
	r29.u64 = r24.u32 == 0 ? 32 : __builtin_clz(r24.u32);
	// rlwimi r4,r6,1,0,30
	ctx.r4.u64 = (__builtin_rotateleft32(ctx.r6.u32, 1) & 0xFFFFFFFE) | (ctx.r4.u64 & 0xFFFFFFFF00000001);
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
	// rlwinm r8,r8,0,0,25
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFC0;
	// or r9,r3,r9
	ctx.r9.u64 = ctx.r3.u64 | ctx.r9.u64;
	// rlwinm r29,r29,27,31,31
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 27) & 0x1;
	// rlwinm r6,r5,0,1,12
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x7FF80000;
	// or r8,r8,r26
	ctx.r8.u64 = ctx.r8.u64 | r26.u64;
	// ori r9,r9,2
	ctx.r9.u64 = ctx.r9.u64 | 2;
	// or r10,r4,r6
	ctx.r10.u64 = ctx.r4.u64 | ctx.r6.u64;
	// rlwimi r28,r29,4,27,27
	r28.u64 = (__builtin_rotateleft32(r29.u32, 4) & 0x10) | (r28.u64 & 0xFFFFFFFFFFFFFFEF);
	// addi r30,r22,-1
	r30.s64 = r22.s64 + -1;
	// rlwimi r8,r28,6,24,25
	ctx.r8.u64 = (__builtin_rotateleft32(r28.u32, 6) & 0xC0) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFF3F);
	// stw r9,28(r11)
	PPC_STORE_U32(r11.u32 + 28, ctx.r9.u32);
	// rlwimi r7,r30,6,22,25
	ctx.r7.u64 = (__builtin_rotateleft32(r30.u32, 6) & 0x3C0) | (ctx.r7.u64 & 0xFFFFFFFFFFFFFC3F);
	// stw r10,40(r11)
	PPC_STORE_U32(r11.u32 + 40, ctx.r10.u32);
	// rlwimi r8,r28,6,21,21
	ctx.r8.u64 = (__builtin_rotateleft32(r28.u32, 6) & 0x400) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFBFF);
	// lwz r10,372(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// lwz r9,132(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// stw r7,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r7.u32);
	// stw r8,32(r11)
	PPC_STORE_U32(r11.u32 + 32, ctx.r8.u32);
	// lwz r11,136(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r10,380(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 380);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x823ed164
	return;
}

__attribute__((alias("__imp__sub_8218B840"))) PPC_WEAK_FUNC(sub_8218B840);
PPC_FUNC_IMPL(__imp__sub_8218B840) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed118
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// clrlwi r24,r28,26
	r24.u64 = r28.u32 & 0x3F;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// mr r31,r8
	r31.u64 = ctx.r8.u64;
	// mr r21,r9
	r21.u64 = ctx.r9.u64;
	// mr r20,r10
	r20.u64 = ctx.r10.u64;
	// li r22,1
	r22.s64 = 1;
	// cmplwi cr6,r24,22
	cr6.compare<uint32_t>(r24.u32, 22, xer);
	// beq cr6,0x8218b888
	if (cr6.getEQ()) goto loc_8218B888;
	// cmplwi cr6,r24,23
	cr6.compare<uint32_t>(r24.u32, 23, xer);
	// li r25,0
	r25.s64 = 0;
	// bne cr6,0x8218b88c
	if (!cr6.getEQ()) goto loc_8218B88C;
loc_8218B888:
	// mr r25,r22
	r25.u64 = r22.u64;
loc_8218B88C:
	// cmplwi cr6,r24,54
	cr6.compare<uint32_t>(r24.u32, 54, xer);
	// bne cr6,0x8218b898
	if (!cr6.getEQ()) goto loc_8218B898;
	// li r24,7
	r24.s64 = 7;
loc_8218B898:
	// li r11,4
	r11.s64 = 4;
	// stw r22,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r22.u32);
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r10,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r10.u32);
	// li r23,-1
	r23.s64 = -1;
	// bl 0x8218a1d8
	sub_8218A1D8(ctx, base);
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x8218b908
	if (cr6.getEQ()) goto loc_8218B908;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r10,r27
	ctx.r10.u64 = r27.u64;
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// blt cr6,0x8218b8e0
	if (cr6.getLT()) goto loc_8218B8E0;
	// rlwinm r10,r27,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 1) & 0xFFFFFFFE;
loc_8218B8E0:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// bne cr6,0x8218b8ec
	if (!cr6.getEQ()) goto loc_8218B8EC;
	// rlwinm r11,r29,1,0,30
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
loc_8218B8EC:
	// addi r11,r11,31
	r11.s64 = r11.s64 + 31;
	// addi r10,r10,15
	ctx.r10.s64 = ctx.r10.s64 + 15;
	// rlwinm r11,r11,27,5,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x7FFFFFF;
	// rlwinm r10,r10,28,4,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0xFFFFFFF;
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// clrlwi r7,r11,9
	ctx.r7.u64 = r11.u32 & 0x7FFFFF;
	// b 0x8218b90c
	goto loc_8218B90C;
loc_8218B908:
	// li r7,0
	ctx.r7.s64 = 0;
loc_8218B90C:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x8218b924
	if (cr6.getEQ()) goto loc_8218B924;
	// lwz r9,0(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// lwz r23,4(r26)
	r23.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// lwz r8,8(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// b 0x8218b948
	goto loc_8218B948;
loc_8218B924:
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x8218b948
	if (cr6.getEQ()) goto loc_8218B948;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lwz r11,-31440(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -31440);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8218b948
	if (!cr6.getEQ()) goto loc_8218B948;
	// li r23,0
	r23.s64 = 0;
loc_8218B948:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x8218b958
	if (cr6.getEQ()) goto loc_8218B958;
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// bne cr6,0x8218b974
	if (!cr6.getEQ()) goto loc_8218B974;
loc_8218B958:
	// li r10,80
	ctx.r10.s64 = 80;
	// addi r11,r29,79
	r11.s64 = r29.s64 + 79;
	// divwu r11,r11,r10
	r11.u32 = r11.u32 / ctx.r10.u32;
	// mulli r10,r11,80
	ctx.r10.s64 = r11.s64 * 80;
	// addi r11,r29,31
	r11.s64 = r29.s64 + 31;
	// rlwinm r11,r11,0,0,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFE0;
	// b 0x8218b98c
	goto loc_8218B98C;
loc_8218B974:
	// li r10,40
	ctx.r10.s64 = 40;
	// addi r11,r29,39
	r11.s64 = r29.s64 + 39;
	// divwu r11,r11,r10
	r11.u32 = r11.u32 / ctx.r10.u32;
	// mulli r10,r11,40
	ctx.r10.s64 = r11.s64 * 40;
	// addi r11,r29,15
	r11.s64 = r29.s64 + 15;
	// rlwinm r11,r11,0,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFF0;
loc_8218B98C:
	// lwz r6,36(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// addi r5,r29,-1
	ctx.r5.s64 = r29.s64 + -1;
	// rlwimi r30,r11,2,0,29
	r30.u64 = (__builtin_rotateleft32(r11.u32, 2) & 0xFFFFFFFC) | (r30.u64 & 0xFFFFFFFF00000003);
	// stw r28,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r28.u32);
	// rlwinm r5,r5,18,0,13
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 18) & 0xFFFC0000;
	// clrlwi r6,r6,29
	ctx.r6.u64 = ctx.r6.u32 & 0x7;
	// clrlwi r10,r10,18
	ctx.r10.u64 = ctx.r10.u32 & 0x3FFF;
	// or r6,r5,r6
	ctx.r6.u64 = ctx.r5.u64 | ctx.r6.u64;
	// addi r5,r27,-1
	ctx.r5.s64 = r27.s64 + -1;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// rlwimi r6,r5,3,14,28
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r5.u32, 3) & 0x3FFF8) | (ctx.r6.u64 & 0xFFFFFFFFFFFC0007);
	// rlwinm r5,r30,16,0,15
	ctx.r5.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 16) & 0xFFFF0000;
	// addi r11,r11,-19608
	r11.s64 = r11.s64 + -19608;
	// or r10,r5,r10
	ctx.r10.u64 = ctx.r5.u64 | ctx.r10.u64;
	// rlwinm r5,r24,1,0,30
	ctx.r5.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r6,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r6.u32);
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// stw r10,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r10.u32);
	// lhzx r11,r5,r11
	r11.u64 = PPC_LOAD_U16(ctx.r5.u32 + r11.u32);
	// rlwinm r11,r11,24,28,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 24) & 0xF;
	// beq cr6,0x8218ba28
	if (cr6.getEQ()) goto loc_8218BA28;
	// rlwinm r11,r11,16,15,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0x10000;
	// clrlwi r10,r9,20
	ctx.r10.u64 = ctx.r9.u32 & 0xFFF;
	// cmpwi cr6,r23,-1
	cr6.compare<int32_t>(r23.s32, -1, xer);
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// beq cr6,0x8218ba1c
	if (cr6.getEQ()) goto loc_8218BA1C;
	// addi r11,r24,-22
	r11.s64 = r24.s64 + -22;
	// rlwinm r10,r23,13,0,18
	ctx.r10.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 13) & 0xFFFFE000;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// rlwimi r22,r11,4,0,27
	r22.u64 = (__builtin_rotateleft32(r11.u32, 4) & 0xFFFFFFF0) | (r22.u64 & 0xFFFFFFFF0000000F);
	// stw r22,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r22.u32);
	// b 0x8218ba7c
	goto loc_8218BA7C;
loc_8218BA1C:
	// li r11,0
	r11.s64 = 0;
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// b 0x8218ba7c
	goto loc_8218BA7C;
loc_8218BA28:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8218ba68
	if (!cr6.getEQ()) goto loc_8218BA68;
	// rlwinm. r10,r28,0,14,14
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0x20000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218ba68
	if (!cr0.getEQ()) goto loc_8218BA68;
	// rlwinm r10,r28,0,21,22
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0x600;
	// cmpwi cr6,r10,1536
	cr6.compare<int32_t>(ctx.r10.s32, 1536, xer);
	// bne cr6,0x8218ba68
	if (!cr6.getEQ()) goto loc_8218BA68;
	// rlwinm r10,r28,0,19,20
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0x1800;
	// cmpwi cr6,r10,6144
	cr6.compare<int32_t>(ctx.r10.s32, 6144, xer);
	// bne cr6,0x8218ba68
	if (!cr6.getEQ()) goto loc_8218BA68;
	// rlwinm r10,r28,0,17,18
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0x6000;
	// cmpwi cr6,r10,24576
	cr6.compare<int32_t>(ctx.r10.s32, 24576, xer);
	// bne cr6,0x8218ba68
	if (!cr6.getEQ()) goto loc_8218BA68;
	// rlwinm. r10,r28,0,15,16
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0x18000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218ba68
	if (!cr0.getEQ()) goto loc_8218BA68;
	// mr r11,r22
	r11.u64 = r22.u64;
loc_8218BA68:
	// rlwimi r11,r8,4,22,27
	r11.u64 = (__builtin_rotateleft32(ctx.r8.u32, 4) & 0x3F0) | (r11.u64 & 0xFFFFFFFFFFFFFC0F);
	// clrlwi r10,r9,20
	ctx.r10.u64 = ctx.r9.u32 & 0xFFF;
	// rlwinm r11,r11,16,6,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0x3FF0000;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
loc_8218BA7C:
	// mulli r11,r3,5120
	r11.s64 = ctx.r3.s64 * 5120;
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// stw r3,0(r21)
	PPC_STORE_U32(r21.u32 + 0, ctx.r3.u32);
	// stw r7,0(r20)
	PPC_STORE_U32(r20.u32 + 0, ctx.r7.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x823ed168
	return;
}

__attribute__((alias("__imp__sub_8218BA98"))) PPC_WEAK_FUNC(sub_8218BA98);
PPC_FUNC_IMPL(__imp__sub_8218BA98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,44(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 44);
	// rlwinm r11,r11,26,28,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0xF;
	// addi r3,r11,1
	ctx.r3.s64 = r11.s64 + 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218BAA8"))) PPC_WEAK_FUNC(sub_8218BAA8);
PPC_FUNC_IMPL(__imp__sub_8218BAA8) {
	PPC_FUNC_PROLOGUE();
	// mr r8,r7
	ctx.r8.u64 = ctx.r7.u64;
	// mr r7,r6
	ctx.r7.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// b 0x8218b4a0
	sub_8218B4A0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218BAC0"))) PPC_WEAK_FUNC(sub_8218BAC0);
PPC_FUNC_IMPL(__imp__sub_8218BAC0) {
	PPC_FUNC_PROLOGUE();
	// b 0x8218ad18
	sub_8218AD18(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218BAC8"))) PPC_WEAK_FUNC(sub_8218BAC8);
PPC_FUNC_IMPL(__imp__sub_8218BAC8) {
	PPC_FUNC_PROLOGUE();
	// b 0x8218b4a0
	sub_8218B4A0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218BAD0"))) PPC_WEAK_FUNC(sub_8218BAD0);
PPC_FUNC_IMPL(__imp__sub_8218BAD0) {
	PPC_FUNC_PROLOGUE();
	// b 0x8218ae18
	sub_8218AE18(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218BAD8"))) PPC_WEAK_FUNC(sub_8218BAD8);
PPC_FUNC_IMPL(__imp__sub_8218BAD8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed120
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// li r30,0
	r30.s64 = 0;
	// lis r4,25728
	ctx.r4.s64 = 1686110208;
	// li r3,52
	ctx.r3.s64 = 52;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// mr r24,r8
	r24.u64 = ctx.r8.u64;
	// mr r23,r10
	r23.u64 = ctx.r10.u64;
	// mr r22,r30
	r22.u64 = r30.u64;
	// bl 0x8209d000
	sub_8209D000(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x8218bb24
	if (!cr0.getEQ()) goto loc_8218BB24;
loc_8218BB1C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8218bbf0
	goto loc_8218BBF0;
loc_8218BB24:
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// addi r11,r1,132
	r11.s64 = ctx.r1.s64 + 132;
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// li r10,2
	ctx.r10.s64 = 2;
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// mr r9,r24
	ctx.r9.u64 = r24.u64;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// stw r8,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r8.u32);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r11.u32);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8218b530
	sub_8218B530(ctx, base);
	// not r11,r29
	r11.u64 = ~r29.u64;
	// lwz r3,128(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// rlwinm r11,r11,30,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// rlwinm r11,r11,28,0,3
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 28) & 0xF0000000;
	// oris r30,r11,35968
	r30.u64 = r11.u64 | 2357198848;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8209d000
	sub_8209D000(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// bne 0x8218bba0
	if (!cr0.getEQ()) goto loc_8218BBA0;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8218BB98:
	// bl 0x8209d060
	sub_8209D060(ctx, base);
	// b 0x8218bb1c
	goto loc_8218BB1C;
loc_8218BBA0:
	// lwz r3,132(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8218bbd4
	if (cr6.getEQ()) goto loc_8218BBD4;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8209d000
	sub_8209D000(ctx, base);
	// mr. r22,r3
	r22.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r22.s32, 0, xer);
	// bne 0x8218bbd4
	if (!cr0.getEQ()) goto loc_8218BBD4;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8209d060
	sub_8209D060(ctx, base);
	// lis r4,-20096
	ctx.r4.s64 = -1317011456;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// b 0x8218bb98
	goto loc_8218BB98;
loc_8218BBD4:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// rlwimi r11,r29,0,0,19
	r11.u64 = (__builtin_rotateleft32(r29.u32, 0) & 0xFFFFF000) | (r11.u64 & 0xFFFFFFFF00000FFF);
	// rlwimi r22,r10,0,20,31
	r22.u64 = (__builtin_rotateleft32(ctx.r10.u32, 0) & 0xFFF) | (r22.u64 & 0xFFFFFFFFFFFFF000);
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// stw r22,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r22.u32);
loc_8218BBF0:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x823ed170
	return;
}

__attribute__((alias("__imp__sub_8218BBF8"))) PPC_WEAK_FUNC(sub_8218BBF8);
PPC_FUNC_IMPL(__imp__sub_8218BBF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// lis r4,25728
	ctx.r4.s64 = 1686110208;
	// li r3,48
	ctx.r3.s64 = 48;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r30,r7
	r30.u64 = ctx.r7.u64;
	// bl 0x8209d000
	sub_8209D000(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x8218bc34
	if (!cr0.getEQ()) goto loc_8218BC34;
loc_8218BC2C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8218bd18
	goto loc_8218BD18;
loc_8218BC34:
	// addi r10,r1,84
	ctx.r10.s64 = ctx.r1.s64 + 84;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8218b840
	sub_8218B840(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// oris r11,r11,16
	r11.u64 = r11.u64 | 1048576;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bne cr6,0x8218bd14
	if (!cr6.getEQ()) goto loc_8218BD14;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// clrlwi r11,r11,26
	r11.u64 = r11.u32 & 0x3F;
	// cmplwi cr6,r11,22
	cr6.compare<uint32_t>(r11.u32, 22, xer);
	// beq cr6,0x8218bc88
	if (cr6.getEQ()) goto loc_8218BC88;
	// cmplwi cr6,r11,23
	cr6.compare<uint32_t>(r11.u32, 23, xer);
	// li r29,0
	r29.s64 = 0;
	// bne cr6,0x8218bc8c
	if (!cr6.getEQ()) goto loc_8218BC8C;
loc_8218BC88:
	// li r29,1
	r29.s64 = 1;
loc_8218BC8C:
	// lwz r30,80(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8219c148
	sub_8219C148(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8218bcb4
	if (!cr0.getEQ()) goto loc_8218BCB4;
loc_8218BCA4:
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8209d060
	sub_8209D060(ctx, base);
	// b 0x8218bc2c
	goto loc_8218BC2C;
loc_8218BCB4:
	// lwz r3,84(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// add r11,r3,r30
	r11.u64 = ctx.r3.u64 + r30.u64;
	// cmplwi cr6,r11,2048
	cr6.compare<uint32_t>(r11.u32, 2048, xer);
	// ble cr6,0x8218bcd0
	if (!cr6.getGT()) goto loc_8218BCD0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8219c0f8
	sub_8219C0F8(ctx, base);
	// b 0x8218bca4
	goto loc_8218BCA4;
loc_8218BCD0:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// oris r11,r11,32768
	r11.u64 = r11.u64 | 2147483648;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// rlwimi r3,r11,0,0,19
	ctx.r3.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFF000) | (ctx.r3.u64 & 0xFFFFFFFF00000FFF);
	// stw r3,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r3.u32);
	// beq cr6,0x8218bd14
	if (cr6.getEQ()) goto loc_8218BD14;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lwz r10,-31440(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -31440);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x8218bd14
	if (!cr6.getEQ()) goto loc_8218BD14;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r10,-31440(r11)
	PPC_STORE_U32(r11.u32 + -31440, ctx.r10.u32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// clrlwi r11,r11,15
	r11.u64 = r11.u32 & 0x1FFFF;
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
loc_8218BD14:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8218BD18:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_8218BD20"))) PPC_WEAK_FUNC(sub_8218BD20);
PPC_FUNC_IMPL(__imp__sub_8218BD20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218bd58
	if (cr0.getEQ()) goto loc_8218BD58;
	// lwz r11,28(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,24(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// rlwinm r4,r11,4,28,31
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xF;
	// bl 0x8218ad18
	sub_8218AD18(ctx, base);
	// b 0x8218bd9c
	goto loc_8218BD9C;
loc_8218BD58:
	// lwz r10,40(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	// li r11,0
	r11.s64 = 0;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// rlwinm r11,r11,14,18,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 14) & 0x3FFF;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
	// lwz r11,36(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 36);
	// rlwinm r11,r11,29,17,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0x7FFF;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r11.u32);
	// lhz r11,24(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 24);
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
loc_8218BD9C:
	// li r11,4
	r11.s64 = 4;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218BDB8"))) PPC_WEAK_FUNC(sub_8218BDB8);
PPC_FUNC_IMPL(__imp__sub_8218BDB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,28(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lwz r3,24(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// rlwinm r4,r11,4,28,31
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xF;
	// bl 0x8218ae18
	sub_8218AE18(ctx, base);
	// li r11,16
	r11.s64 = 16;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218BE00"))) PPC_WEAK_FUNC(sub_8218BE00);
PPC_FUNC_IMPL(__imp__sub_8218BE00) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed124
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r4,3134
	r11.s64 = ctx.r4.s64 + 3134;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// rlwinm r28,r11,2,0,29
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// lwzx r27,r28,r31
	r27.u64 = PPC_LOAD_U32(r28.u32 + r31.u32);
	// beq cr6,0x8218bf04
	if (cr6.getEQ()) goto loc_8218BF04;
	// lwz r8,32(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 32);
	// addi r11,r4,48
	r11.s64 = ctx.r4.s64 + 48;
	// lwz r7,48(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 48);
	// add r4,r31,r4
	ctx.r4.u64 = r31.u64 + ctx.r4.u64;
	// rlwinm r29,r8,12,20,31
	r29.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 12) & 0xFFF;
	// lwz r9,44(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 44);
	// rlwinm r30,r7,12,20,31
	r30.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 12) & 0xFFF;
	// lwz r26,28(r5)
	r26.u64 = PPC_LOAD_U32(ctx.r5.u32 + 28);
	// mulli r11,r11,24
	r11.s64 = r11.s64 * 24;
	// lwz r25,40(r5)
	r25.u64 = PPC_LOAD_U32(ctx.r5.u32 + 40);
	// lwz r24,36(r5)
	r24.u64 = PPC_LOAD_U32(ctx.r5.u32 + 36);
	// lbz r3,11942(r4)
	ctx.r3.u64 = PPC_LOAD_U8(ctx.r4.u32 + 11942);
	// addi r29,r29,512
	r29.s64 = r29.s64 + 512;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// addi r23,r30,512
	r23.s64 = r30.s64 + 512;
	// rlwinm r30,r29,0,19,19
	r30.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 0) & 0x1000;
	// clrlwi r29,r8,3
	r29.u64 = ctx.r8.u32 & 0x1FFFFFFF;
	// rlwinm r8,r23,0,19,19
	ctx.r8.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 0) & 0x1000;
	// add r30,r30,r29
	r30.u64 = r30.u64 + r29.u64;
	// lwz r23,16(r11)
	r23.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// lwz r29,0(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r7,r7,0,3,22
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x1FFFFE00;
	// rlwinm r9,r9,30,28,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0xF;
	// stw r24,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r24.u32);
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// lwz r7,4(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwimi r10,r23,0,30,21
	ctx.r10.u64 = (__builtin_rotateleft32(r23.u32, 0) & 0xFFFFFFFFFFFFFC03) | (ctx.r10.u64 & 0x3FC);
	// lwz r23,12(r11)
	r23.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// rlwimi r26,r29,0,10,21
	r26.u64 = (__builtin_rotateleft32(r29.u32, 0) & 0x3FFC00) | (r26.u64 & 0xFFFFFFFFFFC003FF);
	// lwz r29,20(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwimi r30,r7,0,20,20
	r30.u64 = (__builtin_rotateleft32(ctx.r7.u32, 0) & 0x800) | (r30.u64 & 0xFFFFFFFFFFFFF7FF);
	// rlwimi r25,r23,0,1,12
	r25.u64 = (__builtin_rotateleft32(r23.u32, 0) & 0x7FF80000) | (r25.u64 & 0xFFFFFFFF8007FFFF);
	// rlwimi r8,r29,0,23,31
	ctx.r8.u64 = (__builtin_rotateleft32(r29.u32, 0) & 0x1FF) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFE00);
	// cmplw cr6,r9,r3
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r3.u32, xer);
	// stw r10,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r10.u32);
	// stw r26,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r26.u32);
	// stw r30,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r30.u32);
	// stw r25,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r25.u32);
	// stw r8,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r8.u32);
	// ble cr6,0x8218bed0
	if (!cr6.getGT()) goto loc_8218BED0;
	// lwz r9,44(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 44);
	// rlwinm r3,r9,30,28,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0xF;
loc_8218BED0:
	// lwz r8,44(r5)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + 44);
	// rlwimi r10,r3,2,26,29
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r3.u32, 2) & 0x3C) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFC3);
	// lbz r9,11968(r4)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r4.u32 + 11968);
	// rlwinm r8,r8,26,28,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 26) & 0xF;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// stw r10,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r10.u32);
	// bge cr6,0x8218bef0
	if (!cr6.getLT()) goto loc_8218BEF0;
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
loc_8218BEF0:
	// ld r8,24(r31)
	ctx.r8.u64 = PPC_LOAD_U64(r31.u32 + 24);
	// rlwimi r10,r9,6,22,25
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 6) & 0x3C0) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFC3F);
	// or r8,r8,r6
	ctx.r8.u64 = ctx.r8.u64 | ctx.r6.u64;
	// stw r10,16(r11)
	PPC_STORE_U32(r11.u32 + 16, ctx.r10.u32);
	// std r8,24(r31)
	PPC_STORE_U64(r31.u32 + 24, ctx.r8.u64);
loc_8218BF04:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// stwx r5,r28,r31
	PPC_STORE_U32(r28.u32 + r31.u32, ctx.r5.u32);
	// beq cr6,0x8218bf74
	if (cr6.getEQ()) goto loc_8218BF74;
	// lwz r11,10908(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 10908);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8218bf24
	if (cr0.getEQ()) goto loc_8218BF24;
	// stw r11,8(r27)
	PPC_STORE_U32(r27.u32 + 8, r11.u32);
	// b 0x8218bf74
	goto loc_8218BF74;
loc_8218BF24:
	// lwz r11,10912(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 10912);
	// lwz r10,0(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// and. r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218bf74
	if (cr0.getEQ()) goto loc_8218BF74;
	// lwz r3,13508(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13508);
	// lwz r11,13512(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 13512);
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// blt cr6,0x8218bf4c
	if (cr6.getLT()) goto loc_8218BF4C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8219bac8
	sub_8219BAC8(ctx, base);
loc_8218BF4C:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r10,-1
	ctx.r10.s64 = -1;
	// rlwimi r11,r27,30,2,31
	r11.u64 = (__builtin_rotateleft32(r27.u32, 30) & 0x3FFFFFFF) | (r11.u64 & 0xFFFFFFFFC0000000);
	// rlwinm r11,r11,0,2,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFBFFFFFFF;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// addi r10,r3,8
	ctx.r10.s64 = ctx.r3.s64 + 8;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,0(r3)
	PPC_STORE_U64(ctx.r3.u32 + 0, r11.u64);
	// stw r10,13508(r31)
	PPC_STORE_U32(r31.u32 + 13508, ctx.r10.u32);
loc_8218BF74:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed174
	return;
}

__attribute__((alias("__imp__sub_8218BF80"))) PPC_WEAK_FUNC(sub_8218BF80);
PPC_FUNC_IMPL(__imp__sub_8218BF80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x823ed138
	// lis r6,44
	ctx.r6.s64 = 2883584;
	// li r11,0
	r11.s64 = 0;
	// ori r30,r6,33700
	r30.u64 = ctx.r6.u64 | 33700;
	// lis r6,24
	ctx.r6.s64 = 1572864;
	// andi. r7,r3,16398
	ctx.r7.u64 = ctx.r3.u64 & 16398;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// ori r31,r6,10374
	r31.u64 = ctx.r6.u64 | 10374;
	// lis r6,42
	ctx.r6.s64 = 2752512;
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// addi r10,r4,52
	ctx.r10.s64 = ctx.r4.s64 + 52;
	// ori r6,r6,9145
	ctx.r6.u64 = ctx.r6.u64 | 9145;
	// li r5,1
	ctx.r5.s64 = 1;
	// cmplwi cr6,r7,10
	cr6.compare<uint32_t>(ctx.r7.u32, 10, xer);
	// bgt cr6,0x8218c1c0
	if (cr6.getGT()) goto loc_8218C1C0;
	// beq cr6,0x8218c118
	if (cr6.getEQ()) goto loc_8218C118;
	// cmplwi cr6,r7,2
	cr6.compare<uint32_t>(ctx.r7.u32, 2, xer);
	// beq cr6,0x8218c100
	if (cr6.getEQ()) goto loc_8218C100;
	// cmplwi cr6,r7,4
	cr6.compare<uint32_t>(ctx.r7.u32, 4, xer);
	// beq cr6,0x8218c338
	if (cr6.getEQ()) goto loc_8218C338;
	// cmplwi cr6,r7,6
	cr6.compare<uint32_t>(ctx.r7.u32, 6, xer);
	// beq cr6,0x8218c080
	if (cr6.getEQ()) goto loc_8218C080;
	// cmplwi cr6,r7,8
	cr6.compare<uint32_t>(ctx.r7.u32, 8, xer);
	// bne cr6,0x8218c338
	if (!cr6.getEQ()) goto loc_8218C338;
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// rlwinm. r9,r3,0,19,19
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// sth r11,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, r11.u16);
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// stb r11,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, r11.u8);
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// stb r5,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, ctx.r5.u8);
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
	// beq 0x8218c050
	if (cr0.getEQ()) goto loc_8218C050;
	// li r9,12
	ctx.r9.s64 = 12;
	// stw r30,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r30.u32);
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
loc_8218C024:
	// lis r9,26
	ctx.r9.s64 = 1703936;
	// li r7,16
	ctx.r7.s64 = 16;
	// ori r29,r9,8838
	r29.u64 = ctx.r9.u64 | 8838;
	// li r9,20
	ctx.r9.s64 = 20;
loc_8218C034:
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// li r28,2
	r28.s64 = 2;
	// li r8,3
	ctx.r8.s64 = 3;
	// sth r7,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r7.u16);
	// stw r29,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r29.u32);
	// stb r28,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, r28.u8);
	// b 0x8218c328
	goto loc_8218C328;
loc_8218C050:
	// rlwinm. r9,r3,0,16,16
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// li r9,12
	ctx.r9.s64 = 12;
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// beq 0x8218c068
	if (cr0.getEQ()) goto loc_8218C068;
	// stw r31,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r31.u32);
	// b 0x8218c024
	goto loc_8218C024;
loc_8218C068:
	// lis r8,44
	ctx.r8.s64 = 2883584;
	// li r9,20
	ctx.r9.s64 = 20;
	// ori r7,r8,9125
	ctx.r7.u64 = ctx.r8.u64 | 9125;
	// li r8,2
	ctx.r8.s64 = 2;
	// stw r7,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r7.u32);
	// b 0x8218c334
	goto loc_8218C334;
loc_8218C080:
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// rlwinm. r9,r3,0,19,19
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// sth r11,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, r11.u16);
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// stb r11,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, r11.u8);
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// beq 0x8218c0c4
	if (cr0.getEQ()) goto loc_8218C0C4;
	// lis r8,26
	ctx.r8.s64 = 1703936;
	// li r9,12
	ctx.r9.s64 = 12;
	// ori r7,r8,8838
	ctx.r7.u64 = ctx.r8.u64 | 8838;
	// li r8,2
	ctx.r8.s64 = 2;
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// li r9,16
	ctx.r9.s64 = 16;
	// stb r8,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, ctx.r8.u8);
	// b 0x8218c324
	goto loc_8218C324;
loc_8218C0C4:
	// rlwinm. r9,r3,0,16,16
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// li r9,12
	ctx.r9.s64 = 12;
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// li r8,2
	ctx.r8.s64 = 2;
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// li r9,16
	ctx.r9.s64 = 16;
	// beq 0x8218c0f4
	if (cr0.getEQ()) goto loc_8218C0F4;
	// stw r31,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r31.u32);
	// stb r8,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, ctx.r8.u8);
	// b 0x8218c334
	goto loc_8218C334;
loc_8218C0F4:
	// stw r30,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r30.u32);
	// stb r5,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, ctx.r5.u8);
	// b 0x8218c334
	goto loc_8218C334;
loc_8218C100:
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// li r9,12
	ctx.r9.s64 = 12;
loc_8218C108:
	// mr r8,r5
	ctx.r8.u64 = ctx.r5.u64;
	// sth r11,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, r11.u16);
	// stb r11,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, r11.u8);
	// b 0x8218c328
	goto loc_8218C328;
loc_8218C118:
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// rlwinm. r9,r3,0,19,19
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// sth r11,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, r11.u16);
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// stb r11,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, r11.u8);
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// stb r5,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, ctx.r5.u8);
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
	// beq 0x8218c174
	if (cr0.getEQ()) goto loc_8218C174;
	// li r9,12
	ctx.r9.s64 = 12;
	// lis r8,44
	ctx.r8.s64 = 2883584;
	// li r7,20
	ctx.r7.s64 = 20;
	// ori r8,r8,9125
	ctx.r8.u64 = ctx.r8.u64 | 9125;
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// lis r9,26
	ctx.r9.s64 = 1703936;
	// ori r29,r9,8838
	r29.u64 = ctx.r9.u64 | 8838;
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// li r9,24
	ctx.r9.s64 = 24;
	// b 0x8218c034
	goto loc_8218C034;
loc_8218C174:
	// rlwinm. r9,r3,0,16,16
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// li r9,12
	ctx.r9.s64 = 12;
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// li r9,24
	ctx.r9.s64 = 24;
	// beq 0x8218c1b4
	if (cr0.getEQ()) goto loc_8218C1B4;
	// lis r8,44
	ctx.r8.s64 = 2883584;
	// li r7,20
	ctx.r7.s64 = 20;
	// ori r8,r8,9125
	ctx.r8.u64 = ctx.r8.u64 | 9125;
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
loc_8218C198:
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// li r29,2
	r29.s64 = 2;
	// li r8,3
	ctx.r8.s64 = 3;
	// sth r7,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r7.u16);
	// stw r31,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r31.u32);
	// stb r29,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, r29.u8);
	// b 0x8218c328
	goto loc_8218C328;
loc_8218C1B4:
	// li r8,2
	ctx.r8.s64 = 2;
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// b 0x8218c334
	goto loc_8218C334;
loc_8218C1C0:
	// cmplwi cr6,r7,12
	cr6.compare<uint32_t>(ctx.r7.u32, 12, xer);
	// beq cr6,0x8218c298
	if (cr6.getEQ()) goto loc_8218C298;
	// cmplwi cr6,r7,14
	cr6.compare<uint32_t>(ctx.r7.u32, 14, xer);
	// beq cr6,0x8218c1ec
	if (cr6.getEQ()) goto loc_8218C1EC;
	// cmplwi cr6,r7,16386
	cr6.compare<uint32_t>(ctx.r7.u32, 16386, xer);
	// bne cr6,0x8218c338
	if (!cr6.getEQ()) goto loc_8218C338;
	// lis r9,26
	ctx.r9.s64 = 1703936;
	// ori r9,r9,9126
	ctx.r9.u64 = ctx.r9.u64 | 9126;
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// li r9,16
	ctx.r9.s64 = 16;
	// b 0x8218c108
	goto loc_8218C108;
loc_8218C1EC:
	// lis r8,26
	ctx.r8.s64 = 1703936;
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// sth r11,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, r11.u16);
	// li r9,12
	ctx.r9.s64 = 12;
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// ori r8,r8,9126
	ctx.r8.u64 = ctx.r8.u64 | 9126;
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// rlwinm. r7,r3,0,19,19
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// stb r11,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, r11.u8);
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// stb r5,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, ctx.r5.u8);
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// beq 0x8218c25c
	if (cr0.getEQ()) goto loc_8218C25C;
	// li r9,28
	ctx.r9.s64 = 28;
	// li r29,2
	r29.s64 = 2;
	// lis r8,26
	ctx.r8.s64 = 1703936;
	// ori r7,r8,8838
	ctx.r7.u64 = ctx.r8.u64 | 8838;
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// li r8,3
	ctx.r8.s64 = 3;
	// li r9,32
	ctx.r9.s64 = 32;
	// stb r29,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, r29.u8);
	// b 0x8218c324
	goto loc_8218C324;
loc_8218C25C:
	// rlwinm. r9,r3,0,16,16
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// li r9,28
	ctx.r9.s64 = 28;
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// li r7,2
	ctx.r7.s64 = 2;
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
	// li r8,3
	ctx.r8.s64 = 3;
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// li r9,32
	ctx.r9.s64 = 32;
	// stb r7,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, ctx.r7.u8);
	// beq 0x8218c290
	if (cr0.getEQ()) goto loc_8218C290;
	// stw r31,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r31.u32);
	// b 0x8218c334
	goto loc_8218C334;
loc_8218C290:
	// stw r30,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r30.u32);
	// b 0x8218c334
	goto loc_8218C334;
loc_8218C298:
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// rlwinm. r9,r3,0,19,19
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// sth r11,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, r11.u16);
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// stb r11,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, r11.u8);
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stb r5,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, ctx.r5.u8);
	// beq 0x8218c2ec
	if (cr0.getEQ()) goto loc_8218C2EC;
	// li r9,12
	ctx.r9.s64 = 12;
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// li r7,24
	ctx.r7.s64 = 24;
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// lis r9,26
	ctx.r9.s64 = 1703936;
	// ori r29,r9,8838
	r29.u64 = ctx.r9.u64 | 8838;
	// li r9,28
	ctx.r9.s64 = 28;
	// b 0x8218c034
	goto loc_8218C034;
loc_8218C2EC:
	// rlwinm. r9,r3,0,16,16
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// li r9,12
	ctx.r9.s64 = 12;
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// li r9,28
	ctx.r9.s64 = 28;
	// beq 0x8218c318
	if (cr0.getEQ()) goto loc_8218C318;
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// li r7,24
	ctx.r7.s64 = 24;
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
	// b 0x8218c198
	goto loc_8218C198;
loc_8218C318:
	// lis r8,26
	ctx.r8.s64 = 1703936;
	// ori r7,r8,9126
	ctx.r7.u64 = ctx.r8.u64 | 9126;
	// li r8,2
	ctx.r8.s64 = 2;
loc_8218C324:
	// stw r7,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r7.u32);
loc_8218C328:
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
loc_8218C334:
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
loc_8218C338:
	// rlwinm. r7,r3,0,27,27
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x8218c370
	if (cr0.getEQ()) goto loc_8218C370;
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// li r7,3
	ctx.r7.s64 = 3;
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// stw r6,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r6.u32);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,12
	ctx.r9.s64 = ctx.r9.s64 + 12;
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
	// stb r7,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, ctx.r7.u8);
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
loc_8218C370:
	// rlwinm. r7,r3,0,26,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq 0x8218c3a8
	if (cr0.getEQ()) goto loc_8218C3A8;
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// li r7,4
	ctx.r7.s64 = 4;
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// stw r30,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r30.u32);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
	// stb r7,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, ctx.r7.u8);
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
loc_8218C3A8:
	// rlwinm. r6,r3,0,25,25
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// li r7,10
	ctx.r7.s64 = 10;
	// beq 0x8218c3e0
	if (cr0.getEQ()) goto loc_8218C3E0;
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// stw r31,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r31.u32);
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// stb r7,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, ctx.r7.u8);
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// stb r11,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r11.u8);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
loc_8218C3E0:
	// rlwinm. r6,r3,0,24,24
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// beq 0x8218c414
	if (cr0.getEQ()) goto loc_8218C414;
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// stw r31,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r31.u32);
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// stb r7,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, ctx.r7.u8);
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// stb r5,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, ctx.r5.u8);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
loc_8218C414:
	// rlwinm. r31,r3,24,28,31
	r31.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 24) & 0xF;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// rlwinm r6,r3,16,16,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 16) & 0xFFFF;
	// mr r7,r11
	ctx.r7.u64 = r11.u64;
	// beq 0x8218c488
	if (cr0.getEQ()) goto loc_8218C488;
	// lis r5,-32254
	ctx.r5.s64 = -2113798144;
	// add r8,r31,r8
	ctx.r8.u64 = r31.u64 + ctx.r8.u64;
	// addi r5,r5,-19344
	ctx.r5.s64 = ctx.r5.s64 + -19344;
loc_8218C430:
	// clrlwi r30,r6,30
	r30.u64 = ctx.r6.u32 & 0x3;
	// addi r3,r5,-4
	ctx.r3.s64 = ctx.r5.s64 + -4;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// li r28,5
	r28.s64 = 5;
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// rlwinm r6,r6,30,2,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 30) & 0x3FFFFFFF;
	// lbzx r3,r30,r3
	ctx.r3.u64 = PPC_LOAD_U8(r30.u32 + ctx.r3.u32);
	// clrlwi r30,r9,16
	r30.u64 = ctx.r9.u32 & 0xFFFF;
	// sth r9,2(r10)
	PPC_STORE_U16(ctx.r10.u32 + 2, ctx.r9.u16);
	// cmplw cr6,r7,r31
	cr6.compare<uint32_t>(ctx.r7.u32, r31.u32, xer);
	// rlwinm r9,r3,0,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0xFFFFFFFC;
	// sth r11,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r11.u16);
	// add r3,r9,r5
	ctx.r3.u64 = ctx.r9.u64 + ctx.r5.u64;
	// add r9,r30,r9
	ctx.r9.u64 = r30.u64 + ctx.r9.u64;
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// lwz r3,-4(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + -4);
	// stb r11,8(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8, r11.u8);
	// stb r28,9(r10)
	PPC_STORE_U8(ctx.r10.u32 + 9, r28.u8);
	// stb r29,10(r10)
	PPC_STORE_U8(ctx.r10.u32 + 10, r29.u8);
	// stw r3,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r3.u32);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// blt cr6,0x8218c430
	if (cr6.getLT()) goto loc_8218C430;
loc_8218C488:
	// li r9,255
	ctx.r9.s64 = 255;
	// sth r11,-62(r1)
	PPC_STORE_U16(ctx.r1.u32 + -62, r11.u16);
	// stb r11,-56(r1)
	PPC_STORE_U8(ctx.r1.u32 + -56, r11.u8);
	// stb r11,-55(r1)
	PPC_STORE_U8(ctx.r1.u32 + -55, r11.u8);
	// stb r11,-54(r1)
	PPC_STORE_U8(ctx.r1.u32 + -54, r11.u8);
	// lwz r6,-56(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + -56);
	// sth r9,-64(r1)
	PPC_STORE_U16(ctx.r1.u32 + -64, ctx.r9.u16);
	// li r9,-1
	ctx.r9.s64 = -1;
	// lwz r7,-64(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + -64);
	// stw r6,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r6.u32);
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// stw r7,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r7.u32);
	// stw r8,24(r4)
	PPC_STORE_U32(ctx.r4.u32 + 24, ctx.r8.u32);
	// stw r11,28(r4)
	PPC_STORE_U32(ctx.r4.u32 + 28, r11.u32);
	// stw r11,48(r4)
	PPC_STORE_U32(ctx.r4.u32 + 48, r11.u32);
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_8218C4C8"))) PPC_WEAK_FUNC(sub_8218C4C8);
PPC_FUNC_IMPL(__imp__sub_8218C4C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lbz r11,0(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// lbz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// subf r3,r10,r11
	ctx.r3.s64 = r11.s64 - ctx.r10.s64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218C4D8"))) PPC_WEAK_FUNC(sub_8218C4D8);
PPC_FUNC_IMPL(__imp__sub_8218C4D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r5,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r5.u32);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// beq cr6,0x8218c518
	if (cr6.getEQ()) goto loc_8218C518;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
loc_8218C518:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218C530"))) PPC_WEAK_FUNC(sub_8218C530);
PPC_FUNC_IMPL(__imp__sub_8218C530) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// add r30,r11,r5
	r30.u64 = r11.u64 + ctx.r5.u64;
	// cmplw cr6,r30,r10
	cr6.compare<uint32_t>(r30.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8218c574
	if (cr6.getGT()) goto loc_8218C574;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8218c588
	if (cr6.getEQ()) goto loc_8218C588;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// b 0x8218c588
	goto loc_8218C588;
loc_8218C574:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8218c588
	if (cr6.getEQ()) goto loc_8218C588;
	// lis r11,-32768
	r11.s64 = -2147483648;
	// ori r11,r11,16389
	r11.u64 = r11.u64 | 16389;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
loc_8218C588:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// ble cr6,0x8218c59c
	if (!cr6.getGT()) goto loc_8218C59C;
	// stw r30,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r30.u32);
loc_8218C59C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218C5B8"))) PPC_WEAK_FUNC(sub_8218C5B8);
PPC_FUNC_IMPL(__imp__sub_8218C5B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r9,r11,28,4,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 28) & 0xFFFFFFF;
	// or r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 | r11.u64;
	// rlwinm r9,r9,16,28,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 16) & 0xF;
	// rlwinm. r10,r11,17,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 17) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8218c5dc
	if (cr0.getEQ()) goto loc_8218C5DC;
	// rlwinm. r8,r11,0,17,17
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x8218c5dc
	if (cr0.getEQ()) goto loc_8218C5DC;
	// li r9,15
	ctx.r9.s64 = 15;
loc_8218C5DC:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8218c5f4
	if (cr6.getEQ()) goto loc_8218C5F4;
	// clrlwi r11,r11,26
	r11.u64 = r11.u32 & 0x3F;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// li r11,1
	r11.s64 = 1;
	// blt cr6,0x8218c5f8
	if (cr6.getLT()) goto loc_8218C5F8;
loc_8218C5F4:
	// li r11,0
	r11.s64 = 0;
loc_8218C5F8:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218c60c
	if (cr0.getEQ()) goto loc_8218C60C;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// bne cr6,0x8218c610
	if (!cr6.getEQ()) goto loc_8218C610;
loc_8218C60C:
	// li r11,0
	r11.s64 = 0;
loc_8218C610:
	// clrlwi. r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beqlr 
	if (cr0.getEQ()) return;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// clrlwi r11,r9,24
	r11.u64 = ctx.r9.u32 & 0xFF;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218C630"))) PPC_WEAK_FUNC(sub_8218C630);
PPC_FUNC_IMPL(__imp__sub_8218C630) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// li r11,0
	r11.s64 = 0;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
loc_8218C638:
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r11,64
	cr6.compare<uint32_t>(r11.u32, 64, xer);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// blt cr6,0x8218c638
	if (cr6.getLT()) goto loc_8218C638;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// addi r10,r4,4
	ctx.r10.s64 = ctx.r4.s64 + 4;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr 
	if (cr0.getEQ()) return;
loc_8218C660:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// rlwinm r8,r9,16,28,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 16) & 0xF;
	// rlwinm r9,r9,14,26,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 14) & 0x3C;
	// stwx r8,r9,r3
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, ctx.r8.u32);
	// bne 0x8218c660
	if (!cr0.getEQ()) goto loc_8218C660;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218C680"))) PPC_WEAK_FUNC(sub_8218C680);
PPC_FUNC_IMPL(__imp__sub_8218C680) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bnelr 
	if (!cr0.getEQ()) return;
	// clrlwi. r11,r4,24
	r11.u64 = ctx.r4.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// beq 0x8218c6bc
	if (cr0.getEQ()) goto loc_8218C6BC;
	// rlwinm r10,r11,22,24,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 22) & 0xFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// rlwimi r11,r10,12,14,19
	r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 12) & 0x3F000) | (r11.u64 & 0xFFFFFFFFFFFC0FFF);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, r11.u32);
	// rlwinm r11,r11,29,24,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0xFC;
	// lwzx r11,r11,r8
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	// rlwimi r9,r11,5,21,26
	ctx.r9.u64 = (__builtin_rotateleft32(r11.u32, 5) & 0x7E0) | (ctx.r9.u64 & 0xFFFFFFFFFFFFF81F);
	// stw r9,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r9.u32);
	// blr 
	return;
loc_8218C6BC:
	// rlwinm. r10,r11,0,16,16
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218c6e4
	if (!cr0.getEQ()) goto loc_8218C6E4;
	// rlwinm r10,r11,26,24,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0xFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// rlwimi r11,r10,8,18,23
	r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 8) & 0x3F00) | (r11.u64 & 0xFFFFFFFFFFFFC0FF);
	// rlwinm r10,r11,2,24,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFC;
	// stw r11,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, r11.u32);
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// rlwimi r10,r11,0,0,25
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFC0) | (ctx.r10.u64 & 0xFFFFFFFF0000003F);
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
loc_8218C6E4:
	// lwz r10,8(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// lis r11,-32019
	r11.s64 = -2098397184;
	// lwz r6,0(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// addi r11,r11,27348
	r11.s64 = r11.s64 + 27348;
	// rlwinm r9,r10,8,27,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0x1F;
	// addi r5,r11,32
	ctx.r5.s64 = r11.s64 + 32;
	// rlwinm r4,r6,6,26,31
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0x3F;
	// lbzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + r11.u32);
	// lbzx r5,r4,r5
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r4.u32 + ctx.r5.u32);
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// blt cr6,0x8218c730
	if (cr6.getLT()) goto loc_8218C730;
	// rlwinm. r11,r10,0,0,0
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218c730
	if (cr0.getEQ()) goto loc_8218C730;
	// lbz r11,9(r7)
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 9);
	// rlwinm r10,r11,2,24,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFC;
	// rlwinm r11,r11,0,0,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFC0;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// stb r11,9(r7)
	PPC_STORE_U8(ctx.r7.u32 + 9, r11.u8);
loc_8218C730:
	// cmplwi cr6,r9,2
	cr6.compare<uint32_t>(ctx.r9.u32, 2, xer);
	// blt cr6,0x8218c75c
	if (cr6.getLT()) goto loc_8218C75C;
	// lwz r11,8(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218c75c
	if (cr0.getEQ()) goto loc_8218C75C;
	// lbz r11,10(r7)
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 10);
	// rlwinm r10,r11,2,24,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFC;
	// rlwinm r11,r11,0,0,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFC0;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// stb r11,10(r7)
	PPC_STORE_U8(ctx.r7.u32 + 10, r11.u8);
loc_8218C75C:
	// cmplwi cr6,r9,3
	cr6.compare<uint32_t>(ctx.r9.u32, 3, xer);
	// bge cr6,0x8218c76c
	if (!cr6.getLT()) goto loc_8218C76C;
	// cmplwi cr6,r5,1
	cr6.compare<uint32_t>(ctx.r5.u32, 1, xer);
	// bne cr6,0x8218c790
	if (!cr6.getEQ()) goto loc_8218C790;
loc_8218C76C:
	// lwz r11,8(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// rlwinm. r10,r11,0,2,2
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8218c790
	if (cr0.getEQ()) goto loc_8218C790;
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// rlwinm r10,r11,2,24,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFC;
	// rlwinm r11,r11,0,24,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xC0;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// stb r11,11(r7)
	PPC_STORE_U8(ctx.r7.u32 + 11, r11.u8);
loc_8218C790:
	// cmplwi cr6,r5,2
	cr6.compare<uint32_t>(ctx.r5.u32, 2, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
	// lwz r11,8(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
	// lwz r10,4(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// rlwimi r9,r11,30,4,4
	ctx.r9.u64 = (__builtin_rotateleft32(r11.u32, 30) & 0x8000000) | (ctx.r9.u64 & 0xFFFFFFFFF7FFFFFF);
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
	// rlwimi r5,r9,6,30,31
	ctx.r5.u64 = (__builtin_rotateleft32(ctx.r9.u32, 6) & 0x3) | (ctx.r5.u64 & 0xFFFFFFFFFFFFFFFC);
	// clrlwi r9,r5,26
	ctx.r9.u64 = ctx.r5.u32 & 0x3F;
	// rlwinm r5,r9,2,24,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFC;
	// rlwinm r9,r9,0,0,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFC0;
	// lwzx r8,r5,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r5.u32 + ctx.r8.u32);
	// or r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 | ctx.r9.u64;
	// rlwimi r10,r9,0,26,29
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0x3C) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFC3);
	// rlwimi r11,r9,28,2,2
	r11.u64 = (__builtin_rotateleft32(ctx.r9.u32, 28) & 0x20000000) | (r11.u64 & 0xFFFFFFFFDFFFFFFF);
	// rlwimi r6,r9,26,5,5
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r9.u32, 26) & 0x4000000) | (ctx.r6.u64 & 0xFFFFFFFFFBFFFFFF);
	// stb r10,7(r7)
	PPC_STORE_U8(ctx.r7.u32 + 7, ctx.r10.u8);
	// stw r11,8(r7)
	PPC_STORE_U32(ctx.r7.u32 + 8, r11.u32);
	// stw r6,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r6.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218C7E0"))) PPC_WEAK_FUNC(sub_8218C7E0);
PPC_FUNC_IMPL(__imp__sub_8218C7E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bnelr 
	if (!cr0.getEQ()) return;
	// clrlwi. r11,r4,24
	r11.u64 = ctx.r4.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bnelr 
	if (!cr0.getEQ()) return;
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm. r10,r11,0,16,16
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beqlr 
	if (cr0.getEQ()) return;
	// rlwinm r10,r11,2,24,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFC;
	// lwzx r10,r10,r8
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// rlwimi r10,r11,0,0,25
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFC0) | (ctx.r10.u64 & 0xFFFFFFFF0000003F);
	// stw r10,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218C810"))) PPC_WEAK_FUNC(sub_8218C810);
PPC_FUNC_IMPL(__imp__sub_8218C810) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bnelr 
	if (!cr0.getEQ()) return;
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// clrlwi. r10,r4,24
	ctx.r10.u64 = ctx.r4.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8218c840
	if (cr0.getEQ()) goto loc_8218C840;
	// lwz r9,0(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r10,r9,20,26,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 20) & 0x3F;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8218c838
	if (cr6.getGT()) goto loc_8218C838;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8218C838:
	// rlwinm r10,r9,27,26,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x3F;
	// b 0x8218c90c
	goto loc_8218C90C;
loc_8218C840:
	// lwz r6,0(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm. r10,r6,0,16,16
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218c86c
	if (!cr0.getEQ()) goto loc_8218C86C;
	// rlwinm r10,r6,24,26,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 24) & 0x3F;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8218c85c
	if (cr6.getGT()) goto loc_8218C85C;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8218C85C:
	// clrlwi r10,r6,26
	ctx.r10.u64 = ctx.r6.u32 & 0x3F;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8218c86c
	if (cr6.getGT()) goto loc_8218C86C;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8218C86C:
	// lis r9,-32019
	ctx.r9.s64 = -2098397184;
	// lwz r10,8(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// rlwinm r4,r6,6,26,31
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 6) & 0x3F;
	// addi r9,r9,27348
	ctx.r9.s64 = ctx.r9.s64 + 27348;
	// addi r5,r9,32
	ctx.r5.s64 = ctx.r9.s64 + 32;
	// lbzx r4,r4,r5
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r4.u32 + ctx.r5.u32);
	// rlwinm r5,r10,8,27,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0x1F;
	// lbzx r5,r5,r9
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r5.u32 + ctx.r9.u32);
	// cmplwi cr6,r5,1
	cr6.compare<uint32_t>(ctx.r5.u32, 1, xer);
	// blt cr6,0x8218c8ac
	if (cr6.getLT()) goto loc_8218C8AC;
	// rlwinm. r9,r10,0,0,0
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8218c8ac
	if (cr0.getEQ()) goto loc_8218C8AC;
	// rlwinm r9,r10,16,26,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0x3F;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x8218c8ac
	if (cr6.getGT()) goto loc_8218C8AC;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8218C8AC:
	// cmplwi cr6,r5,2
	cr6.compare<uint32_t>(ctx.r5.u32, 2, xer);
	// blt cr6,0x8218c8cc
	if (cr6.getLT()) goto loc_8218C8CC;
	// rlwinm. r9,r10,0,1,1
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8218c8cc
	if (cr0.getEQ()) goto loc_8218C8CC;
	// rlwinm r9,r10,24,26,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0x3F;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x8218c8cc
	if (cr6.getGT()) goto loc_8218C8CC;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8218C8CC:
	// cmplwi cr6,r5,3
	cr6.compare<uint32_t>(ctx.r5.u32, 3, xer);
	// bge cr6,0x8218c8dc
	if (!cr6.getLT()) goto loc_8218C8DC;
	// cmplwi cr6,r4,1
	cr6.compare<uint32_t>(ctx.r4.u32, 1, xer);
	// bne cr6,0x8218c8f4
	if (!cr6.getEQ()) goto loc_8218C8F4;
loc_8218C8DC:
	// rlwinm. r9,r10,0,2,2
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8218c8f4
	if (cr0.getEQ()) goto loc_8218C8F4;
	// clrlwi r9,r10,26
	ctx.r9.u64 = ctx.r10.u32 & 0x3F;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x8218c8f4
	if (cr6.getGT()) goto loc_8218C8F4;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8218C8F4:
	// cmplwi cr6,r4,2
	cr6.compare<uint32_t>(ctx.r4.u32, 2, xer);
	// bne cr6,0x8218c918
	if (!cr6.getEQ()) goto loc_8218C918;
	// lwz r9,4(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// rlwimi r6,r10,30,4,4
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r10.u32, 30) & 0x8000000) | (ctx.r6.u64 & 0xFFFFFFFFF7FFFFFF);
	// rlwimi r9,r6,6,30,31
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r6.u32, 6) & 0x3) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFFC);
	// clrlwi r10,r9,26
	ctx.r10.u64 = ctx.r9.u32 & 0x3F;
loc_8218C90C:
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bgt cr6,0x8218c918
	if (cr6.getGT()) goto loc_8218C918;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8218C918:
	// stw r11,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218C920"))) PPC_WEAK_FUNC(sub_8218C920);
PPC_FUNC_IMPL(__imp__sub_8218C920) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister temp{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// clrlwi r10,r11,20
	ctx.r10.u64 = r11.u32 & 0xFFF;
	// rlwinm r5,r11,16,20,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFF;
	// rlwinm. r8,r11,20,29,31
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0x7;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// mulli r11,r10,12
	r11.s64 = ctx.r10.s64 * 12;
	// add r11,r11,r4
	r11.u64 = r11.u64 + ctx.r4.u64;
	// beqlr 
	if (cr0.getEQ()) return;
	// li r6,0
	ctx.r6.s64 = 0;
loc_8218C948:
	// slw r10,r3,r6
	ctx.r10.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r3.u32 << (ctx.r6.u8 & 0x3F));
	// and. r10,r10,r5
	ctx.r10.u64 = ctx.r10.u64 & ctx.r5.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218c994
	if (!cr0.getEQ()) goto loc_8218C994;
	// lbz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 8);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r10,r10,27
	ctx.r10.u64 = ctx.r10.u32 & 0x1F;
	// rlwinm r9,r9,6,26,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 6) & 0x3F;
	// addi r10,r10,-20
	ctx.r10.s64 = ctx.r10.s64 + -20;
	// addi r9,r9,-27
	ctx.r9.s64 = ctx.r9.s64 + -27;
	// subfic r10,r10,3
	xer.ca = ctx.r10.u32 <= 3;
	ctx.r10.s64 = 3 - ctx.r10.s64;
	// subfe r10,r10,r10
	temp.u8 = (~ctx.r10.u32 + ctx.r10.u32 < ~ctx.r10.u32) | (~ctx.r10.u32 + ctx.r10.u32 + xer.ca < xer.ca);
	ctx.r10.u64 = ~ctx.r10.u64 + ctx.r10.u64 + xer.ca;
	xer.ca = temp.u8;
	// subfic r9,r9,7
	xer.ca = ctx.r9.u32 <= 7;
	ctx.r9.s64 = 7 - ctx.r9.s64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// subfe r9,r9,r9
	temp.u8 = (~ctx.r9.u32 + ctx.r9.u32 < ~ctx.r9.u32) | (~ctx.r9.u32 + ctx.r9.u32 + xer.ca < xer.ca);
	ctx.r9.u64 = ~ctx.r9.u64 + ctx.r9.u64 + xer.ca;
	xer.ca = temp.u8;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218c9ac
	if (!cr0.getEQ()) goto loc_8218C9AC;
	// clrlwi. r10,r9,24
	ctx.r10.u64 = ctx.r9.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218c9ac
	if (!cr0.getEQ()) goto loc_8218C9AC;
loc_8218C994:
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// addi r6,r6,2
	ctx.r6.s64 = ctx.r6.s64 + 2;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// cmplw cr6,r7,r8
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r8.u32, xer);
	// blt cr6,0x8218c948
	if (cr6.getLT()) goto loc_8218C948;
	// blr 
	return;
loc_8218C9AC:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218C9B8"))) PPC_WEAK_FUNC(sub_8218C9B8);
PPC_FUNC_IMPL(__imp__sub_8218C9B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218ca80
	if (cr0.getEQ()) goto loc_8218CA80;
	// lwz r31,4(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// li r11,1
	r11.s64 = 1;
	// rlwinm r30,r31,20,28,31
	r30.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 20) & 0xF;
	// slw r11,r11,r30
	r11.u64 = r30.u8 & 0x20 ? 0 : (r11.u32 << (r30.u8 & 0x3F));
	// andi. r11,r11,24702
	r11.u64 = r11.u64 & 24702;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8218ca80
	if (cr0.getEQ()) goto loc_8218CA80;
	// mr r4,r8
	ctx.r4.u64 = ctx.r8.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8218c920
	sub_8218C920(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r30,6
	cr6.compare<uint32_t>(r30.u32, 6, xer);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// bgt cr6,0x8218ca44
	if (cr6.getGT()) goto loc_8218CA44;
	// cmplwi cr6,r30,5
	cr6.compare<uint32_t>(r30.u32, 5, xer);
	// bge cr6,0x8218ca3c
	if (!cr6.getLT()) goto loc_8218CA3C;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8218ca80
	if (cr6.getEQ()) goto loc_8218CA80;
	// cmplwi cr6,r30,2
	cr6.compare<uint32_t>(r30.u32, 2, xer);
	// ble cr6,0x8218ca3c
	if (!cr6.getGT()) goto loc_8218CA3C;
	// cmplwi cr6,r30,3
	cr6.compare<uint32_t>(r30.u32, 3, xer);
	// beq cr6,0x8218ca68
	if (cr6.getEQ()) goto loc_8218CA68;
	// cmplwi cr6,r30,4
	cr6.compare<uint32_t>(r30.u32, 4, xer);
	// beq cr6,0x8218ca54
	if (cr6.getEQ()) goto loc_8218CA54;
	// b 0x8218ca80
	goto loc_8218CA80;
loc_8218CA3C:
	// rlwimi r31,r11,9,22,22
	r31.u64 = (__builtin_rotateleft32(r11.u32, 9) & 0x200) | (r31.u64 & 0xFFFFFFFFFFFFFDFF);
	// b 0x8218ca7c
	goto loc_8218CA7C;
loc_8218CA44:
	// cmplwi cr6,r30,13
	cr6.compare<uint32_t>(r30.u32, 13, xer);
	// beq cr6,0x8218ca68
	if (cr6.getEQ()) goto loc_8218CA68;
	// cmplwi cr6,r30,14
	cr6.compare<uint32_t>(r30.u32, 14, xer);
	// bne cr6,0x8218ca80
	if (!cr6.getEQ()) goto loc_8218CA80;
loc_8218CA54:
	// subfic r11,r11,0
	xer.ca = r11.u32 <= 0;
	r11.s64 = 0 - r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// andi. r11,r11,10
	r11.u64 = r11.u64 & 10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// b 0x8218ca78
	goto loc_8218CA78;
loc_8218CA68:
	// subfic r11,r11,0
	xer.ca = r11.u32 <= 0;
	r11.s64 = 0 - r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// andi. r11,r11,10
	r11.u64 = r11.u64 & 10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
loc_8218CA78:
	// rlwimi r31,r11,12,16,19
	r31.u64 = (__builtin_rotateleft32(r11.u32, 12) & 0xF000) | (r31.u64 & 0xFFFFFFFFFFFF0FFF);
loc_8218CA7C:
	// stw r31,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r31.u32);
loc_8218CA80:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_8218CA88"))) PPC_WEAK_FUNC(sub_8218CA88);
PPC_FUNC_IMPL(__imp__sub_8218CA88) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r30,r7
	r30.u64 = ctx.r7.u64;
	// mr r31,r8
	r31.u64 = ctx.r8.u64;
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8218cb50
	if (!cr0.getEQ()) goto loc_8218CB50;
	// clrlwi. r11,r4,24
	r11.u64 = ctx.r4.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8218cb50
	if (!cr0.getEQ()) goto loc_8218CB50;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8218c5b8
	sub_8218C5B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8218cb50
	if (cr0.getEQ()) goto loc_8218CB50;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r6,80(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// clrlwi r4,r11,26
	ctx.r4.u64 = r11.u32 & 0x3F;
loc_8218CAD4:
	// li r11,1
	r11.s64 = 1;
	// slw r11,r11,r5
	r11.u64 = ctx.r5.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r5.u8 & 0x3F));
	// and. r11,r11,r6
	r11.u64 = r11.u64 & ctx.r6.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218cb44
	if (cr0.getEQ()) goto loc_8218CB44;
	// addi r11,r4,4
	r11.s64 = ctx.r4.s64 + 4;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r5
	r11.u64 = r11.u64 + ctx.r5.u64;
	// lbzx r11,r11,r31
	r11.u64 = PPC_LOAD_U8(r11.u32 + r31.u32);
	// cmplwi cr6,r11,255
	cr6.compare<uint32_t>(r11.u32, 255, xer);
	// beq cr6,0x8218cb44
	if (cr6.getEQ()) goto loc_8218CB44;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,40
	r11.s64 = r11.s64 + 40;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// clrlwi r30,r29,20
	r30.u64 = r29.u32 & 0xFFF;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r8,r10,r9
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r10.u32 + ctx.r9.u32);
	// clrlwi r8,r8,20
	ctx.r8.u64 = ctx.r8.u32 & 0xFFF;
	// lhzx r7,r11,r31
	ctx.r7.u64 = PPC_LOAD_U16(r11.u32 + r31.u32);
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r30,r8,r3
	PPC_STORE_U32(ctx.r8.u32 + ctx.r3.u32, r30.u32);
	// lhzx r8,r11,r31
	ctx.r8.u64 = PPC_LOAD_U16(r11.u32 + r31.u32);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// sthx r8,r11,r31
	PPC_STORE_U16(r11.u32 + r31.u32, ctx.r8.u16);
	// lwzx r11,r10,r9
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// rlwinm r11,r11,20,28,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
	// andc r6,r6,r11
	ctx.r6.u64 = ctx.r6.u64 & ~r11.u64;
loc_8218CB44:
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
	// cmplwi cr6,r5,4
	cr6.compare<uint32_t>(ctx.r5.u32, 4, xer);
	// blt cr6,0x8218cad4
	if (cr6.getLT()) goto loc_8218CAD4;
loc_8218CB50:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_8218CB58"))) PPC_WEAK_FUNC(sub_8218CB58);
PPC_FUNC_IMPL(__imp__sub_8218CB58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r7
	r30.u64 = ctx.r7.u64;
	// mr r31,r8
	r31.u64 = ctx.r8.u64;
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8218cc04
	if (!cr0.getEQ()) goto loc_8218CC04;
	// clrlwi. r11,r4,24
	r11.u64 = ctx.r4.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8218cc04
	if (!cr0.getEQ()) goto loc_8218CC04;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8218c5b8
	sub_8218C5B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8218cc04
	if (cr0.getEQ()) goto loc_8218CC04;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// clrlwi r5,r11,26
	ctx.r5.u64 = r11.u32 & 0x3F;
loc_8218CBA8:
	// li r11,1
	r11.s64 = 1;
	// slw r11,r11,r6
	r11.u64 = ctx.r6.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r6.u8 & 0x3F));
	// and. r11,r11,r7
	r11.u64 = r11.u64 & ctx.r7.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218cbf8
	if (cr0.getEQ()) goto loc_8218CBF8;
	// addi r11,r5,2
	r11.s64 = ctx.r5.s64 + 2;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r6
	r11.u64 = r11.u64 + ctx.r6.u64;
	// lbzx r11,r11,r31
	r11.u64 = PPC_LOAD_U8(r11.u32 + r31.u32);
	// cmplwi cr6,r11,255
	cr6.compare<uint32_t>(r11.u32, 255, xer);
	// beq cr6,0x8218cbf8
	if (cr6.getEQ()) goto loc_8218CBF8;
	// addi r10,r11,36
	ctx.r10.s64 = r11.s64 + 36;
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r10,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r10,r11,r31
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + r31.u32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// sthx r10,r11,r31
	PPC_STORE_U16(r11.u32 + r31.u32, ctx.r10.u16);
	// lwzx r11,r9,r8
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// rlwinm r11,r11,20,28,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
	// andc r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 & ~r11.u64;
loc_8218CBF8:
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// cmplwi cr6,r6,4
	cr6.compare<uint32_t>(ctx.r6.u32, 4, xer);
	// blt cr6,0x8218cba8
	if (cr6.getLT()) goto loc_8218CBA8;
loc_8218CC04:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218CC20"))) PPC_WEAK_FUNC(sub_8218CC20);
PPC_FUNC_IMPL(__imp__sub_8218CC20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bnelr 
	if (!cr0.getEQ()) return;
	// clrlwi. r11,r4,24
	r11.u64 = ctx.r4.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bnelr 
	if (!cr0.getEQ()) return;
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm. r10,r11,0,16,16
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8218cc78
	if (cr0.getEQ()) goto loc_8218CC78;
	// clrlwi r10,r11,26
	ctx.r10.u64 = r11.u32 & 0x3F;
	// cmplwi cr6,r10,3
	cr6.compare<uint32_t>(ctx.r10.u32, 3, xer);
	// bgt cr6,0x8218cc64
	if (cr6.getGT()) goto loc_8218CC64;
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// slw r10,r9,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r10.u8 & 0x3F));
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | r11.u64;
	// rlwimi r10,r11,0,0,27
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFF0) | (ctx.r10.u64 & 0xFFFFFFFF0000000F);
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
	// b 0x8218cc78
	goto loc_8218CC78;
loc_8218CC64:
	// cmplwi cr6,r10,61
	cr6.compare<uint32_t>(ctx.r10.u32, 61, xer);
	// bne cr6,0x8218cc78
	if (!cr6.getEQ()) goto loc_8218CC78;
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// ori r11,r11,16
	r11.u64 = r11.u64 | 16;
	// stw r11,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r11.u32);
loc_8218CC78:
	// lbz r11,8(r7)
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 8);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// blt cr6,0x8218cc90
	if (cr6.getLT()) goto loc_8218CC90;
	// cmplwi cr6,r11,27
	cr6.compare<uint32_t>(r11.u32, 27, xer);
	// ble cr6,0x8218cca8
	if (!cr6.getGT()) goto loc_8218CCA8;
loc_8218CC90:
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm r11,r11,6,26,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0x3F;
	// cmplwi cr6,r11,35
	cr6.compare<uint32_t>(r11.u32, 35, xer);
	// bltlr cr6
	if (cr6.getLT()) return;
	// cmplwi cr6,r11,39
	cr6.compare<uint32_t>(r11.u32, 39, xer);
	// bgtlr cr6
	if (cr6.getGT()) return;
loc_8218CCA8:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// ori r11,r11,32
	r11.u64 = r11.u64 | 32;
	// stw r11,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218CCB8"))) PPC_WEAK_FUNC(sub_8218CCB8);
PPC_FUNC_IMPL(__imp__sub_8218CCB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed118
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r22,r5
	r22.u64 = ctx.r5.u64;
	// mr r21,r6
	r21.u64 = ctx.r6.u64;
	// mr r23,r8
	r23.u64 = ctx.r8.u64;
	// mr r20,r9
	r20.u64 = ctx.r9.u64;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm. r26,r11,20,29,31
	r26.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0x7;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// beq 0x8218cd94
	if (cr0.getEQ()) goto loc_8218CD94;
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// clrlwi r9,r11,20
	ctx.r9.u64 = r11.u32 & 0xFFF;
	// rlwinm r25,r11,16,20,31
	r25.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFF;
	// rlwinm r8,r10,4,26,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0x30;
	// mulli r10,r9,12
	ctx.r10.s64 = ctx.r9.s64 * 12;
	// rlwinm r9,r11,4,28,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xF;
	// add r31,r10,r7
	r31.u64 = ctx.r10.u64 + ctx.r7.u64;
	// li r30,0
	r30.s64 = 0;
	// or r24,r8,r9
	r24.u64 = ctx.r8.u64 | ctx.r9.u64;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x8218cd94
	if (cr6.getEQ()) goto loc_8218CD94;
	// li r28,0
	r28.s64 = 0;
	// li r27,1
	r27.s64 = 1;
loc_8218CD18:
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// bgt cr6,0x8218cd90
	if (cr6.getGT()) goto loc_8218CD90;
	// bne cr6,0x8218cd78
	if (!cr6.getEQ()) goto loc_8218CD78;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// slw r10,r27,r28
	ctx.r10.u64 = r28.u8 & 0x20 ? 0 : (r27.u32 << (r28.u8 & 0x3F));
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// clrlwi r11,r11,20
	r11.u64 = r11.u32 & 0xFFF;
	// and r10,r10,r25
	ctx.r10.u64 = ctx.r10.u64 & r25.u64;
	// add r6,r11,r30
	ctx.r6.u64 = r11.u64 + r30.u64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// li r3,0
	ctx.r3.s64 = 0;
	// xori r4,r10,1
	ctx.r4.u64 = ctx.r10.u64 ^ 1;
	// slw r11,r27,r30
	r11.u64 = r30.u8 & 0x20 ? 0 : (r27.u32 << (r30.u8 & 0x3F));
	// and r11,r11,r24
	r11.u64 = r11.u64 & r24.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r5,r11,1
	ctx.r5.u64 = r11.u64 ^ 1;
	// mtctr r22
	ctr.u64 = r22.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r11,r31,12
	r11.s64 = r31.s64 + 12;
	// stw r11,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r11.u32);
loc_8218CD78:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r28,r28,2
	r28.s64 = r28.s64 + 2;
	// addi r31,r31,12
	r31.s64 = r31.s64 + 12;
	// cmplw cr6,r30,r26
	cr6.compare<uint32_t>(r30.u32, r26.u32, xer);
	// blt cr6,0x8218cd18
	if (cr6.getLT()) goto loc_8218CD18;
	// b 0x8218cd94
	goto loc_8218CD94;
loc_8218CD90:
	// stw r27,0(r20)
	PPC_STORE_U32(r20.u32 + 0, r27.u32);
loc_8218CD94:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x823ed168
	return;
}

__attribute__((alias("__imp__sub_8218CDA0"))) PPC_WEAK_FUNC(sub_8218CDA0);
PPC_FUNC_IMPL(__imp__sub_8218CDA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r3,19896(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 19896);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8218cde0
	if (cr0.getEQ()) goto loc_8218CDE0;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r11,19896(r31)
	PPC_STORE_U32(r31.u32 + 19896, r11.u32);
loc_8218CDE0:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stw r30,19896(r31)
	PPC_STORE_U32(r31.u32 + 19896, r30.u32);
	// beq cr6,0x8218ce00
	if (cr6.getEQ()) goto loc_8218CE00;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_8218CE00:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218CE18"))) PPC_WEAK_FUNC(sub_8218CE18);
PPC_FUNC_IMPL(__imp__sub_8218CE18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// lwz r11,19892(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 19892);
	// andi. r10,r4,249
	ctx.r10.u64 = ctx.r4.u64 & 249;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// clrlwi r9,r4,31
	ctx.r9.u64 = ctx.r4.u32 & 0x1;
	// rlwinm r11,r11,0,29,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFF07;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// stw r11,19892(r3)
	PPC_STORE_U32(ctx.r3.u32 + 19892, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218CE38"))) PPC_WEAK_FUNC(sub_8218CE38);
PPC_FUNC_IMPL(__imp__sub_8218CE38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// stw r4,104(r11)
	PPC_STORE_U32(r11.u32 + 104, ctx.r4.u32);
	// stw r5,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r5.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218CE50"))) PPC_WEAK_FUNC(sub_8218CE50);
PPC_FUNC_IMPL(__imp__sub_8218CE50) {
	PPC_FUNC_PROLOGUE();
	// b 0x8218cda0
	sub_8218CDA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218CE58"))) PPC_WEAK_FUNC(sub_8218CE58);
PPC_FUNC_IMPL(__imp__sub_8218CE58) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed120
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r22,r9
	r22.u64 = ctx.r9.u64;
	// mr r23,r10
	r23.u64 = ctx.r10.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// cmplw cr6,r11,r6
	cr6.compare<uint32_t>(r11.u32, ctx.r6.u32, xer);
	// bne cr6,0x8218ce9c
	if (!cr6.getEQ()) goto loc_8218CE9C;
	// lwz r11,4(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8218ce9c
	if (!cr0.getEQ()) goto loc_8218CE9C;
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// clrlwi r11,r11,20
	r11.u64 = r11.u32 & 0xFFF;
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
loc_8218CE9C:
	// rlwinm. r11,r22,0,29,30
	r11.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 0) & 0x6;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218cfe8
	if (cr0.getEQ()) goto loc_8218CFE8;
	// lwz r31,4(r24)
	r31.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// rlwinm. r11,r31,0,20,20
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218cebc
	if (cr0.getEQ()) goto loc_8218CEBC;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r6,r8
	ctx.r6.u64 = ctx.r8.u64;
	// b 0x8218cec4
	goto loc_8218CEC4;
loc_8218CEBC:
	// lwz r9,0(r4)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mr r7,r5
	ctx.r7.u64 = ctx.r5.u64;
loc_8218CEC4:
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// rlwinm. r25,r11,20,29,31
	r25.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0x7;
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// beq 0x8218cfe8
	if (cr0.getEQ()) goto loc_8218CFE8;
	// clrlwi r10,r11,20
	ctx.r10.u64 = r11.u32 & 0xFFF;
	// mulli r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 * 12;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x8218cfe0
	if (cr6.getLT()) goto loc_8218CFE0;
	// mulli r9,r25,12
	ctx.r9.s64 = r25.s64 * 12;
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmplw cr6,r9,r6
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r6.u32, xer);
	// bgt cr6,0x8218cfe0
	if (cr6.getGT()) goto loc_8218CFE0;
	// rlwinm r9,r31,4,26,27
	ctx.r9.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 4) & 0x30;
	// rlwinm r8,r11,4,28,31
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xF;
	// add r29,r10,r7
	r29.u64 = ctx.r10.u64 + ctx.r7.u64;
	// rlwinm r28,r11,16,20,31
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFF;
	// or r26,r9,r8
	r26.u64 = ctx.r9.u64 | ctx.r8.u64;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8218cfe8
	if (cr6.getEQ()) goto loc_8218CFE8;
	// li r30,0
	r30.s64 = 0;
	// li r27,1
	r27.s64 = 1;
loc_8218CF18:
	// li r11,2
	r11.s64 = 2;
	// slw r10,r27,r30
	ctx.r10.u64 = r30.u8 & 0x20 ? 0 : (r27.u32 << (r30.u8 & 0x3F));
	// slw r9,r27,r31
	ctx.r9.u64 = r31.u8 & 0x20 ? 0 : (r27.u32 << (r31.u8 & 0x3F));
	// and r8,r10,r28
	ctx.r8.u64 = ctx.r10.u64 & r28.u64;
	// and r9,r9,r26
	ctx.r9.u64 = ctx.r9.u64 & r26.u64;
	// cntlzw r9,r9
	ctx.r9.u64 = ctx.r9.u32 == 0 ? 32 : __builtin_clz(ctx.r9.u32);
	// rlwinm r9,r9,27,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 27) & 0x1;
	// xori r9,r9,1
	ctx.r9.u64 = ctx.r9.u64 ^ 1;
	// slw r11,r11,r30
	r11.u64 = r30.u8 & 0x20 ? 0 : (r11.u32 << (r30.u8 & 0x3F));
	// and r11,r11,r28
	r11.u64 = r11.u64 & r28.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r10,r11,1
	ctx.r10.u64 = r11.u64 ^ 1;
	// subfic r11,r8,0
	xer.ca = ctx.r8.u32 <= 0;
	r11.s64 = 0 - ctx.r8.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// rlwinm r11,r11,0,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8218cf68
	if (cr0.getEQ()) goto loc_8218CF68;
	// ori r11,r11,32
	r11.u64 = r11.u64 | 32;
loc_8218CF68:
	// clrlwi. r10,r9,24
	ctx.r10.u64 = ctx.r9.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8218cf74
	if (cr0.getEQ()) goto loc_8218CF74;
	// ori r11,r11,16
	r11.u64 = r11.u64 | 16;
loc_8218CF74:
	// lwz r10,4(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// rlwinm. r9,r10,0,20,20
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8218cf84
	if (cr0.getEQ()) goto loc_8218CF84;
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
loc_8218CF84:
	// rlwinm r10,r10,0,16,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xF000;
	// cmplwi cr6,r10,20480
	cr6.compare<uint32_t>(ctx.r10.u32, 20480, xer);
	// bne cr6,0x8218cf94
	if (!cr6.getEQ()) goto loc_8218CF94;
	// ori r11,r11,128
	r11.u64 = r11.u64 | 128;
loc_8218CF94:
	// and r10,r11,r22
	ctx.r10.u64 = r11.u64 & r22.u64;
	// rlwinm. r10,r10,0,29,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x6;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8218cfc8
	if (cr0.getEQ()) goto loc_8218CFC8;
	// lwz r10,0(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r6,260(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// clrlwi r10,r10,20
	ctx.r10.u64 = ctx.r10.u32 & 0xFFF;
	// add r4,r10,r31
	ctx.r4.u64 = ctx.r10.u64 + r31.u64;
	// mtctr r23
	ctr.u64 = r23.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8218cfe8
	if (cr0.getLT()) goto loc_8218CFE8;
loc_8218CFC8:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,2
	r30.s64 = r30.s64 + 2;
	// addi r29,r29,12
	r29.s64 = r29.s64 + 12;
	// cmplw cr6,r31,r25
	cr6.compare<uint32_t>(r31.u32, r25.u32, xer);
	// blt cr6,0x8218cf18
	if (cr6.getLT()) goto loc_8218CF18;
	// b 0x8218cfe8
	goto loc_8218CFE8;
loc_8218CFE0:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_8218CFE8:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed170
	return;
}

__attribute__((alias("__imp__sub_8218CFF0"))) PPC_WEAK_FUNC(sub_8218CFF0);
PPC_FUNC_IMPL(__imp__sub_8218CFF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed100
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r23,r4
	r23.u64 = ctx.r4.u64;
	// mr r20,r10
	r20.u64 = ctx.r10.u64;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// mr r18,r3
	r18.u64 = ctx.r3.u64;
	// mr r17,r5
	r17.u64 = ctx.r5.u64;
	// stw r23,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r23.u32);
	// mr r16,r6
	r16.u64 = ctx.r6.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// mr r14,r8
	r14.u64 = ctx.r8.u64;
	// mr r21,r9
	r21.u64 = ctx.r9.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// li r31,0
	r31.s64 = 0;
	// li r28,0
	r28.s64 = 0;
	// li r26,0
	r26.s64 = 0;
	// li r19,-1
	r19.s64 = -1;
	// li r15,-1
	r15.s64 = -1;
	// addi r22,r11,-4
	r22.s64 = r11.s64 + -4;
	// addi r24,r10,-4
	r24.s64 = ctx.r10.s64 + -4;
	// li r29,1
	r29.s64 = 1;
loc_8218D04C:
	// li r11,12
	r11.s64 = 12;
	// li r9,6
	ctx.r9.s64 = 6;
	// divwu r11,r31,r11
	r11.u32 = r31.u32 / r11.u32;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// subf r10,r11,r31
	ctx.r10.s64 = r31.s64 - r11.s64;
	// divwu r10,r10,r9
	ctx.r10.u32 = ctx.r10.u32 / ctx.r9.u32;
	// beq cr6,0x8218d07c
	if (cr6.getEQ()) goto loc_8218D07C;
	// cmplw cr6,r31,r16
	cr6.compare<uint32_t>(r31.u32, r16.u32, xer);
	// bge cr6,0x8218d370
	if (!cr6.getLT()) goto loc_8218D370;
	// add r27,r11,r17
	r27.u64 = r11.u64 + r17.u64;
	// b 0x8218d08c
	goto loc_8218D08C;
loc_8218D07C:
	// lwz r8,96(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r31,r8
	cr6.compare<uint32_t>(r31.u32, ctx.r8.u32, xer);
	// bge cr6,0x8218d370
	if (!cr6.getLT()) goto loc_8218D370;
	// add r27,r11,r18
	r27.u64 = r11.u64 + r18.u64;
loc_8218D08C:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// clrlwi. r7,r21,31
	ctx.r7.u64 = r21.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// lhz r11,6(r27)
	r11.u64 = PPC_LOAD_U16(r27.u32 + 6);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
	// rlwinm r11,r10,3,0,28
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// lwz r8,8(r27)
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// add r30,r11,r10
	r30.u64 = r11.u64 + ctx.r10.u64;
	// lhz r11,4(r27)
	r11.u64 = PPC_LOAD_U16(r27.u32 + 4);
	// rlwinm r8,r8,16,0,15
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 16) & 0xFFFF0000;
	// or r11,r11,r8
	r11.u64 = r11.u64 | ctx.r8.u64;
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r11.u32);
	// lhz r11,8(r27)
	r11.u64 = PPC_LOAD_U16(r27.u32 + 8);
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r11.u32);
	// beq 0x8218d0ec
	if (cr0.getEQ()) goto loc_8218D0EC;
	// lwz r6,404(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// divwu r4,r31,r9
	ctx.r4.u32 = r31.u32 / ctx.r9.u32;
	// li r3,1
	ctx.r3.s64 = 1;
	// mtctr r20
	ctr.u64 = r20.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8218d378
	if (cr0.getLT()) goto loc_8218D378;
loc_8218D0EC:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r8,0
	ctx.r8.s64 = 0;
	// rlwinm r10,r11,20,28,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
	// cmplwi cr6,r10,15
	cr6.compare<uint32_t>(ctx.r10.u32, 15, xer);
	// bgt cr6,0x8218d2f8
	if (cr6.getGT()) goto loc_8218D2F8;
	// lis r12,-32254
	r12.s64 = -2113798144;
	// addi r12,r12,-19040
	r12.s64 = r12.s64 + -19040;
	// lbzx r0,r12,r10
	r0.u64 = PPC_LOAD_U8(r12.u32 + ctx.r10.u32);
	// rlwinm r0,r0,2,0,29
	r0.u64 = __builtin_rotateleft64(r0.u32 | (r0.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r12,-32231
	r12.s64 = -2112290816;
	// addi r12,r12,-11992
	r12.s64 = r12.s64 + -11992;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (ctx.r10.u64) {
	case 0:
		goto loc_8218D2F4;
	case 1:
		goto loc_8218D2F0;
	case 2:
		goto loc_8218D2EC;
	case 3:
		goto loc_8218D128;
	case 4:
		goto loc_8218D2BC;
	case 5:
		goto loc_8218D2F0;
	case 6:
		goto loc_8218D2EC;
	case 7:
		goto loc_8218D15C;
	case 8:
		goto loc_8218D1A0;
	case 9:
		goto loc_8218D1E0;
	case 10:
		goto loc_8218D254;
	case 11:
		goto loc_8218D274;
	case 12:
		goto loc_8218D2F4;
	case 13:
		goto loc_8218D128;
	case 14:
		goto loc_8218D2BC;
	case 15:
		goto loc_8218D2F4;
	default:
		__builtin_unreachable();
	}
loc_8218D128:
	// rlwinm r10,r11,30,24,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0xFF;
	// rlwinm r11,r11,22,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 22) & 0x1;
	// clrlwi r9,r10,27
	ctx.r9.u64 = ctx.r10.u32 & 0x1F;
	// rlwinm r10,r10,29,3,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r10,r10,r25
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// slw r9,r29,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r29.u32 << (ctx.r9.u8 & 0x3F));
	// and r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 & ctx.r10.u64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 ^ 1;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x8218d2f4
	if (!cr6.getEQ()) goto loc_8218D2F4;
	// b 0x8218d2f0
	goto loc_8218D2F0;
loc_8218D15C:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r9,r10,18,25,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x7C;
	// lwzx r9,r9,r14
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r14.u32);
	// clrlwi. r9,r9,24
	ctx.r9.u64 = ctx.r9.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x8218d180
	if (!cr0.getEQ()) goto loc_8218D180;
	// clrlwi r10,r10,19
	ctx.r10.u64 = ctx.r10.u32 & 0x1FFF;
loc_8218D174:
	// rlwinm r28,r11,21,31,31
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 21) & 0x1;
	// mulli r31,r10,6
	r31.s64 = ctx.r10.s64 * 6;
	// b 0x8218d2f8
	goto loc_8218D2F8;
loc_8218D180:
	// addi r15,r15,1
	r15.s64 = r15.s64 + 1;
	// addi r24,r24,4
	r24.s64 = r24.s64 + 4;
	// cmpwi cr6,r15,4
	cr6.compare<int32_t>(r15.s32, 4, xer);
	// blt cr6,0x8218d198
	if (cr6.getLT()) goto loc_8218D198;
loc_8218D190:
	// mr r26,r29
	r26.u64 = r29.u64;
	// b 0x8218d2f8
	goto loc_8218D2F8;
loc_8218D198:
	// stw r8,0(r24)
	PPC_STORE_U32(r24.u32 + 0, ctx.r8.u32);
	// b 0x8218d2f4
	goto loc_8218D2F4;
loc_8218D1A0:
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// blt cr6,0x8218d190
	if (cr6.getLT()) goto loc_8218D190;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r10,0(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// rlwinm r7,r9,18,25,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 18) & 0x7C;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lwzx r7,r7,r14
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + r14.u32);
	// stw r10,0(r24)
	PPC_STORE_U32(r24.u32 + 0, ctx.r10.u32);
	// clrlwi r7,r7,24
	ctx.r7.u64 = ctx.r7.u32 & 0xFF;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// bge cr6,0x8218d1d4
	if (!cr6.getLT()) goto loc_8218D1D4;
loc_8218D1CC:
	// clrlwi r10,r9,19
	ctx.r10.u64 = ctx.r9.u32 & 0x1FFF;
	// b 0x8218d174
	goto loc_8218D174;
loc_8218D1D4:
	// addi r15,r15,-1
	r15.s64 = r15.s64 + -1;
	// addi r24,r24,-4
	r24.s64 = r24.s64 + -4;
	// b 0x8218d2f4
	goto loc_8218D2F4;
loc_8218D1E0:
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r10,r9,0,18,18
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218d224
	if (!cr0.getEQ()) goto loc_8218D224;
	// rlwinm. r10,r9,0,17,17
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x4000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218d2f4
	if (!cr0.getEQ()) goto loc_8218D2F4;
	// rlwinm r10,r11,30,24,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0xFF;
	// rlwinm r7,r11,22,31,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 22) & 0x1;
	// clrlwi r6,r10,27
	ctx.r6.u64 = ctx.r10.u32 & 0x1F;
	// rlwinm r10,r10,29,3,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r10,r10,r25
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// slw r6,r29,r6
	ctx.r6.u64 = ctx.r6.u8 & 0x20 ? 0 : (r29.u32 << (ctx.r6.u8 & 0x3F));
	// and r10,r6,r10
	ctx.r10.u64 = ctx.r6.u64 & ctx.r10.u64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 ^ 1;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// bne cr6,0x8218d2f4
	if (!cr6.getEQ()) goto loc_8218D2F4;
loc_8218D224:
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// addi r22,r22,4
	r22.s64 = r22.s64 + 4;
	// cmpwi cr6,r19,4
	cr6.compare<int32_t>(r19.s32, 4, xer);
	// bge cr6,0x8218d190
	if (!cr6.getLT()) goto loc_8218D190;
	// rlwinm r10,r28,16,0,15
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 16) & 0xFFFF0000;
	// addi r7,r31,6
	ctx.r7.s64 = r31.s64 + 6;
	// clrlwi r9,r9,19
	ctx.r9.u64 = ctx.r9.u32 & 0x1FFF;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// rlwinm r28,r11,21,31,31
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 21) & 0x1;
	// mulli r31,r9,6
	r31.s64 = ctx.r9.s64 * 6;
	// stw r10,0(r22)
	PPC_STORE_U32(r22.u32 + 0, ctx.r10.u32);
	// b 0x8218d2f8
	goto loc_8218D2F8;
loc_8218D254:
	// cmpwi cr6,r19,0
	cr6.compare<int32_t>(r19.s32, 0, xer);
	// blt cr6,0x8218d190
	if (cr6.getLT()) goto loc_8218D190;
	// lwz r11,0(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// addi r19,r19,-1
	r19.s64 = r19.s64 + -1;
	// addi r22,r22,-4
	r22.s64 = r22.s64 + -4;
	// clrlwi r31,r11,16
	r31.u64 = r11.u32 & 0xFFFF;
	// rlwinm r28,r11,16,16,31
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF;
	// b 0x8218d2f8
	goto loc_8218D2F8;
loc_8218D274:
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r10,r9,0,18,18
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218d1cc
	if (!cr0.getEQ()) goto loc_8218D1CC;
	// rlwinm. r10,r9,0,17,17
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x4000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218d2f4
	if (!cr0.getEQ()) goto loc_8218D2F4;
	// rlwinm r10,r11,30,24,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0xFF;
	// rlwinm r7,r11,22,31,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 22) & 0x1;
	// clrlwi r6,r10,27
	ctx.r6.u64 = ctx.r10.u32 & 0x1F;
	// rlwinm r10,r10,29,3,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r10,r10,r25
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// slw r6,r29,r6
	ctx.r6.u64 = ctx.r6.u8 & 0x20 ? 0 : (r29.u32 << (ctx.r6.u8 & 0x3F));
	// and r10,r6,r10
	ctx.r10.u64 = ctx.r6.u64 & ctx.r10.u64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 ^ 1;
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// bne cr6,0x8218d2f4
	if (!cr6.getEQ()) goto loc_8218D2F4;
	// b 0x8218d1cc
	goto loc_8218D1CC;
loc_8218D2BC:
	// rlwinm r10,r11,30,24,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0xFF;
	// rlwinm r11,r11,22,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 22) & 0x1;
	// clrlwi r9,r10,27
	ctx.r9.u64 = ctx.r10.u32 & 0x1F;
	// rlwinm r10,r10,29,3,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r10,r10,r25
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r25.u32);
	// slw r9,r29,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r29.u32 << (ctx.r9.u8 & 0x3F));
	// and r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 & ctx.r10.u64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 ^ 1;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x8218d2f4
	if (!cr6.getEQ()) goto loc_8218D2F4;
loc_8218D2EC:
	// mr r26,r29
	r26.u64 = r29.u64;
loc_8218D2F0:
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
loc_8218D2F4:
	// addi r31,r31,6
	r31.s64 = r31.s64 + 6;
loc_8218D2F8:
	// clrlwi. r11,r8,24
	r11.u64 = ctx.r8.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218d334
	if (cr0.getEQ()) goto loc_8218D334;
	// lwz r11,404(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 404);
	// mr r10,r20
	ctx.r10.u64 = r20.u64;
	// mr r9,r21
	ctx.r9.u64 = r21.u64;
	// mr r8,r16
	ctx.r8.u64 = r16.u64;
	// mr r7,r17
	ctx.r7.u64 = r17.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r5,r18
	ctx.r5.u64 = r18.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8218ce58
	sub_8218CE58(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8218d378
	if (cr0.getLT()) goto loc_8218D378;
loc_8218D334:
	// clrlwi. r11,r26,24
	r11.u64 = r26.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// rlwimi r10,r11,16,0,15
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 16) & 0xFFFF0000) | (ctx.r10.u64 & 0xFFFFFFFF0000FFFF);
	// stw r10,4(r27)
	PPC_STORE_U32(r27.u32 + 4, ctx.r10.u32);
	// lwz r11,124(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// lwz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// rlwinm r11,r11,16,0,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF0000;
	// rlwinm r10,r10,16,16,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// stw r11,8(r27)
	PPC_STORE_U32(r27.u32 + 8, r11.u32);
	// beq 0x8218d04c
	if (cr0.getEQ()) goto loc_8218D04C;
	// b 0x8218d378
	goto loc_8218D378;
loc_8218D370:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_8218D378:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// b 0x823ed150
	return;
}

__attribute__((alias("__imp__sub_8218D380"))) PPC_WEAK_FUNC(sub_8218D380);
PPC_FUNC_IMPL(__imp__sub_8218D380) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed110
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r9
	r27.u64 = ctx.r9.u64;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r22,r5
	r22.u64 = ctx.r5.u64;
	// mr r21,r6
	r21.u64 = ctx.r6.u64;
	// mr r26,r10
	r26.u64 = ctx.r10.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// rlwinm. r11,r27,0,28,28
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218d3c4
	if (cr0.getEQ()) goto loc_8218D3C4;
	// lwz r11,340(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bl 0x8218cff0
	sub_8218CFF0(ctx, base);
	// b 0x8218d4ec
	goto loc_8218D4EC;
loc_8218D3C4:
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// mr r31,r25
	r31.u64 = r25.u64;
	// li r24,0
	r24.s64 = 0;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8218d4ec
	if (cr6.getEQ()) goto loc_8218D4EC;
	// lwz r23,340(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// clrlwi r18,r27,31
	r18.u64 = r27.u32 & 0x1;
loc_8218D3E0:
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r20,r31,4
	r20.s64 = r31.s64 + 4;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r19,r31,8
	r19.s64 = r31.s64 + 8;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r28,0
	r28.s64 = 0;
	// addi r30,r1,112
	r30.s64 = ctx.r1.s64 + 112;
	// rlwinm r8,r10,16,0,15
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF0000;
	// stw r9,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r9.u32);
	// rlwinm r9,r11,16,16,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
	// or r11,r8,r9
	r11.u64 = ctx.r8.u64 | ctx.r9.u64;
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r11.u32);
	// rlwinm r11,r10,16,16,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF;
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r11.u32);
loc_8218D420:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// beq cr6,0x8218d450
	if (cr6.getEQ()) goto loc_8218D450;
	// li r11,6
	r11.s64 = 6;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// divwu r11,r24,r11
	r11.u32 = r24.u32 / r11.u32;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// add r4,r11,r28
	ctx.r4.u64 = r11.u64 + r28.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// mtctr r26
	ctr.u64 = r26.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8218d4ec
	if (cr0.getLT()) goto loc_8218D4EC;
loc_8218D450:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r10,1
	ctx.r10.s64 = 1;
	// rlwinm r11,r11,20,28,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
	// slw r11,r10,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r10.u32 << (r11.u8 & 0x3F));
	// andi. r11,r11,24702
	r11.u64 = r11.u64 & 24702;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8218d49c
	if (cr0.getEQ()) goto loc_8218D49C;
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
	// stw r23,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r23.u32);
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// mr r8,r21
	ctx.r8.u64 = r21.u64;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8218ce58
	sub_8218CE58(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8218d4ec
	if (cr0.getLT()) goto loc_8218D4EC;
loc_8218D49C:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// cmplwi cr6,r28,2
	cr6.compare<uint32_t>(r28.u32, 2, xer);
	// blt cr6,0x8218d420
	if (cr6.getLT()) goto loc_8218D420;
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// addi r24,r24,12
	r24.s64 = r24.s64 + 12;
	// lwz r10,116(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lwz r9,124(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// rlwimi r10,r11,16,0,15
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 16) & 0xFFFF0000) | (ctx.r10.u64 & 0xFFFFFFFF0000FFFF);
	// lwz r8,112(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// rlwinm r11,r11,16,16,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF;
	// rlwinm r9,r9,16,0,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 16) & 0xFFFF0000;
	// or r11,r9,r11
	r11.u64 = ctx.r9.u64 | r11.u64;
	// stw r8,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r8.u32);
	// addi r31,r31,12
	r31.s64 = r31.s64 + 12;
	// stw r10,0(r20)
	PPC_STORE_U32(r20.u32 + 0, ctx.r10.u32);
	// stw r11,0(r19)
	PPC_STORE_U32(r19.u32 + 0, r11.u32);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// blt cr6,0x8218d3e0
	if (cr6.getLT()) goto loc_8218D3E0;
loc_8218D4EC:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x823ed160
	return;
}

__attribute__((alias("__imp__sub_8218D4F8"))) PPC_WEAK_FUNC(sub_8218D4F8);
PPC_FUNC_IMPL(__imp__sub_8218D4F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplw cr6,r11,r31
	cr6.compare<uint32_t>(r11.u32, r31.u32, xer);
	// bgt cr6,0x8218d560
	if (cr6.getGT()) goto loc_8218D560;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// cmplw cr6,r31,r9
	cr6.compare<uint32_t>(r31.u32, ctx.r9.u32, xer);
	// bge cr6,0x8218d560
	if (!cr6.getLT()) goto loc_8218D560;
	// subf r10,r31,r10
	ctx.r10.s64 = ctx.r10.s64 - r31.s64;
	// addi r4,r31,4
	ctx.r4.s64 = r31.s64 + 4;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// srawi r11,r11,2
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x3) != 0);
	r11.s64 = r11.s32 >> 2;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823ef8a0
	sub_823EF8A0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
loc_8218D560:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218D580"))) PPC_WEAK_FUNC(sub_8218D580);
PPC_FUNC_IMPL(__imp__sub_8218D580) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// li r11,0
	r11.s64 = 0;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
loc_8218D588:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8218d5a4
	if (!cr6.getEQ()) goto loc_8218D5A4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// blt cr6,0x8218d588
	if (cr6.getLT()) goto loc_8218D588;
loc_8218D5A4:
	// rlwinm r11,r11,5,0,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// b 0x8218d5cc
	goto loc_8218D5CC;
loc_8218D5AC:
	// clrlwi r10,r11,27
	ctx.r10.u64 = r11.u32 & 0x1F;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r8,r11,29,3,29
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r8,r8,r3
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r3.u32);
	// slw r10,r9,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r10.u8 & 0x3F));
	// and. r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 & ctx.r8.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218d5d4
	if (!cr0.getEQ()) goto loc_8218D5D4;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_8218D5CC:
	// cmplwi cr6,r11,256
	cr6.compare<uint32_t>(r11.u32, 256, xer);
	// blt cr6,0x8218d5ac
	if (cr6.getLT()) goto loc_8218D5AC;
loc_8218D5D4:
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218D5E0"))) PPC_WEAK_FUNC(sub_8218D5E0);
PPC_FUNC_IMPL(__imp__sub_8218D5E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed118
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lis r10,-16384
	ctx.r10.s64 = -1073741824;
	// addi r11,r31,-4
	r11.s64 = r31.s64 + -4;
	// ori r8,r10,15104
	ctx.r8.u64 = ctx.r10.u64 | 15104;
	// li r9,768
	ctx.r9.s64 = 768;
	// lis r10,-16359
	ctx.r10.s64 = -1072103424;
	// li r7,0
	ctx.r7.s64 = 0;
	// ori r6,r10,11008
	ctx.r6.u64 = ctx.r10.u64 | 11008;
	// stwu r8,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	r11.u32 = ea;
	// li r3,24
	ctx.r3.s64 = 24;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// li r5,96
	ctx.r5.s64 = 96;
	// addi r30,r10,-19480
	r30.s64 = ctx.r10.s64 + -19480;
	// stwu r9,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	r11.u32 = ea;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stwu r6,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	r11.u32 = ea;
	// stwu r7,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	r11.u32 = ea;
	// stwu r3,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	r11.u32 = ea;
	// mr r29,r11
	r29.u64 = r11.u64;
	// addi r3,r29,4
	ctx.r3.s64 = r29.s64 + 4;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lis r10,-16374
	ctx.r10.s64 = -1073086464;
	// addi r11,r29,96
	r11.s64 = r29.s64 + 96;
	// ori r10,r10,11008
	ctx.r10.u64 = ctx.r10.u64 | 11008;
	// li r9,1
	ctx.r9.s64 = 1;
	// li r8,9
	ctx.r8.s64 = 9;
	// addi r4,r30,96
	ctx.r4.s64 = r30.s64 + 96;
	// li r5,36
	ctx.r5.s64 = 36;
	// stwu r10,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	r11.u32 = ea;
	// mr r30,r11
	r30.u64 = r11.u64;
	// addi r3,r30,4
	ctx.r3.s64 = r30.s64 + 4;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lis r10,1
	ctx.r10.s64 = 65536;
	// addi r11,r30,36
	r11.s64 = r30.s64 + 36;
	// ori r8,r10,8576
	ctx.r8.u64 = ctx.r10.u64 | 8576;
	// lis r9,4096
	ctx.r9.s64 = 268435456;
	// li r7,0
	ctx.r7.s64 = 0;
	// ori r9,r9,14
	ctx.r9.u64 = ctx.r9.u64 | 14;
	// lis r10,2
	ctx.r10.s64 = 131072;
	// stwu r8,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	r11.u32 = ea;
	// li r4,0
	ctx.r4.s64 = 0;
	// ori r6,r10,8448
	ctx.r6.u64 = ctx.r10.u64 | 8448;
	// lis r10,0
	ctx.r10.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// ori r10,r10,65535
	ctx.r10.u64 = ctx.r10.u64 | 65535;
	// stwu r9,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	r11.u32 = ea;
	// li r8,8851
	ctx.r8.s64 = 8851;
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
	// lis r9,2
	ctx.r9.s64 = 131072;
	// lis r20,8
	r20.s64 = 524288;
	// li r30,0
	r30.s64 = 0;
	// stwu r7,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	r11.u32 = ea;
	// li r29,8704
	r29.s64 = 8704;
	// li r28,0
	r28.s64 = 0;
	// li r27,8707
	r27.s64 = 8707;
	// li r26,0
	r26.s64 = 0;
	// li r25,8712
	r25.s64 = 8712;
	// stwu r6,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	r11.u32 = ea;
	// ori r6,r9,8708
	ctx.r6.u64 = ctx.r9.u64 | 8708;
	// lis r9,1
	ctx.r9.s64 = 65536;
	// li r24,4
	r24.s64 = 4;
	// li r23,8452
	r23.s64 = 8452;
	// li r22,0
	r22.s64 = 0;
	// stwu r5,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	r11.u32 = ea;
	// li r5,768
	ctx.r5.s64 = 768;
	// li r21,8832
	r21.s64 = 8832;
	// ori r20,r20,8
	r20.u64 = r20.u64 | 8;
	// stwu r4,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r4.u32);
	r11.u32 = ea;
	// li r4,8978
	ctx.r4.s64 = 8978;
	// stwu r3,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	r11.u32 = ea;
	// li r3,8205
	ctx.r3.s64 = 8205;
	// stwu r8,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	r11.u32 = ea;
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// stwu r7,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	r11.u32 = ea;
	// stwu r6,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	r11.u32 = ea;
	// stwu r5,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	r11.u32 = ea;
	// stwu r4,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r4.u32);
	r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	r11.u32 = ea;
	// li r10,8962
	ctx.r10.s64 = 8962;
	// li r9,4
	ctx.r9.s64 = 4;
	// lis r8,2
	ctx.r8.s64 = 131072;
	// li r6,0
	ctx.r6.s64 = 0;
	// ori r8,r8,8320
	ctx.r8.u64 = ctx.r8.u64 | 8320;
	// stwu r3,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r3.u32);
	r11.u32 = ea;
	// lis r5,16
	ctx.r5.s64 = 1048576;
	// ori r5,r5,16
	ctx.r5.u64 = ctx.r5.u64 | 16;
	// stwu r30,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, r30.u32);
	r11.u32 = ea;
	// stwu r29,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, r29.u32);
	r11.u32 = ea;
	// stwu r28,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, r28.u32);
	r11.u32 = ea;
	// stwu r27,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, r27.u32);
	r11.u32 = ea;
	// stwu r26,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, r26.u32);
	r11.u32 = ea;
	// stwu r25,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, r25.u32);
	r11.u32 = ea;
	// stwu r24,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, r24.u32);
	r11.u32 = ea;
	// stwu r23,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, r23.u32);
	r11.u32 = ea;
	// stwu r22,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, r22.u32);
	r11.u32 = ea;
	// stwu r21,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, r21.u32);
	r11.u32 = ea;
	// stwu r20,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, r20.u32);
	r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	r11.u32 = ea;
	// stwu r7,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	r11.u32 = ea;
	// stwu r6,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	r11.u32 = ea;
	// stwu r5,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r5.u32);
	r11.u32 = ea;
	// subf r11,r31,r11
	r11.s64 = r11.s64 - r31.s64;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// srawi r3,r11,2
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x3) != 0);
	ctx.r3.s64 = r11.s32 >> 2;
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x823ed168
	return;
}

__attribute__((alias("__imp__sub_8218D7B0"))) PPC_WEAK_FUNC(sub_8218D7B0);
PPC_FUNC_IMPL(__imp__sub_8218D7B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister r11{};
	PPCRegister r12{};
	// li r12,1
	r12.s64 = 1;
	// ld r11,16(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// rldicr r12,r12,41,63
	r12.u64 = __builtin_rotateleft64(r12.u64, 41) & 0xFFFFFFFFFFFFFFFF;
	// or r10,r11,r12
	ctx.r10.u64 = r11.u64 | r12.u64;
	// li r12,1
	r12.s64 = 1;
	// li r11,1
	r11.s64 = 1;
	// rldicr r12,r12,40,63
	r12.u64 = __builtin_rotateleft64(r12.u64, 40) & 0xFFFFFFFFFFFFFFFF;
	// rldicr r11,r11,35,63
	r11.u64 = __builtin_rotateleft64(r11.u64, 35) & 0xFFFFFFFFFFFFFFFF;
	// std r10,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r10.u64);
	// or r10,r10,r12
	ctx.r10.u64 = ctx.r10.u64 | r12.u64;
	// li r12,1
	r12.s64 = 1;
	// rldicr r12,r12,39,63
	r12.u64 = __builtin_rotateleft64(r12.u64, 39) & 0xFFFFFFFFFFFFFFFF;
	// std r10,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r10.u64);
	// or r10,r10,r12
	ctx.r10.u64 = ctx.r10.u64 | r12.u64;
	// li r12,1
	r12.s64 = 1;
	// rldicr r12,r12,44,63
	r12.u64 = __builtin_rotateleft64(r12.u64, 44) & 0xFFFFFFFFFFFFFFFF;
	// std r10,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r10.u64);
	// ld r10,24(r3)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 24);
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | r11.u64;
	// std r10,24(r3)
	PPC_STORE_U64(ctx.r3.u32 + 24, ctx.r10.u64);
	// ld r10,16(r3)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// ori r10,r10,128
	ctx.r10.u64 = ctx.r10.u64 | 128;
	// std r10,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r10.u64);
	// ori r10,r10,64
	ctx.r10.u64 = ctx.r10.u64 | 64;
	// std r10,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r10.u64);
	// ori r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 | 32;
	// std r10,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r10.u64);
	// ld r10,32(r3)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 32);
	// oris r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 524288;
	// std r10,32(r3)
	PPC_STORE_U64(ctx.r3.u32 + 32, ctx.r10.u64);
	// ld r10,16(r3)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// or r10,r10,r12
	ctx.r10.u64 = ctx.r10.u64 | r12.u64;
	// li r12,1
	r12.s64 = 1;
	// rldicr r12,r12,37,63
	r12.u64 = __builtin_rotateleft64(r12.u64, 37) & 0xFFFFFFFFFFFFFFFF;
	// std r10,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r10.u64);
	// oris r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 524288;
	// std r10,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r10.u64);
	// oris r10,r10,16
	ctx.r10.u64 = ctx.r10.u64 | 1048576;
	// std r10,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r10.u64);
	// ori r10,r10,2048
	ctx.r10.u64 = ctx.r10.u64 | 2048;
	// std r10,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r10.u64);
	// ori r10,r10,256
	ctx.r10.u64 = ctx.r10.u64 | 256;
	// std r10,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r10.u64);
	// ori r10,r10,8
	ctx.r10.u64 = ctx.r10.u64 | 8;
	// std r10,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r10.u64);
	// or r10,r10,r12
	ctx.r10.u64 = ctx.r10.u64 | r12.u64;
	// li r12,1
	r12.s64 = 1;
	// rldicr r12,r12,54,63
	r12.u64 = __builtin_rotateleft64(r12.u64, 54) & 0xFFFFFFFFFFFFFFFF;
	// std r10,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, ctx.r10.u64);
	// ld r10,24(r3)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 24);
	// or r10,r10,r12
	ctx.r10.u64 = ctx.r10.u64 | r12.u64;
	// std r10,24(r3)
	PPC_STORE_U64(ctx.r3.u32 + 24, ctx.r10.u64);
	// ld r10,32(r3)
	ctx.r10.u64 = PPC_LOAD_U64(ctx.r3.u32 + 32);
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// std r11,32(r3)
	PPC_STORE_U64(ctx.r3.u32 + 32, r11.u64);
	// ld r11,24(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 24);
	// oris r11,r11,32768
	r11.u64 = r11.u64 | 2147483648;
	// std r11,24(r3)
	PPC_STORE_U64(ctx.r3.u32 + 24, r11.u64);
	// lwz r11,10440(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 10440);
	// lwz r10,10436(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 10436);
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r11,r11,17,0,14
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 17) & 0xFFFE0000;
	// rlwinm r8,r10,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// srawi r7,r9,17
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x1FFFF) != 0);
	ctx.r7.s64 = ctx.r9.s32 >> 17;
	// rlwinm r10,r10,17,0,14
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 17) & 0xFFFE0000;
	// srawi r6,r11,17
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1FFFF) != 0);
	ctx.r6.s64 = r11.s32 >> 17;
	// srawi r5,r8,17
	xer.ca = (ctx.r8.s32 < 0) & ((ctx.r8.u32 & 0x1FFFF) != 0);
	ctx.r5.s64 = ctx.r8.s32 >> 17;
	// srawi r4,r10,17
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x1FFFF) != 0);
	ctx.r4.s64 = ctx.r10.s32 >> 17;
	// b 0x82192c70
	sub_82192C70(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218D8C8"))) PPC_WEAK_FUNC(sub_8218D8C8);
PPC_FUNC_IMPL(__imp__sub_8218D8C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	uint32_t ea{};
	// li r8,1480
	ctx.r8.s64 = 1480;
	// addi r11,r5,-4
	r11.s64 = ctx.r5.s64 + -4;
	// lis r7,2
	ctx.r7.s64 = 131072;
	// neg r10,r4
	ctx.r10.s64 = -ctx.r4.s64;
	// lis r9,7
	ctx.r9.s64 = 458752;
	// rlwimi r10,r4,8,17,23
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r4.u32, 8) & 0x7F00) | (ctx.r10.u64 & 0xFFFFFFFFFFFF80FF);
	// stwu r8,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	r11.u32 = ea;
	// ori r6,r9,36096
	ctx.r6.u64 = ctx.r9.u64 | 36096;
	// rlwinm r10,r10,4,13,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0x7FFF0;
	// li r9,8
	ctx.r9.s64 = 8;
	// rlwinm r10,r10,0,21,19
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFF7FF;
	// stwu r7,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	r11.u32 = ea;
	// ori r8,r10,1
	ctx.r8.u64 = ctx.r10.u64 | 1;
	// stwu r6,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	r11.u32 = ea;
loc_8218D900:
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// stwu r8,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	r11.u32 = ea;
	// bne 0x8218d900
	if (!cr0.getEQ()) goto loc_8218D900;
	// li r9,3328
	ctx.r9.s64 = 3328;
	// stwu r9,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	r11.u32 = ea;
	// subf r11,r5,r11
	r11.s64 = r11.s64 - ctx.r5.s64;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// srawi r3,r11,2
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x3) != 0);
	ctx.r3.s64 = r11.s32 >> 2;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218D928"))) PPC_WEAK_FUNC(sub_8218D928);
PPC_FUNC_IMPL(__imp__sub_8218D928) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r4,-19072
	ctx.r4.s64 = -1249902592;
	// li r3,8192
	ctx.r3.s64 = 8192;
	// bl 0x8209d000
	sub_8209D000(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r28,r30,8192
	r28.s64 = r30.s64 + 8192;
	// bne 0x8218d958
	if (!cr0.getEQ()) goto loc_8218D958;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8218da54
	goto loc_8218DA54;
loc_8218D958:
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// stw r30,13764(r31)
	PPC_STORE_U32(r31.u32 + 13764, r30.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218d5e0
	sub_8218D5E0(ctx, base);
	// rlwinm r11,r30,12,20,31
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 12) & 0xFFF;
	// clrlwi r10,r30,3
	ctx.r10.u64 = r30.u32 & 0x1FFFFFFF;
	// lwz r9,13768(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 13768);
	// addi r11,r11,512
	r11.s64 = r11.s64 + 512;
	// li r4,16
	ctx.r4.s64 = 16;
	// rlwinm r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	// addi r29,r31,13904
	r29.s64 = r31.s64 + 13904;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// rlwimi r10,r9,0,0,7
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0xFF000000) | (ctx.r10.u64 & 0xFFFFFFFF00FFFFFF);
	// stw r11,13772(r31)
	PPC_STORE_U32(r31.u32 + 13772, r11.u32);
	// addi r11,r3,7
	r11.s64 = ctx.r3.s64 + 7;
	// rlwinm r11,r11,2,0,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFE0;
	// stw r10,13768(r31)
	PPC_STORE_U32(r31.u32 + 13768, ctx.r10.u32);
	// add r5,r11,r30
	ctx.r5.u64 = r11.u64 + r30.u64;
loc_8218D9A8:
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218d8c8
	sub_8218D8C8(ctx, base);
	// rlwinm r11,r5,12,20,31
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 12) & 0xFFF;
	// clrlwi r10,r5,3
	ctx.r10.u64 = ctx.r5.u32 & 0x1FFFFFFF;
	// lwz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// addi r11,r11,512
	r11.s64 = r11.s64 + 512;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// rlwinm r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	// cmplwi cr6,r4,112
	cr6.compare<uint32_t>(ctx.r4.u32, 112, xer);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// rlwimi r10,r9,0,0,7
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0xFF000000) | (ctx.r10.u64 & 0xFFFFFFFF00FFFFFF);
	// stw r11,4(r29)
	PPC_STORE_U32(r29.u32 + 4, r11.u32);
	// addi r11,r3,7
	r11.s64 = ctx.r3.s64 + 7;
	// rlwinm r11,r11,2,0,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFE0;
	// stw r10,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r10.u32);
	// addi r29,r29,8
	r29.s64 = r29.s64 + 8;
	// add r5,r11,r5
	ctx.r5.u64 = r11.u64 + ctx.r5.u64;
	// ble cr6,0x8218d9a8
	if (!cr6.getGT()) goto loc_8218D9A8;
	// addi r11,r5,-4
	r11.s64 = ctx.r5.s64 + -4;
	// li r10,24
	ctx.r10.s64 = 24;
loc_8218DA00:
	// lis r9,-16384
	ctx.r9.s64 = -1073741824;
	// lis r8,1
	ctx.r8.s64 = 65536;
	// ori r9,r9,13824
	ctx.r9.u64 = ctx.r9.u64 | 13824;
	// ori r8,r8,129
	ctx.r8.u64 = ctx.r8.u64 | 129;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stwu r9,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	r11.u32 = ea;
	// bne 0x8218da00
	if (!cr0.getEQ()) goto loc_8218DA00;
	// subf r10,r5,r11
	ctx.r10.s64 = r11.s64 - ctx.r5.s64;
	// lwz r9,14800(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 14800);
	// rlwinm r11,r5,12,20,31
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 12) & 0xFFF;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r11,r11,512
	r11.s64 = r11.s64 + 512;
	// srawi r8,r10,2
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
	ctx.r8.s64 = ctx.r10.s32 >> 2;
	// rlwinm r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	// clrlwi r10,r5,3
	ctx.r10.u64 = ctx.r5.u32 & 0x1FFFFFFF;
	// rlwimi r8,r9,0,0,7
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0xFF000000) | (ctx.r8.u64 & 0xFFFFFFFF00FFFFFF);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r8,14800(r31)
	PPC_STORE_U32(r31.u32 + 14800, ctx.r8.u32);
	// stw r11,14804(r31)
	PPC_STORE_U32(r31.u32 + 14804, r11.u32);
loc_8218DA54:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_8218DA60"))) PPC_WEAK_FUNC(sub_8218DA60);
PPC_FUNC_IMPL(__imp__sub_8218DA60) {
	PPC_FUNC_PROLOGUE();
	// lwz r3,13764(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 13764);
	// lis r4,-20096
	ctx.r4.s64 = -1317011456;
	// b 0x8209d060
	sub_8209D060(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218DA70"))) PPC_WEAK_FUNC(sub_8218DA70);
PPC_FUNC_IMPL(__imp__sub_8218DA70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r31{};
	PPCRegister temp{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r10,r4,120
	ctx.r10.s64 = ctx.r4.s64 + 120;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// rlwinm r10,r10,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// dcbt r0,r11
	// li r8,128
	ctx.r8.s64 = 128;
	// dcbt r8,r11
	// li r4,16
	ctx.r4.s64 = 16;
	// cmplwi cr6,r6,3
	cr6.compare<uint32_t>(ctx.r6.u32, 3, xer);
	// ble cr6,0x8218db14
	if (!cr6.getGT()) goto loc_8218DB14;
	// addi r8,r6,-4
	ctx.r8.s64 = ctx.r6.s64 + -4;
	// li r5,32
	ctx.r5.s64 = 32;
	// rlwinm r8,r8,30,2,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 30) & 0x3FFFFFFF;
	// li r6,48
	ctx.r6.s64 = 48;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
loc_8218DAB4:
	// li r31,256
	r31.s64 = 256;
	// dcbt r31,r11
	// li r31,64
	r31.s64 = 64;
	// lvrx v13,r4,r11
	temp.u32 = ctx.r4.u32 + r11.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// lvlx v0,0,r11
	temp.u32 = r11.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// lvlx v12,r4,r11
	temp.u32 = ctx.r4.u32 + r11.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vor v0,v0,v13
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)ctx.v13.u8)));
	// lvrx v11,r5,r11
	temp.u32 = ctx.r5.u32 + r11.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// lvlx v10,r5,r11
	temp.u32 = ctx.r5.u32 + r11.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vor v13,v12,v11
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v11.u8)));
	// lvrx v9,r6,r11
	temp.u32 = ctx.r6.u32 + r11.u32;
	_mm_store_si128((__m128i*)ctx.v9.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// lvlx v8,r6,r11
	temp.u32 = ctx.r6.u32 + r11.u32;
	_mm_store_si128((__m128i*)ctx.v8.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vor v12,v10,v9
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v10.u8), _mm_load_si128((__m128i*)ctx.v9.u8)));
	// lvrx v7,r31,r11
	temp.u32 = r31.u32 + r11.u32;
	_mm_store_si128((__m128i*)ctx.v7.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// addi r11,r11,64
	r11.s64 = r11.s64 + 64;
	// vor v11,v8,v7
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v8.u8), _mm_load_si128((__m128i*)ctx.v7.u8)));
	// stvx128 v0,r0,r10
	_mm_store_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v13,r10,r4
	_mm_store_si128((__m128i*)(base + ((ctx.r10.u32 + ctx.r4.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v12,r10,r5
	_mm_store_si128((__m128i*)(base + ((ctx.r10.u32 + ctx.r5.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v11,r10,r6
	_mm_store_si128((__m128i*)(base + ((ctx.r10.u32 + ctx.r6.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v11.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r10,r10,64
	ctx.r10.s64 = ctx.r10.s64 + 64;
	// bne 0x8218dab4
	if (!cr0.getEQ()) goto loc_8218DAB4;
loc_8218DB14:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8218db44
	if (cr6.getEQ()) goto loc_8218DB44;
loc_8218DB1C:
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
	// mr r6,r11
	ctx.r6.u64 = r11.u64;
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvrx v13,r4,r6
	temp.u32 = ctx.r4.u32 + ctx.r6.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// vor v0,v0,v13
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)ctx.v13.u8)));
	// stvx128 v0,r0,r10
	_mm_store_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// bne 0x8218db1c
	if (!cr0.getEQ()) goto loc_8218DB1C;
loc_8218DB44:
	// ld r11,0(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
	// or r11,r11,r7
	r11.u64 = r11.u64 | ctx.r7.u64;
	// std r11,0(r3)
	PPC_STORE_U64(ctx.r3.u32 + 0, r11.u64);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218DB58"))) PPC_WEAK_FUNC(sub_8218DB58);
PPC_FUNC_IMPL(__imp__sub_8218DB58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r31{};
	PPCRegister temp{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r10,r4,376
	ctx.r10.s64 = ctx.r4.s64 + 376;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// rlwinm r10,r10,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
	// add r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 + ctx.r3.u64;
	// dcbt r0,r11
	// li r8,128
	ctx.r8.s64 = 128;
	// dcbt r8,r11
	// li r4,16
	ctx.r4.s64 = 16;
	// cmplwi cr6,r6,3
	cr6.compare<uint32_t>(ctx.r6.u32, 3, xer);
	// ble cr6,0x8218dbfc
	if (!cr6.getGT()) goto loc_8218DBFC;
	// addi r8,r6,-4
	ctx.r8.s64 = ctx.r6.s64 + -4;
	// li r5,32
	ctx.r5.s64 = 32;
	// rlwinm r8,r8,30,2,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 30) & 0x3FFFFFFF;
	// li r6,48
	ctx.r6.s64 = 48;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
loc_8218DB9C:
	// li r31,256
	r31.s64 = 256;
	// dcbt r31,r11
	// li r31,64
	r31.s64 = 64;
	// lvrx v13,r4,r11
	temp.u32 = ctx.r4.u32 + r11.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// lvlx v0,0,r11
	temp.u32 = r11.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// lvlx v12,r4,r11
	temp.u32 = ctx.r4.u32 + r11.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vor v0,v0,v13
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)ctx.v13.u8)));
	// lvrx v11,r5,r11
	temp.u32 = ctx.r5.u32 + r11.u32;
	_mm_store_si128((__m128i*)ctx.v11.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// lvlx v10,r5,r11
	temp.u32 = ctx.r5.u32 + r11.u32;
	_mm_store_si128((__m128i*)ctx.v10.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vor v13,v12,v11
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)ctx.v11.u8)));
	// lvrx v9,r6,r11
	temp.u32 = ctx.r6.u32 + r11.u32;
	_mm_store_si128((__m128i*)ctx.v9.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// lvlx v8,r6,r11
	temp.u32 = ctx.r6.u32 + r11.u32;
	_mm_store_si128((__m128i*)ctx.v8.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// vor v12,v10,v9
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v10.u8), _mm_load_si128((__m128i*)ctx.v9.u8)));
	// lvrx v7,r31,r11
	temp.u32 = r31.u32 + r11.u32;
	_mm_store_si128((__m128i*)ctx.v7.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// addi r11,r11,64
	r11.s64 = r11.s64 + 64;
	// vor v11,v8,v7
	_mm_store_si128((__m128i*)ctx.v11.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v8.u8), _mm_load_si128((__m128i*)ctx.v7.u8)));
	// stvx128 v0,r0,r10
	_mm_store_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v13,r10,r4
	_mm_store_si128((__m128i*)(base + ((ctx.r10.u32 + ctx.r4.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v12,r10,r5
	_mm_store_si128((__m128i*)(base + ((ctx.r10.u32 + ctx.r5.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v12.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v11,r10,r6
	_mm_store_si128((__m128i*)(base + ((ctx.r10.u32 + ctx.r6.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v11.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r10,r10,64
	ctx.r10.s64 = ctx.r10.s64 + 64;
	// bne 0x8218db9c
	if (!cr0.getEQ()) goto loc_8218DB9C;
loc_8218DBFC:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8218dc2c
	if (cr6.getEQ()) goto loc_8218DC2C;
loc_8218DC04:
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
	// mr r6,r11
	ctx.r6.u64 = r11.u64;
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// lvlx v0,0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskL[(temp.u32 & 0xF) * 16])));
	// lvrx v13,r4,r6
	temp.u32 = ctx.r4.u32 + ctx.r6.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, temp.u32 & 0xF ? _mm_shuffle_epi8(_mm_load_si128((__m128i*)(base + (temp.u32 & ~0xF))), _mm_load_si128((__m128i*)&VectorMaskR[(temp.u32 & 0xF) * 16])) : _mm_setzero_si128());
	// vor v0,v0,v13
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)ctx.v13.u8)));
	// stvx128 v0,r0,r10
	_mm_store_si128((__m128i*)(base + ((ctx.r10.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r10,r10,16
	ctx.r10.s64 = ctx.r10.s64 + 16;
	// bne 0x8218dc04
	if (!cr0.getEQ()) goto loc_8218DC04;
loc_8218DC2C:
	// ld r11,8(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 8);
	// or r11,r7,r11
	r11.u64 = ctx.r7.u64 | r11.u64;
	// std r11,8(r3)
	PPC_STORE_U64(ctx.r3.u32 + 8, r11.u64);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218DC40"))) PPC_WEAK_FUNC(sub_8218DC40);
PPC_FUNC_IMPL(__imp__sub_8218DC40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
loc_8218DC40:
	// lwz r9,0(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// clrlwi r11,r4,27
	r11.u64 = ctx.r4.u32 & 0x1F;
	// li r8,1
	ctx.r8.s64 = 1;
	// clrlwi r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	// rlwinm r10,r4,27,5,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// addi r10,r10,2528
	ctx.r10.s64 = ctx.r10.s64 + 2528;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// slw r9,r9,r11
	ctx.r9.u64 = r11.u8 & 0x20 ? 0 : (ctx.r9.u32 << (r11.u8 & 0x3F));
	// slw r11,r8,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r8.u32 << (r11.u8 & 0x3F));
	// lwzx r8,r10,r3
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	// andc r11,r8,r11
	r11.u64 = ctx.r8.u64 & ~r11.u64;
	// or r11,r11,r9
	r11.u64 = r11.u64 | ctx.r9.u64;
	// stwx r11,r10,r3
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, r11.u32);
	// bne 0x8218dc40
	if (!cr0.getEQ()) goto loc_8218DC40;
	// li r12,1
	r12.s64 = 1;
	// ld r11,32(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 32);
	// rldicr r12,r12,56,63
	r12.u64 = __builtin_rotateleft64(r12.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// or r11,r11,r12
	r11.u64 = r11.u64 | r12.u64;
	// std r11,32(r3)
	PPC_STORE_U64(ctx.r3.u32 + 32, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218DCA0"))) PPC_WEAK_FUNC(sub_8218DCA0);
PPC_FUNC_IMPL(__imp__sub_8218DCA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
loc_8218DCA0:
	// lwz r9,0(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// clrlwi r11,r4,27
	r11.u64 = ctx.r4.u32 & 0x1F;
	// li r8,1
	ctx.r8.s64 = 1;
	// clrlwi r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	// rlwinm r10,r4,27,5,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// addi r10,r10,2532
	ctx.r10.s64 = ctx.r10.s64 + 2532;
	// addi r5,r5,4
	ctx.r5.s64 = ctx.r5.s64 + 4;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// slw r9,r9,r11
	ctx.r9.u64 = r11.u8 & 0x20 ? 0 : (ctx.r9.u32 << (r11.u8 & 0x3F));
	// slw r11,r8,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r8.u32 << (r11.u8 & 0x3F));
	// lwzx r8,r10,r3
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	// andc r11,r8,r11
	r11.u64 = ctx.r8.u64 & ~r11.u64;
	// or r11,r11,r9
	r11.u64 = r11.u64 | ctx.r9.u64;
	// stwx r11,r10,r3
	PPC_STORE_U32(ctx.r10.u32 + ctx.r3.u32, r11.u32);
	// bne 0x8218dca0
	if (!cr0.getEQ()) goto loc_8218DCA0;
	// li r12,1
	r12.s64 = 1;
	// ld r11,32(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 32);
	// rldicr r12,r12,56,63
	r12.u64 = __builtin_rotateleft64(r12.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// or r11,r11,r12
	r11.u64 = r11.u64 | r12.u64;
	// std r11,32(r3)
	PPC_STORE_U64(ctx.r3.u32 + 32, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218DD00"))) PPC_WEAK_FUNC(sub_8218DD00);
PPC_FUNC_IMPL(__imp__sub_8218DD00) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	// addi r11,r4,2536
	r11.s64 = ctx.r4.s64 + 2536;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
loc_8218DD0C:
	// lbz r10,11(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 11);
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// lbz r9,7(r5)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r5.u32 + 7);
	// rotlwi r10,r10,8
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 8);
	// lbz r8,3(r5)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r5.u32 + 3);
	// addi r5,r5,16
	ctx.r5.s64 = ctx.r5.s64 + 16;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// rlwinm r10,r10,8,0,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFFFFFF00;
	// or r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 | ctx.r8.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x8218dd0c
	if (!cr0.getEQ()) goto loc_8218DD0C;
	// li r12,1
	r12.s64 = 1;
	// ld r11,32(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 32);
	// rldicr r12,r12,56,63
	r12.u64 = __builtin_rotateleft64(r12.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// or r11,r11,r12
	r11.u64 = r11.u64 | r12.u64;
	// std r11,32(r3)
	PPC_STORE_U64(ctx.r3.u32 + 32, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218DD58"))) PPC_WEAK_FUNC(sub_8218DD58);
PPC_FUNC_IMPL(__imp__sub_8218DD58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	// addi r11,r4,2552
	r11.s64 = ctx.r4.s64 + 2552;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
loc_8218DD64:
	// lbz r10,11(r5)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r5.u32 + 11);
	// addic. r6,r6,-1
	xer.ca = ctx.r6.u32 > 0;
	ctx.r6.s64 = ctx.r6.s64 + -1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// lbz r9,7(r5)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r5.u32 + 7);
	// rotlwi r10,r10,8
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 8);
	// lbz r8,3(r5)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r5.u32 + 3);
	// addi r5,r5,16
	ctx.r5.s64 = ctx.r5.s64 + 16;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// rlwinm r10,r10,8,0,23
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFFFFFF00;
	// or r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 | ctx.r8.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x8218dd64
	if (!cr0.getEQ()) goto loc_8218DD64;
	// li r12,1
	r12.s64 = 1;
	// ld r11,32(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 32);
	// rldicr r12,r12,56,63
	r12.u64 = __builtin_rotateleft64(r12.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// or r11,r11,r12
	r11.u64 = r11.u64 | r12.u64;
	// std r11,32(r3)
	PPC_STORE_U64(ctx.r3.u32 + 32, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218DDB0"))) PPC_WEAK_FUNC(sub_8218DDB0);
PPC_FUNC_IMPL(__imp__sub_8218DDB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister temp{};
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, r11.u32);
	// stw r11,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, r11.u32);
	// stw r11,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, r11.u32);
	// stw r11,12(r4)
	PPC_STORE_U32(ctx.r4.u32 + 12, r11.u32);
	// lwz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// clrlwi r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	// stw r3,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r3.u32);
	// add r9,r11,r3
	ctx.r9.u64 = r11.u64 + ctx.r3.u64;
	// subfic r10,r10,0
	xer.ca = ctx.r10.u32 <= 0;
	ctx.r10.s64 = 0 - ctx.r10.s64;
	// subfe r10,r10,r10
	temp.u8 = (~ctx.r10.u32 + ctx.r10.u32 < ~ctx.r10.u32) | (~ctx.r10.u32 + ctx.r10.u32 + xer.ca < xer.ca);
	ctx.r10.u64 = ~ctx.r10.u64 + ctx.r10.u64 + xer.ca;
	xer.ca = temp.u8;
	// stw r9,8(r4)
	PPC_STORE_U32(ctx.r4.u32 + 8, ctx.r9.u32);
	// andi. r10,r10,832
	ctx.r10.u64 = ctx.r10.u64 & 832;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 + 40;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// stw r11,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, r11.u32);
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// stw r11,12(r4)
	PPC_STORE_U32(ctx.r4.u32 + 12, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218DE00"))) PPC_WEAK_FUNC(sub_8218DE00);
PPC_FUNC_IMPL(__imp__sub_8218DE00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// li r11,0
	r11.s64 = 0;
	// li r10,7
	ctx.r10.s64 = 7;
	// li r9,1
	ctx.r9.s64 = 1;
	// lis r8,-1
	ctx.r8.s64 = -65536;
	// std r11,0(r3)
	PPC_STORE_U64(ctx.r3.u32 + 0, r11.u64);
	// std r11,8(r3)
	PPC_STORE_U64(ctx.r3.u32 + 8, r11.u64);
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// std r11,24(r3)
	PPC_STORE_U64(ctx.r3.u32 + 24, r11.u64);
	// std r11,32(r3)
	PPC_STORE_U64(ctx.r3.u32 + 32, r11.u64);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// stw r9,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r9.u32);
	// stw r8,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, ctx.r8.u32);
	// stw r4,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, ctx.r4.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218DE38"))) PPC_WEAK_FUNC(sub_8218DE38);
PPC_FUNC_IMPL(__imp__sub_8218DE38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r31,12684(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 12684);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x8218debc
	if (cr0.getEQ()) goto loc_8218DEBC;
	// lwz r11,10908(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 10908);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8218de6c
	if (cr0.getEQ()) goto loc_8218DE6C;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// b 0x8218debc
	goto loc_8218DEBC;
loc_8218DE6C:
	// lwz r11,10912(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 10912);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// and. r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218debc
	if (cr0.getEQ()) goto loc_8218DEBC;
	// lwz r3,13508(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 13508);
	// lwz r11,13512(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 13512);
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// blt cr6,0x8218de94
	if (cr6.getLT()) goto loc_8218DE94;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8219bac8
	sub_8219BAC8(ctx, base);
loc_8218DE94:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r10,-1
	ctx.r10.s64 = -1;
	// rlwimi r11,r31,30,2,31
	r11.u64 = (__builtin_rotateleft32(r31.u32, 30) & 0x3FFFFFFF) | (r11.u64 & 0xFFFFFFFFC0000000);
	// rlwinm r11,r11,0,2,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFBFFFFFFF;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// addi r10,r3,8
	ctx.r10.s64 = ctx.r3.s64 + 8;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,0(r3)
	PPC_STORE_U64(ctx.r3.u32 + 0, r11.u64);
	// stw r10,13508(r30)
	PPC_STORE_U32(r30.u32 + 13508, ctx.r10.u32);
loc_8218DEBC:
	// stw r29,12684(r30)
	PPC_STORE_U32(r30.u32 + 12684, r29.u32);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// ld r11,16(r30)
	r11.u64 = PPC_LOAD_U64(r30.u32 + 16);
	// oris r11,r11,16
	r11.u64 = r11.u64 | 1048576;
	// std r11,16(r30)
	PPC_STORE_U64(r30.u32 + 16, r11.u64);
	// oris r11,r11,2
	r11.u64 = r11.u64 | 131072;
	// std r11,16(r30)
	PPC_STORE_U64(r30.u32 + 16, r11.u64);
	// beq cr6,0x8218dfec
	if (cr6.getEQ()) goto loc_8218DFEC;
	// addi r11,r29,40
	r11.s64 = r29.s64 + 40;
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8218dfec
	if (cr0.getEQ()) goto loc_8218DFEC;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// ld r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U64(r30.u32 + 8);
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// andc r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r9.u64;
	// std r10,8(r30)
	PPC_STORE_U64(r30.u32 + 8, ctx.r10.u64);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// cmpldi cr6,r10,0
	cr6.compare<uint64_t>(ctx.r10.u64, 0, xer);
	// beq cr6,0x8218df20
	if (cr6.getEQ()) goto loc_8218DF20;
	// li r12,1
	r12.s64 = 1;
	// ld r10,32(r30)
	ctx.r10.u64 = PPC_LOAD_U64(r30.u32 + 32);
	// rldicr r12,r12,56,63
	r12.u64 = __builtin_rotateleft64(r12.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// or r10,r10,r12
	ctx.r10.u64 = ctx.r10.u64 | r12.u64;
	// std r10,32(r30)
	PPC_STORE_U64(r30.u32 + 32, ctx.r10.u64);
loc_8218DF20:
	// addi r31,r11,20
	r31.s64 = r11.s64 + 20;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// addi r28,r30,1152
	r28.s64 = r30.s64 + 1152;
	// add r29,r11,r31
	r29.u64 = r11.u64 + r31.u64;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// bge cr6,0x8218dfec
	if (!cr6.getLT()) goto loc_8218DFEC;
loc_8218DF38:
	// lhz r11,2(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 2);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8218df54
	if (cr0.getEQ()) goto loc_8218DF54;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// blt cr6,0x8218df38
	if (cr6.getLT()) goto loc_8218DF38;
loc_8218DF54:
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// bge cr6,0x8218dfec
	if (!cr6.getLT()) goto loc_8218DFEC;
loc_8218DF5C:
	// lhz r11,2(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 2);
	// lhz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 0);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8218dfe4
	if (cr0.getEQ()) goto loc_8218DFE4;
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// clrlwi r11,r10,16
	r11.u64 = ctx.r10.u32 & 0xFFFF;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// add r3,r11,r28
	ctx.r3.u64 = r11.u64 + r28.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// add r31,r30,r31
	r31.u64 = r30.u64 + r31.u64;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// blt cr6,0x8218df5c
	if (cr6.getLT()) goto loc_8218DF5C;
	// b 0x8218dfe4
	goto loc_8218DFE4;
loc_8218DF98:
	// lhz r10,2(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 2);
	// lhz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U16(r31.u32 + 0);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8218dfec
	if (cr0.getEQ()) goto loc_8218DFEC;
	// clrlwi r11,r9,16
	r11.u64 = ctx.r9.u32 & 0xFFFF;
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
loc_8218DFB4:
	// addis r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 65536;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// lwz r7,4(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// and r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 & ctx.r8.u64;
	// addi r31,r31,8
	r31.s64 = r31.s64 + 8;
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// clrlwi. r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218dfb4
	if (!cr0.getEQ()) goto loc_8218DFB4;
loc_8218DFE4:
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// blt cr6,0x8218df98
	if (cr6.getLT()) goto loc_8218DF98;
loc_8218DFEC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_8218DFF8"))) PPC_WEAK_FUNC(sub_8218DFF8);
PPC_FUNC_IMPL(__imp__sub_8218DFF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r5,872
	ctx.r5.s64 = 872;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// lwz r11,872(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 872);
	// li r10,6
	ctx.r10.s64 = 6;
	// stw r30,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r30.u32);
	// rlwinm r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	// li r9,1
	ctx.r9.s64 = 1;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// lis r8,-1
	ctx.r8.s64 = -65536;
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// stw r9,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r9.u32);
	// addic. r11,r11,1
	xer.ca = r11.u32 > 4294967294;
	r11.s64 = r11.s64 + 1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r8,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r8.u32);
	// beq 0x8218e0e8
	if (cr0.getEQ()) goto loc_8218E0E8;
	// addi r25,r31,40
	r25.s64 = r31.s64 + 40;
	// addi r27,r31,896
	r27.s64 = r31.s64 + 896;
	// mr r24,r11
	r24.u64 = r11.u64;
loc_8218E05C:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// addi r11,r11,872
	r11.s64 = r11.s64 + 872;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// add r26,r10,r9
	r26.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r9,24(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// addi r9,r9,9
	ctx.r9.s64 = ctx.r9.s64 + 9;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
	// beq 0x8218e0d0
	if (cr0.getEQ()) goto loc_8218E0D0;
	// addi r30,r25,28
	r30.s64 = r25.s64 + 28;
	// mr r29,r11
	r29.u64 = r11.u64;
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
loc_8218E09C:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// clrlwi r11,r11,20
	r11.u64 = r11.u32 & 0xFFF;
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// add r4,r11,r26
	ctx.r4.u64 = r11.u64 + r26.u64;
	// cmplw cr6,r30,r4
	cr6.compare<uint32_t>(r30.u32, ctx.r4.u32, xer);
	// beq cr6,0x8218e0c0
	if (cr6.getEQ()) goto loc_8218E0C0;
	// li r5,12
	ctx.r5.s64 = 12;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
loc_8218E0C0:
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// addi r30,r30,12
	r30.s64 = r30.s64 + 12;
	// bne 0x8218e09c
	if (!cr0.getEQ()) goto loc_8218E09C;
loc_8218E0D0:
	// li r11,-1
	r11.s64 = -1;
	// addic. r24,r24,-1
	xer.ca = r24.u32 > 0;
	r24.s64 = r24.s64 + -1;
	cr0.compare<int32_t>(r24.s32, 0, xer);
	// addi r27,r27,8
	r27.s64 = r27.s64 + 8;
	// stw r11,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r11.u32);
	// addi r25,r25,416
	r25.s64 = r25.s64 + 416;
	// bne 0x8218e05c
	if (!cr0.getEQ()) goto loc_8218E05C;
loc_8218E0E8:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_8218E0F0"))) PPC_WEAK_FUNC(sub_8218E0F0);
PPC_FUNC_IMPL(__imp__sub_8218E0F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8218e118
	if (cr6.getEQ()) goto loc_8218E118;
	// ld r11,16(r30)
	r11.u64 = PPC_LOAD_U64(r30.u32 + 16);
	// oris r11,r11,8
	r11.u64 = r11.u64 | 524288;
	// std r11,16(r30)
	PPC_STORE_U64(r30.u32 + 16, r11.u64);
loc_8218E118:
	// lwz r31,12688(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 12688);
	// cmplwi r31,0
	cr0.compare<uint32_t>(r31.u32, 0, xer);
	// beq 0x8218e188
	if (cr0.getEQ()) goto loc_8218E188;
	// lwz r11,10908(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 10908);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8218e138
	if (cr0.getEQ()) goto loc_8218E138;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// b 0x8218e188
	goto loc_8218E188;
loc_8218E138:
	// lwz r11,10912(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 10912);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// and. r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218e188
	if (cr0.getEQ()) goto loc_8218E188;
	// lwz r3,13508(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 13508);
	// lwz r11,13512(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 13512);
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// blt cr6,0x8218e160
	if (cr6.getLT()) goto loc_8218E160;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8219bac8
	sub_8219BAC8(ctx, base);
loc_8218E160:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r10,-1
	ctx.r10.s64 = -1;
	// rlwimi r11,r31,30,2,31
	r11.u64 = (__builtin_rotateleft32(r31.u32, 30) & 0x3FFFFFFF) | (r11.u64 & 0xFFFFFFFFC0000000);
	// rlwinm r11,r11,0,2,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFBFFFFFFF;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// addi r10,r3,8
	ctx.r10.s64 = ctx.r3.s64 + 8;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// std r11,0(r3)
	PPC_STORE_U64(ctx.r3.u32 + 0, r11.u64);
	// stw r10,13508(r30)
	PPC_STORE_U32(r30.u32 + 13508, ctx.r10.u32);
loc_8218E188:
	// lbz r11,10942(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 10942);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// stw r29,12688(r30)
	PPC_STORE_U32(r30.u32 + 12688, r29.u32);
	// clrlwi r11,r11,25
	r11.u64 = r11.u32 & 0x7F;
	// stb r11,10942(r30)
	PPC_STORE_U8(r30.u32 + 10942, r11.u8);
	// beq cr6,0x8218e2b4
	if (cr6.getEQ()) goto loc_8218E2B4;
	// addic. r11,r29,872
	xer.ca = r29.u32 > 4294966423;
	r11.s64 = r29.s64 + 872;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218e2b4
	if (cr0.getEQ()) goto loc_8218E2B4;
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8218e2b4
	if (cr0.getEQ()) goto loc_8218E2B4;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// ld r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U64(r30.u32 + 0);
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// andc r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r9.u64;
	// std r10,0(r30)
	PPC_STORE_U64(r30.u32 + 0, ctx.r10.u64);
	// ld r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U64(r11.u32 + 8);
	// cmpldi cr6,r10,0
	cr6.compare<uint64_t>(ctx.r10.u64, 0, xer);
	// beq cr6,0x8218e1e8
	if (cr6.getEQ()) goto loc_8218E1E8;
	// li r12,1
	r12.s64 = 1;
	// ld r10,32(r30)
	ctx.r10.u64 = PPC_LOAD_U64(r30.u32 + 32);
	// rldicr r12,r12,56,63
	r12.u64 = __builtin_rotateleft64(r12.u64, 56) & 0xFFFFFFFFFFFFFFFF;
	// or r10,r10,r12
	ctx.r10.u64 = ctx.r10.u64 | r12.u64;
	// std r10,32(r30)
	PPC_STORE_U64(r30.u32 + 32, ctx.r10.u64);
loc_8218E1E8:
	// addi r31,r11,20
	r31.s64 = r11.s64 + 20;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// addi r28,r30,1152
	r28.s64 = r30.s64 + 1152;
	// add r29,r11,r31
	r29.u64 = r11.u64 + r31.u64;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// bge cr6,0x8218e2b4
	if (!cr6.getLT()) goto loc_8218E2B4;
loc_8218E200:
	// lhz r11,2(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 2);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8218e21c
	if (cr0.getEQ()) goto loc_8218E21C;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// blt cr6,0x8218e200
	if (cr6.getLT()) goto loc_8218E200;
loc_8218E21C:
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// bge cr6,0x8218e2b4
	if (!cr6.getLT()) goto loc_8218E2B4;
loc_8218E224:
	// lhz r11,2(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 2);
	// lhz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 0);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8218e2ac
	if (cr0.getEQ()) goto loc_8218E2AC;
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// clrlwi r11,r10,16
	r11.u64 = ctx.r10.u32 & 0xFFFF;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// add r3,r11,r28
	ctx.r3.u64 = r11.u64 + r28.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// add r31,r30,r31
	r31.u64 = r30.u64 + r31.u64;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// blt cr6,0x8218e224
	if (cr6.getLT()) goto loc_8218E224;
	// b 0x8218e2ac
	goto loc_8218E2AC;
loc_8218E260:
	// lhz r10,2(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 2);
	// lhz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U16(r31.u32 + 0);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8218e2b4
	if (cr0.getEQ()) goto loc_8218E2B4;
	// clrlwi r11,r9,16
	r11.u64 = ctx.r9.u32 & 0xFFFF;
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
loc_8218E27C:
	// addis r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 65536;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// lwz r7,4(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// and r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 & ctx.r8.u64;
	// addi r31,r31,8
	r31.s64 = r31.s64 + 8;
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// clrlwi. r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218e27c
	if (!cr0.getEQ()) goto loc_8218E27C;
loc_8218E2AC:
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// blt cr6,0x8218e260
	if (cr6.getLT()) goto loc_8218E260;
loc_8218E2B4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_8218E2C0"))) PPC_WEAK_FUNC(sub_8218E2C0);
PPC_FUNC_IMPL(__imp__sub_8218E2C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// stw r4,11812(r3)
	PPC_STORE_U32(ctx.r3.u32 + 11812, ctx.r4.u32);
	// ld r11,16(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// oris r11,r11,8
	r11.u64 = r11.u64 | 524288;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218E2D8"))) PPC_WEAK_FUNC(sub_8218E2D8);
PPC_FUNC_IMPL(__imp__sub_8218E2D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r27,0
	r27.s64 = 0;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// mr r30,r27
	r30.u64 = r27.u64;
	// std r27,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r27.u64);
	// mr r28,r27
	r28.u64 = r27.u64;
	// lhz r11,0(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 0);
	// std r27,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r27.u64);
	// b 0x8218e330
	goto loc_8218E330;
loc_8218E30C:
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// bgt cr6,0x8218e318
	if (cr6.getGT()) goto loc_8218E318;
	// mr r28,r11
	r28.u64 = r11.u64;
loc_8218E318:
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// li r8,255
	ctx.r8.s64 = 255;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// stbx r8,r11,r9
	PPC_STORE_U8(r11.u32 + ctx.r9.u32, ctx.r8.u8);
	// lhz r11,0(r10)
	r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
loc_8218E330:
	// cmplwi cr6,r11,255
	cr6.compare<uint32_t>(r11.u32, 255, xer);
	// bne cr6,0x8218e30c
	if (!cr6.getEQ()) goto loc_8218E30C;
	// mulli r11,r30,12
	r11.s64 = r30.s64 * 12;
	// addi r5,r11,56
	ctx.r5.s64 = r11.s64 + 56;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// lis r11,16
	r11.s64 = 1048576;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r30,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r30.u32);
	// ori r11,r11,5
	r11.u64 = r11.u64 | 5;
	// stw r28,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r28.u32);
	// lis r9,-1
	ctx.r9.s64 = -65536;
	// stw r27,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r27.u32);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// ld r11,80(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// stw r9,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r9.u32);
	// std r11,32(r31)
	PPC_STORE_U64(r31.u32 + 32, r11.u64);
	// ld r11,88(r1)
	r11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// std r11,40(r31)
	PPC_STORE_U64(r31.u32 + 40, r11.u64);
	// beq cr6,0x8218e3bc
	if (cr6.getEQ()) goto loc_8218E3BC;
	// mr r11,r29
	r11.u64 = r29.u64;
	// addi r10,r31,52
	ctx.r10.s64 = r31.s64 + 52;
loc_8218E394:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r9,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r9.u32);
	// lwz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// stw r9,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, ctx.r9.u32);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// bne 0x8218e394
	if (!cr0.getEQ()) goto loc_8218E394;
loc_8218E3BC:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_8218E3C8"))) PPC_WEAK_FUNC(sub_8218E3C8);
PPC_FUNC_IMPL(__imp__sub_8218E3C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// lhz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U16(r30.u32 + 0);
	// b 0x8218e3fc
	goto loc_8218E3FC;
loc_8218E3F0:
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lhz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r10.u32 + 0);
loc_8218E3FC:
	// cmplwi cr6,r9,255
	cr6.compare<uint32_t>(ctx.r9.u32, 255, xer);
	// bne cr6,0x8218e3f0
	if (!cr6.getEQ()) goto loc_8218E3F0;
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// addi r3,r11,56
	ctx.r3.s64 = r11.s64 + 56;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// bl 0x8209d000
	sub_8209D000(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x8218e424
	if (!cr0.getEQ()) goto loc_8218E424;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8218e434
	goto loc_8218E434;
loc_8218E424:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8218e2d8
	sub_8218E2D8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_8218E434:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218E450"))) PPC_WEAK_FUNC(sub_8218E450);
PPC_FUNC_IMPL(__imp__sub_8218E450) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8218e47c
	if (!cr6.getEQ()) goto loc_8218E47C;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// bne cr6,0x8218e47c
	if (!cr6.getEQ()) goto loc_8218E47C;
	// li r30,64
	r30.s64 = 64;
	// li r6,64
	ctx.r6.s64 = 64;
loc_8218E47C:
	// clrlwi. r11,r4,31
	r11.u64 = ctx.r4.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218e48c
	if (cr0.getEQ()) goto loc_8218E48C;
	// li r11,0
	r11.s64 = 0;
	// b 0x8218e49c
	goto loc_8218E49C;
loc_8218E48C:
	// lwz r11,10920(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 10920);
	// rlwimi r6,r30,8,17,23
	ctx.r6.u64 = (__builtin_rotateleft32(r30.u32, 8) & 0x7F00) | (ctx.r6.u64 & 0xFFFFFFFFFFFF80FF);
	// rlwimi r11,r6,4,21,27
	r11.u64 = (__builtin_rotateleft32(ctx.r6.u32, 4) & 0x7F0) | (r11.u64 & 0xFFFFFFFFFFFFF80F);
	// rlwimi r11,r6,4,13,19
	r11.u64 = (__builtin_rotateleft32(ctx.r6.u32, 4) & 0x7F000) | (r11.u64 & 0xFFFFFFFFFFF80FFF);
loc_8218E49C:
	// stw r11,10920(r31)
	PPC_STORE_U32(r31.u32 + 10920, r11.u32);
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lwz r11,12708(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12708);
	// lwz r9,56(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// and r29,r11,r4
	r29.u64 = r11.u64 & ctx.r4.u64;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// ble cr6,0x8218e4c4
	if (!cr6.getGT()) goto loc_8218E4C4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8219d6d8
	sub_8219D6D8(ctx, base);
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
loc_8218E4C4:
	// oris r11,r29,49153
	r11.u64 = r29.u64 | 3221291008;
	// rlwinm r9,r30,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 3) & 0xFFFFFFF8;
	// ori r11,r11,16128
	r11.u64 = r11.u64 | 16128;
	// add r7,r9,r31
	ctx.r7.u64 = ctx.r9.u64 + r31.u64;
	// addi r8,r30,1722
	ctx.r8.s64 = r30.s64 + 1722;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r8,r8,3,0,28
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 3) & 0xFFFFFFF8;
	// stwu r11,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, r11.u32);
	ctx.r10.u32 = ea;
	// lwz r9,13772(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 13772);
	// stwu r9,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r10.u32 = ea;
	// lwz r9,13768(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 13768);
	// clrlwi r9,r9,8
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFFFF;
	// stwu r9,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r10.u32 = ea;
	// stwu r11,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, r11.u32);
	ctx.r10.u32 = ea;
	// lwz r9,13780(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 13780);
	// stwu r9,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r10.u32 = ea;
	// lwzx r9,r8,r31
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + r31.u32);
	// clrlwi r9,r9,8
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFFFF;
	// stwu r9,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	ctx.r10.u32 = ea;
	// stwu r11,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, r11.u32);
	ctx.r10.u32 = ea;
	// lwz r11,14804(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 14804);
	// stwu r11,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, r11.u32);
	ctx.r10.u32 = ea;
	// lwz r11,14800(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 14800);
	// clrlwi r11,r11,8
	r11.u64 = r11.u32 & 0xFFFFFF;
	// stwu r11,4(r10)
	ea = 4 + ctx.r10.u32;
	PPC_STORE_U32(ea, r11.u32);
	ctx.r10.u32 = ea;
	// stw r10,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r10.u32);
	// bl 0x8218d7b0
	sub_8218D7B0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_8218E538"))) PPC_WEAK_FUNC(sub_8218E538);
PPC_FUNC_IMPL(__imp__sub_8218E538) {
	PPC_FUNC_PROLOGUE();
	// b 0x8235e790
	sub_8235E790(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218E540"))) PPC_WEAK_FUNC(sub_8218E540);
PPC_FUNC_IMPL(__imp__sub_8218E540) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// b 0x8235e790
	sub_8235E790(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218E550"))) PPC_WEAK_FUNC(sub_8218E550);
PPC_FUNC_IMPL(__imp__sub_8218E550) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// clrlwi. r29,r4,24
	r29.u64 = ctx.r4.u32 & 0xFF;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// bne 0x8218e580
	if (!cr0.getEQ()) goto loc_8218E580;
	// lis r11,-32231
	r11.s64 = -2112290816;
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r6,r11,-15160
	ctx.r6.s64 = r11.s64 + -15160;
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// bl 0x823ef960
	sub_823EF960(ctx, base);
loc_8218E580:
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r10,-1
	ctx.r10.s64 = -1;
	// li r30,0
	r30.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// std r10,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r10.u64);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// std r10,8(r11)
	PPC_STORE_U64(r11.u32 + 8, ctx.r10.u64);
	// li r3,1
	ctx.r3.s64 = 1;
	// ble cr6,0x8218e624
	if (!cr6.getGT()) goto loc_8218E624;
	// addi r7,r31,4
	ctx.r7.s64 = r31.s64 + 4;
loc_8218E5B4:
	// lwz r9,0(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// rlwinm r11,r9,12,28,31
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 12) & 0xF;
	// lbzx r10,r11,r8
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + ctx.r8.u32);
	// cmplwi cr6,r10,255
	cr6.compare<uint32_t>(ctx.r10.u32, 255, xer);
	// bne cr6,0x8218e608
	if (!cr6.getEQ()) goto loc_8218E608;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8218e5dc
	if (cr6.getEQ()) goto loc_8218E5DC;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// b 0x8218e5e4
	goto loc_8218E5E4;
loc_8218E5DC:
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
loc_8218E5E4:
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// stbx r10,r11,r8
	PPC_STORE_U8(r11.u32 + ctx.r8.u32, ctx.r10.u8);
	// bge cr6,0x8218e5f8
	if (!cr6.getLT()) goto loc_8218E5F8;
	// slw r11,r3,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r3.u32 << (r11.u8 & 0x3F));
	// or r4,r11,r4
	ctx.r4.u64 = r11.u64 | ctx.r4.u64;
loc_8218E5F8:
	// cmplwi cr6,r10,16
	cr6.compare<uint32_t>(ctx.r10.u32, 16, xer);
	// bge cr6,0x8218e608
	if (!cr6.getLT()) goto loc_8218E608;
	// slw r11,r3,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r3.u32 << (ctx.r10.u8 & 0x3F));
	// or r5,r11,r5
	ctx.r5.u64 = r11.u64 | ctx.r5.u64;
loc_8218E608:
	// rlwimi r9,r10,16,12,15
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xF0000) | (ctx.r9.u64 & 0xFFFFFFFFFFF0FFFF);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// stw r9,0(r7)
	PPC_STORE_U32(ctx.r7.u32 + 0, ctx.r9.u32);
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplw cr6,r6,r11
	cr6.compare<uint32_t>(ctx.r6.u32, r11.u32, xer);
	// blt cr6,0x8218e5b4
	if (cr6.getLT()) goto loc_8218E5B4;
loc_8218E624:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x8218e638
	if (!cr6.getEQ()) goto loc_8218E638;
	// cmplw cr6,r4,r5
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r5.u32, xer);
	// beq cr6,0x8218e638
	if (cr6.getEQ()) goto loc_8218E638;
	// li r3,0
	ctx.r3.s64 = 0;
loc_8218E638:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_8218E640"))) PPC_WEAK_FUNC(sub_8218E640);
PPC_FUNC_IMPL(__imp__sub_8218E640) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r11,0
	r11.s64 = 0;
	// li r5,9120
	ctx.r5.s64 = 9120;
	// stw r4,9572(r31)
	PPC_STORE_U32(r31.u32 + 9572, ctx.r4.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,9568(r31)
	PPC_STORE_U32(r31.u32 + 9568, r11.u32);
	// std r11,9120(r31)
	PPC_STORE_U64(r31.u32 + 9120, r11.u64);
	// std r11,9128(r31)
	PPC_STORE_U64(r31.u32 + 9128, r11.u64);
	// std r11,9136(r31)
	PPC_STORE_U64(r31.u32 + 9136, r11.u64);
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,288
	ctx.r5.s64 = 288;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,9208
	ctx.r3.s64 = r31.s64 + 9208;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,9496
	ctx.r3.s64 = r31.s64 + 9496;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,9528
	ctx.r3.s64 = r31.s64 + 9528;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,64
	ctx.r5.s64 = 64;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,9144
	ctx.r3.s64 = r31.s64 + 9144;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218E6D0"))) PPC_WEAK_FUNC(sub_8218E6D0);
PPC_FUNC_IMPL(__imp__sub_8218E6D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// li r11,0
	r11.s64 = 0;
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r11,9564(r3)
	PPC_STORE_U32(ctx.r3.u32 + 9564, r11.u32);
	// beq cr6,0x8218e700
	if (cr6.getEQ()) goto loc_8218E700;
	// clrlwi r8,r4,27
	ctx.r8.u64 = ctx.r4.u32 & 0x1F;
	// addi r11,r3,9496
	r11.s64 = ctx.r3.s64 + 9496;
	// rlwinm r10,r4,29,3,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r7,r10,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// slw r8,r9,r8
	ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r8.u8 & 0x3F));
	// or r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 | ctx.r7.u64;
	// stwx r8,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r8.u32);
loc_8218E700:
	// rlwinm r11,r4,27,5,31
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// clrlwi r8,r4,27
	ctx.r8.u64 = ctx.r4.u32 & 0x1F;
	// subfic r7,r11,31
	xer.ca = r11.u32 <= 31;
	ctx.r7.s64 = 31 - r11.s64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// clrldi r7,r7,32
	ctx.r7.u64 = ctx.r7.u64 & 0xFFFFFFFF;
	// addi r10,r3,9528
	ctx.r10.s64 = ctx.r3.s64 + 9528;
	// slw r8,r9,r8
	ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r8.u8 & 0x3F));
	// sld r9,r9,r7
	ctx.r9.u64 = ctx.r7.u8 & 0x40 ? 0 : (ctx.r9.u64 << (ctx.r7.u8 & 0x7F));
	// lwzx r7,r11,r10
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// or r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 | ctx.r7.u64;
	// stwx r8,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r8.u32);
	// ld r11,9128(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 9128);
	// or r11,r9,r11
	r11.u64 = ctx.r9.u64 | r11.u64;
	// std r11,9128(r3)
	PPC_STORE_U64(ctx.r3.u32 + 9128, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218E740"))) PPC_WEAK_FUNC(sub_8218E740);
PPC_FUNC_IMPL(__imp__sub_8218E740) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister r11{};
	// rlwinm r11,r4,30,2,31
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 30) & 0x3FFFFFFF;
	// ld r9,9120(r3)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r3.u32 + 9120);
	// li r7,1
	ctx.r7.s64 = 1;
	// lwz r8,9572(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 9572);
	// subfic r11,r11,63
	xer.ca = r11.u32 <= 63;
	r11.s64 = 63 - r11.s64;
	// li r6,0
	ctx.r6.s64 = 0;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// addi r10,r3,9144
	ctx.r10.s64 = ctx.r3.s64 + 9144;
	// stw r6,9564(r3)
	PPC_STORE_U32(ctx.r3.u32 + 9564, ctx.r6.u32);
	// sld r11,r7,r11
	r11.u64 = r11.u8 & 0x40 ? 0 : (ctx.r7.u64 << (r11.u8 & 0x7F));
	// or r11,r11,r9
	r11.u64 = r11.u64 | ctx.r9.u64;
	// std r11,9120(r3)
	PPC_STORE_U64(ctx.r3.u32 + 9120, r11.u64);
	// lwz r11,19892(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 19892);
	// lwz r6,0(r5)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// rlwinm r11,r11,6,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0x100;
	// add r11,r11,r4
	r11.u64 = r11.u64 + ctx.r4.u64;
	// addi r8,r11,48
	ctx.r8.s64 = r11.s64 + 48;
	// clrlwi r4,r11,27
	ctx.r4.u64 = r11.u32 & 0x1F;
	// rlwinm r8,r8,4,0,27
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 4) & 0xFFFFFFF0;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// add r11,r8,r3
	r11.u64 = ctx.r8.u64 + ctx.r3.u64;
	// rlwinm r9,r9,29,3,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x1FFFFFFC;
	// stw r6,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r6.u32);
	// slw r8,r7,r4
	ctx.r8.u64 = ctx.r4.u8 & 0x20 ? 0 : (ctx.r7.u32 << (ctx.r4.u8 & 0x3F));
	// lwz r7,4(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// stw r7,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r7.u32);
	// lwz r7,8(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// lwz r7,12(r5)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r5.u32 + 12);
	// stw r7,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r7.u32);
	// lwzx r11,r9,r10
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// or r11,r8,r11
	r11.u64 = ctx.r8.u64 | r11.u64;
	// stwx r11,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218E7C8"))) PPC_WEAK_FUNC(sub_8218E7C8);
PPC_FUNC_IMPL(__imp__sub_8218E7C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// clrlwi r9,r4,27
	ctx.r9.u64 = ctx.r4.u32 & 0x1F;
	// li r8,1
	ctx.r8.s64 = 1;
	// rlwinm r10,r4,27,5,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 27) & 0x7FFFFFF;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r10,r10,2286
	ctx.r10.s64 = ctx.r10.s64 + 2286;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// slw r9,r8,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r9.u8 & 0x3F));
	// and r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 & ctx.r10.u64;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r3,r10,1
	ctx.r3.u64 = ctx.r10.u64 ^ 1;
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beqlr 
	if (cr0.getEQ()) return;
	// addi r10,r4,48
	ctx.r10.s64 = ctx.r4.s64 + 48;
	// rlwinm r10,r10,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r10,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// stw r10,4(r5)
	PPC_STORE_U32(ctx.r5.u32 + 4, ctx.r10.u32);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r10,8(r5)
	PPC_STORE_U32(ctx.r5.u32 + 8, ctx.r10.u32);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// stw r11,12(r5)
	PPC_STORE_U32(ctx.r5.u32 + 12, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218E830"))) PPC_WEAK_FUNC(sub_8218E830);
PPC_FUNC_IMPL(__imp__sub_8218E830) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lwz r3,108(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// lwz r10,112(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// rotlwi r9,r3,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r3,r10
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r10.u32, xer);
	// bge cr6,0x8218e8b0
	if (!cr6.getLT()) goto loc_8218E8B0;
	// lwz r9,112(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 112);
	// rotlwi r10,r3,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r3.u32, 0);
	// rlwinm r11,r9,3,0,28
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// add r9,r11,r10
	ctx.r9.u64 = r11.u64 + ctx.r10.u64;
loc_8218E860:
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r10,1
	ctx.r10.s64 = 1;
	// rlwinm r8,r11,20,28,31
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
	// slw r10,r10,r8
	ctx.r10.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r8.u8 & 0x3F));
	// andi. r10,r10,24702
	ctx.r10.u64 = ctx.r10.u64 & 24702;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8218e8a4
	if (cr0.getEQ()) goto loc_8218E8A4;
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8218e8a4
	if (!cr0.getEQ()) goto loc_8218E8A4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// clrlwi r10,r11,20
	ctx.r10.u64 = r11.u32 & 0xFFF;
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// bgt cr6,0x8218e8a4
	if (cr6.getGT()) goto loc_8218E8A4;
	// rlwinm r11,r11,20,29,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0x7;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// bltlr cr6
	if (cr6.getLT()) return;
loc_8218E8A4:
	// addi r3,r3,8
	ctx.r3.s64 = ctx.r3.s64 + 8;
	// cmplw cr6,r3,r9
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, xer);
	// blt cr6,0x8218e860
	if (cr6.getLT()) goto loc_8218E860;
loc_8218E8B0:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218E8B8"))) PPC_WEAK_FUNC(sub_8218E8B8);
PPC_FUNC_IMPL(__imp__sub_8218E8B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// bl 0x8218e830
	sub_8218E830(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8218e9a0
	if (cr0.getEQ()) goto loc_8218E9A0;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// clrlwi r9,r11,20
	ctx.r9.u64 = r11.u32 & 0xFFF;
	// subf r9,r9,r30
	ctx.r9.s64 = r30.s64 - ctx.r9.s64;
	// rlwinm r9,r9,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// slw r10,r10,r9
	ctx.r10.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r9.u8 & 0x3F));
	// beq cr6,0x8218e910
	if (cr6.getEQ()) goto loc_8218E910;
	// rlwinm r10,r10,16,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF0000;
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | r11.u64;
	// rlwimi r10,r11,0,16,3
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFFFF000FFFF) | (ctx.r10.u64 & 0xFFF0000);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// b 0x8218e928
	goto loc_8218E928;
loc_8218E910:
	// lis r9,-4096
	ctx.r9.s64 = -268435456;
	// not r10,r10
	ctx.r10.u64 = ~ctx.r10.u64;
	// ori r9,r9,65535
	ctx.r9.u64 = ctx.r9.u64 | 65535;
	// rlwimi r9,r10,16,4,15
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r10.u32, 16) & 0xFFF0000) | (ctx.r9.u64 & 0xFFFFFFFFF000FFFF);
	// and r11,r9,r11
	r11.u64 = ctx.r9.u64 & r11.u64;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
loc_8218E928:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm. r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218e9a0
	if (cr0.getEQ()) goto loc_8218E9A0;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x8218e9a0
	if (cr6.getEQ()) goto loc_8218E9A0;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bne cr6,0x8218e9a0
	if (!cr6.getEQ()) goto loc_8218E9A0;
	// li r11,0
	r11.s64 = 0;
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,128
	ctx.r3.s64 = r31.s64 + 128;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stb r11,124(r31)
	PPC_STORE_U8(r31.u32 + 124, r11.u8);
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,160
	ctx.r3.s64 = r31.s64 + 160;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,192
	ctx.r3.s64 = r31.s64 + 192;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,224
	ctx.r3.s64 = r31.s64 + 224;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
loc_8218E9A0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_8218E9A8"))) PPC_WEAK_FUNC(sub_8218E9A8);
PPC_FUNC_IMPL(__imp__sub_8218E9A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,80(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x8218e9bc
	if (!cr6.getLT()) goto loc_8218E9BC;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_8218E9BC:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x8218ea74
	if (cr6.getEQ()) goto loc_8218EA74;
	// lwz r11,108(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 108);
	// lwz r10,112(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	// rotlwi r9,r11,0
	ctx.r9.u64 = __builtin_rotateleft32(r11.u32, 0);
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x8218ea74
	if (!cr6.getLT()) goto loc_8218EA74;
	// lwz r10,112(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	// rotlwi r9,r11,0
	ctx.r9.u64 = __builtin_rotateleft32(r11.u32, 0);
	// li r8,1
	ctx.r8.s64 = 1;
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r7,r10,r9
	ctx.r7.u64 = ctx.r10.u64 + ctx.r9.u64;
loc_8218E9F4:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r10,20,28,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0xF;
	// slw r9,r8,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r9.u8 & 0x3F));
	// andi. r9,r9,24702
	ctx.r9.u64 = ctx.r9.u64 & 24702;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x8218ea34
	if (cr0.getEQ()) goto loc_8218EA34;
	// rlwinm. r10,r10,0,20,20
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218ea34
	if (!cr0.getEQ()) goto loc_8218EA34;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r9,r10,20
	ctx.r9.u64 = ctx.r10.u32 & 0xFFF;
	// cmplw cr6,r9,r4
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r4.u32, xer);
	// bgt cr6,0x8218ea34
	if (cr6.getGT()) goto loc_8218EA34;
	// rlwinm r10,r10,20,29,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0x7;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// blt cr6,0x8218ea44
	if (cr6.getLT()) goto loc_8218EA44;
loc_8218EA34:
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// blt cr6,0x8218e9f4
	if (cr6.getLT()) goto loc_8218E9F4;
	// b 0x8218ea74
	goto loc_8218EA74;
loc_8218EA44:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r10,r11,20
	ctx.r10.u64 = r11.u32 & 0xFFF;
	// rlwinm r11,r11,16,16,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF;
	// subf r10,r10,r4
	ctx.r10.s64 = ctx.r4.s64 - ctx.r10.s64;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// slw r10,r8,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r10.u8 & 0x3F));
	// and r11,r10,r11
	r11.u64 = ctx.r10.u64 & r11.u64;
	// clrlwi r11,r11,20
	r11.u64 = r11.u32 & 0xFFF;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// stw r11,0(r5)
	PPC_STORE_U32(ctx.r5.u32 + 0, r11.u32);
loc_8218EA74:
	// lwz r11,96(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 96);
	// mulli r10,r4,12
	ctx.r10.s64 = ctx.r4.s64 * 12;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218EA88"))) PPC_WEAK_FUNC(sub_8218EA88);
PPC_FUNC_IMPL(__imp__sub_8218EA88) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,112(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 112);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8218eae4
	if (cr0.getEQ()) goto loc_8218EAE4;
	// lwz r10,80(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 80);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bge cr6,0x8218eaa8
	if (!cr6.getLT()) goto loc_8218EAA8;
	// li r11,0
	r11.s64 = 0;
	// b 0x8218eab8
	goto loc_8218EAB8;
loc_8218EAA8:
	// lwz r10,108(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 108);
	// rlwinm r11,r11,3,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r11,r11,-8
	r11.s64 = r11.s64 + -8;
loc_8218EAB8:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm. r10,r10,20,28,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0xF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8218eae4
	if (cr0.getEQ()) goto loc_8218EAE4;
	// cmplwi cr6,r10,6
	cr6.compare<uint32_t>(ctx.r10.u32, 6, xer);
	// ble cr6,0x8218ead8
	if (!cr6.getGT()) goto loc_8218EAD8;
	// addi r10,r10,-13
	ctx.r10.s64 = ctx.r10.s64 + -13;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bgt cr6,0x8218eae4
	if (cr6.getGT()) goto loc_8218EAE4;
loc_8218EAD8:
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r3,r11,20,29,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0x7;
	// blr 
	return;
loc_8218EAE4:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218EAF0"))) PPC_WEAK_FUNC(sub_8218EAF0);
PPC_FUNC_IMPL(__imp__sub_8218EAF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218ebb4
	if (cr0.getEQ()) goto loc_8218EBB4;
	// lwz r10,4(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// rlwinm r9,r10,20,28,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0xF;
	// addi r9,r9,-3
	ctx.r9.s64 = ctx.r9.s64 + -3;
	// cmplwi cr6,r9,11
	cr6.compare<uint32_t>(ctx.r9.u32, 11, xer);
	// bgt cr6,0x8218ebac
	if (cr6.getGT()) goto loc_8218EBAC;
	// lis r12,-32254
	r12.s64 = -2113798144;
	// addi r12,r12,-19024
	r12.s64 = r12.s64 + -19024;
	// lbzx r0,r12,r9
	r0.u64 = PPC_LOAD_U8(r12.u32 + ctx.r9.u32);
	// lis r12,-32231
	r12.s64 = -2112290816;
	// addi r12,r12,-5316
	r12.s64 = r12.s64 + -5316;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// nop 
	// bctr 
	switch (ctx.r9.u64) {
	case 0:
		goto loc_8218EB3C;
	case 1:
		goto loc_8218EB3C;
	case 2:
		goto loc_8218EBAC;
	case 3:
		goto loc_8218EBAC;
	case 4:
		goto loc_8218EB60;
	case 5:
		goto loc_8218EB60;
	case 6:
		goto loc_8218EB80;
	case 7:
		goto loc_8218EBAC;
	case 8:
		goto loc_8218EB80;
	case 9:
		goto loc_8218EB98;
	case 10:
		goto loc_8218EB3C;
	case 11:
		goto loc_8218EB3C;
	default:
		__builtin_unreachable();
	}
loc_8218EB3C:
	// rlwinm r10,r10,24,30,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0x3;
	// li r9,1
	ctx.r9.s64 = 1;
	// subfic r10,r10,3
	xer.ca = ctx.r10.u32 <= 3;
	ctx.r10.s64 = 3 - ctx.r10.s64;
	// slw r10,r9,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r10.u8 & 0x3F));
	// rlwinm r10,r10,16,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF0000;
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | r11.u64;
	// rlwimi r10,r11,0,16,11
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFFFFFF0FFFF) | (ctx.r10.u64 & 0xF0000);
loc_8218EB58:
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// b 0x8218ebac
	goto loc_8218EBAC;
loc_8218EB60:
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r10,r10,15,28,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 15) & 0xF;
	// subfic r10,r10,15
	xer.ca = ctx.r10.u32 <= 15;
	ctx.r10.s64 = 15 - ctx.r10.s64;
	// slw r10,r9,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r10.u8 & 0x3F));
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | r11.u64;
	// rlwimi r10,r11,0,0,15
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFF0000) | (ctx.r10.u64 & 0xFFFFFFFF0000FFFF);
	// b 0x8218eb58
	goto loc_8218EB58;
loc_8218EB80:
	// lwz r9,0(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// rlwinm. r7,r9,0,18,18
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x2000;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x8218ebac
	if (!cr0.getEQ()) goto loc_8218EBAC;
	// rlwinm. r9,r9,0,17,17
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x4000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x8218ebac
	if (!cr0.getEQ()) goto loc_8218EBAC;
	// b 0x8218eb3c
	goto loc_8218EB3C;
loc_8218EB98:
	// rlwinm r10,r10,0,21,22
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x600;
	// cmplwi cr6,r10,1536
	cr6.compare<uint32_t>(ctx.r10.u32, 1536, xer);
	// bne cr6,0x8218ebac
	if (!cr6.getEQ()) goto loc_8218EBAC;
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r10,24(r8)
	PPC_STORE_U32(ctx.r8.u32 + 24, ctx.r10.u32);
loc_8218EBAC:
	// stw r11,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r11.u32);
	// b 0x8218ed54
	goto loc_8218ED54;
loc_8218EBB4:
	// lwz r11,12(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	// li r3,1
	ctx.r3.s64 = 1;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8218ebf4
	if (!cr6.getEQ()) goto loc_8218EBF4;
	// clrlwi. r11,r4,24
	r11.u64 = ctx.r4.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r3,12(r8)
	PPC_STORE_U32(ctx.r8.u32 + 12, ctx.r3.u32);
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r10,27,31,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// stw r11,16(r8)
	PPC_STORE_U32(ctx.r8.u32 + 16, r11.u32);
	// beq 0x8218ebec
	if (cr0.getEQ()) goto loc_8218EBEC;
	// clrlwi. r11,r5,24
	r11.u64 = ctx.r5.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// beq 0x8218ebf0
	if (cr0.getEQ()) goto loc_8218EBF0;
loc_8218EBEC:
	// li r11,0
	r11.s64 = 0;
loc_8218EBF0:
	// stw r11,20(r8)
	PPC_STORE_U32(ctx.r8.u32 + 20, r11.u32);
loc_8218EBF4:
	// lwz r11,4(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// clrlwi. r10,r4,24
	ctx.r10.u64 = ctx.r4.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8218ec28
	if (cr0.getEQ()) goto loc_8218EC28;
	// lwz r10,0(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// clrlwi. r9,r10,27
	ctx.r9.u64 = ctx.r10.u32 & 0x1F;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// rlwinm r9,r10,20,26,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0x3F;
	// beq cr6,0x8218ec1c
	if (cr6.getEQ()) goto loc_8218EC1C;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bge cr6,0x8218ec20
	if (!cr6.getLT()) goto loc_8218EC20;
loc_8218EC1C:
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_8218EC20:
	// rlwinm r10,r10,27,26,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x3F;
	// b 0x8218ed3c
	goto loc_8218ED3C;
loc_8218EC28:
	// lwz r9,8(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// lis r10,-32019
	ctx.r10.s64 = -2098397184;
	// lwz r5,0(r7)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// addi r10,r10,27348
	ctx.r10.s64 = ctx.r10.s64 + 27348;
	// rlwinm r6,r9,8,27,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0x1F;
	// addi r4,r10,32
	ctx.r4.s64 = ctx.r10.s64 + 32;
	// rlwinm r31,r5,6,26,31
	r31.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 6) & 0x3F;
	// lbzx r6,r6,r10
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r6.u32 + ctx.r10.u32);
	// lbzx r4,r31,r4
	ctx.r4.u64 = PPC_LOAD_U8(r31.u32 + ctx.r4.u32);
	// cmplwi cr6,r6,1
	cr6.compare<uint32_t>(ctx.r6.u32, 1, xer);
	// blt cr6,0x8218ec78
	if (cr6.getLT()) goto loc_8218EC78;
	// rlwinm. r10,r9,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8218ec78
	if (cr0.getEQ()) goto loc_8218EC78;
	// lbz r10,9(r7)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r7.u32 + 9);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// clrlwi r10,r10,26
	ctx.r10.u64 = ctx.r10.u32 & 0x3F;
	// beq cr6,0x8218ec74
	if (cr6.getEQ()) goto loc_8218EC74;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x8218ec78
	if (!cr6.getLT()) goto loc_8218EC78;
loc_8218EC74:
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8218EC78:
	// cmplwi cr6,r6,2
	cr6.compare<uint32_t>(ctx.r6.u32, 2, xer);
	// blt cr6,0x8218eca4
	if (cr6.getLT()) goto loc_8218ECA4;
	// rlwinm. r10,r9,0,1,1
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8218eca4
	if (cr0.getEQ()) goto loc_8218ECA4;
	// lbz r10,10(r7)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r7.u32 + 10);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// clrlwi r10,r10,26
	ctx.r10.u64 = ctx.r10.u32 & 0x3F;
	// beq cr6,0x8218eca0
	if (cr6.getEQ()) goto loc_8218ECA0;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x8218eca4
	if (!cr6.getLT()) goto loc_8218ECA4;
loc_8218ECA0:
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8218ECA4:
	// cmplwi cr6,r6,3
	cr6.compare<uint32_t>(ctx.r6.u32, 3, xer);
	// bge cr6,0x8218ecb4
	if (!cr6.getLT()) goto loc_8218ECB4;
	// cmplwi cr6,r4,1
	cr6.compare<uint32_t>(ctx.r4.u32, 1, xer);
	// bne cr6,0x8218ecd4
	if (!cr6.getEQ()) goto loc_8218ECD4;
loc_8218ECB4:
	// rlwinm. r10,r9,0,2,2
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8218ecd4
	if (cr0.getEQ()) goto loc_8218ECD4;
	// clrlwi r10,r9,26
	ctx.r10.u64 = ctx.r9.u32 & 0x3F;
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8218ecd0
	if (cr6.getEQ()) goto loc_8218ECD0;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x8218ecd4
	if (!cr6.getLT()) goto loc_8218ECD4;
loc_8218ECD0:
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8218ECD4:
	// cmplwi cr6,r4,2
	cr6.compare<uint32_t>(ctx.r4.u32, 2, xer);
	// bne cr6,0x8218ed04
	if (!cr6.getEQ()) goto loc_8218ED04;
	// mr r10,r5
	ctx.r10.u64 = ctx.r5.u64;
	// lwz r7,4(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// rlwimi r10,r9,30,4,4
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 30) & 0x8000000) | (ctx.r10.u64 & 0xFFFFFFFFF7FFFFFF);
	// rlwimi r7,r10,6,30,31
	ctx.r7.u64 = (__builtin_rotateleft32(ctx.r10.u32, 6) & 0x3) | (ctx.r7.u64 & 0xFFFFFFFFFFFFFFFC);
	// clrlwi r10,r7,26
	ctx.r10.u64 = ctx.r7.u32 & 0x3F;
	// beq cr6,0x8218ed00
	if (cr6.getEQ()) goto loc_8218ED00;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x8218ed04
	if (!cr6.getLT()) goto loc_8218ED04;
loc_8218ED00:
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8218ED04:
	// rlwinm. r10,r5,0,16,16
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// clrlwi r10,r5,26
	ctx.r10.u64 = ctx.r5.u32 & 0x3F;
	// beq 0x8218ed24
	if (cr0.getEQ()) goto loc_8218ED24;
	// addi r10,r10,-32
	ctx.r10.s64 = ctx.r10.s64 + -32;
	// cmplwi cr6,r10,5
	cr6.compare<uint32_t>(ctx.r10.u32, 5, xer);
	// bgt cr6,0x8218ed50
	if (cr6.getGT()) goto loc_8218ED50;
	// stw r3,24(r8)
	PPC_STORE_U32(ctx.r8.u32 + 24, ctx.r3.u32);
	// b 0x8218ed50
	goto loc_8218ED50;
loc_8218ED24:
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8218ed34
	if (cr6.getEQ()) goto loc_8218ED34;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x8218ed38
	if (!cr6.getLT()) goto loc_8218ED38;
loc_8218ED34:
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8218ED38:
	// rlwinm r10,r5,24,26,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 24) & 0x3F;
loc_8218ED3C:
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x8218ed4c
	if (cr6.getEQ()) goto loc_8218ED4C;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x8218ed50
	if (!cr6.getLT()) goto loc_8218ED50;
loc_8218ED4C:
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_8218ED50:
	// stw r11,4(r8)
	PPC_STORE_U32(ctx.r8.u32 + 4, r11.u32);
loc_8218ED54:
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218ED60"))) PPC_WEAK_FUNC(sub_8218ED60);
PPC_FUNC_IMPL(__imp__sub_8218ED60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed120
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// mr r23,r6
	r23.u64 = ctx.r6.u64;
	// mr r22,r7
	r22.u64 = ctx.r7.u64;
	// clrlwi. r11,r4,24
	r11.u64 = ctx.r4.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r27,256(r24)
	r27.u64 = PPC_LOAD_U32(r24.u32 + 256);
	// li r26,12
	r26.s64 = 12;
	// lwz r28,260(r24)
	r28.u64 = PPC_LOAD_U32(r24.u32 + 260);
	// beq 0x8218ee50
	if (cr0.getEQ()) goto loc_8218EE50;
	// subf r11,r27,r28
	r11.s64 = r28.s64 - r27.s64;
	// divw. r29,r11,r26
	r29.s32 = r11.s32 / r26.s32;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x8218ee50
	if (cr0.getEQ()) goto loc_8218EE50;
	// addi r31,r27,8
	r31.s64 = r27.s64 + 8;
	// li r30,0
	r30.s64 = 0;
loc_8218EDA4:
	// lwz r11,-8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -8);
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// li r3,1
	ctx.r3.s64 = 1;
	// lhz r11,-2(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + -2);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lhz r10,-4(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + -4);
	// rlwinm r11,r11,16,0,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF0000;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// lhz r11,0(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 0);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// mtctr r23
	ctr.u64 = r23.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// addi r7,r1,88
	ctx.r7.s64 = ctx.r1.s64 + 88;
	// addi r6,r30,1
	ctx.r6.s64 = r30.s64 + 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,1
	ctx.r3.s64 = 1;
	// mtctr r23
	ctr.u64 = r23.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r30,r30,2
	r30.s64 = r30.s64 + 2;
	// stw r11,-8(r31)
	PPC_STORE_U32(r31.u32 + -8, r11.u32);
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r10,100(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// rlwimi r10,r11,16,0,15
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 16) & 0xFFFF0000) | (ctx.r10.u64 & 0xFFFFFFFF0000FFFF);
	// stw r10,-4(r31)
	PPC_STORE_U32(r31.u32 + -4, ctx.r10.u32);
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// rlwinm r11,r11,16,16,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF;
	// rlwinm r10,r10,16,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF0000;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// addi r31,r31,12
	r31.s64 = r31.s64 + 12;
	// bne 0x8218eda4
	if (!cr0.getEQ()) goto loc_8218EDA4;
loc_8218EE50:
	// clrlwi. r11,r25,24
	r11.u64 = r25.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218ef38
	if (cr0.getEQ()) goto loc_8218EF38;
	// mr r11,r28
	r11.u64 = r28.u64;
	// subf r10,r27,r28
	ctx.r10.s64 = r28.s64 - r27.s64;
	// divw r26,r10,r26
	r26.s32 = ctx.r10.s32 / r26.s32;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
loc_8218EE68:
	// li r10,0
	ctx.r10.s64 = 0;
	// mr r25,r11
	r25.u64 = r11.u64;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// beq cr6,0x8218ef38
	if (cr6.getEQ()) goto loc_8218EF38;
	// addi r31,r27,8
	r31.s64 = r27.s64 + 8;
	// mr r28,r26
	r28.u64 = r26.u64;
loc_8218EE84:
	// lwz r9,-8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + -8);
	// addi r30,r1,112
	r30.s64 = ctx.r1.s64 + 112;
	// lwz r11,-4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -4);
	// li r29,2
	r29.s64 = 2;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r8,r10,16,0,15
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF0000;
	// stw r9,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r9.u32);
	// rlwinm r9,r11,16,16,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
	// or r11,r9,r8
	r11.u64 = ctx.r9.u64 | ctx.r8.u64;
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r11.u32);
	// rlwinm r11,r10,16,16,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF;
	// stw r11,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r11.u32);
loc_8218EEBC:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r10,1
	ctx.r10.s64 = 1;
	// rlwinm r11,r11,20,28,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
	// slw r11,r10,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r10.u32 << (r11.u8 & 0x3F));
	// andi. r11,r11,24702
	r11.u64 = r11.u64 & 24702;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8218eef8
	if (cr0.getEQ()) goto loc_8218EEF8;
	// addi r9,r1,84
	ctx.r9.s64 = ctx.r1.s64 + 84;
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x8218ccb8
	sub_8218CCB8(ctx, base);
loc_8218EEF8:
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r30,r30,8
	r30.s64 = r30.s64 + 8;
	// bne 0x8218eebc
	if (!cr0.getEQ()) goto loc_8218EEBC;
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// addi r31,r31,12
	r31.s64 = r31.s64 + 12;
	// bne 0x8218ee84
	if (!cr0.getEQ()) goto loc_8218EE84;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplw cr6,r25,r11
	cr6.compare<uint32_t>(r25.u32, r11.u32, xer);
	// bne cr6,0x8218ef30
	if (!cr6.getEQ()) goto loc_8218EF30;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x8218ef38
	if (cr6.getEQ()) goto loc_8218EF38;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
loc_8218EF30:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x8218ee68
	if (!cr6.getEQ()) goto loc_8218EE68;
loc_8218EF38:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x823ed170
	return;
}

__attribute__((alias("__imp__sub_8218EF40"))) PPC_WEAK_FUNC(sub_8218EF40);
PPC_FUNC_IMPL(__imp__sub_8218EF40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// cmplwi cr6,r11,19
	cr6.compare<uint32_t>(r11.u32, 19, xer);
	// bgtlr cr6
	if (cr6.getGT()) return;
	// lwz r10,4(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// rlwinm r11,r4,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// clrlwi r9,r10,29
	ctx.r9.u64 = ctx.r10.u32 & 0x7;
	// li r10,1
	ctx.r10.s64 = 1;
	// cmplwi cr6,r9,7
	cr6.compare<uint32_t>(ctx.r9.u32, 7, xer);
	// beq cr6,0x8218ef80
	if (cr6.getEQ()) goto loc_8218EF80;
	// clrlwi r8,r11,27
	ctx.r8.u64 = r11.u32 & 0x1F;
	// rlwinm r9,r11,29,3,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r7,r9,r3
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// slw r8,r10,r8
	ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r8.u8 & 0x3F));
	// or r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 | ctx.r7.u64;
	// stwx r8,r9,r3
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, ctx.r8.u32);
loc_8218EF80:
	// lwz r9,4(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// rlwinm r9,r9,0,26,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x38;
	// cmplwi cr6,r9,56
	cr6.compare<uint32_t>(ctx.r9.u32, 56, xer);
	// beq cr6,0x8218efb0
	if (cr6.getEQ()) goto loc_8218EFB0;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// clrlwi r9,r9,27
	ctx.r9.u64 = ctx.r9.u32 & 0x1F;
	// slw r7,r10,r9
	ctx.r7.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r9.u8 & 0x3F));
	// rlwinm r9,r8,29,3,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r8,r9,r3
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stwx r8,r9,r3
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, ctx.r8.u32);
loc_8218EFB0:
	// lwz r9,4(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// rlwinm r9,r9,0,23,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x1C0;
	// cmplwi cr6,r9,448
	cr6.compare<uint32_t>(ctx.r9.u32, 448, xer);
	// beq cr6,0x8218efe0
	if (cr6.getEQ()) goto loc_8218EFE0;
	// addi r9,r11,2
	ctx.r9.s64 = r11.s64 + 2;
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// clrlwi r9,r9,27
	ctx.r9.u64 = ctx.r9.u32 & 0x1F;
	// slw r7,r10,r9
	ctx.r7.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r9.u8 & 0x3F));
	// rlwinm r9,r8,29,3,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r8,r9,r3
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stwx r8,r9,r3
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, ctx.r8.u32);
loc_8218EFE0:
	// lwz r9,4(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	// rlwinm r9,r9,0,20,22
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xE00;
	// cmplwi cr6,r9,3584
	cr6.compare<uint32_t>(ctx.r9.u32, 3584, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// slw r10,r10,r11
	ctx.r10.u64 = r11.u8 & 0x20 ? 0 : (ctx.r10.u32 << (r11.u8 & 0x3F));
	// rlwinm r11,r9,29,3,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r9,r11,r3
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stwx r10,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218F018"))) PPC_WEAK_FUNC(sub_8218F018);
PPC_FUNC_IMPL(__imp__sub_8218F018) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// clrlwi r10,r11,27
	ctx.r10.u64 = r11.u32 & 0x1F;
	// cmplwi cr6,r10,18
	cr6.compare<uint32_t>(ctx.r10.u32, 18, xer);
	// bgt cr6,0x8218f164
	if (cr6.getGT()) goto loc_8218F164;
	// beq cr6,0x8218f12c
	if (cr6.getEQ()) goto loc_8218F12C;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8218f0ec
	if (cr6.getEQ()) goto loc_8218F0EC;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// beq cr6,0x8218f04c
	if (cr6.getEQ()) goto loc_8218F04C;
	// cmplwi cr6,r10,15
	cr6.compare<uint32_t>(ctx.r10.u32, 15, xer);
	// blelr cr6
	if (!cr6.getGT()) return;
	// cmplwi cr6,r10,17
	cr6.compare<uint32_t>(ctx.r10.u32, 17, xer);
	// bgtlr cr6
	if (cr6.getGT()) return;
loc_8218F04C:
	// rlwinm r9,r11,6,30,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0x3;
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,1
	r11.s64 = 1;
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// clrlwi r9,r9,27
	ctx.r9.u64 = ctx.r9.u32 & 0x1F;
	// slw r7,r11,r9
	ctx.r7.u64 = ctx.r9.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r9.u8 & 0x3F));
	// rlwinm r9,r8,29,3,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r8,r9,r3
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stwx r8,r9,r3
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, ctx.r8.u32);
	// lwz r9,8(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// rlwinm r9,r9,0,16,17
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xC000;
	// cmplwi cr6,r9,16384
	cr6.compare<uint32_t>(ctx.r9.u32, 16384, xer);
	// blt cr6,0x8218f0b0
	if (cr6.getLT()) goto loc_8218F0B0;
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rlwinm r9,r9,4,30,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0x3;
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// clrlwi r9,r9,27
	ctx.r9.u64 = ctx.r9.u32 & 0x1F;
	// slw r7,r11,r9
	ctx.r7.u64 = ctx.r9.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r9.u8 & 0x3F));
	// rlwinm r9,r8,29,3,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r8,r9,r3
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stwx r8,r9,r3
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, ctx.r8.u32);
loc_8218F0B0:
	// lwz r9,8(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	// rlwinm r9,r9,0,16,17
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xC000;
	// cmplwi cr6,r9,32768
	cr6.compare<uint32_t>(ctx.r9.u32, 32768, xer);
	// bltlr cr6
	if (cr6.getLT()) return;
loc_8218F0C0:
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rlwinm r9,r9,2,30,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0x3;
loc_8218F0C8:
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// clrlwi r10,r10,27
	ctx.r10.u64 = ctx.r10.u32 & 0x1F;
	// slw r10,r11,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r10.u8 & 0x3F));
	// rlwinm r11,r9,29,3,29
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r9,r11,r3
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
loc_8218F0E4:
	// stwx r10,r11,r3
	PPC_STORE_U32(r11.u32 + ctx.r3.u32, ctx.r10.u32);
	// blr 
	return;
loc_8218F0EC:
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq cr6,0x8218f100
	if (cr6.getEQ()) goto loc_8218F100;
	// lwz r10,4(r6)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	// rlwinm. r10,r10,0,1,1
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bnelr 
	if (!cr0.getEQ()) return;
loc_8218F100:
	// rlwinm r11,r11,2,30,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x3;
loc_8218F104:
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// li r9,1
	ctx.r9.s64 = 1;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// slw r9,r9,r11
	ctx.r9.u64 = r11.u8 & 0x20 ? 0 : (ctx.r9.u32 << (r11.u8 & 0x3F));
	// rlwinm r11,r10,29,3,29
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r10,r11,r3
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r3.u32);
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// b 0x8218f0e4
	goto loc_8218F0E4;
loc_8218F12C:
	// rlwinm r9,r11,6,30,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0x3;
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// li r11,1
	r11.s64 = 1;
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// clrlwi r9,r9,27
	ctx.r9.u64 = ctx.r9.u32 & 0x1F;
	// slw r7,r11,r9
	ctx.r7.u64 = ctx.r9.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r9.u8 & 0x3F));
	// rlwinm r9,r8,29,3,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r8,r9,r3
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stwx r8,r9,r3
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, ctx.r8.u32);
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rlwinm r9,r9,4,30,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0x3;
	// b 0x8218f0c8
	goto loc_8218F0C8;
loc_8218F164:
	// cmplwi cr6,r10,19
	cr6.compare<uint32_t>(ctx.r10.u32, 19, xer);
	// beq cr6,0x8218f04c
	if (cr6.getEQ()) goto loc_8218F04C;
	// cmplwi cr6,r10,24
	cr6.compare<uint32_t>(ctx.r10.u32, 24, xer);
	// beq cr6,0x8218f1d8
	if (cr6.getEQ()) goto loc_8218F1D8;
	// addi r10,r10,-25
	ctx.r10.s64 = ctx.r10.s64 + -25;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bgtlr cr6
	if (cr6.getGT()) return;
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r11,6,30,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0x3;
	// li r11,1
	r11.s64 = 1;
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// clrlwi r9,r9,27
	ctx.r9.u64 = ctx.r9.u32 & 0x1F;
	// slw r7,r11,r9
	ctx.r7.u64 = ctx.r9.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r9.u8 & 0x3F));
	// rlwinm r9,r8,29,3,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r8,r9,r3
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stwx r8,r9,r3
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, ctx.r8.u32);
	// lwz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// rlwinm r9,r9,4,30,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0x3;
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// clrlwi r9,r9,27
	ctx.r9.u64 = ctx.r9.u32 & 0x1F;
	// slw r7,r11,r9
	ctx.r7.u64 = ctx.r9.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r9.u8 & 0x3F));
	// rlwinm r9,r8,29,3,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r8,r9,r3
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stwx r8,r9,r3
	PPC_STORE_U32(ctx.r9.u32 + ctx.r3.u32, ctx.r8.u32);
	// b 0x8218f0c0
	goto loc_8218F0C0;
loc_8218F1D8:
	// rlwinm r11,r11,6,30,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0x3;
	// b 0x8218f104
	goto loc_8218F104;
}

__attribute__((alias("__imp__sub_8218F1E0"))) PPC_WEAK_FUNC(sub_8218F1E0);
PPC_FUNC_IMPL(__imp__sub_8218F1E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// li r8,2
	ctx.r8.s64 = 2;
	// lwz r9,96(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 96);
	// clrlwi r11,r10,20
	r11.u64 = ctx.r10.u32 & 0xFFF;
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r7,r11,25,7,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 25) & 0x1FFFFFF;
	// xor r7,r7,r11
	ctx.r7.u64 = ctx.r7.u64 ^ r11.u64;
	// rlwinm. r7,r7,0,21,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 0) & 0x7E0;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x8218f248
	if (!cr0.getEQ()) goto loc_8218F248;
	// lwz r9,4(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// rlwinm r11,r11,4,28,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xC;
	// addi r7,r1,-16
	ctx.r7.s64 = ctx.r1.s64 + -16;
	// clrlwi r6,r9,29
	ctx.r6.u64 = ctx.r9.u32 & 0x7;
	// stw r6,-16(r1)
	PPC_STORE_U32(ctx.r1.u32 + -16, ctx.r6.u32);
	// rlwinm r6,r9,29,29,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x7;
	// stw r6,-12(r1)
	PPC_STORE_U32(ctx.r1.u32 + -12, ctx.r6.u32);
	// rlwinm r6,r9,26,29,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 26) & 0x7;
	// rlwinm r9,r9,23,29,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 23) & 0x7;
	// stw r6,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, ctx.r6.u32);
	// stw r9,-4(r1)
	PPC_STORE_U32(ctx.r1.u32 + -4, ctx.r9.u32);
	// lwzx r11,r11,r7
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// cmpwi cr6,r11,7
	cr6.compare<int32_t>(r11.s32, 7, xer);
	// beq cr6,0x8218f248
	if (cr6.getEQ()) goto loc_8218F248;
	// li r8,3
	ctx.r8.s64 = 3;
loc_8218F248:
	// rlwimi r10,r8,20,10,11
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r8.u32, 20) & 0x300000) | (ctx.r10.u64 & 0xFFFFFFFFFFCFFFFF);
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218F258"))) PPC_WEAK_FUNC(sub_8218F258);
PPC_FUNC_IMPL(__imp__sub_8218F258) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// li r31,0
	r31.s64 = 0;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// stw r31,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r31.u32);
loc_8218F27C:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// add r4,r31,r27
	ctx.r4.u64 = r31.u64 + r27.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8218e7c8
	sub_8218E7C8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8218f2a8
	if (cr0.getEQ()) goto loc_8218F2A8;
	// li r11,1
	r11.s64 = 1;
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// slw r11,r11,r31
	r11.u64 = r31.u8 & 0x20 ? 0 : (r11.u32 << (r31.u8 & 0x3F));
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_8218F2A8:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,16
	r30.s64 = r30.s64 + 16;
	// cmplwi cr6,r31,4
	cr6.compare<uint32_t>(r31.u32, 4, xer);
	// blt cr6,0x8218f27c
	if (cr6.getLT()) goto loc_8218F27C;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_8218F2C0"))) PPC_WEAK_FUNC(sub_8218F2C0);
PPC_FUNC_IMPL(__imp__sub_8218F2C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r11,r11,356
	r11.s64 = r11.s64 + 356;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r10,4(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// lwz r10,8(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218F2F0"))) PPC_WEAK_FUNC(sub_8218F2F0);
PPC_FUNC_IMPL(__imp__sub_8218F2F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r3,r11,368
	ctx.r3.s64 = r11.s64 + 368;
	// b 0x8218e6d0
	sub_8218E6D0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218F308"))) PPC_WEAK_FUNC(sub_8218F308);
PPC_FUNC_IMPL(__imp__sub_8218F308) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r3,r11,368
	ctx.r3.s64 = r11.s64 + 368;
	// b 0x8218e740
	sub_8218E740(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218F320"))) PPC_WEAK_FUNC(sub_8218F320);
PPC_FUNC_IMPL(__imp__sub_8218F320) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r3,r11,16
	ctx.r3.s64 = r11.s64 + 16;
	// b 0x8218e8b8
	sub_8218E8B8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218F338"))) PPC_WEAK_FUNC(sub_8218F338);
PPC_FUNC_IMPL(__imp__sub_8218F338) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lwz r3,116(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 116);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218F350"))) PPC_WEAK_FUNC(sub_8218F350);
PPC_FUNC_IMPL(__imp__sub_8218F350) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lwz r11,128(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 128);
	// addi r3,r11,-1
	ctx.r3.s64 = r11.s64 + -1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218F368"))) PPC_WEAK_FUNC(sub_8218F368);
PPC_FUNC_IMPL(__imp__sub_8218F368) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// lwz r10,96(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bge cr6,0x8218f388
	if (!cr6.getLT()) goto loc_8218F388;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_8218F388:
	// lwz r11,124(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 124);
	// rlwinm r10,r4,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 3) & 0xFFFFFFF8;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218F398"))) PPC_WEAK_FUNC(sub_8218F398);
PPC_FUNC_IMPL(__imp__sub_8218F398) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r3,r11,16
	ctx.r3.s64 = r11.s64 + 16;
	// b 0x8218e9a8
	sub_8218E9A8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218F3B0"))) PPC_WEAK_FUNC(sub_8218F3B0);
PPC_FUNC_IMPL(__imp__sub_8218F3B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r3,r11,16
	ctx.r3.s64 = r11.s64 + 16;
	// b 0x8218ea88
	sub_8218EA88(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218F3C8"))) PPC_WEAK_FUNC(sub_8218F3C8);
PPC_FUNC_IMPL(__imp__sub_8218F3C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed100
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r24,r3
	r24.u64 = ctx.r3.u64;
	// li r20,0
	r20.s64 = 0;
	// mr r22,r4
	r22.u64 = ctx.r4.u64;
	// mr r21,r5
	r21.u64 = ctx.r5.u64;
	// clrlwi r14,r6,31
	r14.u64 = ctx.r6.u32 & 0x1;
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// lwz r17,4(r24)
	r17.u64 = PPC_LOAD_U32(r24.u32 + 4);
	// mr r23,r20
	r23.u64 = r20.u64;
	// not r11,r11
	r11.u64 = ~r11.u64;
	// addi r16,r24,20
	r16.s64 = r24.s64 + 20;
	// clrlwi r15,r11,31
	r15.u64 = r11.u32 & 0x1;
loc_8218F404:
	// lwz r11,0(r16)
	r11.u64 = PPC_LOAD_U32(r16.u32 + 0);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8218f640
	if (cr0.getEQ()) goto loc_8218F640;
	// add r11,r11,r24
	r11.u64 = r11.u64 + r24.u64;
	// mr r18,r20
	r18.u64 = r20.u64;
	// addi r31,r11,20
	r31.s64 = r11.s64 + 20;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// rlwinm r11,r11,0,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFC;
	// add r19,r11,r31
	r19.u64 = r11.u64 + r31.u64;
	// b 0x8218f638
	goto loc_8218F638;
loc_8218F42C:
	// lhz r10,2(r31)
	ctx.r10.u64 = PPC_LOAD_U16(r31.u32 + 2);
	// lhz r11,0(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 0);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne 0x8218f450
	if (!cr0.getEQ()) goto loc_8218F450;
	// addi r18,r18,1
	r18.s64 = r18.s64 + 1;
	// cmplwi cr6,r18,3
	cr6.compare<uint32_t>(r18.u32, 3, xer);
	// bge cr6,0x8218f640
	if (!cr6.getLT()) goto loc_8218F640;
	// b 0x8218f638
	goto loc_8218F638;
loc_8218F450:
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// bne cr6,0x8218f508
	if (!cr6.getEQ()) goto loc_8218F508;
	// clrlwi. r9,r10,28
	ctx.r9.u64 = ctx.r10.u32 & 0xF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x8218f654
	if (!cr0.getEQ()) goto loc_8218F654;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// add r9,r9,r17
	ctx.r9.u64 = ctx.r9.u64 + r17.u64;
	// add r30,r9,r24
	r30.u64 = ctx.r9.u64 + r24.u64;
loc_8218F470:
	// clrlwi r28,r11,16
	r28.u64 = r11.u32 & 0xFFFF;
	// cmplwi cr6,r28,512
	cr6.compare<uint32_t>(r28.u32, 512, xer);
	// bge cr6,0x8218f654
	if (!cr6.getLT()) goto loc_8218F654;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// cmpwi cr6,r15,0
	cr6.compare<int32_t>(r15.s32, 0, xer);
	// beq cr6,0x8218f48c
	if (cr6.getEQ()) goto loc_8218F48C;
	// addi r6,r6,-256
	ctx.r6.s64 = ctx.r6.s64 + -256;
loc_8218F48C:
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// beq cr6,0x8218f4a4
	if (cr6.getEQ()) goto loc_8218F4A4;
	// std r20,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r20.u64);
	// std r20,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r20.u64);
	// b 0x8218f4c4
	goto loc_8218F4C4;
loc_8218F4A4:
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r8,4(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r5,12(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// stw r5,12(r11)
	PPC_STORE_U32(r11.u32 + 12, ctx.r5.u32);
loc_8218F4C4:
	// addis r11,r10,1
	r11.s64 = ctx.r10.s64 + 65536;
	// addi r30,r30,16
	r30.s64 = r30.s64 + 16;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// addi r7,r1,112
	ctx.r7.s64 = ctx.r1.s64 + 112;
	// clrlwi r29,r11,16
	r29.u64 = r11.u32 & 0xFFFF;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// mtctr r21
	ctr.u64 = r21.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8218f65c
	if (cr0.getLT()) goto loc_8218F65C;
	// addi r11,r28,1
	r11.s64 = r28.s64 + 1;
	// clrlwi. r10,r29,16
	ctx.r10.u64 = r29.u32 & 0xFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// bne 0x8218f470
	if (!cr0.getEQ()) goto loc_8218F470;
	// b 0x8218f638
	goto loc_8218F638;
loc_8218F508:
	// cmplwi cr6,r18,1
	cr6.compare<uint32_t>(r18.u32, 1, xer);
	// bne cr6,0x8218f598
	if (!cr6.getEQ()) goto loc_8218F598;
loc_8218F510:
	// clrlwi r30,r11,16
	r30.u64 = r11.u32 & 0xFFFF;
	// cmplwi cr6,r30,8992
	cr6.compare<uint32_t>(r30.u32, 8992, xer);
	// blt cr6,0x8218f654
	if (cr6.getLT()) goto loc_8218F654;
	// cmplwi cr6,r30,9120
	cr6.compare<uint32_t>(r30.u32, 9120, xer);
	// bge cr6,0x8218f654
	if (!cr6.getLT()) goto loc_8218F654;
	// addis r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 65536;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r9,r30,-8992
	ctx.r9.s64 = r30.s64 + -8992;
	// stw r20,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r20.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// rlwinm r6,r9,30,2,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFFFFFF;
	// clrlwi r29,r10,16
	r29.u64 = ctx.r10.u32 & 0xFFFF;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// rlwinm r9,r11,16,16,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF;
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// li r5,2
	ctx.r5.s64 = 2;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// rlwinm r11,r10,24,24,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFF;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// extsb r11,r9
	r11.s64 = ctx.r9.s8;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// mtctr r21
	ctr.u64 = r21.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8218f65c
	if (cr0.getLT()) goto loc_8218F65C;
	// addi r11,r30,4
	r11.s64 = r30.s64 + 4;
	// clrlwi. r10,r29,16
	ctx.r10.u64 = r29.u32 & 0xFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// bne 0x8218f510
	if (!cr0.getEQ()) goto loc_8218F510;
	// b 0x8218f638
	goto loc_8218F638;
loc_8218F598:
	// clrlwi r27,r11,16
	r27.u64 = r11.u32 & 0xFFFF;
	// cmplwi cr6,r27,8960
	cr6.compare<uint32_t>(r27.u32, 8960, xer);
	// blt cr6,0x8218f654
	if (cr6.getLT()) goto loc_8218F654;
	// cmplwi cr6,r27,8992
	cr6.compare<uint32_t>(r27.u32, 8992, xer);
	// bge cr6,0x8218f654
	if (!cr6.getLT()) goto loc_8218F654;
	// addi r11,r31,4
	r11.s64 = r31.s64 + 4;
	// lwz r26,0(r31)
	r26.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addis r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 65536;
	// addi r9,r27,-8960
	ctx.r9.s64 = r27.s64 + -8960;
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// rlwinm r29,r9,3,0,26
	r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFE0;
	// lwz r28,0(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r25,r10,16
	r25.u64 = ctx.r10.u32 & 0xFFFF;
	// mr r30,r20
	r30.u64 = r20.u64;
	// addi r31,r11,4
	r31.s64 = r11.s64 + 4;
loc_8218F5D4:
	// li r11,1
	r11.s64 = 1;
	// slw r11,r11,r30
	r11.u64 = r30.u8 & 0x20 ? 0 : (r11.u32 << (r30.u8 & 0x3F));
	// and. r10,r11,r26
	ctx.r10.u64 = r11.u64 & r26.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8218f61c
	if (!cr0.getEQ()) goto loc_8218F61C;
	// and r11,r11,r28
	r11.u64 = r11.u64 & r28.u64;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// add r6,r30,r29
	ctx.r6.u64 = r30.u64 + r29.u64;
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// li r5,0
	ctx.r5.s64 = 0;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// mtctr r21
	ctr.u64 = r21.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8218f65c
	if (cr0.getLT()) goto loc_8218F65C;
loc_8218F61C:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplwi cr6,r30,32
	cr6.compare<uint32_t>(r30.u32, 32, xer);
	// blt cr6,0x8218f5d4
	if (cr6.getLT()) goto loc_8218F5D4;
	// addi r11,r27,4
	r11.s64 = r27.s64 + 4;
	// clrlwi. r10,r25,16
	ctx.r10.u64 = r25.u32 & 0xFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// bne 0x8218f598
	if (!cr0.getEQ()) goto loc_8218F598;
loc_8218F638:
	// cmplw cr6,r31,r19
	cr6.compare<uint32_t>(r31.u32, r19.u32, xer);
	// blt cr6,0x8218f42c
	if (cr6.getLT()) goto loc_8218F42C;
loc_8218F640:
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// addi r16,r16,8
	r16.s64 = r16.s64 + 8;
	// cmplwi cr6,r23,2
	cr6.compare<uint32_t>(r23.u32, 2, xer);
	// blt cr6,0x8218f404
	if (cr6.getLT()) goto loc_8218F404;
	// b 0x8218f65c
	goto loc_8218F65C;
loc_8218F654:
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
loc_8218F65C:
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// b 0x823ed150
	return;
}

__attribute__((alias("__imp__sub_8218F668"))) PPC_WEAK_FUNC(sub_8218F668);
PPC_FUNC_IMPL(__imp__sub_8218F668) {
	PPC_FUNC_PROLOGUE();
	// li r6,0
	ctx.r6.s64 = 0;
	// b 0x8218f3c8
	sub_8218F3C8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8218F670"))) PPC_WEAK_FUNC(sub_8218F670);
PPC_FUNC_IMPL(__imp__sub_8218F670) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// ble cr6,0x8218f6f4
	if (!cr6.getGT()) goto loc_8218F6F4;
	// rlwinm r30,r11,1,0,30
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r30,r4
	cr6.compare<uint32_t>(r30.u32, ctx.r4.u32, xer);
	// bge cr6,0x8218f6a0
	if (!cr6.getLT()) goto loc_8218F6A0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
loc_8218F6A0:
	// lis r4,25728
	ctx.r4.s64 = 1686110208;
	// mulli r3,r30,12
	ctx.r3.s64 = r30.s64 * 12;
	// bl 0x8209d000
	sub_8209D000(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// bne 0x8218f6c4
	if (!cr0.getEQ()) goto loc_8218F6C4;
	// lis r11,-32761
	r11.s64 = -2147024896;
	// ori r11,r11,14
	r11.u64 = r11.u64 | 14;
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// b 0x8218f6f4
	goto loc_8218F6F4;
loc_8218F6C4:
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r30,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r30.u32);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq 0x8218f6f0
	if (cr0.getEQ()) goto loc_8218F6F0;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mulli r5,r11,12
	ctx.r5.s64 = r11.s64 * 12;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// bl 0x8209d060
	sub_8209D060(ctx, base);
loc_8218F6F0:
	// stw r29,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r29.u32);
loc_8218F6F4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_8218F700"))) PPC_WEAK_FUNC(sub_8218F700);
PPC_FUNC_IMPL(__imp__sub_8218F700) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// ble cr6,0x8218f784
	if (!cr6.getGT()) goto loc_8218F784;
	// rlwinm r30,r11,1,0,30
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r30,r4
	cr6.compare<uint32_t>(r30.u32, ctx.r4.u32, xer);
	// bge cr6,0x8218f730
	if (!cr6.getLT()) goto loc_8218F730;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
loc_8218F730:
	// lis r4,25728
	ctx.r4.s64 = 1686110208;
	// rlwinm r3,r30,3,0,28
	ctx.r3.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x8209d000
	sub_8209D000(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// bne 0x8218f754
	if (!cr0.getEQ()) goto loc_8218F754;
	// lis r11,-32761
	r11.s64 = -2147024896;
	// ori r11,r11,14
	r11.u64 = r11.u64 | 14;
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// b 0x8218f784
	goto loc_8218F784;
loc_8218F754:
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r30,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r30.u32);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq 0x8218f780
	if (cr0.getEQ()) goto loc_8218F780;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// rlwinm r5,r11,3,0,28
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x8209d060
	sub_8209D060(ctx, base);
loc_8218F780:
	// stw r29,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r29.u32);
loc_8218F784:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_8218F790"))) PPC_WEAK_FUNC(sub_8218F790);
PPC_FUNC_IMPL(__imp__sub_8218F790) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// ble cr6,0x8218f814
	if (!cr6.getGT()) goto loc_8218F814;
	// rlwinm r30,r11,1,0,30
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmplw cr6,r30,r4
	cr6.compare<uint32_t>(r30.u32, ctx.r4.u32, xer);
	// bge cr6,0x8218f7c0
	if (!cr6.getLT()) goto loc_8218F7C0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
loc_8218F7C0:
	// lis r4,25728
	ctx.r4.s64 = 1686110208;
	// rlwinm r3,r30,2,0,29
	ctx.r3.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8209d000
	sub_8209D000(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// bne 0x8218f7e4
	if (!cr0.getEQ()) goto loc_8218F7E4;
	// lis r11,-32761
	r11.s64 = -2147024896;
	// ori r11,r11,14
	r11.u64 = r11.u64 | 14;
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
	// b 0x8218f814
	goto loc_8218F814;
loc_8218F7E4:
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r30,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r30.u32);
	// cmplwi r4,0
	cr0.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq 0x8218f810
	if (cr0.getEQ()) goto loc_8218F810;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x8209d060
	sub_8209D060(ctx, base);
loc_8218F810:
	// stw r29,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r29.u32);
loc_8218F814:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_8218F820"))) PPC_WEAK_FUNC(sub_8218F820);
PPC_FUNC_IMPL(__imp__sub_8218F820) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r10,-31436(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -31436);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8218f85c
	if (cr6.getEQ()) goto loc_8218F85C;
	// rotlwi r11,r10,0
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8218f85c
	if (!cr0.getEQ()) goto loc_8218F85C;
loc_8218F854:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8218f928
	goto loc_8218F928;
loc_8218F85C:
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// clrlwi r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	// lwz r28,8(r29)
	r28.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// add r27,r11,r29
	r27.u64 = r11.u64 + r29.u64;
	// subfic r10,r10,0
	xer.ca = ctx.r10.u32 <= 0;
	ctx.r10.s64 = 0 - ctx.r10.s64;
	// subfe r10,r10,r10
	temp.u8 = (~ctx.r10.u32 + ctx.r10.u32 < ~ctx.r10.u32) | (~ctx.r10.u32 + ctx.r10.u32 + xer.ca < xer.ca);
	ctx.r10.u64 = ~ctx.r10.u64 + ctx.r10.u64 + xer.ca;
	xer.ca = temp.u8;
	// andi. r10,r10,832
	ctx.r10.u64 = ctx.r10.u64 & 832;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 + 40;
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + r11.u64;
	// bl 0x8209d000
	sub_8209D000(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x8218f854
	if (cr0.getEQ()) goto loc_8218F854;
	// li r30,0
	r30.s64 = 0;
	// lwz r5,4(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r31,40
	ctx.r3.s64 = r31.s64 + 40;
	// std r30,0(r31)
	PPC_STORE_U64(r31.u32 + 0, r30.u64);
	// std r30,8(r31)
	PPC_STORE_U64(r31.u32 + 8, r30.u64);
	// std r30,16(r31)
	PPC_STORE_U64(r31.u32 + 16, r30.u64);
	// std r30,24(r31)
	PPC_STORE_U64(r31.u32 + 24, r30.u64);
	// std r30,32(r31)
	PPC_STORE_U64(r31.u32 + 32, r30.u64);
	// bl 0x8235e790
	sub_8235E790(ctx, base);
	// lis r4,-19072
	ctx.r4.s64 = -1249902592;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8209d000
	sub_8209D000(ctx, base);
	// mr. r29,r3
	r29.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// bne 0x8218f8e0
	if (!cr0.getEQ()) goto loc_8218F8E0;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8209d060
	sub_8209D060(ctx, base);
	// b 0x8218f854
	goto loc_8218F854;
loc_8218F8E0:
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lis r9,16
	ctx.r9.s64 = 1048576;
	// std r30,0(r31)
	PPC_STORE_U64(r31.u32 + 0, r30.u64);
	// li r11,1
	r11.s64 = 1;
	// lis r10,-1
	ctx.r10.s64 = -65536;
	// std r30,8(r31)
	PPC_STORE_U64(r31.u32 + 8, r30.u64);
	// ori r9,r9,7
	ctx.r9.u64 = ctx.r9.u64 | 7;
	// std r30,16(r31)
	PPC_STORE_U64(r31.u32 + 16, r30.u64);
	// std r30,24(r31)
	PPC_STORE_U64(r31.u32 + 24, r30.u64);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// std r30,32(r31)
	PPC_STORE_U64(r31.u32 + 32, r30.u64);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r10,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r10.u32);
	// stw r29,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r29.u32);
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
loc_8218F928:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_8218F930"))) PPC_WEAK_FUNC(sub_8218F930);
PPC_FUNC_IMPL(__imp__sub_8218F930) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r10,-31432(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -31432);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8218f96c
	if (cr6.getEQ()) goto loc_8218F96C;
	// rotlwi r11,r10,0
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8218f96c
	if (!cr0.getEQ()) goto loc_8218F96C;
loc_8218F964:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x8218fa18
	goto loc_8218FA18;
loc_8218F96C:
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	// lwz r29,8(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// add r27,r11,r31
	r27.u64 = r11.u64 + r31.u64;
	// subfic r10,r10,0
	xer.ca = ctx.r10.u32 <= 0;
	ctx.r10.s64 = 0 - ctx.r10.s64;
	// subfe r10,r10,r10
	temp.u8 = (~ctx.r10.u32 + ctx.r10.u32 < ~ctx.r10.u32) | (~ctx.r10.u32 + ctx.r10.u32 + xer.ca < xer.ca);
	ctx.r10.u64 = ~ctx.r10.u64 + ctx.r10.u64 + xer.ca;
	xer.ca = temp.u8;
	// andi. r10,r10,832
	ctx.r10.u64 = ctx.r10.u64 & 832;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r10,r10,40
	ctx.r10.s64 = ctx.r10.s64 + 40;
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + r11.u64;
	// bl 0x8209d000
	sub_8209D000(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// beq 0x8218f964
	if (cr0.getEQ()) goto loc_8218F964;
	// li r5,872
	ctx.r5.s64 = 872;
	// lwz r28,4(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r30,872
	ctx.r3.s64 = r30.s64 + 872;
	// bl 0x8235e790
	sub_8235E790(ctx, base);
	// lis r4,-19072
	ctx.r4.s64 = -1249902592;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8209d000
	sub_8209D000(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x8218f9ec
	if (!cr0.getEQ()) goto loc_8218F9EC;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8209d060
	sub_8209D060(ctx, base);
	// b 0x8218f964
	goto loc_8218F964;
loc_8218F9EC:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8218dff8
	sub_8218DFF8(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// oris r11,r11,16
	r11.u64 = r11.u64 | 1048576;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
loc_8218FA18:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_8218FA20"))) PPC_WEAK_FUNC(sub_8218FA20);
PPC_FUNC_IMPL(__imp__sub_8218FA20) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// addi r4,r31,12184
	ctx.r4.s64 = r31.s64 + 12184;
	// stw r3,12424(r31)
	PPC_STORE_U32(r31.u32 + 12424, ctx.r3.u32);
	// bl 0x8218bf80
	sub_8218BF80(ctx, base);
	// stw r4,11812(r31)
	PPC_STORE_U32(r31.u32 + 11812, ctx.r4.u32);
	// ld r11,16(r31)
	r11.u64 = PPC_LOAD_U64(r31.u32 + 16);
	// oris r11,r11,8
	r11.u64 = r11.u64 | 524288;
	// std r11,16(r31)
	PPC_STORE_U64(r31.u32 + 16, r11.u64);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218FA68"))) PPC_WEAK_FUNC(sub_8218FA68);
PPC_FUNC_IMPL(__imp__sub_8218FA68) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed108
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r20,r4
	r20.u64 = ctx.r4.u64;
	// lwz r3,9568(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 9568);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8218fec0
	if (cr0.getLT()) goto loc_8218FEC0;
	// lwz r11,9564(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 9564);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8218feb0
	if (!cr6.getEQ()) goto loc_8218FEB0;
	// addi r31,r20,20
	r31.s64 = r20.s64 + 20;
	// addi r30,r26,9120
	r30.s64 = r26.s64 + 9120;
	// li r5,20
	ctx.r5.s64 = 20;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r17,4(r31)
	r17.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// lwz r11,9572(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 9572);
	// lwz r16,4(r31)
	r16.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r19,1
	r19.s64 = 1;
	// lwz r10,19892(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// rlwinm. r10,r10,26,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8218fc20
	if (cr0.getEQ()) goto loc_8218FC20;
	// lwz r10,9560(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 9560);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x8218fc20
	if (cr6.getEQ()) goto loc_8218FC20;
	// lwz r10,19932(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 19932);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x8218fc20
	if (cr6.getEQ()) goto loc_8218FC20;
	// li r18,0
	r18.s64 = 0;
	// mr r21,r19
	r21.u64 = r19.u64;
	// stw r18,19932(r11)
	PPC_STORE_U32(r11.u32 + 19932, r18.u32);
loc_8218FAEC:
	// lwz r11,9572(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 9572);
	// mr r25,r18
	r25.u64 = r18.u64;
	// ld r22,0(r30)
	r22.u64 = PPC_LOAD_U64(r30.u32 + 0);
	// lwz r10,19892(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// lwz r23,19936(r11)
	r23.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// rlwinm r24,r10,6,23,23
	r24.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0x100;
loc_8218FB04:
	// rlwinm r10,r25,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r10,30,2,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// subfic r11,r11,63
	xer.ca = r11.u32 <= 63;
	r11.s64 = 63 - r11.s64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// sld r11,r19,r11
	r11.u64 = r11.u8 & 0x40 ? 0 : (r19.u64 << (r11.u8 & 0x7F));
	// and r11,r11,r22
	r11.u64 = r11.u64 & r22.u64;
	// cmpdi cr6,r11,0
	cr6.compare<int64_t>(r11.s64, 0, xer);
	// beq cr6,0x8218fca0
	if (cr6.getEQ()) goto loc_8218FCA0;
	// addi r11,r25,1
	r11.s64 = r25.s64 + 1;
	// mr r28,r25
	r28.u64 = r25.u64;
	// cmplwi cr6,r11,64
	cr6.compare<uint32_t>(r11.u32, 64, xer);
	// bge cr6,0x8218fb7c
	if (!cr6.getLT()) goto loc_8218FB7C;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
loc_8218FB38:
	// rlwinm r9,r10,30,2,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// subfic r9,r9,63
	xer.ca = ctx.r9.u32 <= 63;
	ctx.r9.s64 = 63 - ctx.r9.s64;
	// clrldi r9,r9,32
	ctx.r9.u64 = ctx.r9.u64 & 0xFFFFFFFF;
	// sld r9,r19,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x40 ? 0 : (r19.u64 << (ctx.r9.u8 & 0x7F));
	// and r9,r9,r22
	ctx.r9.u64 = ctx.r9.u64 & r22.u64;
	// cmpdi cr6,r9,0
	cr6.compare<int64_t>(ctx.r9.s64, 0, xer);
	// beq cr6,0x8218fb7c
	if (cr6.getEQ()) goto loc_8218FB7C;
	// lwz r9,9560(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 9560);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x8218fb68
	if (!cr6.getEQ()) goto loc_8218FB68;
	// cmplw cr6,r11,r23
	cr6.compare<uint32_t>(r11.u32, r23.u32, xer);
	// beq cr6,0x8218fb7c
	if (cr6.getEQ()) goto loc_8218FB7C;
loc_8218FB68:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmplwi cr6,r11,64
	cr6.compare<uint32_t>(r11.u32, 64, xer);
	// blt cr6,0x8218fb38
	if (cr6.getLT()) goto loc_8218FB38;
loc_8218FB7C:
	// rlwinm r10,r28,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r27,4(r20)
	r27.u64 = PPC_LOAD_U32(r20.u32 + 4);
	// subf r11,r28,r25
	r11.s64 = r25.s64 - r28.s64;
	// add r30,r10,r24
	r30.u64 = ctx.r10.u64 + r24.u64;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r29,r11,1
	r29.s64 = r11.s64 + 1;
	// sth r30,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, r30.u16);
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// rlwinm r11,r29,4,12,27
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 4) & 0xFFFF0;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// sth r11,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, r11.u16);
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// addi r11,r30,48
	r11.s64 = r30.s64 + 48;
	// lwz r10,9560(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 9560);
	// rlwinm r5,r29,6,0,25
	ctx.r5.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 6) & 0xFFFFFFC0;
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// add r4,r11,r26
	ctx.r4.u64 = r11.u64 + r26.u64;
	// beq cr6,0x8218fc5c
	if (cr6.getEQ()) goto loc_8218FC5C;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r27.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// beq cr6,0x8218fca0
	if (cr6.getEQ()) goto loc_8218FCA0;
	// cmplw cr6,r28,r23
	cr6.compare<uint32_t>(r28.u32, r23.u32, xer);
	// mr r11,r28
	r11.u64 = r28.u64;
	// bgt cr6,0x8218fc0c
	if (cr6.getGT()) goto loc_8218FC0C;
	// mr r11,r23
	r11.u64 = r23.u64;
loc_8218FC0C:
	// subf r10,r28,r11
	ctx.r10.s64 = r11.s64 - r28.s64;
	// add r9,r29,r28
	ctx.r9.u64 = r29.u64 + r28.u64;
	// rlwinm r10,r10,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0xFFFFFFC0;
	// add r10,r10,r27
	ctx.r10.u64 = ctx.r10.u64 + r27.u64;
	// b 0x8218fc50
	goto loc_8218FC50;
loc_8218FC20:
	// li r18,0
	r18.s64 = 0;
	// mr r21,r18
	r21.u64 = r18.u64;
	// b 0x8218faec
	goto loc_8218FAEC;
loc_8218FC2C:
	// lwz r8,9572(r26)
	ctx.r8.u64 = PPC_LOAD_U32(r26.u32 + 9572);
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// addi r10,r10,64
	ctx.r10.s64 = ctx.r10.s64 + 64;
	// lwz r6,19936(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 19936);
	// lwz r8,19940(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 19940);
	// subf r6,r6,r11
	ctx.r6.s64 = r11.s64 - ctx.r6.s64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r7,r6,r8
	PPC_STORE_U32(ctx.r6.u32 + ctx.r8.u32, ctx.r7.u32);
loc_8218FC50:
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// blt cr6,0x8218fc2c
	if (cr6.getLT()) goto loc_8218FC2C;
	// b 0x8218fca0
	goto loc_8218FCA0;
loc_8218FC5C:
	// cmplw cr6,r28,r23
	cr6.compare<uint32_t>(r28.u32, r23.u32, xer);
	// bge cr6,0x8218fc74
	if (!cr6.getLT()) goto loc_8218FC74;
	// mr r3,r20
	ctx.r3.u64 = r20.u64;
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r27.u32);
	// b 0x8218fc90
	goto loc_8218FC90;
loc_8218FC74:
	// lwz r11,9572(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 9572);
	// lwz r10,19936(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// lwz r11,19940(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19940);
	// subf r10,r10,r28
	ctx.r10.s64 = r28.s64 - ctx.r10.s64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
loc_8218FC90:
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218c530
	sub_8218C530(ctx, base);
loc_8218FCA0:
	// addi r25,r25,1
	r25.s64 = r25.s64 + 1;
	// cmplwi cr6,r25,64
	cr6.compare<uint32_t>(r25.u32, 64, xer);
	// blt cr6,0x8218fb04
	if (cr6.getLT()) goto loc_8218FB04;
	// li r5,4
	ctx.r5.s64 = 4;
	// stw r18,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r18.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// mr r30,r18
	r30.u64 = r18.u64;
loc_8218FCC4:
	// clrlwi r10,r30,27
	ctx.r10.u64 = r30.u32 & 0x1F;
	// rlwinm r11,r30,27,5,31
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 27) & 0x7FFFFFF;
	// addi r11,r11,2302
	r11.s64 = r11.s64 + 2302;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r26
	r11.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// slw r10,r19,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (r19.u32 << (ctx.r10.u8 & 0x3F));
	// and. r11,r10,r11
	r11.u64 = ctx.r10.u64 & r11.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8218fd64
	if (cr0.getEQ()) goto loc_8218FD64;
	// addi r11,r30,1
	r11.s64 = r30.s64 + 1;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// b 0x8218fd18
	goto loc_8218FD18;
loc_8218FCF0:
	// clrlwi r8,r11,27
	ctx.r8.u64 = r11.u32 & 0x1F;
	// rlwinm r9,r11,27,5,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x7FFFFFF;
	// addi r9,r9,2302
	ctx.r9.s64 = ctx.r9.s64 + 2302;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r26
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r26.u32);
	// slw r8,r19,r8
	ctx.r8.u64 = ctx.r8.u8 & 0x20 ? 0 : (r19.u32 << (ctx.r8.u8 & 0x3F));
	// and. r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 & ctx.r9.u64;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x8218fd20
	if (cr0.getEQ()) goto loc_8218FD20;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
loc_8218FD18:
	// cmplwi cr6,r11,2280
	cr6.compare<uint32_t>(r11.u32, 2280, xer);
	// blt cr6,0x8218fcf0
	if (cr6.getLT()) goto loc_8218FCF0;
loc_8218FD20:
	// rlwinm r29,r10,2,0,29
	r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r10,r30
	r11.s64 = r30.s64 - ctx.r10.s64;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r28,r11,1
	r28.s64 = r11.s64 + 1;
	// sth r29,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, r29.u16);
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// sth r28,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, r28.u16);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// rlwinm r5,r28,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// add r4,r29,r26
	ctx.r4.u64 = r29.u64 + r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218c530
	sub_8218C530(ctx, base);
loc_8218FD64:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplwi cr6,r30,2280
	cr6.compare<uint32_t>(r30.u32, 2280, xer);
	// blt cr6,0x8218fcc4
	if (cr6.getLT()) goto loc_8218FCC4;
	// li r5,4
	ctx.r5.s64 = 4;
	// stw r18,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r18.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// mr r28,r18
	r28.u64 = r18.u64;
loc_8218FD88:
	// addi r11,r28,2382
	r11.s64 = r28.s64 + 2382;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r26
	r11.u64 = PPC_LOAD_U32(r11.u32 + r26.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8218fe68
	if (cr6.getEQ()) goto loc_8218FE68;
	// addi r11,r28,1
	r11.s64 = r28.s64 + 1;
	// mr r29,r28
	r29.u64 = r28.u64;
	// b 0x8218fdd0
	goto loc_8218FDD0;
loc_8218FDA8:
	// clrlwi r9,r11,27
	ctx.r9.u64 = r11.u32 & 0x1F;
	// rlwinm r10,r11,27,5,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x7FFFFFF;
	// addi r10,r10,2382
	ctx.r10.s64 = ctx.r10.s64 + 2382;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r26
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r26.u32);
	// slw r9,r19,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r19.u32 << (ctx.r9.u8 & 0x3F));
	// and. r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 & ctx.r10.u64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8218fdd8
	if (cr0.getEQ()) goto loc_8218FDD8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
loc_8218FDD0:
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// blt cr6,0x8218fda8
	if (cr6.getLT()) goto loc_8218FDA8;
loc_8218FDD8:
	// addi r10,r29,2240
	ctx.r10.s64 = r29.s64 + 2240;
	// subf r11,r29,r28
	r11.s64 = r28.s64 - r29.s64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r30,r11,1
	r30.s64 = r11.s64 + 1;
	// sth r10,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, ctx.r10.u16);
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// rlwinm r11,r30,1,0,30
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// li r5,2
	ctx.r5.s64 = 2;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// sth r11,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, r11.u16);
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x8218fe68
	if (cr6.getEQ()) goto loc_8218FE68;
	// addi r11,r29,2374
	r11.s64 = r29.s64 + 2374;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r29,r11,r26
	r29.u64 = r11.u64 + r26.u64;
loc_8218FE28:
	// lwz r11,32(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 32);
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// not r11,r11
	r11.u64 = ~r11.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// bne 0x8218fe28
	if (!cr0.getEQ()) goto loc_8218FE28;
loc_8218FE68:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmplwi cr6,r28,8
	cr6.compare<uint32_t>(r28.u32, 8, xer);
	// blt cr6,0x8218fd88
	if (cr6.getLT()) goto loc_8218FD88;
	// li r5,4
	ctx.r5.s64 = 4;
	// stw r18,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r18.u32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// addi r11,r17,16
	r11.s64 = r17.s64 + 16;
	// lwz r30,4(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// subf r11,r16,r30
	r11.s64 = r30.s64 - r16.s64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
loc_8218FEB0:
	// lwz r3,16(r20)
	ctx.r3.u64 = PPC_LOAD_U32(r20.u32 + 16);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8218fec0
	if (cr0.getLT()) goto loc_8218FEC0;
	// lwz r3,36(r20)
	ctx.r3.u64 = PPC_LOAD_U32(r20.u32 + 36);
loc_8218FEC0:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x823ed158
	return;
}

__attribute__((alias("__imp__sub_8218FEC8"))) PPC_WEAK_FUNC(sub_8218FEC8);
PPC_FUNC_IMPL(__imp__sub_8218FEC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,128
	ctx.r3.s64 = r31.s64 + 128;
	// stw r30,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r30.u32);
	// stw r30,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r30.u32);
	// stw r30,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r30.u32);
	// stb r30,124(r31)
	PPC_STORE_U8(r31.u32 + 124, r30.u8);
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,160
	ctx.r3.s64 = r31.s64 + 160;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,192
	ctx.r3.s64 = r31.s64 + 192;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,224
	ctx.r3.s64 = r31.s64 + 224;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// stw r30,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r30.u32);
	// stw r30,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r30.u32);
	// stw r30,264(r31)
	PPC_STORE_U32(r31.u32 + 264, r30.u32);
	// stw r30,120(r31)
	PPC_STORE_U32(r31.u32 + 120, r30.u32);
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// stw r30,316(r31)
	PPC_STORE_U32(r31.u32 + 316, r30.u32);
	// stw r30,336(r31)
	PPC_STORE_U32(r31.u32 + 336, r30.u32);
	// stw r30,320(r31)
	PPC_STORE_U32(r31.u32 + 320, r30.u32);
	// stw r30,324(r31)
	PPC_STORE_U32(r31.u32 + 324, r30.u32);
	// stw r30,328(r31)
	PPC_STORE_U32(r31.u32 + 328, r30.u32);
	// stw r30,332(r31)
	PPC_STORE_U32(r31.u32 + 332, r30.u32);
	// stw r30,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r30.u32);
	// stw r30,340(r31)
	PPC_STORE_U32(r31.u32 + 340, r30.u32);
	// stw r30,344(r31)
	PPC_STORE_U32(r31.u32 + 344, r30.u32);
	// stw r30,348(r31)
	PPC_STORE_U32(r31.u32 + 348, r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8218FF88"))) PPC_WEAK_FUNC(sub_8218FF88);
PPC_FUNC_IMPL(__imp__sub_8218FF88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed110
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r18,1
	r18.s64 = 1;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// stw r18,84(r29)
	PPC_STORE_U32(r29.u32 + 84, r18.u32);
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// rlwinm. r11,r11,30,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x821904d8
	if (!cr0.getEQ()) goto loc_821904D8;
	// lwz r31,304(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 304);
	// addi r19,r29,304
	r19.s64 = r29.s64 + 304;
	// b 0x8219000c
	goto loc_8219000C;
loc_8218FFBC:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r9,r11,24,28,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 24) & 0xF;
	// rlwinm r10,r11,20,12,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0xFFFFF;
	// add r9,r9,r29
	ctx.r9.u64 = ctx.r9.u64 + r29.u64;
	// clrlwi r8,r10,28
	ctx.r8.u64 = ctx.r10.u32 & 0xF;
	// lbz r9,320(r9)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + 320);
	// and r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 & ctx.r10.u64;
	// clrlwi r10,r9,28
	ctx.r10.u64 = ctx.r9.u32 & 0xF;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// beq cr6,0x82190008
	if (cr6.getEQ()) goto loc_82190008;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8218fff8
	if (cr6.getEQ()) goto loc_8218FFF8;
	// rlwimi r11,r10,12,16,19
	r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 12) & 0xF000) | (r11.u64 & 0xFFFFFFFFFFFF0FFF);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x82190008
	goto loc_82190008;
loc_8218FFF8:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// bl 0x8218d4f8
	sub_8218D4F8(ctx, base);
	// addi r31,r31,-4
	r31.s64 = r31.s64 + -4;
loc_82190008:
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
loc_8219000C:
	// lwz r11,4(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 4);
	// lwz r10,0(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// blt cr6,0x8218ffbc
	if (cr6.getLT()) goto loc_8218FFBC;
	// lwz r26,292(r29)
	r26.u64 = PPC_LOAD_U32(r29.u32 + 292);
	// addi r22,r29,292
	r22.s64 = r29.s64 + 292;
	// li r20,0
	r20.s64 = 0;
	// li r23,0
	r23.s64 = 0;
	// li r28,0
	r28.s64 = 0;
	// li r27,0
	r27.s64 = 0;
	// b 0x8219037c
	goto loc_8219037C;
loc_82190040:
	// lwz r31,0(r26)
	r31.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r24,96(r29)
	r24.u64 = PPC_LOAD_U32(r29.u32 + 96);
	// clrlwi r30,r31,20
	r30.u64 = r31.u32 & 0xFFF;
	// mulli r11,r30,12
	r11.s64 = r30.s64 * 12;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// add r21,r11,r24
	r21.u64 = r11.u64 + r24.u64;
	// bl 0x8218e830
	sub_8218E830(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82190328
	if (cr6.getEQ()) goto loc_82190328;
	// lwz r11,-4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + -4);
	// clrlwi r11,r11,20
	r11.u64 = r11.u32 & 0xFFF;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// bne cr6,0x8219009c
	if (!cr6.getEQ()) goto loc_8219009C;
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// rlwinm. r11,r11,0,9,9
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8219009c
	if (!cr0.getEQ()) goto loc_8219009C;
	// rlwinm. r11,r31,0,9,9
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0x400000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r18
	r11.u64 = r18.u64;
	// beq 0x821900a0
	if (cr0.getEQ()) goto loc_821900A0;
loc_8219009C:
	// li r11,0
	r11.s64 = 0;
loc_821900A0:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x821900d8
	if (cr0.getEQ()) goto loc_821900D8;
	// lwz r11,0(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// lwz r10,0(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 0);
	// xor r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 ^ r11.u64;
	// rlwinm. r9,r9,0,21,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x7E0;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x821900d8
	if (!cr0.getEQ()) goto loc_821900D8;
	// xor r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 ^ r11.u64;
	// rlwinm. r9,r9,0,20,20
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x821900d8
	if (!cr0.getEQ()) goto loc_821900D8;
	// xor r11,r10,r11
	r11.u64 = ctx.r10.u64 ^ r11.u64;
	// rlwinm. r11,r11,0,0,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xC0000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r18
	r11.u64 = r18.u64;
	// beq 0x821900dc
	if (cr0.getEQ()) goto loc_821900DC;
loc_821900D8:
	// li r11,0
	r11.s64 = 0;
loc_821900DC:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82190110
	if (cr0.getEQ()) goto loc_82190110;
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// li r10,2
	ctx.r10.s64 = 2;
	// clrlwi r9,r11,20
	ctx.r9.u64 = r11.u32 & 0xFFF;
	// rlwinm r11,r11,16,16,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF;
	// subf r9,r9,r30
	ctx.r9.s64 = r30.s64 - ctx.r9.s64;
	// rlwinm r9,r9,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// slw r10,r10,r9
	ctx.r10.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r10.u32 << (ctx.r9.u8 & 0x3F));
	// and r11,r10,r11
	r11.u64 = ctx.r10.u64 & r11.u64;
	// clrlwi. r11,r11,20
	r11.u64 = r11.u32 & 0xFFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r18
	r11.u64 = r18.u64;
	// beq 0x82190114
	if (cr0.getEQ()) goto loc_82190114;
loc_82190110:
	// li r11,0
	r11.s64 = 0;
loc_82190114:
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// clrlwi r8,r11,24
	ctx.r8.u64 = r11.u32 & 0xFF;
	// rlwinm. r11,r10,1,31,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82190130
	if (!cr0.getEQ()) goto loc_82190130;
	// lwz r10,4(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// rlwinm. r10,r10,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8219016c
	if (cr0.getEQ()) goto loc_8219016C;
loc_82190130:
	// clrlwi. r10,r8,24
	ctx.r10.u64 = ctx.r8.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82190164
	if (cr0.getEQ()) goto loc_82190164;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82190164
	if (cr6.getEQ()) goto loc_82190164;
	// lwz r11,4(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 4);
	// rlwinm. r11,r11,0,0,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82190164
	if (cr0.getEQ()) goto loc_82190164;
	// lwz r11,8(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 8);
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// xor r11,r11,r10
	r11.u64 = r11.u64 ^ ctx.r10.u64;
	// rlwinm. r11,r11,0,0,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r18
	r11.u64 = r18.u64;
	// beq 0x82190168
	if (cr0.getEQ()) goto loc_82190168;
loc_82190164:
	// li r11,0
	r11.s64 = 0;
loc_82190168:
	// clrlwi r8,r11,24
	ctx.r8.u64 = r11.u32 & 0xFF;
loc_8219016C:
	// clrlwi. r11,r8,24
	r11.u64 = ctx.r8.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82190328
	if (cr0.getEQ()) goto loc_82190328;
	// cmplw cr6,r23,r25
	cr6.compare<uint32_t>(r23.u32, r25.u32, xer);
	// beq cr6,0x82190328
	if (cr6.getEQ()) goto loc_82190328;
	// addi r11,r23,8
	r11.s64 = r23.s64 + 8;
	// cmplw cr6,r11,r25
	cr6.compare<uint32_t>(r11.u32, r25.u32, xer);
	// bne cr6,0x821901ac
	if (!cr6.getEQ()) goto loc_821901AC;
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// rlwinm r11,r11,0,16,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF000;
	// cmplwi cr6,r11,4096
	cr6.compare<uint32_t>(r11.u32, 4096, xer);
	// bne cr6,0x821901a4
	if (!cr6.getEQ()) goto loc_821901A4;
	// lwz r11,0(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 0);
	// rlwinm. r11,r11,0,16,16
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x821901ac
	if (!cr0.getEQ()) goto loc_821901AC;
loc_821901A4:
	// mr r11,r18
	r11.u64 = r18.u64;
	// b 0x821901b0
	goto loc_821901B0;
loc_821901AC:
	// li r11,0
	r11.s64 = 0;
loc_821901B0:
	// lwz r6,4(r23)
	ctx.r6.u64 = PPC_LOAD_U32(r23.u32 + 4);
	// clrlwi r8,r11,24
	ctx.r8.u64 = r11.u32 & 0xFF;
	// lwz r5,4(r25)
	ctx.r5.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// rlwinm r11,r6,20,28,31
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 20) & 0xF;
	// rlwinm r9,r5,20,28,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 20) & 0xF;
	// slw r10,r18,r11
	ctx.r10.u64 = r11.u8 & 0x20 ? 0 : (r18.u32 << (r11.u8 & 0x3F));
	// slw r9,r18,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r18.u32 << (ctx.r9.u8 & 0x3F));
	// andi. r11,r10,24600
	r11.u64 = ctx.r10.u64 & 24600;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// andi. r7,r9,24600
	ctx.r7.u64 = ctx.r9.u64 & 24600;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// cntlzw r7,r7
	ctx.r7.u64 = ctx.r7.u32 == 0 ? 32 : __builtin_clz(ctx.r7.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// rlwinm r7,r7,27,31,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// xori r7,r7,1
	ctx.r7.u64 = ctx.r7.u64 ^ 1;
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x821901fc
	if (!cr0.getEQ()) goto loc_821901FC;
	// clrlwi. r4,r7,24
	ctx.r4.u64 = ctx.r7.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq 0x82190238
	if (cr0.getEQ()) goto loc_82190238;
loc_821901FC:
	// clrlwi. r8,r8,24
	ctx.r8.u64 = ctx.r8.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82190230
	if (cr0.getEQ()) goto loc_82190230;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82190230
	if (cr6.getEQ()) goto loc_82190230;
	// clrlwi. r11,r7,24
	r11.u64 = ctx.r7.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82190230
	if (cr0.getEQ()) goto loc_82190230;
	// xor r11,r6,r5
	r11.u64 = ctx.r6.u64 ^ ctx.r5.u64;
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82190230
	if (!cr0.getEQ()) goto loc_82190230;
	// xor r11,r6,r5
	r11.u64 = ctx.r6.u64 ^ ctx.r5.u64;
	// rlwinm. r11,r11,0,22,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x3FC;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r18
	r11.u64 = r18.u64;
	// beq 0x82190234
	if (cr0.getEQ()) goto loc_82190234;
loc_82190230:
	// li r11,0
	r11.s64 = 0;
loc_82190234:
	// clrlwi r8,r11,24
	ctx.r8.u64 = r11.u32 & 0xFF;
loc_82190238:
	// rlwinm r11,r10,0,25,26
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x60;
	// rlwinm r10,r9,0,25,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x60;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// xori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 ^ 1;
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82190268
	if (!cr0.getEQ()) goto loc_82190268;
	// clrlwi. r9,r10,24
	ctx.r9.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x821902ac
	if (cr0.getEQ()) goto loc_821902AC;
loc_82190268:
	// clrlwi. r9,r8,24
	ctx.r9.u64 = ctx.r8.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x821902a4
	if (cr0.getEQ()) goto loc_821902A4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x821902a4
	if (cr6.getEQ()) goto loc_821902A4;
	// clrlwi. r11,r10,24
	r11.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x821902a4
	if (cr0.getEQ()) goto loc_821902A4;
	// xor r11,r6,r5
	r11.u64 = ctx.r6.u64 ^ ctx.r5.u64;
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x821902a4
	if (!cr0.getEQ()) goto loc_821902A4;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x8218c920
	sub_8218C920(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r18
	r11.u64 = r18.u64;
	// bne 0x821902a8
	if (!cr0.getEQ()) goto loc_821902A8;
loc_821902A4:
	// li r11,0
	r11.s64 = 0;
loc_821902A8:
	// clrlwi r8,r11,24
	ctx.r8.u64 = r11.u32 & 0xFF;
loc_821902AC:
	// clrlwi. r11,r8,24
	r11.u64 = ctx.r8.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82190328
	if (cr0.getEQ()) goto loc_82190328;
	// lwz r11,108(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 108);
	// subf r10,r11,r25
	ctx.r10.s64 = r25.s64 - r11.s64;
	// rotlwi r9,r11,0
	ctx.r9.u64 = __builtin_rotateleft32(r11.u32, 0);
	// srawi r7,r10,3
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7) != 0);
	ctx.r7.s64 = ctx.r10.s32 >> 3;
	// lwz r10,112(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 112);
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x82190328
	if (!cr6.getLT()) goto loc_82190328;
	// lwz r10,112(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 112);
	// rotlwi r9,r11,0
	ctx.r9.u64 = __builtin_rotateleft32(r11.u32, 0);
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
loc_821902E8:
	// clrlwi. r9,r8,24
	ctx.r9.u64 = ctx.r8.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82190328
	if (cr0.getEQ()) goto loc_82190328;
	// lwz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r9,r9,20,28,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 20) & 0xF;
	// slw r9,r18,r9
	ctx.r9.u64 = ctx.r9.u8 & 0x20 ? 0 : (r18.u32 << (ctx.r9.u8 & 0x3F));
	// andi. r9,r9,2944
	ctx.r9.u64 = ctx.r9.u64 & 2944;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x8219031c
	if (cr0.getEQ()) goto loc_8219031C;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r9,r9,19
	ctx.r9.u64 = ctx.r9.u32 & 0x1FFF;
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// bne cr6,0x8219031c
	if (!cr6.getEQ()) goto loc_8219031C;
	// li r8,0
	ctx.r8.s64 = 0;
loc_8219031C:
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x821902e8
	if (cr6.getLT()) goto loc_821902E8;
loc_82190328:
	// clrlwi. r11,r20,24
	r11.u64 = r20.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82190354
	if (!cr0.getEQ()) goto loc_82190354;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x8219036c
	if (cr6.getEQ()) goto loc_8219036C;
	// clrlwi. r11,r8,24
	r11.u64 = ctx.r8.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8219036c
	if (cr0.getEQ()) goto loc_8219036C;
	// lwz r11,-4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + -4);
	// mr r20,r18
	r20.u64 = r18.u64;
	// rlwimi r11,r18,20,10,11
	r11.u64 = (__builtin_rotateleft32(r18.u32, 20) & 0x300000) | (r11.u64 & 0xFFFFFFFFFFCFFFFF);
	// stw r11,-4(r26)
	PPC_STORE_U32(r26.u32 + -4, r11.u32);
	// b 0x8219036c
	goto loc_8219036C;
loc_82190354:
	// clrlwi. r11,r8,24
	r11.u64 = ctx.r8.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8219036c
	if (!cr0.getEQ()) goto loc_8219036C;
	// addi r4,r26,-4
	ctx.r4.s64 = r26.s64 + -4;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8218f1e0
	sub_8218F1E0(ctx, base);
	// li r20,0
	r20.s64 = 0;
loc_8219036C:
	// mr r27,r26
	r27.u64 = r26.u64;
	// addi r26,r26,4
	r26.s64 = r26.s64 + 4;
	// mr r23,r25
	r23.u64 = r25.u64;
	// mr r28,r21
	r28.u64 = r21.u64;
loc_8219037C:
	// lwz r11,4(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 4);
	// lwz r10,0(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// cmplw cr6,r26,r11
	cr6.compare<uint32_t>(r26.u32, r11.u32, xer);
	// blt cr6,0x82190040
	if (cr6.getLT()) goto loc_82190040;
	// clrlwi. r11,r20,24
	r11.u64 = r20.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x821903b8
	if (cr0.getEQ()) goto loc_821903B8;
	// lwz r11,4(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 4);
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// bl 0x8218f1e0
	sub_8218F1E0(ctx, base);
loc_821903B8:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r11,19896(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19896);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x821904d8
	if (cr6.getEQ()) goto loc_821904D8;
	// lwz r31,0(r19)
	r31.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// b 0x821903fc
	goto loc_821903FC;
loc_821903D0:
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r6,r11,20,28,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
	// clrlwi r5,r11,24
	ctx.r5.u64 = r11.u32 & 0xFF;
	// lwz r3,19896(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 19896);
	// rlwinm r4,r11,24,28,31
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 24) & 0xF;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
loc_821903FC:
	// lwz r11,4(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 4);
	// lwz r10,0(r19)
	ctx.r10.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// blt cr6,0x821903d0
	if (cr6.getLT()) goto loc_821903D0;
	// lwz r31,0(r22)
	r31.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// b 0x821904c0
	goto loc_821904C0;
loc_8219041C:
	// lwz r11,260(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 260);
	// li r10,12
	ctx.r10.s64 = 12;
	// lwz r9,256(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + 256);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// subf r9,r9,r11
	ctx.r9.s64 = r11.s64 - ctx.r9.s64;
	// clrlwi r11,r8,20
	r11.u64 = ctx.r8.u32 & 0xFFF;
	// divw r30,r9,r10
	r30.s32 = ctx.r9.s32 / ctx.r10.s32;
	// add r4,r11,r30
	ctx.r4.u64 = r11.u64 + r30.u64;
	// bl 0x8218e9a8
	sub_8218E9A8(ctx, base);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r8,r11,0,20,22
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xE00;
	// rlwinm r7,r11,0,23,25
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1C0;
	// rlwinm r6,r11,0,26,28
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x38;
	// add r7,r8,r7
	ctx.r7.u64 = ctx.r8.u64 + ctx.r7.u64;
	// clrlwi r8,r11,29
	ctx.r8.u64 = r11.u32 & 0x7;
	// rlwinm r9,r10,12,30,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0x3;
	// add r11,r7,r6
	r11.u64 = ctx.r7.u64 + ctx.r6.u64;
	// cmplwi cr6,r9,2
	cr6.compare<uint32_t>(ctx.r9.u32, 2, xer);
	// add r6,r11,r8
	ctx.r6.u64 = r11.u64 + ctx.r8.u64;
	// beq cr6,0x82190484
	if (cr6.getEQ()) goto loc_82190484;
	// cmplwi cr6,r9,3
	cr6.compare<uint32_t>(ctx.r9.u32, 3, xer);
	// li r8,0
	ctx.r8.s64 = 0;
	// bne cr6,0x82190488
	if (!cr6.getEQ()) goto loc_82190488;
loc_82190484:
	// mr r8,r18
	ctx.r8.u64 = r18.u64;
loc_82190488:
	// lwz r5,0(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// clrlwi r11,r10,20
	r11.u64 = ctx.r10.u32 & 0xFFF;
	// lwz r4,0(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm r9,r10,24,24,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xF0;
	// rlwinm r7,r10,16,28,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xF;
	// add r7,r9,r7
	ctx.r7.u64 = ctx.r9.u64 + ctx.r7.u64;
	// lwz r3,19896(r5)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r5.u32 + 19896);
	// rlwinm r5,r4,20,26,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 20) & 0x3F;
	// add r4,r11,r30
	ctx.r4.u64 = r11.u64 + r30.u64;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
loc_821904C0:
	// lwz r11,4(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + 4);
	// lwz r10,0(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// blt cr6,0x8219041c
	if (cr6.getLT()) goto loc_8219041C;
loc_821904D8:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed160
	return;
}

__attribute__((alias("__imp__sub_821904E0"))) PPC_WEAK_FUNC(sub_821904E0);
PPC_FUNC_IMPL(__imp__sub_821904E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// li r5,104
	ctx.r5.s64 = 104;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r31,308(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 308);
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,64
	ctx.r5.s64 = 64;
	// li r4,255
	ctx.r4.s64 = 255;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8219057c
	if (cr6.getEQ()) goto loc_8219057C;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
loc_82190530:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// rlwinm r7,r11,24,28,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 24) & 0xF;
	// rlwinm r6,r11,20,28,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
loc_82190540:
	// li r11,1
	r11.s64 = 1;
	// slw r11,r11,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r10.u8 & 0x3F));
	// and. r11,r11,r6
	r11.u64 = r11.u64 & ctx.r6.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82190560
	if (cr0.getEQ()) goto loc_82190560;
	// rlwinm r11,r7,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stbx r9,r11,r4
	PPC_STORE_U8(r11.u32 + ctx.r4.u32, ctx.r9.u8);
loc_82190560:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi cr6,r10,4
	cr6.compare<uint32_t>(ctx.r10.u32, 4, xer);
	// blt cr6,0x82190540
	if (cr6.getLT()) goto loc_82190540;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r9,r31
	cr6.compare<uint32_t>(ctx.r9.u32, r31.u32, xer);
	// blt cr6,0x82190530
	if (cr6.getLT()) goto loc_82190530;
loc_8219057C:
	// lis r11,-32231
	r11.s64 = -2112290816;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// addi r6,r11,-13480
	ctx.r6.s64 = r11.s64 + -13480;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8218ed60
	sub_8218ED60(ctx, base);
	// li r8,0
	ctx.r8.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x821905d4
	if (cr6.getEQ()) goto loc_821905D4;
	// addi r9,r1,152
	ctx.r9.s64 = ctx.r1.s64 + 152;
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
loc_821905B0:
	// lwz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lhz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// addi r9,r9,2
	ctx.r9.s64 = ctx.r9.s64 + 2;
	// rlwimi r6,r8,16,4,15
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r8.u32, 16) & 0xFFF0000) | (ctx.r6.u64 & 0xFFFFFFFFF000FFFF);
	// add r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 + ctx.r8.u64;
	// stw r6,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r6.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x821905b0
	if (!cr0.getEQ()) goto loc_821905B0;
loc_821905D4:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_821905E0"))) PPC_WEAK_FUNC(sub_821905E0);
PPC_FUNC_IMPL(__imp__sub_821905E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r5
	ctx.r3.u64 = ctx.r5.u64;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// lwz r4,112(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// lwz r10,100(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// addi r9,r4,1
	ctx.r9.s64 = ctx.r4.s64 + 1;
	// addi r11,r11,31
	r11.s64 = r11.s64 + 31;
	// rlwinm r26,r9,31,1,31
	r26.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r11,r11,0,0,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFE0;
	// add r10,r10,r26
	ctx.r10.u64 = ctx.r10.u64 + r26.u64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// mulli r27,r10,12
	r27.s64 = ctx.r10.s64 * 12;
	// bne cr6,0x82190640
	if (!cr6.getEQ()) goto loc_82190640;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// b 0x821909cc
	goto loc_821909CC;
loc_82190640:
	// stw r11,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r11.u32);
	// stw r27,4(r24)
	PPC_STORE_U32(r24.u32 + 4, r27.u32);
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// add r11,r10,r27
	r11.u64 = ctx.r10.u64 + r27.u64;
	// lwz r8,12(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// stw r11,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r11.u32);
	// ble cr6,0x8219066c
	if (!cr6.getGT()) goto loc_8219066C;
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
loc_8219066C:
	// lwz r9,8(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// li r29,0
	r29.s64 = 0;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// mr r28,r29
	r28.u64 = r29.u64;
	// bgt cr6,0x82190684
	if (cr6.getGT()) goto loc_82190684;
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
loc_82190684:
	// lwz r6,108(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// mr r30,r28
	r30.u64 = r28.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// li r25,1
	r25.s64 = 1;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82190750
	if (cr6.getEQ()) goto loc_82190750;
loc_8219069C:
	// ld r11,0(r6)
	r11.u64 = PPC_LOAD_U64(ctx.r6.u32 + 0);
	// addi r6,r6,8
	ctx.r6.s64 = ctx.r6.s64 + 8;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r11,r8,20,28,31
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 20) & 0xF;
	// slw r11,r25,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r25.u32 << (r11.u8 & 0x3F));
	// andi. r11,r11,24702
	r11.u64 = r11.u64 & 24702;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x821906d0
	if (cr0.getEQ()) goto loc_821906D0;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// add r5,r11,r26
	ctx.r5.u64 = r11.u64 + r26.u64;
	// rlwimi r5,r11,0,0,19
	ctx.r5.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFF000) | (ctx.r5.u64 & 0xFFFFFFFF00000FFF);
	// b 0x821906d4
	goto loc_821906D4;
loc_821906D0:
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_821906D4:
	// addi r11,r10,1
	r11.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r11,r4
	cr6.compare<uint32_t>(r11.u32, ctx.r4.u32, xer);
	// bge cr6,0x82190714
	if (!cr6.getLT()) goto loc_82190714;
	// ld r11,0(r6)
	r11.u64 = PPC_LOAD_U64(ctx.r6.u32 + 0);
	// addi r6,r6,8
	ctx.r6.s64 = ctx.r6.s64 + 8;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// rlwinm r11,r9,20,28,31
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 20) & 0xF;
	// slw r11,r25,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r25.u32 << (r11.u8 & 0x3F));
	// andi. r11,r11,24702
	r11.u64 = r11.u64 & 24702;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82190720
	if (cr0.getEQ()) goto loc_82190720;
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// add r11,r7,r26
	r11.u64 = ctx.r7.u64 + r26.u64;
	// rlwimi r11,r7,0,0,19
	r11.u64 = (__builtin_rotateleft32(ctx.r7.u32, 0) & 0xFFFFF000) | (r11.u64 & 0xFFFFFFFF00000FFF);
	// b 0x82190724
	goto loc_82190724;
loc_82190714:
	// mr r11,r29
	r11.u64 = r29.u64;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// b 0x82190724
	goto loc_82190724;
loc_82190720:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_82190724:
	// rlwimi r8,r11,16,0,15
	ctx.r8.u64 = (__builtin_rotateleft32(r11.u32, 16) & 0xFFFF0000) | (ctx.r8.u64 & 0xFFFFFFFF0000FFFF);
	// stw r5,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r5.u32);
	// rlwinm r7,r11,16,16,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF;
	// rlwinm r11,r9,16,0,15
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 16) & 0xFFFF0000;
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// or r11,r7,r11
	r11.u64 = ctx.r7.u64 | r11.u64;
	// stw r8,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r8.u32);
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// addi r30,r30,12
	r30.s64 = r30.s64 + 12;
	// blt cr6,0x8219069c
	if (cr6.getLT()) goto loc_8219069C;
loc_82190750:
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,96(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// mulli r5,r11,12
	ctx.r5.s64 = r11.s64 * 12;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// stw r28,256(r31)
	PPC_STORE_U32(r31.u32 + 256, r28.u32);
	// stw r30,260(r31)
	PPC_STORE_U32(r31.u32 + 260, r30.u32);
	// addi r9,r31,340
	ctx.r9.s64 = r31.s64 + 340;
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lis r10,-32231
	ctx.r10.s64 = -2112290816;
	// addi r7,r1,96
	ctx.r7.s64 = ctx.r1.s64 + 96;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r6,r10,-5392
	ctx.r6.s64 = ctx.r10.s64 + -5392;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r11,264(r31)
	PPC_STORE_U32(r31.u32 + 264, r11.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// lwz r10,4(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// lwz r10,8(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r27,4(r24)
	PPC_STORE_U32(r24.u32 + 4, r27.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// rlwinm r11,r11,30,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	// stw r10,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r10.u32);
	// stw r29,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r29.u32);
	// stw r29,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r29.u32);
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r29.u32);
	// stw r29,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r29.u32);
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// bl 0x8218ed60
	sub_8218ED60(ctx, base);
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x821907f8
	if (cr6.getEQ()) goto loc_821907F8;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r25,19952(r11)
	PPC_STORE_U32(r11.u32 + 19952, r25.u32);
loc_821907F8:
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r11,r29
	r11.u64 = r29.u64;
	// stw r10,16(r24)
	PPC_STORE_U32(r24.u32 + 16, ctx.r10.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r10,19892(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 19892);
	// rlwinm. r9,r10,29,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82190824
	if (cr0.getEQ()) goto loc_82190824;
	// rlwinm. r11,r10,30,31,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,2
	r11.s64 = 131072;
	// bne 0x82190824
	if (!cr0.getEQ()) goto loc_82190824;
	// lis r11,4
	r11.s64 = 262144;
loc_82190824:
	// rlwinm. r10,r10,30,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// beq 0x821908b0
	if (cr0.getEQ()) goto loc_821908B0;
	// lwz r10,272(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 272);
	// lwz r8,268(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 268);
	// rlwimi r11,r10,5,22,26
	r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 5) & 0x3E0) | (r11.u64 & 0xFFFFFFFFFFFFFC1F);
	// rlwinm. r10,r11,0,22,26
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x3E0;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8219092c
	if (cr0.getEQ()) goto loc_8219092C;
	// lis r10,-32019
	ctx.r10.s64 = -2098397184;
	// addi r6,r10,27432
	ctx.r6.s64 = ctx.r10.s64 + 27432;
loc_8219084C:
	// lwz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// clrlwi r10,r7,16
	ctx.r10.u64 = ctx.r7.u32 & 0xFFFF;
	// rlwinm r5,r9,12,28,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 12) & 0xF;
	// rlwinm r9,r9,16,28,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 16) & 0xF;
	// lbzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r6.u32);
	// rotlwi r9,r9,10
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 10);
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + r11.u64;
	// rlwimi r9,r11,0,22,14
	ctx.r9.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFFFFFFE03FF) | (ctx.r9.u64 & 0x1FC00);
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
	// slw r9,r25,r5
	ctx.r9.u64 = ctx.r5.u8 & 0x20 ? 0 : (r25.u32 << (ctx.r5.u8 & 0x3F));
	// or r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 | ctx.r10.u64;
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// mr r5,r9
	ctx.r5.u64 = ctx.r9.u64;
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// beq cr6,0x82190898
	if (cr6.getEQ()) goto loc_82190898;
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// mr r7,r9
	ctx.r7.u64 = ctx.r9.u64;
	// rlwimi r10,r11,0,0,26
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFE0) | (ctx.r10.u64 & 0xFFFFFFFF0000001F);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_82190898:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// rlwinm r10,r11,27,27,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1F;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r29,r10
	cr6.compare<uint32_t>(r29.u32, ctx.r10.u32, xer);
	// blt cr6,0x8219084c
	if (cr6.getLT()) goto loc_8219084C;
	// b 0x8219092c
	goto loc_8219092C;
loc_821908B0:
	// lwz r10,308(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 308);
	// lwz r8,304(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 304);
	// rlwimi r11,r10,5,22,26
	r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 5) & 0x3E0) | (r11.u64 & 0xFFFFFFFFFFFFFC1F);
	// rlwinm. r10,r11,0,22,26
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x3E0;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8219092c
	if (cr0.getEQ()) goto loc_8219092C;
	// lis r10,-32019
	ctx.r10.s64 = -2098397184;
	// addi r6,r10,27432
	ctx.r6.s64 = ctx.r10.s64 + 27432;
loc_821908CC:
	// lwz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// clrlwi r10,r7,16
	ctx.r10.u64 = ctx.r7.u32 & 0xFFFF;
	// rlwinm r5,r9,24,28,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 24) & 0xF;
	// rlwinm r9,r9,20,28,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 20) & 0xF;
	// lbzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r6.u32);
	// rotlwi r9,r9,10
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 10);
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + r11.u64;
	// rlwimi r9,r11,0,22,14
	ctx.r9.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFFFFFFE03FF) | (ctx.r9.u64 & 0x1FC00);
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
	// slw r9,r25,r5
	ctx.r9.u64 = ctx.r5.u8 & 0x20 ? 0 : (r25.u32 << (ctx.r5.u8 & 0x3F));
	// or r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 | ctx.r10.u64;
	// clrlwi r9,r9,16
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFF;
	// mr r5,r9
	ctx.r5.u64 = ctx.r9.u64;
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// beq cr6,0x82190918
	if (cr6.getEQ()) goto loc_82190918;
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// mr r7,r9
	ctx.r7.u64 = ctx.r9.u64;
	// rlwimi r10,r11,0,0,26
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFE0) | (ctx.r10.u64 & 0xFFFFFFFF0000001F);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
loc_82190918:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// rlwinm r10,r11,27,27,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1F;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// cmplw cr6,r29,r10
	cr6.compare<uint32_t>(r29.u32, ctx.r10.u32, xer);
	// blt cr6,0x821908cc
	if (cr6.getLT()) goto loc_821908CC;
loc_8219092C:
	// stw r11,20(r24)
	PPC_STORE_U32(r24.u32 + 20, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// rlwinm. r10,r11,30,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8219097c
	if (cr0.getEQ()) goto loc_8219097C;
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm. r11,r11,25,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 25) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82190954
	if (cr0.getEQ()) goto loc_82190954;
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// b 0x8219095c
	goto loc_8219095C;
loc_82190954:
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// rlwinm r11,r11,15,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 15) & 0x1;
loc_8219095C:
	// lwz r10,88(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// lwz r9,336(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 336);
	// rlwimi r10,r11,17,14,14
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 17) & 0x20000) | (ctx.r10.u64 & 0xFFFFFFFFFFFDFFFF);
	// lwz r8,92(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// rlwimi r8,r9,2,28,29
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r9.u32, 2) & 0xC) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFF3);
	// andis. r10,r10,30734
	ctx.r10.u64 = ctx.r10.u64 & 2014183424;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// andi. r11,r8,65294
	r11.u64 = ctx.r8.u64 & 65294;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// b 0x821909c4
	goto loc_821909C4;
loc_8219097C:
	// rlwinm r11,r11,25,7,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 25) & 0x1FFFFFF;
	// not r11,r11
	r11.u64 = ~r11.u64;
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82190994
	if (cr0.getEQ()) goto loc_82190994;
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// b 0x8219099c
	goto loc_8219099C;
loc_82190994:
	// lhz r11,88(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 88);
	// clrlwi r11,r11,31
	r11.u64 = r11.u32 & 0x1;
loc_8219099C:
	// lwz r9,88(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// rlwimi r9,r11,16,15,15
	ctx.r9.u64 = (__builtin_rotateleft32(r11.u32, 16) & 0x10000) | (ctx.r9.u64 & 0xFFFFFFFFFFFEFFFF);
	// andis. r10,r9,34801
	ctx.r10.u64 = ctx.r9.u64 & 2280718336;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x821909b8
	if (cr6.getEQ()) goto loc_821909B8;
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// b 0x821909c0
	goto loc_821909C0;
loc_821909B8:
	// lwz r11,92(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 92);
	// rlwinm r11,r11,14,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 14) & 0x1;
loc_821909C0:
	// rlwinm r11,r11,18,13,13
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 18) & 0x40000;
loc_821909C4:
	// stw r10,8(r24)
	PPC_STORE_U32(r24.u32 + 8, ctx.r10.u32);
	// stw r11,12(r24)
	PPC_STORE_U32(r24.u32 + 12, r11.u32);
loc_821909CC:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_821909D8"))) PPC_WEAK_FUNC(sub_821909D8);
PPC_FUNC_IMPL(__imp__sub_821909D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister r11{};
	// addi r11,r4,2248
	r11.s64 = ctx.r4.s64 + 2248;
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// subfic r8,r4,63
	xer.ca = ctx.r4.u32 <= 63;
	ctx.r8.s64 = 63 - ctx.r4.s64;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mulli r11,r9,9936
	r11.s64 = ctx.r9.s64 * 9936;
	// clrldi r9,r8,32
	ctx.r9.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// li r6,1
	ctx.r6.s64 = 1;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r11,r11,368
	r11.s64 = r11.s64 + 368;
	// addi r8,r11,9208
	ctx.r8.s64 = r11.s64 + 9208;
	// ld r3,9128(r11)
	ctx.r3.u64 = PPC_LOAD_U64(r11.u32 + 9128);
	// stw r7,9564(r11)
	PPC_STORE_U32(r11.u32 + 9564, ctx.r7.u32);
	// sld r4,r6,r9
	ctx.r4.u64 = ctx.r9.u8 & 0x40 ? 0 : (ctx.r6.u64 << (ctx.r9.u8 & 0x7F));
	// rlwinm r9,r10,30,2,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// or r7,r4,r3
	ctx.r7.u64 = ctx.r4.u64 | ctx.r3.u64;
	// std r7,9128(r11)
	PPC_STORE_U64(r11.u32 + 9128, ctx.r7.u64);
	// mr r7,r9
	ctx.r7.u64 = ctx.r9.u64;
	// clrlwi r9,r9,27
	ctx.r9.u64 = ctx.r9.u32 & 0x1F;
	// slw r6,r6,r9
	ctx.r6.u64 = ctx.r9.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r9.u8 & 0x3F));
	// rlwinm r9,r7,29,3,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 29) & 0x1FFFFFFC;
	// lwzx r7,r9,r8
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// or r7,r6,r7
	ctx.r7.u64 = ctx.r6.u64 | ctx.r7.u64;
	// stwx r7,r9,r8
	PPC_STORE_U32(ctx.r9.u32 + ctx.r8.u32, ctx.r7.u32);
	// lbz r9,11(r5)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r5.u32 + 11);
	// lbz r8,7(r5)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r5.u32 + 7);
	// rotlwi r9,r9,8
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 8);
	// lbz r7,3(r5)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r5.u32 + 3);
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
	// rlwinm r9,r9,8,0,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFFFF00;
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82190A60"))) PPC_WEAK_FUNC(sub_82190A60);
PPC_FUNC_IMPL(__imp__sub_82190A60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,304(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 304);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82190a88
	if (cr0.getEQ()) goto loc_82190A88;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// bl 0x8209d060
	sub_8209D060(ctx, base);
loc_82190A88:
	// lwz r3,292(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 292);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82190a9c
	if (cr0.getEQ()) goto loc_82190A9C;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// bl 0x8209d060
	sub_8209D060(ctx, base);
loc_82190A9C:
	// lwz r3,280(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 280);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82190ab0
	if (cr0.getEQ()) goto loc_82190AB0;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// bl 0x8209d060
	sub_8209D060(ctx, base);
loc_82190AB0:
	// lwz r3,268(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 268);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82190ac4
	if (cr0.getEQ()) goto loc_82190AC4;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// bl 0x8209d060
	sub_8209D060(ctx, base);
loc_82190AC4:
	// lwz r3,108(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82190ad8
	if (cr0.getEQ()) goto loc_82190AD8;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// bl 0x8209d060
	sub_8209D060(ctx, base);
loc_82190AD8:
	// lwz r3,96(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82190aec
	if (cr0.getEQ()) goto loc_82190AEC;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// bl 0x8209d060
	sub_8209D060(ctx, base);
loc_82190AEC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82190B00"))) PPC_WEAK_FUNC(sub_82190B00);
PPC_FUNC_IMPL(__imp__sub_82190B00) {
	PPC_FUNC_PROLOGUE();
	// b 0x821909d8
	sub_821909D8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82190B08"))) PPC_WEAK_FUNC(sub_82190B08);
PPC_FUNC_IMPL(__imp__sub_82190B08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// addi r29,r31,16
	r29.s64 = r31.s64 + 16;
	// li r28,2
	r28.s64 = 2;
	// stw r30,19900(r31)
	PPC_STORE_U32(r31.u32 + 19900, r30.u32);
	// stw r30,19892(r31)
	PPC_STORE_U32(r31.u32 + 19892, r30.u32);
loc_82190B2C:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8218fec8
	sub_8218FEC8(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// stw r11,9916(r29)
	PPC_STORE_U32(r29.u32 + 9916, r11.u32);
	// addi r29,r29,9936
	r29.s64 = r29.s64 + 9936;
	// bne 0x82190b2c
	if (!cr0.getEQ()) goto loc_82190B2C;
	// lwz r3,19896(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 19896);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82190b68
	if (cr0.getEQ()) goto loc_82190B68;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r30,19896(r31)
	PPC_STORE_U32(r31.u32 + 19896, r30.u32);
loc_82190B68:
	// li r11,-1
	r11.s64 = -1;
	// stw r30,19904(r31)
	PPC_STORE_U32(r31.u32 + 19904, r30.u32);
	// stw r30,19932(r31)
	PPC_STORE_U32(r31.u32 + 19932, r30.u32);
	// stw r30,19944(r31)
	PPC_STORE_U32(r31.u32 + 19944, r30.u32);
	// stw r30,19952(r31)
	PPC_STORE_U32(r31.u32 + 19952, r30.u32);
	// stw r11,19936(r31)
	PPC_STORE_U32(r31.u32 + 19936, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_82190B88"))) PPC_WEAK_FUNC(sub_82190B88);
PPC_FUNC_IMPL(__imp__sub_82190B88) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-688(r1)
	ea = -688 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r30,r26,20
	r30.s64 = r26.s64 + 20;
	// lwz r8,8(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne 0x82190c08
	if (!cr0.getEQ()) goto loc_82190C08;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x821905e0
	sub_821905E0(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// rlwinm. r11,r11,30,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82190bdc
	if (cr0.getEQ()) goto loc_82190BDC;
	// lwz r11,272(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 272);
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// b 0x82190bfc
	goto loc_82190BFC;
loc_82190BDC:
	// lwz r10,308(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 308);
	// lwz r11,316(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 316);
	// lwz r9,296(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 296);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lwz r10,284(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 284);
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r11,r11,9
	r11.s64 = r11.s64 + 9;
loc_82190BFC:
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// b 0x821913ec
	goto loc_821913EC;
loc_82190C08:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// rlwinm. r11,r11,30,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82190fd4
	if (cr0.getEQ()) goto loc_82190FD4;
	// addi r28,r31,268
	r28.s64 = r31.s64 + 268;
	// lwz r11,268(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 268);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// lwz r7,0(r28)
	ctx.r7.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stw r8,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r8.u32);
	// add r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 + ctx.r7.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x82190cb4
	if (!cr6.getLT()) goto loc_82190CB4;
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// rotlwi r7,r7,0
	ctx.r7.u64 = __builtin_rotateleft32(ctx.r7.u32, 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r7,r10,r7
	ctx.r7.u64 = ctx.r10.u64 + ctx.r7.u64;
loc_82190C54:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r6,r8,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lbz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r5,r1,100
	ctx.r5.s64 = ctx.r1.s64 + 100;
	// rlwinm r3,r10,18,14,31
	ctx.r3.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x3FFFF;
	// rlwinm r29,r10,28,16,19
	r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0xF000;
	// rlwinm r27,r10,0,8,11
	r27.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xF00000;
	// rlwinm r10,r10,17,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 17) & 0x1;
	// rotlwi r4,r8,13
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r8.u32, 13);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// add r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 + ctx.r9.u64;
	// or r10,r4,r8
	ctx.r10.u64 = ctx.r4.u64 | ctx.r8.u64;
	// clrlwi r3,r3,24
	ctx.r3.u64 = ctx.r3.u32 & 0xFF;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwimi r3,r10,1,0,30
	ctx.r3.u64 = (__builtin_rotateleft32(ctx.r10.u32, 1) & 0xFFFFFFFE) | (ctx.r3.u64 & 0xFFFFFFFF00000001);
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// rlwinm r10,r3,10,0,21
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 10) & 0xFFFFFC00;
	// or r10,r10,r29
	ctx.r10.u64 = ctx.r10.u64 | r29.u64;
	// or r10,r10,r27
	ctx.r10.u64 = ctx.r10.u64 | r27.u64;
	// stwx r10,r6,r5
	PPC_STORE_U32(ctx.r6.u32 + ctx.r5.u32, ctx.r10.u32);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r8,r10,1
	ctx.r8.s64 = ctx.r10.s64 + 1;
	// stw r8,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r8.u32);
	// blt cr6,0x82190c54
	if (cr6.getLT()) goto loc_82190C54;
loc_82190CB4:
	// lwz r11,272(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 272);
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bne cr6,0x82190cc8
	if (!cr6.getEQ()) goto loc_82190CC8;
	// li r11,0
	r11.s64 = 0;
	// b 0x82190cd8
	goto loc_82190CD8;
loc_82190CC8:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq cr6,0x82190cd8
	if (cr6.getEQ()) goto loc_82190CD8;
	// li r11,2
	r11.s64 = 2;
loc_82190CD8:
	// stw r11,336(r31)
	PPC_STORE_U32(r31.u32 + 336, r11.u32);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r11,r10,32
	r11.s64 = ctx.r10.s64 + 32;
	// lwz r8,12(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// ble cr6,0x82190d00
	if (!cr6.getGT()) goto loc_82190D00;
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
loc_82190D00:
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// li r29,0
	r29.s64 = 0;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x82190d14
	if (cr6.getGT()) goto loc_82190D14;
	// mr r29,r10
	r29.u64 = ctx.r10.u64;
loc_82190D14:
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821905e0
	sub_821905E0(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// rlwinm r4,r11,29,31,31
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0x1;
	// bl 0x8218e550
	sub_8218E550(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82190d50
	if (!cr0.getEQ()) goto loc_82190D50;
	// lis r11,-30602
	r11.s64 = -2005532672;
	// ori r11,r11,2945
	r11.u64 = r11.u64 | 2945;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
	// b 0x821913ec
	goto loc_821913EC;
loc_82190D50:
	// lwz r11,272(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 272);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r8,12(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// ble cr6,0x82190d7c
	if (!cr6.getGT()) goto loc_82190D7C;
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
loc_82190D7C:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x82190d90
	if (!cr6.getGT()) goto loc_82190D90;
	// li r9,0
	ctx.r9.s64 = 0;
loc_82190D90:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r11,272(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 272);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r7,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r7.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82190e30
	if (!cr6.getGT()) goto loc_82190E30;
	// addi r6,r1,100
	ctx.r6.s64 = ctx.r1.s64 + 100;
loc_82190DB8:
	// lwz r11,0(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// mr r7,r11
	ctx.r7.u64 = r11.u64;
	// rlwimi r10,r11,16,16,31
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 16) & 0xFFFF) | (ctx.r10.u64 & 0xFFFFFFFFFFFF0000);
	// rlwimi r7,r10,24,20,31
	ctx.r7.u64 = (__builtin_rotateleft32(ctx.r10.u32, 24) & 0xFFF) | (ctx.r7.u64 & 0xFFFFFFFFFFFFF000);
	// clrlwi r7,r7,16
	ctx.r7.u64 = ctx.r7.u32 & 0xFFFF;
	// rlwinm r10,r7,24,28,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 24) & 0xF;
	// cmplw cr6,r10,r5
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r5.u32, xer);
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// ble cr6,0x82190de4
	if (!cr6.getGT()) goto loc_82190DE4;
	// mr r5,r10
	ctx.r5.u64 = ctx.r10.u64;
loc_82190DE4:
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplw cr6,r10,r7
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r7.u32, xer);
	// ble cr6,0x82190df8
	if (!cr6.getGT()) goto loc_82190DF8;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// stw r7,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r7.u32);
loc_82190DF8:
	// not r27,r11
	r27.u64 = ~r11.u64;
	// lwz r30,272(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 272);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm r27,r27,21,31,31
	r27.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 21) & 0x1;
	// rlwinm r11,r11,22,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 22) & 0x1;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// cmplw cr6,r8,r30
	cr6.compare<uint32_t>(ctx.r8.u32, r30.u32, xer);
	// slw r27,r27,r10
	r27.u64 = ctx.r10.u8 & 0x20 ? 0 : (r27.u32 << (ctx.r10.u8 & 0x3F));
	// slw r11,r11,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r10.u8 & 0x3F));
	// or r4,r27,r4
	ctx.r4.u64 = r27.u64 | ctx.r4.u64;
	// or r3,r11,r3
	ctx.r3.u64 = r11.u64 | ctx.r3.u64;
	// blt cr6,0x82190db8
	if (cr6.getLT()) goto loc_82190DB8;
loc_82190E30:
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// rlwinm r10,r11,13,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 13) & 0x1;
	// rlwinm r11,r11,14,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 14) & 0x1;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// add r11,r11,r5
	r11.u64 = r11.u64 + ctx.r5.u64;
	// cmplwi cr6,r11,15
	cr6.compare<uint32_t>(r11.u32, 15, xer);
	// ble cr6,0x82190e50
	if (!cr6.getGT()) goto loc_82190E50;
	// li r11,15
	r11.s64 = 15;
loc_82190E50:
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// ble cr6,0x82190e5c
	if (!cr6.getGT()) goto loc_82190E5C;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
loc_82190E5C:
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r1,368
	ctx.r3.s64 = ctx.r1.s64 + 368;
	// sth r11,24(r29)
	PPC_STORE_U16(r29.u32 + 24, r11.u16);
	// sth r10,26(r29)
	PPC_STORE_U16(r29.u32 + 26, ctx.r10.u16);
	// bl 0x8218c630
	sub_8218C630(ctx, base);
	// lis r11,-32231
	r11.s64 = -2112290816;
	// addi r7,r1,368
	ctx.r7.s64 = ctx.r1.s64 + 368;
	// addi r6,r11,-14720
	ctx.r6.s64 = r11.s64 + -14720;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218ed60
	sub_8218ED60(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r3,19896(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19896);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82190eb8
	if (cr0.getEQ()) goto loc_82190EB8;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r4,r1,368
	ctx.r4.s64 = ctx.r1.s64 + 368;
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82190EB8:
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// rlwinm. r11,r11,24,26,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 24) & 0x3F;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82190ecc
	if (cr0.getEQ()) goto loc_82190ECC;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// b 0x82190ee8
	goto loc_82190EE8;
loc_82190ECC:
	// lis r11,-32231
	r11.s64 = -2112290816;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// addi r6,r11,-14320
	ctx.r6.s64 = r11.s64 + -14320;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218ed60
	sub_8218ED60(ctx, base);
loc_82190EE8:
	// lwz r10,8(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lis r11,-32231
	r11.s64 = -2112290816;
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// addi r6,r11,-13280
	ctx.r6.s64 = r11.s64 + -13280;
	// rlwimi r10,r9,8,18,23
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 8) & 0x3F00) | (ctx.r10.u64 & 0xFFFFFFFFFFFFC0FF);
	// li r11,0
	r11.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,8(r29)
	PPC_STORE_U32(r29.u32 + 8, ctx.r10.u32);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// bl 0x8218ed60
	sub_8218ED60(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,28(r29)
	PPC_STORE_U32(r29.u32 + 28, r11.u32);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm. r9,r11,0,28,28
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82190f3c
	if (cr0.getEQ()) goto loc_82190F3C;
	// li r10,4
	ctx.r10.s64 = 4;
	// b 0x82190f58
	goto loc_82190F58;
loc_82190F3C:
	// rlwinm. r9,r11,0,29,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82190f4c
	if (cr0.getEQ()) goto loc_82190F4C;
	// li r10,3
	ctx.r10.s64 = 3;
	// b 0x82190f58
	goto loc_82190F58;
loc_82190F4C:
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82190f58
	if (cr0.getEQ()) goto loc_82190F58;
	// li r10,2
	ctx.r10.s64 = 2;
loc_82190F58:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwimi r11,r10,28,1,3
	r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 28) & 0x70000000) | (r11.u64 & 0xFFFFFFFF8FFFFFFF);
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// stw r11,8(r29)
	PPC_STORE_U32(r29.u32 + 8, r11.u32);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwimi r10,r11,23,4,4
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 23) & 0x8000000) | (ctx.r10.u64 & 0xFFFFFFFFF7FFFFFF);
	// stw r10,8(r29)
	PPC_STORE_U32(r29.u32 + 8, ctx.r10.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,19896(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19896);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x821913d0
	if (cr6.getEQ()) goto loc_821913D0;
	// lwz r30,0(r28)
	r30.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// b 0x82190fb8
	goto loc_82190FB8;
loc_82190F8C:
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lbz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// rlwinm r6,r11,16,28,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xF;
	// rlwinm r4,r11,12,28,31
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 12) & 0xF;
	// lwz r3,19896(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 19896);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
loc_82190FB8:
	// lwz r11,4(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// lwz r10,0(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x82190f8c
	if (cr6.getLT()) goto loc_82190F8C;
	// b 0x821913d0
	goto loc_821913D0;
loc_82190FD4:
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r11,r10,36
	r11.s64 = ctx.r10.s64 + 36;
	// lwz r7,12(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// ble cr6,0x82190ff8
	if (!cr6.getGT()) goto loc_82190FF8;
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
loc_82190FF8:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r27,0
	r27.s64 = 0;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bgt cr6,0x8219100c
	if (cr6.getGT()) goto loc_8219100C;
	// mr r27,r10
	r27.u64 = ctx.r10.u64;
loc_8219100C:
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821905e0
	sub_821905E0(ctx, base);
	// lwz r11,284(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 284);
	// stw r11,24(r27)
	PPC_STORE_U32(r27.u32 + 24, r11.u32);
	// lwz r11,296(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 296);
	// stw r11,28(r27)
	PPC_STORE_U32(r27.u32 + 28, r11.u32);
	// lwz r11,316(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 316);
	// stw r11,32(r27)
	PPC_STORE_U32(r27.u32 + 32, r11.u32);
	// lwz r10,284(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 284);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r5,r10,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r9,12(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r3,r10,r11
	ctx.r3.u64 = ctx.r10.u64 + r11.u64;
	// add r11,r11,r5
	r11.u64 = r11.u64 + ctx.r5.u64;
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// ble cr6,0x82191060
	if (!cr6.getGT()) goto loc_82191060;
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
loc_82191060:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x82191074
	if (!cr6.getGT()) goto loc_82191074;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82191074:
	// lwz r4,280(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 280);
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lwz r11,296(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 296);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r8,12(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// ble cr6,0x821910a8
	if (!cr6.getGT()) goto loc_821910A8;
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
loc_821910A8:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x821910bc
	if (!cr6.getGT()) goto loc_821910BC;
	// li r9,0
	ctx.r9.s64 = 0;
loc_821910BC:
	// lwz r6,256(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 256);
	// li r7,12
	ctx.r7.s64 = 12;
	// lwz r8,260(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 260);
	// addi r10,r31,292
	ctx.r10.s64 = r31.s64 + 292;
	// lwz r11,292(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 292);
	// subf r8,r6,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r6.s64;
	// divw r6,r8,r7
	ctx.r6.s32 = ctx.r8.s32 / ctx.r7.s32;
	// b 0x821910f4
	goto loc_821910F4;
loc_821910DC:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// add r7,r8,r6
	ctx.r7.u64 = ctx.r8.u64 + ctx.r6.u64;
	// rlwimi r7,r8,0,0,19
	ctx.r7.u64 = (__builtin_rotateleft32(ctx.r8.u32, 0) & 0xFFFFF000) | (ctx.r7.u64 & 0xFFFFFFFF00000FFF);
	// stw r7,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, ctx.r7.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
loc_821910F4:
	// lwz r8,4(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x821910dc
	if (cr6.getLT()) goto loc_821910DC;
	// lwz r11,304(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 304);
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r10,308(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 308);
	// rotlwi r8,r11,0
	ctx.r8.u64 = __builtin_rotateleft32(r11.u32, 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stw r9,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r9.u32);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x8219117c
	if (!cr6.getLT()) goto loc_8219117C;
	// lwz r10,308(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 308);
	// rotlwi r8,r11,0
	ctx.r8.u64 = __builtin_rotateleft32(r11.u32, 0);
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r10,r8
	ctx.r8.u64 = ctx.r10.u64 + ctx.r8.u64;
loc_82191140:
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r7,r1,180
	ctx.r7.s64 = ctx.r1.s64 + 180;
	// mr r6,r10
	ctx.r6.u64 = ctx.r10.u64;
	// rlwinm r5,r10,0,16,19
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xF000;
	// rlwimi r6,r10,12,0,19
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r10.u32, 12) & 0xFFFFF000) | (ctx.r6.u64 & 0xFFFFFFFF00000FFF);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// rlwinm r10,r6,12,0,11
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 12) & 0xFFF00000;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// or r10,r10,r5
	ctx.r10.u64 = ctx.r10.u64 | ctx.r5.u64;
	// stwx r10,r9,r7
	PPC_STORE_U32(ctx.r9.u32 + ctx.r7.u32, ctx.r10.u32);
	// lwz r10,176(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	// addi r9,r10,1
	ctx.r9.s64 = ctx.r10.s64 + 1;
	// stw r9,176(r1)
	PPC_STORE_U32(ctx.r1.u32 + 176, ctx.r9.u32);
	// blt cr6,0x82191140
	if (cr6.getLT()) goto loc_82191140;
loc_8219117C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// rlwinm r4,r11,29,31,31
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0x1;
	// bl 0x8218e550
	sub_8218E550(ctx, base);
	// lwz r11,308(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 308);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r8,12(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// ble cr6,0x821911bc
	if (!cr6.getGT()) goto loc_821911BC;
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
loc_821911BC:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r29,0
	r29.s64 = 0;
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x821911d4
	if (cr6.getGT()) goto loc_821911D4;
	// mr r29,r10
	r29.u64 = ctx.r10.u64;
loc_821911D4:
	// lwz r11,308(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 308);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82191220
	if (!cr6.getGT()) goto loc_82191220;
	// addi r8,r1,180
	ctx.r8.s64 = ctx.r1.s64 + 180;
loc_821911EC:
	// lwz r11,0(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// mr r7,r11
	ctx.r7.u64 = r11.u64;
	// mr r6,r11
	ctx.r6.u64 = r11.u64;
	// rlwimi r7,r11,16,16,31
	ctx.r7.u64 = (__builtin_rotateleft32(r11.u32, 16) & 0xFFFF) | (ctx.r7.u64 & 0xFFFFFFFFFFFF0000);
	// rlwimi r6,r7,24,20,31
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r7.u32, 24) & 0xFFF) | (ctx.r6.u64 & 0xFFFFFFFFFFFFF000);
	// clrlwi r11,r6,16
	r11.u64 = ctx.r6.u32 & 0xFFFF;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lwz r11,308(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 308);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x821911ec
	if (cr6.getLT()) goto loc_821911EC;
loc_82191220:
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// addi r3,r1,368
	ctx.r3.s64 = ctx.r1.s64 + 368;
	// bl 0x8218c630
	sub_8218C630(ctx, base);
	// lis r11,-32231
	r11.s64 = -2112290816;
	// addi r7,r1,368
	ctx.r7.s64 = ctx.r1.s64 + 368;
	// addi r6,r11,-14368
	ctx.r6.s64 = r11.s64 + -14368;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218ed60
	sub_8218ED60(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x821904e0
	sub_821904E0(ctx, base);
	// lwz r11,316(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 316);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r8,12(r30)
	ctx.r8.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
	// ble cr6,0x82191280
	if (!cr6.getGT()) goto loc_82191280;
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
loc_82191280:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r28,0
	r28.s64 = 0;
	// lwz r9,8(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmplw cr6,r11,r9
	cr6.compare<uint32_t>(r11.u32, ctx.r9.u32, xer);
	// bgt cr6,0x82191298
	if (cr6.getGT()) goto loc_82191298;
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
loc_82191298:
	// li r5,112
	ctx.r5.s64 = 112;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,256
	ctx.r3.s64 = ctx.r1.s64 + 256;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,64
	ctx.r5.s64 = 64;
	// li r4,255
	ctx.r4.s64 = 255;
	// addi r3,r1,272
	ctx.r3.s64 = ctx.r1.s64 + 272;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// lwz r30,308(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 308);
	// lwz r11,316(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 316);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r29,256(r1)
	PPC_STORE_U32(ctx.r1.u32 + 256, r29.u32);
	// cmplwi r30,0
	cr0.compare<uint32_t>(r30.u32, 0, xer);
	// stw r28,264(r1)
	PPC_STORE_U32(ctx.r1.u32 + 264, r28.u32);
	// stw r30,260(r1)
	PPC_STORE_U32(ctx.r1.u32 + 260, r30.u32);
	// stw r11,268(r1)
	PPC_STORE_U32(ctx.r1.u32 + 268, r11.u32);
	// beq 0x8219132c
	if (cr0.getEQ()) goto loc_8219132C;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
loc_821912E0:
	// lwz r11,0(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// rlwinm r8,r11,24,28,31
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 24) & 0xF;
	// rlwinm r6,r11,20,28,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
loc_821912F0:
	// li r11,1
	r11.s64 = 1;
	// slw r11,r11,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r10.u8 & 0x3F));
	// and. r11,r11,r6
	r11.u64 = r11.u64 & ctx.r6.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82191310
	if (cr0.getEQ()) goto loc_82191310;
	// rlwinm r11,r8,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r4,r1,272
	ctx.r4.s64 = ctx.r1.s64 + 272;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stbx r9,r11,r4
	PPC_STORE_U8(r11.u32 + ctx.r4.u32, ctx.r9.u8);
loc_82191310:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplwi cr6,r10,4
	cr6.compare<uint32_t>(ctx.r10.u32, 4, xer);
	// blt cr6,0x821912f0
	if (cr6.getLT()) goto loc_821912F0;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r7,r7,4
	ctx.r7.s64 = ctx.r7.s64 + 4;
	// cmplw cr6,r9,r30
	cr6.compare<uint32_t>(ctx.r9.u32, r30.u32, xer);
	// blt cr6,0x821912e0
	if (cr6.getLT()) goto loc_821912E0;
loc_8219132C:
	// lis r11,-32231
	r11.s64 = -2112290816;
	// addi r7,r1,256
	ctx.r7.s64 = ctx.r1.s64 + 256;
	// addi r6,r11,-13688
	ctx.r6.s64 = r11.s64 + -13688;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218ed60
	sub_8218ED60(ctx, base);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82191394
	if (cr6.getEQ()) goto loc_82191394;
	// addi r9,r1,336
	ctx.r9.s64 = ctx.r1.s64 + 336;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// mr r11,r30
	r11.u64 = r30.u64;
loc_8219135C:
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// lhz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// addi r9,r9,2
	ctx.r9.s64 = ctx.r9.s64 + 2;
	// lhz r8,0(r8)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r8.u32 + 0);
	// clrlwi r8,r8,20
	ctx.r8.u64 = ctx.r8.u32 & 0xFFF;
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r8,r28
	ctx.r8.u64 = ctx.r8.u64 + r28.u64;
	// lwz r7,-4(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + -4);
	// ori r7,r7,4096
	ctx.r7.u64 = ctx.r7.u64 | 4096;
	// stw r7,-4(r8)
	PPC_STORE_U32(ctx.r8.u32 + -4, ctx.r7.u32);
	// bne 0x8219135c
	if (!cr0.getEQ()) goto loc_8219135C;
loc_82191394:
	// lwz r11,88(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// clrlwi. r11,r11,26
	r11.u64 = r11.u32 & 0x3F;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// bne 0x821913c4
	if (!cr0.getEQ()) goto loc_821913C4;
	// lis r11,-32231
	r11.s64 = -2112290816;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// addi r6,r11,-14320
	ctx.r6.s64 = r11.s64 + -14320;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218ed60
	sub_8218ED60(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_821913C4:
	// lwz r10,8(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// rlwimi r10,r11,0,26,31
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0x3F) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFC0);
	// stw r10,8(r27)
	PPC_STORE_U32(r27.u32 + 8, ctx.r10.u32);
loc_821913D0:
	// lis r11,-32231
	r11.s64 = -2112290816;
	// lwz r7,256(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 256);
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r6,r11,-13896
	ctx.r6.s64 = r11.s64 + -13896;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218ed60
	sub_8218ED60(ctx, base);
loc_821913EC:
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82191408
	if (cr0.getLT()) goto loc_82191408;
	// lwz r3,16(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82191408
	if (cr0.getLT()) goto loc_82191408;
	// lwz r3,36(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + 36);
loc_82191408:
	// addi r1,r1,688
	ctx.r1.s64 = ctx.r1.s64 + 688;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_82191410"))) PPC_WEAK_FUNC(sub_82191410);
PPC_FUNC_IMPL(__imp__sub_82191410) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r28,1
	r28.s64 = 1;
	// li r30,0
	r30.s64 = 0;
	// addi r31,r29,9932
	r31.s64 = r29.s64 + 9932;
	// stw r28,19888(r29)
	PPC_STORE_U32(r29.u32 + 19888, r28.u32);
loc_82191430:
	// addi r3,r31,-9916
	ctx.r3.s64 = r31.s64 + -9916;
	// bl 0x8218fec8
	sub_8218FEC8(ctx, base);
	// cntlzw r11,r30
	r11.u64 = r30.u32 == 0 ? 32 : __builtin_clz(r30.u32);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// stw r28,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r28.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// cmplwi cr6,r30,2
	cr6.compare<uint32_t>(r30.u32, 2, xer);
	// stw r11,-4(r31)
	PPC_STORE_U32(r31.u32 + -4, r11.u32);
	// addi r31,r31,9936
	r31.s64 = r31.s64 + 9936;
	// blt cr6,0x82191430
	if (cr6.getLT()) goto loc_82191430;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82190b08
	sub_82190B08(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_82191468"))) PPC_WEAK_FUNC(sub_82191468);
PPC_FUNC_IMPL(__imp__sub_82191468) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,19896(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 19896);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x821914a4
	if (cr0.getEQ()) goto loc_821914A4;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r11,19896(r31)
	PPC_STORE_U32(r31.u32 + 19896, r11.u32);
loc_821914A4:
	// lwz r3,19940(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 19940);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x821914b8
	if (cr0.getEQ()) goto loc_821914B8;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// bl 0x8209d060
	sub_8209D060(ctx, base);
loc_821914B8:
	// lwz r3,19920(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 19920);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x821914cc
	if (cr0.getEQ()) goto loc_821914CC;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// bl 0x8209d060
	sub_8209D060(ctx, base);
loc_821914CC:
	// lwz r3,19908(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 19908);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x821914e0
	if (cr0.getEQ()) goto loc_821914E0;
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// bl 0x8209d060
	sub_8209D060(ctx, base);
loc_821914E0:
	// addi r31,r31,19888
	r31.s64 = r31.s64 + 19888;
	// li r30,1
	r30.s64 = 1;
loc_821914E8:
	// addi r31,r31,-9936
	r31.s64 = r31.s64 + -9936;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82190a60
	sub_82190A60(ctx, base);
	// addic. r30,r30,-1
	xer.ca = r30.u32 > 0;
	r30.s64 = r30.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bge 0x821914e8
	if (!cr0.getLT()) goto loc_821914E8;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82191518"))) PPC_WEAK_FUNC(sub_82191518);
PPC_FUNC_IMPL(__imp__sub_82191518) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed12c
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// lwz r3,19900(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 19900);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x821916fc
	if (cr0.getLT()) goto loc_821916FC;
	// lwz r11,19904(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 19904);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82191550
	if (!cr6.getEQ()) goto loc_82191550;
	// lis r3,-32768
	ctx.r3.s64 = -2147483648;
	// ori r3,r3,16389
	ctx.r3.u64 = ctx.r3.u64 | 16389;
	// b 0x821916fc
	goto loc_821916FC;
loc_82191550:
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// lwz r10,19892(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 19892);
	// li r29,0
	r29.s64 = 0;
	// lis r9,4138
	ctx.r9.s64 = 271187968;
	// addi r31,r26,20
	r31.s64 = r26.s64 + 20;
	// ori r8,r9,4352
	ctx.r8.u64 = ctx.r9.u64 | 4352;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// std r29,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r29.u64);
	// rlwinm r10,r10,26,6,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 26) & 0x3FFFFFF;
	// std r29,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r29.u64);
	// li r5,36
	ctx.r5.s64 = 36;
	// std r29,16(r11)
	PPC_STORE_U64(r11.u32 + 16, r29.u64);
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// std r29,24(r11)
	PPC_STORE_U64(r11.u32 + 24, r29.u64);
	// stw r29,32(r11)
	PPC_STORE_U32(r11.u32 + 32, r29.u32);
	// rlwimi r8,r10,5,26,26
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r10.u32, 5) & 0x20) | (ctx.r8.u64 & 0xFFFFFFFFFFFFFFDF);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm r10,r9,30,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x1;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r25,4(r31)
	r25.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// or r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 | ctx.r10.u64;
	// andi. r11,r11,222
	r11.u64 = r11.u64 & 222;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// lwz r11,19924(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 19924);
	// rlwinm. r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x821915e4
	if (cr0.getEQ()) goto loc_821915E4;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r4,19920(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 19920);
	// subf r11,r25,r11
	r11.s64 = r11.s64 - r25.s64;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
	// bl 0x8218c530
	sub_8218C530(ctx, base);
loc_821915E4:
	// lwz r11,19912(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 19912);
	// rlwinm. r28,r11,2,0,29
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x82191620
	if (cr0.getEQ()) goto loc_82191620;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r5,4
	ctx.r5.s64 = 4;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r28,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r28.u32);
	// subf r11,r25,r11
	r11.s64 = r11.s64 - r25.s64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lwz r4,19908(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 19908);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218c530
	sub_8218C530(ctx, base);
loc_82191620:
	// addi r27,r1,116
	r27.s64 = ctx.r1.s64 + 116;
	// addi r28,r30,368
	r28.s64 = r30.s64 + 368;
loc_82191628:
	// lwz r11,9564(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 9564);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82191654
	if (!cr6.getEQ()) goto loc_82191654;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
	// bl 0x8218fa68
	sub_8218FA68(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82191654
	if (!cr0.getLT()) goto loc_82191654;
	// stw r3,19900(r30)
	PPC_STORE_U32(r30.u32 + 19900, ctx.r3.u32);
loc_82191654:
	// lwz r11,-240(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -240);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8219168c
	if (cr6.getEQ()) goto loc_8219168C;
	// cntlzw r11,r29
	r11.u64 = r29.u32 == 0 ? 32 : __builtin_clz(r29.u32);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// addi r3,r28,-352
	ctx.r3.s64 = r28.s64 + -352;
	// xori r5,r11,1
	ctx.r5.u64 = r11.u64 ^ 1;
	// stw r10,4(r27)
	PPC_STORE_U32(r27.u32 + 4, ctx.r10.u32);
	// bl 0x82190b88
	sub_82190B88(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x8219168c
	if (!cr0.getLT()) goto loc_8219168C;
	// stw r3,19900(r30)
	PPC_STORE_U32(r30.u32 + 19900, ctx.r3.u32);
loc_8219168C:
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r27,r27,8
	r27.s64 = r27.s64 + 8;
	// addi r28,r28,9936
	r28.s64 = r28.s64 + 9936;
	// cmplwi cr6,r29,2
	cr6.compare<uint32_t>(r29.u32, 2, xer);
	// blt cr6,0x82191628
	if (cr6.getLT()) goto loc_82191628;
	// lwz r11,19952(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 19952);
	// li r5,36
	ctx.r5.s64 = 36;
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r9,12(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 12);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwimi r10,r11,4,27,27
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 4) & 0x10) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFEF);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// lwz r29,4(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// stw r25,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r25.u32);
	// stw r9,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r9.u32);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// bl 0x8218c530
	sub_8218C530(ctx, base);
	// stw r29,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r29.u32);
	// lwz r11,16(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 16);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// blt 0x821916f4
	if (cr0.getLT()) goto loc_821916F4;
	// lwz r11,36(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 36);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bge 0x821916f8
	if (!cr0.getLT()) goto loc_821916F8;
loc_821916F4:
	// stw r11,19900(r30)
	PPC_STORE_U32(r30.u32 + 19900, r11.u32);
loc_821916F8:
	// lwz r3,19900(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 19900);
loc_821916FC:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_82191708"))) PPC_WEAK_FUNC(sub_82191708);
PPC_FUNC_IMPL(__imp__sub_82191708) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r4,25728
	ctx.r4.s64 = 1686110208;
	// li r3,19968
	ctx.r3.s64 = 19968;
	// bl 0x8209d000
	sub_8209D000(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x82191734
	if (!cr0.getEQ()) goto loc_82191734;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82191740
	goto loc_82191740;
loc_82191734:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82191410
	sub_82191410(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82191740:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82191758"))) PPC_WEAK_FUNC(sub_82191758);
PPC_FUNC_IMPL(__imp__sub_82191758) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r4,r11,1
	ctx.r4.s64 = r11.s64 + 1;
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// ble cr6,0x82191788
	if (!cr6.getGT()) goto loc_82191788;
	// bl 0x8218f670
	sub_8218F670(ctx, base);
loc_82191788:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x821917c8
	if (cr6.getLT()) goto loc_821917C8;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_821917C8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_821917D0"))) PPC_WEAK_FUNC(sub_821917D0);
PPC_FUNC_IMPL(__imp__sub_821917D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r4,r11,1
	ctx.r4.s64 = r11.s64 + 1;
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// ble cr6,0x82191800
	if (!cr6.getGT()) goto loc_82191800;
	// bl 0x8218f700
	sub_8218F700(ctx, base);
loc_82191800:
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x82191838
	if (cr6.getLT()) goto loc_82191838;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,3,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_82191838:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82191840"))) PPC_WEAK_FUNC(sub_82191840);
PPC_FUNC_IMPL(__imp__sub_82191840) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r4,r11,1
	ctx.r4.s64 = r11.s64 + 1;
	// cmplw cr6,r4,r10
	cr6.compare<uint32_t>(ctx.r4.u32, ctx.r10.u32, xer);
	// ble cr6,0x82191870
	if (!cr6.getGT()) goto loc_82191870;
	// bl 0x8218f790
	sub_8218F790(ctx, base);
loc_82191870:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x8219189c
	if (cr6.getLT()) goto loc_8219189C;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r10,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r10.u32);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_8219189C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_821918A8"))) PPC_WEAK_FUNC(sub_821918A8);
PPC_FUNC_IMPL(__imp__sub_821918A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// bl 0x8218fec8
	sub_8218FEC8(ctx, base);
	// addi r3,r31,96
	ctx.r3.s64 = r31.s64 + 96;
	// stw r29,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r29.u32);
	// li r30,0
	r30.s64 = 0;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r30.u32);
	// cmplwi cr6,r11,100
	cr6.compare<uint32_t>(r11.u32, 100, xer);
	// bge cr6,0x821918e8
	if (!cr6.getLT()) goto loc_821918E8;
	// addi r5,r31,80
	ctx.r5.s64 = r31.s64 + 80;
	// li r4,100
	ctx.r4.s64 = 100;
	// bl 0x8218f670
	sub_8218F670(ctx, base);
loc_821918E8:
	// addi r3,r31,108
	ctx.r3.s64 = r31.s64 + 108;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r30.u32);
	// cmplwi cr6,r11,50
	cr6.compare<uint32_t>(r11.u32, 50, xer);
	// bge cr6,0x82191908
	if (!cr6.getLT()) goto loc_82191908;
	// addi r5,r31,80
	ctx.r5.s64 = r31.s64 + 80;
	// li r4,50
	ctx.r4.s64 = 50;
	// bl 0x8218f700
	sub_8218F700(ctx, base);
loc_82191908:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// rlwinm. r11,r11,30,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8219193c
	if (cr0.getEQ()) goto loc_8219193C;
	// addi r3,r31,268
	ctx.r3.s64 = r31.s64 + 268;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r30.u32);
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// bge cr6,0x8219199c
	if (!cr6.getLT()) goto loc_8219199C;
	// addi r5,r31,80
	ctx.r5.s64 = r31.s64 + 80;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x8218f790
	sub_8218F790(ctx, base);
	// b 0x8219199c
	goto loc_8219199C;
loc_8219193C:
	// addi r3,r31,280
	ctx.r3.s64 = r31.s64 + 280;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r30.u32);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bge cr6,0x8219195c
	if (!cr6.getLT()) goto loc_8219195C;
	// addi r5,r31,80
	ctx.r5.s64 = r31.s64 + 80;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8218f790
	sub_8218F790(ctx, base);
loc_8219195C:
	// addi r3,r31,292
	ctx.r3.s64 = r31.s64 + 292;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r30.u32);
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// bge cr6,0x8219197c
	if (!cr6.getLT()) goto loc_8219197C;
	// addi r5,r31,80
	ctx.r5.s64 = r31.s64 + 80;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x8218f790
	sub_8218F790(ctx, base);
loc_8219197C:
	// addi r3,r31,304
	ctx.r3.s64 = r31.s64 + 304;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// stw r30,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, r30.u32);
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// bge cr6,0x8219199c
	if (!cr6.getLT()) goto loc_8219199C;
	// addi r5,r31,80
	ctx.r5.s64 = r31.s64 + 80;
	// li r4,16
	ctx.r4.s64 = 16;
	// bl 0x8218f790
	sub_8218F790(ctx, base);
loc_8219199C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_821919A8"))) PPC_WEAK_FUNC(sub_821919A8);
PPC_FUNC_IMPL(__imp__sub_821919A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// rlwinm. r11,r11,30,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82191a00
	if (cr0.getEQ()) goto loc_82191A00;
	// rlwinm r10,r6,17,0,14
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 17) & 0xFFFE0000;
	// rlwinm r11,r6,0,23,23
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x100;
	// rlwimi r5,r4,4,24,27
	ctx.r5.u64 = (__builtin_rotateleft32(ctx.r4.u32, 4) & 0xF0) | (ctx.r5.u64 & 0xFFFFFFFFFFFFFF0F);
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// rlwinm r10,r6,0,22,22
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x200;
	// rlwimi r11,r5,9,15,22
	r11.u64 = (__builtin_rotateleft32(ctx.r5.u32, 9) & 0x1FE00) | (r11.u64 & 0xFFFFFFFFFFFE01FF);
	// addi r5,r3,80
	ctx.r5.s64 = ctx.r3.s64 + 80;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// addi r3,r3,268
	ctx.r3.s64 = ctx.r3.s64 + 268;
	// rlwinm r11,r11,5,0,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// bl 0x82191840
	sub_82191840(ctx, base);
	// b 0x82191a20
	goto loc_82191A20;
loc_82191A00:
	// rlwimi r4,r5,4,24,27
	ctx.r4.u64 = (__builtin_rotateleft32(ctx.r5.u32, 4) & 0xF0) | (ctx.r4.u64 & 0xFFFFFFFFFFFFFF0F);
	// addi r5,r3,80
	ctx.r5.s64 = ctx.r3.s64 + 80;
	// clrlwi r11,r4,24
	r11.u64 = ctx.r4.u32 & 0xFF;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// rlwimi r6,r11,8,0,23
	ctx.r6.u64 = (__builtin_rotateleft32(r11.u32, 8) & 0xFFFFFF00) | (ctx.r6.u64 & 0xFFFFFFFF000000FF);
	// addi r3,r3,304
	ctx.r3.s64 = ctx.r3.s64 + 304;
	// stw r6,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r6.u32);
	// bl 0x82191840
	sub_82191840(ctx, base);
loc_82191A20:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82191A30"))) PPC_WEAK_FUNC(sub_82191A30);
PPC_FUNC_IMPL(__imp__sub_82191A30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed10c
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r17,r5
	r17.u64 = ctx.r5.u64;
	// mr r22,r6
	r22.u64 = ctx.r6.u64;
	// mr r19,r7
	r19.u64 = ctx.r7.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm. r11,r11,28,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 28) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82192194
	if (cr0.getEQ()) goto loc_82192194;
	// lwz r10,112(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// li r21,0
	r21.s64 = 0;
	// li r18,1
	r18.s64 = 1;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x82191aa8
	if (cr0.getEQ()) goto loc_82191AA8;
	// lwz r9,108(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// rlwinm r11,r10,3,0,28
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// addic. r11,r11,-8
	xer.ca = r11.u32 > 7;
	r11.s64 = r11.s64 + -8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82191aa8
	if (cr0.getEQ()) goto loc_82191AA8;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r11,r11,20,28,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
	// slw r11,r18,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (r18.u32 << (r11.u8 & 0x3F));
	// andi. r11,r11,24702
	r11.u64 = r11.u64 & 24702;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// mr r11,r18
	r11.u64 = r18.u64;
	// bne 0x82191aac
	if (!cr0.getEQ()) goto loc_82191AAC;
loc_82191AA8:
	// mr r11,r21
	r11.u64 = r21.u64;
loc_82191AAC:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r26,r31,108
	r26.s64 = r31.s64 + 108;
	// bne 0x82191ad0
	if (!cr0.getEQ()) goto loc_82191AD0;
	// li r10,4096
	ctx.r10.s64 = 4096;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// addi r5,r31,80
	ctx.r5.s64 = r31.s64 + 80;
	// clrlwi r11,r11,20
	r11.u64 = r11.u32 & 0xFFF;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// b 0x82191b84
	goto loc_82191B84;
loc_82191AD0:
	// lwz r9,108(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// rlwinm r11,r10,3,0,28
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// addi r9,r11,-8
	ctx.r9.s64 = r11.s64 + -8;
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// rlwinm r11,r11,0,17,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x7000;
	// cmplwi cr6,r11,24576
	cr6.compare<uint32_t>(r11.u32, 24576, xer);
	// bge cr6,0x82191afc
	if (!cr6.getLT()) goto loc_82191AFC;
	// lwz r11,120(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82191b94
	if (cr6.getEQ()) goto loc_82191B94;
loc_82191AFC:
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// addi r5,r31,80
	ctx.r5.s64 = r31.s64 + 80;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x82192194
	if (cr6.getLT()) goto loc_82192194;
	// lwz r10,120(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 120);
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// rlwinm r10,r11,20,28,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// bne cr6,0x82191b38
	if (!cr6.getEQ()) goto loc_82191B38;
	// lis r7,-32254
	ctx.r7.s64 = -2113798144;
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// addi r7,r7,-19012
	ctx.r7.s64 = ctx.r7.s64 + -19012;
	// lbzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r7.u32);
	// b 0x82191b48
	goto loc_82191B48;
loc_82191B38:
	// lis r8,-32254
	ctx.r8.s64 = -2113798144;
	// clrlwi r7,r10,24
	ctx.r7.u64 = ctx.r10.u32 & 0xFF;
	// addi r8,r8,-19012
	ctx.r8.s64 = ctx.r8.s64 + -19012;
	// lbzx r8,r7,r8
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r7.u32 + ctx.r8.u32);
loc_82191B48:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	// clrlwi r8,r8,24
	ctx.r8.u64 = ctx.r8.u32 & 0xFF;
	// rlwimi r11,r10,12,16,19
	r11.u64 = (__builtin_rotateleft32(ctx.r10.u32, 12) & 0xF000) | (r11.u64 & 0xFFFFFFFFFFFF0FFF);
	// stw r11,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, r11.u32);
	// ld r11,0(r9)
	r11.u64 = PPC_LOAD_U64(ctx.r9.u32 + 0);
	// lwz r10,100(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwimi r11,r8,12,16,19
	r11.u64 = (__builtin_rotateleft32(ctx.r8.u32, 12) & 0xF000) | (r11.u64 & 0xFFFFFFFFFFFF0FFF);
	// rlwimi r10,r9,0,0,19
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0xFFFFF000) | (ctx.r10.u64 & 0xFFFFFFFF00000FFF);
	// rlwinm r11,r11,0,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFC;
	// rlwinm r11,r11,0,21,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFF7FF;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// andi. r11,r10,36863
	r11.u64 = ctx.r10.u64 & 36863;
	cr0.compare<int32_t>(r11.s32, 0, xer);
loc_82191B84:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x821917d0
	sub_821917D0(ctx, base);
loc_82191B94:
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// stw r21,120(r31)
	PPC_STORE_U32(r31.u32 + 120, r21.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x82192194
	if (cr6.getLT()) goto loc_82192194;
	// lwz r11,112(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// clrlwi. r23,r30,24
	r23.u64 = r30.u32 & 0xFF;
	cr0.compare<int32_t>(r23.s32, 0, xer);
	// lwz r10,0(r26)
	ctx.r10.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// addi r27,r11,-1
	r27.s64 = r11.s64 + -1;
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// rlwinm r11,r11,3,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r24,r11,r10
	r24.u64 = r11.u64 + ctx.r10.u64;
	// lwz r11,-8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + -8);
	// rlwinm r10,r11,0,0,19
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFF000;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// rlwinm r20,r11,20,29,31
	r20.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0x7;
	// addi r11,r10,4096
	r11.s64 = ctx.r10.s64 + 4096;
	// rlwimi r11,r9,0,20,16
	r11.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0xFFFFFFFFFFFF8FFF) | (r11.u64 & 0x7000);
	// stw r11,-8(r24)
	PPC_STORE_U32(r24.u32 + -8, r11.u32);
	// beq 0x82191bf8
	if (cr0.getEQ()) goto loc_82191BF8;
	// rlwinm r10,r20,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 1) & 0xFFFFFFFE;
	// slw r10,r18,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (r18.u32 << (ctx.r10.u8 & 0x3F));
	// rlwinm r10,r10,16,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF0000;
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | r11.u64;
	// rlwimi r10,r11,0,16,3
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFFFF000FFFF) | (ctx.r10.u64 & 0xFFF0000);
	// stw r10,-8(r24)
	PPC_STORE_U32(r24.u32 + -8, ctx.r10.u32);
loc_82191BF8:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm. r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82192150
	if (cr0.getEQ()) goto loc_82192150;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// mr r25,r21
	r25.u64 = r21.u64;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// std r21,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r21.u64);
	// std r21,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, r21.u64);
	// std r21,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r21.u64);
	// std r21,8(r10)
	PPC_STORE_U64(ctx.r10.u32 + 8, r21.u64);
	// std r21,16(r11)
	PPC_STORE_U64(r11.u32 + 16, r21.u64);
	// std r21,16(r10)
	PPC_STORE_U64(ctx.r10.u32 + 16, r21.u64);
	// std r21,24(r11)
	PPC_STORE_U64(r11.u32 + 24, r21.u64);
	// std r21,24(r10)
	PPC_STORE_U64(ctx.r10.u32 + 24, r21.u64);
	// beq cr6,0x82191cc0
	if (cr6.getEQ()) goto loc_82191CC0;
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x82191c64
	if (cr6.getEQ()) goto loc_82191C64;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// clrlwi. r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82191c64
	if (!cr0.getEQ()) goto loc_82191C64;
	// lwz r11,4(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 4);
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82191cc0
	if (!cr0.getEQ()) goto loc_82191CC0;
loc_82191C64:
	// addi r11,r31,128
	r11.s64 = r31.s64 + 128;
	// addi r9,r31,16
	ctx.r9.s64 = r31.s64 + 16;
	// li r10,8
	ctx.r10.s64 = 8;
loc_82191C70:
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// or r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 | ctx.r7.u64;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82191c70
	if (!cr0.getEQ()) goto loc_82191C70;
	// addi r11,r31,192
	r11.s64 = r31.s64 + 192;
	// addi r9,r31,48
	ctx.r9.s64 = r31.s64 + 48;
	// li r10,8
	ctx.r10.s64 = 8;
loc_82191C9C:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// or r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 | ctx.r7.u64;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82191c9c
	if (!cr0.getEQ()) goto loc_82191C9C;
	// stw r21,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r21.u32);
loc_82191CC0:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x82191f94
	if (cr6.getEQ()) goto loc_82191F94;
	// lwz r29,0(r19)
	r29.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// clrlwi r28,r29,27
	r28.u64 = r29.u32 & 0x1F;
	// rlwinm. r11,r29,0,13,13
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82191cfc
	if (cr0.getEQ()) goto loc_82191CFC;
	// mr r30,r21
	r30.u64 = r21.u64;
loc_82191CDC:
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8218ef40
	sub_8218EF40(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplwi cr6,r30,64
	cr6.compare<uint32_t>(r30.u32, 64, xer);
	// blt cr6,0x82191cdc
	if (cr6.getLT()) goto loc_82191CDC;
	// b 0x82191d0c
	goto loc_82191D0C;
loc_82191CFC:
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// rlwinm r4,r29,20,26,31
	ctx.r4.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 20) & 0x3F;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8218ef40
	sub_8218EF40(ctx, base);
loc_82191D0C:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x82191d20
	if (!cr6.getEQ()) goto loc_82191D20;
	// lwz r11,4(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 4);
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82191d68
	if (!cr0.getEQ()) goto loc_82191D68;
loc_82191D20:
	// rlwinm. r11,r29,0,20,20
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82191d54
	if (cr0.getEQ()) goto loc_82191D54;
	// mr r30,r21
	r30.u64 = r21.u64;
	// clrlwi r29,r17,24
	r29.u64 = r17.u32 & 0xFF;
loc_82191D30:
	// mr r6,r19
	ctx.r6.u64 = r19.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8218f018
	sub_8218F018(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplwi cr6,r30,64
	cr6.compare<uint32_t>(r30.u32, 64, xer);
	// blt cr6,0x82191d30
	if (cr6.getLT()) goto loc_82191D30;
	// b 0x82191d68
	goto loc_82191D68;
loc_82191D54:
	// mr r6,r19
	ctx.r6.u64 = r19.u64;
	// clrlwi r5,r17,24
	ctx.r5.u64 = r17.u32 & 0xFF;
	// rlwinm r4,r29,27,26,31
	ctx.r4.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 27) & 0x3F;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8218f018
	sub_8218F018(ctx, base);
loc_82191D68:
	// lbz r11,124(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 124);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82191e58
	if (cr0.getEQ()) goto loc_82191E58;
	// addi r11,r28,-24
	r11.s64 = r28.s64 + -24;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bgt cr6,0x82191d88
	if (cr6.getGT()) goto loc_82191D88;
	// mr r25,r18
	r25.u64 = r18.u64;
	// b 0x82191e58
	goto loc_82191E58;
loc_82191D88:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// bne cr6,0x82191e58
	if (!cr6.getEQ()) goto loc_82191E58;
	// clrlwi. r11,r17,24
	r11.u64 = r17.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82191e58
	if (cr0.getEQ()) goto loc_82191E58;
	// clrlwi. r11,r22,24
	r11.u64 = r22.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82191e58
	if (!cr0.getEQ()) goto loc_82191E58;
	// lwz r11,4(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 4);
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82191dd0
	if (!cr0.getEQ()) goto loc_82191DD0;
	// addi r3,r31,16
	ctx.r3.s64 = r31.s64 + 16;
	// stw r18,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r18.u32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// stw r27,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r27.u32);
	// li r5,32
	ctx.r5.s64 = 32;
	// stw r20,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r20.u32);
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// addi r3,r31,48
	ctx.r3.s64 = r31.s64 + 48;
	// b 0x82191e4c
	goto loc_82191E4C;
loc_82191DD0:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82191e58
	if (cr6.getEQ()) goto loc_82191E58;
	// addi r3,r31,16
	ctx.r3.s64 = r31.s64 + 16;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// li r10,8
	ctx.r10.s64 = 8;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
loc_82191DEC:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82191dec
	if (!cr0.getEQ()) goto loc_82191DEC;
	// addi r30,r31,48
	r30.s64 = r31.s64 + 48;
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// li r10,8
	ctx.r10.s64 = 8;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
loc_82191E1C:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// or r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 | ctx.r7.u64;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82191e1c
	if (!cr0.getEQ()) goto loc_82191E1C;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// li r5,32
	ctx.r5.s64 = 32;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_82191E4C:
	// li r5,32
	ctx.r5.s64 = 32;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
loc_82191E58:
	// addi r30,r31,192
	r30.s64 = r31.s64 + 192;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// li r5,32
	ctx.r5.s64 = 32;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// addi r29,r31,224
	r29.s64 = r31.s64 + 224;
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// li r10,8
	ctx.r10.s64 = 8;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
loc_82191E7C:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82191e7c
	if (!cr0.getEQ()) goto loc_82191E7C;
	// mr r11,r21
	r11.u64 = r21.u64;
loc_82191EA0:
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,32
	cr6.compare<uint32_t>(r11.u32, 32, xer);
	// and r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 & ctx.r8.u64;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// blt cr6,0x82191ea0
	if (cr6.getLT()) goto loc_82191EA0;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8218d580
	sub_8218D580(ctx, base);
	// cmplwi cr6,r3,256
	cr6.compare<uint32_t>(ctx.r3.u32, 256, xer);
	// blt cr6,0x82191fa0
	if (cr6.getLT()) goto loc_82191FA0;
	// clrlwi. r11,r17,24
	r11.u64 = r17.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// li r5,32
	ctx.r5.s64 = 32;
	// beq 0x82191f20
	if (cr0.getEQ()) goto loc_82191F20;
	// addi r4,r31,160
	ctx.r4.s64 = r31.s64 + 160;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r10,8
	ctx.r10.s64 = 8;
loc_82191EFC:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82191efc
	if (!cr0.getEQ()) goto loc_82191EFC;
	// b 0x82191f54
	goto loc_82191F54;
loc_82191F20:
	// addi r4,r31,128
	ctx.r4.s64 = r31.s64 + 128;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// addi r11,r1,160
	r11.s64 = ctx.r1.s64 + 160;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// li r10,8
	ctx.r10.s64 = 8;
loc_82191F34:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// or r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 | ctx.r7.u64;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82191f34
	if (!cr0.getEQ()) goto loc_82191F34;
loc_82191F54:
	// mr r11,r21
	r11.u64 = r21.u64;
loc_82191F58:
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// lwz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r11,32
	cr6.compare<uint32_t>(r11.u32, 32, xer);
	// and r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 & ctx.r8.u64;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// blt cr6,0x82191f58
	if (cr6.getLT()) goto loc_82191F58;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8218d580
	sub_8218D580(ctx, base);
	// cmplwi cr6,r3,256
	cr6.compare<uint32_t>(ctx.r3.u32, 256, xer);
	// bge cr6,0x82191fa4
	if (!cr6.getLT()) goto loc_82191FA4;
	// b 0x82191fa0
	goto loc_82191FA0;
loc_82191F94:
	// lbz r11,124(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 124);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82191fa4
	if (cr0.getEQ()) goto loc_82191FA4;
loc_82191FA0:
	// mr r25,r18
	r25.u64 = r18.u64;
loc_82191FA4:
	// clrlwi. r11,r25,24
	r11.u64 = r25.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8219206c
	if (cr0.getEQ()) goto loc_8219206C;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addi r3,r31,128
	ctx.r3.s64 = r31.s64 + 128;
	// li r5,32
	ctx.r5.s64 = 32;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82192010
	if (cr6.getEQ()) goto loc_82192010;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r8,2
	ctx.r8.s64 = 2;
	// lwz r9,0(r26)
	ctx.r9.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// addi r4,r31,16
	ctx.r4.s64 = r31.s64 + 16;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// slw r11,r8,r11
	r11.u64 = r11.u8 & 0x20 ? 0 : (ctx.r8.u32 << (r11.u8 & 0x3F));
	// rlwinm r8,r11,16,0,15
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF0000;
	// lwzx r11,r10,r9
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// or r8,r8,r11
	ctx.r8.u64 = ctx.r8.u64 | r11.u64;
	// rlwimi r8,r11,0,16,3
	ctx.r8.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFFFF000FFFF) | (ctx.r8.u64 & 0xFFF0000);
	// stwx r8,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, ctx.r8.u32);
	// stw r21,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r21.u32);
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// addi r4,r31,48
	ctx.r4.s64 = r31.s64 + 48;
	// addi r3,r31,192
	ctx.r3.s64 = r31.s64 + 192;
	// li r5,32
	ctx.r5.s64 = 32;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// b 0x82192048
	goto loc_82192048;
loc_82192010:
	// li r9,2
	ctx.r9.s64 = 2;
	// lwz r11,-8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + -8);
	// rlwinm r10,r20,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 1) & 0xFFFFFFFE;
	// li r4,0
	ctx.r4.s64 = 0;
	// slw r10,r9,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r10.u8 & 0x3F));
	// rlwinm r10,r10,16,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF0000;
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | r11.u64;
	// rlwimi r10,r11,0,16,3
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFFFF000FFFF) | (ctx.r10.u64 & 0xFFF0000);
	// stw r10,-8(r24)
	PPC_STORE_U32(r24.u32 + -8, ctx.r10.u32);
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,192
	ctx.r3.s64 = r31.s64 + 192;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
loc_82192048:
	// li r5,32
	ctx.r5.s64 = 32;
	// stb r21,124(r31)
	PPC_STORE_U8(r31.u32 + 124, r21.u8);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,160
	ctx.r3.s64 = r31.s64 + 160;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,224
	ctx.r3.s64 = r31.s64 + 224;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
loc_8219206C:
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// beq cr6,0x82192150
	if (cr6.getEQ()) goto loc_82192150;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82192150
	if (!cr6.getEQ()) goto loc_82192150;
	// lwz r11,0(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// cmplwi cr6,r11,24
	cr6.compare<uint32_t>(r11.u32, 24, xer);
	// blt cr6,0x82192098
	if (cr6.getLT()) goto loc_82192098;
	// cmplwi cr6,r11,26
	cr6.compare<uint32_t>(r11.u32, 26, xer);
	// ble cr6,0x8219209c
	if (!cr6.getGT()) goto loc_8219209C;
loc_82192098:
	// stb r18,124(r31)
	PPC_STORE_U8(r31.u32 + 124, r18.u8);
loc_8219209C:
	// clrlwi. r11,r17,24
	r11.u64 = r17.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r9,r1,96
	ctx.r9.s64 = ctx.r1.s64 + 96;
	// li r10,8
	ctx.r10.s64 = 8;
	// beq 0x82192100
	if (cr0.getEQ()) goto loc_82192100;
	// addi r11,r31,128
	r11.s64 = r31.s64 + 128;
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - r11.s64;
loc_821920B4:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r7,r9,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x821920b4
	if (!cr0.getEQ()) goto loc_821920B4;
	// addi r11,r31,192
	r11.s64 = r31.s64 + 192;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// li r10,8
	ctx.r10.s64 = 8;
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - r11.s64;
loc_821920E0:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r7,r9,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x821920e0
	if (!cr0.getEQ()) goto loc_821920E0;
	// b 0x82192150
	goto loc_82192150;
loc_82192100:
	// addi r11,r31,160
	r11.s64 = r31.s64 + 160;
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - r11.s64;
loc_82192108:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r7,r9,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82192108
	if (!cr0.getEQ()) goto loc_82192108;
	// addi r11,r31,224
	r11.s64 = r31.s64 + 224;
	// addi r9,r1,128
	ctx.r9.s64 = ctx.r1.s64 + 128;
	// li r10,8
	ctx.r10.s64 = 8;
	// subf r9,r11,r9
	ctx.r9.s64 = ctx.r9.s64 - r11.s64;
loc_82192134:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwzx r7,r9,r11
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bne 0x82192134
	if (!cr0.getEQ()) goto loc_82192134;
loc_82192150:
	// clrlwi. r11,r17,24
	r11.u64 = r17.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82192194
	if (cr0.getEQ()) goto loc_82192194;
	// cmplwi cr6,r20,4
	cr6.compare<uint32_t>(r20.u32, 4, xer);
	// bge cr6,0x8219217c
	if (!cr6.getLT()) goto loc_8219217C;
	// slw r10,r18,r20
	ctx.r10.u64 = r20.u8 & 0x20 ? 0 : (r18.u32 << (r20.u8 & 0x3F));
	// lwz r11,-8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + -8);
	// rlwinm r10,r10,28,0,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0xF0000000;
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | r11.u64;
	// rlwimi r10,r11,0,4,31
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFF) | (ctx.r10.u64 & 0xFFFFFFFFF0000000);
	// stw r10,-8(r24)
	PPC_STORE_U32(r24.u32 + -8, ctx.r10.u32);
	// b 0x82192194
	goto loc_82192194;
loc_8219217C:
	// addi r10,r20,-4
	ctx.r10.s64 = r20.s64 + -4;
	// lwz r11,-4(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + -4);
	// slw r10,r18,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (r18.u32 << (ctx.r10.u8 & 0x3F));
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | r11.u64;
	// rlwimi r10,r11,0,0,29
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFFC) | (ctx.r10.u64 & 0xFFFFFFFF00000003);
	// stw r10,-4(r24)
	PPC_STORE_U32(r24.u32 + -4, ctx.r10.u32);
loc_82192194:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// b 0x823ed15c
	return;
}

__attribute__((alias("__imp__sub_821921A0"))) PPC_WEAK_FUNC(sub_821921A0);
PPC_FUNC_IMPL(__imp__sub_821921A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r10,19892(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 19892);
	// rlwinm. r10,r10,30,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x821921ec
	if (!cr0.getEQ()) goto loc_821921EC;
	// rlwimi r4,r5,1,27,30
	ctx.r4.u64 = (__builtin_rotateleft32(ctx.r5.u32, 1) & 0x1E) | (ctx.r4.u64 & 0xFFFFFFFFFFFFFFE1);
	// addi r5,r11,80
	ctx.r5.s64 = r11.s64 + 80;
	// clrlwi r10,r4,27
	ctx.r10.u64 = ctx.r4.u32 & 0x1F;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// rlwimi r6,r10,8,0,23
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r10.u32, 8) & 0xFFFFFF00) | (ctx.r6.u64 & 0xFFFFFFFF000000FF);
	// addi r3,r11,280
	ctx.r3.s64 = r11.s64 + 280;
	// stw r6,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r6.u32);
	// bl 0x82191840
	sub_82191840(ctx, base);
loc_821921EC:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82192200"))) PPC_WEAK_FUNC(sub_82192200);
PPC_FUNC_IMPL(__imp__sub_82192200) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r25,64
	r25.s64 = 64;
	// addi r27,r30,368
	r27.s64 = r30.s64 + 368;
	// addi r26,r30,10304
	r26.s64 = r30.s64 + 10304;
	// li r28,0
	r28.s64 = 0;
	// li r24,1
	r24.s64 = 1;
loc_82192224:
	// subfic r29,r28,63
	xer.ca = r28.u32 <= 63;
	r29.s64 = 63 - r28.s64;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// rlwinm r31,r29,2,0,29
	r31.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r1,96
	ctx.r6.s64 = ctx.r1.s64 + 96;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x8218f258
	sub_8218F258(ctx, base);
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// addi r6,r1,160
	ctx.r6.s64 = ctx.r1.s64 + 160;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8218f258
	sub_8218F258(ctx, base);
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// or. r11,r5,r4
	r11.u64 = ctx.r5.u64 | ctx.r4.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x821922e0
	if (cr0.getEQ()) goto loc_821922E0;
	// and. r3,r5,r4
	ctx.r3.u64 = ctx.r5.u64 & ctx.r4.u64;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x821922d4
	if (cr0.getEQ()) goto loc_821922D4;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
loc_8219227C:
	// slw r11,r24,r6
	r11.u64 = ctx.r6.u8 & 0x20 ? 0 : (r24.u32 << (ctx.r6.u8 & 0x3F));
	// and. r11,r11,r3
	r11.u64 = r11.u64 & ctx.r3.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x821922c4
	if (cr0.getEQ()) goto loc_821922C4;
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// addi r10,r1,160
	ctx.r10.s64 = ctx.r1.s64 + 160;
	// add r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// addi r8,r11,16
	ctx.r8.s64 = r11.s64 + 16;
loc_8219229C:
	// lbz r7,0(r11)
	ctx.r7.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// lbz r31,0(r10)
	r31.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// subf. r7,r31,r7
	ctx.r7.s64 = ctx.r7.s64 - r31.s64;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x821922bc
	if (!cr0.getEQ()) goto loc_821922BC;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// bne cr6,0x8219229c
	if (!cr6.getEQ()) goto loc_8219229C;
loc_821922BC:
	// cmpwi r7,0
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne 0x821922d4
	if (!cr0.getEQ()) goto loc_821922D4;
loc_821922C4:
	// addi r9,r9,16
	ctx.r9.s64 = ctx.r9.s64 + 16;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// cmplwi cr6,r9,64
	cr6.compare<uint32_t>(ctx.r9.u32, 64, xer);
	// blt cr6,0x8219227c
	if (cr6.getLT()) goto loc_8219227C;
loc_821922D4:
	// andc. r11,r5,r4
	r11.u64 = ctx.r5.u64 & ~ctx.r4.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x821922ec
	if (!cr0.getEQ()) goto loc_821922EC;
	// mr r25,r29
	r25.u64 = r29.u64;
loc_821922E0:
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// cmplwi cr6,r28,64
	cr6.compare<uint32_t>(r28.u32, 64, xer);
	// blt cr6,0x82192224
	if (cr6.getLT()) goto loc_82192224;
loc_821922EC:
	// addi r31,r30,19940
	r31.s64 = r30.s64 + 19940;
	// stw r25,19936(r30)
	PPC_STORE_U32(r30.u32 + 19936, r25.u32);
	// stw r24,19932(r30)
	PPC_STORE_U32(r30.u32 + 19932, r24.u32);
	// subfic r29,r25,64
	xer.ca = r25.u32 <= 64;
	r29.s64 = 64 - r25.s64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// ble cr6,0x82192318
	if (!cr6.getGT()) goto loc_82192318;
	// addi r5,r30,19900
	ctx.r5.s64 = r30.s64 + 19900;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218f790
	sub_8218F790(ctx, base);
loc_82192318:
	// stw r29,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r29.u32);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_82192328"))) PPC_WEAK_FUNC(sub_82192328);
PPC_FUNC_IMPL(__imp__sub_82192328) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r3,r11,16
	ctx.r3.s64 = r11.s64 + 16;
	// b 0x8218ff88
	sub_8218FF88(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82192340"))) PPC_WEAK_FUNC(sub_82192340);
PPC_FUNC_IMPL(__imp__sub_82192340) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r3,r11,16
	ctx.r3.s64 = r11.s64 + 16;
	// b 0x821919a8
	sub_821919A8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82192358"))) PPC_WEAK_FUNC(sub_82192358);
PPC_FUNC_IMPL(__imp__sub_82192358) {
	PPC_FUNC_PROLOGUE();
	// b 0x821921a0
	sub_821921A0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82192360"))) PPC_WEAK_FUNC(sub_82192360);
PPC_FUNC_IMPL(__imp__sub_82192360) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,19888(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 19888);
	// addic. r30,r11,-1
	xer.ca = r11.u32 > 0;
	r30.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// stw r30,19888(r31)
	PPC_STORE_U32(r31.u32 + 19888, r30.u32);
	// bne 0x82192398
	if (!cr0.getEQ()) goto loc_82192398;
	// bl 0x82191468
	sub_82191468(ctx, base);
	// lis r4,9344
	ctx.r4.s64 = 612368384;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8209d060
	sub_8209D060(ctx, base);
loc_82192398:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821923B8"))) PPC_WEAK_FUNC(sub_821923B8);
PPC_FUNC_IMPL(__imp__sub_821923B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// bl 0x82190b08
	sub_82190B08(ctx, base);
	// addi r30,r31,16
	r30.s64 = r31.s64 + 16;
	// stw r28,19892(r31)
	PPC_STORE_U32(r31.u32 + 19892, r28.u32);
	// li r29,2
	r29.s64 = 2;
loc_821923DC:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821918a8
	sub_821918A8(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r30,352
	ctx.r3.s64 = r30.s64 + 352;
	// bl 0x8218e640
	sub_8218E640(ctx, base);
	// addic. r29,r29,-1
	xer.ca = r29.u32 > 0;
	r29.s64 = r29.s64 + -1;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// addi r30,r30,9936
	r30.s64 = r30.s64 + 9936;
	// bne 0x821923dc
	if (!cr0.getEQ()) goto loc_821923DC;
	// li r11,0
	r11.s64 = 0;
	// stw r11,19912(r31)
	PPC_STORE_U32(r31.u32 + 19912, r11.u32);
	// lwz r10,19892(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 19892);
	// stw r11,19924(r31)
	PPC_STORE_U32(r31.u32 + 19924, r11.u32);
	// rlwinm r10,r10,26,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 26) & 0x1;
	// stw r11,19896(r31)
	PPC_STORE_U32(r31.u32 + 19896, r11.u32);
	// subfic r11,r10,0
	xer.ca = ctx.r10.u32 <= 0;
	r11.s64 = 0 - ctx.r10.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_82192430"))) PPC_WEAK_FUNC(sub_82192430);
PPC_FUNC_IMPL(__imp__sub_82192430) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// addi r31,r30,19908
	r31.s64 = r30.s64 + 19908;
	// addi r11,r28,3
	r11.s64 = r28.s64 + 3;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// rlwinm r29,r11,30,2,31
	r29.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFFFFFF;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// ble cr6,0x82192470
	if (!cr6.getGT()) goto loc_82192470;
	// addi r5,r30,19900
	ctx.r5.s64 = r30.s64 + 19900;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218f790
	sub_8218F790(ctx, base);
loc_82192470:
	// stw r29,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r29.u32);
	// lwz r11,19900(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 19900);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x82192490
	if (cr6.getLT()) goto loc_82192490;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
loc_82192490:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_82192498"))) PPC_WEAK_FUNC(sub_82192498);
PPC_FUNC_IMPL(__imp__sub_82192498) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r4,r11,-18996
	ctx.r4.s64 = r11.s64 + -18996;
	// li r5,14
	ctx.r5.s64 = 14;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x823ee630
	sub_823EE630(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x821924d0
	if (!cr0.getEQ()) goto loc_821924D0;
	// addi r26,r26,10
	r26.s64 = r26.s64 + 10;
loc_821924D0:
	// mr r11,r26
	r11.u64 = r26.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_821924D8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x821924d8
	if (!cr6.getEQ()) goto loc_821924D8;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// li r27,0
	r27.s64 = 0;
	// addi r10,r11,-1
	ctx.r10.s64 = r11.s64 + -1;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// rotlwi r29,r10,0
	r29.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// addi r31,r28,19920
	r31.s64 = r28.s64 + 19920;
	// std r27,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r27.u64);
	// addi r11,r29,3
	r11.s64 = r29.s64 + 3;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// rlwinm r11,r11,30,2,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFFFFFF;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r29.u32);
	// addi r30,r11,2
	r30.s64 = r11.s64 + 2;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// ble cr6,0x82192534
	if (!cr6.getGT()) goto loc_82192534;
	// addi r5,r28,19900
	ctx.r5.s64 = r28.s64 + 19900;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218f790
	sub_8218F790(ctx, base);
loc_82192534:
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// lwz r11,19900(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 19900);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x8219256c
	if (cr6.getLT()) goto loc_8219256C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r10,r30,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// ld r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// stw r27,-4(r10)
	PPC_STORE_U32(ctx.r10.u32 + -4, r27.u32);
	// std r9,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r9.u64);
	// bl 0x823ee010
	sub_823EE010(ctx, base);
loc_8219256C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_82192578"))) PPC_WEAK_FUNC(sub_82192578);
PPC_FUNC_IMPL(__imp__sub_82192578) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,0
	r11.s64 = 0;
	// lwz r10,19900(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 19900);
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r31,r11
	r31.u64 = r11.u64;
	// mr r29,r11
	r29.u64 = r11.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
	// blt cr6,0x821925e4
	if (cr6.getLT()) goto loc_821925E4;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x82191518
	sub_82191518(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x821925e4
	if (cr0.getLT()) goto loc_821925E4;
	// lwz r31,112(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r29,92(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
loc_821925E4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x821925f0
	if (cr6.getEQ()) goto loc_821925F0;
	// stw r31,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r31.u32);
loc_821925F0:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x821925fc
	if (cr6.getEQ()) goto loc_821925FC;
	// stw r29,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r29.u32);
loc_821925FC:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_82192608"))) PPC_WEAK_FUNC(sub_82192608);
PPC_FUNC_IMPL(__imp__sub_82192608) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// lwz r3,19900(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 19900);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x821926d8
	if (cr0.getLT()) goto loc_821926D8;
	// li r11,0
	r11.s64 = 0;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
	// bl 0x82191518
	sub_82191518(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r3,19900(r31)
	PPC_STORE_U32(r31.u32 + 19900, ctx.r3.u32);
	// blt 0x821926d8
	if (cr0.getLT()) goto loc_821926D8;
	// lwz r5,92(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r30,112(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// add r27,r5,r30
	r27.u64 = ctx.r5.u64 + r30.u64;
	// cmplw cr6,r27,r28
	cr6.compare<uint32_t>(r27.u32, r28.u32, xer);
	// ble cr6,0x82192694
	if (!cr6.getGT()) goto loc_82192694;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// b 0x821926d8
	goto loc_821926D8;
loc_82192694:
	// add r4,r30,r29
	ctx.r4.u64 = r30.u64 + r29.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8218c4d8
	sub_8218C4D8(ctx, base);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// bl 0x8218c4d8
	sub_8218C4D8(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82191518
	sub_82191518(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r3,19900(r31)
	PPC_STORE_U32(r31.u32 + 19900, ctx.r3.u32);
	// blt 0x821926d4
	if (cr0.getLT()) goto loc_821926D4;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x821926d4
	if (cr6.getEQ()) goto loc_821926D4;
	// stw r27,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r27.u32);
loc_821926D4:
	// lwz r3,19900(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 19900);
loc_821926D8:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_821926E0"))) PPC_WEAK_FUNC(sub_821926E0);
PPC_FUNC_IMPL(__imp__sub_821926E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82191a30
	sub_82191A30(ctx, base);
	// addi r5,r31,80
	ctx.r5.s64 = r31.s64 + 80;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r31,96
	ctx.r3.s64 = r31.s64 + 96;
	// bl 0x82191758
	sub_82191758(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// addi r3,r11,-1
	ctx.r3.s64 = r11.s64 + -1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82192740"))) PPC_WEAK_FUNC(sub_82192740);
PPC_FUNC_IMPL(__imp__sub_82192740) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// cntlzw r11,r5
	r11.u64 = ctx.r5.u32 == 0 ? 32 : __builtin_clz(ctx.r5.u32);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r5,r11,27,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82191a30
	sub_82191A30(ctx, base);
	// addi r5,r31,80
	ctx.r5.s64 = r31.s64 + 80;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r31,96
	ctx.r3.s64 = r31.s64 + 96;
	// bl 0x82191758
	sub_82191758(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// addi r3,r11,-1
	ctx.r3.s64 = r11.s64 + -1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821927A8"))) PPC_WEAK_FUNC(sub_821927A8);
PPC_FUNC_IMPL(__imp__sub_821927A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// cntlzw r11,r28
	r11.u64 = r28.u32 == 0 ? 32 : __builtin_clz(r28.u32);
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// li r6,1
	ctx.r6.s64 = 1;
	// rlwinm r5,r11,27,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82191a30
	sub_82191A30(ctx, base);
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// addi r27,r31,80
	r27.s64 = r31.s64 + 80;
	// rlwimi r10,r28,6,25,25
	ctx.r10.u64 = (__builtin_rotateleft32(r28.u32, 6) & 0x40) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFBF);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r31,292
	ctx.r3.s64 = r31.s64 + 292;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// andi. r10,r10,79
	ctx.r10.u64 = ctx.r10.u64 & 79;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// rlwimi r30,r10,8,0,23
	r30.u64 = (__builtin_rotateleft32(ctx.r10.u32, 8) & 0xFFFFFF00) | (r30.u64 & 0xFFFFFFFF000000FF);
	// rlwimi r11,r30,8,0,19
	r11.u64 = (__builtin_rotateleft32(r30.u32, 8) & 0xFFFFF000) | (r11.u64 & 0xFFFFFFFF00000FFF);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// bl 0x82191840
	sub_82191840(ctx, base);
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r31,96
	ctx.r3.s64 = r31.s64 + 96;
	// bl 0x82191758
	sub_82191758(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// addi r3,r11,-1
	ctx.r3.s64 = r11.s64 + -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_82192830"))) PPC_WEAK_FUNC(sub_82192830);
PPC_FUNC_IMPL(__imp__sub_82192830) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82191a30
	sub_82191A30(ctx, base);
	// addi r5,r31,80
	ctx.r5.s64 = r31.s64 + 80;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r31,96
	ctx.r3.s64 = r31.s64 + 96;
	// bl 0x82191758
	sub_82191758(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// rlwinm. r11,r11,30,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x821928bc
	if (!cr0.getEQ()) goto loc_821928BC;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8218c5b8
	sub_8218C5B8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x821928bc
	if (cr0.getEQ()) goto loc_821928BC;
	// lwz r11,316(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 316);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,316(r31)
	PPC_STORE_U32(r31.u32 + 316, r11.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r11,r11,26
	r11.u64 = r11.u32 & 0x3F;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lbz r10,320(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 320);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stb r10,320(r11)
	PPC_STORE_U8(r11.u32 + 320, ctx.r10.u8);
loc_821928BC:
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// addi r3,r11,-1
	ctx.r3.s64 = r11.s64 + -1;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821928E0"))) PPC_WEAK_FUNC(sub_821928E0);
PPC_FUNC_IMPL(__imp__sub_821928E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm. r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8219295c
	if (cr0.getEQ()) goto loc_8219295C;
	// lbz r11,124(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 124);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8219295c
	if (cr0.getEQ()) goto loc_8219295C;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,1
	ctx.r9.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// std r10,0(r11)
	PPC_STORE_U64(r11.u32 + 0, ctx.r10.u64);
	// stw r10,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r10.u32);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// clrlwi r10,r10,6
	ctx.r10.u64 = ctx.r10.u32 & 0x3FFFFFF;
	// rlwimi r11,r9,25,3,7
	r11.u64 = (__builtin_rotateleft32(ctx.r9.u32, 25) & 0x1F000000) | (r11.u64 & 0xFFFFFFFFE0FFFFFF);
	// oris r10,r10,51200
	ctx.r10.u64 = ctx.r10.u64 | 3355443200;
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// bl 0x82192830
	sub_82192830(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8218e8b8
	sub_8218E8B8(ctx, base);
loc_8219295C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82192970"))) PPC_WEAK_FUNC(sub_82192970);
PPC_FUNC_IMPL(__imp__sub_82192970) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,19892(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 19892);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82192998
	if (cr0.getEQ()) goto loc_82192998;
	// bl 0x82192200
	sub_82192200(ctx, base);
	// b 0x821929ac
	goto loc_821929AC;
loc_82192998:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// addi r3,r11,16
	ctx.r3.s64 = r11.s64 + 16;
	// bl 0x8218ff88
	sub_8218FF88(ctx, base);
loc_821929AC:
	// li r11,1
	r11.s64 = 1;
	// stw r11,19904(r31)
	PPC_STORE_U32(r31.u32 + 19904, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821929C8"))) PPC_WEAK_FUNC(sub_821929C8);
PPC_FUNC_IMPL(__imp__sub_821929C8) {
	PPC_FUNC_PROLOGUE();
	// b 0x82192360
	sub_82192360(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821929D0"))) PPC_WEAK_FUNC(sub_821929D0);
PPC_FUNC_IMPL(__imp__sub_821929D0) {
	PPC_FUNC_PROLOGUE();
	// b 0x821923b8
	sub_821923B8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821929D8"))) PPC_WEAK_FUNC(sub_821929D8);
PPC_FUNC_IMPL(__imp__sub_821929D8) {
	PPC_FUNC_PROLOGUE();
	// b 0x82192430
	sub_82192430(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821929E0"))) PPC_WEAK_FUNC(sub_821929E0);
PPC_FUNC_IMPL(__imp__sub_821929E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r3,r11,16
	ctx.r3.s64 = r11.s64 + 16;
	// b 0x821926e0
	sub_821926E0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_821929F8"))) PPC_WEAK_FUNC(sub_821929F8);
PPC_FUNC_IMPL(__imp__sub_821929F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r3,r11,16
	ctx.r3.s64 = r11.s64 + 16;
	// b 0x82192740
	sub_82192740(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82192A10"))) PPC_WEAK_FUNC(sub_82192A10);
PPC_FUNC_IMPL(__imp__sub_82192A10) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r3,r11,16
	ctx.r3.s64 = r11.s64 + 16;
	// b 0x821927a8
	sub_821927A8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82192A28"))) PPC_WEAK_FUNC(sub_82192A28);
PPC_FUNC_IMPL(__imp__sub_82192A28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r3,r11,16
	ctx.r3.s64 = r11.s64 + 16;
	// b 0x82192830
	sub_82192830(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82192A40"))) PPC_WEAK_FUNC(sub_82192A40);
PPC_FUNC_IMPL(__imp__sub_82192A40) {
	PPC_FUNC_PROLOGUE();
	// b 0x82192498
	sub_82192498(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82192A48"))) PPC_WEAK_FUNC(sub_82192A48);
PPC_FUNC_IMPL(__imp__sub_82192A48) {
	PPC_FUNC_PROLOGUE();
	// b 0x82192970
	sub_82192970(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82192A50"))) PPC_WEAK_FUNC(sub_82192A50);
PPC_FUNC_IMPL(__imp__sub_82192A50) {
	PPC_FUNC_PROLOGUE();
	// b 0x82192608
	sub_82192608(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82192A58"))) PPC_WEAK_FUNC(sub_82192A58);
PPC_FUNC_IMPL(__imp__sub_82192A58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,19900(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 19900);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x82192a78
	if (!cr6.getLT()) goto loc_82192A78;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82192a90
	goto loc_82192A90;
loc_82192A78:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// bl 0x82192578
	sub_82192578(ctx, base);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
loc_82192A90:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82192AA0"))) PPC_WEAK_FUNC(sub_82192AA0);
PPC_FUNC_IMPL(__imp__sub_82192AA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r26,0
	r26.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r26,120(r31)
	PPC_STORE_U32(r31.u32 + 120, r26.u32);
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm. r11,r11,28,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 28) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82192b8c
	if (cr0.getEQ()) goto loc_82192B8C;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r10,1
	ctx.r10.s64 = 1;
	// rlwinm r27,r11,20,28,31
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
	// slw r28,r10,r27
	r28.u64 = r27.u8 & 0x20 ? 0 : (ctx.r10.u32 << (r27.u8 & 0x3F));
	// andi. r11,r28,28664
	r11.u64 = r28.u64 & 28664;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82192b1c
	if (cr0.getEQ()) goto loc_82192B1C;
	// lwz r29,100(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// bl 0x821928e0
	sub_821928E0(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// subf. r10,r29,r11
	ctx.r10.s64 = r11.s64 - r29.s64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82192b1c
	if (cr0.getEQ()) goto loc_82192B1C;
	// andi. r11,r28,24702
	r11.u64 = r28.u64 & 24702;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82192b1c
	if (cr0.getEQ()) goto loc_82192B1C;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// rlwimi r10,r11,0,0,19
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFF000) | (ctx.r10.u64 & 0xFFFFFFFF00000FFF);
	// stw r10,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r10.u32);
loc_82192B1C:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm. r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82192b8c
	if (cr0.getEQ()) goto loc_82192B8C;
	// cmplwi cr6,r27,12
	cr6.compare<uint32_t>(r27.u32, 12, xer);
	// bne cr6,0x82192b8c
	if (!cr6.getEQ()) goto loc_82192B8C;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82192b8c
	if (!cr0.getEQ()) goto loc_82192B8C;
	// li r5,32
	ctx.r5.s64 = 32;
	// stw r26,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r26.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// stb r26,124(r31)
	PPC_STORE_U8(r31.u32 + 124, r26.u8);
	// addi r3,r31,128
	ctx.r3.s64 = r31.s64 + 128;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,160
	ctx.r3.s64 = r31.s64 + 160;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,192
	ctx.r3.s64 = r31.s64 + 192;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,224
	ctx.r3.s64 = r31.s64 + 224;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
loc_82192B8C:
	// addi r5,r31,80
	ctx.r5.s64 = r31.s64 + 80;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r31,108
	ctx.r3.s64 = r31.s64 + 108;
	// bl 0x821917d0
	sub_821917D0(ctx, base);
	// lwz r11,112(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// addi r3,r11,-1
	ctx.r3.s64 = r11.s64 + -1;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_82192BB0"))) PPC_WEAK_FUNC(sub_82192BB0);
PPC_FUNC_IMPL(__imp__sub_82192BB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x821928e0
	sub_821928E0(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,19892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 19892);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm. r11,r11,28,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 28) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82192c1c
	if (cr0.getEQ()) goto loc_82192C1C;
	// lwz r10,112(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x82192c1c
	if (cr0.getEQ()) goto loc_82192C1C;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addic. r11,r11,-8
	xer.ca = r11.u32 > 7;
	r11.s64 = r11.s64 + -8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82192c1c
	if (cr0.getEQ()) goto loc_82192C1C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// li r11,1
	r11.s64 = 1;
	// rlwinm r10,r10,20,28,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0xF;
	// slw r10,r11,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r10.u8 & 0x3F));
	// andi. r10,r10,24702
	ctx.r10.u64 = ctx.r10.u64 & 24702;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x82192c1c
	if (cr0.getEQ()) goto loc_82192C1C;
	// stw r11,120(r31)
	PPC_STORE_U32(r31.u32 + 120, r11.u32);
loc_82192C1C:
	// lwz r3,112(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 112);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82192C38"))) PPC_WEAK_FUNC(sub_82192C38);
PPC_FUNC_IMPL(__imp__sub_82192C38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r3,r11,16
	ctx.r3.s64 = r11.s64 + 16;
	// b 0x82192aa0
	sub_82192AA0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82192C50"))) PPC_WEAK_FUNC(sub_82192C50);
PPC_FUNC_IMPL(__imp__sub_82192C50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mulli r11,r11,9936
	r11.s64 = r11.s64 * 9936;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// addi r3,r11,16
	ctx.r3.s64 = r11.s64 + 16;
	// b 0x82192bb0
	sub_82192BB0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82192C68"))) PPC_WEAK_FUNC(sub_82192C68);
PPC_FUNC_IMPL(__imp__sub_82192C68) {
	PPC_FUNC_PROLOGUE();
	// b 0x82192a58
	sub_82192A58(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82192C70"))) PPC_WEAK_FUNC(sub_82192C70);
PPC_FUNC_IMPL(__imp__sub_82192C70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed114
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// mr r22,r6
	r22.u64 = ctx.r6.u64;
	// mr r21,r7
	r21.u64 = ctx.r7.u64;
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// ble cr6,0x82192ca8
	if (!cr6.getGT()) goto loc_82192CA8;
	// bl 0x8219d6d8
	sub_8219D6D8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82192CA8:
	// lbz r10,10940(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 10940);
	// rlwinm. r9,r10,0,27,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82192cbc
	if (cr0.getEQ()) goto loc_82192CBC;
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x82192d4c
	goto loc_82192D4C;
loc_82192CBC:
	// rlwinm. r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82192d44
	if (cr0.getEQ()) goto loc_82192D44;
	// lwz r10,12432(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12432);
	// lwz r9,12720(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12720);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// beq cr6,0x82192cdc
	if (cr6.getEQ()) goto loc_82192CDC;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82192d44
	if (!cr6.getEQ()) goto loc_82192D44;
loc_82192CDC:
	// lwz r10,12436(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12436);
	// lwz r9,12724(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12724);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// beq cr6,0x82192cf4
	if (cr6.getEQ()) goto loc_82192CF4;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82192d44
	if (!cr6.getEQ()) goto loc_82192D44;
loc_82192CF4:
	// lwz r10,12440(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12440);
	// lwz r9,12728(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12728);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// beq cr6,0x82192d0c
	if (cr6.getEQ()) goto loc_82192D0C;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82192d44
	if (!cr6.getEQ()) goto loc_82192D44;
loc_82192D0C:
	// lwz r10,12444(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12444);
	// lwz r9,12732(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12732);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// beq cr6,0x82192d24
	if (cr6.getEQ()) goto loc_82192D24;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82192d44
	if (!cr6.getEQ()) goto loc_82192D44;
loc_82192D24:
	// lwz r10,12448(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12448);
	// lwz r9,12736(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12736);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// beq cr6,0x82192d3c
	if (cr6.getEQ()) goto loc_82192D3C;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82192d44
	if (!cr6.getEQ()) goto loc_82192D44;
loc_82192D3C:
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x82192d48
	goto loc_82192D48;
loc_82192D44:
	// li r10,0
	ctx.r10.s64 = 0;
loc_82192D48:
	// clrlwi r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
loc_82192D4C:
	// clrlwi. r10,r10,24
	ctx.r10.u64 = ctx.r10.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// li r9,0
	ctx.r9.s64 = 0;
	// bne 0x82192d8c
	if (!cr0.getEQ()) goto loc_82192D8C;
	// lis r10,2
	ctx.r10.s64 = 131072;
	// rlwinm r8,r23,16,2,15
	ctx.r8.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 16) & 0x3FFF0000;
	// ori r10,r10,8320
	ctx.r10.u64 = ctx.r10.u64 | 8320;
	// clrlwi r7,r24,18
	ctx.r7.u64 = r24.u32 & 0x3FFF;
	// rlwinm r6,r21,16,2,15
	ctx.r6.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 16) & 0x3FFF0000;
	// stwu r10,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	r11.u32 = ea;
	// or r10,r8,r7
	ctx.r10.u64 = ctx.r8.u64 | ctx.r7.u64;
	// clrlwi r8,r22,18
	ctx.r8.u64 = r22.u32 & 0x3FFF;
	// or r8,r6,r8
	ctx.r8.u64 = ctx.r6.u64 | ctx.r8.u64;
	// stwu r9,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	r11.u32 = ea;
	// b 0x82192f44
	goto loc_82192F44;
loc_82192D8C:
	// lis r10,-16384
	ctx.r10.s64 = -1073741824;
	// li r26,0
	r26.s64 = 0;
	// ori r25,r10,24832
	r25.u64 = ctx.r10.u64 | 24832;
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
	// stwu r10,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	r11.u32 = ea;
	// stwu r9,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	r11.u32 = ea;
	// lis r9,-16384
	ctx.r9.s64 = -1073741824;
	// lwz r10,12740(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12740);
	// ori r30,r9,24576
	r30.u64 = ctx.r9.u64 | 24576;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// ble cr6,0x82192ecc
	if (!cr6.getGT()) goto loc_82192ECC;
	// li r29,0
	r29.s64 = 0;
	// addi r28,r31,12748
	r28.s64 = r31.s64 + 12748;
	// addi r27,r31,12988
	r27.s64 = r31.s64 + 12988;
loc_82192DC4:
	// lwz r10,-4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + -4);
	// mr r7,r24
	ctx.r7.u64 = r24.u64;
	// lwz r6,-4(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + -4);
	// lwz r5,0(r27)
	ctx.r5.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// cmpw cr6,r24,r10
	cr6.compare<int32_t>(r24.s32, ctx.r10.s32, xer);
	// bgt cr6,0x82192de0
	if (cr6.getGT()) goto loc_82192DE0;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
loc_82192DE0:
	// lwz r8,0(r28)
	ctx.r8.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// cmpw cr6,r23,r8
	cr6.compare<int32_t>(r23.s32, ctx.r8.s32, xer);
	// ble cr6,0x82192df0
	if (!cr6.getGT()) goto loc_82192DF0;
	// mr r8,r23
	ctx.r8.u64 = r23.u64;
loc_82192DF0:
	// lwz r9,4(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// cmpw cr6,r22,r9
	cr6.compare<int32_t>(r22.s32, ctx.r9.s32, xer);
	// bge cr6,0x82192e00
	if (!cr6.getLT()) goto loc_82192E00;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
loc_82192E00:
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// cmpw cr6,r21,r10
	cr6.compare<int32_t>(r21.s32, ctx.r10.s32, xer);
	// bge cr6,0x82192e10
	if (!cr6.getLT()) goto loc_82192E10;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
loc_82192E10:
	// cmpw cr6,r7,r9
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r9.s32, xer);
	// bge cr6,0x82192e20
	if (!cr6.getLT()) goto loc_82192E20;
	// cmpw cr6,r8,r10
	cr6.compare<int32_t>(ctx.r8.s32, ctx.r10.s32, xer);
	// blt cr6,0x82192e30
	if (cr6.getLT()) goto loc_82192E30;
loc_82192E20:
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
loc_82192E30:
	// li r3,3
	ctx.r3.s64 = 3;
	// clrlwi r7,r7,18
	ctx.r7.u64 = ctx.r7.u32 & 0x3FFF;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// rlwinm r8,r8,16,2,15
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 16) & 0x3FFF0000;
	// lis r20,-16381
	r20.s64 = -1073545216;
	// or r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 | ctx.r7.u64;
	// ori r20,r20,11521
	r20.u64 = r20.u64 | 11521;
	// stwu r4,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r4.u32);
	r11.u32 = ea;
	// lis r19,4
	r19.s64 = 262144;
	// neg r6,r6
	ctx.r6.s64 = -ctx.r6.s64;
	// ori r19,r19,128
	r19.u64 = r19.u64 | 128;
	// neg r5,r5
	ctx.r5.s64 = -ctx.r5.s64;
	// clrlwi r6,r6,17
	ctx.r6.u64 = ctx.r6.u32 & 0x7FFF;
	// rlwinm r5,r5,16,1,15
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 16) & 0x7FFF0000;
	// rlwinm r10,r10,16,2,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0x3FFF0000;
	// or r6,r5,r6
	ctx.r6.u64 = ctx.r5.u64 | ctx.r6.u64;
	// clrlwi r9,r9,18
	ctx.r9.u64 = ctx.r9.u32 & 0x3FFF;
	// slw r7,r3,r29
	ctx.r7.u64 = r29.u8 & 0x20 ? 0 : (ctx.r3.u32 << (r29.u8 & 0x3F));
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stwu r7,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	r11.u32 = ea;
	// stwu r20,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, r20.u32);
	r11.u32 = ea;
	// stwu r19,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, r19.u32);
	r11.u32 = ea;
	// stwu r6,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	r11.u32 = ea;
	// stwu r8,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	r11.u32 = ea;
	// lwz r10,56(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// ble cr6,0x82192eb0
	if (!cr6.getGT()) goto loc_82192EB0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8219d6d8
	sub_8219D6D8(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_82192EB0:
	// lwz r10,12740(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12740);
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// addi r27,r27,8
	r27.s64 = r27.s64 + 8;
	// addi r28,r28,16
	r28.s64 = r28.s64 + 16;
	// addi r29,r29,2
	r29.s64 = r29.s64 + 2;
	// cmplw cr6,r26,r10
	cr6.compare<uint32_t>(r26.u32, ctx.r10.u32, xer);
	// blt cr6,0x82192dc4
	if (cr6.getLT()) goto loc_82192DC4;
loc_82192ECC:
	// lbz r10,10943(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 10943);
	// rlwinm. r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82192f2c
	if (cr0.getEQ()) goto loc_82192F2C;
	// lbz r10,10940(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 10940);
	// rlwinm. r10,r10,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82192f2c
	if (cr0.getEQ()) goto loc_82192F2C;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// li r9,1
	ctx.r9.s64 = 1;
	// lis r8,-16382
	ctx.r8.s64 = -1073610752;
	// lis r7,4
	ctx.r7.s64 = 262144;
	// ori r8,r8,11521
	ctx.r8.u64 = ctx.r8.u64 | 11521;
	// stwu r10,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	r11.u32 = ea;
	// ori r7,r7,129
	ctx.r7.u64 = ctx.r7.u64 | 129;
	// clrlwi r6,r24,18
	ctx.r6.u64 = r24.u32 & 0x3FFF;
	// rlwinm r10,r23,16,2,15
	ctx.r10.u64 = __builtin_rotateleft64(r23.u32 | (r23.u64 << 32), 16) & 0x3FFF0000;
	// rlwinm r5,r21,16,2,15
	ctx.r5.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 16) & 0x3FFF0000;
	// or r10,r10,r6
	ctx.r10.u64 = ctx.r10.u64 | ctx.r6.u64;
	// stwu r9,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r9.u32);
	r11.u32 = ea;
	// clrlwi r6,r22,18
	ctx.r6.u64 = r22.u32 & 0x3FFF;
	// or r6,r5,r6
	ctx.r6.u64 = ctx.r5.u64 | ctx.r6.u64;
	// stwu r8,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r8.u32);
	r11.u32 = ea;
	// stwu r7,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r7.u32);
	r11.u32 = ea;
	// stwu r10,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	r11.u32 = ea;
	// stwu r6,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r6.u32);
	r11.u32 = ea;
loc_82192F2C:
	// stwu r30,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, r30.u32);
	r11.u32 = ea;
	// lwz r10,12700(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12700);
	// stwu r10,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	r11.u32 = ea;
	// stwu r25,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, r25.u32);
	r11.u32 = ea;
	// lwz r10,12704(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12704);
	// stwu r10,4(r11)
	ea = 4 + r11.u32;
	PPC_STORE_U32(ea, ctx.r10.u32);
	r11.u32 = ea;
loc_82192F44:
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x823ed164
	return;
}

__attribute__((alias("__imp__sub_82192F50"))) PPC_WEAK_FUNC(sub_82192F50);
PPC_FUNC_IMPL(__imp__sub_82192F50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,10568(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 10568);
	// rlwimi r4,r11,0,0,28
	ctx.r4.u64 = (__builtin_rotateleft32(r11.u32, 0) & 0xFFFFFFF8) | (ctx.r4.u64 & 0xFFFFFFFF00000007);
	// stw r4,10568(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10568, ctx.r4.u32);
	// ld r11,16(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82192F70"))) PPC_WEAK_FUNC(sub_82192F70);
PPC_FUNC_IMPL(__imp__sub_82192F70) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,10568(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 10568);
	// clrlwi r3,r11,29
	ctx.r3.u64 = r11.u32 & 0x7;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82192F80"))) PPC_WEAK_FUNC(sub_82192F80);
PPC_FUNC_IMPL(__imp__sub_82192F80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,10568(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 10568);
	// rlwimi r11,r4,3,21,28
	r11.u64 = (__builtin_rotateleft32(ctx.r4.u32, 3) & 0x7F8) | (r11.u64 & 0xFFFFFFFFFFFFF807);
	// stw r11,10568(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10568, r11.u32);
	// ld r11,16(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82192FA0"))) PPC_WEAK_FUNC(sub_82192FA0);
PPC_FUNC_IMPL(__imp__sub_82192FA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,10568(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 10568);
	// rlwinm r3,r11,29,24,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0xFF;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82192FB0"))) PPC_WEAK_FUNC(sub_82192FB0);
PPC_FUNC_IMPL(__imp__sub_82192FB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,10556(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 10556);
	// rlwimi r11,r4,3,28,28
	r11.u64 = (__builtin_rotateleft32(ctx.r4.u32, 3) & 0x8) | (r11.u64 & 0xFFFFFFFFFFFFFFF7);
	// stw r11,10556(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10556, r11.u32);
	// ld r11,16(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// ori r11,r11,512
	r11.u64 = r11.u64 | 512;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// oris r11,r11,4
	r11.u64 = r11.u64 | 262144;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82192FD8"))) PPC_WEAK_FUNC(sub_82192FD8);
PPC_FUNC_IMPL(__imp__sub_82192FD8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,10556(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 10556);
	// rlwinm r3,r11,29,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0x1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82192FE8"))) PPC_WEAK_FUNC(sub_82192FE8);
PPC_FUNC_IMPL(__imp__sub_82192FE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,11844(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11844);
	// rlwimi r11,r4,31,0,0
	r11.u64 = (__builtin_rotateleft32(ctx.r4.u32, 31) & 0x80000000) | (r11.u64 & 0xFFFFFFFF7FFFFFFF);
	// stw r11,11844(r3)
	PPC_STORE_U32(ctx.r3.u32 + 11844, r11.u32);
	// rlwinm. r10,r11,0,1,1
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r11,11840(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// bne 0x82193020
	if (!cr0.getEQ()) goto loc_82193020;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// rlwinm r9,r11,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// andi. r10,r11,4112
	ctx.r10.u64 = r11.u64 & 4112;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// rlwinm r10,r10,12,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0xFFFF0000;
	// rlwinm r10,r10,0,12,10
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFEFFFFF;
	// rlwinm r10,r10,0,4,2
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFEFFFFFFF;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
loc_82193020:
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// bne cr6,0x82193030
	if (!cr6.getEQ()) goto loc_82193030;
	// lis r11,1
	r11.s64 = 65536;
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
loc_82193030:
	// stw r11,10552(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10552, r11.u32);
	// stw r11,10584(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10584, r11.u32);
	// stw r11,10588(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10588, r11.u32);
	// stw r11,10592(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10592, r11.u32);
	// ld r11,16(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82193068"))) PPC_WEAK_FUNC(sub_82193068);
PPC_FUNC_IMPL(__imp__sub_82193068) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,11844(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11844);
	// rlwinm r3,r11,1,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82193078"))) PPC_WEAK_FUNC(sub_82193078);
PPC_FUNC_IMPL(__imp__sub_82193078) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// lwz r10,11840(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// lwz r11,11844(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11844);
	// rlwimi r10,r4,5,24,26
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r4.u32, 5) & 0xE0) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFF1F);
	// stw r10,11840(r3)
	PPC_STORE_U32(ctx.r3.u32 + 11840, ctx.r10.u32);
	// rlwinm. r10,r11,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beqlr 
	if (cr0.getEQ()) return;
	// rlwinm. r10,r11,0,1,1
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r11,11840(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// bne 0x821930bc
	if (!cr0.getEQ()) goto loc_821930BC;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// rlwinm r9,r11,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// andi. r10,r11,4112
	ctx.r10.u64 = r11.u64 & 4112;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// rlwinm r10,r10,12,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0xFFFF0000;
	// rlwinm r10,r10,0,12,10
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFEFFFFF;
	// rlwinm r10,r10,0,4,2
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFEFFFFFFF;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
loc_821930BC:
	// stw r11,10552(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10552, r11.u32);
	// stw r11,10584(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10584, r11.u32);
	// stw r11,10588(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10588, r11.u32);
	// stw r11,10592(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10592, r11.u32);
	// ld r11,16(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821930F8"))) PPC_WEAK_FUNC(sub_821930F8);
PPC_FUNC_IMPL(__imp__sub_821930F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,11840(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// rlwinm r3,r11,27,29,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x7;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82193108"))) PPC_WEAK_FUNC(sub_82193108);
PPC_FUNC_IMPL(__imp__sub_82193108) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// lwz r10,11840(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// lwz r11,11844(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11844);
	// rlwimi r10,r4,0,27,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r4.u32, 0) & 0x1F) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFE0);
	// stw r10,11840(r3)
	PPC_STORE_U32(ctx.r3.u32 + 11840, ctx.r10.u32);
	// rlwinm. r10,r11,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beqlr 
	if (cr0.getEQ()) return;
	// rlwinm. r10,r11,0,1,1
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r11,11840(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// bne 0x8219314c
	if (!cr0.getEQ()) goto loc_8219314C;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// rlwinm r9,r11,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// andi. r10,r11,4112
	ctx.r10.u64 = r11.u64 & 4112;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// rlwinm r10,r10,12,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0xFFFF0000;
	// rlwinm r10,r10,0,12,10
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFEFFFFF;
	// rlwinm r10,r10,0,4,2
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFEFFFFFFF;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
loc_8219314C:
	// stw r11,10552(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10552, r11.u32);
	// stw r11,10584(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10584, r11.u32);
	// stw r11,10588(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10588, r11.u32);
	// stw r11,10592(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10592, r11.u32);
	// ld r11,16(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82193188"))) PPC_WEAK_FUNC(sub_82193188);
PPC_FUNC_IMPL(__imp__sub_82193188) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,11840(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// clrlwi r3,r11,27
	ctx.r3.u64 = r11.u32 & 0x1F;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82193198"))) PPC_WEAK_FUNC(sub_82193198);
PPC_FUNC_IMPL(__imp__sub_82193198) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// lwz r10,11840(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// lwz r11,11844(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11844);
	// rlwimi r10,r4,8,19,23
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r4.u32, 8) & 0x1F00) | (ctx.r10.u64 & 0xFFFFFFFFFFFFE0FF);
	// stw r10,11840(r3)
	PPC_STORE_U32(ctx.r3.u32 + 11840, ctx.r10.u32);
	// rlwinm. r10,r11,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beqlr 
	if (cr0.getEQ()) return;
	// rlwinm. r10,r11,0,1,1
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r11,11840(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// bne 0x821931dc
	if (!cr0.getEQ()) goto loc_821931DC;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// rlwinm r9,r11,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// andi. r10,r11,4112
	ctx.r10.u64 = r11.u64 & 4112;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// rlwinm r10,r10,12,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 12) & 0xFFFF0000;
	// rlwinm r10,r10,0,12,10
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFEFFFFF;
	// rlwinm r10,r10,0,4,2
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFEFFFFFFF;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
loc_821931DC:
	// stw r11,10552(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10552, r11.u32);
	// stw r11,10584(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10584, r11.u32);
	// stw r11,10588(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10588, r11.u32);
	// stw r11,10592(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10592, r11.u32);
	// ld r11,16(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82193218"))) PPC_WEAK_FUNC(sub_82193218);
PPC_FUNC_IMPL(__imp__sub_82193218) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,11840(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// rlwinm r3,r11,24,27,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 24) & 0x1F;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82193228"))) PPC_WEAK_FUNC(sub_82193228);
PPC_FUNC_IMPL(__imp__sub_82193228) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// lwz r10,11840(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// lwz r11,11844(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11844);
	// rlwimi r10,r4,21,8,10
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r4.u32, 21) & 0xE00000) | (ctx.r10.u64 & 0xFFFFFFFFFF1FFFFF);
	// stw r10,11840(r3)
	PPC_STORE_U32(ctx.r3.u32 + 11840, ctx.r10.u32);
	// rlwinm. r10,r11,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beqlr 
	if (cr0.getEQ()) return;
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beqlr 
	if (cr0.getEQ()) return;
	// lwz r11,11840(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// stw r11,10552(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10552, r11.u32);
	// stw r11,10584(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10584, r11.u32);
	// stw r11,10588(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10588, r11.u32);
	// stw r11,10592(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10592, r11.u32);
	// ld r11,16(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82193288"))) PPC_WEAK_FUNC(sub_82193288);
PPC_FUNC_IMPL(__imp__sub_82193288) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lwz r11,11840(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// rlwinm r3,r11,11,29,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 11) & 0x7;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82193298"))) PPC_WEAK_FUNC(sub_82193298);
PPC_FUNC_IMPL(__imp__sub_82193298) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// lwz r10,11840(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// lwz r11,11844(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11844);
	// rlwimi r10,r4,16,11,15
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r4.u32, 16) & 0x1F0000) | (ctx.r10.u64 & 0xFFFFFFFFFFE0FFFF);
	// stw r10,11840(r3)
	PPC_STORE_U32(ctx.r3.u32 + 11840, ctx.r10.u32);
	// rlwinm. r10,r11,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beqlr 
	if (cr0.getEQ()) return;
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beqlr 
	if (cr0.getEQ()) return;
	// lwz r11,11840(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// stw r11,10552(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10552, r11.u32);
	// stw r11,10584(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10584, r11.u32);
	// stw r11,10588(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10588, r11.u32);
	// stw r11,10592(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10592, r11.u32);
	// ld r11,16(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_821932F8"))) PPC_WEAK_FUNC(sub_821932F8);
PPC_FUNC_IMPL(__imp__sub_821932F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lhz r11,11840(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 11840);
	// clrlwi r3,r11,27
	ctx.r3.u64 = r11.u32 & 0x1F;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82193308"))) PPC_WEAK_FUNC(sub_82193308);
PPC_FUNC_IMPL(__imp__sub_82193308) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// lwz r10,11840(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// lwz r11,11844(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11844);
	// rlwimi r10,r4,24,3,7
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r4.u32, 24) & 0x1F000000) | (ctx.r10.u64 & 0xFFFFFFFFE0FFFFFF);
	// stw r10,11840(r3)
	PPC_STORE_U32(ctx.r3.u32 + 11840, ctx.r10.u32);
	// rlwinm. r10,r11,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beqlr 
	if (cr0.getEQ()) return;
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beqlr 
	if (cr0.getEQ()) return;
	// lwz r11,11840(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 11840);
	// stw r11,10552(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10552, r11.u32);
	// stw r11,10584(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10584, r11.u32);
	// stw r11,10588(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10588, r11.u32);
	// stw r11,10592(r3)
	PPC_STORE_U32(ctx.r3.u32 + 10592, r11.u32);
	// ld r11,16(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 16);
	// ori r11,r11,1024
	r11.u64 = r11.u64 | 1024;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// std r11,16(r3)
	PPC_STORE_U64(ctx.r3.u32 + 16, r11.u64);
	// blr 
	return;
}

