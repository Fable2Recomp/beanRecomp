#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_8209EC28"))) PPC_WEAK_FUNC(sub_8209EC28);
PPC_FUNC_IMPL(__imp__sub_8209EC28) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed118
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,-6396(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -6396);
	// cmpwi cr6,r11,90
	cr6.compare<int32_t>(r11.s32, 90, xer);
	// bne cr6,0x8209ec54
	if (!cr6.getEQ()) goto loc_8209EC54;
	// bl 0x821086c0
	sub_821086C0(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x823ed168
	return;
loc_8209EC54:
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// mr r22,r3
	r22.u64 = ctx.r3.u64;
	// li r26,0
	r26.s64 = 0;
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// lis r29,-32014
	r29.s64 = -2098069504;
	// ble cr6,0x8209ee08
	if (!cr6.getGT()) goto loc_8209EE08;
	// clrlwi r20,r31,24
	r20.u64 = r31.u32 & 0xFF;
	// lis r23,-32015
	r23.s64 = -2098135040;
	// lis r24,-32015
	r24.s64 = -2098135040;
	// lis r28,-32010
	r28.s64 = -2097807360;
	// lis r25,-32015
	r25.s64 = -2098135040;
	// li r27,-1
	r27.s64 = -1;
	// li r21,-32704
	r21.s64 = -32704;
loc_8209EC88:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820ca0b0
	sub_820CA0B0(ctx, base);
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// lhz r4,2306(r11)
	ctx.r4.u64 = PPC_LOAD_U16(r11.u32 + 2306);
	// lhz r3,2304(r11)
	ctx.r3.u64 = PPC_LOAD_U16(r11.u32 + 2304);
	// bl 0x8210e1a8
	sub_8210E1A8(ctx, base);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// lhz r4,2310(r11)
	ctx.r4.u64 = PPC_LOAD_U16(r11.u32 + 2310);
	// lhz r3,2308(r11)
	ctx.r3.u64 = PPC_LOAD_U16(r11.u32 + 2308);
	// bl 0x8210e228
	sub_8210E228(ctx, base);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// lfs f1,4728(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4728);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210e310
	sub_8210E310(ctx, base);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// lfs f1,4732(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4732);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210e350
	sub_8210E350(ctx, base);
	// bl 0x8210df98
	sub_8210DF98(ctx, base);
	// bl 0x82096180
	sub_82096180(ctx, base);
	// bl 0x82139320
	sub_82139320(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x8209ece4
	if (!cr6.getEQ()) goto loc_8209ECE4;
	// bl 0x820e8c18
	sub_820E8C18(ctx, base);
loc_8209ECE4:
	// bl 0x82139320
	sub_82139320(ctx, base);
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// bne cr6,0x8209ecf4
	if (!cr6.getEQ()) goto loc_8209ECF4;
	// bl 0x820be390
	sub_820BE390(ctx, base);
loc_8209ECF4:
	// lbz r11,-8431(r23)
	r11.u64 = PPC_LOAD_U8(r23.u32 + -8431);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8209ed04
	if (cr6.getEQ()) goto loc_8209ED04;
	// bl 0x8214afc8
	sub_8214AFC8(ctx, base);
loc_8209ED04:
	// bl 0x82117788
	sub_82117788(ctx, base);
	// cmplwi cr6,r20,0
	cr6.compare<uint32_t>(r20.u32, 0, xer);
	// bne cr6,0x8209ed14
	if (!cr6.getEQ()) goto loc_8209ED14;
	// bl 0x820cfbb0
	sub_820CFBB0(ctx, base);
loc_8209ED14:
	// bl 0x820cf1d8
	sub_820CF1D8(ctx, base);
	// bl 0x820ce618
	sub_820CE618(ctx, base);
	// bl 0x820cdde0
	sub_820CDDE0(ctx, base);
	// bl 0x820b3d28
	sub_820B3D28(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8209ed30
	if (cr6.getEQ()) goto loc_8209ED30;
	// bl 0x820cf4f0
	sub_820CF4F0(ctx, base);
loc_8209ED30:
	// bl 0x820b3d38
	sub_820B3D38(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8209ed4c
	if (cr6.getEQ()) goto loc_8209ED4C;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820a74a0
	sub_820A74A0(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x820a74a0
	sub_820A74A0(ctx, base);
loc_8209ED4C:
	// bl 0x820cfd38
	sub_820CFD38(ctx, base);
	// bl 0x82117338
	sub_82117338(ctx, base);
	// lbz r11,-13406(r25)
	r11.u64 = PPC_LOAD_U8(r25.u32 + -13406);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8209ed9c
	if (cr6.getEQ()) goto loc_8209ED9C;
	// lwz r11,21420(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 21420);
	// li r30,0
	r30.s64 = 0;
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8209ed9c
	if (cr6.getEQ()) goto loc_8209ED9C;
	// li r31,0
	r31.s64 = 0;
loc_8209ED78:
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82114428
	sub_82114428(ctx, base);
	// lwz r11,21420(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 21420);
	// addi r31,r31,8
	r31.s64 = r31.s64 + 8;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// lwzx r11,r31,r11
	r11.u64 = PPC_LOAD_U32(r31.u32 + r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8209ed78
	if (!cr6.getEQ()) goto loc_8209ED78;
loc_8209ED9C:
	// lbz r11,-13407(r24)
	r11.u64 = PPC_LOAD_U8(r24.u32 + -13407);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8209edb4
	if (cr6.getEQ()) goto loc_8209EDB4;
	// bl 0x823d22e0
	sub_823D22E0(ctx, base);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x82112dd0
	sub_82112DD0(ctx, base);
loc_8209EDB4:
	// bl 0x820d86a0
	sub_820D86A0(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x8213dfd8
	sub_8213DFD8(ctx, base);
	// bl 0x82145ed8
	sub_82145ED8(ctx, base);
	// bl 0x821409d0
	sub_821409D0(ctx, base);
	// li r3,11
	ctx.r3.s64 = 11;
	// bl 0x82136fa0
	sub_82136FA0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8209edfc
	if (cr6.getEQ()) goto loc_8209EDFC;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820a0d30
	sub_820A0D30(ctx, base);
	// cmpwi cr6,r3,23
	cr6.compare<int32_t>(ctx.r3.s32, 23, xer);
	// bne cr6,0x8209edf8
	if (!cr6.getEQ()) goto loc_8209EDF8;
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// lwz r11,4228(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4228);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8209edfc
	if (!cr6.getEQ()) goto loc_8209EDFC;
loc_8209EDF8:
	// bl 0x820aaad0
	sub_820AAAD0(ctx, base);
loc_8209EDFC:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// cmpw cr6,r26,r22
	cr6.compare<int32_t>(r26.s32, r22.s32, xer);
	// blt cr6,0x8209ec88
	if (cr6.getLT()) goto loc_8209EC88;
loc_8209EE08:
	// li r4,240
	ctx.r4.s64 = 240;
	// li r3,320
	ctx.r3.s64 = 320;
	// bl 0x8210e1a8
	sub_8210E1A8(ctx, base);
	// li r4,240
	ctx.r4.s64 = 240;
	// li r3,320
	ctx.r3.s64 = 320;
	// bl 0x8210e170
	sub_8210E170(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8210e228
	sub_8210E228(ctx, base);
	// bl 0x8210df98
	sub_8210DF98(ctx, base);
	// bl 0x82096180
	sub_82096180(ctx, base);
	// bl 0x82099cd0
	sub_82099CD0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,16
	ctx.r6.s64 = 16;
	// lfs f1,2776(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f1.f64 = double(temp.f32);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,13356(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 13356);
	// bl 0x821974b8
	sub_821974B8(ctx, base);
	// li r31,0
	r31.s64 = 0;
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// ble cr6,0x8209eee8
	if (!cr6.getGT()) goto loc_8209EEE8;
loc_8209EE70:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ca0b0
	sub_820CA0B0(ctx, base);
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// lhz r4,2306(r11)
	ctx.r4.u64 = PPC_LOAD_U16(r11.u32 + 2306);
	// lhz r3,2304(r11)
	ctx.r3.u64 = PPC_LOAD_U16(r11.u32 + 2304);
	// bl 0x8210e1a8
	sub_8210E1A8(ctx, base);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// lhz r4,2310(r11)
	ctx.r4.u64 = PPC_LOAD_U16(r11.u32 + 2310);
	// lhz r3,2308(r11)
	ctx.r3.u64 = PPC_LOAD_U16(r11.u32 + 2308);
	// bl 0x8210e228
	sub_8210E228(ctx, base);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// lfs f1,4728(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4728);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210e310
	sub_8210E310(ctx, base);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// lfs f1,4732(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4732);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210e350
	sub_8210E350(ctx, base);
	// bl 0x8210df98
	sub_8210DF98(ctx, base);
	// bl 0x82096180
	sub_82096180(ctx, base);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// lwz r11,128(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 128);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x8209eedc
	if (cr6.getEQ()) goto loc_8209EEDC;
	// bl 0x820aa748
	sub_820AA748(ctx, base);
	// bl 0x820a5500
	sub_820A5500(ctx, base);
	// bl 0x820a35a8
	sub_820A35A8(ctx, base);
	// bl 0x820be560
	sub_820BE560(ctx, base);
loc_8209EEDC:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmpw cr6,r31,r22
	cr6.compare<int32_t>(r31.s32, r22.s32, xer);
	// blt cr6,0x8209ee70
	if (cr6.getLT()) goto loc_8209EE70;
loc_8209EEE8:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x823ed168
	return;
}

__attribute__((alias("__imp__sub_8209EEF0"))) PPC_WEAK_FUNC(sub_8209EEF0);
PPC_FUNC_IMPL(__imp__sub_8209EEF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r11,-6364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -6364);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x8209ef0c
	if (!cr6.getLT()) goto loc_8209EF0C;
	// li r11,0
	r11.s64 = 0;
	// stw r11,-6364(r10)
	PPC_STORE_U32(ctx.r10.u32 + -6364, r11.u32);
	// b 0x8209ef10
	goto loc_8209EF10;
loc_8209EF0C:
	// bne cr6,0x8209efa4
	if (!cr6.getEQ()) goto loc_8209EFA4;
loc_8209EF10:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,3060(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3060);
	f0.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19408(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19408, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19412(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19412, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f13,19416(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 19416, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f13,19420(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 19420, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19424(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19424, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,12904(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12904);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f12,27968(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 27968, temp.u32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f13,27972(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 27972, temp.u32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f0,27976(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 27976, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,12900(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12900);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32033
	r11.s64 = -2099314688;
	// stfs f13,-8808(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + -8808, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,12896(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12896);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f13,19388(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 19388, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19428(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19428, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,12892(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12892);
	f0.f64 = double(temp.f32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f0,27980(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 27980, temp.u32);
	// blr 
	return;
loc_8209EFA4:
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x8209f048
	if (!cr6.getEQ()) goto loc_8209F048;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,2776(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f13,19408(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 19408, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f13,19412(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 19412, temp.u32);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r11,11488(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 11488);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,12888(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12888);
	f0.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19416(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19416, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19420(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19420, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f13,19424(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 19424, temp.u32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f0,27968(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 27968, temp.u32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f0,27972(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 27972, temp.u32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f13,27976(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 27976, temp.u32);
	// lis r11,-32033
	r11.s64 = -2099314688;
	// stfs f0,-8808(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + -8808, temp.u32);
	// beq cr6,0x8209f01c
	if (cr6.getEQ()) goto loc_8209F01C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,12884(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12884);
	f0.f64 = double(temp.f32);
loc_8209F01C:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19388(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19388, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,12896(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12896);
	f0.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19428(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19428, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f0,27980(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 27980, temp.u32);
	// blr 
	return;
loc_8209F048:
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x8209f0f8
	if (!cr6.getEQ()) goto loc_8209F0F8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2776(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19408(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19408, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19412(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19412, temp.u32);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r11,11488(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 11488);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19416(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19416, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19420(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19420, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19424(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19424, temp.u32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f0,27968(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 27968, temp.u32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f0,27972(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 27972, temp.u32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f0,27976(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 27976, temp.u32);
	// lis r11,-32033
	r11.s64 = -2099314688;
	// stfs f0,-8808(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + -8808, temp.u32);
	// beq cr6,0x8209f0d4
	if (cr6.getEQ()) goto loc_8209F0D4;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,12888(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12888);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f13,19388(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 19388, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19428(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19428, temp.u32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f0,27980(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 27980, temp.u32);
	// blr 
	return;
loc_8209F0D4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,12892(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12892);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f13,19388(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 19388, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19428(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19428, temp.u32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f0,27980(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 27980, temp.u32);
	// blr 
	return;
loc_8209F0F8:
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2776(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19408(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19408, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19412(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19412, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19416(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19416, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19420(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19420, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19424(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19424, temp.u32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f0,27968(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 27968, temp.u32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f0,27972(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 27972, temp.u32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f0,27976(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 27976, temp.u32);
	// lis r11,-32033
	r11.s64 = -2099314688;
	// stfs f0,-8808(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + -8808, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19388(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19388, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stfs f0,19428(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 19428, temp.u32);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// stfs f0,27980(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 27980, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8209F170"))) PPC_WEAK_FUNC(sub_8209F170);
PPC_FUNC_IMPL(__imp__sub_8209F170) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// addi r12,r1,-40
	r12.s64 = ctx.r1.s64 + -40;
	// bl 0x823ed548
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82137f30
	sub_82137F30(ctx, base);
	// extsb r29,r31
	r29.s64 = r31.s8;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820ca110
	sub_820CA110(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82139330
	sub_82139330(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// lis r30,-32014
	r30.s64 = -2098069504;
	// beq cr6,0x8209f344
	if (cr6.getEQ()) goto loc_8209F344;
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// bne cr6,0x8209f394
	if (!cr6.getEQ()) goto loc_8209F394;
	// bl 0x82139340
	sub_82139340(ctx, base);
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// bne cr6,0x8209f2fc
	if (!cr6.getEQ()) goto loc_8209F2FC;
	// bl 0x820ebbf8
	sub_820EBBF8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8209f21c
	if (!cr6.getEQ()) goto loc_8209F21C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820a0248
	sub_820A0248(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// bl 0x820a0148
	sub_820A0148(ctx, base);
	// li r4,-1
	ctx.r4.s64 = -1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// bl 0x820a0548
	sub_820A0548(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820a0448
	sub_820A0448(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f29,f1
	ctx.fpscr.disableFlushMode();
	f29.f64 = ctx.f1.f64;
	// bl 0x820a0348
	sub_820A0348(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// b 0x8209f32c
	goto loc_8209F32C;
loc_8209F21C:
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8209f254
	if (cr6.getEQ()) goto loc_8209F254;
	// lwz r10,428(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8209f254
	if (cr6.getEQ()) goto loc_8209F254;
	// rotlwi r11,r10,0
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8209f254
	if (cr6.getEQ()) goto loc_8209F254;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// rlwinm r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8209f2ac
	if (!cr6.getEQ()) goto loc_8209F2AC;
loc_8209F254:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// blt cr6,0x8209f2ac
	if (cr6.getLT()) goto loc_8209F2AC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820a0248
	sub_820A0248(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// bl 0x820a0148
	sub_820A0148(ctx, base);
	// li r4,-1
	ctx.r4.s64 = -1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f29,f1
	ctx.fpscr.disableFlushMode();
	f29.f64 = ctx.f1.f64;
	// bl 0x820a0548
	sub_820A0548(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820a0448
	sub_820A0448(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f28,f1
	ctx.fpscr.disableFlushMode();
	f28.f64 = ctx.f1.f64;
	// bl 0x820a0348
	sub_820A0348(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// fmr f2,f28
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = f28.f64;
	// fmr f3,f29
	ctx.f3.f64 = f29.f64;
	// fmr f4,f30
	ctx.f4.f64 = f30.f64;
	// b 0x8209f2c4
	goto loc_8209F2C4;
loc_8209F2AC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r5,0
	ctx.r5.s64 = 0;
	// lfs f4,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f4.f64 = double(temp.f32);
	// fmr f3,f4
	ctx.f3.f64 = ctx.f4.f64;
	// fmr f2,f4
	ctx.f2.f64 = ctx.f4.f64;
	// fmr f1,f4
	ctx.f1.f64 = ctx.f4.f64;
loc_8209F2C4:
	// bl 0x820bdc80
	sub_820BDC80(ctx, base);
	// bl 0x820ca338
	sub_820CA338(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8209f33c
	if (cr6.getEQ()) goto loc_8209F33C;
	// bl 0x8216c150
	sub_8216C150(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8209f33c
	if (cr6.getEQ()) goto loc_8209F33C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x82159c68
	sub_82159C68(ctx, base);
	// bl 0x8213bf80
	sub_8213BF80(ctx, base);
	// b 0x8209f394
	goto loc_8209F394;
loc_8209F2FC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820a0248
	sub_820A0248(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// bl 0x820a0148
	sub_820A0148(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// bl 0x820a0448
	sub_820A0448(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f29,f1
	ctx.fpscr.disableFlushMode();
	f29.f64 = ctx.f1.f64;
	// bl 0x820a0348
	sub_820A0348(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
loc_8209F32C:
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// fmr f3,f30
	ctx.f3.f64 = f30.f64;
	// fmr f2,f29
	ctx.f2.f64 = f29.f64;
	// bl 0x820bdc80
	sub_820BDC80(ctx, base);
loc_8209F33C:
	// bl 0x8213bf80
	sub_8213BF80(ctx, base);
	// b 0x8209f394
	goto loc_8209F394;
loc_8209F344:
	// bl 0x82139340
	sub_82139340(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8209f364
	if (cr6.getEQ()) goto loc_8209F364;
	// bl 0x82139340
	sub_82139340(ctx, base);
	// cmpwi cr6,r3,59
	cr6.compare<int32_t>(ctx.r3.s32, 59, xer);
	// bne cr6,0x8209f364
	if (!cr6.getEQ()) goto loc_8209F364;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r11,17304(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 17304);
loc_8209F364:
	// li r4,-1
	ctx.r4.s64 = -1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820a0548
	sub_820A0548(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820a0248
	sub_820A0248(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// bl 0x820a0148
	sub_820A0148(ctx, base);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// fmr f2,f31
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = f31.f64;
	// bl 0x820e8880
	sub_820E8880(ctx, base);
loc_8209F394:
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r11,556(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 556);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r5,r11,27,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// bl 0x82090b68
	sub_82090B68(ctx, base);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// lwz r11,556(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 556);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r5,r11,27,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// bl 0x82090b68
	sub_82090B68(ctx, base);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lwz r9,428(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// lfs f0,1328(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1328);
	f0.f64 = double(temp.f32);
	// lfs f13,1336(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1336);
	ctx.f13.f64 = double(temp.f32);
	// lwz r10,-908(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -908);
	// lfs f11,12(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f0,f11,f0
	f0.f64 = double(float(ctx.f11.f64 - f0.f64));
	// lfs f10,20(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f13,f10,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 - ctx.f13.f64));
	// lfs f12,56(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f0,f0,f0
	f0.f64 = double(float(f0.f64 * f0.f64));
	// fmadds f0,f13,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// fsqrts f0,f0
	f0.f64 = double(float(sqrt(f0.f64)));
	// fadds f0,f0,f12
	f0.f64 = double(float(f0.f64 + ctx.f12.f64));
	// stfs f0,56(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 56, temp.u32);
	// bl 0x820ec268
	sub_820EC268(ctx, base);
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// bne cr6,0x8209f498
	if (!cr6.getEQ()) goto loc_8209F498;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x8209f4cc
	if (!cr6.getEQ()) goto loc_8209F4CC;
	// bl 0x820c15a8
	sub_820C15A8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8209f4c0
	if (cr6.getEQ()) goto loc_8209F4C0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820a0d30
	sub_820A0D30(ctx, base);
	// cmpwi cr6,r3,88
	cr6.compare<int32_t>(ctx.r3.s32, 88, xer);
	// beq cr6,0x8209f464
	if (cr6.getEQ()) goto loc_8209F464;
	// li r4,88
	ctx.r4.s64 = 88;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820a0cf8
	sub_820A0CF8(ctx, base);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lwz r10,2380(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2380);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x8209f464
	if (!cr6.getEQ()) goto loc_8209F464;
	// li r10,5
	ctx.r10.s64 = 5;
	// stw r10,2380(r11)
	PPC_STORE_U32(r11.u32 + 2380, ctx.r10.u32);
loc_8209F464:
	// lwz r11,-908(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -908);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r9,96(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 96);
	// lwz r10,-6384(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -6384);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// stw r10,96(r11)
	PPC_STORE_U32(r11.u32 + 96, ctx.r10.u32);
	// lwz r11,-908(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -908);
	// stb r8,105(r11)
	PPC_STORE_U8(r11.u32 + 105, ctx.r8.u8);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// addi r12,r1,-40
	r12.s64 = ctx.r1.s64 + -40;
	// bl 0x823ed594
	// b 0x823ed188
	return;
loc_8209F498:
	// bl 0x820ec268
	sub_820EC268(ctx, base);
	// cmpwi cr6,r3,3
	cr6.compare<int32_t>(ctx.r3.s32, 3, xer);
	// bne cr6,0x8209f4cc
	if (!cr6.getEQ()) goto loc_8209F4CC;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x8209f4cc
	if (!cr6.getEQ()) goto loc_8209F4CC;
	// bl 0x820c1600
	sub_820C1600(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r10,1
	ctx.r10.s64 = 1;
	// bne cr6,0x8209f4c4
	if (!cr6.getEQ()) goto loc_8209F4C4;
loc_8209F4C0:
	// li r10,0
	ctx.r10.s64 = 0;
loc_8209F4C4:
	// lwz r11,-908(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -908);
	// stb r10,105(r11)
	PPC_STORE_U8(r11.u32 + 105, ctx.r10.u8);
loc_8209F4CC:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// addi r12,r1,-40
	r12.s64 = ctx.r1.s64 + -40;
	// bl 0x823ed594
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_8209F4E0"))) PPC_WEAK_FUNC(sub_8209F4E0);
PPC_FUNC_IMPL(__imp__sub_8209F4E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lwz r3,13356(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 13356);
	// bl 0x82198d58
	sub_82198D58(ctx, base);
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lwz r3,-6344(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + -6344);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8209f520
	if (cr6.getEQ()) goto loc_8209F520;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8209f520
	if (cr6.getEQ()) goto loc_8209F520;
	// lwz r3,-6344(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + -6344);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_8209F520:
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lwz r11,-6396(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -6396);
	// cmpwi cr6,r11,90
	cr6.compare<int32_t>(r11.s32, 90, xer);
	// beq cr6,0x8209f534
	if (cr6.getEQ()) goto loc_8209F534;
	// bl 0x820c21d8
	sub_820C21D8(ctx, base);
loc_8209F534:
	// bl 0x82137cf8
	sub_82137CF8(ctx, base);
	// bl 0x82120e78
	sub_82120E78(ctx, base);
	// bl 0x82135df8
	sub_82135DF8(ctx, base);
	// bl 0x82143960
	sub_82143960(ctx, base);
	// bl 0x820e83a0
	sub_820E83A0(ctx, base);
	// lwz r3,-6396(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + -6396);
	// bl 0x820d0848
	sub_820D0848(ctx, base);
	// bl 0x820cc868
	sub_820CC868(ctx, base);
	// bl 0x820bfd90
	sub_820BFD90(ctx, base);
	// bl 0x823d22e0
	sub_823D22E0(ctx, base);
	// bl 0x82115860
	sub_82115860(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8209F578"))) PPC_WEAK_FUNC(sub_8209F578);
PPC_FUNC_IMPL(__imp__sub_8209F578) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// stw r3,-6388(r11)
	PPC_STORE_U32(r11.u32 + -6388, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8209F588"))) PPC_WEAK_FUNC(sub_8209F588);
PPC_FUNC_IMPL(__imp__sub_8209F588) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r3,-6388(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + -6388);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8209F598"))) PPC_WEAK_FUNC(sub_8209F598);
PPC_FUNC_IMPL(__imp__sub_8209F598) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r3,-6364(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + -6364);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8209F5A8"))) PPC_WEAK_FUNC(sub_8209F5A8);
PPC_FUNC_IMPL(__imp__sub_8209F5A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// stw r3,-6364(r11)
	PPC_STORE_U32(r11.u32 + -6364, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8209F5B8"))) PPC_WEAK_FUNC(sub_8209F5B8);
PPC_FUNC_IMPL(__imp__sub_8209F5B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f1,-6340(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6340);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8209F5C8"))) PPC_WEAK_FUNC(sub_8209F5C8);
PPC_FUNC_IMPL(__imp__sub_8209F5C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f1,-6332(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6332);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8209F5D8"))) PPC_WEAK_FUNC(sub_8209F5D8);
PPC_FUNC_IMPL(__imp__sub_8209F5D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed124
	// stfd f29,-104(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -104, f29.u64);
	// stfd f30,-96(r1)
	PPC_STORE_U64(ctx.r1.u32 + -96, f30.u64);
	// stfd f31,-88(r1)
	PPC_STORE_U64(ctx.r1.u32 + -88, f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// b 0x830e0670
	// ERROR 830E0670
	return;
	// li r28,0
	r28.s64 = 0;
	// lis r30,-32014
	r30.s64 = -2098069504;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// lfs f31,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f31.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// li r3,1
	ctx.r3.s64 = 1;
	// stfs f31,-6380(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + -6380, temp.u32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r31,r11,-6396
	r31.s64 = r11.s64 + -6396;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// stw r25,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r25.u32);
	// stfs f31,-6368(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + -6368, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r23,r11,1140
	r23.s64 = r11.s64 + 1140;
	// li r11,1
	r11.s64 = 1;
	// stw r11,12(r23)
	PPC_STORE_U32(r23.u32 + 12, r11.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f30.f64 = double(temp.f32);
	// mr r11,r28
	r11.u64 = r28.u64;
	// stfs f30,56(r31)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 56, temp.u32);
	// stfs f30,72(r31)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 72, temp.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// li r11,1
	r11.s64 = 1;
	// stw r11,-6384(r30)
	PPC_STORE_U32(r30.u32 + -6384, r11.u32);
	// mr r11,r28
	r11.u64 = r28.u64;
	// stw r11,-6372(r10)
	PPC_STORE_U32(ctx.r10.u32 + -6372, r11.u32);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// stw r11,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r11.u32);
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// stw r11,-6376(r10)
	PPC_STORE_U32(ctx.r10.u32 + -6376, r11.u32);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// stw r11,68(r31)
	PPC_STORE_U32(r31.u32 + 68, r11.u32);
	// stw r11,-6344(r10)
	PPC_STORE_U32(ctx.r10.u32 + -6344, r11.u32);
	// bl 0x82118920
	sub_82118920(ctx, base);
	// bl 0x8213dfa0
	sub_8213DFA0(ctx, base);
	// bl 0x82146538
	sub_82146538(ctx, base);
	// cmpwi cr6,r25,90
	cr6.compare<int32_t>(r25.s32, 90, xer);
	// bne cr6,0x8209f6ac
	if (!cr6.getEQ()) goto loc_8209F6AC;
	// bl 0x820ae360
	sub_820AE360(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x82117c90
	sub_82117C90(ctx, base);
	// bl 0x820ea4a8
	sub_820EA4A8(ctx, base);
	// b 0x8209f830
	goto loc_8209F830;
loc_8209F6AC:
	// lis r10,-32010
	ctx.r10.s64 = -2097807360;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r11,r28
	r11.u64 = r28.u64;
	// cmpwi cr6,r3,90
	cr6.compare<int32_t>(ctx.r3.s32, 90, xer);
	// stw r11,2796(r10)
	PPC_STORE_U32(ctx.r10.u32 + 2796, r11.u32);
	// beq cr6,0x8209f734
	if (cr6.getEQ()) goto loc_8209F734;
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8209f734
	if (!cr6.getEQ()) goto loc_8209F734;
	// lwz r11,-6384(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x8209f734
	if (!cr6.getGT()) goto loc_8209F734;
	// lis r11,-32010
	r11.s64 = -2097807360;
	// lwz r11,4024(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4024);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8209f734
	if (cr6.getEQ()) goto loc_8209F734;
	// lis r11,-32010
	r11.s64 = -2097807360;
	// li r30,1
	r30.s64 = 1;
	// addi r29,r11,3544
	r29.s64 = r11.s64 + 3544;
loc_8209F6F8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82136f40
	sub_82136F40(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8209f724
	if (cr6.getEQ()) goto loc_8209F724;
	// lbzx r11,r30,r29
	r11.u64 = PPC_LOAD_U8(r30.u32 + r29.u32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8209f720
	if (cr6.getEQ()) goto loc_8209F720;
	// bl 0x82138080
	sub_82138080(ctx, base);
	// b 0x8209f724
	goto loc_8209F724;
loc_8209F720:
	// bl 0x82137968
	sub_82137968(ctx, base);
loc_8209F724:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmpwi cr6,r30,81
	cr6.compare<int32_t>(r30.s32, 81, xer);
	// blt cr6,0x8209f6f8
	if (cr6.getLT()) goto loc_8209F6F8;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_8209F734:
	// bl 0x82114ef8
	sub_82114EF8(ctx, base);
	// bl 0x820c2900
	sub_820C2900(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82145130
	sub_82145130(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r10,32767
	ctx.r10.s64 = 2147418112;
	// addi r26,r11,-1360
	r26.s64 = r11.s64 + -1360;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r30,r26,100
	r30.s64 = r26.s64 + 100;
	// ori r24,r10,65535
	r24.u64 = ctx.r10.u64 | 65535;
	// lfs f29,2940(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2940);
	f29.f64 = double(temp.f32);
loc_8209F760:
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x8209f780
	if (!cr6.getEQ()) goto loc_8209F780;
	// stfs f31,-8(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r30.u32 + -8, temp.u32);
	// stb r28,6(r30)
	PPC_STORE_U8(r30.u32 + 6, r28.u8);
	// stfs f31,0(r30)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r30.u32 + 0, temp.u32);
	// stb r28,7(r30)
	PPC_STORE_U8(r30.u32 + 7, r28.u8);
	// b 0x8209f7dc
	goto loc_8209F7DC;
loc_8209F780:
	// mr r27,r28
	r27.u64 = r28.u64;
	// addi r29,r26,92
	r29.s64 = r26.s64 + 92;
loc_8209F788:
	// bl 0x820ec268
	sub_820EC268(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// bne cr6,0x8209f79c
	if (!cr6.getEQ()) goto loc_8209F79C;
	// stfs f29,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// b 0x8209f7a8
	goto loc_8209F7A8;
loc_8209F79C:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x820eba68
	sub_820EBA68(ctx, base);
	// stfs f1,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
loc_8209F7A8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x820ebaa0
	sub_820EBAA0(ctx, base);
	// stfs f1,8(r29)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r29.u32 + 8, temp.u32);
	// addi r29,r29,112
	r29.s64 = r29.s64 + 112;
	// addi r11,r26,540
	r11.s64 = r26.s64 + 540;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// cmpw cr6,r29,r11
	cr6.compare<int32_t>(r29.s32, r11.s32, xer);
	// blt cr6,0x8209f788
	if (cr6.getLT()) goto loc_8209F788;
	// bl 0x820ebb00
	sub_820EBB00(ctx, base);
	// stw r3,4(r23)
	PPC_STORE_U32(r23.u32 + 4, ctx.r3.u32);
	// bl 0x820ebb70
	sub_820EBB70(ctx, base);
	// stw r3,8(r23)
	PPC_STORE_U32(r23.u32 + 8, ctx.r3.u32);
	// bl 0x820eb8c0
	sub_820EB8C0(ctx, base);
loc_8209F7DC:
	// addi r11,r30,-64
	r11.s64 = r30.s64 + -64;
	// stfs f30,-44(r30)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r30.u32 + -44, temp.u32);
	// stfs f30,-36(r30)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r30.u32 + -36, temp.u32);
	// stw r28,-48(r30)
	PPC_STORE_U32(r30.u32 + -48, r28.u32);
	// stw r28,-40(r30)
	PPC_STORE_U32(r30.u32 + -40, r28.u32);
	// addi r10,r26,548
	ctx.r10.s64 = r26.s64 + 548;
	// stw r24,-32(r30)
	PPC_STORE_U32(r30.u32 + -32, r24.u32);
	// stw r28,-28(r30)
	PPC_STORE_U32(r30.u32 + -28, r28.u32);
	// stw r28,-16(r30)
	PPC_STORE_U32(r30.u32 + -16, r28.u32);
	// stw r28,-12(r30)
	PPC_STORE_U32(r30.u32 + -12, r28.u32);
	// stw r28,-24(r30)
	PPC_STORE_U32(r30.u32 + -24, r28.u32);
	// stw r24,-20(r30)
	PPC_STORE_U32(r30.u32 + -20, r24.u32);
	// stb r28,4(r30)
	PPC_STORE_U8(r30.u32 + 4, r28.u8);
	// stw r28,-4(r30)
	PPC_STORE_U32(r30.u32 + -4, r28.u32);
	// addi r30,r30,112
	r30.s64 = r30.s64 + 112;
	// stw r28,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r28.u32);
	// stw r28,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r28.u32);
	// cmpw cr6,r30,r10
	cr6.compare<int32_t>(r30.s32, ctx.r10.s32, xer);
	// stw r28,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r28.u32);
	// stw r28,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r28.u32);
	// blt cr6,0x8209f760
	if (cr6.getLT()) goto loc_8209F760;
loc_8209F830:
	// bl 0x820cc8c0
	sub_820CC8C0(ctx, base);
	// bl 0x821396b0
	sub_821396B0(ctx, base);
	// bl 0x82118908
	sub_82118908(ctx, base);
	// bl 0x820cfed8
	sub_820CFED8(ctx, base);
	// bl 0x820e8688
	sub_820E8688(ctx, base);
	// bl 0x82135e60
	sub_82135E60(ctx, base);
	// bl 0x82120f10
	sub_82120F10(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82136600
	sub_82136600(ctx, base);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x820d24c8
	sub_820D24C8(ctx, base);
	// bl 0x82143a68
	sub_82143A68(ctx, base);
	// bl 0x82146310
	sub_82146310(ctx, base);
	// bl 0x8209da40
	sub_8209DA40(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmpwi cr6,r11,90
	cr6.compare<int32_t>(r11.s32, 90, xer);
	// beq cr6,0x8209f8c4
	if (cr6.getEQ()) goto loc_8209F8C4;
	// bl 0x82138c98
	sub_82138C98(ctx, base);
	// bl 0x820adb18
	sub_820ADB18(ctx, base);
	// mr r30,r28
	r30.u64 = r28.u64;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x8209f8bc
	if (!cr6.getGT()) goto loc_8209F8BC;
loc_8209F88C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// bl 0x820c27d0
	sub_820C27D0(ctx, base);
	// bl 0x820adbe0
	sub_820ADBE0(ctx, base);
	// bl 0x820afc48
	sub_820AFC48(ctx, base);
	// bl 0x820bff40
	sub_820BFF40(ctx, base);
	// bl 0x820bf4a8
	sub_820BF4A8(ctx, base);
	// bl 0x820af470
	sub_820AF470(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpw cr6,r30,r3
	cr6.compare<int32_t>(r30.s32, ctx.r3.s32, xer);
	// blt cr6,0x8209f88c
	if (cr6.getLT()) goto loc_8209F88C;
loc_8209F8BC:
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
loc_8209F8C4:
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82118920
	sub_82118920(ctx, base);
	// bl 0x8215cb90
	sub_8215CB90(ctx, base);
	// bl 0x8215cba0
	sub_8215CBA0(ctx, base);
	// bl 0x82181e58
	sub_82181E58(ctx, base);
	// bl 0x82181d98
	sub_82181D98(ctx, base);
	// bl 0x82131018
	sub_82131018(ctx, base);
	// bl 0x82130b58
	sub_82130B58(ctx, base);
	// stfs f31,0(r23)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r23.u32 + 0, temp.u32);
	// stw r28,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r28.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f29,-104(r1)
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -104);
	// lfd f30,-96(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// lfd f31,-88(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// b 0x823ed174
	return;
}

__attribute__((alias("__imp__sub_8209F900"))) PPC_WEAK_FUNC(sub_8209F900);
PPC_FUNC_IMPL(__imp__sub_8209F900) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed124
	// stfd f31,-88(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -88, f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r24,r11,-6396
	r24.s64 = r11.s64 + -6396;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8209f934
	if (cr6.getEQ()) goto loc_8209F934;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r23,r11,-6384
	r23.s64 = r11.s64 + -6384;
	// li r11,0
	r11.s64 = 0;
	// b 0x8209f970
	goto loc_8209F970;
loc_8209F934:
	// bl 0x8213b200
	sub_8213B200(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8209f950
	if (cr6.getEQ()) goto loc_8209F950;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r23,r11,-6384
	r23.s64 = r11.s64 + -6384;
	// li r11,0
	r11.s64 = 0;
	// b 0x8209f970
	goto loc_8209F970;
loc_8209F950:
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lis r11,-32055
	r11.s64 = -2100756480;
	// addi r23,r10,-6384
	r23.s64 = ctx.r10.s64 + -6384;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r11,-21848(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -21848);
	// lwz r9,-6372(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -6372);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stw r9,-6372(r10)
	PPC_STORE_U32(ctx.r10.u32 + -6372, ctx.r9.u32);
loc_8209F970:
	// extsw r8,r11
	ctx.r8.s64 = r11.s32;
	// stw r11,0(r23)
	PPC_STORE_U32(r23.u32 + 0, r11.u32);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lwz r9,-6376(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -6376);
	// add r9,r9,r11
	ctx.r9.u64 = ctx.r9.u64 + r11.u64;
	// stw r9,-6376(r10)
	PPC_STORE_U32(ctx.r10.u32 + -6376, ctx.r9.u32);
	// lwz r10,0(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// cmpwi cr6,r10,90
	cr6.compare<int32_t>(ctx.r10.s32, 90, xer);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfs f0,-6380(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + -6380, temp.u32);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// stfs f0,-6368(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + -6368, temp.u32);
	// beq cr6,0x8209fa1c
	if (cr6.getEQ()) goto loc_8209FA1C;
	// lwz r10,48(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 48);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x8209fa1c
	if (!cr6.getEQ()) goto loc_8209FA1C;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x8209fa1c
	if (!cr6.getGT()) goto loc_8209FA1C;
	// lis r11,-32010
	r11.s64 = -2097807360;
	// lwz r11,4024(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4024);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8209fa1c
	if (cr6.getEQ()) goto loc_8209FA1C;
	// lis r11,-32010
	r11.s64 = -2097807360;
	// li r31,1
	r31.s64 = 1;
	// addi r30,r11,3544
	r30.s64 = r11.s64 + 3544;
loc_8209F9E4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82136f40
	sub_82136F40(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x8209fa10
	if (!cr6.getEQ()) goto loc_8209FA10;
	// lbzx r11,r30,r31
	r11.u64 = PPC_LOAD_U8(r30.u32 + r31.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8209fa0c
	if (cr6.getEQ()) goto loc_8209FA0C;
	// bl 0x82138080
	sub_82138080(ctx, base);
	// b 0x8209fa10
	goto loc_8209FA10;
loc_8209FA0C:
	// bl 0x82137968
	sub_82137968(ctx, base);
loc_8209FA10:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmpwi cr6,r31,81
	cr6.compare<int32_t>(r31.s32, 81, xer);
	// blt cr6,0x8209f9e4
	if (cr6.getLT()) goto loc_8209F9E4;
loc_8209FA1C:
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x8209fdac
	if (!cr6.getGT()) goto loc_8209FDAC;
	// lwz r11,0(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// cmpwi cr6,r11,90
	cr6.compare<int32_t>(r11.s32, 90, xer);
	// beq cr6,0x8209fdac
	if (cr6.getEQ()) goto loc_8209FDAC;
	// bl 0x82144c50
	sub_82144C50(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// cmpwi cr6,r3,6
	cr6.compare<int32_t>(ctx.r3.s32, 6, xer);
	// addi r25,r11,-1384
	r25.s64 = r11.s64 + -1384;
	// bne cr6,0x8209fab4
	if (!cr6.getEQ()) goto loc_8209FAB4;
	// li r29,0
	r29.s64 = 0;
	// li r28,0
	r28.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x8209fab4
	if (!cr6.getGT()) goto loc_8209FAB4;
	// mr r31,r25
	r31.u64 = r25.u64;
loc_8209FA64:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r10,480(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 480);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x8209fa88
	if (cr6.getEQ()) goto loc_8209FA88;
	// lwz r11,1356(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1356);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8209fa88
	if (cr6.getEQ()) goto loc_8209FA88;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
loc_8209FA88:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpw cr6,r30,r3
	cr6.compare<int32_t>(r30.s32, ctx.r3.s32, xer);
	// blt cr6,0x8209fa64
	if (cr6.getLT()) goto loc_8209FA64;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// ble cr6,0x8209fab4
	if (!cr6.getGT()) goto loc_8209FAB4;
	// cmpw cr6,r29,r28
	cr6.compare<int32_t>(r29.s32, r28.s32, xer);
	// bne cr6,0x8209fab4
	if (!cr6.getEQ()) goto loc_8209FAB4;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x82144c60
	sub_82144C60(ctx, base);
loc_8209FAB4:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r26,r11,1148
	r26.s64 = r11.s64 + 1148;
	// lwz r11,-4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + -4);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x8209fbc8
	if (!cr6.getGT()) goto loc_8209FBC8;
	// lwz r30,48(r24)
	r30.u64 = PPC_LOAD_U32(r24.u32 + 48);
	// addi r10,r11,-3600
	ctx.r10.s64 = r11.s64 + -3600;
	// lwz r9,0(r23)
	ctx.r9.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// cmpw cr6,r30,r10
	cr6.compare<int32_t>(r30.s32, ctx.r10.s32, xer);
	// add r29,r30,r9
	r29.u64 = r30.u64 + ctx.r9.u64;
	// bge cr6,0x8209fb24
	if (!cr6.getLT()) goto loc_8209FB24;
	// cmpw cr6,r29,r10
	cr6.compare<int32_t>(r29.s32, ctx.r10.s32, xer);
	// blt cr6,0x8209fb24
	if (cr6.getLT()) goto loc_8209FB24;
	// li r31,0
	r31.s64 = 0;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x8209fb20
	if (!cr6.getGT()) goto loc_8209FB20;
loc_8209FAF8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,45124
	ctx.r3.u64 = ctx.r3.u64 | 45124;
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// bl 0x820b4260
	sub_820B4260(ctx, base);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpw cr6,r31,r3
	cr6.compare<int32_t>(r31.s32, ctx.r3.s32, xer);
	// blt cr6,0x8209faf8
	if (cr6.getLT()) goto loc_8209FAF8;
loc_8209FB20:
	// lwz r11,-4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + -4);
loc_8209FB24:
	// addi r11,r11,-600
	r11.s64 = r11.s64 + -600;
	// cmpw cr6,r29,r11
	cr6.compare<int32_t>(r29.s32, r11.s32, xer);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r31,r11,-6344
	r31.s64 = r11.s64 + -6344;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// blt cr6,0x8209fb7c
	if (cr6.getLT()) goto loc_8209FB7C;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x8209fb7c
	if (!cr6.getEQ()) goto loc_8209FB7C;
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x8209fba4
	if (!cr6.getEQ()) goto loc_8209FBA4;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,886
	ctx.r8.s64 = 886;
	// addi r7,r11,12908
	ctx.r7.s64 = r11.s64 + 12908;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,161
	ctx.r4.s64 = 161;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_8209FB7C:
	// lwz r11,8(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8209fba4
	if (cr6.getEQ()) goto loc_8209FBA4;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8209fba4
	if (cr6.getEQ()) goto loc_8209FBA4;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8209fba4
	if (cr6.getEQ()) goto loc_8209FBA4;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_8209FBA4:
	// bl 0x8215fc88
	sub_8215FC88(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x8209fbc8
	if (!cr6.getEQ()) goto loc_8209FBC8;
	// lwz r11,-4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + -4);
	// cmpw cr6,r30,r11
	cr6.compare<int32_t>(r30.s32, r11.s32, xer);
	// bge cr6,0x8209fbc8
	if (!cr6.getLT()) goto loc_8209FBC8;
	// cmpw cr6,r29,r11
	cr6.compare<int32_t>(r29.s32, r11.s32, xer);
	// blt cr6,0x8209fbc8
	if (cr6.getLT()) goto loc_8209FBC8;
	// bl 0x82139ad8
	sub_82139AD8(ctx, base);
loc_8209FBC8:
	// bl 0x8215fc88
	sub_8215FC88(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// lfs f31,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// bne cr6,0x8209fc94
	if (!cr6.getEQ()) goto loc_8209FC94;
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x8209fc94
	if (!cr6.getGT()) goto loc_8209FC94;
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8209fc94
	if (cr6.getEQ()) goto loc_8209FC94;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r27,0
	r27.s64 = 0;
	// li r28,0
	r28.s64 = 0;
	// li r31,0
	r31.s64 = 0;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// ble cr6,0x8209fc94
	if (!cr6.getGT()) goto loc_8209FC94;
	// mr r30,r25
	r30.u64 = r25.u64;
loc_8209FC14:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r10,480(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 480);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x8209fc4c
	if (cr6.getEQ()) goto loc_8209FC4C;
	// lwz r10,1356(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1356);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x8209fc48
	if (cr6.getEQ()) goto loc_8209FC48;
	// lwz r10,1360(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1360);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x8209fc48
	if (cr6.getEQ()) goto loc_8209FC48;
	// lfs f0,1292(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1292);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// blt cr6,0x8209fc4c
	if (cr6.getLT()) goto loc_8209FC4C;
loc_8209FC48:
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
loc_8209FC4C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8213a720
	sub_8213A720(ctx, base);
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// cmpw cr6,r3,r11
	cr6.compare<int32_t>(ctx.r3.s32, r11.s32, xer);
	// blt cr6,0x8209fc64
	if (cr6.getLT()) goto loc_8209FC64;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
loc_8209FC64:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// cmpw cr6,r31,r29
	cr6.compare<int32_t>(r31.s32, r29.s32, xer);
	// blt cr6,0x8209fc14
	if (cr6.getLT()) goto loc_8209FC14;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// ble cr6,0x8209fc94
	if (!cr6.getGT()) goto loc_8209FC94;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x8209fc90
	if (!cr6.getEQ()) goto loc_8209FC90;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82139ad8
	sub_82139AD8(ctx, base);
	// b 0x8209fc94
	goto loc_8209FC94;
loc_8209FC90:
	// bl 0x82139aa8
	sub_82139AA8(ctx, base);
loc_8209FC94:
	// bl 0x8215fc88
	sub_8215FC88(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x8209fdac
	if (!cr6.getEQ()) goto loc_8209FDAC;
	// bl 0x820ec268
	sub_820EC268(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x8209fdac
	if (!cr6.getEQ()) goto loc_8209FDAC;
	// lwz r11,0(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8209fdac
	if (cr6.getEQ()) goto loc_8209FDAC;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// li r29,0
	r29.s64 = 0;
	// li r28,0
	r28.s64 = 0;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x8209fd88
	if (!cr6.getGT()) goto loc_8209FD88;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r4,r11,-1360
	ctx.r4.s64 = r11.s64 + -1360;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r31,r4,104
	r31.s64 = ctx.r4.s64 + 104;
loc_8209FCE0:
	// addi r11,r4,36
	r11.s64 = ctx.r4.s64 + 36;
	// li r8,0
	ctx.r8.s64 = 0;
	// add r10,r6,r11
	ctx.r10.u64 = ctx.r6.u64 + r11.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r9,r25
	ctx.r9.u64 = r25.u64;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8209FCF8:
	// lwz r7,0(r9)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// lwz r7,480(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 480);
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// bne cr6,0x8209fd0c
	if (!cr6.getEQ()) goto loc_8209FD0C;
	// addi r5,r5,1
	ctx.r5.s64 = ctx.r5.s64 + 1;
loc_8209FD0C:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// add r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 + ctx.r8.u64;
	// addi r10,r10,112
	ctx.r10.s64 = ctx.r10.s64 + 112;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8209fcf8
	if (!cr6.getEQ()) goto loc_8209FCF8;
	// cmpwi cr6,r8,2
	cr6.compare<int32_t>(ctx.r8.s32, 2, xer);
	// blt cr6,0x8209fd74
	if (cr6.getLT()) goto loc_8209FD74;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8209fd44
	if (!cr6.getEQ()) goto loc_8209FD44;
	// addi r11,r5,1
	r11.s64 = ctx.r5.s64 + 1;
	// stb r11,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r11.u8);
loc_8209FD44:
	// lwzx r11,r6,r25
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + r25.u32);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// lwz r10,1356(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1356);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x8209fd74
	if (cr6.getEQ()) goto loc_8209FD74;
	// lwz r10,1360(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1360);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x8209fd74
	if (cr6.getEQ()) goto loc_8209FD74;
	// lfs f0,1292(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1292);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bge cr6,0x8209fd74
	if (!cr6.getLT()) goto loc_8209FD74;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
loc_8209FD74:
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// addi r31,r31,112
	r31.s64 = r31.s64 + 112;
	// addi r6,r6,4
	ctx.r6.s64 = ctx.r6.s64 + 4;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8209fce0
	if (!cr6.getEQ()) goto loc_8209FCE0;
loc_8209FD88:
	// addi r11,r3,-1
	r11.s64 = ctx.r3.s64 + -1;
	// cmpw cr6,r28,r11
	cr6.compare<int32_t>(r28.s32, r11.s32, xer);
	// blt cr6,0x8209fda0
	if (cr6.getLT()) goto loc_8209FDA0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x82139ad8
	sub_82139AD8(ctx, base);
	// b 0x8209fdac
	goto loc_8209FDAC;
loc_8209FDA0:
	// cmpw cr6,r29,r11
	cr6.compare<int32_t>(r29.s32, r11.s32, xer);
	// blt cr6,0x8209fdac
	if (cr6.getLT()) goto loc_8209FDAC;
	// bl 0x82139aa8
	sub_82139AA8(ctx, base);
loc_8209FDAC:
	// lwz r11,48(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + 48);
	// lwz r10,0(r23)
	ctx.r10.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// lwz r9,0(r23)
	ctx.r9.u64 = PPC_LOAD_U32(r23.u32 + 0);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lwz r10,60(r24)
	ctx.r10.u64 = PPC_LOAD_U32(r24.u32 + 60);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r9,0(r24)
	ctx.r9.u64 = PPC_LOAD_U32(r24.u32 + 0);
	// cmpwi cr6,r9,90
	cr6.compare<int32_t>(ctx.r9.s32, 90, xer);
	// stw r11,48(r24)
	PPC_STORE_U32(r24.u32 + 48, r11.u32);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// stw r10,60(r24)
	PPC_STORE_U32(r24.u32 + 60, ctx.r10.u32);
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f12,f0
	ctx.f12.f64 = double(float(f0.f64));
	// lfs f0,6576(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6576);
	f0.f64 = double(temp.f32);
	// frsp f11,f13
	ctx.f11.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f12,f0
	ctx.f13.f64 = double(float(ctx.f12.f64 * f0.f64));
	// stfs f13,56(r24)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r24.u32 + 56, temp.u32);
	// fmuls f0,f11,f0
	f0.f64 = double(float(ctx.f11.f64 * f0.f64));
	// stfs f0,64(r24)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r24.u32 + 64, temp.u32);
	// bne cr6,0x8209fe28
	if (!cr6.getEQ()) goto loc_8209FE28;
	// bl 0x82107970
	sub_82107970(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f31,-88(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// b 0x823ed174
	return;
loc_8209FE28:
	// bl 0x8209eef0
	sub_8209EEF0(ctx, base);
	// bl 0x8214ad90
	sub_8214AD90(ctx, base);
	// bl 0x8213dfd0
	sub_8213DFD0(ctx, base);
	// bl 0x820a5390
	sub_820A5390(ctx, base);
	// bl 0x82145cc0
	sub_82145CC0(ctx, base);
	// bl 0x82140740
	sub_82140740(ctx, base);
	// bl 0x820cf580
	sub_820CF580(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f31,-88(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// b 0x823ed174
	return;
}

__attribute__((alias("__imp__sub_8209FE50"))) PPC_WEAK_FUNC(sub_8209FE50);
PPC_FUNC_IMPL(__imp__sub_8209FE50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r31,0
	r31.s64 = 0;
	// li r30,0
	r30.s64 = 0;
loc_8209FE6C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823b19b0
	sub_823B19B0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x8209fe84
	if (cr6.getEQ()) goto loc_8209FE84;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// extsb r31,r11
	r31.s64 = r11.s8;
loc_8209FE84:
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// blt cr6,0x8209fe6c
	if (cr6.getLT()) goto loc_8209FE6C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8209FEB0"))) PPC_WEAK_FUNC(sub_8209FEB0);
PPC_FUNC_IMPL(__imp__sub_8209FEB0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x823b19b0
	sub_823B19B0(ctx, base);
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = r11.u64 ^ 1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8209FEE0"))) PPC_WEAK_FUNC(sub_8209FEE0);
PPC_FUNC_IMPL(__imp__sub_8209FEE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed12c
	// stfd f30,-80(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -80, f30.u64);
	// stfd f31,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, f31.u64);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r29,r11,-6304
	r29.s64 = r11.s64 + -6304;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r30,0
	r30.s64 = 0;
	// addi r31,r29,48
	r31.s64 = r29.s64 + 48;
	// lfs f30,12924(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12924);
	f30.f64 = double(temp.f32);
	// lfs f31,12928(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12928);
	f31.f64 = double(temp.f32);
loc_8209FF14:
	// lfs f0,-48(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + -48);
	f0.f64 = double(temp.f32);
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// stfs f0,-16(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + -16, temp.u32);
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// lfs f0,-32(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + -32);
	f0.f64 = double(temp.f32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stfs f0,0(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// lfs f0,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	f0.f64 = double(temp.f32);
	// stfs f0,48(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 48, temp.u32);
	// lfs f0,32(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	f0.f64 = double(temp.f32);
	// stfs f0,64(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 64, temp.u32);
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// stw r11,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r11.u32);
	// bl 0x823b1aa0
	sub_823B1AA0(ctx, base);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// lwz r10,88(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// addi r4,r1,92
	ctx.r4.s64 = ctx.r1.s64 + 92;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// std r10,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r10.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// lfd f13,112(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * f31.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// stfs f0,-48(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + -48, temp.u32);
	// fmuls f0,f13,f30
	f0.f64 = double(float(ctx.f13.f64 * f30.f64));
	// stfs f0,-32(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + -32, temp.u32);
	// bl 0x823b1ba0
	sub_823B1BA0(ctx, base);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, r11.u64);
	// std r10,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r10.u64);
	// lfd f0,120(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// lfd f13,128(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * f31.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// stfs f0,16(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 16, temp.u32);
	// fmuls f0,f13,f30
	f0.f64 = double(float(ctx.f13.f64 * f30.f64));
	// stfs f0,32(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 32, temp.u32);
	// bl 0x823b1e98
	sub_823B1E98(ctx, base);
	// rlwinm r11,r3,0,19,19
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x1000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a000c
	if (cr6.getEQ()) goto loc_820A000C;
	// lis r6,0
	ctx.r6.s64 = 0;
	// ori r6,r6,32768
	ctx.r6.u64 = ctx.r6.u64 | 32768;
	// b 0x820a0010
	goto loc_820A0010;
loc_820A000C:
	// li r6,0
	ctx.r6.s64 = 0;
loc_820A0010:
	// rlwinm r11,r3,0,17,17
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x4000;
	// lis r7,1
	ctx.r7.s64 = 65536;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a0024
	if (!cr6.getEQ()) goto loc_820A0024;
	// li r7,0
	ctx.r7.s64 = 0;
loc_820A0024:
	// rlwinm r11,r3,0,16,16
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x8000;
	// lis r8,2
	ctx.r8.s64 = 131072;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a0038
	if (!cr6.getEQ()) goto loc_820A0038;
	// li r8,0
	ctx.r8.s64 = 0;
loc_820A0038:
	// rlwinm r11,r3,0,26,26
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x20;
	// lis r9,16
	ctx.r9.s64 = 1048576;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a004c
	if (!cr6.getEQ()) goto loc_820A004C;
	// li r9,0
	ctx.r9.s64 = 0;
loc_820A004C:
	// rlwinm r11,r3,0,25,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x40;
	// lis r10,4
	ctx.r10.s64 = 262144;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a0060
	if (!cr6.getEQ()) goto loc_820A0060;
	// li r10,0
	ctx.r10.s64 = 0;
loc_820A0060:
	// rlwinm r11,r3,0,24,24
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,8
	r11.s64 = 524288;
	// bne cr6,0x820a0074
	if (!cr6.getEQ()) goto loc_820A0074;
	// li r11,0
	r11.s64 = 0;
loc_820A0074:
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// rlwimi r5,r3,2,29,29
	ctx.r5.u64 = (__builtin_rotateleft32(ctx.r3.u32, 2) & 0x4) | (ctx.r5.u64 & 0xFFFFFFFFFFFFFFFB);
	// rlwinm r28,r3,0,29,29
	r28.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x4;
	// rlwimi r4,r5,1,28,29
	ctx.r4.u64 = (__builtin_rotateleft32(ctx.r5.u32, 1) & 0xC) | (ctx.r4.u64 & 0xFFFFFFFFFFFFFFF3);
	// rlwinm r27,r3,0,28,28
	r27.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x8;
	// rlwinm r4,r4,1,26,28
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 1) & 0x38;
	// rlwinm r26,r3,0,18,18
	r26.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x2000;
	// rlwinm r25,r3,29,26,26
	r25.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 29) & 0x20;
	// or r3,r4,r28
	ctx.r3.u64 = ctx.r4.u64 | r28.u64;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// rlwinm r28,r3,2,0,29
	r28.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r4,r1,81
	ctx.r4.s64 = ctx.r1.s64 + 81;
	// or r28,r28,r27
	r28.u64 = r28.u64 | r27.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// rlwinm r28,r28,4,0,27
	r28.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 4) & 0xFFFFFFF0;
	// or r28,r28,r26
	r28.u64 = r28.u64 | r26.u64;
	// rlwinm r28,r28,1,0,30
	r28.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 1) & 0xFFFFFFFE;
	// or r28,r28,r25
	r28.u64 = r28.u64 | r25.u64;
	// or r11,r28,r11
	r11.u64 = r28.u64 | r11.u64;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// or r11,r11,r9
	r11.u64 = r11.u64 | ctx.r9.u64;
	// or r11,r11,r8
	r11.u64 = r11.u64 | ctx.r8.u64;
	// or r11,r11,r7
	r11.u64 = r11.u64 | ctx.r7.u64;
	// or r11,r11,r6
	r11.u64 = r11.u64 | ctx.r6.u64;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
	// bl 0x823b1c70
	sub_823B1C70(ctx, base);
	// lbz r11,80(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,15
	cr6.compare<uint32_t>(r11.u32, 15, xer);
	// ble cr6,0x820a00f8
	if (!cr6.getGT()) goto loc_820A00F8;
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// ori r11,r11,8192
	r11.u64 = r11.u64 | 8192;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
loc_820A00F8:
	// lbz r11,81(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 81);
	// cmplwi cr6,r11,15
	cr6.compare<uint32_t>(r11.u32, 15, xer);
	// ble cr6,0x820a0110
	if (!cr6.getGT()) goto loc_820A0110;
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// ori r11,r11,32
	r11.u64 = r11.u64 | 32;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
loc_820A0110:
	// lwz r10,80(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// lwz r11,96(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// andc r11,r10,r11
	r11.u64 = ctx.r10.u64 & ~r11.u64;
	// addi r10,r29,64
	ctx.r10.s64 = r29.s64 + 64;
	// stw r11,128(r31)
	PPC_STORE_U32(r31.u32 + 128, r11.u32);
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// cmpw cr6,r31,r10
	cr6.compare<int32_t>(r31.s32, ctx.r10.s32, xer);
	// blt cr6,0x8209ff14
	if (cr6.getLT()) goto loc_8209FF14;
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// lfd f30,-80(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// lfd f31,-72(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_820A0148"))) PPC_WEAK_FUNC(sub_820A0148);
PPC_FUNC_IMPL(__imp__sub_820A0148) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r30,r11,-6304
	r30.s64 = r11.s64 + -6304;
	// lwz r11,192(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 192);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a01a4
	if (!cr6.getLT()) goto loc_820A01A4;
	// bl 0x823b19b0
	sub_823B19B0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820a01a4
	if (!cr6.getEQ()) goto loc_820A01A4;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r11,r11,-6032
	r11.s64 = r11.s64 + -6032;
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f1,2688(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	ctx.f1.f64 = double(temp.f32);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// b 0x820a01ac
	goto loc_820A01AC;
loc_820A01A4:
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lfsx f1,r11,r30
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + r30.u32);
	ctx.f1.f64 = double(temp.f32);
loc_820A01AC:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A01C8"))) PPC_WEAK_FUNC(sub_820A01C8);
PPC_FUNC_IMPL(__imp__sub_820A01C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r30,r11,-6304
	r30.s64 = r11.s64 + -6304;
	// lwz r11,192(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 192);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a0224
	if (!cr6.getLT()) goto loc_820A0224;
	// bl 0x823b19b0
	sub_823B19B0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820a0224
	if (!cr6.getEQ()) goto loc_820A0224;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r11,r11,-6032
	r11.s64 = r11.s64 + -6032;
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f1,2688(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	ctx.f1.f64 = double(temp.f32);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// b 0x820a0230
	goto loc_820A0230;
loc_820A0224:
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r30,32
	ctx.r10.s64 = r30.s64 + 32;
	// lfsx f1,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	ctx.f1.f64 = double(temp.f32);
loc_820A0230:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0248"))) PPC_WEAK_FUNC(sub_820A0248);
PPC_FUNC_IMPL(__imp__sub_820A0248) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r30,r11,-6304
	r30.s64 = r11.s64 + -6304;
	// lwz r11,192(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 192);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a02a4
	if (!cr6.getLT()) goto loc_820A02A4;
	// bl 0x823b19b0
	sub_823B19B0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820a02a4
	if (!cr6.getEQ()) goto loc_820A02A4;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r11,r11,-6016
	r11.s64 = r11.s64 + -6016;
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f1,2688(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	ctx.f1.f64 = double(temp.f32);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// b 0x820a02b0
	goto loc_820A02B0;
loc_820A02A4:
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r30,16
	ctx.r10.s64 = r30.s64 + 16;
	// lfsx f1,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	ctx.f1.f64 = double(temp.f32);
loc_820A02B0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A02C8"))) PPC_WEAK_FUNC(sub_820A02C8);
PPC_FUNC_IMPL(__imp__sub_820A02C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r30,r11,-6304
	r30.s64 = r11.s64 + -6304;
	// lwz r11,192(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 192);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a0324
	if (!cr6.getLT()) goto loc_820A0324;
	// bl 0x823b19b0
	sub_823B19B0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820a0324
	if (!cr6.getEQ()) goto loc_820A0324;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r11,r11,-6016
	r11.s64 = r11.s64 + -6016;
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f1,2688(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	ctx.f1.f64 = double(temp.f32);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// b 0x820a0330
	goto loc_820A0330;
loc_820A0324:
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r30,48
	ctx.r10.s64 = r30.s64 + 48;
	// lfsx f1,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	ctx.f1.f64 = double(temp.f32);
loc_820A0330:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0348"))) PPC_WEAK_FUNC(sub_820A0348);
PPC_FUNC_IMPL(__imp__sub_820A0348) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r30,r11,-6304
	r30.s64 = r11.s64 + -6304;
	// lwz r11,192(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 192);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a03a4
	if (!cr6.getLT()) goto loc_820A03A4;
	// bl 0x823b19b0
	sub_823B19B0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820a03a4
	if (!cr6.getEQ()) goto loc_820A03A4;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r11,r11,-6032
	r11.s64 = r11.s64 + -6032;
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f1,2688(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	ctx.f1.f64 = double(temp.f32);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// b 0x820a03b0
	goto loc_820A03B0;
loc_820A03A4:
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r30,64
	ctx.r10.s64 = r30.s64 + 64;
	// lfsx f1,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	ctx.f1.f64 = double(temp.f32);
loc_820A03B0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A03C8"))) PPC_WEAK_FUNC(sub_820A03C8);
PPC_FUNC_IMPL(__imp__sub_820A03C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r30,r11,-6304
	r30.s64 = r11.s64 + -6304;
	// lwz r11,192(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 192);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a0424
	if (!cr6.getLT()) goto loc_820A0424;
	// bl 0x823b19b0
	sub_823B19B0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820a0424
	if (!cr6.getEQ()) goto loc_820A0424;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r11,r11,-6032
	r11.s64 = r11.s64 + -6032;
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f1,2688(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	ctx.f1.f64 = double(temp.f32);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// b 0x820a0430
	goto loc_820A0430;
loc_820A0424:
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r30,96
	ctx.r10.s64 = r30.s64 + 96;
	// lfsx f1,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	ctx.f1.f64 = double(temp.f32);
loc_820A0430:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0448"))) PPC_WEAK_FUNC(sub_820A0448);
PPC_FUNC_IMPL(__imp__sub_820A0448) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r30,r11,-6304
	r30.s64 = r11.s64 + -6304;
	// lwz r11,192(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 192);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a04a4
	if (!cr6.getLT()) goto loc_820A04A4;
	// bl 0x823b19b0
	sub_823B19B0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820a04a4
	if (!cr6.getEQ()) goto loc_820A04A4;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r11,r11,-6032
	r11.s64 = r11.s64 + -6032;
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f1,2688(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	ctx.f1.f64 = double(temp.f32);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// b 0x820a04b0
	goto loc_820A04B0;
loc_820A04A4:
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r30,80
	ctx.r10.s64 = r30.s64 + 80;
	// lfsx f1,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	ctx.f1.f64 = double(temp.f32);
loc_820A04B0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A04C8"))) PPC_WEAK_FUNC(sub_820A04C8);
PPC_FUNC_IMPL(__imp__sub_820A04C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r30,r11,-6304
	r30.s64 = r11.s64 + -6304;
	// lwz r11,192(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 192);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a0524
	if (!cr6.getLT()) goto loc_820A0524;
	// bl 0x823b19b0
	sub_823B19B0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820a0524
	if (!cr6.getEQ()) goto loc_820A0524;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r11,r11,-6016
	r11.s64 = r11.s64 + -6016;
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// lfs f1,2688(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	ctx.f1.f64 = double(temp.f32);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// b 0x820a0530
	goto loc_820A0530;
loc_820A0524:
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r30,112
	ctx.r10.s64 = r30.s64 + 112;
	// lfsx f1,r11,r10
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	ctx.f1.f64 = double(temp.f32);
loc_820A0530:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0548"))) PPC_WEAK_FUNC(sub_820A0548);
PPC_FUNC_IMPL(__imp__sub_820A0548) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r30,r11,-6304
	r30.s64 = r11.s64 + -6304;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r11,192(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 192);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a059c
	if (!cr6.getLT()) goto loc_820A059C;
	// bl 0x823b19b0
	sub_823B19B0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820a059c
	if (!cr6.getEQ()) goto loc_820A059C;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// rlwinm r10,r31,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-6000
	r11.s64 = r11.s64 + -6000;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
loc_820A059C:
	// rlwinm r11,r31,2,0,29
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r30,128
	ctx.r10.s64 = r30.s64 + 128;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// and r3,r11,r29
	ctx.r3.u64 = r11.u64 & r29.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820A05B8"))) PPC_WEAK_FUNC(sub_820A05B8);
PPC_FUNC_IMPL(__imp__sub_820A05B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// bl 0x82091fb8
	sub_82091FB8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a05e8
	if (cr6.getEQ()) goto loc_820A05E8;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
loc_820A05E8:
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r31,r11,-6304
	r31.s64 = r11.s64 + -6304;
	// lwz r11,192(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 192);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a062c
	if (!cr6.getLT()) goto loc_820A062C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823b19b0
	sub_823B19B0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820a062c
	if (!cr6.getEQ()) goto loc_820A062C;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// rlwinm r10,r30,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-5984
	r11.s64 = r11.s64 + -5984;
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
loc_820A062C:
	// rlwinm r11,r30,2,0,29
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r31,176
	ctx.r10.s64 = r31.s64 + 176;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// and r3,r11,r29
	ctx.r3.u64 = r11.u64 & r29.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820A0648"))) PPC_WEAK_FUNC(sub_820A0648);
PPC_FUNC_IMPL(__imp__sub_820A0648) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// bl 0x820a0148
	sub_820A0148(ctx, base);
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// stfd f0,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, f0.u64);
	// lbz r11,87(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 87);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// addi r11,r11,60
	r11.s64 = r11.s64 + 60;
	// cmpwi cr6,r11,120
	cr6.compare<int32_t>(r11.s32, 120, xer);
	// ble cr6,0x820a068c
	if (!cr6.getGT()) goto loc_820A068C;
	// li r11,120
	r11.s64 = 120;
	// b 0x820a0698
	goto loc_820A0698;
loc_820A068C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a0698
	if (!cr6.getLT()) goto loc_820A0698;
	// li r11,0
	r11.s64 = 0;
loc_820A0698:
	// subf r10,r31,r30
	ctx.r10.s64 = r30.s64 - r31.s64;
	// lis r9,-30584
	ctx.r9.s64 = -2004353024;
	// mullw r11,r10,r11
	r11.s64 = int64_t(ctx.r10.s32) * int64_t(r11.s32);
	// ori r9,r9,34953
	ctx.r9.u64 = ctx.r9.u64 | 34953;
	// mulhw r10,r11,r9
	ctx.r10.s64 = (int64_t(r11.s32) * int64_t(ctx.r9.s32)) >> 32;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// srawi r11,r11,6
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x3F) != 0);
	r11.s64 = r11.s32 >> 6;
	// rlwinm r10,r11,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// add r3,r11,r31
	ctx.r3.u64 = r11.u64 + r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A06D8"))) PPC_WEAK_FUNC(sub_820A06D8);
PPC_FUNC_IMPL(__imp__sub_820A06D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// bl 0x820a0248
	sub_820A0248(ctx, base);
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// stfd f0,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, f0.u64);
	// lbz r11,87(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 87);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// addi r11,r11,60
	r11.s64 = r11.s64 + 60;
	// cmpwi cr6,r11,120
	cr6.compare<int32_t>(r11.s32, 120, xer);
	// ble cr6,0x820a071c
	if (!cr6.getGT()) goto loc_820A071C;
	// li r11,120
	r11.s64 = 120;
	// b 0x820a0728
	goto loc_820A0728;
loc_820A071C:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a0728
	if (!cr6.getLT()) goto loc_820A0728;
	// li r11,0
	r11.s64 = 0;
loc_820A0728:
	// subf r10,r31,r30
	ctx.r10.s64 = r30.s64 - r31.s64;
	// lis r9,-30584
	ctx.r9.s64 = -2004353024;
	// mullw r11,r10,r11
	r11.s64 = int64_t(ctx.r10.s32) * int64_t(r11.s32);
	// ori r9,r9,34953
	ctx.r9.u64 = ctx.r9.u64 | 34953;
	// mulhw r10,r11,r9
	ctx.r10.s64 = (int64_t(r11.s32) * int64_t(ctx.r9.s32)) >> 32;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// srawi r11,r11,6
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x3F) != 0);
	r11.s64 = r11.s32 >> 6;
	// rlwinm r10,r11,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// add r3,r11,r31
	ctx.r3.u64 = r11.u64 + r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0768"))) PPC_WEAK_FUNC(sub_820A0768);
PPC_FUNC_IMPL(__imp__sub_820A0768) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister temp{};
	// fmr f3,f1
	ctx.fpscr.disableFlushMode();
	ctx.f3.f64 = ctx.f1.f64;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lfs f2,1168(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1168);
	ctx.f2.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lfs f1,1164(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1164);
	ctx.f1.f64 = double(temp.f32);
	// b 0x823b28e0
	sub_823B28E0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820A0788"))) PPC_WEAK_FUNC(sub_820A0788);
PPC_FUNC_IMPL(__imp__sub_820A0788) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0790"))) PPC_WEAK_FUNC(sub_820A0790);
PPC_FUNC_IMPL(__imp__sub_820A0790) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r3,1176(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 1176);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A07A0"))) PPC_WEAK_FUNC(sub_820A07A0);
PPC_FUNC_IMPL(__imp__sub_820A07A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r28,-32014
	r28.s64 = -2098069504;
	// lwz r11,-3860(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -3860);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820a0828
	if (cr6.getEQ()) goto loc_820A0828;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r10,1
	ctx.r10.s64 = 1;
	// addi r30,r11,14664
	r30.s64 = r11.s64 + 14664;
	// lis r29,-32014
	r29.s64 = -2098069504;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r9,r30,16
	ctx.r9.s64 = r30.s64 + 16;
	// stw r10,2532(r11)
	PPC_STORE_U32(r11.u32 + 2532, ctx.r10.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r11,-3856(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -3856);
	// addi r4,r10,2468
	ctx.r4.s64 = ctx.r10.s64 + 2468;
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r11,r9
	ctx.r3.u64 = r11.u64 + ctx.r9.u64;
	// bl 0x8210ba08
	sub_8210BA08(ctx, base);
	// lwz r11,-3856(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -3856);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// rlwinm r9,r11,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r4,r10,2468
	ctx.r4.s64 = ctx.r10.s64 + 2468;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// addi r10,r30,4
	ctx.r10.s64 = r30.s64 + 4;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,-3860(r28)
	PPC_STORE_U32(r28.u32 + -3860, r11.u32);
loc_820A0828:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820A0830"))) PPC_WEAK_FUNC(sub_820A0830);
PPC_FUNC_IMPL(__imp__sub_820A0830) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stfd f30,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, f30.u64);
	// stfd f31,-40(r1)
	PPC_STORE_U64(ctx.r1.u32 + -40, f31.u64);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lfs f0,68(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 68);
	f0.f64 = double(temp.f32);
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// li r11,1
	r11.s64 = 1;
	// blt cr6,0x820a088c
	if (cr6.getLT()) goto loc_820A088C;
	// addi r10,r3,68
	ctx.r10.s64 = ctx.r3.s64 + 68;
loc_820A0860:
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r10,r10,36
	ctx.r10.s64 = ctx.r10.s64 + 36;
	// fsubs f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 - f0.f64));
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// lwz r9,40(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 40);
	// clrlwi r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a088c
	if (!cr6.getEQ()) goto loc_820A088C;
	// lfs f0,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// bge cr6,0x820a0860
	if (!cr6.getLT()) goto loc_820A0860;
loc_820A088C:
	// addi r10,r11,2
	ctx.r10.s64 = r11.s64 + 2;
	// rlwinm r9,r10,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r3
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r3.u32);
	// clrlwi r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// rlwinm r10,r11,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r31,r11,r3
	r31.u64 = r11.u64 + ctx.r3.u64;
	// beq cr6,0x820a08e8
	if (cr6.getEQ()) goto loc_820A08E8;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r31,16
	ctx.r3.s64 = r31.s64 + 16;
	// bl 0x8210ba08
	sub_8210BA08(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// lfd f30,-48(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// lfd f31,-40(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x823ed18c
	return;
loc_820A08E8:
	// lfs f0,32(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	f0.f64 = double(temp.f32);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// addi r3,r31,-20
	ctx.r3.s64 = r31.s64 + -20;
	// lfs f30,28(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	f30.f64 = double(temp.f32);
	// fdivs f31,f1,f0
	f31.f64 = double(float(ctx.f1.f64 / f0.f64));
	// bl 0x8210c888
	sub_8210C888(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r31,16
	ctx.r3.s64 = r31.s64 + 16;
	// bl 0x8210c888
	sub_8210C888(ctx, base);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r31,52
	ctx.r3.s64 = r31.s64 + 52;
	// bl 0x8210c888
	sub_8210C888(ctx, base);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// addi r3,r31,88
	ctx.r3.s64 = r31.s64 + 88;
	// bl 0x8210c888
	sub_8210C888(ctx, base);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8210cda0
	sub_8210CDA0(ctx, base);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8210cda0
	sub_8210CDA0(ctx, base);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8210cda0
	sub_8210CDA0(ctx, base);
	// addi r8,r1,96
	ctx.r8.s64 = ctx.r1.s64 + 96;
	// addi r6,r1,144
	ctx.r6.s64 = ctx.r1.s64 + 144;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// addi r5,r1,112
	ctx.r5.s64 = ctx.r1.s64 + 112;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8210d2f8
	sub_8210D2F8(ctx, base);
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// addi r6,r31,76
	ctx.r6.s64 = r31.s64 + 76;
	// fmr f2,f30
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = f30.f64;
	// addi r5,r31,40
	ctx.r5.s64 = r31.s64 + 40;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// addi r4,r31,4
	ctx.r4.s64 = r31.s64 + 4;
	// addi r3,r31,-32
	ctx.r3.s64 = r31.s64 + -32;
	// bl 0x8210b020
	sub_8210B020(ctx, base);
	// cmpwi cr6,r29,1
	cr6.compare<int32_t>(r29.s32, 1, xer);
	// bne cr6,0x820a09b0
	if (!cr6.getEQ()) goto loc_820A09B0;
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	f0.f64 = double(temp.f32);
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	f0.f64 = double(temp.f32);
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
loc_820A09B0:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8210c988
	sub_8210C988(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// lfd f30,-48(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// lfd f31,-40(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820A09E0"))) PPC_WEAK_FUNC(sub_820A09E0);
PPC_FUNC_IMPL(__imp__sub_820A09E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// addi r11,r3,578
	r11.s64 = ctx.r3.s64 + 578;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bgt cr6,0x820a0a2c
	if (cr6.getGT()) goto loc_820A0A2C;
	// addi r10,r3,580
	ctx.r10.s64 = ctx.r3.s64 + 580;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x820a0a24
	if (!cr6.getEQ()) goto loc_820A0A24;
	// addi r10,r3,2097
	ctx.r10.s64 = ctx.r3.s64 + 2097;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x820a0a2c
	if (cr6.getLT()) goto loc_820A0A2C;
loc_820A0A24:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_820A0A2C:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0A38"))) PPC_WEAK_FUNC(sub_820A0A38);
PPC_FUNC_IMPL(__imp__sub_820A0A38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// addi r11,r3,584
	r11.s64 = ctx.r3.s64 + 584;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0A50"))) PPC_WEAK_FUNC(sub_820A0A50);
PPC_FUNC_IMPL(__imp__sub_820A0A50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// addi r11,r3,582
	r11.s64 = ctx.r3.s64 + 582;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0A68"))) PPC_WEAK_FUNC(sub_820A0A68);
PPC_FUNC_IMPL(__imp__sub_820A0A68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,1180
	r11.s64 = r11.s64 + 1180;
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0A80"))) PPC_WEAK_FUNC(sub_820A0A80);
PPC_FUNC_IMPL(__imp__sub_820A0A80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// addi r11,r3,578
	r11.s64 = ctx.r3.s64 + 578;
	// addi r10,r3,580
	ctx.r10.s64 = ctx.r3.s64 + 580;
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// rlwinm r5,r10,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r8,r3,2097
	ctx.r8.s64 = ctx.r3.s64 + 2097;
	// li r4,-1
	ctx.r4.s64 = -1;
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r3,2100
	ctx.r6.s64 = ctx.r3.s64 + 2100;
	// stwx r9,r7,r10
	PPC_STORE_U32(ctx.r7.u32 + ctx.r10.u32, ctx.r9.u32);
	// rlwinm r7,r6,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// li r6,1
	ctx.r6.s64 = 1;
	// stwx r9,r5,r10
	PPC_STORE_U32(ctx.r5.u32 + ctx.r10.u32, ctx.r9.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stwx r4,r8,r10
	PPC_STORE_U32(ctx.r8.u32 + ctx.r10.u32, ctx.r4.u32);
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stwx r6,r7,r11
	PPC_STORE_U32(ctx.r7.u32 + r11.u32, ctx.r6.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0AD8"))) PPC_WEAK_FUNC(sub_820A0AD8);
PPC_FUNC_IMPL(__imp__sub_820A0AD8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r9,-32014
	ctx.r9.s64 = -2098069504;
	// addi r11,r3,2100
	r11.s64 = ctx.r3.s64 + 2100;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,-1364(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + -1364);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
	// addi r10,r3,578
	ctx.r10.s64 = ctx.r3.s64 + 578;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// blt cr6,0x820a0b38
	if (cr6.getLT()) goto loc_820A0B38;
	// addi r8,r3,580
	ctx.r8.s64 = ctx.r3.s64 + 580;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r8,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// cmpw cr6,r4,r8
	cr6.compare<int32_t>(ctx.r4.s32, ctx.r8.s32, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// li r7,-1
	ctx.r7.s64 = -1;
	// addi r8,r3,2097
	ctx.r8.s64 = ctx.r3.s64 + 2097;
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r7,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r7.u32);
	// lwz r11,-1364(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + -1364);
	// stwx r4,r8,r11
	PPC_STORE_U32(ctx.r8.u32 + r11.u32, ctx.r4.u32);
	// blr 
	return;
loc_820A0B38:
	// addi r9,r3,580
	ctx.r9.s64 = ctx.r3.s64 + 580;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// cmpw cr6,r4,r9
	cr6.compare<int32_t>(ctx.r4.s32, ctx.r9.s32, xer);
	// beq cr6,0x820a0b5c
	if (cr6.getEQ()) goto loc_820A0B5C;
	// addi r10,r3,2097
	ctx.r10.s64 = ctx.r3.s64 + 2097;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r4,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r4.u32);
	// blr 
	return;
loc_820A0B5C:
	// li r9,1
	ctx.r9.s64 = 1;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0B68"))) PPC_WEAK_FUNC(sub_820A0B68);
PPC_FUNC_IMPL(__imp__sub_820A0B68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r3,8376(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 8376);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0B78"))) PPC_WEAK_FUNC(sub_820A0B78);
PPC_FUNC_IMPL(__imp__sub_820A0B78) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// lwz r9,-1364(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// bne cr6,0x820a0ba0
	if (!cr6.getEQ()) goto loc_820A0BA0;
	// lwz r10,8376(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8376);
loc_820A0BA0:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r8,r10,56
	ctx.r8.s64 = ctx.r10.s64 * 56;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// addi r7,r11,4
	ctx.r7.s64 = r11.s64 + 4;
	// lwzx r4,r8,r7
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// bne cr6,0x820a0bc4
	if (!cr6.getEQ()) goto loc_820A0BC4;
	// lwz r10,8376(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8376);
loc_820A0BC4:
	// mulli r10,r10,56
	ctx.r10.s64 = ctx.r10.s64 * 56;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// lwzx r31,r10,r11
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// beq cr6,0x820a0c14
	if (cr6.getEQ()) goto loc_820A0C14;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a0c14
	if (cr6.getEQ()) goto loc_820A0C14;
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a0c14
	if (!cr6.getEQ()) goto loc_820A0C14;
	// cmpwi cr6,r3,84
	cr6.compare<int32_t>(ctx.r3.s32, 84, xer);
	// bne cr6,0x820a0bfc
	if (!cr6.getEQ()) goto loc_820A0BFC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r5,r11,13952
	ctx.r5.s64 = r11.s64 + 13952;
	// b 0x820a0c04
	goto loc_820A0C04;
loc_820A0BFC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r5,r11,13948
	ctx.r5.s64 = r11.s64 + 13948;
loc_820A0C04:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r7,0(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r6,8(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x8211db38
	sub_8211DB38(ctx, base);
loc_820A0C14:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0C30"))) PPC_WEAK_FUNC(sub_820A0C30);
PPC_FUNC_IMPL(__imp__sub_820A0C30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// addi r11,r30,578
	r11.s64 = r30.s64 + 578;
	// rlwinm r27,r11,2,0,29
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwzx r10,r27,r11
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bge cr6,0x820a0cec
	if (!cr6.getLT()) goto loc_820A0CEC;
	// addi r9,r30,2100
	ctx.r9.s64 = r30.s64 + 2100;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r9,r9,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x820a0cec
	if (!cr6.getEQ()) goto loc_820A0CEC;
	// cmpwi cr6,r10,-3
	cr6.compare<int32_t>(ctx.r10.s32, -3, xer);
	// ble cr6,0x820a0ca0
	if (!cr6.getGT()) goto loc_820A0CA0;
	// addi r10,r30,580
	ctx.r10.s64 = r30.s64 + 580;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x820a0ca0
	if (cr6.getEQ()) goto loc_820A0CA0;
	// lwzx r10,r27,r11
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stwx r10,r27,r11
	PPC_STORE_U32(r27.u32 + r11.u32, ctx.r10.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_820A0CA0:
	// addi r10,r30,2097
	ctx.r10.s64 = r30.s64 + 2097;
	// rlwinm r29,r10,2,0,29
	r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r28,r29,r11
	r28.u64 = PPC_LOAD_U32(r29.u32 + r11.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x820a0b78
	sub_820A0B78(ctx, base);
	// addi r11,r30,584
	r11.s64 = r30.s64 + 584;
	// li r8,1
	ctx.r8.s64 = 1;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r10,r30,580
	ctx.r10.s64 = r30.s64 + 580;
	// li r7,-1
	ctx.r7.s64 = -1;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r3,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r3.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stwx r8,r27,r11
	PPC_STORE_U32(r27.u32 + r11.u32, ctx.r8.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stwx r28,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, r28.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stwx r7,r29,r11
	PPC_STORE_U32(r29.u32 + r11.u32, ctx.r7.u32);
loc_820A0CEC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820A0CF8"))) PPC_WEAK_FUNC(sub_820A0CF8);
PPC_FUNC_IMPL(__imp__sub_820A0CF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// mulli r11,r3,936
	r11.s64 = ctx.r3.s64 * 936;
	// lwz r9,-1364(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// li r8,5
	ctx.r8.s64 = 5;
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r8,2384(r9)
	PPC_STORE_U32(ctx.r9.u32 + 2384, ctx.r8.u32);
	// lwz r9,-1364(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// stw r4,2404(r9)
	PPC_STORE_U32(ctx.r9.u32 + 2404, ctx.r4.u32);
	// lwz r10,-1364(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stw r7,2412(r11)
	PPC_STORE_U32(r11.u32 + 2412, ctx.r7.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0D30"))) PPC_WEAK_FUNC(sub_820A0D30);
PPC_FUNC_IMPL(__imp__sub_820A0D30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mulli r10,r3,936
	ctx.r10.s64 = ctx.r3.s64 * 936;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r3,2344(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0D48"))) PPC_WEAK_FUNC(sub_820A0D48);
PPC_FUNC_IMPL(__imp__sub_820A0D48) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// mulli r11,r3,936
	r11.s64 = ctx.r3.s64 * 936;
	// lwz r9,-1364(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// li r8,14
	ctx.r8.s64 = 14;
	// stw r8,2384(r9)
	PPC_STORE_U32(ctx.r9.u32 + 2384, ctx.r8.u32);
	// lwz r10,-1364(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stw r4,2404(r11)
	PPC_STORE_U32(r11.u32 + 2404, ctx.r4.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0D70"))) PPC_WEAK_FUNC(sub_820A0D70);
PPC_FUNC_IMPL(__imp__sub_820A0D70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mulli r10,r3,936
	ctx.r10.s64 = ctx.r3.s64 * 936;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r3,2348(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 2348);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bgelr cr6
	if (!cr6.getLT()) return;
	// lwz r3,2344(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0D98"))) PPC_WEAK_FUNC(sub_820A0D98);
PPC_FUNC_IMPL(__imp__sub_820A0D98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r5,-32014
	ctx.r5.s64 = -2098069504;
	// mulli r6,r3,936
	ctx.r6.s64 = ctx.r3.s64 * 936;
	// lwz r11,-1364(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + -1364);
	// add r11,r6,r11
	r11.u64 = ctx.r6.u64 + r11.u64;
	// lwz r10,2348(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2348);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blt cr6,0x820a0dd8
	if (cr6.getLT()) goto loc_820A0DD8;
	// lwz r4,2344(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// bl 0x820a0ad8
	sub_820A0AD8(ctx, base);
	// lwz r11,-1364(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + -1364);
	// li r10,-1
	ctx.r10.s64 = -1;
	// add r11,r6,r11
	r11.u64 = ctx.r6.u64 + r11.u64;
	// stw r10,2348(r11)
	PPC_STORE_U32(r11.u32 + 2348, ctx.r10.u32);
loc_820A0DD8:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0DE8"))) PPC_WEAK_FUNC(sub_820A0DE8);
PPC_FUNC_IMPL(__imp__sub_820A0DE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mulli r10,r3,936
	ctx.r10.s64 = ctx.r3.s64 * 936;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lbz r11,2356(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 2356);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0E08"))) PPC_WEAK_FUNC(sub_820A0E08);
PPC_FUNC_IMPL(__imp__sub_820A0E08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// bne cr6,0x820a0e64
	if (!cr6.getEQ()) goto loc_820A0E64;
	// lwz r11,2348(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2348);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a0e28
	if (!cr6.getLT()) goto loc_820A0E28;
	// lwz r11,2344(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2344);
loc_820A0E28:
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r11,56
	r11.s64 = r11.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a0e54
	if (!cr6.getEQ()) goto loc_820A0E54;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lfs f1,4(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
loc_820A0E54:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
	// lfs f1,4(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
loc_820A0E64:
	// lwz r11,3284(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3284);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a0e74
	if (!cr6.getLT()) goto loc_820A0E74;
	// lwz r11,3280(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3280);
loc_820A0E74:
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r11,56
	r11.s64 = r11.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a0ea4
	if (!cr6.getEQ()) goto loc_820A0EA4;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lfs f0,4(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	f0.f64 = double(temp.f32);
	// fneg f1,f0
	ctx.f1.u64 = f0.u64 ^ 0x8000000000000000;
	// blr 
	return;
loc_820A0EA4:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
	// lfs f0,4(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	f0.f64 = double(temp.f32);
	// fneg f1,f0
	ctx.f1.u64 = f0.u64 ^ 0x8000000000000000;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0EB8"))) PPC_WEAK_FUNC(sub_820A0EB8);
PPC_FUNC_IMPL(__imp__sub_820A0EB8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r11,2348(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2348);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// bge cr6,0x820a0ed4
	if (!cr6.getLT()) goto loc_820A0ED4;
	// lwz r9,2344(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2344);
loc_820A0ED4:
	// cmpwi cr6,r9,17
	cr6.compare<int32_t>(ctx.r9.s32, 17, xer);
	// bne cr6,0x820a0ee4
	if (!cr6.getEQ()) goto loc_820A0EE4;
	// lfs f1,4412(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4412);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
loc_820A0EE4:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// bge cr6,0x820a0ef4
	if (!cr6.getLT()) goto loc_820A0EF4;
	// lwz r9,2344(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2344);
loc_820A0EF4:
	// cmpwi cr6,r9,40
	cr6.compare<int32_t>(ctx.r9.s32, 40, xer);
	// bne cr6,0x820a0f04
	if (!cr6.getEQ()) goto loc_820A0F04;
	// lfs f1,4416(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4416);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
loc_820A0F04:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a0f10
	if (!cr6.getLT()) goto loc_820A0F10;
	// lwz r11,2344(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2344);
loc_820A0F10:
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r11,56
	r11.s64 = r11.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a0f3c
	if (!cr6.getEQ()) goto loc_820A0F3C;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lfs f1,52(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 52);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
loc_820A0F3C:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
	// lfs f1,52(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 52);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0F50"))) PPC_WEAK_FUNC(sub_820A0F50);
PPC_FUNC_IMPL(__imp__sub_820A0F50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,2348(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2348);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// bge cr6,0x820a0f6c
	if (!cr6.getLT()) goto loc_820A0F6C;
	// lwz r9,2344(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2344);
loc_820A0F6C:
	// cmpwi cr6,r9,17
	cr6.compare<int32_t>(ctx.r9.s32, 17, xer);
	// bne cr6,0x820a0fac
	if (!cr6.getEQ()) goto loc_820A0FAC;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f12,4412(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4412);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,13964(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13964);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmadds f0,f1,f0,f13
	f0.f64 = double(float(ctx.f1.f64 * f0.f64 + ctx.f13.f64));
	// lfs f13,13960(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13960);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f12
	f0.f64 = double(float(f0.f64 * ctx.f12.f64));
	// stfs f0,4412(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4412, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blelr cr6
	if (!cr6.getGT()) return;
	// stfs f13,4412(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 4412, temp.u32);
	// blr 
	return;
loc_820A0FAC:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bge cr6,0x820a0fb8
	if (!cr6.getLT()) goto loc_820A0FB8;
	// lwz r10,2344(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2344);
loc_820A0FB8:
	// cmpwi cr6,r10,40
	cr6.compare<int32_t>(ctx.r10.s32, 40, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f12,4416(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4416);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,13964(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13964);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmadds f0,f1,f0,f13
	f0.f64 = double(float(ctx.f1.f64 * f0.f64 + ctx.f13.f64));
	// lfs f13,13960(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13960);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f12
	f0.f64 = double(float(f0.f64 * ctx.f12.f64));
	// stfs f0,4416(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4416, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blelr cr6
	if (!cr6.getGT()) return;
	// stfs f13,4416(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 4416, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A0FF8"))) PPC_WEAK_FUNC(sub_820A0FF8);
PPC_FUNC_IMPL(__imp__sub_820A0FF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,2348(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2348);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// bge cr6,0x820a1014
	if (!cr6.getLT()) goto loc_820A1014;
	// lwz r9,2344(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2344);
loc_820A1014:
	// cmpwi cr6,r9,17
	cr6.compare<int32_t>(ctx.r9.s32, 17, xer);
	// bne cr6,0x820a1054
	if (!cr6.getEQ()) goto loc_820A1054;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f12,4412(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4412);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,13964(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13964);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmadds f0,f1,f0,f13
	f0.f64 = double(float(ctx.f1.f64 * f0.f64 + ctx.f13.f64));
	// lfs f13,13968(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13968);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 / f0.f64));
	// stfs f0,4412(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4412, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgelr cr6
	if (!cr6.getLT()) return;
	// stfs f13,4412(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 4412, temp.u32);
	// blr 
	return;
loc_820A1054:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bge cr6,0x820a1060
	if (!cr6.getLT()) goto loc_820A1060;
	// lwz r10,2344(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2344);
loc_820A1060:
	// cmpwi cr6,r10,40
	cr6.compare<int32_t>(ctx.r10.s32, 40, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f12,4416(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4416);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,13964(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13964);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmadds f0,f1,f0,f13
	f0.f64 = double(float(ctx.f1.f64 * f0.f64 + ctx.f13.f64));
	// lfs f13,13968(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13968);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 / f0.f64));
	// stfs f0,4416(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4416, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgelr cr6
	if (!cr6.getLT()) return;
	// stfs f13,4416(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 4416, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A10A0"))) PPC_WEAK_FUNC(sub_820A10A0);
PPC_FUNC_IMPL(__imp__sub_820A10A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r3,56
	r11.s64 = ctx.r3.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a10cc
	if (!cr6.getEQ()) goto loc_820A10CC;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lfs f1,44(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 44);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
loc_820A10CC:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
	// lfs f1,44(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 44);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A10E0"))) PPC_WEAK_FUNC(sub_820A10E0);
PPC_FUNC_IMPL(__imp__sub_820A10E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r3,56
	r11.s64 = ctx.r3.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a110c
	if (!cr6.getEQ()) goto loc_820A110C;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lfs f1,104(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 104);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
loc_820A110C:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
	// lfs f1,104(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 104);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A1120"))) PPC_WEAK_FUNC(sub_820A1120);
PPC_FUNC_IMPL(__imp__sub_820A1120) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r3,56
	r11.s64 = ctx.r3.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a1148
	if (!cr6.getEQ()) goto loc_820A1148;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820a1150
	goto loc_820A1150;
loc_820A1148:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
loc_820A1150:
	// lbz r11,34(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 34);
	// extsb r10,r11
	ctx.r10.s64 = r11.s8;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r11,1176(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1176);
	// mullw r11,r10,r11
	r11.s64 = int64_t(ctx.r10.s32) * int64_t(r11.s32);
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A1170"))) PPC_WEAK_FUNC(sub_820A1170);
PPC_FUNC_IMPL(__imp__sub_820A1170) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r3,56
	r11.s64 = ctx.r3.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a119c
	if (!cr6.getEQ()) goto loc_820A119C;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lbz r3,37(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 37);
	// blr 
	return;
loc_820A119C:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
	// lbz r3,37(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 37);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A11B0"))) PPC_WEAK_FUNC(sub_820A11B0);
PPC_FUNC_IMPL(__imp__sub_820A11B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r3,56
	r11.s64 = ctx.r3.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a11dc
	if (!cr6.getEQ()) goto loc_820A11DC;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lhz r3,38(r11)
	ctx.r3.u64 = PPC_LOAD_U16(r11.u32 + 38);
	// blr 
	return;
loc_820A11DC:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
	// lhz r3,38(r11)
	ctx.r3.u64 = PPC_LOAD_U16(r11.u32 + 38);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A11F0"))) PPC_WEAK_FUNC(sub_820A11F0);
PPC_FUNC_IMPL(__imp__sub_820A11F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r3,56
	r11.s64 = ctx.r3.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a121c
	if (!cr6.getEQ()) goto loc_820A121C;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lbz r3,36(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 36);
	// blr 
	return;
loc_820A121C:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
	// lbz r3,36(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 36);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A1230"))) PPC_WEAK_FUNC(sub_820A1230);
PPC_FUNC_IMPL(__imp__sub_820A1230) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r3,56
	r11.s64 = ctx.r3.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a1258
	if (!cr6.getEQ()) goto loc_820A1258;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820a1260
	goto loc_820A1260;
loc_820A1258:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
loc_820A1260:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// and r11,r11,r4
	r11.u64 = r11.u64 & ctx.r4.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r3,r11,1
	ctx.r3.u64 = r11.u64 ^ 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A1278"))) PPC_WEAK_FUNC(sub_820A1278);
PPC_FUNC_IMPL(__imp__sub_820A1278) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f30,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, f30.u64);
	// stfd f31,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lfs f31,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f31.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// lfs f30,2780(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2780);
	f30.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// fsubs f0,f31,f0
	f0.f64 = double(float(f31.f64 - f0.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// stfs f0,2792(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2792, temp.u32);
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// fsubs f0,f31,f0
	f0.f64 = double(float(f31.f64 - f0.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// stfs f0,3728(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 3728, temp.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f30,-32(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// lfd f31,-24(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A1300"))) PPC_WEAK_FUNC(sub_820A1300);
PPC_FUNC_IMPL(__imp__sub_820A1300) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r9,-32014
	ctx.r9.s64 = -2098069504;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// lwz r10,-1364(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + -1364);
	// beq cr6,0x820a13c0
	if (cr6.getEQ()) goto loc_820A13C0;
	// mulli r5,r3,936
	ctx.r5.s64 = ctx.r3.s64 * 936;
	// add r11,r5,r10
	r11.u64 = ctx.r5.u64 + ctx.r10.u64;
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// lis r7,-32256
	ctx.r7.s64 = -2113929216;
	// lwz r8,2344(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// lfs f0,13972(r7)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 13972);
	f0.f64 = double(temp.f32);
	// lfs f11,13976(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 13976);
	ctx.f11.f64 = double(temp.f32);
	// cmpwi cr6,r8,30
	cr6.compare<int32_t>(ctx.r8.s32, 30, xer);
	// beq cr6,0x820a1344
	if (cr6.getEQ()) goto loc_820A1344;
	// cmpwi cr6,r8,23
	cr6.compare<int32_t>(ctx.r8.s32, 23, xer);
	// beq cr6,0x820a1344
	if (cr6.getEQ()) goto loc_820A1344;
	// fmr f13,f11
	ctx.f13.f64 = ctx.f11.f64;
	// b 0x820a1348
	goto loc_820A1348;
loc_820A1344:
	// fmr f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = f0.f64;
loc_820A1348:
	// lfs f12,2876(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2876);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// bge cr6,0x820a1374
	if (!cr6.getLT()) goto loc_820A1374;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lfs f10,2876(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2876);
	ctx.f10.f64 = double(temp.f32);
	// lfs f13,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f12,13984(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13984);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f13,f12,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f10.f64));
	// stfs f13,2876(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 2876, temp.u32);
	// lwz r10,-1364(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + -1364);
loc_820A1374:
	// add r10,r5,r10
	ctx.r10.u64 = ctx.r5.u64 + ctx.r10.u64;
	// lwz r11,2344(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2344);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x820a1394
	if (cr6.getEQ()) goto loc_820A1394;
	// cmpwi cr6,r11,23
	cr6.compare<int32_t>(r11.s32, 23, xer);
	// beq cr6,0x820a1394
	if (cr6.getEQ()) goto loc_820A1394;
	// fmr f13,f11
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = ctx.f11.f64;
	// b 0x820a1398
	goto loc_820A1398;
loc_820A1394:
	// fmr f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = f0.f64;
loc_820A1398:
	// lfs f12,2876(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2876);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// blelr cr6
	if (!cr6.getGT()) return;
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x820a13b8
	if (cr6.getEQ()) goto loc_820A13B8;
	// cmpwi cr6,r11,23
	cr6.compare<int32_t>(r11.s32, 23, xer);
	// beq cr6,0x820a13b8
	if (cr6.getEQ()) goto loc_820A13B8;
	// fmr f0,f11
	f0.f64 = ctx.f11.f64;
loc_820A13B8:
	// stfs f0,2876(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 2876, temp.u32);
	// blr 
	return;
loc_820A13C0:
	// mulli r7,r3,936
	ctx.r7.s64 = ctx.r3.s64 * 936;
	// add r11,r7,r10
	r11.u64 = ctx.r7.u64 + ctx.r10.u64;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lfs f0,2876(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2876);
	f0.f64 = double(temp.f32);
	// lfs f12,2688(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 2688);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// ble cr6,0x820a13fc
	if (!cr6.getGT()) goto loc_820A13FC;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lfs f11,2876(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2876);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,13980(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13980);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f0,f0,f13,f11
	f0.f64 = double(float(-(f0.f64 * ctx.f13.f64 - ctx.f11.f64)));
	// stfs f0,2876(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2876, temp.u32);
	// lwz r10,-1364(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + -1364);
loc_820A13FC:
	// add r11,r7,r10
	r11.u64 = ctx.r7.u64 + ctx.r10.u64;
	// lfs f0,2876(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2876);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bgelr cr6
	if (!cr6.getLT()) return;
	// stfs f12,2876(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 2876, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A1418"))) PPC_WEAK_FUNC(sub_820A1418);
PPC_FUNC_IMPL(__imp__sub_820A1418) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r7,-32014
	ctx.r7.s64 = -2098069504;
	// mulli r6,r3,936
	ctx.r6.s64 = ctx.r3.s64 * 936;
	// lwz r8,-1364(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + -1364);
	// add r11,r6,r8
	r11.u64 = ctx.r6.u64 + ctx.r8.u64;
	// lwz r10,2348(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2348);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bge cr6,0x820a1438
	if (!cr6.getLT()) goto loc_820A1438;
	// lwz r10,2344(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2344);
loc_820A1438:
	// lis r9,-32190
	ctx.r9.s64 = -2109603840;
	// mulli r10,r10,56
	ctx.r10.s64 = ctx.r10.s64 * 56;
	// addi r9,r9,6504
	ctx.r9.s64 = ctx.r9.s64 + 6504;
	// addi r5,r9,8
	ctx.r5.s64 = ctx.r9.s64 + 8;
	// lwzx r5,r10,r5
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x820a1460
	if (!cr6.getEQ()) goto loc_820A1460;
	// addi r9,r9,12
	ctx.r9.s64 = ctx.r9.s64 + 12;
	// lwzx r10,r10,r9
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// b 0x820a1468
	goto loc_820A1468;
loc_820A1460:
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// addi r10,r10,1240
	ctx.r10.s64 = ctx.r10.s64 + 1240;
loc_820A1468:
	// lwz r9,2884(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2884);
	// lfs f0,80(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 80);
	f0.f64 = double(temp.f32);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x820a14d0
	if (cr6.getEQ()) goto loc_820A14D0;
	// lfs f13,2880(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2880);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820a14a8
	if (!cr6.getLT()) goto loc_820A14A8;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lfs f11,2880(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2880);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f13,12900(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12900);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f12,f13,f11
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + ctx.f11.f64));
	// stfs f13,2880(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 2880, temp.u32);
	// lwz r8,-1364(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + -1364);
loc_820A14A8:
	// add r11,r6,r8
	r11.u64 = ctx.r6.u64 + ctx.r8.u64;
	// lfs f13,2880(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2880);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bltlr cr6
	if (cr6.getLT()) return;
	// stfs f0,2880(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2880, temp.u32);
	// lwz r11,-1364(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + -1364);
	// li r10,0
	ctx.r10.s64 = 0;
	// add r11,r6,r11
	r11.u64 = ctx.r6.u64 + r11.u64;
	// stw r10,2884(r11)
	PPC_STORE_U32(r11.u32 + 2884, ctx.r10.u32);
	// blr 
	return;
loc_820A14D0:
	// lwz r10,2388(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2388);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blelr cr6
	if (!cr6.getGT()) return;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,2880(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2880);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,2688(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2688);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f13,f12
	cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// ble cr6,0x820a1514
	if (!cr6.getGT()) goto loc_820A1514;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lfs f11,2880(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2880);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f0,13988(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13988);
	f0.f64 = double(temp.f32);
	// fnmsubs f0,f13,f0,f11
	f0.f64 = double(float(-(ctx.f13.f64 * f0.f64 - ctx.f11.f64)));
	// stfs f0,2880(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2880, temp.u32);
	// lwz r8,-1364(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + -1364);
loc_820A1514:
	// add r11,r6,r8
	r11.u64 = ctx.r6.u64 + ctx.r8.u64;
	// lfs f0,2880(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2880);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bgelr cr6
	if (!cr6.getLT()) return;
	// stfs f12,2880(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 2880, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A1530"))) PPC_WEAK_FUNC(sub_820A1530);
PPC_FUNC_IMPL(__imp__sub_820A1530) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a156c
	if (cr6.getEQ()) goto loc_820A156C;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_820A156C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,36(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a1590
	if (cr6.getEQ()) goto loc_820A1590;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_820A1590:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,40(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a15b4
	if (cr6.getEQ()) goto loc_820A15B4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_820A15B4:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,44(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 44);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a15d8
	if (cr6.getEQ()) goto loc_820A15D8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_820A15D8:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,48(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 48);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a15fc
	if (cr6.getEQ()) goto loc_820A15FC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_820A15FC:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,52(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 52);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a1620
	if (cr6.getEQ()) goto loc_820A1620;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_820A1620:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lhz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 12);
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// cmpwi cr6,r10,35
	cr6.compare<int32_t>(ctx.r10.s32, 35, xer);
	// ble cr6,0x820a1654
	if (!cr6.getGT()) goto loc_820A1654;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,140(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 140);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a1654
	if (cr6.getEQ()) goto loc_820A1654;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_820A1654:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A1670"))) PPC_WEAK_FUNC(sub_820A1670);
PPC_FUNC_IMPL(__imp__sub_820A1670) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lhz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 12);
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// cmpwi cr6,r10,15
	cr6.compare<int32_t>(ctx.r10.s32, 15, xer);
	// ble cr6,0x820a16e0
	if (!cr6.getGT()) goto loc_820A16E0;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a16bc
	if (cr6.getEQ()) goto loc_820A16BC;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_820A16BC:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,60(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a16e0
	if (cr6.getEQ()) goto loc_820A16E0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_820A16E0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A16F8"))) PPC_WEAK_FUNC(sub_820A16F8);
PPC_FUNC_IMPL(__imp__sub_820A16F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// lwz r30,16(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r25,r8
	r25.u64 = ctx.r8.u64;
	// mr r24,r9
	r24.u64 = ctx.r9.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820a17f4
	if (cr6.getEQ()) goto loc_820A17F4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820ccb20
	sub_820CCB20(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820cca18
	sub_820CCA18(ctx, base);
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lfs f1,20(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d4fd8
	sub_820D4FD8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d0458
	sub_820D0458(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d4d08
	sub_820D4D08(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820e00b8
	sub_820E00B8(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a17f4
	if (cr6.getEQ()) goto loc_820A17F4;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r10,r10,65
	ctx.r10.u64 = ctx.r10.u64 | 65;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stw r24,136(r11)
	PPC_STORE_U32(r11.u32 + 136, r24.u32);
	// bl 0x820d48f8
	sub_820D48F8(ctx, base);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// addi r4,r11,32
	ctx.r4.s64 = r11.s64 + 32;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lfs f0,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,4(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lfs f0,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lfs f0,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,12(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 12, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stw r31,228(r11)
	PPC_STORE_U32(r11.u32 + 228, r31.u32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,108(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lwz r11,-6372(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -6372);
	// stw r11,232(r10)
	PPC_STORE_U32(ctx.r10.u32 + 232, r11.u32);
loc_820A17F4:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_820A1800"))) PPC_WEAK_FUNC(sub_820A1800);
PPC_FUNC_IMPL(__imp__sub_820A1800) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// stfd f30,-88(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -88, f30.u64);
	// stfd f31,-80(r1)
	PPC_STORE_U64(ctx.r1.u32 + -80, f31.u64);
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r24,r8
	r24.u64 = ctx.r8.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820a19d4
	if (cr6.getEQ()) goto loc_820A19D4;
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,-1364(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// bl 0x820b3c78
	sub_820B3C78(ctx, base);
	// lfs f0,16(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	f0.f64 = double(temp.f32);
	// li r25,0
	r25.s64 = 0;
	// lfs f13,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820a186c
	if (!cr6.getGT()) goto loc_820A186C;
	// fsubs f31,f0,f1
	f31.f64 = double(float(f0.f64 - ctx.f1.f64));
	// fsubs f30,f13,f1
	f30.f64 = double(float(ctx.f13.f64 - ctx.f1.f64));
	// b 0x820a1874
	goto loc_820A1874;
loc_820A186C:
	// fsubs f31,f13,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(ctx.f13.f64 - ctx.f1.f64));
	// fsubs f30,f0,f1
	f30.f64 = double(float(f0.f64 - ctx.f1.f64));
loc_820A1874:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// bl 0x820b3e10
	sub_820B3E10(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f4,8(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// li r8,31
	ctx.r8.s64 = 31;
	// lfs f3,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f2,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// fmr f6,f30
	ctx.f6.f64 = f30.f64;
	// fmr f5,f31
	ctx.f5.f64 = f31.f64;
	// lfs f8,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f7,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f7.f64 = double(temp.f32);
	// bl 0x82112020
	sub_82112020(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820a18dc
	if (cr6.getEQ()) goto loc_820A18DC;
	// lfs f0,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f0,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,116(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f0,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	f0.f64 = double(temp.f32);
	// b 0x820a18fc
	goto loc_820A18FC;
loc_820A18DC:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// li r25,1
	r25.s64 = 1;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// lfs f0,12(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f0,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	f0.f64 = double(temp.f32);
	// stfs f0,116(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f0,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	f0.f64 = double(temp.f32);
loc_820A18FC:
	// li r4,1
	ctx.r4.s64 = 1;
	// stfs f0,120(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820b3e10
	sub_820B3E10(ctx, base);
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
	// mr r8,r26
	ctx.r8.u64 = r26.u64;
	// lwz r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820a16f8
	sub_820A16F8(ctx, base);
	// lwz r11,100(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 100);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a19c0
	if (cr6.getEQ()) goto loc_820A19C0;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// beq cr6,0x820a1978
	if (cr6.getEQ()) goto loc_820A1978;
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r10,r10,256
	ctx.r10.u64 = ctx.r10.u64 | 256;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lfs f0,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	f0.f64 = double(temp.f32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// stfs f0,212(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 212, temp.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// lfs f0,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,216(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 216, temp.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// lfs f0,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,220(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 220, temp.u32);
loc_820A1978:
	// bl 0x820b3d88
	sub_820B3D88(ctx, base);
	// li r10,255
	ctx.r10.s64 = 255;
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// addi r31,r1,100
	r31.s64 = ctx.r1.s64 + 100;
	// stb r3,104(r1)
	PPC_STORE_U8(ctx.r1.u32 + 104, ctx.r3.u8);
	// addi r29,r1,128
	r29.s64 = ctx.r1.s64 + 128;
	// addi r28,r11,204
	r28.s64 = r11.s64 + 204;
	// addi r27,r1,104
	r27.s64 = ctx.r1.s64 + 104;
	// stb r10,105(r1)
	PPC_STORE_U8(ctx.r1.u32 + 105, ctx.r10.u8);
	// addi r26,r1,112
	r26.s64 = ctx.r1.s64 + 112;
	// bl 0x820b3de0
	sub_820B3DE0(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// li r9,20
	ctx.r9.s64 = 20;
	// bl 0x821159b8
	sub_821159B8(ctx, base);
loc_820A19C0:
	// clrlwi r11,r24,24
	r11.u64 = r24.u32 & 0xFF;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// stw r11,136(r30)
	PPC_STORE_U32(r30.u32 + 136, r11.u32);
loc_820A19D4:
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// lfd f30,-88(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// lfd f31,-80(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_820A19E8"))) PPC_WEAK_FUNC(sub_820A19E8);
PPC_FUNC_IMPL(__imp__sub_820A19E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82136da8
	sub_82136DA8(ctx, base);
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// lis r30,-32014
	r30.s64 = -2098069504;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// addi r3,r11,2960
	ctx.r3.s64 = r11.s64 + 2960;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r4,26
	ctx.r4.s64 = 26;
	// li r3,196
	ctx.r3.s64 = 196;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f0,148(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f0,152(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// bl 0x820e2be8
	sub_820E2BE8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a1b60
	if (cr6.getEQ()) goto loc_820A1B60;
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lwz r11,4372(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4372);
	// subfic r11,r11,240
	xer.ca = r11.u32 <= 240;
	r11.s64 = 240 - r11.s64;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// sth r11,130(r31)
	PPC_STORE_U16(r31.u32 + 130, r11.u16);
	// bge cr6,0x820a1aa0
	if (!cr6.getLT()) goto loc_820A1AA0;
	// li r11,0
	r11.s64 = 0;
	// sth r11,130(r31)
	PPC_STORE_U16(r31.u32 + 130, r11.u16);
loc_820A1AA0:
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,15,12
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFF9FFFF;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r10,r3,17,0,14
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 17) & 0xFFFE0000;
	// li r8,1
	ctx.r8.s64 = 1;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820a1800
	sub_820A1800(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a1b60
	if (cr6.getEQ()) goto loc_820A1B60;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// li r9,60
	ctx.r9.s64 = 60;
	// li r8,1920
	ctx.r8.s64 = 1920;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// lfs f0,14016(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14016);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,14012(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14012);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r7,r10,13992
	ctx.r7.s64 = ctx.r10.s64 + 13992;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f0,140(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 140, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f13,148(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 148, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stw r9,188(r11)
	PPC_STORE_U32(r11.u32 + 188, ctx.r9.u32);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a1b60
	if (cr6.getEQ()) goto loc_820A1B60;
	// addi r4,r31,88
	ctx.r4.s64 = r31.s64 + 88;
	// bl 0x820dd8d8
	sub_820DD8D8(ctx, base);
loc_820A1B60:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820A1B70"))) PPC_WEAK_FUNC(sub_820A1B70);
PPC_FUNC_IMPL(__imp__sub_820A1B70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// addi r4,r1,240
	ctx.r4.s64 = ctx.r1.s64 + 240;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82136da8
	sub_82136DA8(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f1,14036(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14036);
	ctx.f1.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// bl 0x8210b968
	sub_8210B968(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// lfs f1,14032(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14032);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// addi r3,r11,2960
	ctx.r3.s64 = r11.s64 + 2960;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// stfs f0,160(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// stfs f0,164(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// stfs f0,168(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r31,r3,31
	r31.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f4,200(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f4.f64 = double(temp.f32);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lfs f3,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f3.f64 = double(temp.f32);
	// addi r3,r1,240
	ctx.r3.s64 = ctx.r1.s64 + 240;
	// lfs f2,192(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f2.f64 = double(temp.f32);
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f0,14028(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14028);
	f0.f64 = double(temp.f32);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// lfs f13,14024(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14024);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmadds f13,f12,f0,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// lfs f0,14020(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14020);
	f0.f64 = double(temp.f32);
	// fdivs f1,f0,f13
	ctx.f1.f64 = double(float(f0.f64 / ctx.f13.f64));
	// bl 0x820d3760
	sub_820D3760(ctx, base);
	// li r4,3
	ctx.r4.s64 = 3;
	// li r3,186
	ctx.r3.s64 = 186;
	// bl 0x820e2be8
	sub_820E2BE8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a1d30
	if (cr6.getEQ()) goto loc_820A1D30;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,15,12
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFF9FFFF;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r10,r3,17,0,14
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 17) & 0xFFFE0000;
	// li r8,1
	ctx.r8.s64 = 1;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// addi r7,r1,240
	ctx.r7.s64 = ctx.r1.s64 + 240;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820a1800
	sub_820A1800(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a1d18
	if (cr6.getEQ()) goto loc_820A1D18;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lfs f0,13964(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13964);
	f0.f64 = double(temp.f32);
	// li r10,60
	ctx.r10.s64 = 60;
	// ori r9,r9,2
	ctx.r9.u64 = ctx.r9.u64 | 2;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f0,140(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 140, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stw r10,188(r11)
	PPC_STORE_U32(r11.u32 + 188, ctx.r10.u32);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// ori r11,r11,32
	r11.u64 = r11.u64 | 32;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
loc_820A1D18:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a1d28
	if (cr6.getEQ()) goto loc_820A1D28;
	// stw r28,60(r11)
	PPC_STORE_U32(r11.u32 + 60, r28.u32);
loc_820A1D28:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820e0360
	sub_820E0360(ctx, base);
loc_820A1D30:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820A1D40"))) PPC_WEAK_FUNC(sub_820A1D40);
PPC_FUNC_IMPL(__imp__sub_820A1D40) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-288(r1)
	ea = -288 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r27,r7
	r27.u64 = ctx.r7.u64;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82136da8
	sub_82136DA8(ctx, base);
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// addi r3,r11,2960
	ctx.r3.s64 = r11.s64 + 2960;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r3,199
	ctx.r3.s64 = 199;
	// cmpwi cr6,r30,27
	cr6.compare<int32_t>(r30.s32, 27, xer);
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f0,148(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f0,152(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// beq cr6,0x820a1dec
	if (cr6.getEQ()) goto loc_820A1DEC;
	// cmpwi cr6,r30,28
	cr6.compare<int32_t>(r30.s32, 28, xer);
	// beq cr6,0x820a1de4
	if (cr6.getEQ()) goto loc_820A1DE4;
	// cmpwi cr6,r30,29
	cr6.compare<int32_t>(r30.s32, 29, xer);
	// bne cr6,0x820a1df0
	if (!cr6.getEQ()) goto loc_820A1DF0;
	// b 0x820a1df0
	goto loc_820A1DF0;
loc_820A1DE4:
	// li r3,200
	ctx.r3.s64 = 200;
	// b 0x820a1df0
	goto loc_820A1DF0;
loc_820A1DEC:
	// li r3,201
	ctx.r3.s64 = 201;
loc_820A1DF0:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x820e2be8
	sub_820E2BE8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a1efc
	if (cr6.getEQ()) goto loc_820A1EFC;
	// cmpwi cr6,r30,27
	cr6.compare<int32_t>(r30.s32, 27, xer);
	// beq cr6,0x820a1e24
	if (cr6.getEQ()) goto loc_820A1E24;
	// cmpwi cr6,r30,28
	cr6.compare<int32_t>(r30.s32, 28, xer);
	// beq cr6,0x820a1e24
	if (cr6.getEQ()) goto loc_820A1E24;
	// cmpwi cr6,r30,29
	cr6.compare<int32_t>(r30.s32, 29, xer);
	// beq cr6,0x820a1e24
	if (cr6.getEQ()) goto loc_820A1E24;
	// li r11,240
	r11.s64 = 240;
	// b 0x820a1e38
	goto loc_820A1E38;
loc_820A1E24:
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// li r11,300
	r11.s64 = 300;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x820a1e38
	if (cr6.getEQ()) goto loc_820A1E38;
	// li r11,180
	r11.s64 = 180;
loc_820A1E38:
	// sth r11,130(r31)
	PPC_STORE_U16(r31.u32 + 130, r11.u16);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,15,12
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFF9FFFF;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r10,r3,17,0,14
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 17) & 0xFFFE0000;
	// li r8,1
	ctx.r8.s64 = 1;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820a1800
	sub_820A1800(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a1eec
	if (cr6.getEQ()) goto loc_820A1EEC;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// li r9,60
	ctx.r9.s64 = 60;
	// li r8,2294
	ctx.r8.s64 = 2294;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// lfs f0,13964(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13964);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r7,r10,13992
	ctx.r7.s64 = ctx.r10.s64 + 13992;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f0,140(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 140, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stw r9,188(r11)
	PPC_STORE_U32(r11.u32 + 188, ctx.r9.u32);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a1eec
	if (cr6.getEQ()) goto loc_820A1EEC;
	// addi r4,r31,88
	ctx.r4.s64 = r31.s64 + 88;
	// bl 0x820dd8d8
	sub_820DD8D8(ctx, base);
loc_820A1EEC:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a1efc
	if (cr6.getEQ()) goto loc_820A1EFC;
	// stw r27,64(r11)
	PPC_STORE_U32(r11.u32 + 64, r27.u32);
loc_820A1EFC:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// addi r1,r1,288
	ctx.r1.s64 = ctx.r1.s64 + 288;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820A1F10"))) PPC_WEAK_FUNC(sub_820A1F10);
PPC_FUNC_IMPL(__imp__sub_820A1F10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-272(r1)
	ea = -272 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f0,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// addi r3,r11,2960
	ctx.r3.s64 = r11.s64 + 2960;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r4,87
	ctx.r4.s64 = 87;
	// li r3,203
	ctx.r3.s64 = 203;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f0,148(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f0,152(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// bl 0x820e2be8
	sub_820E2BE8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a2018
	if (cr6.getEQ()) goto loc_820A2018;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// li r10,1200
	ctx.r10.s64 = 1200;
	// rlwinm r11,r11,0,15,12
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFF9FFFF;
	// sth r10,130(r31)
	PPC_STORE_U16(r31.u32 + 130, ctx.r10.u16);
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r10,r3,17,0,14
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 17) & 0xFFFE0000;
	// li r8,1
	ctx.r8.s64 = 1;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820a1800
	sub_820A1800(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a2018
	if (cr6.getEQ()) goto loc_820A2018;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r10,108(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// li r9,60
	ctx.r9.s64 = 60;
	// lfs f0,14016(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14016);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,140(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 140, temp.u32);
	// lfs f13,14012(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14012);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f13,148(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 148, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stw r9,188(r11)
	PPC_STORE_U32(r11.u32 + 188, ctx.r9.u32);
loc_820A2018:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// addi r1,r1,272
	ctx.r1.s64 = ctx.r1.s64 + 272;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820A2028"))) PPC_WEAK_FUNC(sub_820A2028);
PPC_FUNC_IMPL(__imp__sub_820A2028) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mulli r10,r3,936
	ctx.r10.s64 = ctx.r3.s64 * 936;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// addi r29,r11,2344
	r29.s64 = r11.s64 + 2344;
	// lwz r31,544(r29)
	r31.u64 = PPC_LOAD_U32(r29.u32 + 544);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a2130
	if (cr6.getEQ()) goto loc_820A2130;
	// lwz r28,16(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x820a2130
	if (cr6.getEQ()) goto loc_820A2130;
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r30,20(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r3,r29,616
	ctx.r3.s64 = r29.s64 + 616;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r10,20(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// stfs f0,132(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// stfs f0,136(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f1,20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// lwz r6,24(r27)
	ctx.r6.u64 = PPC_LOAD_U32(r27.u32 + 24);
	// addi r4,r29,744
	ctx.r4.s64 = r29.s64 + 744;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d4fd8
	sub_820D4FD8(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820d4d08
	sub_820D4D08(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lhz r11,14(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 14);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// rlwinm r3,r11,6,0,25
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0xFFFFFFC0;
	// bl 0x8209cd50
	sub_8209CD50(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r31,88
	ctx.r3.s64 = r31.s64 + 88;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// lwz r31,12(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// addi r29,r1,80
	r29.s64 = ctx.r1.s64 + 80;
	// bl 0x8210d820
	sub_8210D820(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x8210b450
	sub_8210B450(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r4,0(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// bl 0x8211cef0
	sub_8211CEF0(ctx, base);
	// lbz r11,1(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 1);
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// stb r11,1(r28)
	PPC_STORE_U8(r28.u32 + 1, r11.u8);
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lfs f0,56(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 56);
	f0.f64 = double(temp.f32);
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// stfs f0,28(r28)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r28.u32 + 28, temp.u32);
loc_820A2130:
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820A2138"))) PPC_WEAK_FUNC(sub_820A2138);
PPC_FUNC_IMPL(__imp__sub_820A2138) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mulli r10,r3,936
	ctx.r10.s64 = ctx.r3.s64 * 936;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// addi r31,r11,2344
	r31.s64 = r11.s64 + 2344;
	// lwz r11,544(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 544);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a219c
	if (!cr6.getEQ()) goto loc_820A219C;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a219c
	if (!cr6.getGT()) goto loc_820A219C;
	// li r4,86
	ctx.r4.s64 = 86;
	// li r3,202
	ctx.r3.s64 = 202;
	// bl 0x820e2be8
	sub_820E2BE8(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a219c
	if (cr6.getEQ()) goto loc_820A219C;
	// li r11,0
	r11.s64 = 0;
	// stw r3,544(r31)
	PPC_STORE_U32(r31.u32 + 544, ctx.r3.u32);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r11,548(r31)
	PPC_STORE_U32(r31.u32 + 548, r11.u32);
	// sth r10,130(r3)
	PPC_STORE_U16(ctx.r3.u32 + 130, ctx.r10.u16);
loc_820A219C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A21B0"))) PPC_WEAK_FUNC(sub_820A21B0);
PPC_FUNC_IMPL(__imp__sub_820A21B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mulli r10,r3,936
	ctx.r10.s64 = ctx.r3.s64 * 936;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// addi r31,r11,2344
	r31.s64 = r11.s64 + 2344;
	// lwz r3,544(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 544);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a21f0
	if (cr6.getEQ()) goto loc_820A21F0;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x820e0358
	sub_820E0358(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,544(r31)
	PPC_STORE_U32(r31.u32 + 544, r11.u32);
loc_820A21F0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A2208"))) PPC_WEAK_FUNC(sub_820A2208);
PPC_FUNC_IMPL(__imp__sub_820A2208) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed12c
	// stfd f29,-88(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -88, f29.u64);
	// stfd f30,-80(r1)
	PPC_STORE_U64(ctx.r1.u32 + -80, f30.u64);
	// stfd f31,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, f31.u64);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// bl 0x820b3e00
	sub_820B3E00(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lwz r28,-1364(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// addi r3,r28,2960
	ctx.r3.s64 = r28.s64 + 2960;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// stfs f0,148(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// stfs f0,152(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lwz r31,2888(r28)
	r31.u64 = PPC_LOAD_U32(r28.u32 + 2888);
	// lfs f0,14040(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14040);
	f0.f64 = double(temp.f32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// fmuls f31,f13,f0
	f31.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f30,f12,f0
	f30.f64 = double(float(ctx.f12.f64 * f0.f64));
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f29,f13,f0
	f29.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f0,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f0,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// beq cr6,0x820a22c8
	if (cr6.getEQ()) goto loc_820A22C8;
	// li r11,1
	r11.s64 = 1;
	// stw r11,2892(r28)
	PPC_STORE_U32(r28.u32 + 2892, r11.u32);
	// b 0x820a22d8
	goto loc_820A22D8;
loc_820A22C8:
	// li r4,86
	ctx.r4.s64 = 86;
	// li r3,202
	ctx.r3.s64 = 202;
	// bl 0x820e2be8
	sub_820E2BE8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_820A22D8:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a23d4
	if (cr6.getEQ()) goto loc_820A23D4;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r10,r27,17,0,14
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 17) & 0xFFFE0000;
	// li r9,-1
	ctx.r9.s64 = -1;
	// rlwinm r11,r11,0,15,13
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFDFFFF;
	// li r8,1
	ctx.r8.s64 = 1;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// addi r7,r1,160
	ctx.r7.s64 = ctx.r1.s64 + 160;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// sth r9,130(r31)
	PPC_STORE_U16(r31.u32 + 130, ctx.r9.u16);
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820a1800
	sub_820A1800(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a23d4
	if (cr6.getEQ()) goto loc_820A23D4;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// li r10,60
	ctx.r10.s64 = 60;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r9,r9,128
	ctx.r9.u64 = ctx.r9.u64 | 128;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r9,r9,32
	ctx.r9.u64 = ctx.r9.u64 | 32;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lfs f0,92(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	f0.f64 = double(temp.f32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f0,176(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 176, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,180(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 180, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f31,16(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 16, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f30,20(r11)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r11.u32 + 20, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f29,24(r11)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r11.u32 + 24, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stw r10,188(r11)
	PPC_STORE_U32(r11.u32 + 188, ctx.r10.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// addi r5,r11,152
	ctx.r5.s64 = r11.s64 + 152;
	// lwz r10,152(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 152);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a23a0
	if (!cr6.getEQ()) goto loc_820A23A0;
	// li r8,2758
	ctx.r8.s64 = 2758;
	// b 0x820a23b4
	goto loc_820A23B4;
loc_820A23A0:
	// lwz r10,156(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 156);
	// addi r5,r11,156
	ctx.r5.s64 = r11.s64 + 156;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a23d4
	if (!cr6.getEQ()) goto loc_820A23D4;
	// li r8,2760
	ctx.r8.s64 = 2760;
loc_820A23B4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r4,1
	ctx.r4.s64 = 1;
	// addi r7,r11,13992
	ctx.r7.s64 = r11.s64 + 13992;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
loc_820A23D4:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// lfd f29,-88(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -88);
	// lfd f30,-80(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// lfd f31,-72(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_820A23F0"))) PPC_WEAK_FUNC(sub_820A23F0);
PPC_FUNC_IMPL(__imp__sub_820A23F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f30,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, f30.u64);
	// stfd f31,-32(r1)
	PPC_STORE_U64(ctx.r1.u32 + -32, f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lfs f0,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// cmpwi cr6,r4,23
	cr6.compare<int32_t>(ctx.r4.s32, 23, xer);
	// stfs f0,4(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// lfs f0,4(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// lfs f0,8(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,12(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
	// lfs f13,0(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,0(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 0);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// stfs f0,16(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 16, temp.u32);
	// lfs f13,4(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,4(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 4);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// stfs f0,20(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// lfs f11,8(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,8(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// fmuls f11,f13,f13
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// lfs f0,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	f0.f64 = double(temp.f32);
	// stfs f12,24(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r31.u32 + 24, temp.u32);
	// lfs f30,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f30.f64 = double(temp.f32);
	// fmr f10,f12
	ctx.f10.f64 = ctx.f12.f64;
	// fmadds f11,f0,f0,f11
	ctx.f11.f64 = double(float(f0.f64 * f0.f64 + ctx.f11.f64));
	// fmadds f12,f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + ctx.f11.f64));
	// fsqrts f31,f12
	f31.f64 = double(float(sqrt(ctx.f12.f64)));
	// fdivs f12,f30,f31
	ctx.f12.f64 = double(float(f30.f64 / f31.f64));
	// fmuls f0,f0,f12
	f0.f64 = double(float(f0.f64 * ctx.f12.f64));
	// stfs f0,16(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 16, temp.u32);
	// fmuls f0,f13,f12
	f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f0,20(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// fmuls f0,f10,f12
	f0.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// stfs f0,24(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 24, temp.u32);
	// bne cr6,0x820a24ac
	if (!cr6.getEQ()) goto loc_820A24AC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,12020(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12020);
	f0.f64 = double(temp.f32);
	// b 0x820a24b4
	goto loc_820A24B4;
loc_820A24AC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,14056(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14056);
	f0.f64 = double(temp.f32);
loc_820A24B4:
	// fcmpu cr6,f31,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f0.f64);
	// ble cr6,0x820a24c0
	if (!cr6.getGT()) goto loc_820A24C0;
	// fmr f31,f0
	f31.f64 = f0.f64;
loc_820A24C0:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f31,28(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 28, temp.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r4,1(r31)
	PPC_STORE_U8(r31.u32 + 1, ctx.r4.u8);
	// lfs f0,14052(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14052);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f31,f0
	cr6.compare(f31.f64, f0.f64);
	// stb r10,0(r31)
	PPC_STORE_U8(r31.u32 + 0, ctx.r10.u8);
	// bge cr6,0x820a24e4
	if (!cr6.getLT()) goto loc_820A24E4;
	// fmr f31,f0
	f31.f64 = f0.f64;
loc_820A24E4:
	// cmpwi cr6,r4,22
	cr6.compare<int32_t>(ctx.r4.s32, 22, xer);
	// bne cr6,0x820a2570
	if (!cr6.getEQ()) goto loc_820A2570;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,12904(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12904);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f0,f31,f0
	f0.f64 = double(float(f31.f64 * f0.f64));
	// stfs f0,36(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 36, temp.u32);
	// lfs f13,12900(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12900);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f13,f31,f13
	ctx.f13.f64 = double(float(f31.f64 * ctx.f13.f64));
	// stfs f13,32(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 32, temp.u32);
	// lfs f13,14048(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14048);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820a2520
	if (!cr6.getGT()) goto loc_820A2520;
	// stfs f13,36(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 36, temp.u32);
loc_820A2520:
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f0,14016(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14016);
	f0.f64 = double(temp.f32);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// lfs f13,14028(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14028);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// lfs f13,14044(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14044);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f0,f12,f0,f13
	f0.f64 = double(float(-(ctx.f12.f64 * f0.f64 - ctx.f13.f64)));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// b 0x820a261c
	goto loc_820A261C;
loc_820A2570:
	// cmpwi cr6,r4,23
	cr6.compare<int32_t>(ctx.r4.s32, 23, xer);
	// bne cr6,0x820a25ac
	if (!cr6.getEQ()) goto loc_820A25AC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f31,36(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 36, temp.u32);
	// lfs f0,3060(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3060);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f0,f31,f0
	f0.f64 = double(float(f31.f64 * f0.f64));
	// stfs f0,32(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 32, temp.u32);
	// lfs f0,14048(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14048);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f31,f0
	cr6.compare(f31.f64, f0.f64);
	// ble cr6,0x820a25a0
	if (!cr6.getGT()) goto loc_820A25A0;
	// stfs f0,36(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 36, temp.u32);
loc_820A25A0:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// b 0x820a261c
	goto loc_820A261C;
loc_820A25AC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,12892(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12892);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f0,f31,f0
	f0.f64 = double(float(f31.f64 * f0.f64));
	// stfs f0,32(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 32, temp.u32);
	// stfs f0,36(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 36, temp.u32);
	// lfs f13,14048(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14048);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820a25d4
	if (!cr6.getGT()) goto loc_820A25D4;
	// stfs f13,36(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 36, temp.u32);
loc_820A25D4:
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f12,32(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f0,3060(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3060);
	f0.f64 = double(temp.f32);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f11,f13
	ctx.f11.f64 = double(float(ctx.f13.f64));
	// lfs f13,14028(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14028);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmsubs f0,f13,f0,f30
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 - f30.f64));
	// fmuls f0,f0,f12
	f0.f64 = double(float(f0.f64 * ctx.f12.f64));
loc_820A261C:
	// lfs f13,28(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,40(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 40, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820a2634
	if (cr6.getLT()) goto loc_820A2634;
	// li r11,-1
	r11.s64 = -1;
	// stb r11,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r11.u8);
loc_820A2634:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f30,-40(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// lfd f31,-32(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A2658"))) PPC_WEAK_FUNC(sub_820A2658);
PPC_FUNC_IMPL(__imp__sub_820A2658) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed120
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r28,-32014
	r28.s64 = -2098069504;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mulli r25,r30,936
	r25.s64 = r30.s64 * 936;
	// lwz r11,-1364(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -1364);
	// add r11,r25,r11
	r11.u64 = r25.u64 + r11.u64;
	// addi r31,r11,2344
	r31.s64 = r11.s64 + 2344;
	// bl 0x8210d820
	sub_8210D820(ctx, base);
	// lfs f10,24(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// addi r29,r31,924
	r29.s64 = r31.s64 + 924;
	// lfs f0,928(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 928);
	f0.f64 = double(temp.f32);
	// fmuls f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 * f0.f64));
	// lfs f13,932(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 932);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,40(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 40);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,924(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 924);
	ctx.f12.f64 = double(temp.f32);
	// lfs f9,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	ctx.f8.f64 = double(temp.f32);
	// lfs f11,756(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 756);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f0,f10,f13,f0
	f0.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + f0.f64));
	// fmadds f0,f9,f12,f0
	f0.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 + f0.f64));
	// fadds f0,f0,f8
	f0.f64 = double(float(f0.f64 + ctx.f8.f64));
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// fcmpu cr6,f0,f11
	cr6.compare(f0.f64, ctx.f11.f64);
	// blt cr6,0x820a289c
	if (cr6.getLT()) goto loc_820A289C;
	// lwz r11,-1364(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -1364);
	// addi r26,r31,744
	r26.s64 = r31.s64 + 744;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// add r11,r25,r11
	r11.u64 = r25.u64 + r11.u64;
	// addi r3,r31,484
	ctx.r3.s64 = r31.s64 + 484;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// lwz r4,2344(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// bl 0x820a23f0
	sub_820A23F0(ctx, base);
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a2770
	if (cr6.getEQ()) goto loc_820A2770;
	// bl 0x8215fc88
	sub_8215FC88(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// bne cr6,0x820a2770
	if (!cr6.getEQ()) goto loc_820A2770;
	// bl 0x820ca520
	sub_820CA520(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a2770
	if (cr6.getEQ()) goto loc_820A2770;
	// lfs f0,0(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r26.u32 + 0);
	f0.f64 = double(temp.f32);
	// lwz r11,-1364(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -1364);
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// cntlzw r10,r30
	ctx.r10.u64 = r30.u32 == 0 ? 32 : __builtin_clz(r30.u32);
	// lfs f0,748(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 748);
	f0.f64 = double(temp.f32);
	// add r11,r25,r11
	r11.u64 = r25.u64 + r11.u64;
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// addi r24,r1,96
	r24.s64 = ctx.r1.s64 + 96;
	// lfs f0,752(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 752);
	f0.f64 = double(temp.f32);
	// rlwinm r23,r10,27,31,31
	r23.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// addi r22,r1,80
	r22.s64 = ctx.r1.s64 + 80;
	// lfs f0,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,928(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 928);
	f0.f64 = double(temp.f32);
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f0,932(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 932);
	f0.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lwz r27,2344(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// bl 0x820ca338
	sub_820CA338(ctx, base);
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r6,r23
	ctx.r6.u64 = r23.u64;
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// bl 0x8216f978
	sub_8216F978(ctx, base);
loc_820A2770:
	// lwz r11,-1364(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -1364);
	// lwz r11,428(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a289c
	if (cr6.getEQ()) goto loc_820A289C;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820a289c
	if (!cr6.getGT()) goto loc_820A289C;
	// lwz r11,-1364(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -1364);
	// addi r10,r30,696
	ctx.r10.s64 = r30.s64 + 696;
	// lfs f0,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// lfs f13,928(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 928);
	ctx.f13.f64 = double(temp.f32);
	// addi r4,r1,100
	ctx.r4.s64 = ctx.r1.s64 + 100;
	// lfs f12,932(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 932);
	ctx.f12.f64 = double(temp.f32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lwz r9,428(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// lwz r24,8(r9)
	r24.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// rlwinm r9,r30,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// add r8,r30,r9
	ctx.r8.u64 = r30.u64 + ctx.r9.u64;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r27,r8,2,0,29
	r27.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r27,r11
	ctx.r10.u64 = r27.u64 + r11.u64;
	// lfs f11,8344(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8344);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f0,f0,f11
	f0.f64 = double(float(f0.f64 - ctx.f11.f64));
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f0,8348(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8348);
	f0.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfsx f0,r9,r11
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	f0.f64 = double(temp.f32);
	// fsubs f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 - f0.f64));
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// bl 0x820d3710
	sub_820D3710(ctx, base);
	// lfs f13,0(r26)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r26.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r5,r1,88
	ctx.r5.s64 = ctx.r1.s64 + 88;
	// lfs f12,928(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 928);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f11,748(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 748);
	ctx.f11.f64 = double(temp.f32);
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// fsubs f13,f12,f11
	ctx.f13.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f0,932(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 932);
	f0.f64 = double(temp.f32);
	// lfs f13,752(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 752);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// bl 0x820d3710
	sub_820D3710(ctx, base);
	// lfs f11,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// lfs f0,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	f0.f64 = double(temp.f32);
	// lfs f13,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f10.f64 = double(temp.f32);
	// fmadds f0,f0,f13,f12
	f0.f64 = double(float(f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// fmadds f1,f11,f10,f0
	ctx.f1.f64 = double(float(ctx.f11.f64 * ctx.f10.f64 + f0.f64));
	// bl 0x8210acb8
	sub_8210ACB8(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,13972(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13972);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// bgt cr6,0x820a289c
	if (cr6.getGT()) goto loc_820A289C;
	// lwz r11,-1364(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -1364);
	// mulli r9,r30,44
	ctx.r9.s64 = r30.s64 * 44;
	// add r8,r25,r11
	ctx.r8.u64 = r25.u64 + r11.u64;
	// add r10,r27,r11
	ctx.r10.u64 = r27.u64 + r11.u64;
	// add r11,r9,r24
	r11.u64 = ctx.r9.u64 + r24.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r10,8344
	ctx.r5.s64 = ctx.r10.s64 + 8344;
	// addi r3,r11,384
	ctx.r3.s64 = r11.s64 + 384;
	// lwz r4,2344(r8)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r8.u32 + 2344);
	// bl 0x820a23f0
	sub_820A23F0(ctx, base);
loc_820A289C:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed170
	return;
}

__attribute__((alias("__imp__sub_820A28A8"))) PPC_WEAK_FUNC(sub_820A28A8);
PPC_FUNC_IMPL(__imp__sub_820A28A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f21{};
	PPCRegister f22{};
	PPCRegister f23{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// addi r12,r1,-72
	r12.s64 = ctx.r1.s64 + -72;
	// bl 0x823ed52c
	// stwu r1,-912(r1)
	ea = -912 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// lbz r11,0(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// cmplwi cr6,r11,128
	cr6.compare<uint32_t>(r11.u32, 128, xer);
	// bge cr6,0x820a34b4
	if (!cr6.getLT()) goto loc_820A34B4;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r28,0
	r28.s64 = 0;
	// lfs f31,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// li r11,255
	r11.s64 = 255;
	// stfs f31,304(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// sth r28,316(r1)
	PPC_STORE_U16(ctx.r1.u32 + 316, r28.u16);
	// stfs f31,308(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// stfs f31,312(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// stfs f31,320(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// stfs f31,324(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// stb r11,328(r1)
	PPC_STORE_U8(ctx.r1.u32 + 328, r11.u8);
	// stb r11,329(r1)
	PPC_STORE_U8(ctx.r1.u32 + 329, r11.u8);
	// stb r11,330(r1)
	PPC_STORE_U8(ctx.r1.u32 + 330, r11.u8);
	// stb r11,331(r1)
	PPC_STORE_U8(ctx.r1.u32 + 331, r11.u8);
	// bl 0x820b3dc0
	sub_820B3DC0(ctx, base);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lfs f30,36(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 36);
	f30.f64 = double(temp.f32);
	// lfs f29,40(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 40);
	f29.f64 = double(temp.f32);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// addi r26,r11,28936
	r26.s64 = r11.s64 + 28936;
	// fmr f25,f31
	f25.f64 = f31.f64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f24,f31
	f24.f64 = f31.f64;
	// fmr f23,f31
	f23.f64 = f31.f64;
	// lfs f26,14068(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14068);
	f26.f64 = double(temp.f32);
	// bl 0x8210d820
	sub_8210D820(ctx, base);
	// lbz r11,1(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 1);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,22
	cr6.compare<int32_t>(r11.s32, 22, xer);
	// lfs f27,2952(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2952);
	f27.f64 = double(temp.f32);
	// bne cr6,0x820a2968
	if (!cr6.getEQ()) goto loc_820A2968;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// addi r26,r11,26536
	r26.s64 = r11.s64 + 26536;
	// lfs f28,2960(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2960);
	f28.f64 = double(temp.f32);
	// b 0x820a2a24
	goto loc_820A2A24;
loc_820A2968:
	// cmpwi cr6,r11,23
	cr6.compare<int32_t>(r11.s32, 23, xer);
	// bne cr6,0x820a2a1c
	if (!cr6.getEQ()) goto loc_820A2A1C;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// fmr f28,f27
	ctx.fpscr.disableFlushMode();
	f28.f64 = f27.f64;
	// addi r26,r11,26536
	r26.s64 = r11.s64 + 26536;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,20971
	ctx.r10.s64 = 1374355456;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// ori r31,r10,34079
	r31.u64 = ctx.r10.u64 | 34079;
	// mulhwu r10,r11,r31
	ctx.r10.u64 = (uint64_t(r11.u32) * uint64_t(r31.u32)) >> 32;
	// rlwinm r10,r10,28,4,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0xFFFFFFF;
	// mulli r10,r10,50
	ctx.r10.s64 = ctx.r10.s64 * 50;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r11,r11,150
	r11.s64 = r11.s64 + 150;
	// stb r11,331(r1)
	PPC_STORE_U8(ctx.r1.u32 + 331, r11.u8);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-13108
	ctx.r10.s64 = -859045888;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// ori r10,r10,52429
	ctx.r10.u64 = ctx.r10.u64 | 52429;
	// mulhwu r10,r11,r10
	ctx.r10.u64 = (uint64_t(r11.u32) * uint64_t(ctx.r10.u32)) >> 32;
	// rlwinm r10,r10,30,2,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0x3FFFFFFF;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// subf. r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x820a2a24
	if (!cr0.getEQ()) goto loc_820A2A24;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// mulhwu r10,r11,r31
	ctx.r10.u64 = (uint64_t(r11.u32) * uint64_t(r31.u32)) >> 32;
	// rlwinm r10,r10,27,5,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x7FFFFFF;
	// mulli r10,r10,100
	ctx.r10.s64 = ctx.r10.s64 * 100;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// subfic r11,r11,255
	xer.ca = r11.u32 <= 255;
	r11.s64 = 255 - r11.s64;
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// stb r11,329(r1)
	PPC_STORE_U8(ctx.r1.u32 + 329, r11.u8);
	// stb r11,328(r1)
	PPC_STORE_U8(ctx.r1.u32 + 328, r11.u8);
	// b 0x820a2a24
	goto loc_820A2A24;
loc_820A2A1C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f28,3112(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3112);
	f28.f64 = double(temp.f32);
loc_820A2A24:
	// lfs f9,4(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fcmpu cr6,f29,f31
	cr6.compare(f29.f64, f31.f64);
	// lfs f11,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,12(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// stfs f9,232(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// stfs f11,236(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// stfs f10,240(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// ble cr6,0x820a2a6c
	if (!cr6.getGT()) goto loc_820A2A6C;
	// lfs f0,16(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 16);
	f0.f64 = double(temp.f32);
	// lfs f13,20(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f9,f0,f29,f9
	ctx.f9.f64 = double(float(f0.f64 * f29.f64 + ctx.f9.f64));
	// lfs f12,24(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f11,f13,f29,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 * f29.f64 + ctx.f11.f64));
	// fmadds f10,f12,f29,f10
	ctx.f10.f64 = double(float(ctx.f12.f64 * f29.f64 + ctx.f10.f64));
	// stfs f9,232(r1)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// stfs f11,236(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// stfs f10,240(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// b 0x820a2a74
	goto loc_820A2A74;
loc_820A2A6C:
	// fadds f30,f29,f30
	ctx.fpscr.disableFlushMode();
	f30.f64 = double(float(f29.f64 + f30.f64));
	// fmr f29,f31
	f29.f64 = f31.f64;
loc_820A2A74:
	// fadds f13,f29,f30
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(f29.f64 + f30.f64));
	// lfs f0,28(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 28);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820a2a88
	if (!cr6.getGT()) goto loc_820A2A88;
	// fsubs f30,f0,f29
	f30.f64 = double(float(f0.f64 - f29.f64));
loc_820A2A88:
	// lfs f0,20(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	f0.f64 = double(temp.f32);
	// fmadds f11,f0,f30,f11
	ctx.f11.f64 = double(float(f0.f64 * f30.f64 + ctx.f11.f64));
	// lfs f8,4(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// lfs f13,24(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 24);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f10,f13,f30,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * f30.f64 + ctx.f10.f64));
	// lfs f7,8(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// lfs f12,16(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f9,f12,f30,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 * f30.f64 + ctx.f9.f64));
	// fsubs f8,f8,f11
	ctx.f8.f64 = double(float(ctx.f8.f64 - ctx.f11.f64));
	// fsubs f7,f7,f10
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// fmuls f8,f8,f13
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f13.f64));
	// fmsubs f8,f7,f0,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * f0.f64 - ctx.f8.f64));
	// stfs f8,216(r1)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// lfs f7,8(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 8);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f10,f7,f10
	ctx.f10.f64 = double(float(ctx.f7.f64 - ctx.f10.f64));
	// lfs f7,0(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fsubs f7,f7,f9
	ctx.f7.f64 = double(float(ctx.f7.f64 - ctx.f9.f64));
	// fcmpu cr6,f8,f31
	cr6.compare(ctx.f8.f64, f31.f64);
	// fmuls f10,f10,f12
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// fmsubs f13,f7,f13,f10
	ctx.f13.f64 = double(float(ctx.f7.f64 * ctx.f13.f64 - ctx.f10.f64));
	// stfs f13,220(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// lfs f10,0(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// lfs f9,4(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f11,f9,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 - ctx.f11.f64));
	// fmuls f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fmsubs f0,f11,f12,f0
	f0.f64 = double(float(ctx.f11.f64 * ctx.f12.f64 - f0.f64));
	// stfs f0,224(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// bne cr6,0x820a2b1c
	if (!cr6.getEQ()) goto loc_820A2B1C;
	// fcmpu cr6,f13,f31
	cr6.compare(ctx.f13.f64, f31.f64);
	// bne cr6,0x820a2b1c
	if (!cr6.getEQ()) goto loc_820A2B1C;
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// bne cr6,0x820a2b1c
	if (!cr6.getEQ()) goto loc_820A2B1C;
	// fmr f0,f31
	f0.f64 = f31.f64;
	// fmr f13,f28
	ctx.f13.f64 = f28.f64;
	// fmr f12,f31
	ctx.f12.f64 = f31.f64;
	// b 0x820a2b44
	goto loc_820A2B44;
loc_820A2B1C:
	// addi r5,r1,224
	ctx.r5.s64 = ctx.r1.s64 + 224;
	// addi r4,r1,220
	ctx.r4.s64 = ctx.r1.s64 + 220;
	// addi r3,r1,216
	ctx.r3.s64 = ctx.r1.s64 + 216;
	// bl 0x820d3710
	sub_820D3710(ctx, base);
	// lfs f0,216(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	f0.f64 = double(temp.f32);
	// lfs f13,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// lfs f12,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * f28.f64));
	// fmuls f12,f12,f28
	ctx.f12.f64 = double(float(ctx.f12.f64 * f28.f64));
loc_820A2B44:
	// lfs f9,16(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 16);
	ctx.f9.f64 = double(temp.f32);
	// addi r5,r1,256
	ctx.r5.s64 = ctx.r1.s64 + 256;
	// lfs f11,20(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f6,f9,f12
	ctx.f6.f64 = double(float(ctx.f9.f64 * ctx.f12.f64));
	// lfs f10,24(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f8,f11,f0
	ctx.f8.f64 = double(float(ctx.f11.f64 * f0.f64));
	// fmuls f7,f10,f13
	ctx.f7.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// stfs f0,216(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// stfs f12,224(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// addi r4,r1,252
	ctx.r4.s64 = ctx.r1.s64 + 252;
	// addi r3,r1,248
	ctx.r3.s64 = ctx.r1.s64 + 248;
	// stfs f13,220(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// fmsubs f0,f10,f0,f6
	f0.f64 = double(float(ctx.f10.f64 * f0.f64 - ctx.f6.f64));
	// stfs f0,252(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// fmsubs f0,f9,f13,f8
	f0.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 - ctx.f8.f64));
	// stfs f0,256(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// fmsubs f12,f11,f12,f7
	ctx.f12.f64 = double(float(ctx.f11.f64 * ctx.f12.f64 - ctx.f7.f64));
	// stfs f12,248(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// bl 0x820d3710
	sub_820D3710(ctx, base);
	// lfs f0,248(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,248(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// lfs f0,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	f0.f64 = double(temp.f32);
	// addi r4,r1,624
	ctx.r4.s64 = ctx.r1.s64 + 624;
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,252(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// lfs f0,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	f0.f64 = double(temp.f32);
	// addi r3,r1,232
	ctx.r3.s64 = ctx.r1.s64 + 232;
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,256(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// bl 0x8210c818
	sub_8210C818(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,624
	ctx.r4.s64 = ctx.r1.s64 + 624;
	// lfs f29,13964(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13964);
	f29.f64 = double(temp.f32);
	// fmr f1,f29
	ctx.f1.f64 = f29.f64;
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// addi r4,r1,624
	ctx.r4.s64 = ctx.r1.s64 + 624;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8210c778
	sub_8210C778(ctx, base);
	// addi r4,r1,688
	ctx.r4.s64 = ctx.r1.s64 + 688;
	// addi r3,r1,624
	ctx.r3.s64 = ctx.r1.s64 + 624;
	// bl 0x8210be08
	sub_8210BE08(ctx, base);
	// addi r10,r1,336
	ctx.r10.s64 = ctx.r1.s64 + 336;
	// addi r11,r1,304
	r11.s64 = ctx.r1.s64 + 304;
	// li r9,7
	ctx.r9.s64 = 7;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_820A2BFC:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x820a2bfc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820A2BFC;
	// addi r10,r1,364
	ctx.r10.s64 = ctx.r1.s64 + 364;
	// addi r11,r1,304
	r11.s64 = ctx.r1.s64 + 304;
	// li r9,7
	ctx.r9.s64 = 7;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_820A2C20:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x820a2c20
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820A2C20;
	// addi r10,r1,392
	ctx.r10.s64 = ctx.r1.s64 + 392;
	// addi r11,r1,304
	r11.s64 = ctx.r1.s64 + 304;
	// li r9,7
	ctx.r9.s64 = 7;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_820A2C44:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x820a2c44
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820A2C44;
	// addi r10,r1,420
	ctx.r10.s64 = ctx.r1.s64 + 420;
	// addi r11,r1,304
	r11.s64 = ctx.r1.s64 + 304;
	// li r9,7
	ctx.r9.s64 = 7;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_820A2C68:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x820a2c68
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820A2C68;
	// lbz r11,1(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 1);
	// extsb r8,r11
	ctx.r8.s64 = r11.s8;
	// cmpwi cr6,r8,22
	cr6.compare<int32_t>(ctx.r8.s32, 22, xer);
	// bne cr6,0x820a2d1c
	if (!cr6.getEQ()) goto loc_820A2D1C;
	// addi r10,r1,448
	ctx.r10.s64 = ctx.r1.s64 + 448;
	// addi r11,r1,304
	r11.s64 = ctx.r1.s64 + 304;
	// li r9,7
	ctx.r9.s64 = 7;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_820A2C9C:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x820a2c9c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820A2C9C;
	// addi r10,r1,476
	ctx.r10.s64 = ctx.r1.s64 + 476;
	// addi r11,r1,304
	r11.s64 = ctx.r1.s64 + 304;
	// li r9,7
	ctx.r9.s64 = 7;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_820A2CC0:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x820a2cc0
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820A2CC0;
	// addi r10,r1,504
	ctx.r10.s64 = ctx.r1.s64 + 504;
	// addi r11,r1,304
	r11.s64 = ctx.r1.s64 + 304;
	// li r9,7
	ctx.r9.s64 = 7;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_820A2CE4:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x820a2ce4
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820A2CE4;
	// addi r10,r1,532
	ctx.r10.s64 = ctx.r1.s64 + 532;
	// addi r11,r1,304
	r11.s64 = ctx.r1.s64 + 304;
	// li r9,7
	ctx.r9.s64 = 7;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_820A2D08:
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x820a2d08
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820A2D08;
loc_820A2D1C:
	// cmpwi cr6,r8,23
	cr6.compare<int32_t>(ctx.r8.s32, 23, xer);
	// bne cr6,0x820a2e10
	if (!cr6.getEQ()) goto loc_820A2E10;
	// lfs f0,16(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 16);
	f0.f64 = double(temp.f32);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// lfs f11,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f11.f64 = double(temp.f32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// fmadds f0,f0,f30,f11
	f0.f64 = double(float(f0.f64 * f30.f64 + ctx.f11.f64));
	// stfs f0,176(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// lfs f13,20(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	f0.f64 = double(temp.f32);
	// fmadds f0,f30,f13,f0
	f0.f64 = double(float(f30.f64 * ctx.f13.f64 + f0.f64));
	// stfs f0,180(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// lfs f12,24(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	f0.f64 = double(temp.f32);
	// fmadds f0,f12,f30,f0
	f0.f64 = double(float(ctx.f12.f64 * f30.f64 + f0.f64));
	// stfs f0,184(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// bl 0x8210b6e0
	sub_8210B6E0(ctx, base);
	// fmuls f0,f28,f29
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f28.f64 * f29.f64));
	// stfs f0,292(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// addi r5,r1,264
	ctx.r5.s64 = ctx.r1.s64 + 264;
	// stfs f0,288(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// addi r3,r1,288
	ctx.r3.s64 = ctx.r1.s64 + 288;
	// lfs f0,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	f0.f64 = double(temp.f32);
	// fneg f1,f0
	ctx.f1.u64 = f0.u64 ^ 0x8000000000000000;
	// bl 0x8210d738
	sub_8210D738(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,264(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	f0.f64 = double(temp.f32);
	// lfs f13,3060(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3060);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820a2dcc
	if (!cr6.getLT()) goto loc_820A2DCC;
	// lfs f13,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 * ctx.f13.f64));
	// lfs f11,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f0,f12
	ctx.f12.f64 = double(float(f0.f64 * ctx.f12.f64));
	// fmuls f11,f0,f11
	ctx.f11.f64 = double(float(f0.f64 * ctx.f11.f64));
	// lfs f0,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,176(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// fmuls f13,f12,f0
	ctx.f13.f64 = double(float(ctx.f12.f64 * f0.f64));
	// stfs f13,180(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// fmuls f0,f11,f0
	f0.f64 = double(float(ctx.f11.f64 * f0.f64));
	// stfs f0,184(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
loc_820A2DCC:
	// addi r31,r1,176
	r31.s64 = ctx.r1.s64 + 176;
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8210b6e0
	sub_8210B6E0(ctx, base);
	// lfs f8,232(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f8.f64 = double(temp.f32);
	// lfs f0,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	f0.f64 = double(temp.f32);
	// lfs f10,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f0,f0,f8
	f0.f64 = double(float(f0.f64 - ctx.f8.f64));
	// lfs f13,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f13.f64 = double(temp.f32);
	// lfs f9,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// lfs f12,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// fmuls f7,f0,f27
	ctx.f7.f64 = double(float(f0.f64 * f27.f64));
	// fmuls f6,f13,f27
	ctx.f6.f64 = double(float(ctx.f13.f64 * f27.f64));
	// fmuls f5,f12,f27
	ctx.f5.f64 = double(float(ctx.f12.f64 * f27.f64));
	// b 0x820a2e38
	goto loc_820A2E38;
loc_820A2E10:
	// fmuls f0,f30,f27
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f30.f64 * f27.f64));
	// lfs f13,16(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,20(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,24(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 24);
	ctx.f11.f64 = double(temp.f32);
	// lfs f9,240(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 240);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,236(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 236);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,232(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 232);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f7,f13,f0
	ctx.f7.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fmuls f6,f0,f12
	ctx.f6.f64 = double(float(f0.f64 * ctx.f12.f64));
	// fmuls f5,f11,f0
	ctx.f5.f64 = double(float(ctx.f11.f64 * f0.f64));
loc_820A2E38:
	// lfs f4,216(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f4.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f3,220(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 220);
	ctx.f3.f64 = double(temp.f32);
	// fneg f1,f4
	ctx.f1.u64 = ctx.f4.u64 ^ 0x8000000000000000;
	// lfs f2,224(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 224);
	ctx.f2.f64 = double(temp.f32);
	// fneg f29,f3
	f29.u64 = ctx.f3.u64 ^ 0x8000000000000000;
	// fneg f28,f2
	f28.u64 = ctx.f2.u64 ^ 0x8000000000000000;
	// stfs f31,356(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// fctiwz f0,f4
	f0.s64 = (ctx.f4.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f4.f64));
	// stfd f0,264(r1)
	PPC_STORE_U64(ctx.r1.u32 + 264, f0.u64);
	// fctiwz f0,f3
	f0.s64 = (ctx.f3.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f3.f64));
	// stfd f0,288(r1)
	PPC_STORE_U64(ctx.r1.u32 + 288, f0.u64);
	// fctiwz f0,f2
	f0.s64 = (ctx.f2.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f2.f64));
	// stfd f0,280(r1)
	PPC_STORE_U64(ctx.r1.u32 + 280, f0.u64);
	// lfs f13,14064(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14064);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f12,f4,f13
	ctx.f12.f64 = double(float(ctx.f4.f64 * ctx.f13.f64));
	// lhz r10,294(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 294);
	// fmuls f11,f3,f13
	ctx.f11.f64 = double(float(ctx.f3.f64 * ctx.f13.f64));
	// stfs f31,380(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// stfs f31,384(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// fctiwz f1,f1
	ctx.f1.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// stfd f1,272(r1)
	PPC_STORE_U64(ctx.r1.u32 + 272, ctx.f1.u64);
	// fctiwz f1,f29
	ctx.f1.s64 = (f29.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f29.f64));
	// stfd f1,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, ctx.f1.u64);
	// fctiwz f1,f28
	ctx.f1.s64 = (f28.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f28.f64));
	// stfd f1,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, ctx.f1.u64);
	// lfs f0,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// lhz r11,270(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 270);
	// stfs f0,352(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// fadds f1,f12,f7
	ctx.f1.f64 = double(float(ctx.f12.f64 + ctx.f7.f64));
	// fadds f29,f11,f6
	f29.f64 = double(float(ctx.f11.f64 + ctx.f6.f64));
	// fctiwz f1,f1
	ctx.f1.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// lhz r9,286(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 286);
	// stfd f1,280(r1)
	PPC_STORE_U64(ctx.r1.u32 + 280, ctx.f1.u64);
	// fctiwz f1,f29
	ctx.f1.s64 = (f29.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f29.f64));
	// stfd f1,264(r1)
	PPC_STORE_U64(ctx.r1.u32 + 264, ctx.f1.u64);
	// extsh r9,r9
	ctx.r9.s64 = ctx.r9.s16;
	// lhz r8,278(r1)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r1.u32 + 278);
	// lhz r7,198(r1)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r1.u32 + 198);
	// lhz r6,206(r1)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r1.u32 + 206);
	// std r11,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, r11.u64);
	// extsh r11,r8
	r11.s64 = ctx.r8.s16;
	// std r10,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, ctx.r10.u64);
	// extsh r10,r7
	ctx.r10.s64 = ctx.r7.s16;
	// std r9,272(r1)
	PPC_STORE_U64(ctx.r1.u32 + 272, ctx.r9.u64);
	// extsh r8,r6
	ctx.r8.s64 = ctx.r6.s16;
	// std r11,288(r1)
	PPC_STORE_U64(ctx.r1.u32 + 288, r11.u64);
	// lfd f27,288(r1)
	f27.u64 = PPC_LOAD_U64(ctx.r1.u32 + 288);
	// std r10,208(r1)
	PPC_STORE_U64(ctx.r1.u32 + 208, ctx.r10.u64);
	// fcfid f27,f27
	f27.f64 = double(f27.s64);
	// std r8,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, ctx.r8.u64);
	// lfd f21,176(r1)
	f21.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// fcfid f21,f21
	f21.f64 = double(f21.s64);
	// lhz r10,270(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 270);
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// lhz r11,286(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 286);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// lfd f1,200(r1)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r1.u32 + 200);
	// std r11,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, r11.u64);
	// lfd f29,192(r1)
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fcfid f1,f1
	ctx.f1.f64 = double(ctx.f1.s64);
	// lfd f28,272(r1)
	f28.u64 = PPC_LOAD_U64(ctx.r1.u32 + 272);
	// fcfid f29,f29
	f29.f64 = double(f29.s64);
	// fcfid f28,f28
	f28.f64 = double(f28.s64);
	// std r10,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, ctx.r10.u64);
	// lfd f22,208(r1)
	f22.u64 = PPC_LOAD_U64(ctx.r1.u32 + 208);
	// fcfid f22,f22
	f22.f64 = double(f22.s64);
	// frsp f1,f1
	ctx.f1.f64 = double(float(ctx.f1.f64));
	// stfs f1,336(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// frsp f1,f29
	ctx.f1.f64 = double(float(f29.f64));
	// stfs f1,340(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// frsp f1,f28
	ctx.f1.f64 = double(float(f28.f64));
	// stfs f1,344(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// frsp f1,f27
	ctx.f1.f64 = double(float(f27.f64));
	// stfs f1,364(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// frsp f1,f22
	ctx.f1.f64 = double(float(f22.f64));
	// stfs f1,368(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// frsp f1,f21
	ctx.f1.f64 = double(float(f21.f64));
	// stfs f1,372(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// fsubs f12,f7,f12
	ctx.f12.f64 = double(float(ctx.f7.f64 - ctx.f12.f64));
	// lfd f1,200(r1)
	ctx.f1.u64 = PPC_LOAD_U64(ctx.r1.u32 + 200);
	// fsubs f11,f6,f11
	ctx.f11.f64 = double(float(ctx.f6.f64 - ctx.f11.f64));
	// fcfid f1,f1
	ctx.f1.f64 = double(ctx.f1.s64);
	// lfd f29,192(r1)
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fmuls f13,f2,f13
	ctx.f13.f64 = double(float(ctx.f2.f64 * ctx.f13.f64));
	// lbz r11,1(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 1);
	// stfs f0,408(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// cmplwi cr6,r11,22
	cr6.compare<uint32_t>(r11.u32, 22, xer);
	// stfs f0,412(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// stfs f31,436(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// stfs f0,440(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// fctiwz f12,f12
	ctx.f12.s64 = (ctx.f12.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f12.f64));
	// stfd f12,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, ctx.f12.u64);
	// fctiwz f12,f11
	ctx.f12.s64 = (ctx.f11.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f11.f64));
	// stfd f12,208(r1)
	PPC_STORE_U64(ctx.r1.u32 + 208, ctx.f12.u64);
	// frsp f1,f1
	ctx.f1.f64 = double(float(ctx.f1.f64));
	// stfs f1,392(r1)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// fcfid f1,f29
	ctx.f1.f64 = double(f29.s64);
	// lhz r11,182(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 182);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// std r11,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, r11.u64);
	// frsp f12,f1
	ctx.f12.f64 = double(float(ctx.f1.f64));
	// stfs f12,396(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// fadds f12,f13,f5
	ctx.f12.f64 = double(float(ctx.f13.f64 + ctx.f5.f64));
	// fsubs f13,f5,f13
	ctx.f13.f64 = double(float(ctx.f5.f64 - ctx.f13.f64));
	// fctiwz f12,f12
	ctx.f12.s64 = (ctx.f12.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f12.f64));
	// stfd f12,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, ctx.f12.u64);
	// fctiwz f13,f13
	ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f13.f64));
	// stfd f13,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, ctx.f13.u64);
	// lfd f13,176(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// stfs f13,420(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// lhz r10,214(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 214);
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// std r10,208(r1)
	PPC_STORE_U64(ctx.r1.u32 + 208, ctx.r10.u64);
	// lhz r11,206(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 206);
	// lhz r10,198(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 198);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// std r11,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, r11.u64);
	// std r10,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, ctx.r10.u64);
	// lfd f12,208(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 208);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f13,f12
	ctx.f13.f64 = double(float(ctx.f12.f64));
	// stfs f13,424(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// lfd f13,200(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 200);
	// lfd f12,192(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// stfs f13,400(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// frsp f13,f12
	ctx.f13.f64 = double(float(ctx.f12.f64));
	// stfs f13,428(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// bne cr6,0x820a32f4
	if (!cr6.getEQ()) goto loc_820A32F4;
	// lfs f1,20(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	ctx.f1.f64 = double(temp.f32);
	// fmadds f1,f30,f1,f10
	ctx.f1.f64 = double(float(f30.f64 * ctx.f1.f64 + ctx.f10.f64));
	// lfs f13,4(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f29,24(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 24);
	f29.f64 = double(temp.f32);
	// fsubs f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 - ctx.f10.f64));
	// fmadds f29,f29,f30,f9
	f29.f64 = double(float(f29.f64 * f30.f64 + ctx.f9.f64));
	// lfs f12,8(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f28,16(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 16);
	f28.f64 = double(temp.f32);
	// fsubs f9,f12,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// fmadds f30,f28,f30,f8
	f30.f64 = double(float(f28.f64 * f30.f64 + ctx.f8.f64));
	// lfs f11,0(r25)
	temp.u32 = PPC_LOAD_U32(r25.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f8,f11,f8
	ctx.f8.f64 = double(float(ctx.f11.f64 - ctx.f8.f64));
	// fsubs f13,f13,f1
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f1.f64));
	// fmuls f10,f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f10.f64));
	// fsubs f12,f12,f29
	ctx.f12.f64 = double(float(ctx.f12.f64 - f29.f64));
	// fsubs f11,f11,f30
	ctx.f11.f64 = double(float(ctx.f11.f64 - f30.f64));
	// fmuls f13,f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// fmadds f10,f9,f9,f10
	ctx.f10.f64 = double(float(ctx.f9.f64 * ctx.f9.f64 + ctx.f10.f64));
	// fmadds f13,f12,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f12.f64 + ctx.f13.f64));
	// fmadds f10,f8,f8,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f8.f64 + ctx.f10.f64));
	// fmadds f13,f11,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f11.f64 + ctx.f13.f64));
	// fcmpu cr6,f13,f10
	cr6.compare(ctx.f13.f64, ctx.f10.f64);
	// bge cr6,0x820a30d0
	if (!cr6.getLT()) goto loc_820A30D0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f25,f7
	f25.f64 = ctx.f7.f64;
	// fmr f24,f6
	f24.f64 = ctx.f6.f64;
	// fmr f23,f5
	f23.f64 = ctx.f5.f64;
	// lfs f26,14060(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14060);
	f26.f64 = double(temp.f32);
loc_820A30D0:
	// lfs f13,248(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 248);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f10,f4,f26
	ctx.f10.f64 = double(float(ctx.f4.f64 * f26.f64));
	// fmuls f13,f13,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 * f26.f64));
	// lfs f12,252(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 252);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f12,f26
	ctx.f12.f64 = double(float(ctx.f12.f64 * f26.f64));
	// fmuls f11,f11,f26
	ctx.f11.f64 = double(float(ctx.f11.f64 * f26.f64));
	// stfs f0,464(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// fmuls f9,f3,f26
	ctx.f9.f64 = double(float(ctx.f3.f64 * f26.f64));
	// stfs f0,468(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// stfs f31,492(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// stfs f31,496(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// fadds f5,f10,f25
	ctx.f5.f64 = double(float(ctx.f10.f64 + f25.f64));
	// fadds f8,f13,f25
	ctx.f8.f64 = double(float(ctx.f13.f64 + f25.f64));
	// fadds f7,f12,f24
	ctx.f7.f64 = double(float(ctx.f12.f64 + f24.f64));
	// fadds f6,f11,f23
	ctx.f6.f64 = double(float(ctx.f11.f64 + f23.f64));
	// fsubs f13,f25,f13
	ctx.f13.f64 = double(float(f25.f64 - ctx.f13.f64));
	// fsubs f12,f24,f12
	ctx.f12.f64 = double(float(f24.f64 - ctx.f12.f64));
	// fsubs f11,f23,f11
	ctx.f11.f64 = double(float(f23.f64 - ctx.f11.f64));
	// fadds f4,f9,f24
	ctx.f4.f64 = double(float(ctx.f9.f64 + f24.f64));
	// fctiwz f8,f8
	ctx.f8.s64 = (ctx.f8.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f8.f64));
	// stfd f8,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, ctx.f8.u64);
	// fctiwz f8,f7
	ctx.f8.s64 = (ctx.f7.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f7.f64));
	// stfd f8,208(r1)
	PPC_STORE_U64(ctx.r1.u32 + 208, ctx.f8.u64);
	// fctiwz f8,f6
	ctx.f8.s64 = (ctx.f6.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f6.f64));
	// stfd f8,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, ctx.f8.u64);
	// fctiwz f13,f13
	ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f13.f64));
	// stfd f13,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, ctx.f13.u64);
	// fctiwz f13,f12
	ctx.f13.s64 = (ctx.f12.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f12.f64));
	// stfd f13,272(r1)
	PPC_STORE_U64(ctx.r1.u32 + 272, ctx.f13.u64);
	// fctiwz f13,f11
	ctx.f13.s64 = (ctx.f11.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f11.f64));
	// stfd f13,280(r1)
	PPC_STORE_U64(ctx.r1.u32 + 280, ctx.f13.u64);
	// lhz r11,182(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 182);
	// fctiwz f13,f5
	ctx.f13.s64 = (ctx.f5.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f5.f64));
	// stfd f13,264(r1)
	PPC_STORE_U64(ctx.r1.u32 + 264, ctx.f13.u64);
	// lhz r5,270(r1)
	ctx.r5.u64 = PPC_LOAD_U16(ctx.r1.u32 + 270);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// fctiwz f12,f4
	ctx.f12.s64 = (ctx.f4.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f4.f64));
	// std r11,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, r11.u64);
	// lfd f13,176(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// extsh r11,r5
	r11.s64 = ctx.r5.s16;
	// std r11,264(r1)
	PPC_STORE_U64(ctx.r1.u32 + 264, r11.u64);
	// lfd f4,264(r1)
	ctx.f4.u64 = PPC_LOAD_U64(ctx.r1.u32 + 264);
	// fcfid f4,f4
	ctx.f4.f64 = double(ctx.f4.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// stfs f13,448(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// lhz r10,214(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 214);
	// lhz r9,206(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 206);
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// lhz r8,198(r1)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r1.u32 + 198);
	// extsh r9,r9
	ctx.r9.s64 = ctx.r9.s16;
	// lhz r7,278(r1)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r1.u32 + 278);
	// extsh r8,r8
	ctx.r8.s64 = ctx.r8.s16;
	// lhz r6,286(r1)
	ctx.r6.u64 = PPC_LOAD_U16(ctx.r1.u32 + 286);
	// extsh r7,r7
	ctx.r7.s64 = ctx.r7.s16;
	// extsh r6,r6
	ctx.r6.s64 = ctx.r6.s16;
	// std r10,208(r1)
	PPC_STORE_U64(ctx.r1.u32 + 208, ctx.r10.u64);
	// std r9,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, ctx.r9.u64);
	// std r8,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, ctx.r8.u64);
	// std r7,272(r1)
	PPC_STORE_U64(ctx.r1.u32 + 272, ctx.r7.u64);
	// std r6,280(r1)
	PPC_STORE_U64(ctx.r1.u32 + 280, ctx.r6.u64);
	// lfd f11,208(r1)
	ctx.f11.u64 = PPC_LOAD_U64(ctx.r1.u32 + 208);
	// lfd f8,200(r1)
	ctx.f8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 200);
	// fcfid f11,f11
	ctx.f11.f64 = double(ctx.f11.s64);
	// lfd f7,192(r1)
	ctx.f7.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fcfid f8,f8
	ctx.f8.f64 = double(ctx.f8.s64);
	// lfd f6,272(r1)
	ctx.f6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 272);
	// fcfid f7,f7
	ctx.f7.f64 = double(ctx.f7.s64);
	// lfd f5,280(r1)
	ctx.f5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 280);
	// fcfid f6,f6
	ctx.f6.f64 = double(ctx.f6.s64);
	// fcfid f5,f5
	ctx.f5.f64 = double(ctx.f5.s64);
	// frsp f13,f11
	ctx.f13.f64 = double(float(ctx.f11.f64));
	// stfs f13,452(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// frsp f13,f8
	ctx.f13.f64 = double(float(ctx.f8.f64));
	// stfs f13,456(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// frsp f13,f7
	ctx.f13.f64 = double(float(ctx.f7.f64));
	// stfs f13,476(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// frsp f13,f6
	ctx.f13.f64 = double(float(ctx.f6.f64));
	// stfs f13,480(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// frsp f13,f5
	ctx.f13.f64 = double(float(ctx.f5.f64));
	// stfd f12,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, ctx.f12.u64);
	// fsubs f12,f25,f10
	ctx.f12.f64 = double(float(f25.f64 - ctx.f10.f64));
	// fsubs f11,f24,f9
	ctx.f11.f64 = double(float(f24.f64 - ctx.f9.f64));
	// stfs f13,484(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// frsp f13,f4
	ctx.f13.f64 = double(float(ctx.f4.f64));
	// stfs f13,504(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 504, temp.u32);
	// fmuls f13,f2,f26
	ctx.f13.f64 = double(float(ctx.f2.f64 * f26.f64));
	// stfs f0,524(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// stfs f0,548(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 548, temp.u32);
	// lhz r11,182(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 182);
	// stfs f31,520(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// stfs f31,552(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 552, temp.u32);
	// fctiwz f0,f12
	f0.s64 = (ctx.f12.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f12.f64));
	// stfd f0,208(r1)
	PPC_STORE_U64(ctx.r1.u32 + 208, f0.u64);
	// fctiwz f0,f11
	f0.s64 = (ctx.f11.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f11.f64));
	// stfd f0,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, f0.u64);
	// std r11,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, r11.u64);
	// fadds f0,f13,f23
	f0.f64 = double(float(ctx.f13.f64 + f23.f64));
	// fsubs f13,f23,f13
	ctx.f13.f64 = double(float(f23.f64 - ctx.f13.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfd f0,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, f0.u64);
	// fctiwz f0,f13
	f0.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f13.f64));
	// stfd f0,272(r1)
	PPC_STORE_U64(ctx.r1.u32 + 272, f0.u64);
	// lfd f0,176(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfs f0,508(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// lhz r11,214(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 214);
	// lhz r10,206(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 206);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// std r11,208(r1)
	PPC_STORE_U64(ctx.r1.u32 + 208, r11.u64);
	// std r10,200(r1)
	PPC_STORE_U64(ctx.r1.u32 + 200, ctx.r10.u64);
	// lhz r11,198(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 198);
	// lhz r10,278(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 278);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// std r11,176(r1)
	PPC_STORE_U64(ctx.r1.u32 + 176, r11.u64);
	// std r10,192(r1)
	PPC_STORE_U64(ctx.r1.u32 + 192, ctx.r10.u64);
	// lfd f0,208(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 208);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lfd f13,200(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 200);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfs f0,532(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// frsp f0,f13
	f0.f64 = double(float(ctx.f13.f64));
	// stfs f0,536(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 536, temp.u32);
	// lfd f0,176(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 176);
	// lfd f13,192(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 192);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfs f0,512(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// frsp f0,f13
	f0.f64 = double(float(ctx.f13.f64));
	// stfs f0,540(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
loc_820A32F4:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// lis r27,-31991
	r27.s64 = -2096562176;
	// bne cr6,0x820a330c
	if (!cr6.getEQ()) goto loc_820A330C;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,13356(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 13356);
	// bl 0x821936a0
	sub_821936A0(ctx, base);
loc_820A330C:
	// lbz r11,1(r29)
	r11.u64 = PPC_LOAD_U8(r29.u32 + 1);
	// addi r10,r1,560
	ctx.r10.s64 = ctx.r1.s64 + 560;
	// li r9,8
	ctx.r9.s64 = 8;
	// cmplwi cr6,r11,22
	cr6.compare<uint32_t>(r11.u32, 22, xer);
	// addi r11,r1,688
	r11.s64 = ctx.r1.s64 + 688;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
	// bne cr6,0x820a3424
	if (!cr6.getEQ()) goto loc_820A3424;
loc_820A3328:
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// std r9,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r9.u64);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// bdnz 0x820a3328
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820A3328;
	// addi r26,r1,336
	r26.s64 = ctx.r1.s64 + 336;
	// bl 0x8210d7d0
	sub_8210D7D0(ctx, base);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// addi r30,r11,28072
	r30.s64 = r11.s64 + 28072;
	// addi r24,r1,560
	r24.s64 = ctx.r1.s64 + 560;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x821463f0
	sub_821463F0(ctx, base);
	// li r11,5
	r11.s64 = 5;
	// li r31,1
	r31.s64 = 1;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r28.u32);
	// li r29,2
	r29.s64 = 2;
	// stw r28,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r28.u32);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// stw r28,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r28.u32);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// stw r28,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r28.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// li r11,7
	r11.s64 = 7;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// stw r28,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r28.u32);
	// li r7,4
	ctx.r7.s64 = 4;
	// stw r28,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r28.u32);
	// li r8,5
	ctx.r8.s64 = 5;
	// stw r31,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r31.u32);
	// li r9,6
	ctx.r9.s64 = 6;
	// stw r29,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r29.u32);
	// li r10,4
	ctx.r10.s64 = 4;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// stw r28,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r28.u32);
	// bl 0x82098e58
	sub_82098E58(ctx, base);
	// addi r26,r1,336
	r26.s64 = ctx.r1.s64 + 336;
	// bl 0x8210d7d0
	sub_8210D7D0(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r30,r1,560
	r30.s64 = ctx.r1.s64 + 560;
	// bl 0x821463f0
	sub_821463F0(ctx, base);
	// li r11,3
	r11.s64 = 3;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r28.u32);
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// stw r28,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r28.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r28,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r28.u32);
	// li r8,2
	ctx.r8.s64 = 2;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// li r9,3
	ctx.r9.s64 = 3;
	// stw r28,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r28.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r28,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r28.u32);
	// stw r28,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r28.u32);
	// stw r31,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r31.u32);
	// stw r29,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r29.u32);
	// stw r28,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r28.u32);
	// bl 0x82098e58
	sub_82098E58(ctx, base);
	// b 0x820a34a8
	goto loc_820A34A8;
loc_820A3424:
	// ld r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U64(r11.u32 + 0);
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// std r9,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, ctx.r9.u64);
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// bdnz 0x820a3424
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_820A3424;
	// addi r30,r1,336
	r30.s64 = ctx.r1.s64 + 336;
	// bl 0x8210d7d0
	sub_8210D7D0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// addi r26,r1,560
	r26.s64 = ctx.r1.s64 + 560;
	// bl 0x821463f0
	sub_821463F0(ctx, base);
	// li r11,3
	r11.s64 = 3;
	// li r31,1
	r31.s64 = 1;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r28.u32);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// stw r28,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r28.u32);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// stw r28,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r28.u32);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// stw r28,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r28.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// li r11,2
	r11.s64 = 2;
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// li r8,2
	ctx.r8.s64 = 2;
	// stw r28,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r28.u32);
	// li r9,3
	ctx.r9.s64 = 3;
	// stw r28,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r28.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r31,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r31.u32);
	// stw r11,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r11.u32);
	// stw r28,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r28.u32);
	// bl 0x82098e58
	sub_82098E58(ctx, base);
loc_820A34A8:
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,13356(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 13356);
	// bl 0x821936a0
	sub_821936A0(ctx, base);
loc_820A34B4:
	// addi r1,r1,912
	ctx.r1.s64 = ctx.r1.s64 + 912;
	// addi r12,r1,-72
	r12.s64 = ctx.r1.s64 + -72;
	// bl 0x823ed578
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_820A34C8"))) PPC_WEAK_FUNC(sub_820A34C8);
PPC_FUNC_IMPL(__imp__sub_820A34C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// cmplwi cr6,r11,128
	cr6.compare<uint32_t>(r11.u32, 128, xer);
	// bge cr6,0x820a358c
	if (!cr6.getLT()) goto loc_820A358C;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-6384(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -6384);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bgt cr6,0x820a3514
	if (cr6.getGT()) goto loc_820A3514;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f13,40(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 40);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,32(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,-6380(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6380);
	f0.f64 = double(temp.f32);
	// fmadds f0,f12,f0,f13
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// b 0x820a3568
	goto loc_820A3568;
loc_820A3514:
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f12,40(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 40);
	ctx.f12.f64 = double(temp.f32);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// lfs f11,32(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 32);
	ctx.f11.f64 = double(temp.f32);
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f0,2692(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2692);
	f0.f64 = double(temp.f32);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f10,f13
	ctx.f10.f64 = double(float(ctx.f13.f64));
	// lfs f13,14028(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14028);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f10,f10,f13
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// lfs f13,3060(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3060);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f10,f0,f13
	f0.f64 = double(float(ctx.f10.f64 * f0.f64 + ctx.f13.f64));
	// fmadds f0,f0,f11,f12
	f0.f64 = double(float(f0.f64 * ctx.f11.f64 + ctx.f12.f64));
loc_820A3568:
	// lfs f13,28(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,40(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 40, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820a3580
	if (cr6.getLT()) goto loc_820A3580;
	// li r11,-1
	r11.s64 = -1;
	// b 0x820a3588
	goto loc_820A3588;
loc_820A3580:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_820A3588:
	// stb r11,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r11.u8);
loc_820A358C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A35A8"))) PPC_WEAK_FUNC(sub_820A35A8);
PPC_FUNC_IMPL(__imp__sub_820A35A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed114
	// stwu r1,-240(r1)
	ea = -240 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r27,0
	r27.s64 = 0;
	// li r19,1
	r19.s64 = 1;
	// li r10,3
	ctx.r10.s64 = 3;
	// addi r11,r1,124
	r11.s64 = ctx.r1.s64 + 124;
	// mr r23,r27
	r23.u64 = r27.u64;
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r27.u32);
	// lis r25,-32014
	r25.s64 = -2098069504;
	// stw r19,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r19.u32);
	// stw r10,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r10.u32);
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r27.u32);
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r27.u32);
	// stw r27,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r27.u32);
	// stw r27,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r27.u32);
	// stw r27,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r27.u32);
	// stw r27,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r27.u32);
	// stw r27,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r27.u32);
	// stw r27,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r27.u32);
	// stw r27,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r27.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r20,r11,1240
	r20.s64 = r11.s64 + 1240;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r26,r11,6504
	r26.s64 = r11.s64 + 6504;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r21,r11,5288
	r21.s64 = r11.s64 + 5288;
	// lis r11,-32013
	r11.s64 = -2098003968;
	// addi r24,r11,5544
	r24.s64 = r11.s64 + 5544;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// addi r22,r11,27912
	r22.s64 = r11.s64 + 27912;
loc_820A3624:
	// lwz r10,-1364(r25)
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + -1364);
	// mulli r11,r23,936
	r11.s64 = r23.s64 * 936;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r31,r11,2344
	r31.s64 = r11.s64 + 2344;
	// lwz r10,2348(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2348);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
	// bge cr6,0x820a3648
	if (!cr6.getLT()) goto loc_820A3648;
	// lwz r28,0(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_820A3648:
	// lbz r11,15(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 15);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a37e4
	if (cr6.getEQ()) goto loc_820A37E4;
	// cmpwi cr6,r28,23
	cr6.compare<int32_t>(r28.s32, 23, xer);
	// beq cr6,0x820a3668
	if (cr6.getEQ()) goto loc_820A3668;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,484
	ctx.r3.s64 = r31.s64 + 484;
	// bl 0x820a28a8
	sub_820A28A8(ctx, base);
loc_820A3668:
	// lwz r11,768(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 768);
	// lhz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 12);
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// cmpwi cr6,r10,16
	cr6.compare<int32_t>(ctx.r10.s32, 16, xer);
	// ble cr6,0x820a3700
	if (!cr6.getGT()) goto loc_820A3700;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,64(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 64);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a3700
	if (cr6.getEQ()) goto loc_820A3700;
	// addi r30,r31,760
	r30.s64 = r31.s64 + 760;
	// lwz r4,68(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a36a8
	if (cr6.getEQ()) goto loc_820A36A8;
	// stw r19,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r19.u32);
loc_820A36A8:
	// cmpwi cr6,r28,25
	cr6.compare<int32_t>(r28.s32, 25, xer);
	// bne cr6,0x820a36e0
	if (!cr6.getEQ()) goto loc_820A36E0;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x823a5650
	sub_823A5650(ctx, base);
	// lwz r11,768(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 768);
	// li r7,4
	ctx.r7.s64 = 4;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r4,64(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 64);
	// bl 0x820d8d20
	sub_820D8D20(ctx, base);
	// b 0x820a3708
	goto loc_820A3708;
loc_820A36E0:
	// lwz r11,768(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 768);
	// li r7,1
	ctx.r7.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r21
	ctx.r5.u64 = r21.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r4,64(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 64);
	// bl 0x820d8d20
	sub_820D8D20(ctx, base);
loc_820A3700:
	// cmpwi cr6,r28,25
	cr6.compare<int32_t>(r28.s32, 25, xer);
	// bne cr6,0x820a3748
	if (!cr6.getEQ()) goto loc_820A3748;
loc_820A3708:
	// lwz r11,544(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 544);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a3748
	if (cr6.getEQ()) goto loc_820A3748;
	// lwz r30,20(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8211c460
	sub_8211C460(ctx, base);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lwz r3,12(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// lhz r11,14(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 14);
	// extsh r4,r11
	ctx.r4.s64 = r11.s16;
	// bl 0x823d22e0
	sub_823D22E0(ctx, base);
	// lwz r11,548(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 548);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820a3748
	if (cr6.getEQ()) goto loc_820A3748;
	// stw r27,544(r31)
	PPC_STORE_U32(r31.u32 + 544, r27.u32);
loc_820A3748:
	// mulli r11,r28,56
	r11.s64 = r28.s64 * 56;
	// addi r10,r26,8
	ctx.r10.s64 = r26.s64 + 8;
	// mr r29,r27
	r29.u64 = r27.u64;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a376c
	if (!cr6.getEQ()) goto loc_820A376C;
	// addi r10,r26,12
	ctx.r10.s64 = r26.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820a3770
	goto loc_820A3770;
loc_820A376C:
	// mr r11,r20
	r11.u64 = r20.u64;
loc_820A3770:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a378c
	if (cr6.getEQ()) goto loc_820A378C;
	// cmpwi cr6,r23,1
	cr6.compare<int32_t>(r23.s32, 1, xer);
	// bne cr6,0x820a378c
	if (!cr6.getEQ()) goto loc_820A378C;
	// mr r29,r19
	r29.u64 = r19.u64;
loc_820A378C:
	// addi r30,r31,760
	r30.s64 = r31.s64 + 760;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,255
	ctx.r5.s64 = 255;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8209ab98
	sub_8209AB98(ctx, base);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,255
	ctx.r5.s64 = 255;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8209ab98
	sub_8209AB98(ctx, base);
	// cmpwi cr6,r28,23
	cr6.compare<int32_t>(r28.s32, 23, xer);
	// bne cr6,0x820a37e4
	if (!cr6.getEQ()) goto loc_820A37E4;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,484
	ctx.r3.s64 = r31.s64 + 484;
	// bl 0x820a28a8
	sub_820A28A8(ctx, base);
loc_820A37E4:
	// addi r23,r23,1
	r23.s64 = r23.s64 + 1;
	// cmpwi cr6,r23,2
	cr6.compare<int32_t>(r23.s32, 2, xer);
	// blt cr6,0x820a3624
	if (cr6.getLT()) goto loc_820A3624;
	// addi r1,r1,240
	ctx.r1.s64 = ctx.r1.s64 + 240;
	// b 0x823ed164
	return;
}

__attribute__((alias("__imp__sub_820A37F8"))) PPC_WEAK_FUNC(sub_820A37F8);
PPC_FUNC_IMPL(__imp__sub_820A37F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed12c
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// cmpwi cr6,r6,30
	cr6.compare<int32_t>(ctx.r6.s32, 30, xer);
	// beq cr6,0x820a381c
	if (cr6.getEQ()) goto loc_820A381C;
	// cmpwi cr6,r6,23
	cr6.compare<int32_t>(ctx.r6.s32, 23, xer);
	// bne cr6,0x820a3820
	if (!cr6.getEQ()) goto loc_820A3820;
loc_820A381C:
	// li r6,60
	ctx.r6.s64 = 60;
loc_820A3820:
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820a0ad8
	sub_820A0AD8(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r6,2348(r10)
	PPC_STORE_U32(ctx.r10.u32 + 2348, ctx.r6.u32);
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,2312(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2312);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bgt cr6,0x820a3860
	if (cr6.getGT()) goto loc_820A3860;
	// lwz r10,2320(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2320);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x820a3bd0
	if (!cr6.getEQ()) goto loc_820A3BD0;
	// lwz r10,8388(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8388);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bge cr6,0x820a3bd0
	if (!cr6.getLT()) goto loc_820A3BD0;
loc_820A3860:
	// lwz r10,2320(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2320);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x820a3bd0
	if (cr6.getEQ()) goto loc_820A3BD0;
	// lwz r29,2336(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 2336);
	// mr r10,r6
	ctx.r10.u64 = ctx.r6.u64;
	// cmpwi cr6,r6,1
	cr6.compare<int32_t>(ctx.r6.s32, 1, xer);
	// bne cr6,0x820a3880
	if (!cr6.getEQ()) goto loc_820A3880;
	// lwz r10,8376(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8376);
loc_820A3880:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r10,r10,56
	ctx.r10.s64 = ctx.r10.s64 * 56;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x820a3bd0
	if (cr6.getEQ()) goto loc_820A3BD0;
	// mulli r10,r6,56
	ctx.r10.s64 = ctx.r6.s64 * 56;
	// addi r9,r11,8
	ctx.r9.s64 = r11.s64 + 8;
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a38b8
	if (!cr6.getEQ()) goto loc_820A38B8;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x820a38c0
	goto loc_820A38C0;
loc_820A38B8:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
loc_820A38C0:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,17,17
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a3bd0
	if (!cr6.getEQ()) goto loc_820A3BD0;
	// lhz r11,14(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 14);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// rlwinm r3,r11,6,0,25
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0xFFFFFFC0;
	// bl 0x8209cd50
	sub_8209CD50(ctx, base);
	// lhz r11,14(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 14);
	// li r31,0
	r31.s64 = 0;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r28,r31
	r28.u64 = r31.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a3920
	if (!cr6.getGT()) goto loc_820A3920;
	// mr r27,r26
	r27.u64 = r26.u64;
loc_820A3900:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// lhz r11,14(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 14);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// addi r27,r27,64
	r27.s64 = r27.s64 + 64;
	// cmpw cr6,r28,r11
	cr6.compare<int32_t>(r28.s32, r11.s32, xer);
	// blt cr6,0x820a3900
	if (cr6.getLT()) goto loc_820A3900;
loc_820A3920:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// stw r26,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r26.u32);
	// bl 0x8211c6c8
	sub_8211C6C8(ctx, base);
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c930
	sub_8211C930(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820a1530
	sub_820A1530(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820a1670
	sub_820A1670(ctx, base);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a397c
	if (cr6.getEQ()) goto loc_820A397C;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a397c
	if (cr6.getEQ()) goto loc_820A397C;
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
loc_820A397C:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lis r11,-32019
	r11.s64 = -2098397184;
	// lwz r10,4(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// addi r11,r11,25696
	r11.s64 = r11.s64 + 25696;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x820a39fc
	if (!cr6.getEQ()) goto loc_820A39FC;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a39cc
	if (cr6.getEQ()) goto loc_820A39CC;
	// rotlwi r11,r10,0
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// bl 0x8210c818
	sub_8210C818(ctx, base);
	// addi r5,r26,192
	ctx.r5.s64 = r26.s64 + 192;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8210b350
	sub_8210B350(ctx, base);
loc_820A39CC:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a39fc
	if (cr6.getEQ()) goto loc_820A39FC;
	// rotlwi r11,r10,0
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// bl 0x8210c818
	sub_8210C818(ctx, base);
	// addi r5,r26,256
	ctx.r5.s64 = r26.s64 + 256;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8210b350
	sub_8210B350(ctx, base);
loc_820A39FC:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a3a44
	if (cr6.getEQ()) goto loc_820A3A44;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r28,4(r3)
	r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// bl 0x82118ac8
	sub_82118AC8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8210c818
	sub_8210C818(ctx, base);
	// rlwinm r11,r27,6,0,25
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 6) & 0xFFFFFFC0;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// add r5,r11,r26
	ctx.r5.u64 = r11.u64 + r26.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8210b350
	sub_8210B350(ctx, base);
loc_820A3A44:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a3a8c
	if (cr6.getEQ()) goto loc_820A3A8C;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// lwz r28,4(r3)
	r28.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// bl 0x82118ac8
	sub_82118AC8(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8210c818
	sub_8210C818(ctx, base);
	// rlwinm r11,r27,6,0,25
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 6) & 0xFFFFFFC0;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// add r5,r11,r26
	ctx.r5.u64 = r11.u64 + r26.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x8210b350
	sub_8210B350(ctx, base);
loc_820A3A8C:
	// lhz r11,12(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 12);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,18
	cr6.compare<int32_t>(r11.s32, 18, xer);
	// ble cr6,0x820a3b04
	if (!cr6.getGT()) goto loc_820A3B04;
	// li r28,92
	r28.s64 = 92;
	// li r27,1
	r27.s64 = 1;
loc_820A3AA4:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// lwz r10,-20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a3ad0
	if (cr6.getEQ()) goto loc_820A3AD0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a3ad0
	if (cr6.getEQ()) goto loc_820A3AD0;
	// stw r27,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r27.u32);
loc_820A3AD0:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwzx r10,r28,r11
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a3af8
	if (cr6.getEQ()) goto loc_820A3AF8;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a3af8
	if (cr6.getEQ()) goto loc_820A3AF8;
	// stw r27,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r27.u32);
loc_820A3AF8:
	// addi r28,r28,4
	r28.s64 = r28.s64 + 4;
	// cmpwi cr6,r28,112
	cr6.compare<int32_t>(r28.s32, 112, xer);
	// blt cr6,0x820a3aa4
	if (cr6.getLT()) goto loc_820A3AA4;
loc_820A3B04:
	// lhz r11,12(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 12);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,16
	cr6.compare<int32_t>(r11.s32, 16, xer);
	// ble cr6,0x820a3b3c
	if (!cr6.getGT()) goto loc_820A3B3C;
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// lwz r10,64(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 64);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a3b3c
	if (cr6.getEQ()) goto loc_820A3B3C;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r4,68(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a3b3c
	if (cr6.getEQ()) goto loc_820A3B3C;
	// stw r31,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r31.u32);
loc_820A3B3C:
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,255
	ctx.r5.s64 = 255;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8209ab98
	sub_8209AB98(ctx, base);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,255
	ctx.r5.s64 = 255;
	// li r4,1
	ctx.r4.s64 = 1;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8209ab98
	sub_8209AB98(ctx, base);
	// bl 0x823d22e0
	sub_823D22E0(ctx, base);
	// lhz r11,14(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 14);
	// mr r30,r31
	r30.u64 = r31.u64;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a3bcc
	if (!cr6.getGT()) goto loc_820A3BCC;
loc_820A3B94:
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// add r3,r31,r11
	ctx.r3.u64 = r31.u64 + r11.u64;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lwz r11,92(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// add r4,r31,r11
	ctx.r4.u64 = r31.u64 + r11.u64;
	// bl 0x8210be08
	sub_8210BE08(ctx, base);
	// lhz r11,14(r29)
	r11.u64 = PPC_LOAD_U16(r29.u32 + 14);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// addi r31,r31,64
	r31.s64 = r31.s64 + 64;
	// cmpw cr6,r30,r11
	cr6.compare<int32_t>(r30.s32, r11.s32, xer);
	// blt cr6,0x820a3b94
	if (cr6.getLT()) goto loc_820A3B94;
loc_820A3BCC:
	// bl 0x823d22e0
	sub_823D22E0(ctx, base);
loc_820A3BD0:
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_820A3BD8"))) PPC_WEAK_FUNC(sub_820A3BD8);
PPC_FUNC_IMPL(__imp__sub_820A3BD8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r9,r11,-5968
	ctx.r9.s64 = r11.s64 + -5968;
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_820A3BE8:
	// lwz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x820a3c10
	if (cr6.getEQ()) goto loc_820A3C10;
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// addi r8,r9,16
	ctx.r8.s64 = ctx.r9.s64 + 16;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// blt cr6,0x820a3be8
	if (cr6.getLT()) goto loc_820A3BE8;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_820A3C10:
	// rlwinm r11,r10,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r11,r9
	ctx.r3.u64 = r11.u64 + ctx.r9.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A3C20"))) PPC_WEAK_FUNC(sub_820A3C20);
PPC_FUNC_IMPL(__imp__sub_820A3C20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed120
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// addi r22,r25,12
	r22.s64 = r25.s64 + 12;
	// mr r24,r5
	r24.u64 = ctx.r5.u64;
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
	// bl 0x820dd8c0
	sub_820DD8C0(ctx, base);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r31,r3,31
	r31.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r30,r11,r31
	r30.u64 = r11.u64 + r31.u64;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r31,r3,31
	r31.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r23,r11,r31
	r23.u64 = r11.u64 + r31.u64;
	// stw r24,1156(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1156, r24.u32);
	// bl 0x82139350
	sub_82139350(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820a3c8c
	if (!cr6.getEQ()) goto loc_820A3C8C;
	// bl 0x82139360
	sub_82139360(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820a3c9c
	if (cr6.getEQ()) goto loc_820A3C9C;
loc_820A3C8C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// addi r3,r11,14072
	ctx.r3.s64 = r11.s64 + 14072;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
loc_820A3C9C:
	// cmpwi cr6,r26,29
	cr6.compare<int32_t>(r26.s32, 29, xer);
	// beq cr6,0x820a3f28
	if (cr6.getEQ()) goto loc_820A3F28;
	// cmpwi cr6,r26,28
	cr6.compare<int32_t>(r26.s32, 28, xer);
	// beq cr6,0x820a3f28
	if (cr6.getEQ()) goto loc_820A3F28;
	// cmpwi cr6,r26,27
	cr6.compare<int32_t>(r26.s32, 27, xer);
	// beq cr6,0x820a3f28
	if (cr6.getEQ()) goto loc_820A3F28;
	// cmpwi cr6,r26,33
	cr6.compare<int32_t>(r26.s32, 33, xer);
	// beq cr6,0x820a3f28
	if (cr6.getEQ()) goto loc_820A3F28;
	// cmpwi cr6,r26,47
	cr6.compare<int32_t>(r26.s32, 47, xer);
	// beq cr6,0x820a3f28
	if (cr6.getEQ()) goto loc_820A3F28;
	// cmpwi cr6,r26,48
	cr6.compare<int32_t>(r26.s32, 48, xer);
	// beq cr6,0x820a3f28
	if (cr6.getEQ()) goto loc_820A3F28;
	// cmpwi cr6,r26,34
	cr6.compare<int32_t>(r26.s32, 34, xer);
	// beq cr6,0x820a3f28
	if (cr6.getEQ()) goto loc_820A3F28;
	// cmpwi cr6,r26,23
	cr6.compare<int32_t>(r26.s32, 23, xer);
	// beq cr6,0x820a3f28
	if (cr6.getEQ()) goto loc_820A3F28;
	// cmpwi cr6,r26,60
	cr6.compare<int32_t>(r26.s32, 60, xer);
	// beq cr6,0x820a3f28
	if (cr6.getEQ()) goto loc_820A3F28;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-6384(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a3f28
	if (!cr6.getGT()) goto loc_820A3F28;
	// bl 0x820a3bd8
	sub_820A3BD8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,13992
	r29.s64 = r11.s64 + 13992;
	// beq cr6,0x820a3e9c
	if (cr6.getEQ()) goto loc_820A3E9C;
	// lbz r11,0(r25)
	r11.u64 = PPC_LOAD_U8(r25.u32 + 0);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x820a3df0
	if (cr6.getEQ()) goto loc_820A3DF0;
	// cmplwi cr6,r11,6
	cr6.compare<uint32_t>(r11.u32, 6, xer);
	// beq cr6,0x820a3df0
	if (cr6.getEQ()) goto loc_820A3DF0;
	// cmpwi cr6,r26,22
	cr6.compare<int32_t>(r26.s32, 22, xer);
	// bne cr6,0x820a3d3c
	if (!cr6.getEQ()) goto loc_820A3D3C;
	// li r8,4568
	ctx.r8.s64 = 4568;
	// li r4,91
	ctx.r4.s64 = 91;
	// b 0x820a3e74
	goto loc_820A3E74;
loc_820A3D3C:
	// li r10,30
	ctx.r10.s64 = 30;
	// lis r11,-13108
	r11.s64 = -859045888;
	// li r8,28
	ctx.r8.s64 = 28;
	// ori r11,r11,52429
	r11.u64 = r11.u64 | 52429;
	// li r7,27
	ctx.r7.s64 = 27;
	// sth r10,102(r1)
	PPC_STORE_U16(ctx.r1.u32 + 102, ctx.r10.u16);
	// mulhwu r11,r30,r11
	r11.u64 = (uint64_t(r30.u32) * uint64_t(r11.u32)) >> 32;
	// sth r10,110(r1)
	PPC_STORE_U16(ctx.r1.u32 + 110, ctx.r10.u16);
	// sth r10,118(r1)
	PPC_STORE_U16(ctx.r1.u32 + 118, ctx.r10.u16);
	// sth r8,98(r1)
	PPC_STORE_U16(ctx.r1.u32 + 98, ctx.r8.u16);
	// sth r8,106(r1)
	PPC_STORE_U16(ctx.r1.u32 + 106, ctx.r8.u16);
	// sth r8,114(r1)
	PPC_STORE_U16(ctx.r1.u32 + 114, ctx.r8.u16);
	// sth r7,96(r1)
	PPC_STORE_U16(ctx.r1.u32 + 96, ctx.r7.u16);
	// sth r7,104(r1)
	PPC_STORE_U16(ctx.r1.u32 + 104, ctx.r7.u16);
	// sth r7,112(r1)
	PPC_STORE_U16(ctx.r1.u32 + 112, ctx.r7.u16);
	// li r10,35
	ctx.r10.s64 = 35;
	// rlwinm r11,r11,28,4,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 28) & 0xFFFFFFF;
	// li r9,29
	ctx.r9.s64 = 29;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// li r8,4580
	ctx.r8.s64 = 4580;
	// sth r10,120(r1)
	PPC_STORE_U16(ctx.r1.u32 + 120, ctx.r10.u16);
	// li r10,36
	ctx.r10.s64 = 36;
	// sth r9,100(r1)
	PPC_STORE_U16(ctx.r1.u32 + 100, ctx.r9.u16);
	// sth r9,108(r1)
	PPC_STORE_U16(ctx.r1.u32 + 108, ctx.r9.u16);
	// sth r9,116(r1)
	PPC_STORE_U16(ctx.r1.u32 + 116, ctx.r9.u16);
	// sth r10,122(r1)
	PPC_STORE_U16(ctx.r1.u32 + 122, ctx.r10.u16);
	// li r10,37
	ctx.r10.s64 = 37;
	// sth r10,124(r1)
	PPC_STORE_U16(ctx.r1.u32 + 124, ctx.r10.u16);
	// li r10,38
	ctx.r10.s64 = 38;
	// sth r10,126(r1)
	PPC_STORE_U16(ctx.r1.u32 + 126, ctx.r10.u16);
	// li r10,39
	ctx.r10.s64 = 39;
	// sth r10,128(r1)
	PPC_STORE_U16(ctx.r1.u32 + 128, ctx.r10.u16);
	// li r10,40
	ctx.r10.s64 = 40;
	// sth r10,130(r1)
	PPC_STORE_U16(ctx.r1.u32 + 130, ctx.r10.u16);
	// li r10,41
	ctx.r10.s64 = 41;
	// sth r10,132(r1)
	PPC_STORE_U16(ctx.r1.u32 + 132, ctx.r10.u16);
	// li r10,42
	ctx.r10.s64 = 42;
	// sth r10,134(r1)
	PPC_STORE_U16(ctx.r1.u32 + 134, ctx.r10.u16);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r11,r30
	r11.s64 = r30.s64 - r11.s64;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r11,r11,r4
	r11.u64 = PPC_LOAD_U16(r11.u32 + ctx.r4.u32);
	// b 0x820a3e70
	goto loc_820A3E70;
loc_820A3DF0:
	// cmpwi cr6,r26,2
	cr6.compare<int32_t>(r26.s32, 2, xer);
	// bne cr6,0x820a3e04
	if (!cr6.getEQ()) goto loc_820A3E04;
	// li r8,4593
	ctx.r8.s64 = 4593;
	// li r4,74
	ctx.r4.s64 = 74;
	// b 0x820a3e74
	goto loc_820A3E74;
loc_820A3E04:
	// cmpwi cr6,r26,1
	cr6.compare<int32_t>(r26.s32, 1, xer);
	// bne cr6,0x820a3e54
	if (!cr6.getEQ()) goto loc_820A3E54;
	// li r10,47
	ctx.r10.s64 = 47;
	// lis r11,-21846
	r11.s64 = -1431699456;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// ori r11,r11,43691
	r11.u64 = r11.u64 | 43691;
	// li r8,4601
	ctx.r8.s64 = 4601;
	// sth r10,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, ctx.r10.u16);
	// li r10,48
	ctx.r10.s64 = 48;
	// mulhwu r11,r30,r11
	r11.u64 = (uint64_t(r30.u32) * uint64_t(r11.u32)) >> 32;
	// sth r10,82(r1)
	PPC_STORE_U16(ctx.r1.u32 + 82, ctx.r10.u16);
	// li r10,49
	ctx.r10.s64 = 49;
	// rlwinm r11,r11,31,1,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFFFFFF;
	// sth r10,84(r1)
	PPC_STORE_U16(ctx.r1.u32 + 84, ctx.r10.u16);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// subf r11,r11,r30
	r11.s64 = r30.s64 - r11.s64;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r11,r11,r9
	r11.u64 = PPC_LOAD_U16(r11.u32 + ctx.r9.u32);
	// b 0x830e0460
	// ERROR 830E0460
	return;
loc_820A3E54:
	// li r11,69
	r11.s64 = 69;
	// rlwinm r10,r30,1,30,30
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0x2;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// li r8,4609
	ctx.r8.s64 = 4609;
	// sth r11,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, r11.u16);
	// sth r11,82(r1)
	PPC_STORE_U16(ctx.r1.u32 + 82, r11.u16);
	// lhzx r11,r10,r9
	r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + ctx.r9.u32);
loc_820A3E70:
	// extsh r4,r11
	ctx.r4.s64 = r11.s16;
loc_820A3E74:
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r6,19944(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + 19944);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwz r3,19936(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a3e9c
	if (cr6.getEQ()) goto loc_820A3E9C;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// bl 0x821448f8
	sub_821448F8(ctx, base);
loc_820A3E9C:
	// bl 0x820a3bd8
	sub_820A3BD8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a3f28
	if (cr6.getEQ()) goto loc_820A3F28;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// blt cr6,0x820a3f28
	if (cr6.getLT()) goto loc_820A3F28;
	// lis r11,-32033
	r11.s64 = -2099314688;
	// rlwinm r10,r24,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-5072
	r11.s64 = r11.s64 + -5072;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a3f28
	if (cr6.getEQ()) goto loc_820A3F28;
	// lhz r11,8(r10)
	r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 8);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a3f14
	if (!cr6.getGT()) goto loc_820A3F14;
	// divwu r9,r23,r11
	ctx.r9.u32 = r23.u32 / r11.u32;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// twllei r11,0
	// lwz r6,19944(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + 19944);
	// mullw r11,r9,r11
	r11.s64 = int64_t(ctx.r9.s32) * int64_t(r11.s32);
	// lwz r3,19936(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 19936);
	// subf r11,r11,r23
	r11.s64 = r23.s64 - r11.s64;
	// li r8,4629
	ctx.r8.s64 = 4629;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lhzx r11,r11,r10
	r11.u64 = PPC_LOAD_U16(r11.u32 + ctx.r10.u32);
	// extsh r4,r11
	ctx.r4.s64 = r11.s16;
	// bl 0x82144920
	sub_82144920(ctx, base);
loc_820A3F14:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a3f28
	if (cr6.getEQ()) goto loc_820A3F28;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// bl 0x820dd8d8
	sub_820DD8D8(ctx, base);
loc_820A3F28:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x823ed170
	return;
}

__attribute__((alias("__imp__sub_820A3F30"))) PPC_WEAK_FUNC(sub_820A3F30);
PPC_FUNC_IMPL(__imp__sub_820A3F30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,-6384(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a3fa4
	if (!cr6.getGT()) goto loc_820A3FA4;
	// bl 0x820a3bd8
	sub_820A3BD8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a3fa4
	if (cr6.getEQ()) goto loc_820A3FA4;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,4650
	ctx.r8.s64 = 4650;
	// addi r7,r11,13992
	ctx.r7.s64 = r11.s64 + 13992;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,70
	ctx.r4.s64 = 70;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a3fa4
	if (cr6.getEQ()) goto loc_820A3FA4;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x820dd8d8
	sub_820DD8D8(ctx, base);
loc_820A3FA4:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A3FC0"))) PPC_WEAK_FUNC(sub_820A3FC0);
PPC_FUNC_IMPL(__imp__sub_820A3FC0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed124
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r23,r4
	r23.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r31,r3,31
	r31.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r31,r11,r31
	r31.u64 = r11.u64 + r31.u64;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// add r24,r11,r30
	r24.u64 = r11.u64 + r30.u64;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// stw r25,1156(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1156, r25.u32);
	// lwz r11,-6384(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a4230
	if (!cr6.getGT()) goto loc_820A4230;
	// bl 0x820a3bd8
	sub_820A3BD8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31994
	r28.s64 = -2096758784;
	// addi r29,r11,13992
	r29.s64 = r11.s64 + 13992;
	// beq cr6,0x820a41a4
	if (cr6.getEQ()) goto loc_820A41A4;
	// cmpwi cr6,r26,23
	cr6.compare<int32_t>(r26.s32, 23, xer);
	// beq cr6,0x820a4190
	if (cr6.getEQ()) goto loc_820A4190;
	// cmpwi cr6,r26,22
	cr6.compare<int32_t>(r26.s32, 22, xer);
	// bne cr6,0x820a406c
	if (!cr6.getEQ()) goto loc_820A406C;
	// li r9,92
	ctx.r9.s64 = 92;
	// rlwinm r11,r31,1,30,30
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 1) & 0x2;
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// li r8,4683
	ctx.r8.s64 = 4683;
	// sth r9,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, ctx.r9.u16);
	// li r9,93
	ctx.r9.s64 = 93;
	// sth r9,82(r1)
	PPC_STORE_U16(ctx.r1.u32 + 82, ctx.r9.u16);
	// lhzx r11,r11,r10
	r11.u64 = PPC_LOAD_U16(r11.u32 + ctx.r10.u32);
	// b 0x820a4178
	goto loc_820A4178;
loc_820A406C:
	// lis r11,14563
	r11.s64 = 954400768;
	// li r8,24
	ctx.r8.s64 = 24;
	// ori r11,r11,36409
	r11.u64 = r11.u64 | 36409;
	// li r9,25
	ctx.r9.s64 = 25;
	// mulhwu r11,r31,r11
	r11.u64 = (uint64_t(r31.u32) * uint64_t(r11.u32)) >> 32;
	// sth r8,106(r1)
	PPC_STORE_U16(ctx.r1.u32 + 106, ctx.r8.u16);
	// sth r8,114(r1)
	PPC_STORE_U16(ctx.r1.u32 + 114, ctx.r8.u16);
	// sth r8,122(r1)
	PPC_STORE_U16(ctx.r1.u32 + 122, ctx.r8.u16);
	// sth r9,108(r1)
	PPC_STORE_U16(ctx.r1.u32 + 108, ctx.r9.u16);
	// sth r9,116(r1)
	PPC_STORE_U16(ctx.r1.u32 + 116, ctx.r9.u16);
	// sth r9,124(r1)
	PPC_STORE_U16(ctx.r1.u32 + 124, ctx.r9.u16);
	// rlwinm r10,r11,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0x1FFFFFFF;
	// li r11,19
	r11.s64 = 19;
	// li r8,31
	ctx.r8.s64 = 31;
	// li r7,23
	ctx.r7.s64 = 23;
	// li r9,33
	ctx.r9.s64 = 33;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// sth r11,96(r1)
	PPC_STORE_U16(ctx.r1.u32 + 96, r11.u16);
	// li r11,20
	r11.s64 = 20;
	// sth r8,128(r1)
	PPC_STORE_U16(ctx.r1.u32 + 128, ctx.r8.u16);
	// sth r8,136(r1)
	PPC_STORE_U16(ctx.r1.u32 + 136, ctx.r8.u16);
	// sth r8,144(r1)
	PPC_STORE_U16(ctx.r1.u32 + 144, ctx.r8.u16);
	// li r8,4700
	ctx.r8.s64 = 4700;
	// sth r7,104(r1)
	PPC_STORE_U16(ctx.r1.u32 + 104, ctx.r7.u16);
	// sth r11,98(r1)
	PPC_STORE_U16(ctx.r1.u32 + 98, r11.u16);
	// li r11,21
	r11.s64 = 21;
	// sth r7,112(r1)
	PPC_STORE_U16(ctx.r1.u32 + 112, ctx.r7.u16);
	// sth r7,120(r1)
	PPC_STORE_U16(ctx.r1.u32 + 120, ctx.r7.u16);
	// sth r9,134(r1)
	PPC_STORE_U16(ctx.r1.u32 + 134, ctx.r9.u16);
	// sth r9,142(r1)
	PPC_STORE_U16(ctx.r1.u32 + 142, ctx.r9.u16);
	// sth r11,100(r1)
	PPC_STORE_U16(ctx.r1.u32 + 100, r11.u16);
	// li r11,22
	r11.s64 = 22;
	// sth r9,150(r1)
	PPC_STORE_U16(ctx.r1.u32 + 150, ctx.r9.u16);
	// sth r11,102(r1)
	PPC_STORE_U16(ctx.r1.u32 + 102, r11.u16);
	// li r11,26
	r11.s64 = 26;
	// sth r11,110(r1)
	PPC_STORE_U16(ctx.r1.u32 + 110, r11.u16);
	// sth r11,118(r1)
	PPC_STORE_U16(ctx.r1.u32 + 118, r11.u16);
	// sth r11,126(r1)
	PPC_STORE_U16(ctx.r1.u32 + 126, r11.u16);
	// li r11,32
	r11.s64 = 32;
	// sth r11,130(r1)
	PPC_STORE_U16(ctx.r1.u32 + 130, r11.u16);
	// sth r11,132(r1)
	PPC_STORE_U16(ctx.r1.u32 + 132, r11.u16);
	// sth r11,138(r1)
	PPC_STORE_U16(ctx.r1.u32 + 138, r11.u16);
	// sth r11,140(r1)
	PPC_STORE_U16(ctx.r1.u32 + 140, r11.u16);
	// sth r11,146(r1)
	PPC_STORE_U16(ctx.r1.u32 + 146, r11.u16);
	// sth r11,148(r1)
	PPC_STORE_U16(ctx.r1.u32 + 148, r11.u16);
	// li r11,35
	r11.s64 = 35;
	// sth r11,152(r1)
	PPC_STORE_U16(ctx.r1.u32 + 152, r11.u16);
	// li r11,36
	r11.s64 = 36;
	// sth r11,154(r1)
	PPC_STORE_U16(ctx.r1.u32 + 154, r11.u16);
	// li r11,37
	r11.s64 = 37;
	// sth r11,156(r1)
	PPC_STORE_U16(ctx.r1.u32 + 156, r11.u16);
	// li r11,38
	r11.s64 = 38;
	// sth r11,158(r1)
	PPC_STORE_U16(ctx.r1.u32 + 158, r11.u16);
	// li r11,39
	r11.s64 = 39;
	// sth r11,160(r1)
	PPC_STORE_U16(ctx.r1.u32 + 160, r11.u16);
	// li r11,40
	r11.s64 = 40;
	// sth r11,162(r1)
	PPC_STORE_U16(ctx.r1.u32 + 162, r11.u16);
	// li r11,41
	r11.s64 = 41;
	// sth r11,164(r1)
	PPC_STORE_U16(ctx.r1.u32 + 164, r11.u16);
	// li r11,42
	r11.s64 = 42;
	// sth r11,166(r1)
	PPC_STORE_U16(ctx.r1.u32 + 166, r11.u16);
	// rlwinm r11,r10,3,0,28
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r11,r31
	r11.s64 = r31.s64 - r11.s64;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r11,r11,r4
	r11.u64 = PPC_LOAD_U16(r11.u32 + ctx.r4.u32);
loc_820A4178:
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// lwz r6,19944(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + 19944);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r3,19936(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 19936);
	// extsh r4,r11
	ctx.r4.s64 = r11.s16;
	// bl 0x82144920
	sub_82144920(ctx, base);
loc_820A4190:
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a41a4
	if (cr6.getEQ()) goto loc_820A41A4;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// bl 0x820dd8d8
	sub_820DD8D8(ctx, base);
loc_820A41A4:
	// bl 0x820a3bd8
	sub_820A3BD8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a4230
	if (cr6.getEQ()) goto loc_820A4230;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// blt cr6,0x820a4230
	if (cr6.getLT()) goto loc_820A4230;
	// lis r11,-32033
	r11.s64 = -2099314688;
	// rlwinm r10,r25,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r25.u32 | (r25.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-5072
	r11.s64 = r11.s64 + -5072;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lhz r11,8(r10)
	r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + 8);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a4230
	if (!cr6.getGT()) goto loc_820A4230;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a421c
	if (cr6.getEQ()) goto loc_820A421C;
	// divwu r9,r24,r11
	ctx.r9.u32 = r24.u32 / r11.u32;
	// lwz r10,0(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// twllei r11,0
	// lwz r6,19944(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + 19944);
	// mullw r11,r9,r11
	r11.s64 = int64_t(ctx.r9.s32) * int64_t(r11.s32);
	// lwz r3,19936(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 19936);
	// subf r11,r11,r24
	r11.s64 = r24.s64 - r11.s64;
	// li r8,4716
	ctx.r8.s64 = 4716;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lhzx r11,r11,r10
	r11.u64 = PPC_LOAD_U16(r11.u32 + ctx.r10.u32);
	// extsh r4,r11
	ctx.r4.s64 = r11.s16;
	// bl 0x82144920
	sub_82144920(ctx, base);
loc_820A421C:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a4230
	if (cr6.getEQ()) goto loc_820A4230;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// bl 0x820dd8d8
	sub_820DD8D8(ctx, base);
loc_820A4230:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x823ed174
	return;
}

__attribute__((alias("__imp__sub_820A4238"))) PPC_WEAK_FUNC(sub_820A4238);
PPC_FUNC_IMPL(__imp__sub_820A4238) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r3,4376(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 4376);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A4248"))) PPC_WEAK_FUNC(sub_820A4248);
PPC_FUNC_IMPL(__imp__sub_820A4248) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r10,r3,56
	ctx.r10.s64 = ctx.r3.s64 * 56;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// addi r11,r11,20
	r11.s64 = r11.s64 + 20;
	// lfsx f1,r10,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A4260"))) PPC_WEAK_FUNC(sub_820A4260);
PPC_FUNC_IMPL(__imp__sub_820A4260) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r10,r3,56
	ctx.r10.s64 = ctx.r3.s64 * 56;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// lfsx f1,r10,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A4278"))) PPC_WEAK_FUNC(sub_820A4278);
PPC_FUNC_IMPL(__imp__sub_820A4278) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r10,r3,56
	ctx.r10.s64 = ctx.r3.s64 * 56;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// addi r11,r11,28
	r11.s64 = r11.s64 + 28;
	// lfsx f1,r10,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A4290"))) PPC_WEAK_FUNC(sub_820A4290);
PPC_FUNC_IMPL(__imp__sub_820A4290) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r10,r3,56
	ctx.r10.s64 = ctx.r3.s64 * 56;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// addi r11,r11,32
	r11.s64 = r11.s64 + 32;
	// lfsx f1,r10,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A42A8"))) PPC_WEAK_FUNC(sub_820A42A8);
PPC_FUNC_IMPL(__imp__sub_820A42A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r10,r3,56
	ctx.r10.s64 = ctx.r3.s64 * 56;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// addi r11,r11,36
	r11.s64 = r11.s64 + 36;
	// lfsx f1,r10,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A42C0"))) PPC_WEAK_FUNC(sub_820A42C0);
PPC_FUNC_IMPL(__imp__sub_820A42C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r10,r3,56
	ctx.r10.s64 = ctx.r3.s64 * 56;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// lhzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r10.u32 + r11.u32);
	// b 0x82136ad8
	sub_82136AD8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820A42D8"))) PPC_WEAK_FUNC(sub_820A42D8);
PPC_FUNC_IMPL(__imp__sub_820A42D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r10,r3,56
	ctx.r10.s64 = ctx.r3.s64 * 56;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// addi r11,r11,18
	r11.s64 = r11.s64 + 18;
	// lhzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r10.u32 + r11.u32);
	// b 0x82136ad8
	sub_82136AD8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820A42F0"))) PPC_WEAK_FUNC(sub_820A42F0);
PPC_FUNC_IMPL(__imp__sub_820A42F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r10,r3,56
	ctx.r10.s64 = ctx.r3.s64 * 56;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// addi r11,r11,42
	r11.s64 = r11.s64 + 42;
	// lhzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r10.u32 + r11.u32);
	// b 0x82136ad8
	sub_82136AD8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820A4308"))) PPC_WEAK_FUNC(sub_820A4308);
PPC_FUNC_IMPL(__imp__sub_820A4308) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r10,r3,56
	ctx.r10.s64 = ctx.r3.s64 * 56;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// addi r11,r11,40
	r11.s64 = r11.s64 + 40;
	// lhzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r10.u32 + r11.u32);
	// b 0x82136ad8
	sub_82136AD8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820A4320"))) PPC_WEAK_FUNC(sub_820A4320);
PPC_FUNC_IMPL(__imp__sub_820A4320) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,14104(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14104);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A4330"))) PPC_WEAK_FUNC(sub_820A4330);
PPC_FUNC_IMPL(__imp__sub_820A4330) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r10,r3,56
	ctx.r10.s64 = ctx.r3.s64 * 56;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// addi r11,r11,44
	r11.s64 = r11.s64 + 44;
	// lfsx f1,r10,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A4348"))) PPC_WEAK_FUNC(sub_820A4348);
PPC_FUNC_IMPL(__imp__sub_820A4348) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r10,r3,56
	ctx.r10.s64 = ctx.r3.s64 * 56;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// addi r11,r11,48
	r11.s64 = r11.s64 + 48;
	// lfsx f1,r10,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A4360"))) PPC_WEAK_FUNC(sub_820A4360);
PPC_FUNC_IMPL(__imp__sub_820A4360) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r10,r3,56
	ctx.r10.s64 = ctx.r3.s64 * 56;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// addi r11,r11,52
	r11.s64 = r11.s64 + 52;
	// lfsx f1,r10,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A4378"))) PPC_WEAK_FUNC(sub_820A4378);
PPC_FUNC_IMPL(__imp__sub_820A4378) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mulli r10,r3,936
	ctx.r10.s64 = ctx.r3.s64 * 936;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lfs f1,2872(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2872);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A4390"))) PPC_WEAK_FUNC(sub_820A4390);
PPC_FUNC_IMPL(__imp__sub_820A4390) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r5,-32014
	ctx.r5.s64 = -2098069504;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// lwz r11,-1364(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + -1364);
	// addi r8,r10,8
	ctx.r8.s64 = ctx.r10.s64 + 8;
	// lwz r7,2344(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// lwz r4,3280(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 3280);
	// mulli r9,r7,56
	ctx.r9.s64 = ctx.r7.s64 * 56;
	// lwzx r8,r9,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// lis r8,-32190
	ctx.r8.s64 = -2109603840;
	// addi r8,r8,1240
	ctx.r8.s64 = ctx.r8.s64 + 1240;
	// bne cr6,0x820a43d0
	if (!cr6.getEQ()) goto loc_820A43D0;
	// addi r6,r10,12
	ctx.r6.s64 = ctx.r10.s64 + 12;
	// lwzx r6,r9,r6
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// b 0x820a43d4
	goto loc_820A43D4;
loc_820A43D0:
	// mr r6,r8
	ctx.r6.u64 = ctx.r8.u64;
loc_820A43D4:
	// mulli r9,r4,56
	ctx.r9.s64 = ctx.r4.s64 * 56;
	// addi r3,r10,8
	ctx.r3.s64 = ctx.r10.s64 + 8;
	// lwzx r3,r9,r3
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x820a43f0
	if (!cr6.getEQ()) goto loc_820A43F0;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r8,r9,r10
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
loc_820A43F0:
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x820a4428
	if (cr6.getEQ()) goto loc_820A4428;
	// lbz r10,2356(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 2356);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a4428
	if (cr6.getEQ()) goto loc_820A4428;
	// lfs f13,2872(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2872);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,92(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 92);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,2872(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2872, temp.u32);
	// lfs f13,88(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820a4424
	if (!cr6.getGT()) goto loc_820A4424;
	// stfs f13,2872(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 2872, temp.u32);
loc_820A4424:
	// lwz r11,-1364(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + -1364);
loc_820A4428:
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq cr6,0x820a4460
	if (cr6.getEQ()) goto loc_820A4460;
	// lbz r10,3292(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 3292);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a4460
	if (cr6.getEQ()) goto loc_820A4460;
	// lfs f13,3808(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3808);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,92(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 92);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,3808(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 3808, temp.u32);
	// lfs f13,88(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820a445c
	if (!cr6.getGT()) goto loc_820A445C;
	// stfs f13,3808(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 3808, temp.u32);
loc_820A445C:
	// lwz r11,-1364(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + -1364);
loc_820A4460:
	// lfs f0,2872(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2872);
	f0.f64 = double(temp.f32);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lfs f13,84(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 84);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// fsubs f12,f0,f13
	ctx.f12.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f0,92(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 92);
	f0.f64 = double(temp.f32);
	// lfs f11,96(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 96);
	ctx.f11.f64 = double(temp.f32);
	// lfs f9,100(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 100);
	ctx.f9.f64 = double(temp.f32);
	// lfs f13,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f10,f0,f13
	ctx.f10.f64 = double(float(f0.f64 * ctx.f13.f64));
	// lfs f0,13960(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 13960);
	f0.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * f0.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * f0.f64));
	// fmuls f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fdivs f13,f10,f11
	ctx.f13.f64 = double(float(ctx.f10.f64 / ctx.f11.f64));
	// fdivs f12,f12,f9
	ctx.f12.f64 = double(float(ctx.f12.f64 / ctx.f9.f64));
	// fcmpu cr6,f12,f13
	cr6.compare(ctx.f12.f64, ctx.f13.f64);
	// ble cr6,0x820a44ac
	if (!cr6.getGT()) goto loc_820A44AC;
	// fmr f13,f12
	ctx.f13.f64 = ctx.f12.f64;
loc_820A44AC:
	// lfs f12,2872(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2872);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// stfs f13,2872(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 2872, temp.u32);
	// lfs f12,84(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f13,f12
	cr6.compare(ctx.f13.f64, ctx.f12.f64);
	// bge cr6,0x820a44c8
	if (!cr6.getLT()) goto loc_820A44C8;
	// stfs f12,2872(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 2872, temp.u32);
loc_820A44C8:
	// lwz r11,-1364(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + -1364);
	// lfs f12,84(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,92(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 92);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,96(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 96);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,100(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 100);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * f0.f64));
	// lfs f13,3808(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3808);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f12,f13,f12
	ctx.f12.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f13,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fdivs f0,f11,f10
	f0.f64 = double(float(ctx.f11.f64 / ctx.f10.f64));
	// fdivs f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 / ctx.f9.f64));
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820a450c
	if (!cr6.getGT()) goto loc_820A450C;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
loc_820A450C:
	// lfs f13,3808(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3808);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// stfs f0,3808(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 3808, temp.u32);
	// lfs f13,84(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 84);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgelr cr6
	if (!cr6.getLT()) return;
	// stfs f13,3808(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 3808, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A4530"))) PPC_WEAK_FUNC(sub_820A4530);
PPC_FUNC_IMPL(__imp__sub_820A4530) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r3,4252(r11)
	PPC_STORE_U32(r11.u32 + 4252, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A4540"))) PPC_WEAK_FUNC(sub_820A4540);
PPC_FUNC_IMPL(__imp__sub_820A4540) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f0,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	f0.f64 = double(temp.f32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// stfs f0,3268(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 3268, temp.u32);
	// stfs f0,4204(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4204, temp.u32);
	// lfs f0,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,3272(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 3272, temp.u32);
	// stfs f0,4208(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4208, temp.u32);
	// lfs f0,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,3276(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 3276, temp.u32);
	// stfs f0,4212(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4212, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A4578"))) PPC_WEAK_FUNC(sub_820A4578);
PPC_FUNC_IMPL(__imp__sub_820A4578) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// addi r12,r1,-32
	r12.s64 = ctx.r1.s64 + -32;
	// bl 0x823ed53c
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// fmr f29,f2
	f29.f64 = ctx.f2.f64;
	// fmr f31,f3
	f31.f64 = ctx.f3.f64;
	// fmr f25,f4
	f25.f64 = ctx.f4.f64;
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// fmr f26,f1
	ctx.fpscr.disableFlushMode();
	f26.f64 = ctx.f1.f64;
	// bl 0x8210d8b0
	sub_8210D8B0(ctx, base);
	// lis r31,-32014
	r31.s64 = -2098069504;
	// fmr f27,f1
	ctx.fpscr.disableFlushMode();
	f27.f64 = ctx.f1.f64;
	// lis r29,-32014
	r29.s64 = -2098069504;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f31,4272(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4272, temp.u32);
	// lwz r11,-6384(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f28,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f28.f64 = double(temp.f32);
	// ble cr6,0x820a460c
	if (!cr6.getGT()) goto loc_820A460C;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// fsubs f13,f28,f31
	ctx.f13.f64 = double(float(f28.f64 - f31.f64));
loc_820A45DC:
	// lfs f0,4264(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4264);
	f0.f64 = double(temp.f32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// fsubs f12,f30,f0
	ctx.f12.f64 = double(float(f30.f64 - f0.f64));
	// fmadds f0,f12,f13,f0
	f0.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + f0.f64));
	// stfs f0,4264(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4264, temp.u32);
	// lfs f0,4268(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4268);
	f0.f64 = double(temp.f32);
	// fsubs f12,f29,f0
	ctx.f12.f64 = double(float(f29.f64 - f0.f64));
	// fmadds f0,f12,f13,f0
	f0.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + f0.f64));
	// stfs f0,4268(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4268, temp.u32);
	// lwz r9,-6384(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + -6384);
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// blt cr6,0x820a45dc
	if (cr6.getLT()) goto loc_820A45DC;
loc_820A460C:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r10,r11,4256
	ctx.r10.s64 = r11.s64 + 4256;
	// lfs f0,4264(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4264);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f28
	f0.f64 = double(float(f0.f64 + f28.f64));
	// lfs f31,2692(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2692);
	f31.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// fmuls f0,f0,f26
	f0.f64 = double(float(f0.f64 * f26.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// stfs f0,4256(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4256, temp.u32);
	// lfs f0,4268(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4268);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f28
	f0.f64 = double(float(f0.f64 + f28.f64));
	// fmuls f0,f0,f27
	f0.f64 = double(float(f0.f64 * f27.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// stfs f0,4260(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4260, temp.u32);
	// lfs f0,3908(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 3908);
	f0.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// lfs f13,12468(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 12468);
	ctx.f13.f64 = double(temp.f32);
	// bge cr6,0x820a4668
	if (!cr6.getLT()) goto loc_820A4668;
	// stfs f0,0(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// b 0x820a467c
	goto loc_820A467C;
loc_820A4668:
	// fsubs f12,f26,f13
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = double(float(f26.f64 - ctx.f13.f64));
	// lfs f11,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fcmpu cr6,f11,f12
	cr6.compare(ctx.f11.f64, ctx.f12.f64);
	// ble cr6,0x820a467c
	if (!cr6.getGT()) goto loc_820A467C;
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
loc_820A467C:
	// lfs f12,4260(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4260);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f12,f0
	cr6.compare(ctx.f12.f64, f0.f64);
	// blt cr6,0x820a4694
	if (cr6.getLT()) goto loc_820A4694;
	// fsubs f0,f27,f13
	f0.f64 = double(float(f27.f64 - ctx.f13.f64));
	// fcmpu cr6,f12,f0
	cr6.compare(ctx.f12.f64, f0.f64);
	// ble cr6,0x820a4698
	if (!cr6.getGT()) goto loc_820A4698;
loc_820A4694:
	// stfs f0,4260(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4260, temp.u32);
loc_820A4698:
	// lwz r30,-1364(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// lfs f0,4256(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4256);
	f0.f64 = double(temp.f32);
	// fadds f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 + f0.f64));
	// stfs f0,4256(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 4256, temp.u32);
	// lwz r30,-1364(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// bl 0x8210d8d0
	sub_8210D8D0(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,4260(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4260);
	f0.f64 = double(temp.f32);
	// fadds f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 + f0.f64));
	// stfs f0,4260(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 4260, temp.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stfs f25,4292(r11)
	temp.f32 = float(f25.f64);
	PPC_STORE_U32(r11.u32 + 4292, temp.u32);
	// lwz r11,-6384(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a4710
	if (!cr6.getGT()) goto loc_820A4710;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// fsubs f13,f28,f25
	ctx.f13.f64 = double(float(f28.f64 - f25.f64));
loc_820A46E0:
	// lfs f0,4284(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4284);
	f0.f64 = double(temp.f32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// fsubs f12,f30,f0
	ctx.f12.f64 = double(float(f30.f64 - f0.f64));
	// fmadds f0,f12,f13,f0
	f0.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + f0.f64));
	// stfs f0,4284(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4284, temp.u32);
	// lfs f0,4288(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4288);
	f0.f64 = double(temp.f32);
	// fsubs f12,f29,f0
	ctx.f12.f64 = double(float(f29.f64 - f0.f64));
	// fmadds f0,f12,f13,f0
	f0.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + f0.f64));
	// stfs f0,4288(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4288, temp.u32);
	// lwz r9,-6384(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + -6384);
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// blt cr6,0x820a46e0
	if (cr6.getLT()) goto loc_820A46E0;
loc_820A4710:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// mr r30,r11
	r30.u64 = r11.u64;
	// lfs f0,4284(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4284);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f28
	f0.f64 = double(float(f0.f64 + f28.f64));
	// fmuls f0,f0,f26
	f0.f64 = double(float(f0.f64 * f26.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// stfs f0,4276(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4276, temp.u32);
	// lfs f0,4288(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4288);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f28
	f0.f64 = double(float(f0.f64 + f28.f64));
	// fmuls f0,f0,f27
	f0.f64 = double(float(f0.f64 * f27.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// stfs f0,4280(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4280, temp.u32);
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// lfs f0,4276(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4276);
	f0.f64 = double(temp.f32);
	// fadds f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 + f0.f64));
	// stfs f0,4276(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 4276, temp.u32);
	// lwz r30,-1364(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// bl 0x8210d8d0
	sub_8210D8D0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,4280(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4280);
	ctx.f13.f64 = double(temp.f32);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lfs f1,14108(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14108);
	ctx.f1.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r3,r11,4276
	ctx.r3.s64 = r11.s64 + 4276;
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,4280(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 4280, temp.u32);
	// bl 0x8210d5e0
	sub_8210D5E0(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f13,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,2796(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2796);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,2800(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2800, temp.u32);
	// lfs f0,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
	// stfs f0,2804(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2804, temp.u32);
	// lfs f0,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	f0.f64 = double(temp.f32);
	// stfs f0,2808(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2808, temp.u32);
	// lfs f0,3732(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3732);
	f0.f64 = double(temp.f32);
	// lfs f13,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,3736(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 3736, temp.u32);
	// lfs f0,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
	// stfs f0,3740(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 3740, temp.u32);
	// lfs f0,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	f0.f64 = double(temp.f32);
	// stfs f0,3744(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 3744, temp.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// addi r12,r1,-32
	r12.s64 = ctx.r1.s64 + -32;
	// bl 0x823ed588
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820A47D8"))) PPC_WEAK_FUNC(sub_820A47D8);
PPC_FUNC_IMPL(__imp__sub_820A47D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,2344(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// mulli r10,r10,56
	ctx.r10.s64 = ctx.r10.s64 * 56;
	// addi r9,r11,8
	ctx.r9.s64 = r11.s64 + 8;
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a480c
	if (!cr6.getEQ()) goto loc_820A480C;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x820a4814
	goto loc_820A4814;
loc_820A480C:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
loc_820A4814:
	// lfs f4,60(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 60);
	ctx.f4.f64 = double(temp.f32);
	// fcmpu cr6,f4,f3
	cr6.compare(ctx.f4.f64, ctx.f3.f64);
	// bge cr6,0x820a4824
	if (!cr6.getLT()) goto loc_820A4824;
	// fmr f4,f3
	ctx.f4.f64 = ctx.f3.f64;
loc_820A4824:
	// b 0x820a4578
	sub_820A4578(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820A4828"))) PPC_WEAK_FUNC(sub_820A4828);
PPC_FUNC_IMPL(__imp__sub_820A4828) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stfd f29,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, f29.u64);
	// stfd f30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, f30.u64);
	// stfd f31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// fmr f30,f2
	f30.f64 = ctx.f2.f64;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// addi r8,r10,8
	ctx.r8.s64 = ctx.r10.s64 + 8;
	// lwz r9,2344(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// mulli r9,r9,56
	ctx.r9.s64 = ctx.r9.s64 * 56;
	// lwzx r8,r9,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r8.u32);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820a487c
	if (!cr6.getEQ()) goto loc_820A487C;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// b 0x820a4884
	goto loc_820A4884;
loc_820A487C:
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// addi r10,r10,1240
	ctx.r10.s64 = ctx.r10.s64 + 1240;
loc_820A4884:
	// lfs f0,4264(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4264);
	f0.f64 = double(temp.f32);
	// fsubs f12,f31,f0
	ctx.f12.f64 = double(float(f31.f64 - f0.f64));
	// lfs f13,4268(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4268);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f11,f30,f13
	ctx.f11.f64 = double(float(f30.f64 - ctx.f13.f64));
	// lfs f29,60(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 60);
	f29.f64 = double(temp.f32);
	// lfs f0,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
	// fmuls f13,f12,f0
	ctx.f13.f64 = double(float(ctx.f12.f64 * f0.f64));
	// fmuls f0,f11,f0
	f0.f64 = double(float(ctx.f11.f64 * f0.f64));
	// fmuls f13,f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f13.f64));
	// fmadds f1,f0,f0,f13
	ctx.f1.f64 = double(float(f0.f64 * f0.f64 + ctx.f13.f64));
	// bl 0x8238ca50
	sub_8238CA50(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,14116(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14116);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// bge cr6,0x820a48d0
	if (!cr6.getLT()) goto loc_820A48D0;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lfs f2,15856(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15856);
	ctx.f2.f64 = double(temp.f32);
	// b 0x820a4910
	goto loc_820A4910;
loc_820A48D0:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,12900(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12900);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fcmpu cr6,f1,f13
	cr6.compare(ctx.f1.f64, ctx.f13.f64);
	// ble cr6,0x820a48ec
	if (!cr6.getGT()) goto loc_820A48EC;
	// lfs f2,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f2.f64 = double(temp.f32);
	// b 0x820a4910
	goto loc_820A4910;
loc_820A48EC:
	// lfs f13,2776(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// fsubs f12,f1,f0
	ctx.f12.f64 = double(float(ctx.f1.f64 - f0.f64));
	// lfs f0,15856(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15856);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f11,f13,f0
	ctx.f11.f64 = double(float(ctx.f13.f64 - f0.f64));
	// lfs f13,2780(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2780);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fmadds f2,f12,f13,f0
	ctx.f2.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + f0.f64));
loc_820A4910:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,14112(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14112);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8238c818
	sub_8238C818(ctx, base);
	// fmr f3,f1
	ctx.fpscr.disableFlushMode();
	ctx.f3.f64 = ctx.f1.f64;
	// fmr f4,f29
	ctx.f4.f64 = f29.f64;
	// fmr f2,f30
	ctx.f2.f64 = f30.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x820a4578
	sub_820A4578(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f29,-32(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// lfd f30,-24(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// lfd f31,-16(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A4950"))) PPC_WEAK_FUNC(sub_820A4950);
PPC_FUNC_IMPL(__imp__sub_820A4950) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// lfs f0,4256(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4256);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// lfs f0,4260(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4260);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r4)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A4970"))) PPC_WEAK_FUNC(sub_820A4970);
PPC_FUNC_IMPL(__imp__sub_820A4970) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,0(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f0,4(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 4, temp.u32);
	// stfs f0,8(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// lfs f1,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f1.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// addi r3,r11,4256
	ctx.r3.s64 = r11.s64 + 4256;
	// b 0x8210d5e0
	sub_8210D5E0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820A49A0"))) PPC_WEAK_FUNC(sub_820A49A0);
PPC_FUNC_IMPL(__imp__sub_820A49A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed548
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r30,-32014
	r30.s64 = -2098069504;
	// mulli r10,r5,936
	ctx.r10.s64 = ctx.r5.s64 * 936;
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// add r7,r10,r11
	ctx.r7.u64 = ctx.r10.u64 + r11.u64;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// addi r10,r11,6504
	ctx.r10.s64 = r11.s64 + 6504;
	// lwz r8,2344(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + 2344);
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// mulli r11,r8,56
	r11.s64 = ctx.r8.s64 * 56;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// lis r9,-32190
	ctx.r9.s64 = -2109603840;
	// addi r6,r9,1240
	ctx.r6.s64 = ctx.r9.s64 + 1240;
	// bne cr6,0x820a4a00
	if (!cr6.getEQ()) goto loc_820A4A00;
	// addi r9,r10,12
	ctx.r9.s64 = ctx.r10.s64 + 12;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// b 0x820a4a04
	goto loc_820A4A04;
loc_820A4A00:
	// mr r9,r6
	ctx.r9.u64 = ctx.r6.u64;
loc_820A4A04:
	// lwz r11,2348(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 2348);
	// lfs f13,48(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 48);
	ctx.f13.f64 = double(temp.f32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a4a18
	if (!cr6.getLT()) goto loc_820A4A18;
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
loc_820A4A18:
	// mulli r11,r11,56
	r11.s64 = r11.s64 * 56;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a4a38
	if (!cr6.getEQ()) goto loc_820A4A38;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820a4a3c
	goto loc_820A4A3C;
loc_820A4A38:
	// mr r11,r6
	r11.u64 = ctx.r6.u64;
loc_820A4A3C:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a4a64
	if (cr6.getEQ()) goto loc_820A4A64;
	// lwz r11,3264(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 3264);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x820a4a64
	if (!cr6.getEQ()) goto loc_820A4A64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,12900(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12900);
	f0.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
loc_820A4A64:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,12464(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12464);
	f0.f64 = double(temp.f32);
	// fmuls f31,f13,f0
	f31.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x8210e390
	sub_8210E390(ctx, base);
	// fdivs f30,f31,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = double(float(f31.f64 / ctx.f1.f64));
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r29,r11,r29
	r29.u64 = r11.u64 + r29.u64;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r28,r3,31
	r28.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lfs f31,14028(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14028);
	f31.f64 = double(temp.f32);
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// clrldi r10,r29,32
	ctx.r10.u64 = r29.u64 & 0xFFFFFFFF;
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// std r10,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r10.u64);
	// lfs f29,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f29.f64 = double(temp.f32);
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// lfd f0,88(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * f31.f64));
	// fmsubs f0,f0,f31,f29
	f0.f64 = double(float(f0.f64 * f31.f64 - f29.f64));
	// fmuls f28,f13,f0
	f28.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// fmuls f0,f1,f28
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 * f28.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f13,f0,f30
	ctx.f13.f64 = double(float(f0.f64 * f30.f64));
	// lfs f0,14124(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14124);
	f0.f64 = double(temp.f32);
	// fmuls f28,f13,f0
	f28.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x8210d8e0
	sub_8210D8E0(ctx, base);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lfs f13,4256(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4256);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,14120(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14120);
	f0.f64 = double(temp.f32);
	// fmuls f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 * f0.f64));
	// fdivs f0,f28,f0
	f0.f64 = double(float(f28.f64 / f0.f64));
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r29,r11,r29
	r29.u64 = r11.u64 + r29.u64;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r28,r3,31
	r28.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// clrldi r10,r29,32
	ctx.r10.u64 = r29.u64 & 0xFFFFFFFF;
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r10,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r10.u64);
	// std r11,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, r11.u64);
	// lfd f0,96(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmsubs f0,f0,f31,f29
	f0.f64 = double(float(f0.f64 * f31.f64 - f29.f64));
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * f31.f64));
	// fmuls f31,f13,f0
	f31.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x8210d8b0
	sub_8210D8B0(ctx, base);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// fmr f12,f1
	ctx.fpscr.disableFlushMode();
	ctx.f12.f64 = ctx.f1.f64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f11,4260(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4260);
	ctx.f11.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,12008(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12008);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// stfs f0,4(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// fmuls f0,f12,f31
	f0.f64 = double(float(ctx.f12.f64 * f31.f64));
	// lfs f1,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f1.f64 = double(temp.f32);
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// fmadds f0,f0,f13,f11
	f0.f64 = double(float(f0.f64 * ctx.f13.f64 + ctx.f11.f64));
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// bl 0x8210d5e0
	sub_8210D5E0(ctx, base);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// addi r12,r1,-48
	r12.s64 = ctx.r1.s64 + -48;
	// bl 0x823ed594
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820A4BE0"))) PPC_WEAK_FUNC(sub_820A4BE0);
PPC_FUNC_IMPL(__imp__sub_820A4BE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// addi r11,r11,-5944
	r11.s64 = r11.s64 + -5944;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r31,r11
	r31.u64 = r11.u64;
loc_820A4C04:
	// lwz r9,100(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820a4c38
	if (cr6.getEQ()) goto loc_820A4C38;
	// addi r31,r31,104
	r31.s64 = r31.s64 + 104;
	// addi r9,r11,2080
	ctx.r9.s64 = r11.s64 + 2080;
	// cmplw cr6,r31,r9
	cr6.compare<uint32_t>(r31.u32, ctx.r9.u32, xer);
	// blt cr6,0x820a4c04
	if (cr6.getLT()) goto loc_820A4C04;
loc_820A4C20:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_820A4C38:
	// addi r11,r11,2080
	r11.s64 = r11.s64 + 2080;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// bge cr6,0x820a4c20
	if (!cr6.getLT()) goto loc_820A4C20;
	// stw r10,100(r31)
	PPC_STORE_U32(r31.u32 + 100, ctx.r10.u32);
	// lfs f0,48(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 48);
	f0.f64 = double(temp.f32);
	// stfs f0,4(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// addi r4,r31,28
	ctx.r4.s64 = r31.s64 + 28;
	// lfs f0,52(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 52);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// lfs f0,56(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 56);
	f0.f64 = double(temp.f32);
	// stfs f0,12(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
	// bl 0x8210b270
	sub_8210B270(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A4C80"))) PPC_WEAK_FUNC(sub_820A4C80);
PPC_FUNC_IMPL(__imp__sub_820A4C80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stfd f29,-80(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -80, f29.u64);
	// stfd f30,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, f30.u64);
	// stfd f31,-64(r1)
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r29,-32014
	r29.s64 = -2098069504;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r28,r31,936
	r28.s64 = r31.s64 * 936;
	// lwz r10,-1364(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// add r10,r28,r10
	ctx.r10.u64 = r28.u64 + ctx.r10.u64;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// addi r9,r11,8
	ctx.r9.s64 = r11.s64 + 8;
	// lwz r30,2344(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2344);
	// mulli r10,r30,56
	ctx.r10.s64 = r30.s64 * 56;
	// lwzx r9,r10,r9
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a4cdc
	if (!cr6.getEQ()) goto loc_820A4CDC;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x820a4ce4
	goto loc_820A4CE4;
loc_820A4CDC:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
loc_820A4CE4:
	// lwz r27,40(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 40);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x820a524c
	if (cr6.getEQ()) goto loc_820A524C;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bgt cr6,0x820a524c
	if (cr6.getGT()) goto loc_820A524C;
	// addi r11,r31,584
	r11.s64 = r31.s64 + 584;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lwz r9,8(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820a4d7c
	if (cr6.getEQ()) goto loc_820A4D7C;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lfs f0,14176(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14176);
	f0.f64 = double(temp.f32);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,88(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f13,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,92(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// lfs f13,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// bl 0x8210c818
	sub_8210C818(ctx, base);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// addi r3,r11,2960
	ctx.r3.s64 = r11.s64 + 2960;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// b 0x820a4d88
	goto loc_820A4D88;
loc_820A4D7C:
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// addi r3,r11,2960
	ctx.r3.s64 = r11.s64 + 2960;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
loc_820A4D88:
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x820a4be0
	sub_820A4BE0(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a524c
	if (cr6.getEQ()) goto loc_820A524C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f31,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// lfs f30,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f30.f64 = double(temp.f32);
	// stfs f30,88(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// stfs f30,92(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// stfs f30,96(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// beq cr6,0x820a4fb4
	if (cr6.getEQ()) goto loc_820A4FB4;
	// cmpwi cr6,r30,5
	cr6.compare<int32_t>(r30.s32, 5, xer);
	// beq cr6,0x820a4fb4
	if (cr6.getEQ()) goto loc_820A4FB4;
	// cmpwi cr6,r30,6
	cr6.compare<int32_t>(r30.s32, 6, xer);
	// beq cr6,0x820a4fb4
	if (cr6.getEQ()) goto loc_820A4FB4;
	// cmpwi cr6,r30,20
	cr6.compare<int32_t>(r30.s32, 20, xer);
	// beq cr6,0x820a4fb4
	if (cr6.getEQ()) goto loc_820A4FB4;
	// cmpwi cr6,r30,21
	cr6.compare<int32_t>(r30.s32, 21, xer);
	// beq cr6,0x820a4fb4
	if (cr6.getEQ()) goto loc_820A4FB4;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// addi r27,r31,16
	r27.s64 = r31.s64 + 16;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f0,14172(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14172);
	f0.f64 = double(temp.f32);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,14028(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14028);
	f31.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 * f31.f64));
	// lfs f13,14168(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14168);
	ctx.f13.f64 = double(temp.f32);
	// fnmadds f0,f12,f0,f13
	f0.f64 = double(float(-(ctx.f12.f64 * f0.f64 + ctx.f13.f64)));
	// stfs f0,16(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 16, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// stfs f30,24(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 24, temp.u32);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f0,14164(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14164);
	f0.f64 = double(temp.f32);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 * f31.f64));
	// lfs f13,14160(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14160);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// addi r3,r11,2960
	ctx.r3.s64 = r11.s64 + 2960;
	// fmadds f0,f12,f0,f13
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// stfs f0,20(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f30,14156(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14156);
	f30.f64 = double(temp.f32);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f29,14152(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14152);
	f29.f64 = double(temp.f32);
	// lfd f0,80(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// fmsubs f0,f0,f30,f29
	f0.f64 = double(float(f0.f64 * f30.f64 - f29.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// fmsubs f0,f0,f30,f29
	f0.f64 = double(float(f0.f64 * f30.f64 - f29.f64));
	// stfs f0,92(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// fmsubs f0,f0,f30,f29
	f0.f64 = double(float(f0.f64 * f30.f64 - f29.f64));
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// bl 0x8210ba08
	sub_8210BA08(ctx, base);
	// addi r4,r31,64
	ctx.r4.s64 = r31.s64 + 64;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// bl 0x8210b270
	sub_8210B270(ctx, base);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// rlwinm r11,r11,8,24,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 8) & 0xFF;
	// mulli r11,r11,30303
	r11.s64 = r11.s64 * 30303;
	// srawi r11,r11,10
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x3FF) != 0);
	r11.s64 = r11.s32 >> 10;
	// addi r30,r11,30303
	r30.s64 = r11.s64 + 30303;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r26,r3,31
	r26.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f13,14148(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14148);
	ctx.f13.f64 = double(temp.f32);
	// add r10,r11,r26
	ctx.r10.u64 = r11.u64 + r26.u64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f9,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	ctx.f9.f64 = double(temp.f32);
	// divwu r11,r10,r30
	r11.u32 = ctx.r10.u32 / r30.u32;
	// mullw r11,r11,r30
	r11.s64 = int64_t(r11.s32) * int64_t(r30.s32);
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lfd f0,80(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// b 0x820a5184
	goto loc_820A5184;
loc_820A4FB4:
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// addi r27,r31,16
	r27.s64 = r31.s64 + 16;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f0,14144(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14144);
	f0.f64 = double(temp.f32);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,14028(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14028);
	f31.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 * f31.f64));
	// lfs f13,14140(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14140);
	ctx.f13.f64 = double(temp.f32);
	// fnmadds f0,f12,f0,f13
	f0.f64 = double(float(-(ctx.f12.f64 * f0.f64 + ctx.f13.f64)));
	// stfs f0,16(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 16, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// stfs f30,24(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 24, temp.u32);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f0,14136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14136);
	f0.f64 = double(temp.f32);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 * f31.f64));
	// lfs f13,14132(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14132);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// addi r3,r11,2960
	ctx.r3.s64 = r11.s64 + 2960;
	// fmadds f0,f12,f0,f13
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// stfs f0,20(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f30,14156(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14156);
	f30.f64 = double(temp.f32);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f29,14152(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14152);
	f29.f64 = double(temp.f32);
	// lfd f0,80(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// fmsubs f0,f0,f30,f29
	f0.f64 = double(float(f0.f64 * f30.f64 - f29.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// fmsubs f0,f0,f30,f29
	f0.f64 = double(float(f0.f64 * f30.f64 - f29.f64));
	// stfs f0,92(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// fmsubs f0,f0,f30,f29
	f0.f64 = double(float(f0.f64 * f30.f64 - f29.f64));
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// bl 0x8210ba08
	sub_8210BA08(ctx, base);
	// addi r4,r31,64
	ctx.r4.s64 = r31.s64 + 64;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// bl 0x8210b270
	sub_8210B270(ctx, base);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// rlwinm r11,r11,8,24,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 8) & 0xFF;
	// mulli r11,r11,30303
	r11.s64 = r11.s64 * 30303;
	// srawi r11,r11,10
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x3FF) != 0);
	r11.s64 = r11.s32 >> 10;
	// addi r30,r11,30303
	r30.s64 = r11.s64 + 30303;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r26,r3,31
	r26.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f13,14148(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14148);
	ctx.f13.f64 = double(temp.f32);
	// add r10,r11,r26
	ctx.r10.u64 = r11.u64 + r26.u64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f9,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	ctx.f9.f64 = double(temp.f32);
	// divwu r11,r10,r30
	r11.u32 = ctx.r10.u32 / r30.u32;
	// mullw r11,r11,r30
	r11.s64 = int64_t(r11.s32) * int64_t(r30.s32);
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lfd f0,80(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
loc_820A5184:
	// fcfid f0,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(f0.s64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// twllei r30,0
	// lfs f7,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f7.f64 = double(temp.f32);
	// lfs f11,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// lfs f6,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f6.f64 = double(temp.f32);
	// lfs f10,24(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 24);
	ctx.f10.f64 = double(temp.f32);
	// lfs f8,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// frsp f5,f0
	ctx.f5.f64 = double(float(f0.f64));
	// lfs f0,14128(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14128);
	f0.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// fmuls f0,f5,f0
	f0.f64 = double(float(ctx.f5.f64 * f0.f64));
	// fnmsubs f13,f0,f13,f12
	ctx.f13.f64 = double(float(-(f0.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// stfs f13,20(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// fmadds f7,f11,f0,f7
	ctx.f7.f64 = double(float(ctx.f11.f64 * f0.f64 + ctx.f7.f64));
	// stfs f7,4(r31)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// fmadds f7,f10,f0,f6
	ctx.f7.f64 = double(float(ctx.f10.f64 * f0.f64 + ctx.f6.f64));
	// stfs f7,12(r31)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
	// fadds f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// fmuls f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * f0.f64));
	// fmadds f0,f0,f9,f8
	f0.f64 = double(float(f0.f64 * ctx.f9.f64 + ctx.f8.f64));
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// lwz r11,-6384(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a524c
	if (!cr6.getGT()) goto loc_820A524C;
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// lfs f0,3008(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3008);
	f0.f64 = double(temp.f32);
	// lfs f12,3072(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3072);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f0,f12
	ctx.f12.f64 = double(float(f0.f64 - ctx.f12.f64));
	// lfs f0,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fdivs f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 / f0.f64));
	// fadds f0,f0,f11
	f0.f64 = double(float(f0.f64 + ctx.f11.f64));
	// stfs f0,0(r27)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r27.u32 + 0, temp.u32);
	// lfs f0,3012(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3012);
	f0.f64 = double(temp.f32);
	// lfs f12,3076(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3076);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f0,f12
	ctx.f12.f64 = double(float(f0.f64 - ctx.f12.f64));
	// lfs f0,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fdivs f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 / f0.f64));
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,20(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// lfs f0,3016(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3016);
	f0.f64 = double(temp.f32);
	// lfs f13,3080(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3080);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f0,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fdivs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 / f0.f64));
	// fadds f0,f0,f10
	f0.f64 = double(float(f0.f64 + ctx.f10.f64));
	// stfs f0,24(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 24, temp.u32);
loc_820A524C:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// lfd f29,-80(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// lfd f30,-72(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f31,-64(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820A5260"))) PPC_WEAK_FUNC(sub_820A5260);
PPC_FUNC_IMPL(__imp__sub_820A5260) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lfs f0,-6368(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6368);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,14148(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14148);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fnmsubs f12,f0,f12,f13
	ctx.f12.f64 = double(float(-(f0.f64 * ctx.f12.f64 - ctx.f13.f64)));
	// lfs f11,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	ctx.f11.f64 = double(temp.f32);
	// fadds f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fmadds f13,f13,f11,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 + ctx.f10.f64));
	// stfs f13,8(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// fcmpu cr6,f13,f9
	cr6.compare(ctx.f13.f64, ctx.f9.f64);
	// bge cr6,0x820a5328
	if (!cr6.getLT()) goto loc_820A5328;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r5,r11,-5952
	ctx.r5.s64 = r11.s64 + -5952;
	// lwz r11,0(r5)
	r11.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a5318
	if (!cr6.getEQ()) goto loc_820A5318;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-6384(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a5318
	if (!cr6.getGT()) goto loc_820A5318;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,2380(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2380);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// beq cr6,0x820a5318
	if (cr6.getEQ()) goto loc_820A5318;
	// lwz r11,3316(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 3316);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x820a5318
	if (cr6.getEQ()) goto loc_820A5318;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,6919
	ctx.r8.s64 = 6919;
	// addi r7,r11,13992
	ctx.r7.s64 = r11.s64 + 13992;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// li r4,122
	ctx.r4.s64 = 122;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
loc_820A5318:
	// li r11,0
	r11.s64 = 0;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_820A5328:
	// lis r29,-32014
	r29.s64 = -2098069504;
	// lfs f13,4(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,16(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 16);
	ctx.f10.f64 = double(temp.f32);
	// li r30,0
	r30.s64 = 0;
	// lfs f11,12(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f13,f10,f0,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 * f0.f64 + ctx.f13.f64));
	// lfs f9,24(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 24);
	ctx.f9.f64 = double(temp.f32);
	// fmadds f0,f9,f0,f11
	f0.f64 = double(float(ctx.f9.f64 * f0.f64 + ctx.f11.f64));
	// stfs f12,20(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// stfs f13,4(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// stfs f0,12(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
	// lwz r11,-6384(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a5384
	if (!cr6.getGT()) goto loc_820A5384;
	// addi r28,r31,28
	r28.s64 = r31.s64 + 28;
	// addi r31,r31,64
	r31.s64 = r31.s64 + 64;
loc_820A5368:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8210c6e8
	sub_8210C6E8(ctx, base);
	// lwz r11,-6384(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -6384);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmpw cr6,r30,r11
	cr6.compare<int32_t>(r30.s32, r11.s32, xer);
	// blt cr6,0x820a5368
	if (cr6.getLT()) goto loc_820A5368;
loc_820A5384:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820A5390"))) PPC_WEAK_FUNC(sub_820A5390);
PPC_FUNC_IMPL(__imp__sub_820A5390) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r30,r11,-5944
	r30.s64 = r11.s64 + -5944;
	// mr r31,r30
	r31.u64 = r30.u64;
loc_820A53B0:
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a53c4
	if (cr6.getEQ()) goto loc_820A53C4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820a5260
	sub_820A5260(ctx, base);
loc_820A53C4:
	// addi r31,r31,104
	r31.s64 = r31.s64 + 104;
	// addi r11,r30,2080
	r11.s64 = r30.s64 + 2080;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// blt cr6,0x820a53b0
	if (cr6.getLT()) goto loc_820A53B0;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A53F0"))) PPC_WEAK_FUNC(sub_820A53F0);
PPC_FUNC_IMPL(__imp__sub_820A53F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r30,100(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// lhz r11,14(r30)
	r11.u64 = PPC_LOAD_U16(r30.u32 + 14);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// rlwinm r3,r11,6,0,25
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0xFFFFFFC0;
	// bl 0x8209cd50
	sub_8209CD50(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r28,1
	r28.s64 = 1;
	// bl 0x8211c6c8
	sub_8211C6C8(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8211c930
	sub_8211C930(ctx, base);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r31,28
	ctx.r3.s64 = r31.s64 + 28;
	// stw r29,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r29.u32);
	// bl 0x8210b208
	sub_8210B208(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// lfs f1,14176(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14176);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// lwz r31,92(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// addi r30,r1,112
	r30.s64 = ctx.r1.s64 + 112;
	// bl 0x8210d820
	sub_8210D820(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// bl 0x8210b450
	sub_8210B450(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// lfs f13,14184(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14184);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,48(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 48);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// lfs f12,14180(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14180);
	ctx.f12.f64 = double(temp.f32);
	// bgt cr6,0x820a54a0
	if (cr6.getGT()) goto loc_820A54A0;
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bge cr6,0x820a54a4
	if (!cr6.getLT()) goto loc_820A54A4;
loc_820A54A0:
	// li r28,0
	r28.s64 = 0;
loc_820A54A4:
	// lfs f0,52(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 52);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x820a54b8
	if (cr6.getGT()) goto loc_820A54B8;
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bge cr6,0x820a54bc
	if (!cr6.getLT()) goto loc_820A54BC;
loc_820A54B8:
	// li r28,0
	r28.s64 = 0;
loc_820A54BC:
	// lfs f0,56(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 56);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x820a54f8
	if (cr6.getGT()) goto loc_820A54F8;
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// blt cr6,0x820a54f8
	if (cr6.getLT()) goto loc_820A54F8;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x820a54f8
	if (cr6.getEQ()) goto loc_820A54F8;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,255
	ctx.r5.s64 = 255;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8209ab98
	sub_8209AB98(ctx, base);
loc_820A54F8:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820A5500"))) PPC_WEAK_FUNC(sub_820A5500);
PPC_FUNC_IMPL(__imp__sub_820A5500) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r30,r11,-5944
	r30.s64 = r11.s64 + -5944;
	// mr r31,r30
	r31.u64 = r30.u64;
loc_820A5520:
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a5534
	if (cr6.getEQ()) goto loc_820A5534;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820a53f0
	sub_820A53F0(ctx, base);
loc_820A5534:
	// addi r31,r31,104
	r31.s64 = r31.s64 + 104;
	// addi r11,r30,2080
	r11.s64 = r30.s64 + 2080;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// blt cr6,0x820a5520
	if (cr6.getLT()) goto loc_820A5520;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A5560"))) PPC_WEAK_FUNC(sub_820A5560);
PPC_FUNC_IMPL(__imp__sub_820A5560) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,4380(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4380);
	// beq cr6,0x820a5580
	if (cr6.getEQ()) goto loc_820A5580;
	// andc r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r3.u64;
	// stw r10,4380(r11)
	PPC_STORE_U32(r11.u32 + 4380, ctx.r10.u32);
	// blr 
	return;
loc_820A5580:
	// or r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 | ctx.r3.u64;
	// stw r10,4380(r11)
	PPC_STORE_U32(r11.u32 + 4380, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A5590"))) PPC_WEAK_FUNC(sub_820A5590);
PPC_FUNC_IMPL(__imp__sub_820A5590) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// addi r11,r3,1145
	r11.s64 = ctx.r3.s64 + 1145;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A55A8"))) PPC_WEAK_FUNC(sub_820A55A8);
PPC_FUNC_IMPL(__imp__sub_820A55A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// rlwinm r10,r3,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// add r10,r3,r10
	ctx.r10.u64 = ctx.r3.u64 + ctx.r10.u64;
	// addi r11,r11,15496
	r11.s64 = r11.s64 + 15496;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A55C8"))) PPC_WEAK_FUNC(sub_820A55C8);
PPC_FUNC_IMPL(__imp__sub_820A55C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mulli r10,r3,936
	ctx.r10.s64 = ctx.r3.s64 * 936;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r3,2388(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 2388);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A55E0"))) PPC_WEAK_FUNC(sub_820A55E0);
PPC_FUNC_IMPL(__imp__sub_820A55E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r3,56
	r11.s64 = ctx.r3.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a560c
	if (!cr6.getEQ()) goto loc_820A560C;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// blr 
	return;
loc_820A560C:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A5620"))) PPC_WEAK_FUNC(sub_820A5620);
PPC_FUNC_IMPL(__imp__sub_820A5620) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r3,56
	r11.s64 = ctx.r3.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a5648
	if (!cr6.getEQ()) goto loc_820A5648;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820a5650
	goto loc_820A5650;
loc_820A5648:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
loc_820A5650:
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// addi r11,r11,1145
	r11.s64 = r11.s64 + 1145;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A5670"))) PPC_WEAK_FUNC(sub_820A5670);
PPC_FUNC_IMPL(__imp__sub_820A5670) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r3,56
	r11.s64 = ctx.r3.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a5698
	if (!cr6.getEQ()) goto loc_820A5698;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820a56a0
	goto loc_820A56A0;
loc_820A5698:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
loc_820A56A0:
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r10,r10,15496
	ctx.r10.s64 = ctx.r10.s64 + 15496;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r10
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A56C0"))) PPC_WEAK_FUNC(sub_820A56C0);
PPC_FUNC_IMPL(__imp__sub_820A56C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r10
	r31.u64 = ctx.r10.u64;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// lfs f0,2692(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2692);
	f0.f64 = double(temp.f32);
	// srawi r10,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r10.s64 = r11.s32 >> 1;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r11,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, r11.u64);
	// lfd f13,136(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// std r10,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r10.u64);
	// lfd f12,128(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// fmsubs f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 - ctx.f12.f64));
	// beq cr6,0x820a5720
	if (cr6.getEQ()) goto loc_820A5720;
	// fneg f13,f13
	ctx.f13.u64 = ctx.f13.u64 ^ 0x8000000000000000;
loc_820A5720:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fadds f13,f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f1.f64));
	// stfs f13,128(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f13,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,12(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// fcmpu cr6,f2,f13
	cr6.compare(ctx.f2.f64, ctx.f13.f64);
	// blt cr6,0x820a5758
	if (cr6.getLT()) goto loc_820A5758;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, r11.u64);
	// lfd f13,136(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fnmsubs f13,f13,f0,f2
	ctx.f13.f64 = double(float(-(ctx.f13.f64 * f0.f64 - ctx.f2.f64)));
	// b 0x820a5794
	goto loc_820A5794;
loc_820A5758:
	// srawi r10,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r10.s64 = r11.s32 >> 1;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r11,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, r11.u64);
	// lfd f13,136(r1)
	ctx.fpscr.disableFlushMode();
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// std r10,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r10.u64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// lfd f12,144(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// fnmsubs f13,f13,f0,f12
	ctx.f13.f64 = double(float(-(ctx.f13.f64 * f0.f64 - ctx.f12.f64)));
	// fadds f13,f13,f3
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f3.f64));
	// fadds f13,f13,f4
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f4.f64));
loc_820A5794:
	// li r11,2
	r11.s64 = 2;
	// lwz r6,8(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwz r7,12(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	// stfs f13,132(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// extsw r31,r7
	r31.s64 = ctx.r7.s32;
	// lwz r8,276(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 276);
	// lwz r5,268(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 268);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
	// extsw r11,r6
	r11.s64 = ctx.r6.s32;
	// lwz r4,260(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	// std r31,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, r31.u64);
	// lfd f12,136(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// stw r8,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r8.u32);
	// std r11,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, r11.u64);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r5,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, ctx.r5.u32);
	// addi r5,r1,136
	ctx.r5.s64 = ctx.r1.s64 + 136;
	// stw r4,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r4.u32);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// lfd f13,144(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,136(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fmuls f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * f0.f64));
	// stfs f0,140(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// bl 0x8214ab68
	sub_8214AB68(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A5828"))) PPC_WEAK_FUNC(sub_820A5828);
PPC_FUNC_IMPL(__imp__sub_820A5828) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed124
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r31,0
	r31.s64 = 0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r27,-31994
	r27.s64 = -2096758784;
	// lis r28,-31991
	r28.s64 = -2096562176;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// stw r31,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r31.u32);
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lfs f1,6580(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6580);
	ctx.f1.f64 = double(temp.f32);
	// mr r23,r8
	r23.u64 = ctx.r8.u64;
	// stw r31,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r31.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r31,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r31.u32);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// stw r31,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r31.u32);
	// addi r4,r1,120
	ctx.r4.s64 = ctx.r1.s64 + 120;
	// addi r3,r1,124
	ctx.r3.s64 = ctx.r1.s64 + 124;
	// mr r24,r6
	r24.u64 = ctx.r6.u64;
	// lwz r6,-31544(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + -31544);
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// lwz r7,15120(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 15120);
	// bl 0x8213e098
	sub_8213E098(ctx, base);
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// bne cr6,0x820a589c
	if (!cr6.getEQ()) goto loc_820A589C;
	// stw r26,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r26.u32);
	// b 0x820a58d0
	goto loc_820A58D0;
loc_820A589C:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x820a58b0
	if (!cr6.getEQ()) goto loc_820A58B0;
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// subf r11,r11,r26
	r11.s64 = r26.s64 - r11.s64;
	// b 0x820a58cc
	goto loc_820A58CC;
loc_820A58B0:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// bne cr6,0x820a58d0
	if (!cr6.getEQ()) goto loc_820A58D0;
	// lwz r11,120(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// srawi r10,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r10.s64 = r11.s32 >> 1;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// add r11,r11,r26
	r11.u64 = r11.u64 + r26.u64;
loc_820A58CC:
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
loc_820A58D0:
	// cmpwi cr6,r25,1
	cr6.compare<int32_t>(r25.s32, 1, xer);
	// bne cr6,0x820a58e0
	if (!cr6.getEQ()) goto loc_820A58E0;
	// stw r24,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r24.u32);
	// b 0x820a5914
	goto loc_820A5914;
loc_820A58E0:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bne cr6,0x820a58f4
	if (!cr6.getEQ()) goto loc_820A58F4;
	// lwz r11,124(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// subf r11,r11,r24
	r11.s64 = r24.s64 - r11.s64;
	// b 0x820a5910
	goto loc_820A5910;
loc_820A58F4:
	// cmpwi cr6,r25,2
	cr6.compare<int32_t>(r25.s32, 2, xer);
	// bne cr6,0x820a5914
	if (!cr6.getEQ()) goto loc_820A5914;
	// lwz r11,124(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// srawi r10,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r10.s64 = r11.s32 >> 1;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// add r11,r11,r24
	r11.u64 = r11.u64 + r24.u64;
loc_820A5910:
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
loc_820A5914:
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// beq cr6,0x820a596c
	if (cr6.getEQ()) goto loc_820A596C;
	// bl 0x8210e198
	sub_8210E198(ctx, base);
	// extsh r30,r3
	r30.s64 = ctx.r3.s16;
	// bl 0x8210e188
	sub_8210E188(ctx, base);
	// li r11,-1
	r11.s64 = -1;
	// lis r9,25700
	ctx.r9.s64 = 1684275200;
	// lwz r7,15120(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 15120);
	// extsh r10,r3
	ctx.r10.s64 = ctx.r3.s16;
	// lwz r6,-31544(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + -31544);
	// ori r9,r9,25855
	ctx.r9.u64 = ctx.r9.u64 | 25855;
	// stw r30,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r30.u32);
	// li r8,-1
	ctx.r8.s64 = -1;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x8213e398
	sub_8213E398(ctx, base);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed174
	return;
loc_820A596C:
	// bl 0x8210e198
	sub_8210E198(ctx, base);
	// extsh r30,r3
	r30.s64 = ctx.r3.s16;
	// bl 0x8210e188
	sub_8210E188(ctx, base);
	// li r11,-1
	r11.s64 = -1;
	// lis r8,255
	ctx.r8.s64 = 16711680;
	// lwz r7,15120(r27)
	ctx.r7.u64 = PPC_LOAD_U32(r27.u32 + 15120);
	// extsh r9,r3
	ctx.r9.s64 = ctx.r3.s16;
	// lwz r6,-31544(r28)
	ctx.r6.u64 = PPC_LOAD_U32(r28.u32 + -31544);
	// ori r8,r8,176
	ctx.r8.u64 = ctx.r8.u64 | 176;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// stw r31,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r31.u32);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// bl 0x8213e0d8
	sub_8213E0D8(ctx, base);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed174
	return;
}

__attribute__((alias("__imp__sub_820A59B8"))) PPC_WEAK_FUNC(sub_820A59B8);
PPC_FUNC_IMPL(__imp__sub_820A59B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r5,r11,14188
	ctx.r5.s64 = r11.s64 + 14188;
	// li r4,10
	ctx.r4.s64 = 10;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// mr r27,r8
	r27.u64 = ctx.r8.u64;
	// bl 0x823eda88
	sub_823EDA88(ctx, base);
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820a5828
	sub_820A5828(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820A5A18"))) PPC_WEAK_FUNC(sub_820A5A18);
PPC_FUNC_IMPL(__imp__sub_820A5A18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed100
	// stfd f29,-176(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -176, f29.u64);
	// stfd f30,-168(r1)
	PPC_STORE_U64(ctx.r1.u32 + -168, f30.u64);
	// stfd f31,-160(r1)
	PPC_STORE_U64(ctx.r1.u32 + -160, f31.u64);
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r24,-32014
	r24.s64 = -2098069504;
	// lwz r11,-1364(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + -1364);
	// lwz r10,4380(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4380);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a6258
	if (!cr6.getEQ()) goto loc_820A6258;
	// lwz r11,8260(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8260);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820a6258
	if (!cr6.getEQ()) goto loc_820A6258;
	// bl 0x8209ec18
	sub_8209EC18(ctx, base);
	// cmpwi cr6,r3,90
	cr6.compare<int32_t>(ctx.r3.s32, 90, xer);
	// beq cr6,0x820a6258
	if (cr6.getEQ()) goto loc_820A6258;
	// lwz r11,-1364(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + -1364);
	// lwz r16,3280(r11)
	r16.u64 = PPC_LOAD_U32(r11.u32 + 3280);
	// lwz r18,2344(r11)
	r18.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// bl 0x820b30a8
	sub_820B30A8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a5a80
	if (cr6.getEQ()) goto loc_820A5A80;
	// li r26,59
	r26.s64 = 59;
	// b 0x820a5aa0
	goto loc_820A5AA0;
loc_820A5A80:
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// clrlwi r11,r3,31
	r11.u64 = ctx.r3.u32 & 0x1;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820a5a9c
	if (cr6.getEQ()) goto loc_820A5A9C;
	// li r14,43
	r14.s64 = 43;
	// li r26,127
	r26.s64 = 127;
	// b 0x820a5aa4
	goto loc_820A5AA4;
loc_820A5A9C:
	// li r26,109
	r26.s64 = 109;
loc_820A5AA0:
	// li r14,59
	r14.s64 = 59;
loc_820A5AA4:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r15,r11,1240
	r15.s64 = r11.s64 + 1240;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r21,255
	r21.s64 = 255;
	// addi r17,r11,6504
	r17.s64 = r11.s64 + 6504;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lfs f31,6580(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6580);
	f31.f64 = double(temp.f32);
	// li r25,0
	r25.s64 = 0;
	// addi r19,r11,15496
	r19.s64 = r11.s64 + 15496;
	// lwz r11,-1364(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + -1364);
	// cmpwi cr6,r18,0
	cr6.compare<int32_t>(r18.s32, 0, xer);
	// beq cr6,0x820a5fe8
	if (cr6.getEQ()) goto loc_820A5FE8;
	// lwz r10,2380(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2380);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// beq cr6,0x820a5fe8
	if (cr6.getEQ()) goto loc_820A5FE8;
	// cmpwi cr6,r10,7
	cr6.compare<int32_t>(ctx.r10.s32, 7, xer);
	// beq cr6,0x820a5fe8
	if (cr6.getEQ()) goto loc_820A5FE8;
	// mulli r22,r18,56
	r22.s64 = r18.s64 * 56;
	// addi r20,r17,8
	r20.s64 = r17.s64 + 8;
	// lwzx r10,r22,r20
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + r20.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a5b0c
	if (!cr6.getEQ()) goto loc_820A5B0C;
	// addi r10,r17,12
	ctx.r10.s64 = r17.s64 + 12;
	// lwzx r10,r22,r10
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + ctx.r10.u32);
	// b 0x820a5b10
	goto loc_820A5B10;
loc_820A5B0C:
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
loc_820A5B10:
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm r10,r10,0,12,12
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a5fe8
	if (!cr6.getEQ()) goto loc_820A5FE8;
	// mr r23,r25
	r23.u64 = r25.u64;
	// cmpwi cr6,r18,88
	cr6.compare<int32_t>(r18.s32, 88, xer);
	// bne cr6,0x820a5c94
	if (!cr6.getEQ()) goto loc_820A5C94;
	// bl 0x8210e280
	sub_8210E280(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// subf r31,r26,r11
	r31.s64 = r11.s64 - r26.s64;
	// bl 0x8210e208
	sub_8210E208(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// addi r29,r11,-4
	r29.s64 = r11.s64 + -4;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mulli r10,r3,112
	ctx.r10.s64 = ctx.r3.s64 * 112;
	// addi r11,r11,-1360
	r11.s64 = r11.s64 + -1360;
	// addi r11,r11,96
	r11.s64 = r11.s64 + 96;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, r11.u64);
	// lfd f0,128(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// frsp f30,f0
	f30.f64 = double(float(f0.f64));
	// lfs f0,14212(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14212);
	f0.f64 = double(temp.f32);
	// fmuls f1,f30,f0
	ctx.f1.f64 = double(float(f30.f64 * f0.f64));
	// bl 0x823ed4c8
	sub_823ED4C8(ctx, base);
	// fmr f13,f1
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = ctx.f1.f64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r10,r1,120
	ctx.r10.s64 = ctx.r1.s64 + 120;
	// lfs f0,6576(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6576);
	f0.f64 = double(temp.f32);
	// fmuls f1,f30,f0
	ctx.f1.f64 = double(float(f30.f64 * f0.f64));
	// frsp f0,f13
	f0.f64 = double(float(ctx.f13.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, f0.u32);
	// bl 0x823ed4c8
	sub_823ED4C8(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// addi r10,r1,112
	ctx.r10.s64 = ctx.r1.s64 + 112;
	// lwz r6,120(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mulli r9,r6,60
	ctx.r9.s64 = ctx.r6.s64 * 60;
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// addi r5,r11,14196
	ctx.r5.s64 = r11.s64 + 14196;
	// stfiwx f0,0,r10
	PPC_STORE_U32(ctx.r10.u32, f0.u32);
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// li r4,20
	ctx.r4.s64 = 20;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// subf r7,r9,r11
	ctx.r7.s64 = r11.s64 - ctx.r9.s64;
	// bl 0x823eda88
	sub_823EDA88(ctx, base);
	// bl 0x8210e2f0
	sub_8210E2F0(ctx, base);
	// extsh r31,r3
	r31.s64 = ctx.r3.s16;
	// bl 0x8210e218
	sub_8210E218(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// lis r30,-31994
	r30.s64 = -2096758784;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// stw r25,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r25.u32);
	// lis r31,-31991
	r31.s64 = -2096562176;
	// stw r25,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r25.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r25,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r25.u32);
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// stw r25,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r25.u32);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lwz r7,15120(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 15120);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// lwz r6,-31544(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + -31544);
	// addi r28,r11,-23
	r28.s64 = r11.s64 + -23;
	// bl 0x8213e098
	sub_8213E098(ctx, base);
	// lwz r11,112(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// stw r29,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r29.u32);
	// srawi r10,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r10.s64 = r11.s32 >> 1;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
	// bl 0x8210e198
	sub_8210E198(ctx, base);
	// extsh r29,r3
	r29.s64 = ctx.r3.s16;
	// bl 0x8210e188
	sub_8210E188(ctx, base);
	// lis r9,25700
	ctx.r9.s64 = 1684275200;
	// lwz r7,15120(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 15120);
	// lwz r6,-31544(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + -31544);
	// extsh r10,r3
	ctx.r10.s64 = ctx.r3.s16;
	// ori r9,r9,25855
	ctx.r9.u64 = ctx.r9.u64 | 25855;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r29.u32);
	// li r8,-1
	ctx.r8.s64 = -1;
	// li r11,-1
	r11.s64 = -1;
	// stw r25,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r25.u32);
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// stw r25,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r25.u32);
	// addi r4,r1,116
	ctx.r4.s64 = ctx.r1.s64 + 116;
	// addi r3,r1,120
	ctx.r3.s64 = ctx.r1.s64 + 120;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
	// bl 0x8213e398
	sub_8213E398(ctx, base);
	// b 0x820a5d68
	goto loc_820A5D68;
loc_820A5C94:
	// cmpwi cr6,r18,1
	cr6.compare<int32_t>(r18.s32, 1, xer);
	// beq cr6,0x820a5ca4
	if (cr6.getEQ()) goto loc_820A5CA4;
	// cmpwi cr6,r18,32
	cr6.compare<int32_t>(r18.s32, 32, xer);
	// ble cr6,0x820a5d6c
	if (!cr6.getGT()) goto loc_820A5D6C;
loc_820A5CA4:
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x820c18b8
	sub_820C18B8(ctx, base);
	// bl 0x820c1a28
	sub_820C1A28(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x820b30a8
	sub_820B30A8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// addi r7,r1,116
	ctx.r7.s64 = ctx.r1.s64 + 116;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// cntlzw r10,r11
	ctx.r10.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// addi r6,r1,120
	ctx.r6.s64 = ctx.r1.s64 + 120;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// rlwinm r29,r10,27,31,31
	r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// lwz r4,-31544(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + -31544);
	// bl 0x8209bd50
	sub_8209BD50(ctx, base);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8209b890
	sub_8209B890(ctx, base);
	// bl 0x8210e280
	sub_8210E280(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// subf r31,r26,r11
	r31.s64 = r11.s64 - r26.s64;
	// bl 0x8210e208
	sub_8210E208(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// addi r28,r11,-4
	r28.s64 = r11.s64 + -4;
	// bl 0x820df8d8
	sub_820DF8D8(ctx, base);
	// lwz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820a5d24
	if (cr6.getEQ()) goto loc_820A5D24;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r11,15864(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 15864);
	// b 0x820a5d2c
	goto loc_820A5D2C;
loc_820A5D24:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r11,15860(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 15860);
loc_820A5D2C:
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// ble cr6,0x820a5d38
	if (!cr6.getGT()) goto loc_820A5D38;
	// subf r23,r11,r10
	r23.s64 = ctx.r10.s64 - r11.s64;
loc_820A5D38:
	// bl 0x8210e2f0
	sub_8210E2F0(ctx, base);
	// extsh r31,r3
	r31.s64 = ctx.r3.s16;
	// bl 0x8210e218
	sub_8210E218(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// add r4,r28,r23
	ctx.r4.u64 = r28.u64 + r23.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r6,r11,-23
	ctx.r6.s64 = r11.s64 + -23;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r8,1
	ctx.r8.s64 = 1;
	// bl 0x820a5828
	sub_820A5828(ctx, base);
loc_820A5D68:
	// lwz r11,-1364(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + -1364);
loc_820A5D6C:
	// lwzx r10,r22,r20
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + r20.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a5d84
	if (!cr6.getEQ()) goto loc_820A5D84;
	// addi r10,r17,12
	ctx.r10.s64 = r17.s64 + 12;
	// lwzx r10,r22,r10
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + ctx.r10.u32);
	// b 0x820a5d88
	goto loc_820A5D88;
loc_820A5D84:
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
loc_820A5D88:
	// lwz r29,28(r10)
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x820a5fe8
	if (cr6.getEQ()) goto loc_820A5FE8;
	// cmpwi cr6,r29,29
	cr6.compare<int32_t>(r29.s32, 29, xer);
	// beq cr6,0x820a5fe8
	if (cr6.getEQ()) goto loc_820A5FE8;
	// rlwinm r10,r29,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r9,r19,4
	ctx.r9.s64 = r19.s64 + 4;
	// add r10,r29,r10
	ctx.r10.u64 = r29.u64 + ctx.r10.u64;
	// li r28,5
	r28.s64 = 5;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r9
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a5e68
	if (cr6.getEQ()) goto loc_820A5E68;
	// addi r11,r19,8
	r11.s64 = r19.s64 + 8;
	// lfsx f30,r10,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	f30.f64 = double(temp.f32);
	// bl 0x8210e2f0
	sub_8210E2F0(ctx, base);
	// extsh r30,r3
	r30.s64 = ctx.r3.s16;
	// bl 0x8210e218
	sub_8210E218(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// addi r11,r11,-25
	r11.s64 = r11.s64 + -25;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, r11.u64);
	// lfd f0,128(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f29,f0
	f29.f64 = double(float(f0.f64));
	// bl 0x8210e280
	sub_8210E280(ctx, base);
	// extsh r30,r3
	r30.s64 = ctx.r3.s16;
	// bl 0x8210e208
	sub_8210E208(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// fmr f4,f30
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f30.f64;
	// extsw r10,r26
	ctx.r10.s64 = r26.s32;
	// fmr f3,f29
	ctx.f3.f64 = f29.f64;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// li r9,1
	ctx.r9.s64 = 1;
	// stw r21,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r21.u32);
	// add r11,r11,r23
	r11.u64 = r11.u64 + r23.u64;
	// stw r21,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r21.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r21,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r21.u32);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r10,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r10.u64);
	// lfd f0,128(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// li r10,255
	ctx.r10.s64 = 255;
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, r11.u64);
	// lfd f13,120(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fsubs f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 - f0.f64));
	// bl 0x820a56c0
	sub_820A56C0(ctx, base);
	// lwz r28,8(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,-1364(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + -1364);
loc_820A5E68:
	// lwzx r8,r22,r20
	ctx.r8.u64 = PPC_LOAD_U32(r22.u32 + r20.u32);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820a5e80
	if (!cr6.getEQ()) goto loc_820A5E80;
	// addi r10,r17,12
	ctx.r10.s64 = r17.s64 + 12;
	// lwzx r10,r22,r10
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + ctx.r10.u32);
	// b 0x820a5e84
	goto loc_820A5E84;
loc_820A5E80:
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
loc_820A5E84:
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm r10,r10,0,9,9
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400000;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// addi r10,r29,1145
	ctx.r10.s64 = r29.s64 + 1145;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// beq cr6,0x820a5ec0
	if (cr6.getEQ()) goto loc_820A5EC0;
	// lwz r9,2388(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2388);
	// mr r29,r25
	r29.u64 = r25.u64;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpw cr6,r16,r18
	cr6.compare<int32_t>(r16.s32, r18.s32, xer);
	// add r27,r10,r9
	r27.u64 = ctx.r10.u64 + ctx.r9.u64;
	// bne cr6,0x820a5ec8
	if (!cr6.getEQ()) goto loc_820A5EC8;
	// lwz r10,3324(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3324);
	// add r27,r10,r27
	r27.u64 = ctx.r10.u64 + r27.u64;
	// b 0x820a5ec8
	goto loc_820A5EC8;
loc_820A5EC0:
	// lwz r29,2388(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 2388);
	// lwzx r27,r10,r11
	r27.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
loc_820A5EC8:
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820a5edc
	if (!cr6.getEQ()) goto loc_820A5EDC;
	// addi r10,r17,12
	ctx.r10.s64 = r17.s64 + 12;
	// lwzx r10,r22,r10
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + ctx.r10.u32);
	// b 0x820a5ee0
	goto loc_820A5EE0;
loc_820A5EDC:
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
loc_820A5EE0:
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm r10,r10,0,9,9
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400000;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a5f50
	if (!cr6.getEQ()) goto loc_820A5F50;
	// bl 0x8210e2f0
	sub_8210E2F0(ctx, base);
	// extsh r31,r3
	r31.s64 = ctx.r3.s16;
	// bl 0x8210e280
	sub_8210E280(ctx, base);
	// extsh r30,r3
	r30.s64 = ctx.r3.s16;
	// bl 0x8210e218
	sub_8210E218(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// addi r31,r11,-23
	r31.s64 = r11.s64 + -23;
	// bl 0x8210e208
	sub_8210E208(ctx, base);
	// srawi r11,r28,1
	xer.ca = (r28.s32 < 0) & ((r28.u32 & 0x1) != 0);
	r11.s64 = r28.s32 >> 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// addze r10,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	ctx.r10.s64 = temp.s64;
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// subf r10,r10,r30
	ctx.r10.s64 = r30.s64 - ctx.r10.s64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// subf r10,r26,r10
	ctx.r10.s64 = ctx.r10.s64 - r26.s64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// li r7,2
	ctx.r7.s64 = 2;
	// add r11,r11,r23
	r11.u64 = r11.u64 + r23.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// bl 0x820a59b8
	sub_820A59B8(ctx, base);
	// lwz r11,-1364(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + -1364);
loc_820A5F50:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bgt cr6,0x820a5f84
	if (cr6.getGT()) goto loc_820A5F84;
	// lwzx r10,r22,r20
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + r20.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a5f70
	if (!cr6.getEQ()) goto loc_820A5F70;
	// addi r10,r17,12
	ctx.r10.s64 = r17.s64 + 12;
	// lwzx r10,r22,r10
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + ctx.r10.u32);
	// b 0x820a5f74
	goto loc_820A5F74;
loc_820A5F70:
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
loc_820A5F74:
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm r10,r10,0,9,9
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400000;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a5fe8
	if (cr6.getEQ()) goto loc_820A5FE8;
loc_820A5F84:
	// bl 0x8210e2f0
	sub_8210E2F0(ctx, base);
	// extsh r31,r3
	r31.s64 = ctx.r3.s16;
	// bl 0x8210e280
	sub_8210E280(ctx, base);
	// extsh r30,r3
	r30.s64 = ctx.r3.s16;
	// bl 0x8210e218
	sub_8210E218(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// addi r31,r11,-23
	r31.s64 = r11.s64 + -23;
	// bl 0x8210e208
	sub_8210E208(ctx, base);
	// addi r11,r28,1
	r11.s64 = r28.s64 + 1;
	// li r5,1
	ctx.r5.s64 = 1;
	// srawi r10,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r10.s64 = r11.s32 >> 1;
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// subf r10,r26,r10
	ctx.r10.s64 = ctx.r10.s64 - r26.s64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// li r7,2
	ctx.r7.s64 = 2;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// li r8,1
	ctx.r8.s64 = 1;
	// add r11,r11,r23
	r11.u64 = r11.u64 + r23.u64;
	// addi r4,r11,3
	ctx.r4.s64 = r11.s64 + 3;
	// bl 0x820a59b8
	sub_820A59B8(ctx, base);
	// lwz r11,-1364(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + -1364);
loc_820A5FE8:
	// cmpwi cr6,r16,0
	cr6.compare<int32_t>(r16.s32, 0, xer);
	// beq cr6,0x820a6258
	if (cr6.getEQ()) goto loc_820A6258;
	// mulli r27,r16,56
	r27.s64 = r16.s64 * 56;
	// addi r26,r17,8
	r26.s64 = r17.s64 + 8;
	// lwzx r9,r27,r26
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + r26.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a6010
	if (!cr6.getEQ()) goto loc_820A6010;
	// addi r10,r17,12
	ctx.r10.s64 = r17.s64 + 12;
	// lwzx r10,r27,r10
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + ctx.r10.u32);
	// b 0x820a6014
	goto loc_820A6014;
loc_820A6010:
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
loc_820A6014:
	// lwz r29,28(r10)
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x820a6258
	if (cr6.getEQ()) goto loc_820A6258;
	// lwz r10,3316(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3316);
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// beq cr6,0x820a6258
	if (cr6.getEQ()) goto loc_820A6258;
	// cmpwi cr6,r10,7
	cr6.compare<int32_t>(ctx.r10.s32, 7, xer);
	// beq cr6,0x820a6258
	if (cr6.getEQ()) goto loc_820A6258;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a6048
	if (!cr6.getEQ()) goto loc_820A6048;
	// addi r10,r17,12
	ctx.r10.s64 = r17.s64 + 12;
	// lwzx r10,r27,r10
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + ctx.r10.u32);
	// b 0x820a604c
	goto loc_820A604C;
loc_820A6048:
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
loc_820A604C:
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm r10,r10,0,12,12
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a6258
	if (!cr6.getEQ()) goto loc_820A6258;
	// rlwinm r10,r29,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r9,r19,4
	ctx.r9.s64 = r19.s64 + 4;
	// add r10,r29,r10
	ctx.r10.u64 = r29.u64 + ctx.r10.u64;
	// li r28,5
	r28.s64 = 5;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r31,r10,r9
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a6100
	if (cr6.getEQ()) goto loc_820A6100;
	// addi r11,r19,8
	r11.s64 = r19.s64 + 8;
	// lfsx f30,r10,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	f30.f64 = double(temp.f32);
	// bl 0x8210e2f0
	sub_8210E2F0(ctx, base);
	// extsh r30,r3
	r30.s64 = ctx.r3.s16;
	// bl 0x8210e218
	sub_8210E218(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// addi r11,r11,-25
	r11.s64 = r11.s64 + -25;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, r11.u64);
	// lfd f0,128(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f29,f0
	f29.f64 = double(float(f0.f64));
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// extsw r11,r14
	r11.s64 = r14.s32;
	// fmr f4,f30
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f30.f64;
	// li r10,255
	ctx.r10.s64 = 255;
	// fmr f3,f29
	ctx.f3.f64 = f29.f64;
	// li r9,1
	ctx.r9.s64 = 1;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// li r7,1
	ctx.r7.s64 = 1;
	// stw r21,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r21.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r21,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r21.u32);
	// std r11,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, r11.u64);
	// lfd f0,128(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// stw r21,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r21.u32);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fadds f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 + f0.f64));
	// bl 0x820a56c0
	sub_820A56C0(ctx, base);
	// lwz r28,8(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,-1364(r24)
	r11.u64 = PPC_LOAD_U32(r24.u32 + -1364);
loc_820A6100:
	// lwzx r8,r27,r26
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + r26.u32);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820a6118
	if (!cr6.getEQ()) goto loc_820A6118;
	// addi r10,r17,12
	ctx.r10.s64 = r17.s64 + 12;
	// lwzx r10,r27,r10
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + ctx.r10.u32);
	// b 0x820a611c
	goto loc_820A611C;
loc_820A6118:
	// mr r10,r15
	ctx.r10.u64 = r15.u64;
loc_820A611C:
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm r10,r10,0,9,9
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400000;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// addi r10,r29,1145
	ctx.r10.s64 = r29.s64 + 1145;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// beq cr6,0x820a6158
	if (cr6.getEQ()) goto loc_820A6158;
	// lwz r9,3324(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 3324);
	// mr r30,r25
	r30.u64 = r25.u64;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpw cr6,r16,r18
	cr6.compare<int32_t>(r16.s32, r18.s32, xer);
	// add r29,r10,r9
	r29.u64 = ctx.r10.u64 + ctx.r9.u64;
	// bne cr6,0x820a6160
	if (!cr6.getEQ()) goto loc_820A6160;
	// lwz r11,2388(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 2388);
	// add r29,r11,r29
	r29.u64 = r11.u64 + r29.u64;
	// b 0x820a6160
	goto loc_820A6160;
loc_820A6158:
	// lwz r30,3324(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 3324);
	// lwzx r29,r10,r11
	r29.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
loc_820A6160:
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820a6174
	if (!cr6.getEQ()) goto loc_820A6174;
	// addi r11,r17,12
	r11.s64 = r17.s64 + 12;
	// lwzx r11,r27,r11
	r11.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// b 0x820a6178
	goto loc_820A6178;
loc_820A6174:
	// mr r11,r15
	r11.u64 = r15.u64;
loc_820A6178:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,9,9
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a61d4
	if (!cr6.getEQ()) goto loc_820A61D4;
	// bl 0x8210e2f0
	sub_8210E2F0(ctx, base);
	// extsh r31,r3
	r31.s64 = ctx.r3.s16;
	// bl 0x8210e218
	sub_8210E218(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// addi r31,r11,-23
	r31.s64 = r11.s64 + -23;
	// bl 0x8210e280
	sub_8210E280(ctx, base);
	// srawi r10,r28,1
	xer.ca = (r28.s32 < 0) & ((r28.u32 & 0x1) != 0);
	ctx.r10.s64 = r28.s32 >> 1;
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// add r11,r11,r14
	r11.u64 = r11.u64 + r14.u64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// addi r4,r11,3
	ctx.r4.s64 = r11.s64 + 3;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r8,1
	ctx.r8.s64 = 1;
	// bl 0x820a59b8
	sub_820A59B8(ctx, base);
loc_820A61D4:
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bgt cr6,0x820a6208
	if (cr6.getGT()) goto loc_820A6208;
	// lwzx r11,r27,r26
	r11.u64 = PPC_LOAD_U32(r27.u32 + r26.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a61f4
	if (!cr6.getEQ()) goto loc_820A61F4;
	// addi r11,r17,12
	r11.s64 = r17.s64 + 12;
	// lwzx r11,r27,r11
	r11.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// b 0x820a61f8
	goto loc_820A61F8;
loc_820A61F4:
	// mr r11,r15
	r11.u64 = r15.u64;
loc_820A61F8:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,9,9
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a6258
	if (cr6.getEQ()) goto loc_820A6258;
loc_820A6208:
	// bl 0x8210e2f0
	sub_8210E2F0(ctx, base);
	// extsh r31,r3
	r31.s64 = ctx.r3.s16;
	// bl 0x8210e218
	sub_8210E218(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// addi r31,r11,-23
	r31.s64 = r11.s64 + -23;
	// bl 0x8210e280
	sub_8210E280(ctx, base);
	// addi r11,r28,1
	r11.s64 = r28.s64 + 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// srawi r10,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r10.s64 = r11.s32 >> 1;
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// subf r10,r10,r14
	ctx.r10.s64 = r14.s64 - ctx.r10.s64;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// li r7,2
	ctx.r7.s64 = 2;
	// addi r4,r11,-4
	ctx.r4.s64 = r11.s64 + -4;
	// li r8,1
	ctx.r8.s64 = 1;
	// bl 0x820a59b8
	sub_820A59B8(ctx, base);
loc_820A6258:
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// lfd f29,-176(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -176);
	// lfd f30,-168(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -168);
	// lfd f31,-160(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -160);
	// b 0x823ed150
	return;
}

__attribute__((alias("__imp__sub_820A6270"))) PPC_WEAK_FUNC(sub_820A6270);
PPC_FUNC_IMPL(__imp__sub_820A6270) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed120
	// stfd f31,-96(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -96, f31.u64);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r28,-32014
	r28.s64 = -2098069504;
	// lwz r9,-1364(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + -1364);
	// lwz r26,2344(r9)
	r26.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2344);
	// lwz r24,3280(r9)
	r24.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3280);
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x820a64b4
	if (cr6.getEQ()) goto loc_820A64B4;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r27,r26,56
	r27.s64 = r26.s64 * 56;
	// addi r25,r11,6504
	r25.s64 = r11.s64 + 6504;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r22,r25,8
	r22.s64 = r25.s64 + 8;
	// addi r23,r11,1240
	r23.s64 = r11.s64 + 1240;
	// lwzx r10,r27,r22
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + r22.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a62c8
	if (!cr6.getEQ()) goto loc_820A62C8;
	// addi r11,r25,12
	r11.s64 = r25.s64 + 12;
	// lwzx r11,r27,r11
	r11.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// b 0x820a62cc
	goto loc_820A62CC;
loc_820A62C8:
	// mr r11,r23
	r11.u64 = r23.u64;
loc_820A62CC:
	// lwz r29,28(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x820a64b4
	if (cr6.getEQ()) goto loc_820A64B4;
	// lwz r11,2380(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2380);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x820a64b4
	if (cr6.getEQ()) goto loc_820A64B4;
	// cmpwi cr6,r11,7
	cr6.compare<int32_t>(r11.s32, 7, xer);
	// beq cr6,0x820a64b4
	if (cr6.getEQ()) goto loc_820A64B4;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a6300
	if (!cr6.getEQ()) goto loc_820A6300;
	// addi r11,r25,12
	r11.s64 = r25.s64 + 12;
	// lwzx r11,r27,r11
	r11.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// b 0x820a6304
	goto loc_820A6304;
loc_820A6300:
	// mr r11,r23
	r11.u64 = r23.u64;
loc_820A6304:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,12,12
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a64b4
	if (!cr6.getEQ()) goto loc_820A64B4;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// rlwinm r10,r29,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r11,r11,15496
	r11.s64 = r11.s64 + 15496;
	// add r10,r29,r10
	ctx.r10.u64 = r29.u64 + ctx.r10.u64;
	// addi r8,r11,4
	ctx.r8.s64 = r11.s64 + 4;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// li r30,5
	r30.s64 = 5;
	// lwzx r31,r10,r8
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a63b0
	if (cr6.getEQ()) goto loc_820A63B0;
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// lfsx f31,r10,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	f31.f64 = double(temp.f32);
	// bl 0x8210e2f0
	sub_8210E2F0(ctx, base);
	// extsh r30,r3
	r30.s64 = ctx.r3.s16;
	// bl 0x8210e218
	sub_8210E218(ctx, base);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmr f4,f31
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f31.f64;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// li r11,255
	r11.s64 = 255;
	// li r7,0
	ctx.r7.s64 = 0;
	// lfs f2,14216(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14216);
	ctx.f2.f64 = double(temp.f32);
	// extsh r10,r3
	ctx.r10.s64 = ctx.r3.s16;
	// lfs f1,2940(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2940);
	ctx.f1.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 + r30.u64;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// addi r9,r10,-25
	ctx.r9.s64 = ctx.r10.s64 + -25;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// li r10,255
	ctx.r10.s64 = 255;
	// extsw r8,r9
	ctx.r8.s64 = ctx.r9.s32;
	// li r9,1
	ctx.r9.s64 = 1;
	// std r8,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r8.u64);
	// lfd f0,112(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f3,f0
	ctx.f3.f64 = double(float(f0.f64));
	// bl 0x820a56c0
	sub_820A56C0(ctx, base);
	// lwz r30,8(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r9,-1364(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + -1364);
loc_820A63B0:
	// lwzx r8,r27,r22
	ctx.r8.u64 = PPC_LOAD_U32(r27.u32 + r22.u32);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820a63c8
	if (!cr6.getEQ()) goto loc_820A63C8;
	// addi r11,r25,12
	r11.s64 = r25.s64 + 12;
	// lwzx r11,r27,r11
	r11.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// b 0x820a63cc
	goto loc_820A63CC;
loc_820A63C8:
	// mr r11,r23
	r11.u64 = r23.u64;
loc_820A63CC:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,9,9
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// addi r11,r29,1145
	r11.s64 = r29.s64 + 1145;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// beq cr6,0x820a6408
	if (cr6.getEQ()) goto loc_820A6408;
	// lwz r10,2388(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2388);
	// li r3,0
	ctx.r3.s64 = 0;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmpw cr6,r24,r26
	cr6.compare<int32_t>(r24.s32, r26.s32, xer);
	// add r31,r11,r10
	r31.u64 = r11.u64 + ctx.r10.u64;
	// bne cr6,0x820a6410
	if (!cr6.getEQ()) goto loc_820A6410;
	// lwz r11,3324(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3324);
	// add r31,r11,r31
	r31.u64 = r11.u64 + r31.u64;
	// b 0x820a6410
	goto loc_820A6410;
loc_820A6408:
	// lwz r3,2388(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2388);
	// lwzx r31,r11,r9
	r31.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
loc_820A6410:
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820a6424
	if (!cr6.getEQ()) goto loc_820A6424;
	// addi r11,r25,12
	r11.s64 = r25.s64 + 12;
	// lwzx r11,r27,r11
	r11.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// b 0x820a6428
	goto loc_820A6428;
loc_820A6424:
	// mr r11,r23
	r11.u64 = r23.u64;
loc_820A6428:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,9,9
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a6458
	if (!cr6.getEQ()) goto loc_820A6458;
	// srawi r11,r30,1
	xer.ca = (r30.s32 < 0) & ((r30.u32 & 0x1) != 0);
	r11.s64 = r30.s32 >> 1;
	// li r8,0
	ctx.r8.s64 = 0;
	// addze r11,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	r11.s64 = temp.s64;
	// li r7,2
	ctx.r7.s64 = 2;
	// li r6,177
	ctx.r6.s64 = 177;
	// li r5,0
	ctx.r5.s64 = 0;
	// subfic r4,r11,196
	xer.ca = r11.u32 <= 196;
	ctx.r4.s64 = 196 - r11.s64;
	// bl 0x820a59b8
	sub_820A59B8(ctx, base);
loc_820A6458:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bgt cr6,0x820a648c
	if (cr6.getGT()) goto loc_820A648C;
	// lwzx r11,r27,r22
	r11.u64 = PPC_LOAD_U32(r27.u32 + r22.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a6478
	if (!cr6.getEQ()) goto loc_820A6478;
	// addi r11,r25,12
	r11.s64 = r25.s64 + 12;
	// lwzx r11,r27,r11
	r11.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// b 0x820a647c
	goto loc_820A647C;
loc_820A6478:
	// mr r11,r23
	r11.u64 = r23.u64;
loc_820A647C:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,9,9
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a64b4
	if (cr6.getEQ()) goto loc_820A64B4;
loc_820A648C:
	// addi r11,r30,1
	r11.s64 = r30.s64 + 1;
	// li r8,0
	ctx.r8.s64 = 0;
	// srawi r11,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	r11.s64 = r11.s32 >> 1;
	// li r7,2
	ctx.r7.s64 = 2;
	// addze r11,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	r11.s64 = temp.s64;
	// li r6,177
	ctx.r6.s64 = 177;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r11,203
	ctx.r4.s64 = r11.s64 + 203;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820a59b8
	sub_820A59B8(ctx, base);
loc_820A64B4:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// lfd f31,-96(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x823ed170
	return;
}

__attribute__((alias("__imp__sub_820A64C0"))) PPC_WEAK_FUNC(sub_820A64C0);
PPC_FUNC_IMPL(__imp__sub_820A64C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,4572(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4572);
	// beq cr6,0x820a64e0
	if (cr6.getEQ()) goto loc_820A64E0;
	// andc r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 & ~ctx.r3.u64;
	// stw r10,4572(r11)
	PPC_STORE_U32(r11.u32 + 4572, ctx.r10.u32);
	// blr 
	return;
loc_820A64E0:
	// or r10,r10,r3
	ctx.r10.u64 = ctx.r10.u64 | ctx.r3.u64;
	// stw r10,4572(r11)
	PPC_STORE_U32(r11.u32 + 4572, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A64F0"))) PPC_WEAK_FUNC(sub_820A64F0);
PPC_FUNC_IMPL(__imp__sub_820A64F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -24, f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r10,4572(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4572);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a65f4
	if (!cr6.getEQ()) goto loc_820A65F4;
	// lwz r11,8260(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8260);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820a65f4
	if (!cr6.getEQ()) goto loc_820A65F4;
	// bl 0x8209ec18
	sub_8209EC18(ctx, base);
	// cmpwi cr6,r3,90
	cr6.compare<int32_t>(ctx.r3.s32, 90, xer);
	// beq cr6,0x820a65f4
	if (cr6.getEQ()) goto loc_820A65F4;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,4256(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4256);
	f0.f64 = double(temp.f32);
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f0,4260(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4260);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,132(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f0,14220(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14220);
	f0.f64 = double(temp.f32);
	// stfs f0,136(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// stfs f0,140(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// bl 0x8210e280
	sub_8210E280(ctx, base);
	// extsh r11,r3
	r11.s64 = ctx.r3.s16;
	// lfs f13,128(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// std r11,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, r11.u64);
	// lfd f0,144(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// bl 0x820c32b8
	sub_820C32B8(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,12888(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12888);
	f0.f64 = double(temp.f32);
	// fmuls f31,f1,f0
	f31.f64 = double(float(ctx.f1.f64 * f0.f64));
	// bl 0x8210e400
	sub_8210E400(ctx, base);
	// extsh r8,r3
	ctx.r8.s64 = ctx.r3.s16;
	// lfs f0,128(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	f0.f64 = double(temp.f32);
	// li r10,2
	ctx.r10.s64 = 2;
	// li r9,110
	ctx.r9.s64 = 110;
	// li r11,255
	r11.s64 = 255;
	// li r7,32
	ctx.r7.s64 = 32;
	// std r8,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r8.u64);
	// li r6,32
	ctx.r6.s64 = 32;
	// stw r10,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r10.u32);
	// lis r10,-31994
	ctx.r10.s64 = -2096758784;
	// stw r9,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r9.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,27912
	ctx.r3.s64 = ctx.r10.s64 + 27912;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// addi r5,r1,136
	ctx.r5.s64 = ctx.r1.s64 + 136;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// lfd f13,144(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmadds f0,f31,f0,f13
	f0.f64 = double(float(f31.f64 * f0.f64 + ctx.f13.f64));
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// bl 0x8214ab68
	sub_8214AB68(ctx, base);
loc_820A65F4:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A6610"))) PPC_WEAK_FUNC(sub_820A6610);
PPC_FUNC_IMPL(__imp__sub_820A6610) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r3,56
	r11.s64 = ctx.r3.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a6638
	if (!cr6.getEQ()) goto loc_820A6638;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820a6640
	goto loc_820A6640;
loc_820A6638:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
loc_820A6640:
	// lhz r11,108(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 108);
	// clrlwi r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,-908(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -908);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A6670"))) PPC_WEAK_FUNC(sub_820A6670);
PPC_FUNC_IMPL(__imp__sub_820A6670) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,-908(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -908);
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A6688"))) PPC_WEAK_FUNC(sub_820A6688);
PPC_FUNC_IMPL(__imp__sub_820A6688) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-908(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -908);
	// lwz r10,108(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A66A0"))) PPC_WEAK_FUNC(sub_820A66A0);
PPC_FUNC_IMPL(__imp__sub_820A66A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-908(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -908);
	// lwz r3,108(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A66B0"))) PPC_WEAK_FUNC(sub_820A66B0);
PPC_FUNC_IMPL(__imp__sub_820A66B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-640(r1)
	ea = -640 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// lis r29,-32014
	r29.s64 = -2098069504;
	// beq cr6,0x820a66dc
	if (cr6.getEQ()) goto loc_820A66DC;
	// bl 0x820ca520
	sub_820CA520(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a66ec
	if (cr6.getEQ()) goto loc_820A66EC;
loc_820A66DC:
	// lwz r11,-908(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -908);
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,28(r11)
	PPC_STORE_U32(r11.u32 + 28, ctx.r10.u32);
loc_820A66EC:
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r10,8312(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8312);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8312(r11)
	PPC_STORE_U32(r11.u32 + 8312, ctx.r10.u32);
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820a6830
	if (!cr6.getGT()) goto loc_820A6830;
	// bl 0x820b57f8
	sub_820B57F8(ctx, base);
	// lwz r11,-908(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -908);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,39130
	ctx.r3.u64 = ctx.r3.u64 | 39130;
	// lwz r28,28(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r5,r11,14224
	ctx.r5.s64 = r11.s64 + 14224;
	// li r4,256
	ctx.r4.s64 = 256;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// bl 0x823eda88
	sub_823EDA88(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820b4260
	sub_820B4260(ctx, base);
	// lwz r11,-908(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -908);
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// ble cr6,0x820a678c
	if (!cr6.getGT()) goto loc_820A678C;
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r9,72(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// lwz r10,8292(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8292);
	// subf r10,r10,r30
	ctx.r10.s64 = r30.s64 - ctx.r10.s64;
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// ble cr6,0x820a677c
	if (!cr6.getGT()) goto loc_820A677C;
	// stw r10,72(r11)
	PPC_STORE_U32(r11.u32 + 72, ctx.r10.u32);
	// lwz r11,-908(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -908);
loc_820A677C:
	// lwz r9,68(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// bge cr6,0x820a678c
	if (!cr6.getLT()) goto loc_820A678C;
	// stw r10,68(r11)
	PPC_STORE_U32(r11.u32 + 68, ctx.r10.u32);
loc_820A678C:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r11,8300(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8300);
	// stw r11,8304(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8304, r11.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r10,8296(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8296);
	// stw r10,8300(r11)
	PPC_STORE_U32(r11.u32 + 8300, ctx.r10.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r10,8292(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8292);
	// stw r10,8296(r11)
	PPC_STORE_U32(r11.u32 + 8296, ctx.r10.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r30,8292(r11)
	PPC_STORE_U32(r11.u32 + 8292, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r10,8296(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8296);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x820a681c
	if (cr6.getEQ()) goto loc_820A681C;
	// lwz r8,8292(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8292);
	// subf r10,r10,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r10.s64;
	// cmpwi cr6,r10,120
	cr6.compare<int32_t>(ctx.r10.s32, 120, xer);
	// bge cr6,0x820a681c
	if (!cr6.getLT()) goto loc_820A681C;
	// lwz r10,8300(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8300);
	// li r9,2
	ctx.r9.s64 = 2;
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x820a681c
	if (cr6.getEQ()) goto loc_820A681C;
	// subf r10,r10,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r10.s64;
	// cmpwi cr6,r10,120
	cr6.compare<int32_t>(ctx.r10.s32, 120, xer);
	// bge cr6,0x820a681c
	if (!cr6.getLT()) goto loc_820A681C;
	// lwz r11,8304(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8304);
	// li r9,3
	ctx.r9.s64 = 3;
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x820a681c
	if (cr6.getEQ()) goto loc_820A681C;
	// subf r11,r11,r8
	r11.s64 = ctx.r8.s64 - r11.s64;
	// cmpwi cr6,r11,120
	cr6.compare<int32_t>(r11.s32, 120, xer);
	// bge cr6,0x820a681c
	if (!cr6.getLT()) goto loc_820A681C;
	// li r9,4
	ctx.r9.s64 = 4;
loc_820A681C:
	// lwz r11,-908(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -908);
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// cmpw cr6,r9,r10
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, xer);
	// ble cr6,0x820a6830
	if (!cr6.getGT()) goto loc_820A6830;
	// stw r9,88(r11)
	PPC_STORE_U32(r11.u32 + 88, ctx.r9.u32);
loc_820A6830:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a687c
	if (cr6.getEQ()) goto loc_820A687C;
	// bl 0x8215fc88
	sub_8215FC88(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// bne cr6,0x820a687c
	if (!cr6.getEQ()) goto loc_820A687C;
	// bl 0x820ca338
	sub_820CA338(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a687c
	if (cr6.getEQ()) goto loc_820A687C;
	// bl 0x8216c140
	sub_8216C140(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a687c
	if (cr6.getEQ()) goto loc_820A687C;
	// lwz r11,-908(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -908);
	// addi r3,r31,1544
	ctx.r3.s64 = r31.s64 + 1544;
	// lwz r4,28(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// bl 0x82177480
	sub_82177480(ctx, base);
loc_820A687C:
	// addi r1,r1,640
	ctx.r1.s64 = ctx.r1.s64 + 640;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820A6888"))) PPC_WEAK_FUNC(sub_820A6888);
PPC_FUNC_IMPL(__imp__sub_820A6888) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-908(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -908);
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A6898"))) PPC_WEAK_FUNC(sub_820A6898);
PPC_FUNC_IMPL(__imp__sub_820A6898) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// lis r30,-32014
	r30.s64 = -2098069504;
	// beq cr6,0x820a68cc
	if (cr6.getEQ()) goto loc_820A68CC;
	// bl 0x820ca520
	sub_820CA520(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a68dc
	if (cr6.getEQ()) goto loc_820A68DC;
loc_820A68CC:
	// lwz r11,-908(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -908);
	// lwz r10,32(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,32(r11)
	PPC_STORE_U32(r11.u32 + 32, ctx.r10.u32);
loc_820A68DC:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a6928
	if (cr6.getEQ()) goto loc_820A6928;
	// bl 0x8215fc88
	sub_8215FC88(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// bne cr6,0x820a6928
	if (!cr6.getEQ()) goto loc_820A6928;
	// bl 0x820ca338
	sub_820CA338(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a6928
	if (cr6.getEQ()) goto loc_820A6928;
	// bl 0x8216c140
	sub_8216C140(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a6928
	if (cr6.getEQ()) goto loc_820A6928;
	// lwz r11,-908(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -908);
	// addi r3,r31,1596
	ctx.r3.s64 = r31.s64 + 1596;
	// lwz r4,32(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 32);
	// bl 0x82177480
	sub_82177480(ctx, base);
loc_820A6928:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A6940"))) PPC_WEAK_FUNC(sub_820A6940);
PPC_FUNC_IMPL(__imp__sub_820A6940) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-624(r1)
	ea = -624 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r10,8280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8280);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8280(r11)
	PPC_STORE_U32(r11.u32 + 8280, ctx.r10.u32);
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820a69e4
	if (!cr6.getGT()) goto loc_820A69E4;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lis r3,0
	ctx.r3.s64 = 0;
	// lwz r11,8280(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8280);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x820a699c
	if (!cr6.getEQ()) goto loc_820A699C;
	// ori r3,r3,39131
	ctx.r3.u64 = ctx.r3.u64 | 39131;
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// li r4,256
	ctx.r4.s64 = 256;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823eda88
	sub_823EDA88(ctx, base);
	// b 0x820a69dc
	goto loc_820A69DC;
loc_820A699C:
	// ori r3,r3,39133
	ctx.r3.u64 = ctx.r3.u64 | 39133;
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,39132
	ctx.r3.u64 = ctx.r3.u64 | 39132;
	// lwz r29,8280(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 8280);
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r5,r11,14240
	ctx.r5.s64 = r11.s64 + 14240;
	// li r4,256
	ctx.r4.s64 = 256;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// bl 0x823eda88
	sub_823EDA88(ctx, base);
loc_820A69DC:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820b4260
	sub_820B4260(ctx, base);
loc_820A69E4:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a6a30
	if (cr6.getEQ()) goto loc_820A6A30;
	// bl 0x8215fc88
	sub_8215FC88(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// bne cr6,0x820a6a30
	if (!cr6.getEQ()) goto loc_820A6A30;
	// bl 0x820ca338
	sub_820CA338(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820a6a30
	if (cr6.getEQ()) goto loc_820A6A30;
	// bl 0x8216c140
	sub_8216C140(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a6a30
	if (cr6.getEQ()) goto loc_820A6A30;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r3,r30,1908
	ctx.r3.s64 = r30.s64 + 1908;
	// lwz r4,8280(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 8280);
	// bl 0x82177480
	sub_82177480(ctx, base);
loc_820A6A30:
	// addi r1,r1,624
	ctx.r1.s64 = ctx.r1.s64 + 624;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820A6A38"))) PPC_WEAK_FUNC(sub_820A6A38);
PPC_FUNC_IMPL(__imp__sub_820A6A38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-624(r1)
	ea = -624 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r10,8284(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8284);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8284(r11)
	PPC_STORE_U32(r11.u32 + 8284, ctx.r10.u32);
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820a6b8c
	if (!cr6.getGT()) goto loc_820A6B8C;
	// bl 0x820b57f8
	sub_820B57F8(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,39134
	ctx.r3.u64 = ctx.r3.u64 | 39134;
	// lwz r29,8284(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 8284);
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r5,r11,14224
	ctx.r5.s64 = r11.s64 + 14224;
	// li r4,256
	ctx.r4.s64 = 256;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// bl 0x823eda88
	sub_823EDA88(ctx, base);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820b4260
	sub_820B4260(ctx, base);
	// lis r7,-32014
	ctx.r7.s64 = -2098069504;
	// lwz r11,-908(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + -908);
	// lwz r10,28(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// ble cr6,0x820a6ae8
	if (!cr6.getGT()) goto loc_820A6AE8;
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r9,72(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 72);
	// lwz r10,8292(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8292);
	// subf r10,r10,r30
	ctx.r10.s64 = r30.s64 - ctx.r10.s64;
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// ble cr6,0x820a6ad8
	if (!cr6.getGT()) goto loc_820A6AD8;
	// stw r10,72(r11)
	PPC_STORE_U32(r11.u32 + 72, ctx.r10.u32);
	// lwz r11,-908(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + -908);
loc_820A6AD8:
	// lwz r9,68(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 68);
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// bge cr6,0x820a6ae8
	if (!cr6.getLT()) goto loc_820A6AE8;
	// stw r10,68(r11)
	PPC_STORE_U32(r11.u32 + 68, ctx.r10.u32);
loc_820A6AE8:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r11,8300(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8300);
	// stw r11,8304(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8304, r11.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r10,8296(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8296);
	// stw r10,8300(r11)
	PPC_STORE_U32(r11.u32 + 8300, ctx.r10.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r10,8292(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8292);
	// stw r10,8296(r11)
	PPC_STORE_U32(r11.u32 + 8296, ctx.r10.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r30,8292(r11)
	PPC_STORE_U32(r11.u32 + 8292, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r10,8296(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8296);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x820a6b78
	if (cr6.getEQ()) goto loc_820A6B78;
	// lwz r8,8292(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8292);
	// subf r10,r10,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r10.s64;
	// cmpwi cr6,r10,120
	cr6.compare<int32_t>(ctx.r10.s32, 120, xer);
	// bge cr6,0x820a6b78
	if (!cr6.getLT()) goto loc_820A6B78;
	// lwz r10,8300(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8300);
	// li r9,2
	ctx.r9.s64 = 2;
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x820a6b78
	if (cr6.getEQ()) goto loc_820A6B78;
	// subf r10,r10,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r10.s64;
	// cmpwi cr6,r10,120
	cr6.compare<int32_t>(ctx.r10.s32, 120, xer);
	// bge cr6,0x820a6b78
	if (!cr6.getLT()) goto loc_820A6B78;
	// lwz r11,8304(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8304);
	// li r9,3
	ctx.r9.s64 = 3;
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x820a6b78
	if (cr6.getEQ()) goto loc_820A6B78;
	// subf r11,r11,r8
	r11.s64 = ctx.r8.s64 - r11.s64;
	// cmpwi cr6,r11,120
	cr6.compare<int32_t>(r11.s32, 120, xer);
	// bge cr6,0x820a6b78
	if (!cr6.getLT()) goto loc_820A6B78;
	// li r9,4
	ctx.r9.s64 = 4;
loc_820A6B78:
	// lwz r11,-908(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + -908);
	// lwz r10,88(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 88);
	// cmpw cr6,r9,r10
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, xer);
	// ble cr6,0x820a6b8c
	if (!cr6.getGT()) goto loc_820A6B8C;
	// stw r9,88(r11)
	PPC_STORE_U32(r11.u32 + 88, ctx.r9.u32);
loc_820A6B8C:
	// addi r1,r1,624
	ctx.r1.s64 = ctx.r1.s64 + 624;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820A6B98"))) PPC_WEAK_FUNC(sub_820A6B98);
PPC_FUNC_IMPL(__imp__sub_820A6B98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// addi r12,r1,-56
	r12.s64 = ctx.r1.s64 + -56;
	// bl 0x823ed544
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r27,r28,936
	r27.s64 = r28.s64 * 936;
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r9,r27,r10
	ctx.r9.u64 = r27.u64 + ctx.r10.u64;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// addi r8,r11,8
	ctx.r8.s64 = r11.s64 + 8;
	// lwz r10,2344(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2344);
	// mulli r10,r10,56
	ctx.r10.s64 = ctx.r10.s64 * 56;
	// lwzx r8,r10,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820a6bec
	if (!cr6.getEQ()) goto loc_820A6BEC;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x820a6bf4
	goto loc_820A6BF4;
loc_820A6BEC:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r10,r11,1240
	ctx.r10.s64 = r11.s64 + 1240;
loc_820A6BF4:
	// lwz r11,2752(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2752);
	// lfs f29,64(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 64);
	f29.f64 = double(temp.f32);
	// rlwinm r30,r28,2,0,29
	r30.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r11,2
	ctx.r10.s64 = r11.s64 + 2;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// srawi r7,r10,2
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
	ctx.r7.s64 = ctx.r10.s32 >> 2;
	// addi r8,r1,88
	ctx.r8.s64 = ctx.r1.s64 + 88;
	// addze r7,r7
	temp.s64 = ctx.r7.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r7.u32;
	ctx.r7.s64 = temp.s64;
	// srawi r6,r11,2
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x3) != 0);
	ctx.r6.s64 = r11.s32 >> 2;
	// rlwinm r7,r7,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 2) & 0xFFFFFFFC;
	// addze r6,r6
	temp.s64 = ctx.r6.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r6.u32;
	ctx.r6.s64 = temp.s64;
	// subf r10,r7,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r7.s64;
	// rlwinm r7,r6,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r29,r1,80
	r29.s64 = ctx.r1.s64 + 80;
	// subf r11,r7,r11
	r11.s64 = r11.s64 - ctx.r7.s64;
	// stwx r10,r30,r29
	PPC_STORE_U32(r30.u32 + r29.u32, ctx.r10.u32);
	// stwx r11,r30,r8
	PPC_STORE_U32(r30.u32 + ctx.r8.u32, r11.u32);
	// stw r11,2752(r9)
	PPC_STORE_U32(ctx.r9.u32 + 2752, r11.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r26,r3,31
	r26.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lwzx r9,r30,r29
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + r29.u32);
	// mulli r10,r28,78
	ctx.r10.s64 = r28.s64 * 78;
	// add r11,r11,r26
	r11.u64 = r11.u64 + r26.u64;
	// add r29,r10,r9
	r29.u64 = ctx.r10.u64 + ctx.r9.u64;
	// clrldi r10,r11,32
	ctx.r10.u64 = r11.u64 & 0xFFFFFFFF;
	// rlwinm r11,r29,1,0,30
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// add r11,r29,r11
	r11.u64 = r29.u64 + r11.u64;
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f31,14028(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 14028);
	f31.f64 = double(temp.f32);
	// add r10,r30,r11
	ctx.r10.u64 = r30.u64 + r11.u64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f30.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmsubs f0,f0,f31,f30
	f0.f64 = double(float(f0.f64 * f31.f64 - f30.f64));
	// fmuls f13,f0,f29
	ctx.f13.f64 = double(float(f0.f64 * f29.f64));
	// lfs f0,14260(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14260);
	f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,2656(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 2656, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r28,r3,31
	r28.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r10,r3,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r11,r29,222
	r11.s64 = r29.s64 + 222;
	// add r10,r10,r28
	ctx.r10.u64 = ctx.r10.u64 + r28.u64;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// clrldi r8,r10,32
	ctx.r8.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lfs f27,6580(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 6580);
	f27.f64 = double(temp.f32);
	// lwz r9,-1364(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// lfd f0,80(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// add r9,r30,r9
	ctx.r9.u64 = r30.u64 + ctx.r9.u64;
	// lfs f28,13964(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13964);
	f28.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmsubs f0,f0,f31,f30
	f0.f64 = double(float(f0.f64 * f31.f64 - f30.f64));
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,2660(r9)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 2660, temp.u32);
	// stfsx f27,r10,r11
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r28,r3,31
	r28.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r10,r3,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r10,r10,r28
	ctx.r10.u64 = ctx.r10.u64 + r28.u64;
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// clrldi r10,r10,32
	ctx.r10.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,2776(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	f0.f64 = double(temp.f32);
	// stfs f0,2708(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2708, temp.u32);
	// lfd f0,80(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmsubs f0,f0,f31,f30
	f0.f64 = double(float(f0.f64 * f31.f64 - f30.f64));
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,2704(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2704, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r28,r3,31
	r28.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r10,r3,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r11,r29,226
	r11.s64 = r29.s64 + 226;
	// add r10,r10,r28
	ctx.r10.u64 = ctx.r10.u64 + r28.u64;
	// clrldi r9,r10,32
	ctx.r9.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmsubs f0,f0,f31,f30
	f0.f64 = double(float(f0.f64 * f31.f64 - f30.f64));
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfsx f0,r10,r11
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r28,r3,31
	r28.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// rlwinm r10,r3,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f0,12888(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12888);
	f0.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r9,r30,r11
	ctx.r9.u64 = r30.u64 + r11.u64;
	// add r11,r10,r28
	r11.u64 = ctx.r10.u64 + r28.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 * f31.f64));
	// lfs f13,12896(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12896);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f12,f0,f13
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// stfs f0,2608(r9)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 2608, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r28,r3,31
	r28.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r10,r3,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r10,r10,r28
	ctx.r10.u64 = ctx.r10.u64 + r28.u64;
	// add r9,r27,r11
	ctx.r9.u64 = r27.u64 + r11.u64;
	// add r8,r30,r11
	ctx.r8.u64 = r30.u64 + r11.u64;
	// clrldi r11,r10,32
	r11.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// lfs f13,2764(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2764);
	ctx.f13.f64 = double(temp.f32);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lfd f0,80(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// frsp f12,f0
	ctx.f12.f64 = double(float(f0.f64));
	// lfs f0,3060(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3060);
	f0.f64 = double(temp.f32);
	// fmadds f0,f12,f31,f0
	f0.f64 = double(float(ctx.f12.f64 * f31.f64 + f0.f64));
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,2612(r8)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r8.u32 + 2612, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r28,r3,31
	r28.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r10,r3,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r11,r29,218
	r11.s64 = r29.s64 + 218;
	// add r10,r10,r28
	ctx.r10.u64 = ctx.r10.u64 + r28.u64;
	// clrldi r9,r10,32
	ctx.r9.u64 = ctx.r10.u64 & 0xFFFFFFFF;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// std r9,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r9.u64);
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmsubs f13,f0,f31,f30
	ctx.f13.f64 = double(float(f0.f64 * f31.f64 - f30.f64));
	// lfs f0,14132(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14132);
	f0.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfsx f0,r10,r11
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, temp.u32);
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// add r11,r27,r10
	r11.u64 = r27.u64 + ctx.r10.u64;
	// lwz r9,2768(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2768);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bge cr6,0x820a6ed4
	if (!cr6.getLT()) goto loc_820A6ED4;
	// add r10,r30,r10
	ctx.r10.u64 = r30.u64 + ctx.r10.u64;
	// lfs f0,2608(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2608);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f27
	f0.f64 = double(float(f0.f64 * f27.f64));
	// stfs f0,2608(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 2608, temp.u32);
	// lwz r10,2768(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2768);
	// cmpwi cr6,r10,-2
	cr6.compare<int32_t>(ctx.r10.s32, -2, xer);
	// bne cr6,0x820a6ecc
	if (!cr6.getEQ()) goto loc_820A6ECC;
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x820a6ee4
	goto loc_820A6EE4;
loc_820A6ECC:
	// li r10,-2
	ctx.r10.s64 = -2;
	// b 0x820a6ee4
	goto loc_820A6EE4;
loc_820A6ED4:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// li r10,-1
	ctx.r10.s64 = -1;
	// beq cr6,0x820a6ee4
	if (cr6.getEQ()) goto loc_820A6EE4;
	// li r10,2
	ctx.r10.s64 = 2;
loc_820A6EE4:
	// stw r10,2768(r11)
	PPC_STORE_U32(r11.u32 + 2768, ctx.r10.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r11,r27,r11
	r11.u64 = r27.u64 + r11.u64;
	// lfs f0,2764(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2764);
	f0.f64 = double(temp.f32);
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// stfs f0,2764(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2764, temp.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// addi r12,r1,-56
	r12.s64 = ctx.r1.s64 + -56;
	// bl 0x823ed590
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820A6F10"))) PPC_WEAK_FUNC(sub_820A6F10);
PPC_FUNC_IMPL(__imp__sub_820A6F10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mulli r10,r3,936
	ctx.r10.s64 = ctx.r3.s64 * 936;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lwz r10,2380(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2380);
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// bne cr6,0x820a6f5c
	if (!cr6.getEQ()) goto loc_820A6F5C;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// bge cr6,0x820a6f44
	if (!cr6.getLT()) goto loc_820A6F44;
	// lwz r10,2416(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2416);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bgt cr6,0x820a6f64
	if (cr6.getGT()) goto loc_820A6F64;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
loc_820A6F44:
	// ble cr6,0x820a6f54
	if (!cr6.getGT()) goto loc_820A6F54;
	// lwz r10,2416(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2416);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blt cr6,0x820a6f64
	if (cr6.getLT()) goto loc_820A6F64;
loc_820A6F54:
	// lwz r3,2404(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 2404);
	// blr 
	return;
loc_820A6F5C:
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// beq cr6,0x820a6f54
	if (cr6.getEQ()) goto loc_820A6F54;
loc_820A6F64:
	// lwz r3,2344(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A6F70"))) PPC_WEAK_FUNC(sub_820A6F70);
PPC_FUNC_IMPL(__imp__sub_820A6F70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r30,-32014
	r30.s64 = -2098069504;
	// mulli r31,r3,936
	r31.s64 = ctx.r3.s64 * 936;
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// lwz r10,2380(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2380);
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// beq cr6,0x820a6fa8
	if (cr6.getEQ()) goto loc_820A6FA8;
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x820a6fd8
	if (!cr6.getEQ()) goto loc_820A6FD8;
loc_820A6FA8:
	// lwz r10,2376(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2376);
	// stw r10,2408(r11)
	PPC_STORE_U32(r11.u32 + 2408, ctx.r10.u32);
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// lwz r10,2408(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2408);
	// bne cr6,0x820a6fd0
	if (!cr6.getEQ()) goto loc_820A6FD0;
	// addi r10,r10,17
	ctx.r10.s64 = ctx.r10.s64 + 17;
	// b 0x820a6fd4
	goto loc_820A6FD4;
loc_820A6FD0:
	// addi r10,r10,13
	ctx.r10.s64 = ctx.r10.s64 + 13;
loc_820A6FD4:
	// stw r10,2408(r11)
	PPC_STORE_U32(r11.u32 + 2408, ctx.r10.u32);
loc_820A6FD8:
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// lwz r9,2380(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2380);
	// cmpwi cr6,r9,5
	cr6.compare<int32_t>(ctx.r9.s32, 5, xer);
	// bne cr6,0x820a6ff4
	if (!cr6.getEQ()) goto loc_820A6FF4;
	// lwz r10,2404(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2404);
	// b 0x820a7008
	goto loc_820A7008;
loc_820A6FF4:
	// cmpwi cr6,r9,6
	cr6.compare<int32_t>(ctx.r9.s32, 6, xer);
	// bne cr6,0x820a7004
	if (!cr6.getEQ()) goto loc_820A7004;
	// lwz r10,2404(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2404);
	// b 0x820a7008
	goto loc_820A7008;
loc_820A7004:
	// lwz r10,2344(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2344);
loc_820A7008:
	// cmpw cr6,r10,r29
	cr6.compare<int32_t>(ctx.r10.s32, r29.s32, xer);
	// beq cr6,0x820a7050
	if (cr6.getEQ()) goto loc_820A7050;
	// cmpwi cr6,r9,5
	cr6.compare<int32_t>(ctx.r9.s32, 5, xer);
	// beq cr6,0x820a7028
	if (cr6.getEQ()) goto loc_820A7028;
	// cmpwi cr6,r9,6
	cr6.compare<int32_t>(ctx.r9.s32, 6, xer);
	// beq cr6,0x820a7028
	if (cr6.getEQ()) goto loc_820A7028;
	// li r10,5
	ctx.r10.s64 = 5;
	// stw r10,2384(r11)
	PPC_STORE_U32(r11.u32 + 2384, ctx.r10.u32);
loc_820A7028:
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// li r10,1
	ctx.r10.s64 = 1;
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// stw r29,2404(r11)
	PPC_STORE_U32(r11.u32 + 2404, r29.u32);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// stw r10,2412(r11)
	PPC_STORE_U32(r11.u32 + 2412, ctx.r10.u32);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// stw r28,2416(r11)
	PPC_STORE_U32(r11.u32 + 2416, r28.u32);
loc_820A7050:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820A7058"))) PPC_WEAK_FUNC(sub_820A7058);
PPC_FUNC_IMPL(__imp__sub_820A7058) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,2380(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2380);
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// bne cr6,0x820a708c
	if (!cr6.getEQ()) goto loc_820A708C;
	// lwz r10,2416(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2416);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blt cr6,0x820a709c
	if (cr6.getLT()) goto loc_820A709C;
	// lwz r9,2404(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2404);
	// b 0x820a70a0
	goto loc_820A70A0;
loc_820A708C:
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x820a709c
	if (!cr6.getEQ()) goto loc_820A709C;
	// lwz r9,2404(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2404);
	// b 0x820a70a0
	goto loc_820A70A0;
loc_820A709C:
	// lwz r9,2344(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2344);
loc_820A70A0:
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// lwz r10,3316(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3316);
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// bne cr6,0x820a70c4
	if (!cr6.getEQ()) goto loc_820A70C4;
	// lwz r10,3352(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3352);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blt cr6,0x820a70d4
	if (cr6.getLT()) goto loc_820A70D4;
	// lwz r10,3340(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3340);
	// b 0x820a70d8
	goto loc_820A70D8;
loc_820A70C4:
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x820a70d4
	if (!cr6.getEQ()) goto loc_820A70D4;
	// lwz r10,3340(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3340);
	// b 0x820a70d8
	goto loc_820A70D8;
loc_820A70D4:
	// lwz r10,3280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3280);
loc_820A70D8:
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// cmpwi cr6,r9,32
	cr6.compare<int32_t>(ctx.r9.s32, 32, xer);
	// bgt cr6,0x820a70ec
	if (cr6.getGT()) goto loc_820A70EC;
	// cmpwi cr6,r10,32
	cr6.compare<int32_t>(ctx.r10.s32, 32, xer);
	// ble cr6,0x820a710c
	if (!cr6.getGT()) goto loc_820A710C;
loc_820A70EC:
	// lwz r10,2352(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2352);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// lwz r11,3288(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 3288);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bne cr6,0x820a7120
	if (!cr6.getEQ()) goto loc_820A7120;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820a7120
	if (!cr6.getEQ()) goto loc_820A7120;
loc_820A710C:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820c2240
	sub_820C2240(ctx, base);
loc_820A7120:
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820a6f70
	sub_820A6F70(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x820a6f70
	sub_820A6F70(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A7150"))) PPC_WEAK_FUNC(sub_820A7150);
PPC_FUNC_IMPL(__imp__sub_820A7150) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,2380(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2380);
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// bne cr6,0x820a71cc
	if (!cr6.getEQ()) goto loc_820A71CC;
	// lwz r10,2416(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2416);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// ble cr6,0x820a71d4
	if (!cr6.getGT()) goto loc_820A71D4;
loc_820A717C:
	// lwz r9,2344(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2344);
loc_820A7180:
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// lwz r10,3316(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3316);
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// bne cr6,0x820a71dc
	if (!cr6.getEQ()) goto loc_820A71DC;
	// lwz r10,3352(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3352);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// ble cr6,0x820a71e4
	if (!cr6.getGT()) goto loc_820A71E4;
loc_820A719C:
	// lwz r10,3280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3280);
loc_820A71A0:
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// cmpwi cr6,r9,32
	cr6.compare<int32_t>(ctx.r9.s32, 32, xer);
	// bgt cr6,0x820a71ec
	if (cr6.getGT()) goto loc_820A71EC;
	// cmpwi cr6,r10,32
	cr6.compare<int32_t>(ctx.r10.s32, 32, xer);
	// bgt cr6,0x820a71ec
	if (cr6.getGT()) goto loc_820A71EC;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820c1230
	sub_820C1230(ctx, base);
	// b 0x820a71fc
	goto loc_820A71FC;
loc_820A71CC:
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x820a717c
	if (!cr6.getEQ()) goto loc_820A717C;
loc_820A71D4:
	// lwz r9,2404(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2404);
	// b 0x820a7180
	goto loc_820A7180;
loc_820A71DC:
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x820a719c
	if (!cr6.getEQ()) goto loc_820A719C;
loc_820A71E4:
	// lwz r10,3340(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3340);
	// b 0x820a71a0
	goto loc_820A71A0;
loc_820A71EC:
	// lwz r10,2352(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2352);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// lwz r11,3288(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 3288);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
loc_820A71FC:
	// li r5,-1
	ctx.r5.s64 = -1;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820a6f70
	sub_820A6F70(ctx, base);
	// li r5,-1
	ctx.r5.s64 = -1;
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x820a6f70
	sub_820A6F70(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A7230"))) PPC_WEAK_FUNC(sub_820A7230);
PPC_FUNC_IMPL(__imp__sub_820A7230) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,2380(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2380);
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// bne cr6,0x820a7264
	if (!cr6.getEQ()) goto loc_820A7264;
	// lwz r10,2416(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2416);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blt cr6,0x820a7274
	if (cr6.getLT()) goto loc_820A7274;
	// lwz r9,2404(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2404);
	// b 0x820a7278
	goto loc_820A7278;
loc_820A7264:
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x820a7274
	if (!cr6.getEQ()) goto loc_820A7274;
	// lwz r9,2404(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2404);
	// b 0x820a7278
	goto loc_820A7278;
loc_820A7274:
	// lwz r9,2344(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2344);
loc_820A7278:
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// lwz r10,3316(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3316);
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// bne cr6,0x820a729c
	if (!cr6.getEQ()) goto loc_820A729C;
	// lwz r10,3352(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3352);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blt cr6,0x820a72ac
	if (cr6.getLT()) goto loc_820A72AC;
	// lwz r11,3340(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 3340);
	// b 0x820a72b0
	goto loc_820A72B0;
loc_820A729C:
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x820a72ac
	if (!cr6.getEQ()) goto loc_820A72AC;
	// lwz r11,3340(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 3340);
	// b 0x820a72b0
	goto loc_820A72B0;
loc_820A72AC:
	// lwz r11,3280(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 3280);
loc_820A72B0:
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// ble cr6,0x820a72c4
	if (!cr6.getGT()) goto loc_820A72C4;
	// cmpwi cr6,r9,32
	cr6.compare<int32_t>(ctx.r9.s32, 32, xer);
	// ble cr6,0x820a72d4
	if (!cr6.getGT()) goto loc_820A72D4;
loc_820A72C4:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a72fc
	if (!cr6.getGT()) goto loc_820A72FC;
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// bgt cr6,0x820a72fc
	if (cr6.getGT()) goto loc_820A72FC;
loc_820A72D4:
	// cmpwi cr6,r9,1
	cr6.compare<int32_t>(ctx.r9.s32, 1, xer);
	// beq cr6,0x820a72f0
	if (cr6.getEQ()) goto loc_820A72F0;
	// li r11,1
	r11.s64 = 1;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// b 0x820a7310
	goto loc_820A7310;
loc_820A72F0:
	// li r11,33
	r11.s64 = 33;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
loc_820A72FC:
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820c2240
	sub_820C2240(ctx, base);
loc_820A7310:
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820a6f70
	sub_820A6F70(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x820a6f70
	sub_820A6F70(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A7340"))) PPC_WEAK_FUNC(sub_820A7340);
PPC_FUNC_IMPL(__imp__sub_820A7340) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,2380(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2380);
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// bne cr6,0x820a737c
	if (!cr6.getEQ()) goto loc_820A737C;
	// lwz r10,2416(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2416);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blt cr6,0x820a738c
	if (cr6.getLT()) goto loc_820A738C;
	// lwz r30,2404(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 2404);
	// b 0x820a7390
	goto loc_820A7390;
loc_820A737C:
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x820a738c
	if (!cr6.getEQ()) goto loc_820A738C;
	// lwz r30,2404(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 2404);
	// b 0x820a7390
	goto loc_820A7390;
loc_820A738C:
	// lwz r30,2344(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 2344);
loc_820A7390:
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// lwz r10,3316(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3316);
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// bne cr6,0x820a73b4
	if (!cr6.getEQ()) goto loc_820A73B4;
	// lwz r10,3352(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3352);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blt cr6,0x820a73c4
	if (cr6.getLT()) goto loc_820A73C4;
	// lwz r31,3340(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 3340);
	// b 0x820a73c8
	goto loc_820A73C8;
loc_820A73B4:
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x820a73c4
	if (!cr6.getEQ()) goto loc_820A73C4;
	// lwz r31,3340(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 3340);
	// b 0x820a73c8
	goto loc_820A73C8;
loc_820A73C4:
	// lwz r31,3280(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 3280);
loc_820A73C8:
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// cmpwi cr6,r30,32
	cr6.compare<int32_t>(r30.s32, 32, xer);
	// bgt cr6,0x820a7458
	if (cr6.getGT()) goto loc_820A7458;
	// cmpwi cr6,r31,32
	cr6.compare<int32_t>(r31.s32, 32, xer);
	// bgt cr6,0x820a7458
	if (cr6.getGT()) goto loc_820A7458;
	// cmpwi cr6,r30,29
	cr6.compare<int32_t>(r30.s32, 29, xer);
	// bne cr6,0x820a7404
	if (!cr6.getEQ()) goto loc_820A7404;
	// li r3,30
	ctx.r3.s64 = 30;
	// bl 0x820c0cc8
	sub_820C0CC8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820a7404
	if (cr6.getEQ()) goto loc_820A7404;
	// li r4,30
	ctx.r4.s64 = 30;
	// li r11,0
	r11.s64 = 0;
	// stw r4,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r4.u32);
	// b 0x820a7464
	goto loc_820A7464;
loc_820A7404:
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820c2240
	sub_820C2240(ctx, base);
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpw cr6,r4,r30
	cr6.compare<int32_t>(ctx.r4.s32, r30.s32, xer);
	// blt cr6,0x820a7434
	if (cr6.getLT()) goto loc_820A7434;
	// bne cr6,0x820a7468
	if (!cr6.getEQ()) goto loc_820A7468;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpw cr6,r11,r31
	cr6.compare<int32_t>(r11.s32, r31.s32, xer);
	// bgt cr6,0x820a7468
	if (cr6.getGT()) goto loc_820A7468;
loc_820A7434:
	// li r6,0
	ctx.r6.s64 = 0;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// li r5,1
	ctx.r5.s64 = 1;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820c1230
	sub_820C1230(ctx, base);
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// b 0x820a7468
	goto loc_820A7468;
loc_820A7458:
	// lwz r4,2352(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 2352);
	// stw r4,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r4.u32);
	// lwz r11,3288(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 3288);
loc_820A7464:
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
loc_820A7468:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820a6f70
	sub_820A6F70(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x820a6f70
	sub_820A6F70(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A74A0"))) PPC_WEAK_FUNC(sub_820A74A0);
PPC_FUNC_IMPL(__imp__sub_820A74A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mulli r10,r3,936
	ctx.r10.s64 = ctx.r3.s64 * 936;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// lwz r10,2344(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2344);
	// addi r8,r11,8
	ctx.r8.s64 = r11.s64 + 8;
	// mulli r10,r10,56
	ctx.r10.s64 = ctx.r10.s64 * 56;
	// lwzx r8,r10,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820a74dc
	if (!cr6.getEQ()) goto loc_820A74DC;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x820a74e4
	goto loc_820A74E4;
loc_820A74DC:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
loc_820A74E4:
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lwz r11,2384(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
	// li r11,9
	r11.s64 = 9;
	// stw r11,2384(r9)
	PPC_STORE_U32(ctx.r9.u32 + 2384, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A7508"))) PPC_WEAK_FUNC(sub_820A7508);
PPC_FUNC_IMPL(__imp__sub_820A7508) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r10,r11,6504
	ctx.r10.s64 = r11.s64 + 6504;
	// mulli r30,r29,936
	r30.s64 = r29.s64 * 936;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r8,r30,r11
	ctx.r8.u64 = r30.u64 + r11.u64;
	// addi r7,r10,8
	ctx.r7.s64 = ctx.r10.s64 + 8;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// lwz r6,2344(r8)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r8.u32 + 2344);
	// mulli r9,r6,56
	ctx.r9.s64 = ctx.r6.s64 * 56;
	// lwzx r7,r9,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x820a7558
	if (!cr6.getEQ()) goto loc_820A7558;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// b 0x820a7560
	goto loc_820A7560;
loc_820A7558:
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// addi r10,r10,1240
	ctx.r10.s64 = ctx.r10.s64 + 1240;
loc_820A7560:
	// lwz r9,2348(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 2348);
	// lwz r5,28(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bge cr6,0x820a7580
	if (!cr6.getLT()) goto loc_820A7580;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820a0ad8
	sub_820A0AD8(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
loc_820A7580:
	// add r10,r30,r11
	ctx.r10.u64 = r30.u64 + r11.u64;
	// lwz r9,2388(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2388);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// ble cr6,0x820a75a8
	if (!cr6.getGT()) goto loc_820A75A8;
	// addi r10,r5,1145
	ctx.r10.s64 = ctx.r5.s64 + 1145;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
loc_820A75A8:
	// cmpwi cr6,r6,32
	cr6.compare<int32_t>(ctx.r6.s32, 32, xer);
	// bgt cr6,0x820a75c0
	if (cr6.getGT()) goto loc_820A75C0;
	// cmpwi cr6,r6,1
	cr6.compare<int32_t>(ctx.r6.s32, 1, xer);
	// beq cr6,0x820a75c0
	if (cr6.getEQ()) goto loc_820A75C0;
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// stw r6,2352(r11)
	PPC_STORE_U32(r11.u32 + 2352, ctx.r6.u32);
loc_820A75C0:
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820a75d4
	if (!cr6.getGT()) goto loc_820A75D4;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820c9f20
	sub_820C9F20(ctx, base);
loc_820A75D4:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r29,0
	r29.s64 = 0;
	// add r10,r30,r11
	ctx.r10.u64 = r30.u64 + r11.u64;
	// addi r28,r10,2344
	r28.s64 = ctx.r10.s64 + 2344;
	// lwz r3,544(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 544);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a7600
	if (cr6.getEQ()) goto loc_820A7600;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x820e0358
	sub_820E0358(ctx, base);
	// stw r29,544(r28)
	PPC_STORE_U32(r28.u32 + 544, r29.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
loc_820A7600:
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// stw r27,2344(r11)
	PPC_STORE_U32(r11.u32 + 2344, r27.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// stw r29,2388(r11)
	PPC_STORE_U32(r11.u32 + 2388, r29.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// stw r29,2820(r11)
	PPC_STORE_U32(r11.u32 + 2820, r29.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// stw r29,2824(r11)
	PPC_STORE_U32(r11.u32 + 2824, r29.u32);
	// bl 0x820c2750
	sub_820C2750(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820A7638"))) PPC_WEAK_FUNC(sub_820A7638);
PPC_FUNC_IMPL(__imp__sub_820A7638) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r3,56
	r11.s64 = ctx.r3.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r8,r11,r9
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// lis r9,-32190
	ctx.r9.s64 = -2109603840;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// addi r7,r9,1240
	ctx.r7.s64 = ctx.r9.s64 + 1240;
	// bne cr6,0x820a7668
	if (!cr6.getEQ()) goto loc_820A7668;
	// addi r9,r10,12
	ctx.r9.s64 = ctx.r10.s64 + 12;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// b 0x820a766c
	goto loc_820A766C;
loc_820A7668:
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
loc_820A766C:
	// lwz r9,108(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 108);
	// rlwinm r9,r9,0,13,13
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0x40000;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820a76e0
	if (cr6.getEQ()) goto loc_820A76E0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820a7690
	if (!cr6.getEQ()) goto loc_820A7690;
	// addi r9,r10,12
	ctx.r9.s64 = ctx.r10.s64 + 12;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// b 0x820a7694
	goto loc_820A7694;
loc_820A7690:
	// mr r9,r7
	ctx.r9.u64 = ctx.r7.u64;
loc_820A7694:
	// lwz r9,28(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x820a76d8
	if (cr6.getEQ()) goto loc_820A76D8;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820a76b4
	if (!cr6.getEQ()) goto loc_820A76B4;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820a76b8
	goto loc_820A76B8;
loc_820A76B4:
	// mr r11,r7
	r11.u64 = ctx.r7.u64;
loc_820A76B8:
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// addi r11,r11,1145
	r11.s64 = r11.s64 + 1145;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a76e0
	if (!cr6.getGT()) goto loc_820A76E0;
loc_820A76D8:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
loc_820A76E0:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A76E8"))) PPC_WEAK_FUNC(sub_820A76E8);
PPC_FUNC_IMPL(__imp__sub_820A76E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f22{};
	PPCRegister f23{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// addi r12,r1,-24
	r12.s64 = ctx.r1.s64 + -24;
	// bl 0x823ed530
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f23,f3
	ctx.fpscr.disableFlushMode();
	f23.f64 = ctx.f3.f64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f28,f1
	f28.f64 = ctx.f1.f64;
	// fmr f22,f4
	f22.f64 = ctx.f4.f64;
	// lfs f24,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f24.f64 = double(temp.f32);
	// fmr f29,f23
	f29.f64 = f23.f64;
	// fcmpu cr6,f23,f24
	cr6.compare(f23.f64, f24.f64);
	// bge cr6,0x820a7728
	if (!cr6.getLT()) goto loc_820A7728;
	// fneg f29,f23
	f29.u64 = f23.u64 ^ 0x8000000000000000;
loc_820A7728:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f31,14112(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14112);
	f31.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f27,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	f27.f64 = double(temp.f32);
	// fcmpu cr6,f2,f31
	cr6.compare(ctx.f2.f64, f31.f64);
	// lfs f25,13964(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13964);
	f25.f64 = double(temp.f32);
	// ble cr6,0x820a775c
	if (!cr6.getGT()) goto loc_820A775C;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r31,r11,-1364
	r31.s64 = r11.s64 + -1364;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f27,4216(r11)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r11.u32 + 4216, temp.u32);
	// b 0x820a77b0
	goto loc_820A77B0;
loc_820A775C:
	// fcmpu cr6,f2,f25
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f2.f64, f25.f64);
	// ble cr6,0x820a77a0
	if (!cr6.getGT()) goto loc_820A77A0;
	// fsubs f13,f2,f25
	ctx.f13.f64 = double(float(ctx.f2.f64 - f25.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,14284(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14284);
	f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r31,r11,-1364
	r31.s64 = r11.s64 + -1364;
	// lfs f13,12892(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 12892);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// fsubs f0,f27,f0
	f0.f64 = double(float(f27.f64 - f0.f64));
	// fmadds f0,f0,f31,f13
	f0.f64 = double(float(f0.f64 * f31.f64 + ctx.f13.f64));
	// stfs f0,4216(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4216, temp.u32);
	// b 0x820a77b0
	goto loc_820A77B0;
loc_820A77A0:
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r31,r11,-1364
	r31.s64 = r11.s64 + -1364;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f25,4216(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f25.f64);
	PPC_STORE_U32(r11.u32 + 4216, temp.u32);
loc_820A77B0:
	// addi r10,r11,4216
	ctx.r10.s64 = r11.s64 + 4216;
	// lfs f30,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f30.f64 = double(temp.f32);
	// bl 0x820b3cd0
	sub_820B3CD0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,14016(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14016);
	f31.f64 = double(temp.f32);
	// fmuls f0,f1,f31
	f0.f64 = double(float(ctx.f1.f64 * f31.f64));
	// fcmpu cr6,f30,f0
	cr6.compare(f30.f64, f0.f64);
	// bge cr6,0x820a77e0
	if (!cr6.getLT()) goto loc_820A77E0;
	// bl 0x820b3cd0
	sub_820B3CD0(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// fmuls f0,f1,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 * f31.f64));
	// stfs f0,4216(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4216, temp.u32);
loc_820A77E0:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f26,2692(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f26.f64 = double(temp.f32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// fmuls f0,f29,f26
	f0.f64 = double(float(f29.f64 * f26.f64));
	// addi r7,r11,4216
	ctx.r7.s64 = r11.s64 + 4216;
	// lfs f13,4216(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4216);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820a7808
	if (!cr6.getGT()) goto loc_820A7808;
	// stfs f0,0(r7)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
loc_820A7808:
	// lis r9,-32014
	ctx.r9.s64 = -2098069504;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r8,-6384(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + -6384);
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lfs f12,14280(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 14280);
	ctx.f12.f64 = double(temp.f32);
	// ble cr6,0x820a7848
	if (!cr6.getGT()) goto loc_820A7848;
loc_820A7824:
	// lfs f0,4408(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4408);
	f0.f64 = double(temp.f32);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lfs f13,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f0,f12,f13
	f0.f64 = double(float(f0.f64 * ctx.f12.f64 + ctx.f13.f64));
	// stfs f0,4408(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4408, temp.u32);
	// lwz r8,-6384(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + -6384);
	// cmpw cr6,r10,r8
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r8.s32, xer);
	// blt cr6,0x820a7824
	if (cr6.getLT()) goto loc_820A7824;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_820A7848:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f11,4408(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4408);
	ctx.f11.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,6576(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6576);
	f0.f64 = double(temp.f32);
	// fmuls f0,f29,f0
	f0.f64 = double(float(f29.f64 * f0.f64));
	// lfs f13,14276(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14276);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// stfs f11,0(r7)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r7.u32 + 0, temp.u32);
	// fcmpu cr6,f0,f28
	cr6.compare(f0.f64, f28.f64);
	// ble cr6,0x820a7874
	if (!cr6.getGT()) goto loc_820A7874;
	// fmr f28,f0
	f28.f64 = f0.f64;
loc_820A7874:
	// lwz r10,-6384(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + -6384);
	// li r11,0
	r11.s64 = 0;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// ble cr6,0x820a78a4
	if (!cr6.getGT()) goto loc_820A78A4;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_820A7888:
	// lfs f0,4404(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4404);
	f0.f64 = double(temp.f32);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// fmadds f0,f0,f12,f28
	f0.f64 = double(float(f0.f64 * ctx.f12.f64 + f28.f64));
	// stfs f0,4404(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4404, temp.u32);
	// lwz r8,-6384(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + -6384);
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// blt cr6,0x820a7888
	if (cr6.getLT()) goto loc_820A7888;
loc_820A78A4:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r30,-32014
	r30.s64 = -2098069504;
	// lfs f0,4404(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4404);
	f0.f64 = double(temp.f32);
	// fmuls f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 * ctx.f13.f64));
	// lfs f0,-6368(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + -6368);
	f0.f64 = double(temp.f32);
	// lfs f12,2756(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2756);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f31,f13,f0
	f31.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fadds f30,f12,f31
	f30.f64 = double(float(ctx.f12.f64 + f31.f64));
	// fcmpu cr6,f30,f27
	cr6.compare(f30.f64, f27.f64);
	// blt cr6,0x820a78f8
	if (cr6.getLT()) goto loc_820A78F8;
loc_820A78CC:
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820a6b98
	sub_820A6B98(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// fsubs f30,f30,f27
	ctx.fpscr.disableFlushMode();
	f30.f64 = double(float(f30.f64 - f27.f64));
	// lwz r10,4400(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4400);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// fcmpu cr6,f30,f27
	cr6.compare(f30.f64, f27.f64);
	// stw r10,4400(r11)
	PPC_STORE_U32(r11.u32 + 4400, ctx.r10.u32);
	// bge cr6,0x820a78cc
	if (!cr6.getLT()) goto loc_820A78CC;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,-6368(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + -6368);
	f0.f64 = double(temp.f32);
loc_820A78F8:
	// lfs f13,4396(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4396);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// stfs f0,4396(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4396, temp.u32);
	// lfs f13,13960(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13960);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820a7960
	if (!cr6.getGT()) goto loc_820A7960;
	// stfs f24,4396(r11)
	temp.f32 = float(f24.f64);
	PPC_STORE_U32(r11.u32 + 4396, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f0,14028(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14028);
	f0.f64 = double(temp.f32);
	// std r11,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmsubs f13,f13,f0,f26
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 - f26.f64));
	// lfs f0,14272(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14272);
	f0.f64 = double(temp.f32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,4392(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4392, temp.u32);
loc_820A7960:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,4392(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4392);
	f0.f64 = double(temp.f32);
	// fadds f13,f0,f31
	ctx.f13.f64 = double(float(f0.f64 + f31.f64));
	// fcmpu cr6,f13,f24
	cr6.compare(ctx.f13.f64, f24.f64);
	// ble cr6,0x820a7984
	if (!cr6.getGT()) goto loc_820A7984;
	// lfs f13,4388(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4388);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// stfs f0,4388(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4388, temp.u32);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
loc_820A7984:
	// lfs f0,4388(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4388);
	f0.f64 = double(temp.f32);
	// addi r10,r11,4388
	ctx.r10.s64 = r11.s64 + 4388;
	// fcmpu cr6,f0,f26
	cr6.compare(f0.f64, f26.f64);
	// ble cr6,0x820a799c
	if (!cr6.getGT()) goto loc_820A799C;
	// stfs f26,0(r10)
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// b 0x820a79e0
	goto loc_820A79E0;
loc_820A799C:
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f13,6584(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 6584);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820a79b4
	if (!cr6.getLT()) goto loc_820A79B4;
	// stfs f13,0(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// b 0x820a79e0
	goto loc_820A79E0;
loc_820A79B4:
	// fcmpu cr6,f0,f25
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, f25.f64);
	// bge cr6,0x820a79e4
	if (!cr6.getLT()) goto loc_820A79E4;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f13,14044(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 14044);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820a79e4
	if (!cr6.getGT()) goto loc_820A79E4;
	// fcmpu cr6,f0,f24
	cr6.compare(f0.f64, f24.f64);
	// ble cr6,0x820a79dc
	if (!cr6.getGT()) goto loc_820A79DC;
	// stfs f13,0(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// b 0x820a79e0
	goto loc_820A79E0;
loc_820A79DC:
	// stfs f25,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f25.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
loc_820A79E0:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_820A79E4:
	// lwz r9,4400(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 4400);
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// extsw r10,r9
	ctx.r10.s64 = ctx.r9.s32;
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// lfd f13,80(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// fadds f31,f0,f30
	f31.f64 = double(float(f0.f64 + f30.f64));
	// fcmpu cr6,f31,f27
	cr6.compare(f31.f64, f27.f64);
	// blt cr6,0x820a7a38
	if (cr6.getLT()) goto loc_820A7A38;
loc_820A7A10:
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x820a6b98
	sub_820A6B98(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// fsubs f31,f31,f27
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(f31.f64 - f27.f64));
	// lwz r10,4400(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4400);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// fcmpu cr6,f31,f27
	cr6.compare(f31.f64, f27.f64);
	// stw r10,4400(r11)
	PPC_STORE_U32(r11.u32 + 4400, ctx.r10.u32);
	// bge cr6,0x820a7a10
	if (!cr6.getLT()) goto loc_820A7A10;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_820A7A38:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// stfs f30,2756(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r11.u32 + 2756, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,14268(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14268);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmuls f0,f22,f0
	f0.f64 = double(float(f22.f64 * f0.f64));
	// stfs f0,2772(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2772, temp.u32);
	// lfs f13,14264(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14264);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f23,f13
	ctx.f13.f64 = double(float(f23.f64 * ctx.f13.f64));
	// stfs f13,2776(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 2776, temp.u32);
	// stfs f31,3692(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 3692, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,3708(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 3708, temp.u32);
	// stfs f13,3712(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 3712, temp.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// addi r12,r1,-24
	r12.s64 = ctx.r1.s64 + -24;
	// bl 0x823ed57c
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820A7A90"))) PPC_WEAK_FUNC(sub_820A7A90);
PPC_FUNC_IMPL(__imp__sub_820A7A90) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stfd f29,-80(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -80, f29.u64);
	// stfd f30,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, f30.u64);
	// stfd f31,-64(r1)
	PPC_STORE_U64(ctx.r1.u32 + -64, f31.u64);
	// stwu r1,-432(r1)
	ea = -432 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x820b3e00
	sub_820B3E00(ctx, base);
	// lis r30,-32014
	r30.s64 = -2098069504;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// mulli r29,r31,936
	r29.s64 = r31.s64 * 936;
	// addi r10,r11,11808
	ctx.r10.s64 = r11.s64 + 11808;
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r4,r1,288
	ctx.r4.s64 = ctx.r1.s64 + 288;
	// add r11,r29,r11
	r11.u64 = r29.u64 + r11.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r26,2344(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// lwz r11,0(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// stw r11,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r11.u32);
	// lwz r11,8(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r11.u32);
	// bl 0x82136da8
	sub_82136DA8(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x820a49a0
	sub_820A49A0(ctx, base);
	// addi r31,r1,144
	r31.s64 = ctx.r1.s64 + 144;
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,144(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f10.f64 = double(temp.f32);
	// lfs f0,14288(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14288);
	f0.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f13,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f0
	ctx.f11.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f11,88(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lwz r11,-6384(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,2780(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2780);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f10,f10,f0,f13
	ctx.f10.f64 = double(float(ctx.f10.f64 * f0.f64 + ctx.f13.f64));
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// ble cr6,0x820a7bb0
	if (!cr6.getGT()) goto loc_820A7BB0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f9,0(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f0,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f13,-6368(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6368);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// lfs f13,12(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f12,4(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,16(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// fmadds f13,f13,f0,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f10.f64));
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f13,20(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// fmadds f0,f13,f0,f11
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f11.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
loc_820A7BB0:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a7c8c
	if (cr6.getEQ()) goto loc_820A7C8C;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820a7c8c
	if (cr6.getEQ()) goto loc_820A7C8C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
	// lfs f31,2952(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2952);
	f31.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f30.f64 = double(temp.f32);
	// fmadds f1,f0,f31,f30
	ctx.f1.f64 = double(float(f0.f64 * f31.f64 + f30.f64));
	// bl 0x8238ca58
	sub_8238CA58(ctx, base);
	// addi r11,r1,136
	r11.s64 = ctx.r1.s64 + 136;
	// lfs f0,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
	// fctiwz f13,f1
	ctx.f13.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// fmadds f1,f0,f31,f30
	ctx.f1.f64 = double(float(f0.f64 * f31.f64 + f30.f64));
	// stfiwx f13,0,r11
	PPC_STORE_U32(r11.u32, ctx.f13.u32);
	// bl 0x8238ca58
	sub_8238CA58(ctx, base);
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// lfs f0,88(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	f0.f64 = double(temp.f32);
	// fctiwz f13,f1
	ctx.f13.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// fmadds f1,f0,f31,f30
	ctx.f1.f64 = double(float(f0.f64 * f31.f64 + f30.f64));
	// stfiwx f13,0,r11
	PPC_STORE_U32(r11.u32, ctx.f13.u32);
	// bl 0x8238ca58
	sub_8238CA58(ctx, base);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// lwz r9,128(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r10,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r10.u64);
	// lfd f0,128(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// std r9,136(r1)
	PPC_STORE_U64(ctx.r1.u32 + 136, ctx.r9.u64);
	// lfd f13,136(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 136);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lfd f12,96(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// frsp f11,f0
	ctx.f11.f64 = double(float(f0.f64));
	// lfs f0,13964(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13964);
	f0.f64 = double(temp.f32);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * f0.f64));
	// stfs f11,80(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmuls f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * f0.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
loc_820A7C8C:
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// add r11,r29,r11
	r11.u64 = r29.u64 + r11.u64;
	// lfs f0,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
	// stfs f0,116(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f0,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	f0.f64 = double(temp.f32);
	// stfs f0,120(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f31,3008(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3008);
	f31.f64 = double(temp.f32);
	// lfs f30,3012(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3012);
	f30.f64 = double(temp.f32);
	// lfs f29,3016(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3016);
	f29.f64 = double(temp.f32);
	// stfs f31,96(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f30,100(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f29,104(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// add r11,r29,r11
	r11.u64 = r29.u64 + r11.u64;
	// addi r3,r11,2960
	ctx.r3.s64 = r11.s64 + 2960;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// stfs f0,208(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// stfs f0,212(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// stfs f0,216(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// li r3,196
	ctx.r3.s64 = 196;
	// bl 0x820e2be8
	sub_820E2BE8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a7e38
	if (cr6.getEQ()) goto loc_820A7E38;
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lwz r11,4372(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4372);
	// subfic r11,r11,240
	xer.ca = r11.u32 <= 240;
	r11.s64 = 240 - r11.s64;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// sth r11,130(r31)
	PPC_STORE_U16(r31.u32 + 130, r11.u16);
	// bge cr6,0x820a7d3c
	if (!cr6.getLT()) goto loc_820A7D3C;
	// li r11,0
	r11.s64 = 0;
	// sth r11,130(r31)
	PPC_STORE_U16(r31.u32 + 130, r11.u16);
loc_820A7D3C:
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,15,12
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFF9FFFF;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r10,r3,17,0,14
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 17) & 0xFFFE0000;
	// li r8,0
	ctx.r8.s64 = 0;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// addi r7,r1,288
	ctx.r7.s64 = ctx.r1.s64 + 288;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,224
	ctx.r5.s64 = ctx.r1.s64 + 224;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820a1800
	sub_820A1800(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a7dfc
	if (cr6.getEQ()) goto loc_820A7DFC;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// li r9,60
	ctx.r9.s64 = 60;
	// li r8,1849
	ctx.r8.s64 = 1849;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,4
	ctx.r4.s64 = 4;
	// lfs f0,14016(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14016);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,14012(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14012);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r7,r10,13992
	ctx.r7.s64 = ctx.r10.s64 + 13992;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f0,140(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 140, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f13,148(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 148, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stw r9,188(r11)
	PPC_STORE_U32(r11.u32 + 188, ctx.r9.u32);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a7dfc
	if (cr6.getEQ()) goto loc_820A7DFC;
	// addi r4,r31,88
	ctx.r4.s64 = r31.s64 + 88;
	// bl 0x820dd8d8
	sub_820DD8D8(ctx, base);
loc_820A7DFC:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a7e38
	if (cr6.getEQ()) goto loc_820A7E38;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820a7e38
	if (cr6.getEQ()) goto loc_820A7E38;
	// stfs f31,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f30,100(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f29,104(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8216ccc8
	sub_8216CCC8(ctx, base);
loc_820A7E38:
	// addi r1,r1,432
	ctx.r1.s64 = ctx.r1.s64 + 432;
	// lfd f29,-80(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// lfd f30,-72(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f31,-64(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820A7E50"))) PPC_WEAK_FUNC(sub_820A7E50);
PPC_FUNC_IMPL(__imp__sub_820A7E50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// addi r12,r1,-40
	r12.s64 = ctx.r1.s64 + -40;
	// bl 0x823ed548
	// stwu r1,-448(r1)
	ea = -448 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x820b3e00
	sub_820B3E00(ctx, base);
	// lis r11,-32250
	r11.s64 = -2113536000;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r11,r11,11808
	r11.s64 = r11.s64 + 11808;
	// addi r4,r1,304
	ctx.r4.s64 = ctx.r1.s64 + 304;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r10,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r10,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r10.u32);
	// stw r11,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r11.u32);
	// bl 0x82136da8
	sub_82136DA8(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r4,r1,152
	ctx.r4.s64 = ctx.r1.s64 + 152;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x820a49a0
	sub_820A49A0(ctx, base);
	// addi r28,r1,152
	r28.s64 = ctx.r1.s64 + 152;
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,152(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,156(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	ctx.f10.f64 = double(temp.f32);
	// lfs f0,14292(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14292);
	f0.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// fmuls f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f13,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f11,f13,f0
	ctx.f11.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f11,88(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lwz r11,-6384(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,2780(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2780);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f10,f10,f0,f13
	ctx.f10.f64 = double(float(ctx.f10.f64 * f0.f64 + ctx.f13.f64));
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// ble cr6,0x820a7f58
	if (!cr6.getGT()) goto loc_820A7F58;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f9,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f0,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f13,-6368(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6368);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// lfs f13,12(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f12,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,16(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// fmadds f13,f13,f0,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f10.f64));
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f13,20(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// fmadds f0,f13,f0,f11
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f11.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
loc_820A7F58:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f28,13964(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13964);
	f28.f64 = double(temp.f32);
	// beq cr6,0x820a8034
	if (cr6.getEQ()) goto loc_820A8034;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820a8034
	if (cr6.getEQ()) goto loc_820A8034;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
	// lfs f31,2952(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2952);
	f31.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f30.f64 = double(temp.f32);
	// fmadds f1,f0,f31,f30
	ctx.f1.f64 = double(float(f0.f64 * f31.f64 + f30.f64));
	// bl 0x8238ca58
	sub_8238CA58(ctx, base);
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// lfs f0,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
	// fctiwz f13,f1
	ctx.f13.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// fmadds f1,f0,f31,f30
	ctx.f1.f64 = double(float(f0.f64 * f31.f64 + f30.f64));
	// stfiwx f13,0,r11
	PPC_STORE_U32(r11.u32, ctx.f13.u32);
	// bl 0x8238ca58
	sub_8238CA58(ctx, base);
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lfs f0,88(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	f0.f64 = double(temp.f32);
	// fctiwz f13,f1
	ctx.f13.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// fmadds f1,f0,f31,f30
	ctx.f1.f64 = double(float(f0.f64 * f31.f64 + f30.f64));
	// stfiwx f13,0,r11
	PPC_STORE_U32(r11.u32, ctx.f13.u32);
	// bl 0x8238ca58
	sub_8238CA58(ctx, base);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// lwz r10,144(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// lwz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r10,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r10.u64);
	// lfd f0,112(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// std r9,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, ctx.r9.u64);
	// lfd f13,144(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lfd f12,96(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f13,f28
	f0.f64 = double(float(ctx.f13.f64 * f28.f64));
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmuls f0,f12,f28
	f0.f64 = double(float(ctx.f12.f64 * f28.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
loc_820A8034:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
	// lis r30,-32014
	r30.s64 = -2098069504;
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// mulli r31,r31,936
	r31.s64 = r31.s64 * 936;
	// lfs f0,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
	// stfs f0,132(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f0,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	f0.f64 = double(temp.f32);
	// lfs f1,14036(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14036);
	ctx.f1.f64 = double(temp.f32);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// stfs f0,136(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// addi r4,r1,240
	ctx.r4.s64 = ctx.r1.s64 + 240;
	// lfs f31,3008(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3008);
	f31.f64 = double(temp.f32);
	// lfs f30,3012(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3012);
	f30.f64 = double(temp.f32);
	// lfs f29,3016(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3016);
	f29.f64 = double(temp.f32);
	// stfs f31,112(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f30,116(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f29,120(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// bl 0x8210b968
	sub_8210B968(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// lfs f1,14032(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14032);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// addi r4,r1,240
	ctx.r4.s64 = ctx.r1.s64 + 240;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// add r11,r31,r11
	r11.u64 = r31.u64 + r11.u64;
	// addi r3,r11,2960
	ctx.r3.s64 = r11.s64 + 2960;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,240
	ctx.r4.s64 = ctx.r1.s64 + 240;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// stfs f0,224(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// stfs f0,228(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// stfs f0,232(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r31,r3,31
	r31.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f4,264(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 264);
	ctx.f4.f64 = double(temp.f32);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// lfs f3,260(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 260);
	ctx.f3.f64 = double(temp.f32);
	// addi r3,r1,304
	ctx.r3.s64 = ctx.r1.s64 + 304;
	// lfs f2,256(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 256);
	ctx.f2.f64 = double(temp.f32);
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f0,14028(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14028);
	f0.f64 = double(temp.f32);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// frsp f12,f13
	ctx.f12.f64 = double(float(ctx.f13.f64));
	// lfs f13,14024(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14024);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmadds f13,f12,f0,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// lfs f0,14020(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14020);
	f0.f64 = double(temp.f32);
	// fdivs f1,f0,f13
	ctx.f1.f64 = double(float(f0.f64 / ctx.f13.f64));
	// bl 0x820d3760
	sub_820D3760(ctx, base);
	// li r4,3
	ctx.r4.s64 = 3;
	// li r3,186
	ctx.r3.s64 = 186;
	// bl 0x820e2be8
	sub_820E2BE8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a8234
	if (cr6.getEQ()) goto loc_820A8234;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,15,12
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFF9FFFF;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r10,r3,17,0,14
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 17) & 0xFFFE0000;
	// li r8,0
	ctx.r8.s64 = 0;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// addi r7,r1,304
	ctx.r7.s64 = ctx.r1.s64 + 304;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,240
	ctx.r5.s64 = ctx.r1.s64 + 240;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820a1800
	sub_820A1800(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a81c4
	if (cr6.getEQ()) goto loc_820A81C4;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// li r10,60
	ctx.r10.s64 = 60;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r9,r9,2
	ctx.r9.u64 = ctx.r9.u64 | 2;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f28,140(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(r11.u32 + 140, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stw r10,188(r11)
	PPC_STORE_U32(r11.u32 + 188, ctx.r10.u32);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// ori r11,r11,32
	r11.u64 = r11.u64 | 32;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
loc_820A81C4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820e0360
	sub_820E0360(ctx, base);
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a8234
	if (cr6.getEQ()) goto loc_820A8234;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820a8234
	if (cr6.getEQ()) goto loc_820A8234;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// stfs f31,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f30,100(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// li r30,-1
	r30.s64 = -1;
	// stfs f29,104(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a821c
	if (cr6.getEQ()) goto loc_820A821C;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8217eea8
	sub_8217EEA8(ctx, base);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r30,60(r11)
	PPC_STORE_U32(r11.u32 + 60, r30.u32);
loc_820A821C:
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// bl 0x8216cf78
	sub_8216CF78(ctx, base);
loc_820A8234:
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// addi r12,r1,-40
	r12.s64 = ctx.r1.s64 + -40;
	// bl 0x823ed594
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820A8248"))) PPC_WEAK_FUNC(sub_820A8248);
PPC_FUNC_IMPL(__imp__sub_820A8248) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// addi r12,r1,-56
	r12.s64 = ctx.r1.s64 + -56;
	// bl 0x823ed548
	// stwu r1,-448(r1)
	ea = -448 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lfs f31,14288(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14288);
	f31.f64 = double(temp.f32);
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// bl 0x820b3e00
	sub_820B3E00(ctx, base);
	// lis r31,-32014
	r31.s64 = -2098069504;
	// mulli r30,r29,936
	r30.s64 = r29.s64 * 936;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r26,2344(r11)
	r26.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// cmpwi cr6,r26,61
	cr6.compare<int32_t>(r26.s32, 61, xer);
	// bne cr6,0x820a829c
	if (!cr6.getEQ()) goto loc_820A829C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,14296(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14296);
	f31.f64 = double(temp.f32);
loc_820A829C:
	// addi r4,r1,288
	ctx.r4.s64 = ctx.r1.s64 + 288;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82136da8
	sub_82136DA8(ctx, base);
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x820a49a0
	sub_820A49A0(ctx, base);
	// addi r29,r1,128
	r29.s64 = ctx.r1.s64 + 128;
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f0,128(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	f0.f64 = double(temp.f32);
	// fmuls f12,f0,f31
	ctx.f12.f64 = double(float(f0.f64 * f31.f64));
	// lfs f0,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	f0.f64 = double(temp.f32);
	// fmuls f11,f0,f31
	ctx.f11.f64 = double(float(f0.f64 * f31.f64));
	// lfs f13,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// stfs f12,80(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lwz r11,-6384(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -6384);
	// stfs f11,88(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2780(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2780);
	f0.f64 = double(temp.f32);
	// fmadds f10,f13,f31,f0
	ctx.f10.f64 = double(float(ctx.f13.f64 * f31.f64 + f0.f64));
	// stfs f10,84(r1)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// ble cr6,0x820a8354
	if (!cr6.getGT()) goto loc_820A8354;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f9,0(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f0,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f13,-6368(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6368);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// lfs f13,12(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f12,4(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,16(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// fmadds f13,f13,f0,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f10.f64));
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f13,20(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// fmadds f0,f13,f0,f11
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f11.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
loc_820A8354:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f29,13964(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13964);
	f29.f64 = double(temp.f32);
	// beq cr6,0x820a8430
	if (cr6.getEQ()) goto loc_820A8430;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820a8430
	if (cr6.getEQ()) goto loc_820A8430;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
	// lfs f31,2952(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2952);
	f31.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f30.f64 = double(temp.f32);
	// fmadds f1,f0,f31,f30
	ctx.f1.f64 = double(float(f0.f64 * f31.f64 + f30.f64));
	// bl 0x8238ca58
	sub_8238CA58(ctx, base);
	// addi r11,r1,120
	r11.s64 = ctx.r1.s64 + 120;
	// lfs f0,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
	// fctiwz f13,f1
	ctx.f13.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// fmadds f1,f0,f31,f30
	ctx.f1.f64 = double(float(f0.f64 * f31.f64 + f30.f64));
	// stfiwx f13,0,r11
	PPC_STORE_U32(r11.u32, ctx.f13.u32);
	// bl 0x8238ca58
	sub_8238CA58(ctx, base);
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// lfs f0,88(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	f0.f64 = double(temp.f32);
	// fctiwz f13,f1
	ctx.f13.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// fmadds f1,f0,f31,f30
	ctx.f1.f64 = double(float(f0.f64 * f31.f64 + f30.f64));
	// stfiwx f13,0,r11
	PPC_STORE_U32(r11.u32, ctx.f13.u32);
	// bl 0x8238ca58
	sub_8238CA58(ctx, base);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// lwz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r10,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, ctx.r10.u64);
	// lfd f0,112(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// std r9,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, ctx.r9.u64);
	// lfd f13,120(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lfd f12,96(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f0,f13,f29
	f0.f64 = double(float(ctx.f13.f64 * f29.f64));
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmuls f0,f12,f29
	f0.f64 = double(float(ctx.f12.f64 * f29.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
loc_820A8430:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	f0.f64 = double(temp.f32);
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// lfs f0,84(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
	// stfs f0,148(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f0,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	f0.f64 = double(temp.f32);
	// stfs f0,152(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f31,3008(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3008);
	f31.f64 = double(temp.f32);
	// lfs f30,3012(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3012);
	f30.f64 = double(temp.f32);
	// lfs f28,3016(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3016);
	f28.f64 = double(temp.f32);
	// stfs f31,96(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f30,100(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f28,104(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// addi r3,r11,2960
	ctx.r3.s64 = r11.s64 + 2960;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// stfs f0,208(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// stfs f0,212(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// stfs f0,216(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// cmpwi cr6,r26,61
	cr6.compare<int32_t>(r26.s32, 61, xer);
	// bne cr6,0x820a8518
	if (!cr6.getEQ()) goto loc_820A8518;
	// li r3,61
	ctx.r3.s64 = 61;
	// bl 0x820c0f10
	sub_820C0F10(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,61
	ctx.r3.s64 = 61;
	// bl 0x820c0fb8
	sub_820C0FB8(ctx, base);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820a84d0
	if (cr6.getEQ()) goto loc_820A84D0;
	// lwz r3,16(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// bl 0x820da578
	sub_820DA578(ctx, base);
loc_820A84D0:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r8,5
	ctx.r8.s64 = 5;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// lwz r10,2352(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2352);
	// stw r8,2384(r11)
	PPC_STORE_U32(r11.u32 + 2384, ctx.r8.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r10,2404(r11)
	PPC_STORE_U32(r11.u32 + 2404, ctx.r10.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r9,2412(r11)
	PPC_STORE_U32(r11.u32 + 2412, ctx.r9.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r10,3288(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3288);
	// stw r8,3320(r11)
	PPC_STORE_U32(r11.u32 + 3320, ctx.r8.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r10,3340(r11)
	PPC_STORE_U32(r11.u32 + 3340, ctx.r10.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r9,3348(r11)
	PPC_STORE_U32(r11.u32 + 3348, ctx.r9.u32);
	// bne cr6,0x820a861c
	if (!cr6.getEQ()) goto loc_820A861C;
loc_820A8518:
	// addi r11,r26,-27
	r11.s64 = r26.s64 + -27;
	// li r3,199
	ctx.r3.s64 = 199;
	// cmplwi cr6,r11,34
	cr6.compare<uint32_t>(r11.u32, 34, xer);
	// bgt cr6,0x820a8608
	if (cr6.getGT()) goto loc_820A8608;
	// lis r12,-32245
	r12.s64 = -2113208320;
	// addi r12,r12,-31424
	r12.s64 = r12.s64 + -31424;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820A85DC;
	case 1:
		goto loc_820A85D4;
	case 2:
		goto loc_820A85CC;
	case 3:
		goto loc_820A8608;
	case 4:
		goto loc_820A8608;
	case 5:
		goto loc_820A8608;
	case 6:
		goto loc_820A85E4;
	case 7:
		goto loc_820A8604;
	case 8:
		goto loc_820A8608;
	case 9:
		goto loc_820A8608;
	case 10:
		goto loc_820A8608;
	case 11:
		goto loc_820A8608;
	case 12:
		goto loc_820A8608;
	case 13:
		goto loc_820A8608;
	case 14:
		goto loc_820A8608;
	case 15:
		goto loc_820A8608;
	case 16:
		goto loc_820A8608;
	case 17:
		goto loc_820A8608;
	case 18:
		goto loc_820A8608;
	case 19:
		goto loc_820A8608;
	case 20:
		goto loc_820A85EC;
	case 21:
		goto loc_820A85F4;
	case 22:
		goto loc_820A8608;
	case 23:
		goto loc_820A8608;
	case 24:
		goto loc_820A8608;
	case 25:
		goto loc_820A8608;
	case 26:
		goto loc_820A8608;
	case 27:
		goto loc_820A8608;
	case 28:
		goto loc_820A8608;
	case 29:
		goto loc_820A8608;
	case 30:
		goto loc_820A8608;
	case 31:
		goto loc_820A8608;
	case 32:
		goto loc_820A8608;
	case 33:
		goto loc_820A8608;
	case 34:
		goto loc_820A85FC;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-31268(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31268);
	// lwz r16,-31276(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31276);
	// lwz r16,-31284(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31284);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31260(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31260);
	// lwz r16,-31228(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31228);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31252(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31252);
	// lwz r16,-31244(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31244);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31224(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31224);
	// lwz r16,-31236(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31236);
loc_820A85CC:
	// li r3,199
	ctx.r3.s64 = 199;
	// b 0x820a8608
	goto loc_820A8608;
loc_820A85D4:
	// li r3,200
	ctx.r3.s64 = 200;
	// b 0x820a8608
	goto loc_820A8608;
loc_820A85DC:
	// li r3,201
	ctx.r3.s64 = 201;
	// b 0x820a8608
	goto loc_820A8608;
loc_820A85E4:
	// li r3,226
	ctx.r3.s64 = 226;
	// b 0x820a8608
	goto loc_820A8608;
loc_820A85EC:
	// li r3,245
	ctx.r3.s64 = 245;
	// b 0x820a8608
	goto loc_820A8608;
loc_820A85F4:
	// li r3,246
	ctx.r3.s64 = 246;
	// b 0x820a8608
	goto loc_820A8608;
loc_820A85FC:
	// li r3,248
	ctx.r3.s64 = 248;
	// b 0x820a8608
	goto loc_820A8608;
loc_820A8604:
	// li r3,273
	ctx.r3.s64 = 273;
loc_820A8608:
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x820e2be8
	sub_820E2BE8(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820a8804
	if (cr6.getEQ()) goto loc_820A8804;
loc_820A861C:
	// addi r11,r26,-27
	r11.s64 = r26.s64 + -27;
	// cmplwi cr6,r11,34
	cr6.compare<uint32_t>(r11.u32, 34, xer);
	// bgt cr6,0x820a86ec
	if (cr6.getGT()) goto loc_820A86EC;
	// lis r12,-32245
	r12.s64 = -2113208320;
	// addi r12,r12,-31168
	r12.s64 = r12.s64 + -31168;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820A86CC;
	case 1:
		goto loc_820A86CC;
	case 2:
		goto loc_820A86CC;
	case 3:
		goto loc_820A86EC;
	case 4:
		goto loc_820A86EC;
	case 5:
		goto loc_820A86EC;
	case 6:
		goto loc_820A86CC;
	case 7:
		goto loc_820A86E4;
	case 8:
		goto loc_820A86EC;
	case 9:
		goto loc_820A86EC;
	case 10:
		goto loc_820A86EC;
	case 11:
		goto loc_820A86EC;
	case 12:
		goto loc_820A86EC;
	case 13:
		goto loc_820A86EC;
	case 14:
		goto loc_820A86EC;
	case 15:
		goto loc_820A86EC;
	case 16:
		goto loc_820A86EC;
	case 17:
		goto loc_820A86EC;
	case 18:
		goto loc_820A86EC;
	case 19:
		goto loc_820A86EC;
	case 20:
		goto loc_820A86E4;
	case 21:
		goto loc_820A86E4;
	case 22:
		goto loc_820A86EC;
	case 23:
		goto loc_820A86EC;
	case 24:
		goto loc_820A86EC;
	case 25:
		goto loc_820A86EC;
	case 26:
		goto loc_820A86EC;
	case 27:
		goto loc_820A86EC;
	case 28:
		goto loc_820A86EC;
	case 29:
		goto loc_820A86EC;
	case 30:
		goto loc_820A86EC;
	case 31:
		goto loc_820A86EC;
	case 32:
		goto loc_820A86EC;
	case 33:
		goto loc_820A86EC;
	case 34:
		goto loc_820A86E4;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-31028(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31028);
	// lwz r16,-31028(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31028);
	// lwz r16,-31028(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31028);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-31028(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31028);
	// lwz r16,-31004(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31004);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-31004(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31004);
	// lwz r16,-31004(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31004);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-30996(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -30996);
	// lwz r16,-31004(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -31004);
loc_820A86CC:
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// li r11,300
	r11.s64 = 300;
	// beq cr6,0x820a86f0
	if (cr6.getEQ()) goto loc_820A86F0;
	// li r11,180
	r11.s64 = 180;
	// b 0x820a86f0
	goto loc_820A86F0;
loc_820A86E4:
	// li r11,1
	r11.s64 = 1;
	// b 0x820a86f0
	goto loc_820A86F0;
loc_820A86EC:
	// li r11,240
	r11.s64 = 240;
loc_820A86F0:
	// sth r11,130(r30)
	PPC_STORE_U16(r30.u32 + 130, r11.u16);
	// lwz r11,100(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 100);
	// rlwinm r11,r11,0,15,12
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFF9FFFF;
	// stw r11,100(r30)
	PPC_STORE_U32(r30.u32 + 100, r11.u32);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// lwz r11,100(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 100);
	// rlwinm r10,r3,17,0,14
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 17) & 0xFFFE0000;
	// li r8,0
	ctx.r8.s64 = 0;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// addi r7,r1,288
	ctx.r7.s64 = ctx.r1.s64 + 288;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,224
	ctx.r5.s64 = ctx.r1.s64 + 224;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r11,100(r30)
	PPC_STORE_U32(r30.u32 + 100, r11.u32);
	// bl 0x820a1800
	sub_820A1800(ctx, base);
	// lwz r11,100(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 100);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a879c
	if (cr6.getEQ()) goto loc_820A879C;
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// li r9,60
	ctx.r9.s64 = 60;
	// addi r7,r10,13992
	ctx.r7.s64 = ctx.r10.s64 + 13992;
	// li r8,2218
	ctx.r8.s64 = 2218;
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// li r4,4
	ctx.r4.s64 = 4;
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// stfs f29,140(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r11.u32 + 140, temp.u32);
	// lwz r11,108(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 108);
	// stw r9,188(r11)
	PPC_STORE_U32(r11.u32 + 188, ctx.r9.u32);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820a879c
	if (cr6.getEQ()) goto loc_820A879C;
	// addi r4,r30,88
	ctx.r4.s64 = r30.s64 + 88;
	// bl 0x820dd8d8
	sub_820DD8D8(ctx, base);
loc_820A879C:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a8804
	if (cr6.getEQ()) goto loc_820A8804;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820a8804
	if (cr6.getEQ()) goto loc_820A8804;
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// li r31,-1
	r31.s64 = -1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a87dc
	if (cr6.getEQ()) goto loc_820A87DC;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// bl 0x8217ef18
	sub_8217EF18(ctx, base);
	// lwz r11,16(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 16);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r31,64(r11)
	PPC_STORE_U32(r11.u32 + 64, r31.u32);
loc_820A87DC:
	// stfs f31,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f30,100(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f28,104(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// bl 0x8216ce08
	sub_8216CE08(ctx, base);
loc_820A8804:
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// addi r12,r1,-56
	r12.s64 = ctx.r1.s64 + -56;
	// bl 0x823ed594
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820A8818"))) PPC_WEAK_FUNC(sub_820A8818);
PPC_FUNC_IMPL(__imp__sub_820A8818) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// addi r12,r1,-56
	r12.s64 = ctx.r1.s64 + -56;
	// bl 0x823ed544
	// stwu r1,-368(r1)
	ea = -368 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r27,-32014
	r27.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mulli r30,r31,936
	r30.s64 = r31.s64 * 936;
	// lwz r11,-1364(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + -1364);
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// addi r26,r11,2344
	r26.s64 = r11.s64 + 2344;
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x820b3e00
	sub_820B3E00(ctx, base);
	// lis r11,-32250
	r11.s64 = -2113536000;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r11,r11,11808
	r11.s64 = r11.s64 + 11808;
	// addi r3,r1,208
	ctx.r3.s64 = ctx.r1.s64 + 208;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r10,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r10.u32);
	// stw r11,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r11.u32);
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820a49a0
	sub_820A49A0(ctx, base);
	// addi r31,r1,128
	r31.s64 = ctx.r1.s64 + 128;
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,128(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,14300(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14300);
	f0.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// fmuls f31,f13,f0
	f31.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f13,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f30,f13,f0
	f30.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f13,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f29,f13,f0
	f29.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f31,80(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f30,84(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lwz r11,-6384(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -6384);
	// stfs f29,88(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a8928
	if (!cr6.getGT()) goto loc_820A8928;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,0(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,16(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,20(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// lfs f0,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f13,-6368(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6368);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// lfs f13,12(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f12,4(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// lfs f11,8(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// fmadds f31,f13,f0,f31
	f31.f64 = double(float(ctx.f13.f64 * f0.f64 + f31.f64));
	// stfs f31,80(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmadds f30,f12,f0,f30
	f30.f64 = double(float(ctx.f12.f64 * f0.f64 + f30.f64));
	// stfs f30,84(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmadds f29,f11,f0,f29
	f29.f64 = double(float(ctx.f11.f64 * f0.f64 + f29.f64));
	// stfs f29,88(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
loc_820A8928:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a89f8
	if (cr6.getEQ()) goto loc_820A89F8;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820a89f8
	if (cr6.getEQ()) goto loc_820A89F8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f28,2952(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2952);
	f28.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f27,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f27.f64 = double(temp.f32);
	// fmadds f1,f31,f28,f27
	ctx.f1.f64 = double(float(f31.f64 * f28.f64 + f27.f64));
	// bl 0x8238ca58
	sub_8238CA58(ctx, base);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// fmadds f1,f30,f28,f27
	ctx.f1.f64 = double(float(f30.f64 * f28.f64 + f27.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// bl 0x8238ca58
	sub_8238CA58(ctx, base);
	// addi r11,r1,104
	r11.s64 = ctx.r1.s64 + 104;
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// lwz r10,96(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// fmadds f1,f29,f28,f27
	ctx.f1.f64 = double(float(f29.f64 * f28.f64 + f27.f64));
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r10,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r10.u64);
	// lfd f0,96(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f13,104(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f29,13964(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13964);
	f29.f64 = double(temp.f32);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f31,f0,f29
	f31.f64 = double(float(f0.f64 * f29.f64));
	// stfs f31,80(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f30,f13,f29
	f30.f64 = double(float(ctx.f13.f64 * f29.f64));
	// stfs f30,84(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// bl 0x8238ca58
	sub_8238CA58(ctx, base);
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f29,f0,f29
	f29.f64 = double(float(f0.f64 * f29.f64));
	// stfs f29,88(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
loc_820A89F8:
	// lwz r11,-1364(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + -1364);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// stfs f31,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// stfs f30,116(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f29,120(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// addi r3,r11,2960
	ctx.r3.s64 = r11.s64 + 2960;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r4,87
	ctx.r4.s64 = 87;
	// li r3,203
	ctx.r3.s64 = 203;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// stfs f0,192(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// stfs f0,196(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// stfs f0,200(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// bl 0x820e2be8
	sub_820E2BE8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a8b10
	if (cr6.getEQ()) goto loc_820A8B10;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// li r10,1200
	ctx.r10.s64 = 1200;
	// rlwinm r11,r11,0,15,12
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFF9FFFF;
	// sth r10,130(r31)
	PPC_STORE_U16(r31.u32 + 130, ctx.r10.u16);
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r10,r3,17,0,14
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 17) & 0xFFFE0000;
	// addi r30,r26,744
	r30.s64 = r26.s64 + 744;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r7,r1,208
	ctx.r7.s64 = ctx.r1.s64 + 208;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,144
	ctx.r5.s64 = ctx.r1.s64 + 144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x820a1800
	sub_820A1800(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a8ac8
	if (cr6.getEQ()) goto loc_820A8AC8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r10,108(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// li r9,60
	ctx.r9.s64 = 60;
	// lfs f0,14016(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14016);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,140(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 140, temp.u32);
	// lfs f13,14012(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14012);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f13,148(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 148, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stw r9,188(r11)
	PPC_STORE_U32(r11.u32 + 188, ctx.r9.u32);
loc_820A8AC8:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a8b10
	if (cr6.getEQ()) goto loc_820A8B10;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820a8b10
	if (cr6.getEQ()) goto loc_820A8B10;
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,748(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 748);
	f0.f64 = double(temp.f32);
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f0,752(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 752);
	f0.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8216cb88
	sub_8216CB88(ctx, base);
loc_820A8B10:
	// addi r1,r1,368
	ctx.r1.s64 = ctx.r1.s64 + 368;
	// addi r12,r1,-56
	r12.s64 = ctx.r1.s64 + -56;
	// bl 0x823ed590
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_820A8B20"))) PPC_WEAK_FUNC(sub_820A8B20);
PPC_FUNC_IMPL(__imp__sub_820A8B20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// addi r12,r1,-72
	r12.s64 = ctx.r1.s64 + -72;
	// bl 0x823ed538
	// stwu r1,-448(r1)
	ea = -448 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r28,-32014
	r28.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mulli r26,r31,936
	r26.s64 = r31.s64 * 936;
	// lwz r11,-1364(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -1364);
	// add r30,r26,r11
	r30.u64 = r26.u64 + r11.u64;
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// bl 0x820b3e00
	sub_820B3E00(ctx, base);
	// lwz r10,-1364(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + -1364);
	// lis r11,-32250
	r11.s64 = -2113536000;
	// add r10,r26,r10
	ctx.r10.u64 = r26.u64 + ctx.r10.u64;
	// addi r11,r11,11808
	r11.s64 = r11.s64 + 11808;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// addi r3,r1,240
	ctx.r3.s64 = ctx.r1.s64 + 240;
	// lwz r25,2344(r10)
	r25.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2344);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// stw r10,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r10.u32);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// stw r10,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, ctx.r10.u32);
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r11.u32);
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// cmpwi cr6,r25,32
	cr6.compare<int32_t>(r25.s32, 32, xer);
	// bne cr6,0x820a8d0c
	if (!cr6.getEQ()) goto loc_820A8D0C;
	// bl 0x820b1020
	sub_820B1020(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// lfs f31,2776(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f31.f64 = double(temp.f32);
	// beq cr6,0x820a8bc8
	if (cr6.getEQ()) goto loc_820A8BC8;
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a8bc8
	if (cr6.getEQ()) goto loc_820A8BC8;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x820b1048
	sub_820B1048(ctx, base);
	// b 0x820a8bec
	goto loc_820A8BEC;
loc_820A8BC8:
	// lwz r11,-1364(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -1364);
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// addi r3,r11,4256
	ctx.r3.s64 = r11.s64 + 4256;
	// bl 0x8210d5e0
	sub_8210D5E0(ctx, base);
	// addi r24,r1,112
	r24.s64 = ctx.r1.s64 + 112;
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
loc_820A8BEC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,14304(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14304);
	f0.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * f0.f64));
	// stfs f12,84(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * f0.f64));
	// stfs f11,88(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lwz r11,-6384(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a8c70
	if (!cr6.getGT()) goto loc_820A8C70;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f9,0(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 0);
	ctx.f9.f64 = double(temp.f32);
	// lfs f10,12(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f10,f10,f9
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f9.f64));
	// lfs f8,16(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 16);
	ctx.f8.f64 = double(temp.f32);
	// lfs f9,4(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 4);
	ctx.f9.f64 = double(temp.f32);
	// fsubs f9,f8,f9
	ctx.f9.f64 = double(float(ctx.f8.f64 - ctx.f9.f64));
	// lfs f7,20(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// lfs f0,-6368(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fdivs f0,f31,f0
	f0.f64 = double(float(f31.f64 / f0.f64));
	// lfs f8,8(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// fsubs f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 - ctx.f8.f64));
	// fmadds f13,f10,f0,f13
	ctx.f13.f64 = double(float(ctx.f10.f64 * f0.f64 + ctx.f13.f64));
	// stfs f13,80(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmadds f13,f9,f0,f12
	ctx.f13.f64 = double(float(ctx.f9.f64 * f0.f64 + ctx.f12.f64));
	// stfs f13,84(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmadds f0,f8,f0,f11
	f0.f64 = double(float(ctx.f8.f64 * f0.f64 + ctx.f11.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
loc_820A8C70:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a8ce0
	if (cr6.getEQ()) goto loc_820A8CE0;
	// lbz r11,1(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a8ce0
	if (cr6.getEQ()) goto loc_820A8CE0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r31,r1,96
	r31.s64 = ctx.r1.s64 + 96;
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lfs f0,304(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 304);
	f0.f64 = double(temp.f32);
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r10,12(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	// lfs f0,308(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 308);
	f0.f64 = double(temp.f32);
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lfs f0,312(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 312);
	f0.f64 = double(temp.f32);
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8210b6e0
	sub_8210B6E0(ctx, base);
	// bl 0x8213e630
	sub_8213E630(ctx, base);
	// lfs f24,144(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	f24.f64 = double(temp.f32);
	// lfs f25,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	f25.f64 = double(temp.f32);
	// lfs f26,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	f26.f64 = double(temp.f32);
	// b 0x820a8eb8
	goto loc_820A8EB8;
loc_820A8CE0:
	// lfs f0,12(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f0,16(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 16);
	f0.f64 = double(temp.f32);
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f0,20(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	f0.f64 = double(temp.f32);
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// bl 0x8213e630
	sub_8213E630(ctx, base);
	// lfs f24,144(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	f24.f64 = double(temp.f32);
	// lfs f25,140(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	f25.f64 = double(temp.f32);
	// lfs f26,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	f26.f64 = double(temp.f32);
	// b 0x820a8eb8
	goto loc_820A8EB8;
loc_820A8D0C:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x820a49a0
	sub_820A49A0(ctx, base);
	// addi r31,r1,112
	r31.s64 = ctx.r1.s64 + 112;
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,14040(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14040);
	f0.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// fmuls f26,f13,f0
	f26.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f13,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f25,f13,f0
	f25.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f13,3088(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 3088);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,96(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f13,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,-6384(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -6384);
	// fmuls f24,f13,f0
	f24.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f0,3092(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 3092);
	f0.f64 = double(temp.f32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f0,3096(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 3096);
	f0.f64 = double(temp.f32);
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f0,-6368(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fmuls f31,f0,f26
	f31.f64 = double(float(f0.f64 * f26.f64));
	// stfs f31,80(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f30,f0,f25
	f30.f64 = double(float(f0.f64 * f25.f64));
	// stfs f30,84(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmuls f29,f0,f24
	f29.f64 = double(float(f0.f64 * f24.f64));
	// stfs f29,88(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// ble cr6,0x820a8ddc
	if (!cr6.getGT()) goto loc_820A8DDC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,0(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,16(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,20(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// lfs f13,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 / f0.f64));
	// lfs f13,12(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f12.f64));
	// lfs f12,4(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// lfs f11,8(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f11.f64));
	// fmadds f31,f13,f0,f31
	f31.f64 = double(float(ctx.f13.f64 * f0.f64 + f31.f64));
	// stfs f31,80(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmadds f30,f12,f0,f30
	f30.f64 = double(float(ctx.f12.f64 * f0.f64 + f30.f64));
	// stfs f30,84(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// fmadds f29,f11,f0,f29
	f29.f64 = double(float(ctx.f11.f64 * f0.f64 + f29.f64));
	// stfs f29,88(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
loc_820A8DDC:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a8eac
	if (cr6.getEQ()) goto loc_820A8EAC;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820a8eac
	if (cr6.getEQ()) goto loc_820A8EAC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f28,2952(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2952);
	f28.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f27,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f27.f64 = double(temp.f32);
	// fmadds f1,f31,f28,f27
	ctx.f1.f64 = double(float(f31.f64 * f28.f64 + f27.f64));
	// bl 0x8238ca58
	sub_8238CA58(ctx, base);
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// fmadds f1,f30,f28,f27
	ctx.f1.f64 = double(float(f30.f64 * f28.f64 + f27.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// bl 0x8238ca58
	sub_8238CA58(ctx, base);
	// addi r11,r1,152
	r11.s64 = ctx.r1.s64 + 152;
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// fmadds f1,f29,f28,f27
	ctx.f1.f64 = double(float(f29.f64 * f28.f64 + f27.f64));
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,152(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r10,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r10.u64);
	// lfd f0,128(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 128);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// std r11,152(r1)
	PPC_STORE_U64(ctx.r1.u32 + 152, r11.u64);
	// lfd f13,152(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 152);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f29,13964(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13964);
	f29.f64 = double(temp.f32);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f31,f0,f29
	f31.f64 = double(float(f0.f64 * f29.f64));
	// stfs f31,80(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// fmuls f30,f13,f29
	f30.f64 = double(float(ctx.f13.f64 * f29.f64));
	// stfs f30,84(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// bl 0x8238ca58
	sub_8238CA58(ctx, base);
	// addi r11,r1,128
	r11.s64 = ctx.r1.s64 + 128;
	// fctiwz f0,f1
	ctx.fpscr.disableFlushMode();
	f0.s64 = (ctx.f1.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f1.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,128(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,152(r1)
	PPC_STORE_U64(ctx.r1.u32 + 152, r11.u64);
	// lfd f0,152(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 152);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f29,f0,f29
	f29.f64 = double(float(f0.f64 * f29.f64));
	// stfs f29,88(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
loc_820A8EAC:
	// stfs f31,136(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// stfs f30,140(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 140, temp.u32);
	// stfs f29,144(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
loc_820A8EB8:
	// lwz r11,-1364(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -1364);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// add r11,r26,r11
	r11.u64 = r26.u64 + r11.u64;
	// addi r3,r11,2960
	ctx.r3.s64 = r11.s64 + 2960;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// stfs f0,224(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// stfs f0,228(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// stfs f0,232(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// lwz r31,2888(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 2888);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a8ef8
	if (cr6.getEQ()) goto loc_820A8EF8;
	// li r11,1
	r11.s64 = 1;
	// stw r11,2892(r30)
	PPC_STORE_U32(r30.u32 + 2892, r11.u32);
	// b 0x820a8f08
	goto loc_820A8F08;
loc_820A8EF8:
	// li r4,86
	ctx.r4.s64 = 86;
	// li r3,202
	ctx.r3.s64 = 202;
	// bl 0x820e2be8
	sub_820E2BE8(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_820A8F08:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820a907c
	if (cr6.getEQ()) goto loc_820A907C;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// li r10,-1
	ctx.r10.s64 = -1;
	// rlwinm r11,r11,0,15,12
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFF9FFFF;
	// sth r10,130(r31)
	PPC_STORE_U16(r31.u32 + 130, ctx.r10.u16);
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r10,r3,17,0,14
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 17) & 0xFFFE0000;
	// li r8,0
	ctx.r8.s64 = 0;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// addi r7,r1,240
	ctx.r7.s64 = ctx.r1.s64 + 240;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r11,100(r31)
	PPC_STORE_U32(r31.u32 + 100, r11.u32);
	// bl 0x820a1800
	sub_820A1800(ctx, base);
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// rlwinm r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a9018
	if (cr6.getEQ()) goto loc_820A9018;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// cmpwi cr6,r25,32
	cr6.compare<int32_t>(r25.s32, 32, xer);
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r10,r10,128
	ctx.r10.u64 = ctx.r10.u64 | 128;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// beq cr6,0x820a9018
	if (cr6.getEQ()) goto loc_820A9018;
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// li r10,60
	ctx.r10.s64 = 60;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// ori r9,r9,32
	ctx.r9.u64 = ctx.r9.u64 | 32;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// lfs f0,92(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	f0.f64 = double(temp.f32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f0,176(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 176, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,180(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 180, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f26,16(r11)
	temp.f32 = float(f26.f64);
	PPC_STORE_U32(r11.u32 + 16, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f25,20(r11)
	temp.f32 = float(f25.f64);
	PPC_STORE_U32(r11.u32 + 20, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stfs f24,24(r11)
	temp.f32 = float(f24.f64);
	PPC_STORE_U32(r11.u32 + 24, temp.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// stw r10,188(r11)
	PPC_STORE_U32(r11.u32 + 188, ctx.r10.u32);
	// lwz r11,108(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 108);
	// addi r5,r11,152
	ctx.r5.s64 = r11.s64 + 152;
	// lwz r10,152(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 152);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a8fe4
	if (!cr6.getEQ()) goto loc_820A8FE4;
	// li r8,2653
	ctx.r8.s64 = 2653;
	// b 0x820a8ff8
	goto loc_820A8FF8;
loc_820A8FE4:
	// lwz r10,156(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 156);
	// addi r5,r11,156
	ctx.r5.s64 = r11.s64 + 156;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a9018
	if (!cr6.getEQ()) goto loc_820A9018;
	// li r8,2655
	ctx.r8.s64 = 2655;
loc_820A8FF8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r4,1
	ctx.r4.s64 = 1;
	// addi r7,r11,13992
	ctx.r7.s64 = r11.s64 + 13992;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
loc_820A9018:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a907c
	if (cr6.getEQ()) goto loc_820A907C;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820a907c
	if (cr6.getEQ()) goto loc_820A907C;
	// lfs f0,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	f0.f64 = double(temp.f32);
	// stfs f0,152(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	f0.f64 = double(temp.f32);
	// stfs f0,156(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// lfs f0,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	f0.f64 = double(temp.f32);
	// stfs f0,160(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// lfs f0,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	f0.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	f0.f64 = double(temp.f32);
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f0,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	f0.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// mr r6,r3
	ctx.r6.u64 = ctx.r3.u64;
	// addi r5,r1,136
	ctx.r5.s64 = ctx.r1.s64 + 136;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// bl 0x8216ca50
	sub_8216CA50(ctx, base);
loc_820A907C:
	// addi r1,r1,448
	ctx.r1.s64 = ctx.r1.s64 + 448;
	// addi r12,r1,-72
	r12.s64 = ctx.r1.s64 + -72;
	// bl 0x823ed584
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_820A9090"))) PPC_WEAK_FUNC(sub_820A9090);
PPC_FUNC_IMPL(__imp__sub_820A9090) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f23{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed100
	// addi r12,r1,-152
	r12.s64 = ctx.r1.s64 + -152;
	// bl 0x823ed534
	// stwu r1,-768(r1)
	ea = -768 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r21,-32014
	r21.s64 = -2098069504;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r14,r3
	r14.u64 = ctx.r3.u64;
	// li r17,0
	r17.s64 = 0;
	// mulli r22,r14,936
	r22.s64 = r14.s64 * 936;
	// lwz r9,-1364(r21)
	ctx.r9.u64 = PPC_LOAD_U32(r21.u32 + -1364);
	// lfs f28,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f28.f64 = double(temp.f32);
	// stfs f28,96(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f28,100(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// stfs f28,104(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// add r11,r22,r9
	r11.u64 = r22.u64 + ctx.r9.u64;
	// mr r16,r17
	r16.u64 = r17.u64;
	// addi r31,r11,2344
	r31.s64 = r11.s64 + 2344;
	// lwz r10,2348(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2348);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// mr r15,r10
	r15.u64 = ctx.r10.u64;
	// bge cr6,0x820a90ec
	if (!cr6.getLT()) goto loc_820A90EC;
	// lwz r15,0(r31)
	r15.u64 = PPC_LOAD_U32(r31.u32 + 0);
loc_820A90EC:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r25,r15,56
	r25.s64 = r15.s64 * 56;
	// addi r23,r11,6504
	r23.s64 = r11.s64 + 6504;
	// addi r19,r23,8
	r19.s64 = r23.s64 + 8;
	// lwzx r11,r25,r19
	r11.u64 = PPC_LOAD_U32(r25.u32 + r19.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r18,r11,1240
	r18.s64 = r11.s64 + 1240;
	// bne cr6,0x820a911c
	if (!cr6.getEQ()) goto loc_820A911C;
	// addi r11,r23,12
	r11.s64 = r23.s64 + 12;
	// lwzx r20,r25,r11
	r20.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820a9120
	goto loc_820A9120;
loc_820A911C:
	// mr r20,r18
	r20.u64 = r18.u64;
loc_820A9120:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// lfs f27,3060(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3060);
	f27.f64 = double(temp.f32);
	// bne cr6,0x820a91b4
	if (!cr6.getEQ()) goto loc_820A91B4;
	// lwz r11,3284(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3284);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a9140
	if (!cr6.getLT()) goto loc_820A9140;
	// lwz r11,3280(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 3280);
loc_820A9140:
	// mulli r11,r11,56
	r11.s64 = r11.s64 * 56;
	// addi r10,r23,8
	ctx.r10.s64 = r23.s64 + 8;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a9160
	if (!cr6.getEQ()) goto loc_820A9160;
	// addi r10,r23,12
	ctx.r10.s64 = r23.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820a9164
	goto loc_820A9164;
loc_820A9160:
	// mr r11,r18
	r11.u64 = r18.u64;
loc_820A9164:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// lfs f12,452(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 452);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f0,-6368(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6368);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,14408(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14408);
	ctx.f13.f64 = double(temp.f32);
	// beq cr6,0x820a91a0
	if (cr6.getEQ()) goto loc_820A91A0;
	// fmadds f0,f0,f13,f12
	f0.f64 = double(float(f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// stfs f0,452(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 452, temp.u32);
	// fcmpu cr6,f0,f27
	cr6.compare(f0.f64, f27.f64);
	// ble cr6,0x820a9240
	if (!cr6.getGT()) goto loc_820A9240;
	// stfs f27,452(r31)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r31.u32 + 452, temp.u32);
	// b 0x820a9240
	goto loc_820A9240;
loc_820A91A0:
	// fnmsubs f0,f0,f13,f12
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(-(f0.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// stfs f0,452(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 452, temp.u32);
	// fcmpu cr6,f0,f28
	cr6.compare(f0.f64, f28.f64);
	// bge cr6,0x820a9240
	if (!cr6.getLT()) goto loc_820A9240;
	// b 0x820a923c
	goto loc_820A923C;
loc_820A91B4:
	// lwz r11,2348(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2348);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820a91c4
	if (!cr6.getLT()) goto loc_820A91C4;
	// lwz r11,2344(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2344);
loc_820A91C4:
	// mulli r11,r11,56
	r11.s64 = r11.s64 * 56;
	// addi r10,r23,8
	ctx.r10.s64 = r23.s64 + 8;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a91e4
	if (!cr6.getEQ()) goto loc_820A91E4;
	// addi r10,r23,12
	ctx.r10.s64 = r23.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820a91e8
	goto loc_820A91E8;
loc_820A91E4:
	// mr r11,r18
	r11.u64 = r18.u64;
loc_820A91E8:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// lfs f12,452(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 452);
	ctx.f12.f64 = double(temp.f32);
	// rlwinm r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f0,-6368(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6368);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,14408(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14408);
	ctx.f13.f64 = double(temp.f32);
	// beq cr6,0x820a922c
	if (cr6.getEQ()) goto loc_820A922C;
	// fnmsubs f0,f0,f13,f12
	f0.f64 = double(float(-(f0.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,452(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 452, temp.u32);
	// lfs f13,14264(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14264);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820a9240
	if (!cr6.getLT()) goto loc_820A9240;
	// stfs f13,452(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 452, temp.u32);
	// b 0x820a9240
	goto loc_820A9240;
loc_820A922C:
	// fmadds f0,f0,f13,f12
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// stfs f0,452(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 452, temp.u32);
	// fcmpu cr6,f0,f28
	cr6.compare(f0.f64, f28.f64);
	// ble cr6,0x820a9240
	if (!cr6.getGT()) goto loc_820A9240;
loc_820A923C:
	// stfs f28,452(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(r31.u32 + 452, temp.u32);
loc_820A9240:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r30,408(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 408);
	// addi r8,r1,128
	ctx.r8.s64 = ctx.r1.s64 + 128;
	// lfs f1,412(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 412);
	ctx.f1.f64 = double(temp.f32);
	// addi r10,r30,3
	ctx.r10.s64 = r30.s64 + 3;
	// stfs f28,128(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// addi r9,r30,1
	ctx.r9.s64 = r30.s64 + 1;
	// stfs f28,132(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// addi r7,r30,2
	ctx.r7.s64 = r30.s64 + 2;
	// stfs f28,136(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// lfs f29,6580(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6580);
	f29.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f28,112(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f28,116(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f29,120(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// stfs f28,144(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f24,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f24.f64 = double(temp.f32);
	// addi r11,r30,22
	r11.s64 = r30.s64 + 22;
	// stfs f24,148(r1)
	temp.f32 = float(f24.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// rlwinm r6,r11,1,0,30
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// stfs f28,152(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// add r11,r11,r6
	r11.u64 = r11.u64 + ctx.r6.u64;
	// srawi r6,r10,2
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
	ctx.r6.s64 = ctx.r10.s32 >> 2;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addze r6,r6
	temp.s64 = ctx.r6.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r6.u32;
	ctx.r6.s64 = temp.s64;
	// srawi r5,r9,2
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0x3) != 0);
	ctx.r5.s64 = ctx.r9.s32 >> 2;
	// rlwinm r6,r6,2,0,29
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// addze r5,r5
	temp.s64 = ctx.r5.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r5.u32;
	ctx.r5.s64 = temp.s64;
	// srawi r4,r7,2
	xer.ca = (ctx.r7.s32 < 0) & ((ctx.r7.u32 & 0x3) != 0);
	ctx.r4.s64 = ctx.r7.s32 >> 2;
	// subf r29,r6,r10
	r29.s64 = ctx.r10.s64 - ctx.r6.s64;
	// addze r4,r4
	temp.s64 = ctx.r4.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r4.u32;
	ctx.r4.s64 = temp.s64;
	// rlwinm r5,r5,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r4,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r28,r5,r9
	r28.s64 = ctx.r9.s64 - ctx.r5.s64;
	// subf r27,r10,r7
	r27.s64 = ctx.r7.s64 - ctx.r10.s64;
	// add r4,r11,r31
	ctx.r4.u64 = r11.u64 + r31.u64;
	// addi r11,r29,22
	r11.s64 = r29.s64 + 22;
	// addi r10,r28,22
	ctx.r10.s64 = r28.s64 + 22;
	// addi r9,r27,22
	ctx.r9.s64 = r27.s64 + 22;
	// rlwinm r6,r10,1,0,30
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r5,r9,1,0,30
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r7,r11,1,0,30
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r9,r9,r5
	ctx.r9.u64 = ctx.r9.u64 + ctx.r5.u64;
	// add r10,r10,r6
	ctx.r10.u64 = ctx.r10.u64 + ctx.r6.u64;
	// add r11,r11,r7
	r11.u64 = r11.u64 + ctx.r7.u64;
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r6,r9,r31
	ctx.r6.u64 = ctx.r9.u64 + r31.u64;
	// add r5,r10,r31
	ctx.r5.u64 = ctx.r10.u64 + r31.u64;
	// add r3,r11,r31
	ctx.r3.u64 = r11.u64 + r31.u64;
	// bl 0x8210af58
	sub_8210AF58(ctx, base);
	// addi r11,r27,26
	r11.s64 = r27.s64 + 26;
	// addi r10,r28,26
	ctx.r10.s64 = r28.s64 + 26;
	// lfs f1,412(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 412);
	ctx.f1.f64 = double(temp.f32);
	// rlwinm r6,r11,1,0,30
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r7,r10,1,0,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r9,r30,26
	ctx.r9.s64 = r30.s64 + 26;
	// add r11,r11,r6
	r11.u64 = r11.u64 + ctx.r6.u64;
	// add r6,r10,r7
	ctx.r6.u64 = ctx.r10.u64 + ctx.r7.u64;
	// rlwinm r7,r9,1,0,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r6,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 + ctx.r7.u64;
	// add r6,r10,r31
	ctx.r6.u64 = ctx.r10.u64 + r31.u64;
	// add r5,r11,r31
	ctx.r5.u64 = r11.u64 + r31.u64;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r29,26
	r11.s64 = r29.s64 + 26;
	// add r4,r10,r31
	ctx.r4.u64 = ctx.r10.u64 + r31.u64;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r8,r1,112
	ctx.r8.s64 = ctx.r1.s64 + 112;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r3,r11,r31
	ctx.r3.u64 = r11.u64 + r31.u64;
	// bl 0x8210af58
	sub_8210AF58(ctx, base);
	// lfs f1,412(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 412);
	ctx.f1.f64 = double(temp.f32);
	// addi r11,r27,30
	r11.s64 = r27.s64 + 30;
	// addi r10,r28,30
	ctx.r10.s64 = r28.s64 + 30;
	// addi r9,r30,30
	ctx.r9.s64 = r30.s64 + 30;
	// addi r7,r29,30
	ctx.r7.s64 = r29.s64 + 30;
	// addi r8,r1,144
	ctx.r8.s64 = ctx.r1.s64 + 144;
	// rlwinm r3,r11,1,0,30
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r4,r10,1,0,30
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r5,r9,1,0,30
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r6,r7,1,0,30
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r3
	r11.u64 = r11.u64 + ctx.r3.u64;
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// add r5,r9,r5
	ctx.r5.u64 = ctx.r9.u64 + ctx.r5.u64;
	// add r6,r7,r6
	ctx.r6.u64 = ctx.r7.u64 + ctx.r6.u64;
	// rlwinm r7,r11,2,0,29
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r11,r6,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// add r6,r7,r31
	ctx.r6.u64 = ctx.r7.u64 + r31.u64;
	// add r5,r9,r31
	ctx.r5.u64 = ctx.r9.u64 + r31.u64;
	// add r4,r10,r31
	ctx.r4.u64 = ctx.r10.u64 + r31.u64;
	// add r3,r11,r31
	ctx.r3.u64 = r11.u64 + r31.u64;
	// bl 0x8210af58
	sub_8210AF58(ctx, base);
	// lwz r11,-1364(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + -1364);
	// lfs f13,128(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f13.f64 = double(temp.f32);
	// mr r9,r17
	ctx.r9.u64 = r17.u64;
	// lfs f12,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	ctx.f12.f64 = double(temp.f32);
	// add r10,r22,r11
	ctx.r10.u64 = r22.u64 + r11.u64;
	// lfs f11,428(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 428);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f10.f64 = double(temp.f32);
	// lfs f0,4216(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4216);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f13,4216(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4216);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f12,f13,f12
	ctx.f12.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f12,132(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f13,4216(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4216);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// fmuls f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// lfs f10,432(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 432);
	ctx.f10.f64 = double(temp.f32);
	// stfs f13,136(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// fadds f0,f11,f0
	f0.f64 = double(float(ctx.f11.f64 + f0.f64));
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fadds f12,f10,f12
	ctx.f12.f64 = double(float(ctx.f10.f64 + ctx.f12.f64));
	// stfs f12,132(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f11,2796(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2796);
	ctx.f11.f64 = double(temp.f32);
	// lwz r10,-6384(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -6384);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// fadds f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 + f0.f64));
	// ble cr6,0x820a94d0
	if (!cr6.getGT()) goto loc_820A94D0;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f10,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,148(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 148);
	ctx.f6.f64 = double(temp.f32);
	// lfs f5,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f5.f64 = double(temp.f32);
	// lfs f0,14280(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14280);
	f0.f64 = double(temp.f32);
loc_820A9454:
	// lfs f4,228(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 228);
	ctx.f4.f64 = double(temp.f32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// fmadds f4,f4,f0,f11
	ctx.f4.f64 = double(float(ctx.f4.f64 * f0.f64 + ctx.f11.f64));
	// lfs f3,232(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 232);
	ctx.f3.f64 = double(temp.f32);
	// stfs f4,228(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(r31.u32 + 228, temp.u32);
	// fmadds f4,f3,f0,f12
	ctx.f4.f64 = double(float(ctx.f3.f64 * f0.f64 + ctx.f12.f64));
	// lfs f2,236(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 236);
	ctx.f2.f64 = double(temp.f32);
	// stfs f4,232(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(r31.u32 + 232, temp.u32);
	// fmadds f4,f2,f0,f13
	ctx.f4.f64 = double(float(ctx.f2.f64 * f0.f64 + ctx.f13.f64));
	// lfs f1,240(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 240);
	ctx.f1.f64 = double(temp.f32);
	// stfs f4,236(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(r31.u32 + 236, temp.u32);
	// fmadds f4,f1,f0,f8
	ctx.f4.f64 = double(float(ctx.f1.f64 * f0.f64 + ctx.f8.f64));
	// lfs f31,244(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 244);
	f31.f64 = double(temp.f32);
	// stfs f4,240(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(r31.u32 + 240, temp.u32);
	// fmadds f4,f31,f0,f9
	ctx.f4.f64 = double(float(f31.f64 * f0.f64 + ctx.f9.f64));
	// lfs f30,248(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 248);
	f30.f64 = double(temp.f32);
	// stfs f4,244(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(r31.u32 + 244, temp.u32);
	// fmadds f4,f30,f0,f10
	ctx.f4.f64 = double(float(f30.f64 * f0.f64 + ctx.f10.f64));
	// lfs f26,252(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 252);
	f26.f64 = double(temp.f32);
	// stfs f4,248(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(r31.u32 + 248, temp.u32);
	// fmadds f4,f26,f0,f5
	ctx.f4.f64 = double(float(f26.f64 * f0.f64 + ctx.f5.f64));
	// lfs f25,256(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 256);
	f25.f64 = double(temp.f32);
	// stfs f4,252(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(r31.u32 + 252, temp.u32);
	// fmadds f4,f25,f0,f6
	ctx.f4.f64 = double(float(f25.f64 * f0.f64 + ctx.f6.f64));
	// lfs f23,260(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 260);
	f23.f64 = double(temp.f32);
	// stfs f4,256(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(r31.u32 + 256, temp.u32);
	// fmadds f4,f23,f0,f7
	ctx.f4.f64 = double(float(f23.f64 * f0.f64 + ctx.f7.f64));
	// stfs f4,260(r31)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(r31.u32 + 260, temp.u32);
	// lwz r10,-6384(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -6384);
	// cmpw cr6,r9,r10
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, xer);
	// blt cr6,0x820a9454
	if (cr6.getLT()) goto loc_820A9454;
loc_820A94D0:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,228(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 228);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,232(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 232);
	ctx.f12.f64 = double(temp.f32);
	// cmpwi cr6,r14,0
	cr6.compare<int32_t>(r14.s32, 0, xer);
	// lfs f11,236(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 236);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,240(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 240);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,244(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 244);
	ctx.f9.f64 = double(temp.f32);
	// lfs f0,14276(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14276);
	f0.f64 = double(temp.f32);
	// lfs f8,248(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 248);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f7,252(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 252);
	ctx.f7.f64 = double(temp.f32);
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * f0.f64));
	// lfs f6,256(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 256);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * f0.f64));
	// lfs f5,260(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 260);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * f0.f64));
	// stfs f12,196(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r31.u32 + 196, temp.u32);
	// fmuls f8,f8,f0
	ctx.f8.f64 = double(float(ctx.f8.f64 * f0.f64));
	// stfs f11,200(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r31.u32 + 200, temp.u32);
	// fmuls f7,f7,f0
	ctx.f7.f64 = double(float(ctx.f7.f64 * f0.f64));
	// stfs f10,204(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(r31.u32 + 204, temp.u32);
	// fmuls f6,f6,f0
	ctx.f6.f64 = double(float(ctx.f6.f64 * f0.f64));
	// stfs f9,208(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(r31.u32 + 208, temp.u32);
	// fmuls f0,f5,f0
	f0.f64 = double(float(ctx.f5.f64 * f0.f64));
	// stfs f8,212(r31)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(r31.u32 + 212, temp.u32);
	// stfs f7,216(r31)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(r31.u32 + 216, temp.u32);
	// stfs f6,220(r31)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(r31.u32 + 220, temp.u32);
	// stfs f0,224(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 224, temp.u32);
	// stfs f13,192(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 192, temp.u32);
	// bne cr6,0x820a9564
	if (!cr6.getEQ()) goto loc_820A9564;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820a0e08
	sub_820A0E08(ctx, base);
	// lfs f0,440(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 440);
	f0.f64 = double(temp.f32);
	// fadds f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 + f0.f64));
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// b 0x820a9578
	goto loc_820A9578;
loc_820A9564:
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x820a0e08
	sub_820A0E08(ctx, base);
	// fadds f13,f1,f13
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64 + ctx.f13.f64));
	// lfs f0,440(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 440);
	f0.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
loc_820A9578:
	// stfs f0,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// cmpwi cr6,r15,25
	cr6.compare<int32_t>(r15.s32, 25, xer);
	// lfs f13,8(r20)
	temp.u32 = PPC_LOAD_U32(r20.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,444(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 444);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// lfs f13,196(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f12,12(r20)
	temp.u32 = PPC_LOAD_U32(r20.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,448(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 448);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// lfs f12,200(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 200);
	ctx.f12.f64 = double(temp.f32);
	// fadds f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f12.f64));
	// stfs f13,104(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// beq cr6,0x820a962c
	if (cr6.getEQ()) goto loc_820A962C;
	// cmpwi cr6,r15,30
	cr6.compare<int32_t>(r15.s32, 30, xer);
	// beq cr6,0x820a962c
	if (cr6.getEQ()) goto loc_820A962C;
	// cmpwi cr6,r15,23
	cr6.compare<int32_t>(r15.s32, 23, xer);
	// beq cr6,0x820a962c
	if (cr6.getEQ()) goto loc_820A962C;
	// cmpwi cr6,r15,31
	cr6.compare<int32_t>(r15.s32, 31, xer);
	// bne cr6,0x820a95fc
	if (!cr6.getEQ()) goto loc_820A95FC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,14404(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14404);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f11,14400(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14400);
	ctx.f11.f64 = double(temp.f32);
	// lwz r11,-1364(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + -1364);
	// lfs f10,420(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 420);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f0,f10,f12,f0
	f0.f64 = double(float(-(ctx.f10.f64 * ctx.f12.f64 - f0.f64)));
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f0,420(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 420);
	f0.f64 = double(temp.f32);
	// fnmsubs f0,f0,f11,f13
	f0.f64 = double(float(-(f0.f64 * ctx.f11.f64 - ctx.f13.f64)));
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// b 0x820a96a8
	goto loc_820A96A8;
loc_820A95FC:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f12,14116(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14116);
	ctx.f12.f64 = double(temp.f32);
	// lwz r11,-1364(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + -1364);
	// lfs f11,14396(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14396);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,420(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 420);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f0,f10,f12,f0
	f0.f64 = double(float(-(ctx.f10.f64 * ctx.f12.f64 - f0.f64)));
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f0,420(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 420);
	f0.f64 = double(temp.f32);
	// fnmsubs f0,f0,f11,f13
	f0.f64 = double(float(-(f0.f64 * ctx.f11.f64 - ctx.f13.f64)));
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// b 0x820a96a8
	goto loc_820A96A8;
loc_820A962C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// cmpwi cr6,r15,25
	cr6.compare<int32_t>(r15.s32, 25, xer);
	// lfs f12,3904(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3904);
	ctx.f12.f64 = double(temp.f32);
	// lwz r11,-1364(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + -1364);
	// lfs f11,14392(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14392);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,420(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 420);
	ctx.f10.f64 = double(temp.f32);
	// fnmsubs f0,f10,f12,f0
	f0.f64 = double(float(-(ctx.f10.f64 * ctx.f12.f64 - f0.f64)));
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f0,420(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 420);
	f0.f64 = double(temp.f32);
	// fnmsubs f0,f0,f11,f13
	f0.f64 = double(float(-(f0.f64 * ctx.f11.f64 - ctx.f13.f64)));
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// bne cr6,0x820a96a8
	if (!cr6.getEQ()) goto loc_820A96A8;
	// bl 0x820c30e8
	sub_820C30E8(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x820a9690
	if (cr6.getEQ()) goto loc_820A9690;
	// bl 0x820c30e8
	sub_820C30E8(ctx, base);
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// beq cr6,0x820a9690
	if (cr6.getEQ()) goto loc_820A9690;
	// bl 0x820c31d0
	sub_820C31D0(ctx, base);
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// beq cr6,0x820a9690
	if (cr6.getEQ()) goto loc_820A9690;
	// bl 0x820c31d0
	sub_820C31D0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x820a96a4
	if (!cr6.getEQ()) goto loc_820A96A4;
loc_820A9690:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,100(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,3908(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3908);
	f0.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
loc_820A96A4:
	// lwz r11,-1364(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + -1364);
loc_820A96A8:
	// lbz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f25,14028(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14028);
	f25.f64 = double(temp.f32);
	// beq cr6,0x820a97d8
	if (cr6.getEQ()) goto loc_820A97D8;
	// lwzx r9,r25,r19
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + r19.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a96d4
	if (!cr6.getEQ()) goto loc_820A96D4;
	// addi r10,r23,12
	ctx.r10.s64 = r23.s64 + 12;
	// lwzx r10,r25,r10
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + ctx.r10.u32);
	// b 0x820a96d8
	goto loc_820A96D8;
loc_820A96D4:
	// mr r10,r18
	ctx.r10.u64 = r18.u64;
loc_820A96D8:
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a97d8
	if (cr6.getEQ()) goto loc_820A97D8;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820a96fc
	if (!cr6.getEQ()) goto loc_820A96FC;
	// addi r11,r23,12
	r11.s64 = r23.s64 + 12;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820a9700
	goto loc_820A9700;
loc_820A96FC:
	// mr r11,r18
	r11.u64 = r18.u64;
loc_820A9700:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// rlwinm r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,14016(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14016);
	f30.f64 = double(temp.f32);
	// lfs f31,12904(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12904);
	f31.f64 = double(temp.f32);
	// beq cr6,0x820a975c
	if (cr6.getEQ()) goto loc_820A975C;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f13,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f0,112(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f25
	f0.f64 = double(float(f0.f64 * f25.f64));
	// fnmsubs f0,f0,f31,f30
	f0.f64 = double(float(-(f0.f64 * f31.f64 - f30.f64)));
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
loc_820A975C:
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f13,100(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f0,112(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f25
	f0.f64 = double(float(f0.f64 * f25.f64));
	// fnmsubs f0,f0,f31,f30
	f0.f64 = double(float(-(f0.f64 * f31.f64 - f30.f64)));
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f13,104(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f13.f64 = double(temp.f32);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f0,112(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lwz r11,-1364(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + -1364);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f25
	f0.f64 = double(float(f0.f64 * f25.f64));
	// fnmsubs f0,f0,f31,f30
	f0.f64 = double(float(-(f0.f64 * f31.f64 - f30.f64)));
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
loc_820A97D8:
	// lfs f31,4276(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4276);
	f31.f64 = double(temp.f32);
	// bl 0x8210d8c0
	sub_8210D8C0(ctx, base);
	// fsubs f30,f31,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = double(float(f31.f64 - ctx.f1.f64));
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,24(r20)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r20.u32 + 24);
	f0.f64 = double(temp.f32);
	// lfs f31,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f31.f64 = double(temp.f32);
	// fnmsubs f13,f1,f31,f30
	ctx.f13.f64 = double(float(-(ctx.f1.f64 * f31.f64 - f30.f64)));
	// fmuls f30,f13,f0
	f30.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x8210d8a0
	sub_8210D8A0(ctx, base);
	// fmuls f0,f1,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 * f31.f64));
	// lwz r11,-1364(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + -1364);
	// lfs f13,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f30,f0
	f0.f64 = double(float(f30.f64 / f0.f64));
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f30,4280(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4280);
	f30.f64 = double(temp.f32);
	// bl 0x8210d8d0
	sub_8210D8D0(ctx, base);
	// fsubs f30,f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = double(float(f30.f64 - ctx.f1.f64));
	// bl 0x8210d8b0
	sub_8210D8B0(ctx, base);
	// fmuls f0,f1,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 * f31.f64));
	// lwz r11,-1364(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + -1364);
	// fcmpu cr6,f30,f0
	cr6.compare(f30.f64, f0.f64);
	// lfs f30,4280(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4280);
	f30.f64 = double(temp.f32);
	// ble cr6,0x820a9850
	if (!cr6.getGT()) goto loc_820A9850;
	// bl 0x8210d8d0
	sub_8210D8D0(ctx, base);
	// fsubs f30,f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = double(float(f30.f64 - ctx.f1.f64));
	// bl 0x8210d8b0
	sub_8210D8B0(ctx, base);
	// lfs f0,20(r20)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r20.u32 + 20);
	f0.f64 = double(temp.f32);
	// b 0x820a9860
	goto loc_820A9860;
loc_820A9850:
	// bl 0x8210d8d0
	sub_8210D8D0(ctx, base);
	// fsubs f30,f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = double(float(f30.f64 - ctx.f1.f64));
	// bl 0x8210d8b0
	sub_8210D8B0(ctx, base);
	// lfs f0,16(r20)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r20.u32 + 16);
	f0.f64 = double(temp.f32);
loc_820A9860:
	// fnmsubs f13,f1,f31,f30
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(-(ctx.f1.f64 * f31.f64 - f30.f64)));
	// fmuls f30,f13,f0
	f30.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x8210d8b0
	sub_8210D8B0(ctx, base);
	// fmuls f0,f1,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 * f31.f64));
	// lfs f13,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f30,f0
	f0.f64 = double(float(f30.f64 / f0.f64));
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// bl 0x820a07a0
	sub_820A07A0(ctx, base);
	// addi r3,r1,352
	ctx.r3.s64 = ctx.r1.s64 + 352;
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// cmpwi cr6,r15,30
	cr6.compare<int32_t>(r15.s32, 30, xer);
	// beq cr6,0x820a9954
	if (cr6.getEQ()) goto loc_820A9954;
	// cmpwi cr6,r15,23
	cr6.compare<int32_t>(r15.s32, 23, xer);
	// beq cr6,0x820a9954
	if (cr6.getEQ()) goto loc_820A9954;
	// cmpwi cr6,r15,31
	cr6.compare<int32_t>(r15.s32, 31, xer);
	// bne cr6,0x820a98c8
	if (!cr6.getEQ()) goto loc_820A98C8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,14388(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14388);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f0,14384(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14384);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,148(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f0,14380(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14380);
	f0.f64 = double(temp.f32);
	// b 0x820a9974
	goto loc_820A9974;
loc_820A98C8:
	// cmpwi cr6,r15,1
	cr6.compare<int32_t>(r15.s32, 1, xer);
	// bne cr6,0x820a9990
	if (!cr6.getEQ()) goto loc_820A9990;
	// lwz r11,-1364(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + -1364);
	// lwz r11,8376(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8376);
	// cmpwi cr6,r11,17
	cr6.compare<int32_t>(r11.s32, 17, xer);
	// bne cr6,0x820a9990
	if (!cr6.getEQ()) goto loc_820A9990;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// lfs f0,14376(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14376);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f0,14372(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14372);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,148(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f0,14368(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14368);
	f0.f64 = double(temp.f32);
	// stfs f0,152(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// bl 0x8210ba08
	sub_8210BA08(ctx, base);
	// addi r4,r1,352
	ctx.r4.s64 = ctx.r1.s64 + 352;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x8210c778
	sub_8210C778(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,14132(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14132);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f13,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,14364(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14364);
	f0.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f0,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f27
	f0.f64 = double(float(f0.f64 + f27.f64));
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// b 0x820a9990
	goto loc_820A9990;
loc_820A9954:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,14360(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14360);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// lfs f0,14356(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14356);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,148(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// lfs f0,14352(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14352);
	f0.f64 = double(temp.f32);
loc_820A9974:
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// stfs f0,152(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x8210ba08
	sub_8210BA08(ctx, base);
	// addi r4,r1,352
	ctx.r4.s64 = ctx.r1.s64 + 352;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x8210c778
	sub_8210C778(ctx, base);
loc_820A9990:
	// lwz r11,188(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 188);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820a99e8
	if (cr6.getEQ()) goto loc_820A99E8;
	// lfs f0,172(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 172);
	f0.f64 = double(temp.f32);
	// addi r4,r1,352
	ctx.r4.s64 = ctx.r1.s64 + 352;
	// lfs f13,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// addi r3,r31,124
	ctx.r3.s64 = r31.s64 + 124;
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f0,176(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 176);
	f0.f64 = double(temp.f32);
	// lfs f13,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f0,180(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 180);
	f0.f64 = double(temp.f32);
	// lfs f13,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// bl 0x8210c778
	sub_8210C778(ctx, base);
	// stfs f28,400(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// stfs f28,404(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// stfs f28,408(r1)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// b 0x820a99f8
	goto loc_820A99F8;
loc_820A99E8:
	// stfs f28,120(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(r31.u32 + 120, temp.u32);
	// stfs f28,108(r31)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(r31.u32 + 108, temp.u32);
	// stfs f28,112(r31)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(r31.u32 + 112, temp.u32);
	// stfs f28,116(r31)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(r31.u32 + 116, temp.u32);
loc_820A99F8:
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// lfs f9,224(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 224);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,220(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 220);
	ctx.f8.f64 = double(temp.f32);
	// fmr f3,f28
	ctx.f3.f64 = f28.f64;
	// lfs f7,216(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 216);
	ctx.f7.f64 = double(temp.f32);
	// fmr f2,f28
	ctx.f2.f64 = f28.f64;
	// lfs f6,212(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 212);
	ctx.f6.f64 = double(temp.f32);
	// fmr f1,f28
	ctx.f1.f64 = f28.f64;
	// lfs f5,208(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 208);
	ctx.f5.f64 = double(temp.f32);
	// lfs f4,204(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 204);
	ctx.f4.f64 = double(temp.f32);
	// bl 0x8210c040
	sub_8210C040(ctx, base);
	// addi r4,r1,352
	ctx.r4.s64 = ctx.r1.s64 + 352;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x8210c778
	sub_8210C778(ctx, base);
	// lfs f0,464(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 464);
	f0.f64 = double(temp.f32);
	// lfs f11,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f11.f64 = double(temp.f32);
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// fsubs f4,f11,f0
	ctx.f4.f64 = double(float(ctx.f11.f64 - f0.f64));
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	f0.f64 = double(temp.f32);
	// lfs f13,460(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 460);
	ctx.f13.f64 = double(temp.f32);
	// fmr f1,f28
	ctx.f1.f64 = f28.f64;
	// fsubs f3,f0,f13
	ctx.f3.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,456(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 456);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	f0.f64 = double(temp.f32);
	// fsubs f2,f0,f12
	ctx.f2.f64 = double(float(f0.f64 - ctx.f12.f64));
	// bl 0x8210c340
	sub_8210C340(ctx, base);
	// addi r4,r1,352
	ctx.r4.s64 = ctx.r1.s64 + 352;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x8210c778
	sub_8210C778(ctx, base);
	// addi r4,r1,416
	ctx.r4.s64 = ctx.r1.s64 + 416;
	// addi r3,r1,352
	ctx.r3.s64 = ctx.r1.s64 + 352;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// addi r4,r1,416
	ctx.r4.s64 = ctx.r1.s64 + 416;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// addi r30,r31,552
	r30.s64 = r31.s64 + 552;
	// addi r3,r1,416
	ctx.r3.s64 = ctx.r1.s64 + 416;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// addi r29,r31,616
	r29.s64 = r31.s64 + 616;
	// addi r4,r31,680
	ctx.r4.s64 = r31.s64 + 680;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x8210b450
	sub_8210B450(ctx, base);
	// li r24,1
	r24.s64 = 1;
	// mr r11,r15
	r11.u64 = r15.u64;
	// cmpwi cr6,r15,1
	cr6.compare<int32_t>(r15.s32, 1, xer);
	// stb r24,15(r31)
	PPC_STORE_U8(r31.u32 + 15, r24.u8);
	// bne cr6,0x820a9ad0
	if (!cr6.getEQ()) goto loc_820A9AD0;
	// lwz r11,-1364(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + -1364);
	// lwz r11,8376(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8376);
loc_820A9AD0:
	// mulli r11,r11,56
	r11.s64 = r11.s64 * 56;
	// lwzx r11,r11,r23
	r11.u64 = PPC_LOAD_U32(r11.u32 + r23.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820a9b70
	if (cr6.getEQ()) goto loc_820A9B70;
	// lwzx r10,r25,r19
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + r19.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a9af8
	if (!cr6.getEQ()) goto loc_820A9AF8;
	// addi r11,r23,12
	r11.s64 = r23.s64 + 12;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820a9afc
	goto loc_820A9AFC;
loc_820A9AF8:
	// mr r11,r18
	r11.u64 = r18.u64;
loc_820A9AFC:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a9b70
	if (cr6.getEQ()) goto loc_820A9B70;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820a9b20
	if (!cr6.getEQ()) goto loc_820A9B20;
	// addi r11,r23,12
	r11.s64 = r23.s64 + 12;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820a9b24
	goto loc_820A9B24;
loc_820A9B20:
	// mr r11,r18
	r11.u64 = r18.u64;
loc_820A9B24:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,18,18
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a9b70
	if (!cr6.getEQ()) goto loc_820A9B70;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x820a9b70
	if (cr6.getEQ()) goto loc_820A9B70;
	// cmpwi cr6,r11,7
	cr6.compare<int32_t>(r11.s32, 7, xer);
	// beq cr6,0x820a9b70
	if (cr6.getEQ()) goto loc_820A9B70;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x820a09e0
	sub_820A09E0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820a9b70
	if (cr6.getEQ()) goto loc_820A9B70;
	// addi r11,r14,580
	r11.s64 = r14.s64 + 580;
	// lwz r10,-1364(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + -1364);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820a9b74
	if (!cr6.getEQ()) goto loc_820A9B74;
loc_820A9B70:
	// stb r17,15(r31)
	PPC_STORE_U8(r31.u32 + 15, r17.u8);
loc_820A9B74:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x820a9bb0
	if (cr6.getGT()) goto loc_820A9BB0;
	// lwzx r11,r25,r19
	r11.u64 = PPC_LOAD_U32(r25.u32 + r19.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a9b98
	if (!cr6.getEQ()) goto loc_820A9B98;
	// addi r11,r23,12
	r11.s64 = r23.s64 + 12;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820a9b9c
	goto loc_820A9B9C;
loc_820A9B98:
	// mr r11,r18
	r11.u64 = r18.u64;
loc_820A9B9C:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a9bb0
	if (cr6.getEQ()) goto loc_820A9BB0;
	// stb r17,15(r31)
	PPC_STORE_U8(r31.u32 + 15, r17.u8);
loc_820A9BB0:
	// lbz r11,15(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 15);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820aa634
	if (cr6.getEQ()) goto loc_820AA634;
	// addi r11,r14,584
	r11.s64 = r14.s64 + 584;
	// lwz r10,-1364(r21)
	ctx.r10.u64 = PPC_LOAD_U32(r21.u32 + -1364);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r28,r11,r10
	r28.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// lhz r11,14(r28)
	r11.u64 = PPC_LOAD_U16(r28.u32 + 14);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// rlwinm r3,r11,6,0,25
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0xFFFFFFC0;
	// bl 0x8209cd50
	sub_8209CD50(ctx, base);
	// lhz r11,14(r28)
	r11.u64 = PPC_LOAD_U16(r28.u32 + 14);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// mr r30,r17
	r30.u64 = r17.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820a9c18
	if (!cr6.getGT()) goto loc_820A9C18;
	// mr r29,r27
	r29.u64 = r27.u64;
loc_820A9BF8:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// lhz r11,14(r28)
	r11.u64 = PPC_LOAD_U16(r28.u32 + 14);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// addi r29,r29,64
	r29.s64 = r29.s64 + 64;
	// cmpw cr6,r30,r11
	cr6.compare<int32_t>(r30.s32, r11.s32, xer);
	// blt cr6,0x820a9bf8
	if (cr6.getLT()) goto loc_820A9BF8;
loc_820A9C18:
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8211c6c8
	sub_8211C6C8(ctx, base);
	// lhz r11,20(r28)
	r11.u64 = PPC_LOAD_U16(r28.u32 + 20);
	// extsh r4,r11
	ctx.r4.s64 = r11.s16;
	// cmpwi cr6,r4,32
	cr6.compare<int32_t>(ctx.r4.s32, 32, xer);
	// ble cr6,0x820a9c3c
	if (!cr6.getGT()) goto loc_820A9C3C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r3,r11,14320
	ctx.r3.s64 = r11.s64 + 14320;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
loc_820A9C3C:
	// addi r26,r31,760
	r26.s64 = r31.s64 + 760;
	// addi r5,r31,792
	ctx.r5.s64 = r31.s64 + 792;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8211c930
	sub_8211C930(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820a1530
	sub_820A1530(ctx, base);
	// lbz r11,14(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 14);
	// extsb r30,r11
	r30.s64 = r11.s8;
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lhz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 12);
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// cmpwi cr6,r10,15
	cr6.compare<int32_t>(ctx.r10.s32, 15, xer);
	// ble cr6,0x820a9cbc
	if (!cr6.getGT()) goto loc_820A9CBC;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,56(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 56);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a9c98
	if (cr6.getEQ()) goto loc_820A9C98;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_820A9C98:
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,60(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 60);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a9cbc
	if (cr6.getEQ()) goto loc_820A9CBC;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_820A9CBC:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a9ce4
	if (cr6.getEQ()) goto loc_820A9CE4;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lwz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lhz r10,4(r10)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + 4);
	// addi r10,r10,198
	ctx.r10.s64 = ctx.r10.s64 + 198;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r16,r10,r31
	r16.u64 = ctx.r10.u64 + r31.u64;
loc_820A9CE4:
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a9cf8
	if (cr6.getEQ()) goto loc_820A9CF8;
	// rotlwi r11,r10,0
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lwz r17,4(r11)
	r17.u64 = PPC_LOAD_U32(r11.u32 + 4);
loc_820A9CF8:
	// stw r27,772(r31)
	PPC_STORE_U32(r31.u32 + 772, r27.u32);
	// lwzx r11,r25,r19
	r11.u64 = PPC_LOAD_U32(r25.u32 + r19.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820a9d14
	if (!cr6.getEQ()) goto loc_820A9D14;
	// addi r11,r23,12
	r11.s64 = r23.s64 + 12;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820a9d18
	goto loc_820A9D18;
loc_820A9D14:
	// mr r11,r18
	r11.u64 = r18.u64;
loc_820A9D18:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820a9d3c
	if (cr6.getEQ()) goto loc_820A9D3C;
	// cmpwi cr6,r14,1
	cr6.compare<int32_t>(r14.s32, 1, xer);
	// bne cr6,0x820a9d3c
	if (!cr6.getEQ()) goto loc_820A9D3C;
	// addi r4,r1,416
	ctx.r4.s64 = ctx.r1.s64 + 416;
	// fmr f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f29.f64;
	// bl 0x8210bc18
	sub_8210BC18(ctx, base);
loc_820A9D3C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,416
	ctx.r4.s64 = ctx.r1.s64 + 416;
	// lfs f27,14176(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14176);
	f27.f64 = double(temp.f32);
	// fmr f1,f27
	ctx.f1.f64 = f27.f64;
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// addi r3,r1,416
	ctx.r3.s64 = ctx.r1.s64 + 416;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lis r11,-32019
	r11.s64 = -2098397184;
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// addi r11,r11,25696
	r11.s64 = r11.s64 + 25696;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f26,13976(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13976);
	f26.f64 = double(temp.f32);
	// bne cr6,0x820a9ee4
	if (!cr6.getEQ()) goto loc_820A9EE4;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a9e4c
	if (cr6.getEQ()) goto loc_820A9E4C;
	// rotlwi r11,r10,0
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// fmr f1,f28
	ctx.f1.f64 = f28.f64;
	// cmpwi cr6,r15,18
	cr6.compare<int32_t>(r15.s32, 18, xer);
	// lwz r30,4(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// bne cr6,0x820a9dfc
	if (!cr6.getEQ()) goto loc_820A9DFC;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// bne cr6,0x820a9dd4
	if (!cr6.getEQ()) goto loc_820A9DD4;
	// subfic r11,r11,5
	xer.ca = r11.u32 <= 5;
	r11.s64 = 5 - r11.s64;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// rlwinm r9,r11,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f0,112(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// b 0x820a9e1c
	goto loc_820A9E1C;
loc_820A9DD4:
	// subfic r11,r11,6
	xer.ca = r11.u32 <= 6;
	r11.s64 = 6 - r11.s64;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f0,112(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// frsp f13,f0
	ctx.f13.f64 = double(float(f0.f64));
	// lfs f0,14316(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14316);
	f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * f0.f64));
	// b 0x820a9e28
	goto loc_820A9E28;
loc_820A9DFC:
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x820a9e28
	if (!cr6.getEQ()) goto loc_820A9E28;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bge cr6,0x820a9e28
	if (!cr6.getLT()) goto loc_820A9E28;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f0,112(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
loc_820A9E1C:
	// fcfid f0,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f1,f0,f26
	ctx.f1.f64 = double(float(f0.f64 * f26.f64));
loc_820A9E28:
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// bl 0x8210b968
	sub_8210B968(ctx, base);
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// addi r5,r27,192
	ctx.r5.s64 = r27.s64 + 192;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// addi r3,r1,416
	ctx.r3.s64 = ctx.r1.s64 + 416;
	// bl 0x8210b350
	sub_8210B350(ctx, base);
loc_820A9E4C:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820a9ee4
	if (cr6.getEQ()) goto loc_820A9EE4;
	// rotlwi r11,r10,0
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lwz r10,36(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// lwz r30,4(r11)
	r30.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// bne cr6,0x820a9ec8
	if (!cr6.getEQ()) goto loc_820A9EC8;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x820a9e8c
	if (!cr6.getLT()) goto loc_820A9E8C;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f0,112(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// b 0x820a9e9c
	goto loc_820A9E9C;
loc_820A9E8C:
	// subfic r11,r11,6
	xer.ca = r11.u32 <= 6;
	r11.s64 = 6 - r11.s64;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f0,112(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
loc_820A9E9C:
	// fcfid f0,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(f0.s64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// frsp f13,f0
	ctx.f13.f64 = double(float(f0.f64));
	// lfs f0,14312(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14312);
	f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// b 0x820a9ed4
	goto loc_820A9ED4;
loc_820A9EC8:
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8210c818
	sub_8210C818(ctx, base);
loc_820A9ED4:
	// addi r5,r27,256
	ctx.r5.s64 = r27.s64 + 256;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// addi r3,r1,416
	ctx.r3.s64 = ctx.r1.s64 + 416;
	// bl 0x8210b350
	sub_8210B350(ctx, base);
loc_820A9EE4:
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x820a9ef4
	if (cr6.getEQ()) goto loc_820A9EF4;
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r16)
	PPC_STORE_U32(r16.u32 + 0, r11.u32);
loc_820A9EF4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// cmplwi cr6,r17,0
	cr6.compare<uint32_t>(r17.u32, 0, xer);
	// lfs f29,6588(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6588);
	f29.f64 = double(temp.f32);
	// beq cr6,0x820aa338
	if (cr6.getEQ()) goto loc_820AA338;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f31,0(r20)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r20.u32 + 0);
	f31.f64 = double(temp.f32);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f0,12900(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12900);
	f0.f64 = double(temp.f32);
	// lwzx r10,r25,r19
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + r19.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f13,112(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f13,f25
	ctx.f13.f64 = double(float(ctx.f13.f64 * f25.f64));
	// fmadds f30,f13,f0,f24
	f30.f64 = double(float(ctx.f13.f64 * f0.f64 + f24.f64));
	// bne cr6,0x820a9f58
	if (!cr6.getEQ()) goto loc_820A9F58;
	// addi r11,r23,12
	r11.s64 = r23.s64 + 12;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820a9f5c
	goto loc_820A9F5C;
loc_820A9F58:
	// mr r11,r18
	r11.u64 = r18.u64;
loc_820A9F5C:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// clrlwi r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820a9fb8
	if (cr6.getEQ()) goto loc_820A9FB8;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// addi r29,r1,160
	r29.s64 = ctx.r1.s64 + 160;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f0,112(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f25
	f0.f64 = double(float(f0.f64 * f25.f64));
	// fmuls f1,f0,f29
	ctx.f1.f64 = double(float(f0.f64 * f29.f64));
	// bl 0x8210b968
	sub_8210B968(ctx, base);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// b 0x820a9fc4
	goto loc_820A9FC4;
loc_820A9FB8:
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// mr r3,r17
	ctx.r3.u64 = r17.u64;
	// bl 0x8210c818
	sub_8210C818(ctx, base);
loc_820A9FC4:
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x8210bc68
	sub_8210BC68(ctx, base);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// addi r3,r1,416
	ctx.r3.s64 = ctx.r1.s64 + 416;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// addi r4,r27,64
	ctx.r4.s64 = r27.s64 + 64;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// lfs f0,208(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	f0.f64 = double(temp.f32);
	// stfs f0,744(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 744, temp.u32);
	// addi r30,r31,744
	r30.s64 = r31.s64 + 744;
	// lfs f0,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	f0.f64 = double(temp.f32);
	// stfs f0,748(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 748, temp.u32);
	// lfs f0,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	f0.f64 = double(temp.f32);
	// stfs f0,752(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 752, temp.u32);
	// bl 0x8210d870
	sub_8210D870(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x8210b6e0
	sub_8210B6E0(ctx, base);
	// lfs f0,216(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	f0.f64 = double(temp.f32);
	// lbz r11,13(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 13);
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// stfs f0,756(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 756, temp.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820aa35c
	if (cr6.getEQ()) goto loc_820AA35C;
	// cmplwi cr6,r16,0
	cr6.compare<uint32_t>(r16.u32, 0, xer);
	// beq cr6,0x820aa040
	if (cr6.getEQ()) goto loc_820AA040;
	// stw r24,0(r16)
	PPC_STORE_U32(r16.u32 + 0, r24.u32);
loc_820AA040:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820aa1b0
	if (cr6.getEQ()) goto loc_820AA1B0;
	// rotlwi r11,r10,0
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lfs f7,192(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// lfs f0,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	f0.f64 = double(temp.f32);
	// lfs f13,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f11.f64 = double(temp.f32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lfs f10,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f7,f8
	ctx.f8.f64 = double(float(ctx.f7.f64 * ctx.f8.f64));
	// lfs f7,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f0,f0,f7,f8
	f0.f64 = double(float(f0.f64 * ctx.f7.f64 + ctx.f8.f64));
	// fmadds f0,f13,f6,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f6.f64 + f0.f64));
	// lfs f13,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f8,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f0,f12,f13,f0
	f0.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + f0.f64));
	// lfs f13,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f11,f8,f0
	f0.f64 = double(float(ctx.f11.f64 * ctx.f8.f64 + f0.f64));
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,132(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f13,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f0,f10,f13,f0
	f0.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + f0.f64));
	// lfs f13,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f9,f12,f0
	f0.f64 = double(float(ctx.f9.f64 * ctx.f12.f64 + f0.f64));
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,136(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f0,136(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	f0.f64 = double(temp.f32);
	// addi r3,r1,288
	ctx.r3.s64 = ctx.r1.s64 + 288;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// fneg f4,f0
	ctx.f4.u64 = f0.u64 ^ 0x8000000000000000;
	// lfs f0,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	f0.f64 = double(temp.f32);
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// fneg f3,f0
	ctx.f3.u64 = f0.u64 ^ 0x8000000000000000;
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	f0.f64 = double(temp.f32);
	// fneg f2,f0
	ctx.f2.u64 = f0.u64 ^ 0x8000000000000000;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f0,112(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f25
	f0.f64 = double(float(f0.f64 * f25.f64));
	// fmuls f1,f0,f29
	ctx.f1.f64 = double(float(f0.f64 * f29.f64));
	// bl 0x8210c340
	sub_8210C340(ctx, base);
	// addi r4,r1,288
	ctx.r4.s64 = ctx.r1.s64 + 288;
	// fmuls f1,f30,f27
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(f30.f64 * f27.f64));
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// lfs f0,464(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 464);
	f0.f64 = double(temp.f32);
	// lfs f11,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f11.f64 = double(temp.f32);
	// addi r3,r1,480
	ctx.r3.s64 = ctx.r1.s64 + 480;
	// fsubs f4,f11,f0
	ctx.f4.f64 = double(float(ctx.f11.f64 - f0.f64));
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	f0.f64 = double(temp.f32);
	// lfs f13,460(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 460);
	ctx.f13.f64 = double(temp.f32);
	// fmr f1,f28
	ctx.f1.f64 = f28.f64;
	// fsubs f3,f0,f13
	ctx.f3.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,456(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 456);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	f0.f64 = double(temp.f32);
	// fsubs f2,f0,f12
	ctx.f2.f64 = double(float(f0.f64 - ctx.f12.f64));
	// bl 0x8210c070
	sub_8210C070(ctx, base);
	// addi r4,r1,288
	ctx.r4.s64 = ctx.r1.s64 + 288;
	// addi r3,r1,480
	ctx.r3.s64 = ctx.r1.s64 + 480;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// addi r4,r1,288
	ctx.r4.s64 = ctx.r1.s64 + 288;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x8210bdd0
	sub_8210BDD0(ctx, base);
	// addi r4,r1,288
	ctx.r4.s64 = ctx.r1.s64 + 288;
	// addi r3,r1,352
	ctx.r3.s64 = ctx.r1.s64 + 352;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// addi r4,r1,288
	ctx.r4.s64 = ctx.r1.s64 + 288;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// addi r4,r27,128
	ctx.r4.s64 = r27.s64 + 128;
	// addi r3,r1,288
	ctx.r3.s64 = ctx.r1.s64 + 288;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
loc_820AA1B0:
	// lis r11,-32019
	r11.s64 = -2098397184;
	// lwz r10,4(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// addi r11,r11,25932
	r11.s64 = r11.s64 + 25932;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x820aa35c
	if (!cr6.getEQ()) goto loc_820AA35C;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r10,16(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820aa35c
	if (cr6.getEQ()) goto loc_820AA35C;
	// rotlwi r11,r10,0
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lfs f7,192(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 192);
	ctx.f7.f64 = double(temp.f32);
	// lfs f0,160(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	f0.f64 = double(temp.f32);
	// lfs f13,176(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 176);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,164(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 164);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,180(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 180);
	ctx.f11.f64 = double(temp.f32);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lfs f10,168(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 168);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,184(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 184);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f8,f8,f7
	ctx.f8.f64 = double(float(ctx.f8.f64 * ctx.f7.f64));
	// lfs f7,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f0,f0,f7,f8
	f0.f64 = double(float(f0.f64 * ctx.f7.f64 + ctx.f8.f64));
	// fmadds f0,f6,f13,f0
	f0.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + f0.f64));
	// lfs f13,208(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 208);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,128(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f13,196(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 196);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f8,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f0,f12,f13,f0
	f0.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + f0.f64));
	// lfs f13,212(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 212);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f8,f11,f0
	f0.f64 = double(float(ctx.f8.f64 * ctx.f11.f64 + f0.f64));
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,132(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f13,200(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 200);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f0,f10,f13,f0
	f0.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + f0.f64));
	// lfs f13,216(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 216);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f12,f9,f0
	f0.f64 = double(float(ctx.f12.f64 * ctx.f9.f64 + f0.f64));
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,136(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lfs f0,136(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	f0.f64 = double(temp.f32);
	// addi r3,r1,288
	ctx.r3.s64 = ctx.r1.s64 + 288;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// fneg f4,f0
	ctx.f4.u64 = f0.u64 ^ 0x8000000000000000;
	// lfs f0,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	f0.f64 = double(temp.f32);
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// fneg f3,f0
	ctx.f3.u64 = f0.u64 ^ 0x8000000000000000;
	// lfs f0,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	f0.f64 = double(temp.f32);
	// fneg f2,f0
	ctx.f2.u64 = f0.u64 ^ 0x8000000000000000;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f0,112(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f25
	f0.f64 = double(float(f0.f64 * f25.f64));
	// fmuls f1,f0,f29
	ctx.f1.f64 = double(float(f0.f64 * f29.f64));
	// bl 0x8210c340
	sub_8210C340(ctx, base);
	// addi r4,r1,288
	ctx.r4.s64 = ctx.r1.s64 + 288;
	// fmuls f1,f30,f27
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(f30.f64 * f27.f64));
	// bl 0x8210bcc8
	sub_8210BCC8(ctx, base);
	// lfs f0,464(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 464);
	f0.f64 = double(temp.f32);
	// lfs f11,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f11.f64 = double(temp.f32);
	// addi r3,r1,480
	ctx.r3.s64 = ctx.r1.s64 + 480;
	// fsubs f4,f11,f0
	ctx.f4.f64 = double(float(ctx.f11.f64 - f0.f64));
	// lfs f0,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	f0.f64 = double(temp.f32);
	// lfs f13,460(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 460);
	ctx.f13.f64 = double(temp.f32);
	// fmr f1,f28
	ctx.f1.f64 = f28.f64;
	// fsubs f3,f0,f13
	ctx.f3.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,456(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 456);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	f0.f64 = double(temp.f32);
	// fsubs f2,f0,f12
	ctx.f2.f64 = double(float(f0.f64 - ctx.f12.f64));
	// bl 0x8210c070
	sub_8210C070(ctx, base);
	// addi r4,r1,288
	ctx.r4.s64 = ctx.r1.s64 + 288;
	// addi r3,r1,480
	ctx.r3.s64 = ctx.r1.s64 + 480;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// addi r4,r1,288
	ctx.r4.s64 = ctx.r1.s64 + 288;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x8210bdd0
	sub_8210BDD0(ctx, base);
	// addi r4,r1,288
	ctx.r4.s64 = ctx.r1.s64 + 288;
	// addi r3,r1,352
	ctx.r3.s64 = ctx.r1.s64 + 352;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// addi r4,r1,288
	ctx.r4.s64 = ctx.r1.s64 + 288;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// addi r4,r27,192
	ctx.r4.s64 = r27.s64 + 192;
	// addi r3,r1,288
	ctx.r3.s64 = ctx.r1.s64 + 288;
	// bl 0x8210b308
	sub_8210B308(ctx, base);
	// b 0x820aa35c
	goto loc_820AA35C;
loc_820AA338:
	// lfs f0,608(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 608);
	f0.f64 = double(temp.f32);
	// lfs f13,664(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 664);
	ctx.f13.f64 = double(temp.f32);
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// lfs f12,668(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 668);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,672(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 672);
	ctx.f11.f64 = double(temp.f32);
	// stfs f13,744(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 744, temp.u32);
	// stfs f12,748(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r31.u32 + 748, temp.u32);
	// stfs f11,752(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r31.u32 + 752, temp.u32);
	// stfs f0,756(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 756, temp.u32);
loc_820AA35C:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820aa45c
	if (cr6.getEQ()) goto loc_820AA45C;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lwz r30,4(r3)
	r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// bl 0x82118ac8
	sub_82118AC8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lwz r4,16(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x820a1300
	sub_820A1300(ctx, base);
	// lhz r11,12(r28)
	r11.u64 = PPC_LOAD_U16(r28.u32 + 12);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// ble cr6,0x820aa438
	if (!cr6.getGT()) goto loc_820AA438;
	// lwz r10,8(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r11,112(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 112);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820aa438
	if (cr6.getEQ()) goto loc_820AA438;
	// lwz r11,-1364(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + -1364);
	// lwz r9,112(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 112);
	// add r11,r22,r11
	r11.u64 = r22.u64 + r11.u64;
	// lwz r10,2344(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// lwz r11,4(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// cmpwi cr6,r10,30
	cr6.compare<int32_t>(ctx.r10.s32, 30, xer);
	// beq cr6,0x820aa3dc
	if (cr6.getEQ()) goto loc_820AA3DC;
	// cmpwi cr6,r10,23
	cr6.compare<int32_t>(ctx.r10.s32, 23, xer);
	// beq cr6,0x820aa3dc
	if (cr6.getEQ()) goto loc_820AA3DC;
	// fmr f0,f26
	ctx.fpscr.disableFlushMode();
	f0.f64 = f26.f64;
	// b 0x820aa3e4
	goto loc_820AA3E4;
loc_820AA3DC:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,13972(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13972);
	f0.f64 = double(temp.f32);
loc_820AA3E4:
	// lfs f13,532(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 532);
	ctx.f13.f64 = double(temp.f32);
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// fadds f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 + f29.f64));
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f4,f12,f11
	ctx.f4.f64 = double(float(ctx.f12.f64 - ctx.f11.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f3,f10,f12
	ctx.f3.f64 = double(float(ctx.f10.f64 - ctx.f12.f64));
	// lfs f11,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,12(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f2,f11,f12
	ctx.f2.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// fsubs f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 - f0.f64));
	// lfs f0,14308(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14308);
	f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x820d3760
	sub_820D3760(ctx, base);
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// b 0x820aa448
	goto loc_820AA448;
loc_820AA438:
	// addi r5,r1,224
	ctx.r5.s64 = ctx.r1.s64 + 224;
	// lfs f1,532(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 532);
	ctx.f1.f64 = double(temp.f32);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8210b770
	sub_8210B770(ctx, base);
loc_820AA448:
	// rlwinm r11,r29,6,0,25
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 6) & 0xFFFFFFC0;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// add r5,r11,r27
	ctx.r5.u64 = r11.u64 + r27.u64;
	// addi r3,r1,416
	ctx.r3.s64 = ctx.r1.s64 + 416;
	// bl 0x8210b450
	sub_8210B450(ctx, base);
loc_820AA45C:
	// lhz r11,12(r28)
	r11.u64 = PPC_LOAD_U16(r28.u32 + 12);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// ble cr6,0x820aa47c
	if (!cr6.getGT()) goto loc_820AA47C;
	// li r5,29
	ctx.r5.s64 = 29;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x820b3168
	sub_820B3168(ctx, base);
loc_820AA47C:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820aa4dc
	if (cr6.getEQ()) goto loc_820AA4DC;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// lwz r30,4(r3)
	r30.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// bl 0x82118ac8
	sub_82118AC8(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x820a1418
	sub_820A1418(ctx, base);
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8210c818
	sub_8210C818(ctx, base);
	// rlwinm r11,r29,6,0,25
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 6) & 0xFFFFFFC0;
	// lfs f0,536(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 536);
	f0.f64 = double(temp.f32);
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// lfs f13,280(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 280);
	ctx.f13.f64 = double(temp.f32);
	// add r5,r11,r27
	ctx.r5.u64 = r11.u64 + r27.u64;
	// addi r3,r1,416
	ctx.r3.s64 = ctx.r1.s64 + 416;
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// stfs f0,280(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// bl 0x8210b350
	sub_8210B350(ctx, base);
loc_820AA4DC:
	// lhz r11,12(r28)
	r11.u64 = PPC_LOAD_U16(r28.u32 + 12);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// cmpwi cr6,r11,18
	cr6.compare<int32_t>(r11.s32, 18, xer);
	// ble cr6,0x820aa580
	if (!cr6.getGT()) goto loc_820AA580;
	// li r29,5
	r29.s64 = 5;
	// li r30,92
	r30.s64 = 92;
loc_820AA4F4:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// lwz r10,-20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820aa534
	if (cr6.getEQ()) goto loc_820AA534;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820aa534
	if (cr6.getEQ()) goto loc_820AA534;
	// lwz r11,52(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// cmpw cr6,r11,r29
	cr6.compare<int32_t>(r11.s32, r29.s32, xer);
	// mr r11,r24
	r11.u64 = r24.u64;
	// bge cr6,0x820aa530
	if (!cr6.getLT()) goto loc_820AA530;
	// li r11,0
	r11.s64 = 0;
loc_820AA530:
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
loc_820AA534:
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// lwzx r10,r30,r11
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r11.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820aa570
	if (cr6.getEQ()) goto loc_820AA570;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// rotlwi r4,r10,0
	ctx.r4.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// bl 0x82118d48
	sub_82118D48(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820aa570
	if (cr6.getEQ()) goto loc_820AA570;
	// lwz r11,52(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// cmpw cr6,r11,r29
	cr6.compare<int32_t>(r11.s32, r29.s32, xer);
	// mr r11,r24
	r11.u64 = r24.u64;
	// bge cr6,0x820aa56c
	if (!cr6.getLT()) goto loc_820AA56C;
	// li r11,0
	r11.s64 = 0;
loc_820AA56C:
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
loc_820AA570:
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// addi r29,r29,-1
	r29.s64 = r29.s64 + -1;
	// cmpwi cr6,r30,112
	cr6.compare<int32_t>(r30.s32, 112, xer);
	// blt cr6,0x820aa4f4
	if (cr6.getLT()) goto loc_820AA4F4;
loc_820AA580:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8211d028
	sub_8211D028(ctx, base);
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820aa634
	if (cr6.getEQ()) goto loc_820AA634;
	// addi r11,r15,-4
	r11.s64 = r15.s64 + -4;
	// cmplwi cr6,r11,19
	cr6.compare<uint32_t>(r11.u32, 19, xer);
	// bgt cr6,0x820aa634
	if (cr6.getGT()) goto loc_820AA634;
	// lis r12,-32245
	r12.s64 = -2113208320;
	// addi r12,r12,-23112
	r12.s64 = r12.s64 + -23112;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820AA608;
	case 1:
		goto loc_820AA608;
	case 2:
		goto loc_820AA608;
	case 3:
		goto loc_820AA608;
	case 4:
		goto loc_820AA608;
	case 5:
		goto loc_820AA608;
	case 6:
		goto loc_820AA608;
	case 7:
		goto loc_820AA608;
	case 8:
		goto loc_820AA608;
	case 9:
		goto loc_820AA608;
	case 10:
		goto loc_820AA608;
	case 11:
		goto loc_820AA634;
	case 12:
		goto loc_820AA634;
	case 13:
		goto loc_820AA608;
	case 14:
		goto loc_820AA608;
	case 15:
		goto loc_820AA608;
	case 16:
		goto loc_820AA608;
	case 17:
		goto loc_820AA608;
	case 18:
		goto loc_820AA620;
	case 19:
		goto loc_820AA620;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-22988(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -22988);
	// lwz r16,-22988(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -22988);
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-23032(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23032);
	// lwz r16,-23008(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23008);
	// lwz r16,-23008(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -23008);
loc_820AA608:
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x820a2658
	sub_820A2658(ctx, base);
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// b 0x820aa634
	goto loc_820AA634;
loc_820AA620:
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
	// bl 0x820a2658
	sub_820A2658(ctx, base);
loc_820AA634:
	// cmpwi cr6,r15,25
	cr6.compare<int32_t>(r15.s32, 25, xer);
	// bne cr6,0x820aa644
	if (!cr6.getEQ()) goto loc_820AA644;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x820a2028
	sub_820A2028(ctx, base);
loc_820AA644:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820aa738
	if (cr6.getEQ()) goto loc_820AA738;
	// lwz r3,-1364(r21)
	ctx.r3.u64 = PPC_LOAD_U32(r21.u32 + -1364);
	// bl 0x820b3c78
	sub_820B3C78(ctx, base);
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x820a4c80
	sub_820A4C80(ctx, base);
	// cmpwi cr6,r15,24
	cr6.compare<int32_t>(r15.s32, 24, xer);
	// beq cr6,0x820aa718
	if (cr6.getEQ()) goto loc_820AA718;
	// cmpwi cr6,r15,26
	cr6.compare<int32_t>(r15.s32, 26, xer);
	// bne cr6,0x820aa688
	if (!cr6.getEQ()) goto loc_820AA688;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x820a7a90
	sub_820A7A90(ctx, base);
	// addi r1,r1,768
	ctx.r1.s64 = ctx.r1.s64 + 768;
	// addi r12,r1,-152
	r12.s64 = ctx.r1.s64 + -152;
	// bl 0x823ed580
	// b 0x823ed150
	return;
loc_820AA688:
	// cmpwi cr6,r15,25
	cr6.compare<int32_t>(r15.s32, 25, xer);
	// bne cr6,0x820aa6a8
	if (!cr6.getEQ()) goto loc_820AA6A8;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x820a8b20
	sub_820A8B20(ctx, base);
	// addi r1,r1,768
	ctx.r1.s64 = ctx.r1.s64 + 768;
	// addi r12,r1,-152
	r12.s64 = ctx.r1.s64 + -152;
	// bl 0x823ed580
	// b 0x823ed150
	return;
loc_820AA6A8:
	// cmpwi cr6,r15,3
	cr6.compare<int32_t>(r15.s32, 3, xer);
	// bne cr6,0x820aa6c8
	if (!cr6.getEQ()) goto loc_820AA6C8;
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x820a7e50
	sub_820A7E50(ctx, base);
	// addi r1,r1,768
	ctx.r1.s64 = ctx.r1.s64 + 768;
	// addi r12,r1,-152
	r12.s64 = ctx.r1.s64 + -152;
	// bl 0x823ed580
	// b 0x823ed150
	return;
loc_820AA6C8:
	// cmpwi cr6,r15,29
	cr6.compare<int32_t>(r15.s32, 29, xer);
	// beq cr6,0x820aa730
	if (cr6.getEQ()) goto loc_820AA730;
	// cmpwi cr6,r15,28
	cr6.compare<int32_t>(r15.s32, 28, xer);
	// beq cr6,0x820aa730
	if (cr6.getEQ()) goto loc_820AA730;
	// cmpwi cr6,r15,27
	cr6.compare<int32_t>(r15.s32, 27, xer);
	// beq cr6,0x820aa730
	if (cr6.getEQ()) goto loc_820AA730;
	// cmpwi cr6,r15,33
	cr6.compare<int32_t>(r15.s32, 33, xer);
	// beq cr6,0x820aa730
	if (cr6.getEQ()) goto loc_820AA730;
	// cmpwi cr6,r15,47
	cr6.compare<int32_t>(r15.s32, 47, xer);
	// beq cr6,0x820aa730
	if (cr6.getEQ()) goto loc_820AA730;
	// cmpwi cr6,r15,48
	cr6.compare<int32_t>(r15.s32, 48, xer);
	// beq cr6,0x820aa730
	if (cr6.getEQ()) goto loc_820AA730;
	// cmpwi cr6,r15,61
	cr6.compare<int32_t>(r15.s32, 61, xer);
	// beq cr6,0x820aa730
	if (cr6.getEQ()) goto loc_820AA730;
	// cmpwi cr6,r15,34
	cr6.compare<int32_t>(r15.s32, 34, xer);
	// beq cr6,0x820aa730
	if (cr6.getEQ()) goto loc_820AA730;
	// cmpwi cr6,r15,35
	cr6.compare<int32_t>(r15.s32, 35, xer);
	// beq cr6,0x820aa718
	if (cr6.getEQ()) goto loc_820AA718;
	// cmpwi cr6,r15,36
	cr6.compare<int32_t>(r15.s32, 36, xer);
	// bne cr6,0x820aa738
	if (!cr6.getEQ()) goto loc_820AA738;
loc_820AA718:
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x820a8818
	sub_820A8818(ctx, base);
	// addi r1,r1,768
	ctx.r1.s64 = ctx.r1.s64 + 768;
	// addi r12,r1,-152
	r12.s64 = ctx.r1.s64 + -152;
	// bl 0x823ed580
	// b 0x823ed150
	return;
loc_820AA730:
	// mr r3,r14
	ctx.r3.u64 = r14.u64;
	// bl 0x820a8248
	sub_820A8248(ctx, base);
loc_820AA738:
	// addi r1,r1,768
	ctx.r1.s64 = ctx.r1.s64 + 768;
	// addi r12,r1,-152
	r12.s64 = ctx.r1.s64 + -152;
	// bl 0x823ed580
	// b 0x823ed150
	return;
}

__attribute__((alias("__imp__sub_820AA748"))) PPC_WEAK_FUNC(sub_820AA748);
PPC_FUNC_IMPL(__imp__sub_820AA748) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820a9090
	sub_820A9090(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x820a9090
	sub_820A9090(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AA778"))) PPC_WEAK_FUNC(sub_820AA778);
PPC_FUNC_IMPL(__imp__sub_820AA778) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820c1540
	sub_820C1540(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// lis r3,0
	ctx.r3.s64 = 0;
	// beq cr6,0x820aa818
	if (cr6.getEQ()) goto loc_820AA818;
	// ori r3,r3,39128
	ctx.r3.u64 = ctx.r3.u64 | 39128;
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// bl 0x820b4260
	sub_820B4260(ctx, base);
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r10,1
	ctx.r10.s64 = 1;
	// addi r7,r11,13992
	ctx.r7.s64 = r11.s64 + 13992;
	// li r8,6173
	ctx.r8.s64 = 6173;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,245
	ctx.r4.s64 = 245;
	// stw r10,4376(r11)
	PPC_STORE_U32(r11.u32 + 4376, ctx.r10.u32);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r9,5
	ctx.r9.s64 = 5;
	// li r8,61
	ctx.r8.s64 = 61;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r9,2384(r11)
	PPC_STORE_U32(r11.u32 + 2384, ctx.r9.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r8,2404(r11)
	PPC_STORE_U32(r11.u32 + 2404, ctx.r8.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r10,2412(r11)
	PPC_STORE_U32(r11.u32 + 2412, ctx.r10.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r9,3320(r11)
	PPC_STORE_U32(r11.u32 + 3320, ctx.r9.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r10,3340(r11)
	PPC_STORE_U32(r11.u32 + 3340, ctx.r10.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// b 0x820aa864
	goto loc_820AA864;
loc_820AA818:
	// ori r3,r3,39129
	ctx.r3.u64 = ctx.r3.u64 | 39129;
	// bl 0x82136ad8
	sub_82136AD8(ctx, base);
	// bl 0x820b4260
	sub_820B4260(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// li r9,5
	ctx.r9.s64 = 5;
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r8,-1364(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r7,2352(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 2352);
	// stw r9,2384(r8)
	PPC_STORE_U32(ctx.r8.u32 + 2384, ctx.r9.u32);
	// lwz r8,-1364(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r7,2404(r8)
	PPC_STORE_U32(ctx.r8.u32 + 2404, ctx.r7.u32);
	// lwz r8,-1364(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r10,2412(r8)
	PPC_STORE_U32(ctx.r8.u32 + 2412, ctx.r10.u32);
	// lwz r8,-1364(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r7,3288(r8)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r8.u32 + 3288);
	// stw r9,3320(r8)
	PPC_STORE_U32(ctx.r8.u32 + 3320, ctx.r9.u32);
	// lwz r9,-1364(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r7,3340(r9)
	PPC_STORE_U32(ctx.r9.u32 + 3340, ctx.r7.u32);
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
loc_820AA864:
	// stw r10,3348(r11)
	PPC_STORE_U32(r11.u32 + 3348, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AA880"))) PPC_WEAK_FUNC(sub_820AA880);
PPC_FUNC_IMPL(__imp__sub_820AA880) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mulli r10,r3,936
	ctx.r10.s64 = ctx.r3.s64 * 936;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// lwz r10,2344(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2344);
	// addi r8,r11,8
	ctx.r8.s64 = r11.s64 + 8;
	// mulli r10,r10,56
	ctx.r10.s64 = ctx.r10.s64 * 56;
	// lwzx r8,r10,r8
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820aa8bc
	if (!cr6.getEQ()) goto loc_820AA8BC;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x820aa8c4
	goto loc_820AA8C4;
loc_820AA8BC:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
loc_820AA8C4:
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820aa8e0
	if (cr6.getEQ()) goto loc_820AA8E0;
	// lwz r11,2388(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2388);
	// li r3,0
	ctx.r3.s64 = 0;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blelr cr6
	if (!cr6.getGT()) return;
loc_820AA8E0:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AA8E8"))) PPC_WEAK_FUNC(sub_820AA8E8);
PPC_FUNC_IMPL(__imp__sub_820AA8E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r31{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// lis r5,-32014
	ctx.r5.s64 = -2098069504;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// addi r7,r10,6504
	ctx.r7.s64 = ctx.r10.s64 + 6504;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// lwz r9,-1364(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + -1364);
	// addi r6,r7,8
	ctx.r6.s64 = ctx.r7.s64 + 8;
	// addi r31,r10,1240
	r31.s64 = ctx.r10.s64 + 1240;
	// lwz r11,2344(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2344);
	// mulli r11,r11,56
	r11.s64 = r11.s64 * 56;
	// lwzx r8,r11,r6
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820aa928
	if (!cr6.getEQ()) goto loc_820AA928;
	// addi r10,r7,12
	ctx.r10.s64 = ctx.r7.s64 + 12;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820aa92c
	goto loc_820AA92C;
loc_820AA928:
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
loc_820AA92C:
	// lwz r10,28(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	// cmpw cr6,r10,r3
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r3.s32, xer);
	// bne cr6,0x820aa9e0
	if (!cr6.getEQ()) goto loc_820AA9E0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// bne cr6,0x820aa94c
	if (!cr6.getEQ()) goto loc_820AA94C;
	// addi r10,r7,12
	ctx.r10.s64 = ctx.r7.s64 + 12;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820aa950
	goto loc_820AA950;
loc_820AA94C:
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
loc_820AA950:
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm r10,r10,0,10,10
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x200000;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820aa9e0
	if (cr6.getEQ()) goto loc_820AA9E0;
	// lwz r10,2388(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2388);
	// add r10,r10,r4
	ctx.r10.u64 = ctx.r10.u64 + ctx.r4.u64;
	// stw r10,2388(r9)
	PPC_STORE_U32(ctx.r9.u32 + 2388, ctx.r10.u32);
	// lwzx r9,r11,r6
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r6.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820aa984
	if (!cr6.getEQ()) goto loc_820AA984;
	// addi r10,r7,12
	ctx.r10.s64 = ctx.r7.s64 + 12;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820aa988
	goto loc_820AA988;
loc_820AA984:
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
loc_820AA988:
	// lhz r8,32(r10)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r10.u32 + 32);
	// lwz r10,-1364(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + -1364);
	// extsh r8,r8
	ctx.r8.s64 = ctx.r8.s16;
	// lwz r6,2388(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2388);
	// cmpw cr6,r6,r8
	cr6.compare<int32_t>(ctx.r6.s32, ctx.r8.s32, xer);
	// ble cr6,0x820aa9c8
	if (!cr6.getGT()) goto loc_820AA9C8;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820aa9b4
	if (!cr6.getEQ()) goto loc_820AA9B4;
	// addi r9,r7,12
	ctx.r9.s64 = ctx.r7.s64 + 12;
	// lwzx r11,r11,r9
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// b 0x820aa9b8
	goto loc_820AA9B8;
loc_820AA9B4:
	// mr r11,r31
	r11.u64 = r31.u64;
loc_820AA9B8:
	// lhz r11,32(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 32);
	// extsh r11,r11
	r11.s64 = r11.s16;
	// stw r11,2388(r10)
	PPC_STORE_U32(ctx.r10.u32 + 2388, r11.u32);
	// lwz r10,-1364(r5)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r5.u32 + -1364);
loc_820AA9C8:
	// addi r11,r3,1145
	r11.s64 = ctx.r3.s64 + 1145;
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r9,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, ctx.r9.u32);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
loc_820AA9E0:
	// rlwinm r10,r3,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// add r10,r3,r10
	ctx.r10.u64 = ctx.r3.u64 + ctx.r10.u64;
	// addi r11,r11,15496
	r11.s64 = r11.s64 + 15496;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// cmpw cr6,r4,r11
	cr6.compare<int32_t>(ctx.r4.s32, r11.s32, xer);
	// ble cr6,0x820aaa14
	if (!cr6.getGT()) goto loc_820AAA14;
	// addi r10,r3,1145
	ctx.r10.s64 = ctx.r3.s64 + 1145;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r11,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, r11.u32);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
loc_820AAA14:
	// addi r11,r3,1145
	r11.s64 = ctx.r3.s64 + 1145;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// stwx r4,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r4.u32);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AAA28"))) PPC_WEAK_FUNC(sub_820AAA28);
PPC_FUNC_IMPL(__imp__sub_820AAA28) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// addi r8,r7,1145
	ctx.r8.s64 = ctx.r7.s64 + 1145;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// rlwinm r8,r8,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r6,r10,8
	ctx.r6.s64 = ctx.r10.s64 + 8;
	// lwz r9,2344(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// lwzx r3,r8,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r8.u32 + r11.u32);
	// mulli r9,r9,56
	ctx.r9.s64 = ctx.r9.s64 * 56;
	// lwzx r8,r9,r6
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// lis r8,-32190
	ctx.r8.s64 = -2109603840;
	// addi r8,r8,1240
	ctx.r8.s64 = ctx.r8.s64 + 1240;
	// bne cr6,0x820aaa74
	if (!cr6.getEQ()) goto loc_820AAA74;
	// addi r6,r10,12
	ctx.r6.s64 = ctx.r10.s64 + 12;
	// lwzx r9,r9,r6
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// b 0x820aaa78
	goto loc_820AAA78;
loc_820AAA74:
	// mr r9,r8
	ctx.r9.u64 = ctx.r8.u64;
loc_820AAA78:
	// lwz r9,28(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28);
	// cmpw cr6,r9,r7
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r7.s32, xer);
	// bne cr6,0x820aaa8c
	if (!cr6.getEQ()) goto loc_820AAA8C;
	// lwz r9,2388(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2388);
	// add r3,r9,r3
	ctx.r3.u64 = ctx.r9.u64 + ctx.r3.u64;
loc_820AAA8C:
	// lwz r9,3280(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 3280);
	// addi r6,r10,8
	ctx.r6.s64 = ctx.r10.s64 + 8;
	// mulli r9,r9,56
	ctx.r9.s64 = ctx.r9.s64 * 56;
	// lwzx r6,r9,r6
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// bne cr6,0x820aaab0
	if (!cr6.getEQ()) goto loc_820AAAB0;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// b 0x820aaab4
	goto loc_820AAAB4;
loc_820AAAB0:
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
loc_820AAAB4:
	// lwz r10,28(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 28);
	// cmpw cr6,r10,r7
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r7.s32, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
	// lwz r11,3324(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 3324);
	// add r3,r11,r3
	ctx.r3.u64 = r11.u64 + ctx.r3.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AAAD0"))) PPC_WEAK_FUNC(sub_820AAAD0);
PPC_FUNC_IMPL(__imp__sub_820AAAD0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r30,r11,15496
	r30.s64 = r11.s64 + 15496;
	// mr r31,r30
	r31.u64 = r30.u64;
loc_820AAAF4:
	// lwz r4,0(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x820aa8e8
	sub_820AA8E8(ctx, base);
	// addi r31,r31,12
	r31.s64 = r31.s64 + 12;
	// addi r11,r30,360
	r11.s64 = r30.s64 + 360;
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmpw cr6,r31,r11
	cr6.compare<int32_t>(r31.s32, r11.s32, xer);
	// blt cr6,0x820aaaf4
	if (cr6.getLT()) goto loc_820AAAF4;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AAB28"))) PPC_WEAK_FUNC(sub_820AAB28);
PPC_FUNC_IMPL(__imp__sub_820AAB28) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// mulli r7,r3,936
	ctx.r7.s64 = ctx.r3.s64 * 936;
	// lwz r10,-1364(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// add r9,r7,r10
	ctx.r9.u64 = ctx.r7.u64 + ctx.r10.u64;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// lwz r8,2344(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2344);
	// addi r6,r11,8
	ctx.r6.s64 = r11.s64 + 8;
	// mulli r9,r8,56
	ctx.r9.s64 = ctx.r8.s64 * 56;
	// lwzx r6,r9,r6
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r6.u32);
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// bne cr6,0x820aab64
	if (!cr6.getEQ()) goto loc_820AAB64;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// b 0x820aab6c
	goto loc_820AAB6C;
loc_820AAB64:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
loc_820AAB6C:
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpwi cr6,r8,15
	cr6.compare<int32_t>(ctx.r8.s32, 15, xer);
	// addi r11,r11,1145
	r11.s64 = r11.s64 + 1145;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r10
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// beq cr6,0x820aab8c
	if (cr6.getEQ()) goto loc_820AAB8C;
	// cmpwi cr6,r8,16
	cr6.compare<int32_t>(ctx.r8.s32, 16, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
loc_820AAB8C:
	// subf r11,r7,r10
	r11.s64 = ctx.r10.s64 - ctx.r7.s64;
	// lwz r10,3280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 3280);
	// cmpwi cr6,r10,15
	cr6.compare<int32_t>(ctx.r10.s32, 15, xer);
	// beq cr6,0x820aaba4
	if (cr6.getEQ()) goto loc_820AABA4;
	// cmpwi cr6,r10,16
	cr6.compare<int32_t>(ctx.r10.s32, 16, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
loc_820AABA4:
	// lwz r11,3332(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 3332);
	// subf r3,r11,r3
	ctx.r3.s64 = ctx.r3.s64 - r11.s64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AABB0"))) PPC_WEAK_FUNC(sub_820AABB0);
PPC_FUNC_IMPL(__imp__sub_820AABB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// mulli r11,r3,56
	r11.s64 = ctx.r3.s64 * 56;
	// addi r10,r10,6504
	ctx.r10.s64 = ctx.r10.s64 + 6504;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwzx r9,r11,r9
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820aabd8
	if (!cr6.getEQ()) goto loc_820AABD8;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820aabe0
	goto loc_820AABE0;
loc_820AABD8:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,1240
	r11.s64 = r11.s64 + 1240;
loc_820AABE0:
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// b 0x820aa8e8
	sub_820AA8E8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820AABE8"))) PPC_WEAK_FUNC(sub_820AABE8);
PPC_FUNC_IMPL(__imp__sub_820AABE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r4,-32014
	ctx.r4.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mulli r10,r31,936
	ctx.r10.s64 = r31.s64 * 936;
	// lwz r11,-1364(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + -1364);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// addi r5,r11,2344
	ctx.r5.s64 = r11.s64 + 2344;
	// lwz r28,0(r5)
	r28.u64 = PPC_LOAD_U32(ctx.r5.u32 + 0);
	// lwz r30,44(r5)
	r30.u64 = PPC_LOAD_U32(ctx.r5.u32 + 44);
	// bl 0x820aab28
	sub_820AAB28(ctx, base);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r10,r28,56
	ctx.r10.s64 = r28.s64 * 56;
	// addi r9,r11,6504
	ctx.r9.s64 = r11.s64 + 6504;
	// addi r8,r9,8
	ctx.r8.s64 = ctx.r9.s64 + 8;
	// lwzx r11,r10,r8
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r29,r11,1240
	r29.s64 = r11.s64 + 1240;
	// bne cr6,0x820aac48
	if (!cr6.getEQ()) goto loc_820AAC48;
	// addi r11,r9,12
	r11.s64 = ctx.r9.s64 + 12;
	// lwzx r6,r10,r11
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x820aac4c
	goto loc_820AAC4C;
loc_820AAC48:
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
loc_820AAC4C:
	// lhz r7,32(r6)
	ctx.r7.u64 = PPC_LOAD_U16(ctx.r6.u32 + 32);
	// add r11,r3,r30
	r11.u64 = ctx.r3.u64 + r30.u64;
	// extsh r7,r7
	ctx.r7.s64 = ctx.r7.s16;
	// cmpw cr6,r7,r11
	cr6.compare<int32_t>(ctx.r7.s32, r11.s32, xer);
	// bgt cr6,0x820aac68
	if (cr6.getGT()) goto loc_820AAC68;
	// stw r7,44(r5)
	PPC_STORE_U32(ctx.r5.u32 + 44, ctx.r7.u32);
	// b 0x820aac6c
	goto loc_820AAC6C;
loc_820AAC68:
	// stw r11,44(r5)
	PPC_STORE_U32(ctx.r5.u32 + 44, r11.u32);
loc_820AAC6C:
	// lwzx r11,r10,r8
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820aac84
	if (!cr6.getEQ()) goto loc_820AAC84;
	// addi r11,r9,12
	r11.s64 = ctx.r9.s64 + 12;
	// lwzx r11,r10,r11
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x820aac88
	goto loc_820AAC88;
loc_820AAC84:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_820AAC88:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,10,10
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lwz r11,28(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + 28);
	// addi r11,r11,1145
	r11.s64 = r11.s64 + 1145;
	// beq cr6,0x820aacb4
	if (cr6.getEQ()) goto loc_820AACB4;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,-1364(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + -1364);
	// li r10,0
	ctx.r10.s64 = 0;
	// stwx r10,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r10.u32);
	// b 0x820aacd0
	goto loc_820AACD0;
loc_820AACB4:
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,-1364(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + -1364);
	// lwz r9,44(r5)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r5.u32 + 44);
	// lwzx r8,r10,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// subf r9,r9,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r9.s64;
	// add r9,r9,r30
	ctx.r9.u64 = ctx.r9.u64 + r30.u64;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
loc_820AACD0:
	// cmpwi cr6,r28,25
	cr6.compare<int32_t>(r28.s32, 25, xer);
	// bne cr6,0x820aace8
	if (!cr6.getEQ()) goto loc_820AACE8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820a2138
	sub_820A2138(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_820AACE8:
	// cmpwi cr6,r28,15
	cr6.compare<int32_t>(r28.s32, 15, xer);
	// beq cr6,0x820aacf8
	if (cr6.getEQ()) goto loc_820AACF8;
	// cmpwi cr6,r28,16
	cr6.compare<int32_t>(r28.s32, 16, xer);
	// bne cr6,0x820aad1c
	if (!cr6.getEQ()) goto loc_820AAD1C;
loc_820AACF8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820aab28
	sub_820AAB28(ctx, base);
	// cmpwi cr6,r3,5
	cr6.compare<int32_t>(ctx.r3.s32, 5, xer);
	// blt cr6,0x820aad18
	if (cr6.getLT()) goto loc_820AAD18;
	// li r11,5
	r11.s64 = 5;
	// stw r11,52(r5)
	PPC_STORE_U32(ctx.r5.u32 + 52, r11.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_820AAD18:
	// stw r3,52(r5)
	PPC_STORE_U32(ctx.r5.u32 + 52, ctx.r3.u32);
loc_820AAD1C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820AAD28"))) PPC_WEAK_FUNC(sub_820AAD28);
PPC_FUNC_IMPL(__imp__sub_820AAD28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,10
	ctx.r3.s64 = 10;
	// bl 0x820dbd60
	sub_820DBD60(ctx, base);
	// li r6,1
	ctx.r6.s64 = 1;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,2
	ctx.r4.s64 = 2;
	// li r3,5
	ctx.r3.s64 = 5;
	// bl 0x820dbd60
	sub_820DBD60(ctx, base);
	// li r3,17
	ctx.r3.s64 = 17;
	// bl 0x820c0e00
	sub_820C0E00(ctx, base);
	// li r3,17
	ctx.r3.s64 = 17;
	// bl 0x820dbae8
	sub_820DBAE8(ctx, base);
	// li r3,17
	ctx.r3.s64 = 17;
	// bl 0x820dc500
	sub_820DC500(ctx, base);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// addi r11,r11,3144
	r11.s64 = r11.s64 + 3144;
	// lwz r3,28(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// lhz r11,32(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 32);
	// addi r9,r3,1145
	ctx.r9.s64 = ctx.r3.s64 + 1145;
	// extsh r10,r11
	ctx.r10.s64 = r11.s16;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// rlwinm r9,r9,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// add r4,r11,r10
	ctx.r4.u64 = r11.u64 + ctx.r10.u64;
	// bl 0x820aa8e8
	sub_820AA8E8(ctx, base);
	// li r3,44
	ctx.r3.s64 = 44;
	// bl 0x820c0fb8
	sub_820C0FB8(ctx, base);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r9,5
	ctx.r9.s64 = 5;
	// li r8,17
	ctx.r8.s64 = 17;
	// li r11,0
	r11.s64 = 0;
	// stw r9,2384(r10)
	PPC_STORE_U32(ctx.r10.u32 + 2384, ctx.r9.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r8,2404(r10)
	PPC_STORE_U32(ctx.r10.u32 + 2404, ctx.r8.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,2412(r10)
	PPC_STORE_U32(ctx.r10.u32 + 2412, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r9,3320(r10)
	PPC_STORE_U32(ctx.r10.u32 + 3320, ctx.r9.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,3340(r10)
	PPC_STORE_U32(ctx.r10.u32 + 3340, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,3348(r10)
	PPC_STORE_U32(ctx.r10.u32 + 3348, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AAE00"))) PPC_WEAK_FUNC(sub_820AAE00);
PPC_FUNC_IMPL(__imp__sub_820AAE00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f21{};
	PPCRegister f22{};
	PPCRegister f23{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed100
	// addi r12,r1,-152
	r12.s64 = ctx.r1.s64 + -152;
	// bl 0x823ed52c
	// stwu r1,-432(r1)
	ea = -432 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r18,-32014
	r18.s64 = -2098069504;
	// mr r16,r3
	r16.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mulli r17,r16,936
	r17.s64 = r16.s64 * 936;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// add r11,r17,r11
	r11.u64 = r17.u64 + r11.u64;
	// addi r31,r11,2344
	r31.s64 = r11.s64 + 2344;
	// lwz r10,2348(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2348);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blt cr6,0x820aae48
	if (cr6.getLT()) goto loc_820AAE48;
	// mr r26,r10
	r26.u64 = ctx.r10.u64;
	// stw r26,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r26.u32);
	// b 0x820aae54
	goto loc_820AAE54;
loc_820AAE48:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rotlwi r26,r11,0
	r26.u64 = __builtin_rotateleft32(r11.u32, 0);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
loc_820AAE54:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r25,r26,56
	r25.s64 = r26.s64 * 56;
	// addi r14,r11,6504
	r14.s64 = r11.s64 + 6504;
	// addi r24,r14,8
	r24.s64 = r14.s64 + 8;
	// lwzx r11,r25,r24
	r11.u64 = PPC_LOAD_U32(r25.u32 + r24.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r27,r11,1240
	r27.s64 = r11.s64 + 1240;
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r27.u32);
	// bne cr6,0x820aae88
	if (!cr6.getEQ()) goto loc_820AAE88;
	// addi r11,r14,12
	r11.s64 = r14.s64 + 12;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820aae8c
	goto loc_820AAE8C;
loc_820AAE88:
	// mr r11,r27
	r11.u64 = r27.u64;
loc_820AAE8C:
	// lwz r28,28(r11)
	r28.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// li r23,0
	r23.s64 = 0;
	// li r15,1
	r15.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820aaec8
	if (cr6.getEQ()) goto loc_820AAEC8;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820aaec8
	if (cr6.getEQ()) goto loc_820AAEC8;
	// bl 0x820ca520
	sub_820CA520(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r11,r15
	r11.u64 = r15.u64;
	// beq cr6,0x820aaecc
	if (cr6.getEQ()) goto loc_820AAECC;
loc_820AAEC8:
	// mr r11,r23
	r11.u64 = r23.u64;
loc_820AAECC:
	// clrlwi r30,r11,24
	r30.u64 = r11.u32 & 0xFF;
	// bl 0x820ca338
	sub_820CA338(ctx, base);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// stw r29,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r29.u32);
	// stw r11,20(r31)
	PPC_STORE_U32(r31.u32 + 20, r11.u32);
	// bne cr6,0x820aaeec
	if (!cr6.getEQ()) goto loc_820AAEEC;
	// stw r15,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r15.u32);
loc_820AAEEC:
	// clrlwi r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// beq cr6,0x820aaf70
	if (cr6.getEQ()) goto loc_820AAF70;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820aaf70
	if (cr6.getEQ()) goto loc_820AAF70;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// beq cr6,0x820aaf20
	if (cr6.getEQ()) goto loc_820AAF20;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x820aaf20
	if (cr6.getEQ()) goto loc_820AAF20;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x820aaf70
	if (!cr6.getEQ()) goto loc_820AAF70;
loc_820AAF20:
	// addi r30,r3,2220
	r30.s64 = ctx.r3.s64 + 2220;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// stw r11,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r11.u32);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
loc_820AAF70:
	// lbz r11,13(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 13);
	// lis r19,-32014
	r19.s64 = -2098069504;
	// stb r23,12(r31)
	PPC_STORE_U8(r31.u32 + 12, r23.u8);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// addi r11,r11,-2
	r11.s64 = r11.s64 + -2;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// stb r11,13(r31)
	PPC_STORE_U8(r31.u32 + 13, r11.u8);
	// lwz r11,-6384(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820aafb4
	if (!cr6.getGT()) goto loc_820AAFB4;
	// lwz r9,32(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// add r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// stw r10,28(r31)
	PPC_STORE_U32(r31.u32 + 28, ctx.r10.u32);
loc_820AAFB4:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// stw r23,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r23.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab1c0
	if (!cr6.getEQ()) goto loc_820AB1C0;
	// cmpwi cr6,r26,22
	cr6.compare<int32_t>(r26.s32, 22, xer);
	// bne cr6,0x820aafdc
	if (!cr6.getEQ()) goto loc_820AAFDC;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820aafdc
	if (cr6.getEQ()) goto loc_820AAFDC;
	// stw r23,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r23.u32);
loc_820AAFDC:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ab048
	if (cr6.getEQ()) goto loc_820AB048;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x820ab048
	if (cr6.getEQ()) goto loc_820AB048;
	// lwzx r11,r25,r24
	r11.u64 = PPC_LOAD_U32(r25.u32 + r24.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820ab008
	if (!cr6.getEQ()) goto loc_820AB008;
	// addi r11,r14,12
	r11.s64 = r14.s64 + 12;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820ab00c
	goto loc_820AB00C;
loc_820AB008:
	// mr r11,r27
	r11.u64 = r27.u64;
loc_820AB00C:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820ab028
	if (!cr6.getEQ()) goto loc_820AB028;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820ab048
	if (!cr6.getGT()) goto loc_820AB048;
loc_820AB028:
	// cmpwi cr6,r26,22
	cr6.compare<int32_t>(r26.s32, 22, xer);
	// bne cr6,0x820ab03c
	if (!cr6.getEQ()) goto loc_820AB03C;
	// lwz r11,48(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// cmpwi cr6,r11,200
	cr6.compare<int32_t>(r11.s32, 200, xer);
	// bge cr6,0x820ab048
	if (!cr6.getLT()) goto loc_820AB048;
loc_820AB03C:
	// stw r15,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r15.u32);
	// stw r23,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r23.u32);
	// b 0x820ab058
	goto loc_820AB058;
loc_820AB048:
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ab060
	if (cr6.getEQ()) goto loc_820AB060;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
loc_820AB058:
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
loc_820AB060:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// stw r23,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r23.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab1c0
	if (!cr6.getEQ()) goto loc_820AB1C0;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab1c0
	if (!cr6.getEQ()) goto loc_820AB1C0;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x820ab1c0
	if (cr6.getEQ()) goto loc_820AB1C0;
	// bl 0x8209f588
	sub_8209F588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ab1c0
	if (!cr6.getEQ()) goto loc_820AB1C0;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r11,8260(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8260);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab1c0
	if (!cr6.getEQ()) goto loc_820AB1C0;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-3864(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -3864);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ab0cc
	if (cr6.getEQ()) goto loc_820AB0CC;
	// cmpwi cr6,r28,1
	cr6.compare<int32_t>(r28.s32, 1, xer);
	// bne cr6,0x820ab0cc
	if (!cr6.getEQ()) goto loc_820AB0CC;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r10,4584(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4584);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bgt cr6,0x820ab0cc
	if (cr6.getGT()) goto loc_820AB0CC;
	// stw r15,4584(r11)
	PPC_STORE_U32(r11.u32 + 4584, r15.u32);
loc_820AB0CC:
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x820aab28
	sub_820AAB28(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x820ab0f0
	if (!cr6.getGT()) goto loc_820AB0F0;
	// li r11,9
	r11.s64 = 9;
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820ab1c0
	goto loc_820AB1C0;
loc_820AB0F0:
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r11,4224(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4224);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ab1c0
	if (cr6.getEQ()) goto loc_820AB1C0;
	// subfic r3,r16,1
	xer.ca = r16.u32 <= 1;
	ctx.r3.s64 = 1 - r16.s64;
	// lwz r10,-1364(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// mulli r11,r3,936
	r11.s64 = ctx.r3.s64 * 936;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lwz r10,2348(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2348);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bge cr6,0x820ab120
	if (!cr6.getLT()) goto loc_820AB120;
	// lwz r10,2344(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2344);
loc_820AB120:
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// subf r11,r17,r11
	r11.s64 = r11.s64 - r17.s64;
	// addi r30,r11,3280
	r30.s64 = r11.s64 + 3280;
	// lwz r11,36(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 36);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab1c0
	if (!cr6.getEQ()) goto loc_820AB1C0;
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab1c0
	if (!cr6.getEQ()) goto loc_820AB1C0;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x820ab194
	if (cr6.getEQ()) goto loc_820AB194;
	// lwz r11,44(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 44);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab1c0
	if (!cr6.getEQ()) goto loc_820AB1C0;
	// mulli r11,r10,56
	r11.s64 = ctx.r10.s64 * 56;
	// addi r10,r14,8
	ctx.r10.s64 = r14.s64 + 8;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820ab178
	if (!cr6.getEQ()) goto loc_820AB178;
	// addi r10,r14,12
	ctx.r10.s64 = r14.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820ab17c
	goto loc_820AB17C;
loc_820AB178:
	// mr r11,r27
	r11.u64 = r27.u64;
loc_820AB17C:
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ab1c0
	if (cr6.getEQ()) goto loc_820AB1C0;
	// bl 0x820aab28
	sub_820AAB28(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bgt cr6,0x820ab1c0
	if (cr6.getGT()) goto loc_820AB1C0;
loc_820AB194:
	// bl 0x820a7340
	sub_820A7340(ctx, base);
	// lwz r11,40(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 40);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// stw r23,40(r31)
	PPC_STORE_U32(r31.u32 + 40, r23.u32);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// lwz r11,40(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// stw r23,32(r30)
	PPC_STORE_U32(r30.u32 + 32, r23.u32);
	// stw r23,28(r30)
	PPC_STORE_U32(r30.u32 + 28, r23.u32);
	// stw r23,40(r30)
	PPC_STORE_U32(r30.u32 + 40, r23.u32);
	// stw r11,36(r30)
	PPC_STORE_U32(r30.u32 + 36, r11.u32);
loc_820AB1C0:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,2688(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2688);
	f30.f64 = double(temp.f32);
	// lfs f26,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f26.f64 = double(temp.f32);
	// bne cr6,0x820ab4a4
	if (!cr6.getEQ()) goto loc_820AB4A4;
	// addi r11,r26,-1
	r11.s64 = r26.s64 + -1;
	// cmplwi cr6,r11,82
	cr6.compare<uint32_t>(r11.u32, 82, xer);
	// bgt cr6,0x820ab494
	if (cr6.getGT()) goto loc_820AB494;
	// lis r12,-32245
	r12.s64 = -2113208320;
	// addi r12,r12,-19968
	r12.s64 = r12.s64 + -19968;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820AB41C;
	case 1:
		goto loc_820AB3C8;
	case 2:
		goto loc_820AB440;
	case 3:
		goto loc_820AB358;
	case 4:
		goto loc_820AB358;
	case 5:
		goto loc_820AB358;
	case 6:
		goto loc_820AB358;
	case 7:
		goto loc_820AB358;
	case 8:
		goto loc_820AB358;
	case 9:
		goto loc_820AB358;
	case 10:
		goto loc_820AB358;
	case 11:
		goto loc_820AB358;
	case 12:
		goto loc_820AB358;
	case 13:
		goto loc_820AB358;
	case 14:
		goto loc_820AB358;
	case 15:
		goto loc_820AB358;
	case 16:
		goto loc_820AB358;
	case 17:
		goto loc_820AB34C;
	case 18:
		goto loc_820AB358;
	case 19:
		goto loc_820AB358;
	case 20:
		goto loc_820AB358;
	case 21:
		goto loc_820AB358;
	case 22:
		goto loc_820AB358;
	case 23:
		goto loc_820AB34C;
	case 24:
		goto loc_820AB358;
	case 25:
		goto loc_820AB3EC;
	case 26:
		goto loc_820AB3BC;
	case 27:
		goto loc_820AB3BC;
	case 28:
		goto loc_820AB3BC;
	case 29:
		goto loc_820AB358;
	case 30:
		goto loc_820AB44C;
	case 31:
		goto loc_820AB358;
	case 32:
		goto loc_820AB3BC;
	case 33:
		goto loc_820AB3BC;
	case 34:
		goto loc_820AB358;
	case 35:
		goto loc_820AB358;
	case 36:
		goto loc_820AB488;
	case 37:
		goto loc_820AB488;
	case 38:
		goto loc_820AB488;
	case 39:
		goto loc_820AB364;
	case 40:
		goto loc_820AB488;
	case 41:
		goto loc_820AB488;
	case 42:
		goto loc_820AB494;
	case 43:
		goto loc_820AB488;
	case 44:
		goto loc_820AB488;
	case 45:
		goto loc_820AB488;
	case 46:
		goto loc_820AB3BC;
	case 47:
		goto loc_820AB3BC;
	case 48:
		goto loc_820AB488;
	case 49:
		goto loc_820AB488;
	case 50:
		goto loc_820AB488;
	case 51:
		goto loc_820AB488;
	case 52:
		goto loc_820AB488;
	case 53:
		goto loc_820AB488;
	case 54:
		goto loc_820AB488;
	case 55:
		goto loc_820AB488;
	case 56:
		goto loc_820AB488;
	case 57:
		goto loc_820AB488;
	case 58:
		goto loc_820AB488;
	case 59:
		goto loc_820AB358;
	case 60:
		goto loc_820AB3BC;
	case 61:
		goto loc_820AB494;
	case 62:
		goto loc_820AB494;
	case 63:
		goto loc_820AB494;
	case 64:
		goto loc_820AB494;
	case 65:
		goto loc_820AB494;
	case 66:
		goto loc_820AB494;
	case 67:
		goto loc_820AB494;
	case 68:
		goto loc_820AB494;
	case 69:
		goto loc_820AB494;
	case 70:
		goto loc_820AB494;
	case 71:
		goto loc_820AB494;
	case 72:
		goto loc_820AB488;
	case 73:
		goto loc_820AB494;
	case 74:
		goto loc_820AB494;
	case 75:
		goto loc_820AB494;
	case 76:
		goto loc_820AB494;
	case 77:
		goto loc_820AB494;
	case 78:
		goto loc_820AB494;
	case 79:
		goto loc_820AB494;
	case 80:
		goto loc_820AB488;
	case 81:
		goto loc_820AB488;
	case 82:
		goto loc_820AB488;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-19428(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19428);
	// lwz r16,-19512(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19512);
	// lwz r16,-19392(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19392);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19636(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19636);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19636(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19636);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19476(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19476);
	// lwz r16,-19524(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19524);
	// lwz r16,-19524(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19524);
	// lwz r16,-19524(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19524);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19380(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19380);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19524(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19524);
	// lwz r16,-19524(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19524);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19612(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19612);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19524(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19524);
	// lwz r16,-19524(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19524);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19624(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19624);
	// lwz r16,-19524(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19524);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19308(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19308);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
	// lwz r16,-19320(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -19320);
loc_820AB34C:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// blt cr6,0x820ab4a0
	if (cr6.getLT()) goto loc_820AB4A0;
loc_820AB358:
	// li r11,2
	r11.s64 = 2;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820ab498
	goto loc_820AB498;
loc_820AB364:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab388
	if (!cr6.getEQ()) goto loc_820AB388;
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f1,f26
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f26.f64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820b2028
	sub_820B2028(ctx, base);
	// b 0x820ab4a0
	goto loc_820AB4A0;
loc_820AB388:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// blt cr6,0x820ab4a0
	if (cr6.getLT()) goto loc_820AB4A0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f2,f30
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = f30.f64;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// lfs f1,12272(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12272);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x820b2050
	sub_820B2050(ctx, base);
	// li r11,2
	r11.s64 = 2;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820ab498
	goto loc_820AB498;
loc_820AB3BC:
	// li r11,28
	r11.s64 = 28;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820ab498
	goto loc_820AB498;
loc_820AB3C8:
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r11,r3,31
	r11.u64 = ctx.r3.u32 & 0x1;
	// subfic r11,r11,0
	xer.ca = r11.u32 <= 0;
	r11.s64 = 0 - r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// addi r11,r11,17
	r11.s64 = r11.s64 + 17;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820ab498
	goto loc_820AB498;
loc_820AB3EC:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab404
	if (!cr6.getEQ()) goto loc_820AB404;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpwi cr6,r11,240
	cr6.compare<int32_t>(r11.s32, 240, xer);
	// blt cr6,0x820ab4a0
	if (cr6.getLT()) goto loc_820AB4A0;
loc_820AB404:
	// lwz r9,-1364(r18)
	ctx.r9.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// li r10,26
	ctx.r10.s64 = 26;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// stw r11,4372(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4372, r11.u32);
	// stw r10,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r10.u32);
	// b 0x820ab498
	goto loc_820AB498;
loc_820AB41C:
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r11,r3,31
	r11.u64 = ctx.r3.u32 & 0x1;
	// subfic r11,r11,0
	xer.ca = r11.u32 <= 0;
	r11.s64 = 0 - r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// rlwinm r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	// addi r11,r11,30
	r11.s64 = r11.s64 + 30;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820ab498
	goto loc_820AB498;
loc_820AB440:
	// li r11,23
	r11.s64 = 23;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820ab498
	goto loc_820AB498;
loc_820AB44C:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// addi r3,r11,15064
	ctx.r3.s64 = r11.s64 + 15064;
	// extsw r11,r10
	r11.s64 = ctx.r10.s32;
	// addi r5,r31,124
	ctx.r5.s64 = r31.s64 + 124;
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lfd f0,96(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// bl 0x820a0830
	sub_820A0830(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ab358
	if (cr6.getEQ()) goto loc_820AB358;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// b 0x820ab4a0
	goto loc_820AB4A0;
loc_820AB488:
	// li r11,36
	r11.s64 = 36;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820ab498
	goto loc_820AB498;
loc_820AB494:
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
loc_820AB498:
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
loc_820AB4A0:
	// stw r23,920(r31)
	PPC_STORE_U32(r31.u32 + 920, r23.u32);
loc_820AB4A4:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// li r26,13
	r26.s64 = 13;
	// lis r20,-31994
	r20.s64 = -2096758784;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lis r21,-31994
	r21.s64 = -2096758784;
	// addi r27,r11,15280
	r27.s64 = r11.s64 + 15280;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r22,r11,13992
	r22.s64 = r11.s64 + 13992;
	// bne cr6,0x820abaf4
	if (!cr6.getEQ()) goto loc_820ABAF4;
	// lwzx r10,r25,r24
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + r24.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820ab4e4
	if (!cr6.getEQ()) goto loc_820AB4E4;
	// addi r11,r14,12
	r11.s64 = r14.s64 + 12;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820ab4e8
	goto loc_820AB4E8;
loc_820AB4E4:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_820AB4E8:
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ab558
	if (cr6.getEQ()) goto loc_820AB558;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x820ab558
	if (cr6.getGT()) goto loc_820AB558;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// ble cr6,0x820ab520
	if (!cr6.getGT()) goto loc_820AB520;
	// li r11,3
	r11.s64 = 3;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820abaf4
	goto loc_820ABAF4;
loc_820AB520:
	// stw r26,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r26.u32);
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x820ab54c
	if (cr6.getEQ()) goto loc_820AB54C;
	// bl 0x8213b200
	sub_8213B200(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820abaf4
	if (!cr6.getEQ()) goto loc_820ABAF4;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r11,8260(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8260);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820abaf4
	if (!cr6.getEQ()) goto loc_820ABAF4;
loc_820AB54C:
	// li r8,5242
	ctx.r8.s64 = 5242;
	// li r4,89
	ctx.r4.s64 = 89;
	// b 0x820abae0
	goto loc_820ABAE0;
loc_820AB558:
	// lwz r30,84(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r11,r30,-2
	r11.s64 = r30.s64 + -2;
	// cmplwi cr6,r11,58
	cr6.compare<uint32_t>(r11.u32, 58, xer);
	// bgt cr6,0x820ab890
	if (cr6.getGT()) goto loc_820AB890;
	// lis r12,-32245
	r12.s64 = -2113208320;
	// addi r12,r12,-19072
	r12.s64 = r12.s64 + -19072;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820AB7D8;
	case 1:
		goto loc_820AB890;
	case 2:
		goto loc_820AB67C;
	case 3:
		goto loc_820AB67C;
	case 4:
		goto loc_820AB67C;
	case 5:
		goto loc_820AB6EC;
	case 6:
		goto loc_820AB6EC;
	case 7:
		goto loc_820AB6EC;
	case 8:
		goto loc_820AB6EC;
	case 9:
		goto loc_820AB6EC;
	case 10:
		goto loc_820AB6EC;
	case 11:
		goto loc_820AB6EC;
	case 12:
		goto loc_820AB6EC;
	case 13:
		goto loc_820AB67C;
	case 14:
		goto loc_820AB67C;
	case 15:
		goto loc_820AB67C;
	case 16:
		goto loc_820AB67C;
	case 17:
		goto loc_820AB67C;
	case 18:
		goto loc_820AB67C;
	case 19:
		goto loc_820AB67C;
	case 20:
		goto loc_820AB67C;
	case 21:
		goto loc_820AB67C;
	case 22:
		goto loc_820AB67C;
	case 23:
		goto loc_820AB67C;
	case 24:
		goto loc_820AB890;
	case 25:
		goto loc_820AB890;
	case 26:
		goto loc_820AB890;
	case 27:
		goto loc_820AB890;
	case 28:
		goto loc_820AB67C;
	case 29:
		goto loc_820AB810;
	case 30:
		goto loc_820AB67C;
	case 31:
		goto loc_820AB890;
	case 32:
		goto loc_820AB890;
	case 33:
		goto loc_820AB67C;
	case 34:
		goto loc_820AB67C;
	case 35:
		goto loc_820AB890;
	case 36:
		goto loc_820AB890;
	case 37:
		goto loc_820AB890;
	case 38:
		goto loc_820AB66C;
	case 39:
		goto loc_820AB890;
	case 40:
		goto loc_820AB890;
	case 41:
		goto loc_820AB890;
	case 42:
		goto loc_820AB890;
	case 43:
		goto loc_820AB890;
	case 44:
		goto loc_820AB890;
	case 45:
		goto loc_820AB890;
	case 46:
		goto loc_820AB890;
	case 47:
		goto loc_820AB890;
	case 48:
		goto loc_820AB890;
	case 49:
		goto loc_820AB890;
	case 50:
		goto loc_820AB890;
	case 51:
		goto loc_820AB890;
	case 52:
		goto loc_820AB890;
	case 53:
		goto loc_820AB890;
	case 54:
		goto loc_820AB890;
	case 55:
		goto loc_820AB890;
	case 56:
		goto loc_820AB890;
	case 57:
		goto loc_820AB890;
	case 58:
		goto loc_820AB66C;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-18472(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18472);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18708(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18708);
	// lwz r16,-18708(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18708);
	// lwz r16,-18708(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18708);
	// lwz r16,-18708(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18708);
	// lwz r16,-18708(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18708);
	// lwz r16,-18708(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18708);
	// lwz r16,-18708(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18708);
	// lwz r16,-18708(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18708);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18416(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18416);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18820(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18820);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18836(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18836);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18288(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18288);
	// lwz r16,-18836(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -18836);
loc_820AB66C:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab828
	if (!cr6.getEQ()) goto loc_820AB828;
	// b 0x820ab868
	goto loc_820AB868;
loc_820AB67C:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab828
	if (!cr6.getEQ()) goto loc_820AB828;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x820ab6b0
	if (cr6.getEQ()) goto loc_820AB6B0;
	// bl 0x8213b200
	sub_8213B200(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ab6b4
	if (!cr6.getEQ()) goto loc_820AB6B4;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r11,8260(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8260);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab6b4
	if (!cr6.getEQ()) goto loc_820AB6B4;
loc_820AB6B0:
	// stb r15,13(r31)
	PPC_STORE_U8(r31.u32 + 13, r15.u8);
loc_820AB6B4:
	// bl 0x8209f588
	sub_8209F588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ab6d4
	if (!cr6.getEQ()) goto loc_820AB6D4;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r11,8260(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8260);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r15
	r11.u64 = r15.u64;
	// beq cr6,0x820ab6d8
	if (cr6.getEQ()) goto loc_820AB6D8;
loc_820AB6D4:
	// mr r11,r23
	r11.u64 = r23.u64;
loc_820AB6D8:
	// stb r11,12(r31)
	PPC_STORE_U8(r31.u32 + 12, r11.u8);
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// add r11,r17,r11
	r11.u64 = r17.u64 + r11.u64;
	// stw r15,2884(r11)
	PPC_STORE_U32(r11.u32 + 2884, r15.u32);
	// b 0x820ab890
	goto loc_820AB890;
loc_820AB6EC:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ab774
	if (cr6.getEQ()) goto loc_820AB774;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab774
	if (!cr6.getEQ()) goto loc_820AB774;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820ab718
	if (!cr6.getEQ()) goto loc_820AB718;
	// addi r11,r14,12
	r11.s64 = r14.s64 + 12;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820ab71c
	goto loc_820AB71C;
loc_820AB718:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_820AB71C:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ab760
	if (cr6.getEQ()) goto loc_820AB760;
	// bl 0x820b0878
	sub_820B0878(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ab760
	if (!cr6.getEQ()) goto loc_820AB760;
	// lis r10,21845
	ctx.r10.s64 = 1431633920;
	// lwz r11,920(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 920);
	// ori r10,r10,21846
	ctx.r10.u64 = ctx.r10.u64 | 21846;
	// mulhw r10,r11,r10
	ctx.r10.s64 = (int64_t(r11.s32) * int64_t(ctx.r10.s32)) >> 32;
	// rlwinm r9,r10,1,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// subf. r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x820ab774
	if (!cr0.getEQ()) goto loc_820AB774;
loc_820AB760:
	// li r11,3
	r11.s64 = 3;
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820ab890
	goto loc_820AB890;
loc_820AB774:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x820a1120
	sub_820A1120(ctx, base);
	// lwz r10,28(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// extsb r9,r3
	ctx.r9.s64 = ctx.r3.s8;
	// rotlwi r11,r10,1
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 1);
	// divw r8,r10,r9
	ctx.r8.s32 = ctx.r10.s32 / ctx.r9.s32;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// mullw r8,r8,r9
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r9.s32);
	// andc r11,r9,r11
	r11.u64 = ctx.r9.u64 & ~r11.u64;
	// twllei r9,0
	// subf. r10,r8,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r8.s64;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// twlgei r11,-1
	// bne 0x820ab890
	if (!cr0.getEQ()) goto loc_820AB890;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x820ab7d0
	if (cr6.getEQ()) goto loc_820AB7D0;
	// bl 0x8213b200
	sub_8213B200(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ab868
	if (!cr6.getEQ()) goto loc_820AB868;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r11,8260(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8260);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab868
	if (!cr6.getEQ()) goto loc_820AB868;
loc_820AB7D0:
	// stb r15,13(r31)
	PPC_STORE_U8(r31.u32 + 13, r15.u8);
	// b 0x820ab868
	goto loc_820AB868;
loc_820AB7D8:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ab804
	if (cr6.getEQ()) goto loc_820AB804;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab804
	if (!cr6.getEQ()) goto loc_820AB804;
	// li r11,3
	r11.s64 = 3;
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820ab890
	goto loc_820AB890;
loc_820AB804:
	// stb r23,12(r31)
	PPC_STORE_U8(r31.u32 + 12, r23.u8);
	// stb r23,13(r31)
	PPC_STORE_U8(r31.u32 + 13, r23.u8);
	// b 0x820ab890
	goto loc_820AB890;
loc_820AB810:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ab83c
	if (cr6.getEQ()) goto loc_820AB83C;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ab83c
	if (!cr6.getEQ()) goto loc_820AB83C;
loc_820AB828:
	// li r11,3
	r11.s64 = 3;
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820ab890
	goto loc_820AB890;
loc_820AB83C:
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// addi r5,r31,124
	ctx.r5.s64 = r31.s64 + 124;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x820a0830
	sub_820A0830(ctx, base);
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// stb r23,12(r31)
	PPC_STORE_U8(r31.u32 + 12, r23.u8);
	// stb r23,13(r31)
	PPC_STORE_U8(r31.u32 + 13, r23.u8);
	// bne cr6,0x820ab890
	if (!cr6.getEQ()) goto loc_820AB890;
loc_820AB868:
	// bl 0x8209f588
	sub_8209F588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ab888
	if (!cr6.getEQ()) goto loc_820AB888;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r11,8260(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8260);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// mr r11,r15
	r11.u64 = r15.u64;
	// beq cr6,0x820ab88c
	if (cr6.getEQ()) goto loc_820AB88C;
loc_820AB888:
	// mr r11,r23
	r11.u64 = r23.u64;
loc_820AB88C:
	// stb r11,12(r31)
	PPC_STORE_U8(r31.u32 + 12, r11.u8);
loc_820AB890:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ab8d4
	if (cr6.getEQ()) goto loc_820AB8D4;
	// cmpwi cr6,r30,40
	cr6.compare<int32_t>(r30.s32, 40, xer);
	// beq cr6,0x820ab8bc
	if (cr6.getEQ()) goto loc_820AB8BC;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,13964(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13964);
	f31.f64 = double(temp.f32);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// bl 0x820ca110
	sub_820CA110(ctx, base);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x820a0768
	sub_820A0768(ctx, base);
loc_820AB8BC:
	// lwz r10,44(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// lwz r11,920(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 920);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r10,44(r31)
	PPC_STORE_U32(r31.u32 + 44, ctx.r10.u32);
	// stw r11,920(r31)
	PPC_STORE_U32(r31.u32 + 920, r11.u32);
loc_820AB8D4:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// bne cr6,0x820abaf4
	if (!cr6.getEQ()) goto loc_820ABAF4;
	// lwzx r9,r25,r24
	ctx.r9.u64 = PPC_LOAD_U32(r25.u32 + r24.u32);
	// mr r30,r23
	r30.u64 = r23.u64;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820ab8fc
	if (!cr6.getEQ()) goto loc_820AB8FC;
	// addi r11,r14,12
	r11.s64 = r14.s64 + 12;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820ab900
	goto loc_820AB900;
loc_820AB8FC:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_820AB900:
	// lbz r11,37(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 37);
	// lis r28,-32014
	r28.s64 = -2098069504;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ab968
	if (cr6.getEQ()) goto loc_820AB968;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r10,-6376(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + -6376);
	// subf r11,r17,r11
	r11.s64 = r11.s64 - r17.s64;
	// lwz r11,3760(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 3760);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// beq cr6,0x820ab978
	if (cr6.getEQ()) goto loc_820AB978;
	// lwz r11,476(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 476);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bge cr6,0x820ab978
	if (!cr6.getLT()) goto loc_820AB978;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820ab954
	if (!cr6.getEQ()) goto loc_820AB954;
	// addi r11,r14,12
	r11.s64 = r14.s64 + 12;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// lbz r11,37(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 37);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stw r11,476(r31)
	PPC_STORE_U32(r31.u32 + 476, r11.u32);
	// b 0x820ab974
	goto loc_820AB974;
loc_820AB954:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lbz r11,37(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 37);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stw r11,476(r31)
	PPC_STORE_U32(r31.u32 + 476, r11.u32);
	// b 0x820ab974
	goto loc_820AB974;
loc_820AB968:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ab978
	if (cr6.getEQ()) goto loc_820AB978;
loc_820AB974:
	// mr r30,r15
	r30.u64 = r15.u64;
loc_820AB978:
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x820ab9a0
	if (cr6.getEQ()) goto loc_820AB9A0;
	// bl 0x8213b200
	sub_8213B200(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820abaf4
	if (!cr6.getEQ()) goto loc_820ABAF4;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r11,8260(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8260);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820abaf4
	if (!cr6.getEQ()) goto loc_820ABAF4;
loc_820AB9A0:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x820abaa0
	if (cr6.getEQ()) goto loc_820ABAA0;
	// lwz r3,468(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 468);
	// addi r29,r31,468
	r29.s64 = r31.s64 + 468;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820ab9cc
	if (cr6.getEQ()) goto loc_820AB9CC;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ab9cc
	if (cr6.getEQ()) goto loc_820AB9CC;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820AB9CC:
	// lwz r3,472(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 472);
	// addi r30,r31,472
	r30.s64 = r31.s64 + 472;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820ab9f0
	if (cr6.getEQ()) goto loc_820AB9F0;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ab9f0
	if (cr6.getEQ()) goto loc_820AB9F0;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820AB9F0:
	// lwzx r10,r25,r24
	ctx.r10.u64 = PPC_LOAD_U32(r25.u32 + r24.u32);
	// lwz r9,80(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820aba0c
	if (!cr6.getEQ()) goto loc_820ABA0C;
	// addi r11,r14,12
	r11.s64 = r14.s64 + 12;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820aba10
	goto loc_820ABA10;
loc_820ABA0C:
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_820ABA10:
	// lhz r11,38(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 38);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820abaa0
	if (cr6.getEQ()) goto loc_820ABAA0;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820aba54
	if (!cr6.getEQ()) goto loc_820ABA54;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820aba44
	if (!cr6.getEQ()) goto loc_820ABA44;
	// addi r11,r14,12
	r11.s64 = r14.s64 + 12;
	// li r8,5215
	ctx.r8.s64 = 5215;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820aba80
	goto loc_820ABA80;
loc_820ABA44:
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
	// li r8,5215
	ctx.r8.s64 = 5215;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// b 0x820aba80
	goto loc_820ABA80;
loc_820ABA54:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820aba98
	if (!cr6.getEQ()) goto loc_820ABA98;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820aba74
	if (!cr6.getEQ()) goto loc_820ABA74;
	// addi r11,r14,12
	r11.s64 = r14.s64 + 12;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820aba78
	goto loc_820ABA78;
loc_820ABA74:
	// mr r11,r9
	r11.u64 = ctx.r9.u64;
loc_820ABA78:
	// li r8,5217
	ctx.r8.s64 = 5217;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
loc_820ABA80:
	// lhz r11,38(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 38);
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// lwz r6,19944(r21)
	ctx.r6.u64 = PPC_LOAD_U32(r21.u32 + 19944);
	// extsh r4,r11
	ctx.r4.s64 = r11.s16;
	// lwz r3,19936(r20)
	ctx.r3.u64 = PPC_LOAD_U32(r20.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
loc_820ABA98:
	// lwz r11,-6376(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -6376);
	// stw r11,480(r31)
	PPC_STORE_U32(r31.u32 + 480, r11.u32);
loc_820ABAA0:
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r11,23
	cr6.compare<int32_t>(r11.s32, 23, xer);
	// bne cr6,0x820abaf4
	if (!cr6.getEQ()) goto loc_820ABAF4;
	// li r11,92
	r11.s64 = 92;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// li r11,93
	r11.s64 = 93;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// li r8,5225
	ctx.r8.s64 = 5225;
	// rlwinm r11,r11,2,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x4;
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
loc_820ABAE0:
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// lwz r6,19944(r21)
	ctx.r6.u64 = PPC_LOAD_U32(r21.u32 + 19944);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,19936(r20)
	ctx.r3.u64 = PPC_LOAD_U32(r20.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
loc_820ABAF4:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f29,2692(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2692);
	f29.f64 = double(temp.f32);
	// lfs f28,11980(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 11980);
	f28.f64 = double(temp.f32);
	// bne cr6,0x820abe08
	if (!cr6.getEQ()) goto loc_820ABE08;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r11,31
	cr6.compare<int32_t>(r11.s32, 31, xer);
	// bne cr6,0x820abb54
	if (!cr6.getEQ()) goto loc_820ABB54;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// addi r5,r31,124
	ctx.r5.s64 = r31.s64 + 124;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lfd f0,96(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// bl 0x820a0830
	sub_820A0830(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820abbd4
	if (cr6.getEQ()) goto loc_820ABBD4;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// b 0x820abe08
	goto loc_820ABE08;
loc_820ABB54:
	// lwzx r11,r25,r24
	r11.u64 = PPC_LOAD_U32(r25.u32 + r24.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820abb6c
	if (!cr6.getEQ()) goto loc_820ABB6C;
	// addi r11,r14,12
	r11.s64 = r14.s64 + 12;
	// lwzx r8,r25,r11
	ctx.r8.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820abb70
	goto loc_820ABB70;
loc_820ABB6C:
	// lwz r8,80(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_820ABB70:
	// lbz r10,69(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 69);
	// lbz r11,68(r8)
	r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 68);
	// lbz r9,71(r8)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r8.u32 + 71);
	// extsb r5,r10
	ctx.r5.s64 = ctx.r10.s8;
	// lbz r4,35(r8)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r8.u32 + 35);
	// extsb r6,r11
	ctx.r6.s64 = r11.s8;
	// lbz r10,70(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 70);
	// extsb r7,r9
	ctx.r7.s64 = ctx.r9.s8;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// extsb r9,r4
	ctx.r9.s64 = ctx.r4.s8;
	// extsb r4,r10
	ctx.r4.s64 = ctx.r10.s8;
	// add r10,r5,r6
	ctx.r10.u64 = ctx.r5.u64 + ctx.r6.u64;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820abbb4
	if (cr6.getEQ()) goto loc_820ABBB4;
	// lwz r3,32(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpw cr6,r3,r10
	cr6.compare<int32_t>(ctx.r3.s32, ctx.r10.s32, xer);
	// bge cr6,0x820abbd4
	if (!cr6.getLT()) goto loc_820ABBD4;
loc_820ABBB4:
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// blt cr6,0x820abbe4
	if (cr6.getLT()) goto loc_820ABBE4;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820abbec
	if (!cr6.getEQ()) goto loc_820ABBEC;
	// lwz r3,32(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// add r9,r9,r10
	ctx.r9.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmpw cr6,r3,r9
	cr6.compare<int32_t>(ctx.r3.s32, ctx.r9.s32, xer);
	// blt cr6,0x820abbe4
	if (cr6.getLT()) goto loc_820ABBE4;
loc_820ABBD4:
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// b 0x820abe08
	goto loc_820ABE08;
loc_820ABBE4:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820abc38
	if (cr6.getEQ()) goto loc_820ABC38;
loc_820ABBEC:
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820abc38
	if (cr6.getEQ()) goto loc_820ABC38;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpw cr6,r11,r4
	cr6.compare<int32_t>(r11.s32, ctx.r4.s32, xer);
	// blt cr6,0x820abc38
	if (cr6.getLT()) goto loc_820ABC38;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// blt cr6,0x820abc38
	if (cr6.getLT()) goto loc_820ABC38;
	// add r11,r11,r7
	r11.u64 = r11.u64 + ctx.r7.u64;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bge cr6,0x820abc38
	if (!cr6.getLT()) goto loc_820ABC38;
	// cmpw cr6,r11,r4
	cr6.compare<int32_t>(r11.s32, ctx.r4.s32, xer);
	// blt cr6,0x820abc38
	if (cr6.getLT()) goto loc_820ABC38;
	// li r11,4
	r11.s64 = 4;
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// stw r7,56(r31)
	PPC_STORE_U32(r31.u32 + 56, ctx.r7.u32);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820abe08
	goto loc_820ABE08;
loc_820ABC38:
	// lwz r7,32(r31)
	ctx.r7.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpw cr6,r7,r10
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r10.s32, xer);
	// bge cr6,0x820abe08
	if (!cr6.getLT()) goto loc_820ABE08;
	// lfs f13,72(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 72);
	ctx.f13.f64 = double(temp.f32);
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// lfs f11,76(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 76);
	ctx.f11.f64 = double(temp.f32);
	// bne cr6,0x820abc74
	if (!cr6.getEQ()) goto loc_820ABC74;
	// lfs f0,120(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 120);
	f0.f64 = double(temp.f32);
	// lfs f12,108(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 108);
	ctx.f12.f64 = double(temp.f32);
	// lfs f10,112(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 112);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,116(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 116);
	ctx.f9.f64 = double(temp.f32);
	// stfs f0,88(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 88, temp.u32);
	// stfs f12,76(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r31.u32 + 76, temp.u32);
	// stfs f10,80(r31)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(r31.u32 + 80, temp.u32);
	// stfs f9,84(r31)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(r31.u32 + 84, temp.u32);
loc_820ABC74:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// cmpw cr6,r7,r6
	cr6.compare<int32_t>(ctx.r7.s32, ctx.r6.s32, xer);
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// lfs f0,13980(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13980);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,6588(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6588);
	ctx.f12.f64 = double(temp.f32);
	// fnmsubs f0,f11,f0,f12
	f0.f64 = double(float(-(ctx.f11.f64 * f0.f64 - ctx.f12.f64)));
	// stfs f0,104(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 104, temp.u32);
	// bge cr6,0x820abd10
	if (!cr6.getLT()) goto loc_820ABD10;
	// bl 0x820a0e08
	sub_820A0E08(ctx, base);
	// lfs f0,456(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 456);
	f0.f64 = double(temp.f32);
	// fsubs f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 - f0.f64));
	// extsw r11,r7
	r11.s64 = ctx.r7.s32;
	// stfs f30,96(r31)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 96, temp.u32);
	// extsw r10,r6
	ctx.r10.s64 = ctx.r6.s32;
	// lfs f12,464(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 464);
	ctx.f12.f64 = double(temp.f32);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// std r10,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r10.u64);
	// fmuls f11,f0,f13
	ctx.f11.f64 = double(float(f0.f64 * ctx.f13.f64));
	// lfs f0,14440(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14440);
	f0.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * f0.f64));
	// stfs f11,92(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r31.u32 + 92, temp.u32);
	// lfs f11,12(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,100(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 100, temp.u32);
	// lfd f0,96(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lfd f13,104(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// fdivs f1,f0,f13
	ctx.f1.f64 = double(float(f0.f64 / ctx.f13.f64));
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = double(float(ctx.f1.f64));
	// b 0x820abd98
	goto loc_820ABD98;
loc_820ABD10:
	// bl 0x820a0e08
	sub_820A0E08(ctx, base);
	// lfs f0,456(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 456);
	f0.f64 = double(temp.f32);
	// fsubs f0,f1,f0
	f0.f64 = double(float(ctx.f1.f64 - f0.f64));
	// subf r11,r6,r7
	r11.s64 = ctx.r7.s64 - ctx.r6.s64;
	// stfs f30,96(r31)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 96, temp.u32);
	// extsw r10,r5
	ctx.r10.s64 = ctx.r5.s32;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// lfs f12,464(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 464);
	ctx.f12.f64 = double(temp.f32);
	// std r10,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r10.u64);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f11,f0,f13
	ctx.f11.f64 = double(float(f0.f64 * ctx.f13.f64));
	// lfs f0,14440(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14440);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * f0.f64));
	// stfs f11,92(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r31.u32 + 92, temp.u32);
	// lfs f11,12(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 12);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f12,f11,f12
	ctx.f12.f64 = double(float(ctx.f11.f64 - ctx.f12.f64));
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// stfs f0,100(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 100, temp.u32);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f12,f0
	ctx.f12.f64 = double(float(f0.f64));
	// lfs f0,14032(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14032);
	f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fdivs f1,f0,f12
	ctx.f1.f64 = double(float(f0.f64 / ctx.f12.f64));
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fadds f0,f0,f26
	f0.f64 = double(float(f0.f64 + f26.f64));
	// fmuls f31,f0,f29
	f31.f64 = double(float(f0.f64 * f29.f64));
loc_820ABD98:
	// lfs f2,104(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 104);
	ctx.f2.f64 = double(temp.f32);
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// lfs f1,88(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 88);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x82119348
	sub_82119348(ctx, base);
	// lfs f0,76(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 76);
	f0.f64 = double(temp.f32);
	// addi r30,r31,124
	r30.s64 = r31.s64 + 124;
	// lfs f11,92(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	ctx.f11.f64 = double(temp.f32);
	// addi r29,r31,108
	r29.s64 = r31.s64 + 108;
	// lfs f13,80(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 80);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 - f0.f64));
	// lfs f10,96(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 96);
	ctx.f10.f64 = double(temp.f32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lfs f12,84(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f10,f10,f13
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f13.f64));
	// lfs f9,100(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 100);
	ctx.f9.f64 = double(temp.f32);
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// fsubs f9,f9,f12
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f12.f64));
	// stfs f1,120(r31)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r31.u32 + 120, temp.u32);
	// fmadds f0,f11,f31,f0
	f0.f64 = double(float(ctx.f11.f64 * f31.f64 + f0.f64));
	// stfs f0,108(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 108, temp.u32);
	// fmadds f0,f10,f31,f13
	f0.f64 = double(float(ctx.f10.f64 * f31.f64 + ctx.f13.f64));
	// stfs f0,112(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 112, temp.u32);
	// fmadds f0,f9,f31,f12
	f0.f64 = double(float(ctx.f9.f64 * f31.f64 + ctx.f12.f64));
	// stfs f0,116(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 116, temp.u32);
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
loc_820ABE08:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,4
	cr6.compare<int32_t>(r11.s32, 4, xer);
	// bne cr6,0x820abf24
	if (!cr6.getEQ()) goto loc_820ABF24;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x820abe50
	if (!cr6.getEQ()) goto loc_820ABE50;
	// lfs f0,120(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 120);
	f0.f64 = double(temp.f32);
	// lfs f13,108(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,112(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 112);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,116(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 116);
	ctx.f11.f64 = double(temp.f32);
	// stfs f0,88(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 88, temp.u32);
	// stfs f13,76(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 76, temp.u32);
	// stfs f12,80(r31)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r31.u32 + 80, temp.u32);
	// stfs f11,84(r31)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r31.u32 + 84, temp.u32);
	// stfs f30,104(r31)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 104, temp.u32);
	// stfs f30,92(r31)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 92, temp.u32);
	// stfs f30,96(r31)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 96, temp.u32);
	// stfs f30,100(r31)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 100, temp.u32);
loc_820ABE50:
	// lwz r11,56(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 56);
	// cmpw cr6,r10,r11
	cr6.compare<int32_t>(ctx.r10.s32, r11.s32, xer);
	// bge cr6,0x820abf18
	if (!cr6.getLT()) goto loc_820ABF18;
	// subf r10,r10,r11
	ctx.r10.s64 = r11.s64 - ctx.r10.s64;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// std r10,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r10.u64);
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f13,f13,f28
	ctx.f13.f64 = double(float(ctx.f13.f64 * f28.f64));
	// fdivs f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 / f0.f64));
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// lfs f2,104(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 104);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,88(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 88);
	ctx.f1.f64 = double(temp.f32);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fadds f0,f0,f26
	f0.f64 = double(float(f0.f64 + f26.f64));
	// fmuls f31,f0,f29
	f31.f64 = double(float(f0.f64 * f29.f64));
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// bl 0x82119348
	sub_82119348(ctx, base);
	// lfs f0,76(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 76);
	f0.f64 = double(temp.f32);
	// addi r30,r31,124
	r30.s64 = r31.s64 + 124;
	// lfs f11,92(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 92);
	ctx.f11.f64 = double(temp.f32);
	// addi r29,r31,108
	r29.s64 = r31.s64 + 108;
	// lfs f13,80(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 80);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 - f0.f64));
	// lfs f10,96(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 96);
	ctx.f10.f64 = double(temp.f32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lfs f12,84(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 84);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f10,f10,f13
	ctx.f10.f64 = double(float(ctx.f10.f64 - ctx.f13.f64));
	// lfs f9,100(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 100);
	ctx.f9.f64 = double(temp.f32);
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// fsubs f9,f9,f12
	ctx.f9.f64 = double(float(ctx.f9.f64 - ctx.f12.f64));
	// stfs f1,120(r31)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r31.u32 + 120, temp.u32);
	// fmadds f0,f11,f31,f0
	f0.f64 = double(float(ctx.f11.f64 * f31.f64 + f0.f64));
	// stfs f0,108(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 108, temp.u32);
	// fmadds f0,f10,f31,f13
	f0.f64 = double(float(ctx.f10.f64 * f31.f64 + ctx.f13.f64));
	// stfs f0,112(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 112, temp.u32);
	// fmadds f0,f9,f31,f12
	f0.f64 = double(float(ctx.f9.f64 * f31.f64 + ctx.f12.f64));
	// stfs f0,116(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 116, temp.u32);
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x8210bbf8
	sub_8210BBF8(ctx, base);
	// b 0x820abf24
	goto loc_820ABF24;
loc_820ABF18:
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
loc_820ABF24:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,13
	cr6.compare<int32_t>(r11.s32, 13, xer);
	// bne cr6,0x820abf6c
	if (!cr6.getEQ()) goto loc_820ABF6C;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820abf48
	if (!cr6.getEQ()) goto loc_820ABF48;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// add r11,r17,r11
	r11.u64 = r17.u64 + r11.u64;
	// stw r15,2884(r11)
	PPC_STORE_U32(r11.u32 + 2884, r15.u32);
loc_820ABF48:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820abf60
	if (!cr6.getEQ()) goto loc_820ABF60;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// blt cr6,0x820abf6c
	if (cr6.getLT()) goto loc_820ABF6C;
loc_820ABF60:
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
loc_820ABF6C:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r28,17
	r28.s64 = 17;
	// lfs f28,14436(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 14436);
	f28.f64 = double(temp.f32);
	// lfs f29,14100(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14100);
	f29.f64 = double(temp.f32);
	// lfs f24,14432(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14432);
	f24.f64 = double(temp.f32);
	// bne cr6,0x820ac0d8
	if (!cr6.getEQ()) goto loc_820AC0D8;
	// li r30,16
	r30.s64 = 16;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820abfa8
	if (!cr6.getGT()) goto loc_820ABFA8;
	// li r30,12
	r30.s64 = 12;
loc_820ABFA8:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820abfcc
	if (!cr6.getEQ()) goto loc_820ABFCC;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x820abfc8
	if (!cr6.getEQ()) goto loc_820ABFC8;
	// stw r28,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r28.u32);
	// b 0x820abfcc
	goto loc_820ABFCC;
loc_820ABFC8:
	// stw r26,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r26.u32);
loc_820ABFCC:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpw cr6,r11,r30
	cr6.compare<int32_t>(r11.s32, r30.s32, xer);
	// blt cr6,0x820ac064
	if (cr6.getLT()) goto loc_820AC064;
	// lwzx r11,r25,r24
	r11.u64 = PPC_LOAD_U32(r25.u32 + r24.u32);
	// lwz r26,80(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820abff4
	if (!cr6.getEQ()) goto loc_820ABFF4;
	// addi r11,r14,12
	r11.s64 = r14.s64 + 12;
	// lwzx r11,r25,r11
	r11.u64 = PPC_LOAD_U32(r25.u32 + r11.u32);
	// b 0x820abff8
	goto loc_820ABFF8;
loc_820ABFF4:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_820ABFF8:
	// lwz r11,28(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 28);
	// lwz r8,44(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// addi r11,r11,1145
	r11.s64 = r11.s64 + 1145;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// stwx r9,r10,r11
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, ctx.r9.u32);
	// stw r23,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r23.u32);
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820ac030
	if (!cr6.getGT()) goto loc_820AC030;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x820c9f20
	sub_820C9F20(ctx, base);
loc_820AC030:
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x820a21b0
	sub_820A21B0(ctx, base);
	// li r11,6
	r11.s64 = 6;
	// li r3,17
	ctx.r3.s64 = 17;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// bl 0x820c0cc8
	sub_820C0CC8(ctx, base);
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ac05c
	if (cr6.getEQ()) goto loc_820AC05C;
	// stw r28,8376(r11)
	PPC_STORE_U32(r11.u32 + 8376, r28.u32);
	// b 0x820ac0dc
	goto loc_820AC0DC;
loc_820AC05C:
	// stw r15,8376(r11)
	PPC_STORE_U32(r11.u32 + 8376, r15.u32);
	// b 0x820ac0dc
	goto loc_820AC0DC;
loc_820AC064:
	// extsw r11,r11
	r11.s64 = r11.s32;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// extsw r10,r30
	ctx.r10.s64 = r30.s32;
	// addi r4,r31,124
	ctx.r4.s64 = r31.s64 + 124;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// std r10,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, ctx.r10.u64);
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f0,f0,f24
	f0.f64 = double(float(f0.f64 * f24.f64));
	// fdivs f31,f0,f13
	f31.f64 = double(float(f0.f64 / ctx.f13.f64));
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// stfs f30,172(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 172, temp.u32);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fsubs f0,f26,f0
	f0.f64 = double(float(f26.f64 - f0.f64));
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// stfs f0,176(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 176, temp.u32);
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,180(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 180, temp.u32);
loc_820AC0D8:
	// lwz r26,80(r1)
	r26.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_820AC0DC:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// lfd f23,14424(r10)
	ctx.fpscr.disableFlushMode();
	f23.u64 = PPC_LOAD_U64(ctx.r10.u32 + 14424);
	// beq cr6,0x820ac0f8
	if (cr6.getEQ()) goto loc_820AC0F8;
	// cmpwi cr6,r11,7
	cr6.compare<int32_t>(r11.s32, 7, xer);
	// bne cr6,0x820ac270
	if (!cr6.getEQ()) goto loc_820AC270;
loc_820AC0F8:
	// lwz r10,68(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 68);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x820ac114
	if (cr6.getEQ()) goto loc_820AC114;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r9,64(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// blt cr6,0x820ac210
	if (cr6.getLT()) goto loc_820AC210;
loc_820AC114:
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// bne cr6,0x820ac1f0
	if (!cr6.getEQ()) goto loc_820AC1F0;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// subf r10,r17,r11
	ctx.r10.s64 = r11.s64 - r17.s64;
	// lwz r11,3316(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3316);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x820ac1bc
	if (cr6.getEQ()) goto loc_820AC1BC;
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// beq cr6,0x820ac1bc
	if (cr6.getEQ()) goto loc_820AC1BC;
	// lwz r10,3320(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3320);
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// beq cr6,0x820ac1bc
	if (cr6.getEQ()) goto loc_820AC1BC;
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// beq cr6,0x820ac1bc
	if (cr6.getEQ()) goto loc_820AC1BC;
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// beq cr6,0x820ac1bc
	if (cr6.getEQ()) goto loc_820AC1BC;
	// cmpwi cr6,r11,16
	cr6.compare<int32_t>(r11.s32, 16, xer);
	// beq cr6,0x820ac1bc
	if (cr6.getEQ()) goto loc_820AC1BC;
	// cmpwi cr6,r10,14
	cr6.compare<int32_t>(ctx.r10.s32, 14, xer);
	// beq cr6,0x820ac1bc
	if (cr6.getEQ()) goto loc_820AC1BC;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// cmpwi cr6,r16,0
	cr6.compare<int32_t>(r16.s32, 0, xer);
	// bne cr6,0x820ac1a4
	if (!cr6.getEQ()) goto loc_820AC1A4;
	// lwz r4,3280(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 3280);
	// lwz r3,60(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// bl 0x820c0d48
	sub_820C0D48(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ac1bc
	if (!cr6.getEQ()) goto loc_820AC1BC;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// li r10,5
	ctx.r10.s64 = 5;
	// stw r10,3320(r11)
	PPC_STORE_U32(r11.u32 + 3320, ctx.r10.u32);
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// stw r23,3340(r11)
	PPC_STORE_U32(r11.u32 + 3340, r23.u32);
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// stw r23,3348(r11)
	PPC_STORE_U32(r11.u32 + 3348, r23.u32);
	// b 0x820ac1bc
	goto loc_820AC1BC;
loc_820AC1A4:
	// lwz r3,2344(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// lwz r4,60(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// bl 0x820c0d48
	sub_820C0D48(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ac1bc
	if (!cr6.getEQ()) goto loc_820AC1BC;
	// stw r23,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r23.u32);
loc_820AC1BC:
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// lwz r4,60(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// bl 0x820a7508
	sub_820A7508(ctx, base);
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// add r11,r17,r11
	r11.u64 = r17.u64 + r11.u64;
	// lwz r10,2348(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2348);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// mr r27,r10
	r27.u64 = ctx.r10.u64;
	// bge cr6,0x820ac1e4
	if (!cr6.getLT()) goto loc_820AC1E4;
	// lwz r27,2344(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 2344);
loc_820AC1E4:
	// li r11,7
	r11.s64 = 7;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820ac214
	goto loc_820AC214;
loc_820AC1F0:
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x820a09e0
	sub_820A09E0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ac210
	if (cr6.getEQ()) goto loc_820AC210;
	// li r11,8
	r11.s64 = 8;
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
loc_820AC210:
	// lwz r27,84(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_820AC214:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,6
	cr6.compare<int32_t>(r11.s32, 6, xer);
	// beq cr6,0x820ac228
	if (cr6.getEQ()) goto loc_820AC228;
	// cmpwi cr6,r11,7
	cr6.compare<int32_t>(r11.s32, 7, xer);
	// bne cr6,0x820ac274
	if (!cr6.getEQ()) goto loc_820AC274;
loc_820AC228:
	// addi r4,r31,124
	ctx.r4.s64 = r31.s64 + 124;
	// fmr f1,f24
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f24.f64;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// stfs f30,172(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 172, temp.u32);
	// fmr f1,f23
	ctx.f1.f64 = f23.f64;
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// fmr f1,f23
	ctx.f1.f64 = f23.f64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fsubs f0,f26,f0
	f0.f64 = double(float(f26.f64 - f0.f64));
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// stfs f0,176(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 176, temp.u32);
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,180(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 180, temp.u32);
	// b 0x820ac274
	goto loc_820AC274;
loc_820AC270:
	// lwz r27,84(r1)
	r27.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
loc_820AC274:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// lis r29,-32014
	r29.s64 = -2098069504;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// bne cr6,0x820ac5e8
	if (!cr6.getEQ()) goto loc_820AC5E8;
	// li r30,23
	r30.s64 = 23;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820ac298
	if (!cr6.getGT()) goto loc_820AC298;
	// li r30,12
	r30.s64 = 12;
loc_820AC298:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ac4d4
	if (!cr6.getEQ()) goto loc_820AC4D4;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820ac2b8
	if (!cr6.getGT()) goto loc_820AC2B8;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x820c9f38
	sub_820C9F38(ctx, base);
loc_820AC2B8:
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x820aabe8
	sub_820AABE8(ctx, base);
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// stw r23,4224(r11)
	PPC_STORE_U32(r11.u32 + 4224, r23.u32);
	// lwz r11,-6384(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820ac4d4
	if (!cr6.getGT()) goto loc_820AC4D4;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r11,128(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 128);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x820ac4d4
	if (cr6.getEQ()) goto loc_820AC4D4;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x820a09e0
	sub_820A09E0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ac4d4
	if (cr6.getEQ()) goto loc_820AC4D4;
	// lwz r11,-1736(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1736);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ac4d4
	if (!cr6.getEQ()) goto loc_820AC4D4;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r11,480(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 480);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ac4d4
	if (!cr6.getEQ()) goto loc_820AC4D4;
	// cmplwi cr6,r27,88
	cr6.compare<uint32_t>(r27.u32, 88, xer);
	// bgt cr6,0x820ac4b8
	if (cr6.getGT()) goto loc_820AC4B8;
	// lis r12,-32245
	r12.s64 = -2113208320;
	// addi r12,r12,-15568
	r12.s64 = r12.s64 + -15568;
	// rlwinm r0,r27,2,0,29
	r0.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r27.u64) {
	case 0:
		goto loc_820AC4D4;
	case 1:
		goto loc_820AC4D4;
	case 2:
		goto loc_820AC4A0;
	case 3:
		goto loc_820AC4A0;
	case 4:
		goto loc_820AC4B8;
	case 5:
		goto loc_820AC4B8;
	case 6:
		goto loc_820AC4B8;
	case 7:
		goto loc_820AC4B8;
	case 8:
		goto loc_820AC4B8;
	case 9:
		goto loc_820AC4B8;
	case 10:
		goto loc_820AC4B8;
	case 11:
		goto loc_820AC4B8;
	case 12:
		goto loc_820AC4B8;
	case 13:
		goto loc_820AC4B8;
	case 14:
		goto loc_820AC4B8;
	case 15:
		goto loc_820AC4B8;
	case 16:
		goto loc_820AC4B8;
	case 17:
		goto loc_820AC4B8;
	case 18:
		goto loc_820AC4B8;
	case 19:
		goto loc_820AC4B8;
	case 20:
		goto loc_820AC4B8;
	case 21:
		goto loc_820AC4B8;
	case 22:
		goto loc_820AC494;
	case 23:
		goto loc_820AC4D4;
	case 24:
		goto loc_820AC4B8;
	case 25:
		goto loc_820AC4B8;
	case 26:
		goto loc_820AC4D4;
	case 27:
		goto loc_820AC4AC;
	case 28:
		goto loc_820AC4AC;
	case 29:
		goto loc_820AC4AC;
	case 30:
		goto loc_820AC4D4;
	case 31:
		goto loc_820AC4D4;
	case 32:
		goto loc_820AC4D4;
	case 33:
		goto loc_820AC4D4;
	case 34:
		goto loc_820AC4D4;
	case 35:
		goto loc_820AC4B8;
	case 36:
		goto loc_820AC4B8;
	case 37:
		goto loc_820AC4B8;
	case 38:
		goto loc_820AC4B8;
	case 39:
		goto loc_820AC4B8;
	case 40:
		goto loc_820AC4D4;
	case 41:
		goto loc_820AC4B8;
	case 42:
		goto loc_820AC4B8;
	case 43:
		goto loc_820AC4B8;
	case 44:
		goto loc_820AC4B8;
	case 45:
		goto loc_820AC4B8;
	case 46:
		goto loc_820AC4B8;
	case 47:
		goto loc_820AC4D4;
	case 48:
		goto loc_820AC4D4;
	case 49:
		goto loc_820AC4B8;
	case 50:
		goto loc_820AC4B8;
	case 51:
		goto loc_820AC4B8;
	case 52:
		goto loc_820AC4B8;
	case 53:
		goto loc_820AC4B8;
	case 54:
		goto loc_820AC4B8;
	case 55:
		goto loc_820AC4B8;
	case 56:
		goto loc_820AC4B8;
	case 57:
		goto loc_820AC4B8;
	case 58:
		goto loc_820AC4B8;
	case 59:
		goto loc_820AC4B8;
	case 60:
		goto loc_820AC4D4;
	case 61:
		goto loc_820AC4D4;
	case 62:
		goto loc_820AC4B8;
	case 63:
		goto loc_820AC4B8;
	case 64:
		goto loc_820AC4B8;
	case 65:
		goto loc_820AC4B8;
	case 66:
		goto loc_820AC4B8;
	case 67:
		goto loc_820AC4B8;
	case 68:
		goto loc_820AC4B8;
	case 69:
		goto loc_820AC4B8;
	case 70:
		goto loc_820AC4B8;
	case 71:
		goto loc_820AC4B8;
	case 72:
		goto loc_820AC4B8;
	case 73:
		goto loc_820AC4B8;
	case 74:
		goto loc_820AC4B8;
	case 75:
		goto loc_820AC4B8;
	case 76:
		goto loc_820AC4B8;
	case 77:
		goto loc_820AC4B8;
	case 78:
		goto loc_820AC4B8;
	case 79:
		goto loc_820AC4B8;
	case 80:
		goto loc_820AC4B8;
	case 81:
		goto loc_820AC4B8;
	case 82:
		goto loc_820AC4B8;
	case 83:
		goto loc_820AC4B8;
	case 84:
		goto loc_820AC4B8;
	case 85:
		goto loc_820AC4B8;
	case 86:
		goto loc_820AC4B8;
	case 87:
		goto loc_820AC4B8;
	case 88:
		goto loc_820AC4D4;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-15148(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15148);
	// lwz r16,-15148(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15148);
	// lwz r16,-15200(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15200);
	// lwz r16,-15200(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15200);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15212(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15212);
	// lwz r16,-15148(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15148);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15148(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15148);
	// lwz r16,-15188(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15188);
	// lwz r16,-15188(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15188);
	// lwz r16,-15188(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15188);
	// lwz r16,-15148(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15148);
	// lwz r16,-15148(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15148);
	// lwz r16,-15148(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15148);
	// lwz r16,-15148(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15148);
	// lwz r16,-15148(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15148);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15148(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15148);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15148(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15148);
	// lwz r16,-15148(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15148);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15148(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15148);
	// lwz r16,-15148(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15148);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15176(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15176);
	// lwz r16,-15148(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -15148);
loc_820AC494:
	// li r8,5550
	ctx.r8.s64 = 5550;
	// li r4,242
	ctx.r4.s64 = 242;
	// b 0x820ac4c0
	goto loc_820AC4C0;
loc_820AC4A0:
	// li r8,5555
	ctx.r8.s64 = 5555;
	// li r4,233
	ctx.r4.s64 = 233;
	// b 0x820ac4c0
	goto loc_820AC4C0;
loc_820AC4AC:
	// li r8,5561
	ctx.r8.s64 = 5561;
	// li r4,235
	ctx.r4.s64 = 235;
	// b 0x820ac4c0
	goto loc_820AC4C0;
loc_820AC4B8:
	// li r8,5565
	ctx.r8.s64 = 5565;
	// li r4,232
	ctx.r4.s64 = 232;
loc_820AC4C0:
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// lwz r6,19944(r21)
	ctx.r6.u64 = PPC_LOAD_U32(r21.u32 + 19944);
	// li r5,0
	ctx.r5.s64 = 0;
	// lwz r3,19936(r20)
	ctx.r3.u64 = PPC_LOAD_U32(r20.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
loc_820AC4D4:
	// lwz r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpw cr6,r8,r30
	cr6.compare<int32_t>(ctx.r8.s32, r30.s32, xer);
	// bge cr6,0x820ac5dc
	if (!cr6.getLT()) goto loc_820AC5DC;
	// mr r11,r27
	r11.u64 = r27.u64;
	// cmpwi cr6,r27,1
	cr6.compare<int32_t>(r27.s32, 1, xer);
	// bne cr6,0x820ac4f4
	if (!cr6.getEQ()) goto loc_820AC4F4;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r11,8376(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8376);
loc_820AC4F4:
	// mulli r11,r11,56
	r11.s64 = r11.s64 * 56;
	// lwzx r11,r11,r14
	r11.u64 = PPC_LOAD_U32(r11.u32 + r14.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ac5dc
	if (cr6.getEQ()) goto loc_820AC5DC;
	// mulli r11,r27,56
	r11.s64 = r27.s64 * 56;
	// addi r10,r14,8
	ctx.r10.s64 = r14.s64 + 8;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820ac524
	if (!cr6.getEQ()) goto loc_820AC524;
	// addi r10,r14,12
	ctx.r10.s64 = r14.s64 + 12;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820ac528
	goto loc_820AC528;
loc_820AC524:
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
loc_820AC528:
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm r10,r10,0,20,20
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x800;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820ac5dc
	if (cr6.getEQ()) goto loc_820AC5DC;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820ac54c
	if (!cr6.getEQ()) goto loc_820AC54C;
	// addi r10,r14,12
	ctx.r10.s64 = r14.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820ac550
	goto loc_820AC550;
loc_820AC54C:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_820AC550:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,18,18
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820ac5dc
	if (!cr6.getEQ()) goto loc_820AC5DC;
	// subf r11,r8,r30
	r11.s64 = r30.s64 - ctx.r8.s64;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// extsw r10,r30
	ctx.r10.s64 = r30.s32;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// addi r4,r31,124
	ctx.r4.s64 = r31.s64 + 124;
	// std r10,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r10.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f13,f13,f24
	ctx.f13.f64 = double(float(ctx.f13.f64 * f24.f64));
	// fdivs f31,f13,f0
	f31.f64 = double(float(ctx.f13.f64 / f0.f64));
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// stfs f30,172(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 172, temp.u32);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fsubs f0,f26,f0
	f0.f64 = double(float(f26.f64 - f0.f64));
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// stfs f0,176(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 176, temp.u32);
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,180(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 180, temp.u32);
	// b 0x820ac5e8
	goto loc_820AC5E8;
loc_820AC5DC:
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
loc_820AC5E8:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,9
	cr6.compare<int32_t>(r11.s32, 9, xer);
	// bne cr6,0x820ac67c
	if (!cr6.getEQ()) goto loc_820AC67C;
	// mulli r11,r27,56
	r11.s64 = r27.s64 * 56;
	// addi r10,r14,8
	ctx.r10.s64 = r14.s64 + 8;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820ac614
	if (!cr6.getEQ()) goto loc_820AC614;
	// addi r10,r14,12
	ctx.r10.s64 = r14.s64 + 12;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820ac618
	goto loc_820AC618;
loc_820AC614:
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
loc_820AC618:
	// lhz r10,32(r10)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r10.u32 + 32);
	// lwz r8,44(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// extsh r10,r10
	ctx.r10.s64 = ctx.r10.s16;
	// cmpw cr6,r8,r10
	cr6.compare<int32_t>(ctx.r8.s32, ctx.r10.s32, xer);
	// blt cr6,0x820ac654
	if (cr6.getLT()) goto loc_820AC654;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820ac640
	if (!cr6.getEQ()) goto loc_820AC640;
	// addi r10,r14,12
	ctx.r10.s64 = r14.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820ac644
	goto loc_820AC644;
loc_820AC640:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_820AC644:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,10,10
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ac670
	if (cr6.getEQ()) goto loc_820AC670;
loc_820AC654:
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x820aab28
	sub_820AAB28(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x820ac670
	if (!cr6.getGT()) goto loc_820AC670;
	// li r11,10
	r11.s64 = 10;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820ac67c
	goto loc_820AC67C;
loc_820AC670:
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
loc_820AC67C:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// cmpwi cr6,r11,10
	cr6.compare<int32_t>(r11.s32, 10, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f21,14096(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14096);
	f21.f64 = double(temp.f32);
	// lfs f22,14420(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14420);
	f22.f64 = double(temp.f32);
	// bne cr6,0x820ac774
	if (!cr6.getEQ()) goto loc_820AC774;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpwi cr6,r11,16
	cr6.compare<int32_t>(r11.s32, 16, xer);
	// bge cr6,0x820ac760
	if (!cr6.getLT()) goto loc_820AC760;
	// lbz r10,15(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 15);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820ac760
	if (cr6.getEQ()) goto loc_820AC760;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// addi r30,r31,124
	r30.s64 = r31.s64 + 124;
	// cmpwi cr6,r16,0
	cr6.compare<int32_t>(r16.s32, 0, xer);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f27,f0,f30
	f27.f64 = double(float(f0.f64 * f30.f64));
	// fmuls f31,f0,f22
	f31.f64 = double(float(f0.f64 * f22.f64));
	// bne cr6,0x820ac6e8
	if (!cr6.getEQ()) goto loc_820AC6E8;
	// fmr f1,f27
	ctx.f1.f64 = f27.f64;
	// b 0x820ac6ec
	goto loc_820AC6EC;
loc_820AC6E8:
	// fneg f1,f27
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = f27.u64 ^ 0x8000000000000000;
loc_820AC6EC:
	// bl 0x8210b968
	sub_8210B968(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// fmr f1,f27
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f27.f64;
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmr f27,f29
	f27.f64 = f29.f64;
	// cmpwi cr6,r27,25
	cr6.compare<int32_t>(r27.s32, 25, xer);
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// stfs f0,172(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 172, temp.u32);
	// bne cr6,0x820ac72c
	if (!cr6.getEQ()) goto loc_820AC72C;
	// fmr f27,f21
	f27.f64 = f21.f64;
loc_820AC72C:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fsubs f0,f26,f0
	f0.f64 = double(float(f26.f64 - f0.f64));
	// fmuls f0,f0,f27
	f0.f64 = double(float(f0.f64 * f27.f64));
	// stfs f0,176(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 176, temp.u32);
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,180(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 180, temp.u32);
	// b 0x820ac774
	goto loc_820AC774;
loc_820AC760:
	// li r11,11
	r11.s64 = 11;
	// stw r28,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r28.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
loc_820AC774:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,11
	cr6.compare<int32_t>(r11.s32, 11, xer);
	// bne cr6,0x820aca3c
	if (!cr6.getEQ()) goto loc_820ACA3C;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ac974
	if (!cr6.getEQ()) goto loc_820AC974;
	// lwz r11,-6384(r19)
	r11.u64 = PPC_LOAD_U32(r19.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820ac974
	if (!cr6.getGT()) goto loc_820AC974;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r11,128(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 128);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x820ac974
	if (cr6.getEQ()) goto loc_820AC974;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x820a09e0
	sub_820A09E0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ac974
	if (cr6.getEQ()) goto loc_820AC974;
	// lwz r11,-1736(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1736);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ac974
	if (!cr6.getEQ()) goto loc_820AC974;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r11,480(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 480);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ac974
	if (!cr6.getEQ()) goto loc_820AC974;
	// cmplwi cr6,r27,88
	cr6.compare<uint32_t>(r27.u32, 88, xer);
	// bgt cr6,0x820ac958
	if (cr6.getGT()) goto loc_820AC958;
	// lis r12,-32245
	r12.s64 = -2113208320;
	// addi r12,r12,-14348
	r12.s64 = r12.s64 + -14348;
	// rlwinm r0,r27,2,0,29
	r0.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r27.u64) {
	case 0:
		goto loc_820AC974;
	case 1:
		goto loc_820AC974;
	case 2:
		goto loc_820AC974;
	case 3:
		goto loc_820AC974;
	case 4:
		goto loc_820AC958;
	case 5:
		goto loc_820AC958;
	case 6:
		goto loc_820AC958;
	case 7:
		goto loc_820AC958;
	case 8:
		goto loc_820AC958;
	case 9:
		goto loc_820AC958;
	case 10:
		goto loc_820AC958;
	case 11:
		goto loc_820AC958;
	case 12:
		goto loc_820AC958;
	case 13:
		goto loc_820AC958;
	case 14:
		goto loc_820AC958;
	case 15:
		goto loc_820AC958;
	case 16:
		goto loc_820AC958;
	case 17:
		goto loc_820AC958;
	case 18:
		goto loc_820AC958;
	case 19:
		goto loc_820AC958;
	case 20:
		goto loc_820AC958;
	case 21:
		goto loc_820AC958;
	case 22:
		goto loc_820AC974;
	case 23:
		goto loc_820AC974;
	case 24:
		goto loc_820AC958;
	case 25:
		goto loc_820AC958;
	case 26:
		goto loc_820AC974;
	case 27:
		goto loc_820AC974;
	case 28:
		goto loc_820AC974;
	case 29:
		goto loc_820AC974;
	case 30:
		goto loc_820AC974;
	case 31:
		goto loc_820AC974;
	case 32:
		goto loc_820AC974;
	case 33:
		goto loc_820AC974;
	case 34:
		goto loc_820AC974;
	case 35:
		goto loc_820AC958;
	case 36:
		goto loc_820AC958;
	case 37:
		goto loc_820AC958;
	case 38:
		goto loc_820AC958;
	case 39:
		goto loc_820AC958;
	case 40:
		goto loc_820AC974;
	case 41:
		goto loc_820AC958;
	case 42:
		goto loc_820AC958;
	case 43:
		goto loc_820AC958;
	case 44:
		goto loc_820AC958;
	case 45:
		goto loc_820AC958;
	case 46:
		goto loc_820AC958;
	case 47:
		goto loc_820AC974;
	case 48:
		goto loc_820AC974;
	case 49:
		goto loc_820AC958;
	case 50:
		goto loc_820AC958;
	case 51:
		goto loc_820AC958;
	case 52:
		goto loc_820AC958;
	case 53:
		goto loc_820AC958;
	case 54:
		goto loc_820AC958;
	case 55:
		goto loc_820AC958;
	case 56:
		goto loc_820AC958;
	case 57:
		goto loc_820AC958;
	case 58:
		goto loc_820AC958;
	case 59:
		goto loc_820AC958;
	case 60:
		goto loc_820AC974;
	case 61:
		goto loc_820AC974;
	case 62:
		goto loc_820AC958;
	case 63:
		goto loc_820AC958;
	case 64:
		goto loc_820AC958;
	case 65:
		goto loc_820AC958;
	case 66:
		goto loc_820AC958;
	case 67:
		goto loc_820AC958;
	case 68:
		goto loc_820AC958;
	case 69:
		goto loc_820AC958;
	case 70:
		goto loc_820AC958;
	case 71:
		goto loc_820AC958;
	case 72:
		goto loc_820AC958;
	case 73:
		goto loc_820AC958;
	case 74:
		goto loc_820AC958;
	case 75:
		goto loc_820AC958;
	case 76:
		goto loc_820AC958;
	case 77:
		goto loc_820AC958;
	case 78:
		goto loc_820AC958;
	case 79:
		goto loc_820AC958;
	case 80:
		goto loc_820AC958;
	case 81:
		goto loc_820AC958;
	case 82:
		goto loc_820AC958;
	case 83:
		goto loc_820AC958;
	case 84:
		goto loc_820AC958;
	case 85:
		goto loc_820AC958;
	case 86:
		goto loc_820AC958;
	case 87:
		goto loc_820AC958;
	case 88:
		goto loc_820AC974;
	default:
		__builtin_unreachable();
	}
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13992(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13992);
	// lwz r16,-13964(r10)
	r16.u64 = PPC_LOAD_U32(ctx.r10.u32 + -13964);
loc_820AC958:
	// li r8,5680
	ctx.r8.s64 = 5680;
	// lwz r6,19944(r21)
	ctx.r6.u64 = PPC_LOAD_U32(r21.u32 + 19944);
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// lwz r3,19936(r20)
	ctx.r3.u64 = PPC_LOAD_U32(r20.u32 + 19936);
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,50
	ctx.r4.s64 = 50;
	// bl 0x82144920
	sub_82144920(ctx, base);
loc_820AC974:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r10,64(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// blt cr6,0x820ac9a4
	if (cr6.getLT()) goto loc_820AC9A4;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// ble cr6,0x820ac9a4
	if (!cr6.getGT()) goto loc_820AC9A4;
	// li r11,12
	r11.s64 = 12;
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820aca3c
	goto loc_820ACA3C;
loc_820AC9A4:
	// addi r30,r31,124
	r30.s64 = r31.s64 + 124;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// cmpwi cr6,r16,0
	cr6.compare<int32_t>(r16.s32, 0, xer);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bne cr6,0x820ac9c0
	if (!cr6.getEQ()) goto loc_820AC9C0;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// b 0x820ac9c8
	goto loc_820AC9C8;
loc_820AC9C0:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,14416(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14416);
	ctx.f1.f64 = double(temp.f32);
loc_820AC9C8:
	// bl 0x8210b968
	sub_8210B968(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// fmr f1,f24
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f24.f64;
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f1,2752(r11)
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = PPC_LOAD_U64(r11.u32 + 2752);
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// cmpwi cr6,r27,25
	cr6.compare<int32_t>(r27.s32, 25, xer);
	// fmr f31,f29
	f31.f64 = f29.f64;
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// stfs f0,172(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 172, temp.u32);
	// bne cr6,0x820aca0c
	if (!cr6.getEQ()) goto loc_820ACA0C;
	// fmr f31,f21
	f31.f64 = f21.f64;
loc_820ACA0C:
	// fmr f1,f23
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f23.f64;
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// fmr f1,f23
	ctx.f1.f64 = f23.f64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fsubs f0,f26,f0
	f0.f64 = double(float(f26.f64 - f0.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// stfs f0,176(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 176, temp.u32);
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,180(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 180, temp.u32);
loc_820ACA3C:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f25,14412(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14412);
	f25.f64 = double(temp.f32);
	// bne cr6,0x820acbb8
	if (!cr6.getEQ()) goto loc_820ACBB8;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820aca6c
	if (!cr6.getEQ()) goto loc_820ACA6C;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x820aabe8
	sub_820AABE8(ctx, base);
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// stw r23,4224(r11)
	PPC_STORE_U32(r11.u32 + 4224, r23.u32);
loc_820ACA6C:
	// lwz r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpwi cr6,r8,23
	cr6.compare<int32_t>(ctx.r8.s32, 23, xer);
	// bge cr6,0x820acbac
	if (!cr6.getLT()) goto loc_820ACBAC;
	// mr r11,r27
	r11.u64 = r27.u64;
	// cmpwi cr6,r27,1
	cr6.compare<int32_t>(r27.s32, 1, xer);
	// bne cr6,0x820aca8c
	if (!cr6.getEQ()) goto loc_820ACA8C;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r11,8376(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8376);
loc_820ACA8C:
	// mulli r11,r11,56
	r11.s64 = r11.s64 * 56;
	// lwzx r11,r11,r14
	r11.u64 = PPC_LOAD_U32(r11.u32 + r14.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820acbac
	if (cr6.getEQ()) goto loc_820ACBAC;
	// mulli r11,r27,56
	r11.s64 = r27.s64 * 56;
	// addi r10,r14,8
	ctx.r10.s64 = r14.s64 + 8;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820acabc
	if (!cr6.getEQ()) goto loc_820ACABC;
	// addi r10,r14,12
	ctx.r10.s64 = r14.s64 + 12;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820acac0
	goto loc_820ACAC0;
loc_820ACABC:
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
loc_820ACAC0:
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm r10,r10,0,20,20
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x800;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820acbac
	if (cr6.getEQ()) goto loc_820ACBAC;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820acae4
	if (!cr6.getEQ()) goto loc_820ACAE4;
	// addi r10,r14,12
	ctx.r10.s64 = r14.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820acae8
	goto loc_820ACAE8;
loc_820ACAE4:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_820ACAE8:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,18,18
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820acbac
	if (!cr6.getEQ()) goto loc_820ACBAC;
	// subfic r11,r8,23
	xer.ca = ctx.r8.u32 <= 23;
	r11.s64 = 23 - ctx.r8.s64;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// addi r30,r31,124
	r30.s64 = r31.s64 + 124;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// cmpwi cr6,r16,0
	cr6.compare<int32_t>(r16.s32, 0, xer);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f27,f0,f30
	f27.f64 = double(float(f0.f64 * f30.f64));
	// fmuls f31,f0,f25
	f31.f64 = double(float(f0.f64 * f25.f64));
	// bne cr6,0x820acb34
	if (!cr6.getEQ()) goto loc_820ACB34;
	// fmr f1,f27
	ctx.f1.f64 = f27.f64;
	// b 0x820acb38
	goto loc_820ACB38;
loc_820ACB34:
	// fneg f1,f27
	ctx.fpscr.disableFlushMode();
	ctx.f1.u64 = f27.u64 ^ 0x8000000000000000;
loc_820ACB38:
	// bl 0x8210b968
	sub_8210B968(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// fmr f1,f27
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f27.f64;
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmr f27,f29
	f27.f64 = f29.f64;
	// cmpwi cr6,r27,25
	cr6.compare<int32_t>(r27.s32, 25, xer);
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// stfs f0,172(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 172, temp.u32);
	// bne cr6,0x820acb78
	if (!cr6.getEQ()) goto loc_820ACB78;
	// fmr f27,f21
	f27.f64 = f21.f64;
loc_820ACB78:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fsubs f0,f26,f0
	f0.f64 = double(float(f26.f64 - f0.f64));
	// fmuls f0,f0,f27
	f0.f64 = double(float(f0.f64 * f27.f64));
	// stfs f0,176(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 176, temp.u32);
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,180(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 180, temp.u32);
	// b 0x820acbb8
	goto loc_820ACBB8;
loc_820ACBAC:
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
loc_820ACBB8:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,14
	cr6.compare<int32_t>(r11.s32, 14, xer);
	// bne cr6,0x820acc4c
	if (!cr6.getEQ()) goto loc_820ACC4C;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpwi cr6,r11,16
	cr6.compare<int32_t>(r11.s32, 16, xer);
	// bge cr6,0x820acc3c
	if (!cr6.getLT()) goto loc_820ACC3C;
	// lbz r10,15(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 15);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820acc3c
	if (cr6.getEQ()) goto loc_820ACC3C;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// addi r4,r31,124
	ctx.r4.s64 = r31.s64 + 124;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f31,f0,f22
	f31.f64 = double(float(f0.f64 * f22.f64));
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// stfs f30,172(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 172, temp.u32);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fsubs f0,f26,f0
	f0.f64 = double(float(f26.f64 - f0.f64));
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// stfs f0,176(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 176, temp.u32);
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,180(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 180, temp.u32);
	// b 0x820acc4c
	goto loc_820ACC4C;
loc_820ACC3C:
	// li r11,15
	r11.s64 = 15;
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
loc_820ACC4C:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,15
	cr6.compare<int32_t>(r11.s32, 15, xer);
	// bne cr6,0x820acd48
	if (!cr6.getEQ()) goto loc_820ACD48;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820acc74
	if (cr6.getEQ()) goto loc_820ACC74;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x820a09e0
	sub_820A09E0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820acca8
	if (!cr6.getEQ()) goto loc_820ACCA8;
loc_820ACC74:
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// lwz r4,60(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// bl 0x820a0ad8
	sub_820A0AD8(ctx, base);
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// add r11,r17,r11
	r11.u64 = r17.u64 + r11.u64;
	// stw r4,2348(r11)
	PPC_STORE_U32(r11.u32 + 2348, ctx.r4.u32);
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// add r11,r17,r11
	r11.u64 = r17.u64 + r11.u64;
	// lwz r10,2348(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2348);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// mr r27,r10
	r27.u64 = ctx.r10.u64;
	// bge cr6,0x820acca8
	if (!cr6.getLT()) goto loc_820ACCA8;
	// lwz r27,2344(r11)
	r27.u64 = PPC_LOAD_U32(r11.u32 + 2344);
loc_820ACCA8:
	// addi r11,r16,578
	r11.s64 = r16.s64 + 578;
	// lwz r10,-1364(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x820accf0
	if (cr6.getGT()) goto loc_820ACCF0;
	// addi r11,r16,580
	r11.s64 = r16.s64 + 580;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820acd04
	if (!cr6.getEQ()) goto loc_820ACD04;
	// addi r11,r16,2097
	r11.s64 = r16.s64 + 2097;
	// lwz r10,-1364(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820acd04
	if (!cr6.getLT()) goto loc_820ACD04;
loc_820ACCF0:
	// li r11,16
	r11.s64 = 16;
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820acd48
	goto loc_820ACD48;
loc_820ACD04:
	// addi r4,r31,124
	ctx.r4.s64 = r31.s64 + 124;
	// fmr f1,f24
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f24.f64;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// stfs f30,172(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 172, temp.u32);
	// fmr f1,f23
	ctx.f1.f64 = f23.f64;
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// fmr f1,f23
	ctx.f1.f64 = f23.f64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fsubs f0,f26,f0
	f0.f64 = double(float(f26.f64 - f0.f64));
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// stfs f0,176(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 176, temp.u32);
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,180(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 180, temp.u32);
loc_820ACD48:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,16
	cr6.compare<int32_t>(r11.s32, 16, xer);
	// bne cr6,0x820ace88
	if (!cr6.getEQ()) goto loc_820ACE88;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820acd8c
	if (!cr6.getEQ()) goto loc_820ACD8C;
	// cmpwi cr6,r27,32
	cr6.compare<int32_t>(r27.s32, 32, xer);
	// bgt cr6,0x820acd8c
	if (cr6.getGT()) goto loc_820ACD8C;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820acd7c
	if (!cr6.getGT()) goto loc_820ACD7C;
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x820c9f38
	sub_820C9F38(ctx, base);
loc_820ACD7C:
	// mr r3,r16
	ctx.r3.u64 = r16.u64;
	// bl 0x820aabe8
	sub_820AABE8(ctx, base);
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// stw r23,4224(r11)
	PPC_STORE_U32(r11.u32 + 4224, r23.u32);
loc_820ACD8C:
	// lwz r8,32(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpwi cr6,r8,23
	cr6.compare<int32_t>(ctx.r8.s32, 23, xer);
	// bge cr6,0x820ace7c
	if (!cr6.getLT()) goto loc_820ACE7C;
	// mr r11,r27
	r11.u64 = r27.u64;
	// cmpwi cr6,r27,1
	cr6.compare<int32_t>(r27.s32, 1, xer);
	// bne cr6,0x820acdac
	if (!cr6.getEQ()) goto loc_820ACDAC;
	// lwz r11,-1364(r18)
	r11.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r11,8376(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8376);
loc_820ACDAC:
	// mulli r11,r11,56
	r11.s64 = r11.s64 * 56;
	// lwzx r11,r11,r14
	r11.u64 = PPC_LOAD_U32(r11.u32 + r14.u32);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ace7c
	if (cr6.getEQ()) goto loc_820ACE7C;
	// mulli r11,r27,56
	r11.s64 = r27.s64 * 56;
	// addi r10,r14,8
	ctx.r10.s64 = r14.s64 + 8;
	// lwzx r9,r11,r10
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820acddc
	if (!cr6.getEQ()) goto loc_820ACDDC;
	// addi r10,r14,12
	ctx.r10.s64 = r14.s64 + 12;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820acde0
	goto loc_820ACDE0;
loc_820ACDDC:
	// mr r10,r26
	ctx.r10.u64 = r26.u64;
loc_820ACDE0:
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm r10,r10,0,20,20
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x800;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820ace7c
	if (cr6.getEQ()) goto loc_820ACE7C;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x820ace04
	if (!cr6.getEQ()) goto loc_820ACE04;
	// addi r10,r14,12
	ctx.r10.s64 = r14.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820ace08
	goto loc_820ACE08;
loc_820ACE04:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_820ACE08:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,18,18
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820ace7c
	if (!cr6.getEQ()) goto loc_820ACE7C;
	// subfic r11,r8,23
	xer.ca = ctx.r8.u32 <= 23;
	r11.s64 = 23 - ctx.r8.s64;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// addi r4,r31,124
	ctx.r4.s64 = r31.s64 + 124;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f31,f0,f25
	f31.f64 = double(float(f0.f64 * f25.f64));
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// stfs f30,172(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 172, temp.u32);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fsubs f0,f26,f0
	f0.f64 = double(float(f26.f64 - f0.f64));
	// fmuls f0,f0,f29
	f0.f64 = double(float(f0.f64 * f29.f64));
	// stfs f0,176(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 176, temp.u32);
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,180(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 180, temp.u32);
	// b 0x820ace88
	goto loc_820ACE88;
loc_820ACE7C:
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
loc_820ACE88:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,17
	cr6.compare<int32_t>(r11.s32, 17, xer);
	// beq cr6,0x820acebc
	if (cr6.getEQ()) goto loc_820ACEBC;
	// cmpwi cr6,r11,18
	cr6.compare<int32_t>(r11.s32, 18, xer);
	// beq cr6,0x820acebc
	if (cr6.getEQ()) goto loc_820ACEBC;
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// beq cr6,0x820acebc
	if (cr6.getEQ()) goto loc_820ACEBC;
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// beq cr6,0x820acebc
	if (cr6.getEQ()) goto loc_820ACEBC;
	// cmpwi cr6,r11,21
	cr6.compare<int32_t>(r11.s32, 21, xer);
	// beq cr6,0x820acebc
	if (cr6.getEQ()) goto loc_820ACEBC;
	// cmpwi cr6,r11,22
	cr6.compare<int32_t>(r11.s32, 22, xer);
	// bne cr6,0x820ad00c
	if (!cr6.getEQ()) goto loc_820AD00C;
loc_820ACEBC:
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpwi cr6,r11,17
	cr6.compare<int32_t>(r11.s32, 17, xer);
	// extsw r9,r10
	ctx.r9.s64 = ctx.r10.s32;
	// std r9,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r9.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f31,f0
	f31.f64 = double(float(f0.f64));
	// beq cr6,0x820acee4
	if (cr6.getEQ()) goto loc_820ACEE4;
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// bne cr6,0x820acf70
	if (!cr6.getEQ()) goto loc_820ACF70;
loc_820ACEE4:
	// cmpwi cr6,r10,16
	cr6.compare<int32_t>(ctx.r10.s32, 16, xer);
	// blt cr6,0x820acf70
	if (cr6.getLT()) goto loc_820ACF70;
	// li r11,95
	r11.s64 = 95;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// li r11,96
	r11.s64 = 96;
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
	// li r11,97
	r11.s64 = 97;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r6,19944(r21)
	ctx.r6.u64 = PPC_LOAD_U32(r21.u32 + 19944);
	// lis r10,-21846
	ctx.r10.s64 = -1431699456;
	// lwz r3,19936(r20)
	ctx.r3.u64 = PPC_LOAD_U32(r20.u32 + 19936);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// ori r10,r10,43691
	ctx.r10.u64 = ctx.r10.u64 | 43691;
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// mulhwu r10,r11,r10
	ctx.r10.u64 = (uint64_t(r11.u32) * uint64_t(ctx.r10.u32)) >> 32;
	// rlwinm r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// li r8,5835
	ctx.r8.s64 = 5835;
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// li r5,0
	ctx.r5.s64 = 0;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r4,r11,r4
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r4.u32);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,17
	cr6.compare<int32_t>(r11.s32, 17, xer);
	// li r11,18
	r11.s64 = 18;
	// beq cr6,0x820acf6c
	if (cr6.getEQ()) goto loc_820ACF6C;
	// li r11,21
	r11.s64 = 21;
loc_820ACF6C:
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
loc_820ACF70:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// beq cr6,0x820acfb0
	if (cr6.getEQ()) goto loc_820ACFB0;
	// cmpwi cr6,r11,22
	cr6.compare<int32_t>(r11.s32, 22, xer);
	// beq cr6,0x820acfb0
	if (cr6.getEQ()) goto loc_820ACFB0;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// cmpwi cr6,r10,24
	cr6.compare<int32_t>(ctx.r10.s32, 24, xer);
	// blt cr6,0x820acfb0
	if (cr6.getLT()) goto loc_820ACFB0;
	// cmpwi cr6,r11,17
	cr6.compare<int32_t>(r11.s32, 17, xer);
	// stb r15,12(r31)
	PPC_STORE_U8(r31.u32 + 12, r15.u8);
	// beq cr6,0x820acfa8
	if (cr6.getEQ()) goto loc_820ACFA8;
	// cmpwi cr6,r11,18
	cr6.compare<int32_t>(r11.s32, 18, xer);
	// li r11,22
	r11.s64 = 22;
	// bne cr6,0x820acfac
	if (!cr6.getEQ()) goto loc_820ACFAC;
loc_820ACFA8:
	// li r11,19
	r11.s64 = 19;
loc_820ACFAC:
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
loc_820ACFB0:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,17
	cr6.compare<int32_t>(r11.s32, 17, xer);
	// beq cr6,0x820acfd8
	if (cr6.getEQ()) goto loc_820ACFD8;
	// cmpwi cr6,r11,18
	cr6.compare<int32_t>(r11.s32, 18, xer);
	// beq cr6,0x820acfd8
	if (cr6.getEQ()) goto loc_820ACFD8;
	// cmpwi cr6,r11,19
	cr6.compare<int32_t>(r11.s32, 19, xer);
	// beq cr6,0x820acfd8
	if (cr6.getEQ()) goto loc_820ACFD8;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r3,r11,11848
	ctx.r3.s64 = r11.s64 + 11848;
	// b 0x820acfe0
	goto loc_820ACFE0;
loc_820ACFD8:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r3,r11,11488
	ctx.r3.s64 = r11.s64 + 11488;
loc_820ACFE0:
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// addi r5,r31,124
	ctx.r5.s64 = r31.s64 + 124;
	// bl 0x820a0830
	sub_820A0830(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ad000
	if (cr6.getEQ()) goto loc_820AD000;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// b 0x820ad00c
	goto loc_820AD00C;
loc_820AD000:
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
loc_820AD00C:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// beq cr6,0x820ad030
	if (cr6.getEQ()) goto loc_820AD030;
	// cmpwi cr6,r11,31
	cr6.compare<int32_t>(r11.s32, 31, xer);
	// beq cr6,0x820ad030
	if (cr6.getEQ()) goto loc_820AD030;
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// beq cr6,0x820ad030
	if (cr6.getEQ()) goto loc_820AD030;
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// bne cr6,0x820ad110
	if (!cr6.getEQ()) goto loc_820AD110;
loc_820AD030:
	// lwz r9,32(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// extsw r10,r9
	ctx.r10.s64 = ctx.r9.s32;
	// std r10,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, ctx.r10.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// beq cr6,0x820ad0a8
	if (cr6.getEQ()) goto loc_820AD0A8;
	// cmpwi cr6,r11,31
	cr6.compare<int32_t>(r11.s32, 31, xer);
	// beq cr6,0x820ad0a8
	if (cr6.getEQ()) goto loc_820AD0A8;
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// beq cr6,0x820ad06c
	if (cr6.getEQ()) goto loc_820AD06C;
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// bne cr6,0x820ad0e8
	if (!cr6.getEQ()) goto loc_820AD0E8;
loc_820AD06C:
	// lwz r10,-1364(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r10,8376(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8376);
	// cmpwi cr6,r10,17
	cr6.compare<int32_t>(ctx.r10.s32, 17, xer);
	// bne cr6,0x820ad088
	if (!cr6.getEQ()) goto loc_820AD088;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// addi r3,r10,14664
	ctx.r3.s64 = ctx.r10.s64 + 14664;
	// b 0x820ad090
	goto loc_820AD090;
loc_820AD088:
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// addi r3,r10,13904
	ctx.r3.s64 = ctx.r10.s64 + 13904;
loc_820AD090:
	// cmpwi cr6,r11,33
	cr6.compare<int32_t>(r11.s32, 33, xer);
	// beq cr6,0x820ad0e8
	if (cr6.getEQ()) goto loc_820AD0E8;
	// cmpwi cr6,r9,30
	cr6.compare<int32_t>(ctx.r9.s32, 30, xer);
	// blt cr6,0x820ad0e8
	if (cr6.getLT()) goto loc_820AD0E8;
	// li r11,33
	r11.s64 = 33;
	// b 0x820ad0e0
	goto loc_820AD0E0;
loc_820AD0A8:
	// lwz r10,-1364(r18)
	ctx.r10.u64 = PPC_LOAD_U32(r18.u32 + -1364);
	// lwz r10,8376(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8376);
	// cmpwi cr6,r10,17
	cr6.compare<int32_t>(ctx.r10.s32, 17, xer);
	// bne cr6,0x820ad0c4
	if (!cr6.getEQ()) goto loc_820AD0C4;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// addi r3,r10,14264
	ctx.r3.s64 = ctx.r10.s64 + 14264;
	// b 0x820ad0cc
	goto loc_820AD0CC;
loc_820AD0C4:
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// addi r3,r10,13544
	ctx.r3.s64 = ctx.r10.s64 + 13544;
loc_820AD0CC:
	// cmpwi cr6,r11,31
	cr6.compare<int32_t>(r11.s32, 31, xer);
	// beq cr6,0x820ad0e8
	if (cr6.getEQ()) goto loc_820AD0E8;
	// cmpwi cr6,r9,30
	cr6.compare<int32_t>(ctx.r9.s32, 30, xer);
	// blt cr6,0x820ad0e8
	if (cr6.getLT()) goto loc_820AD0E8;
	// li r11,31
	r11.s64 = 31;
loc_820AD0E0:
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// stb r15,12(r31)
	PPC_STORE_U8(r31.u32 + 12, r15.u8);
loc_820AD0E8:
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// addi r5,r31,124
	ctx.r5.s64 = r31.s64 + 124;
	// bl 0x820a0830
	sub_820A0830(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ad104
	if (cr6.getEQ()) goto loc_820AD104;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// b 0x820ad110
	goto loc_820AD110;
loc_820AD104:
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
loc_820AD110:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,26
	cr6.compare<int32_t>(r11.s32, 26, xer);
	// bne cr6,0x820ad190
	if (!cr6.getEQ()) goto loc_820AD190;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820ad184
	if (!cr6.getGT()) goto loc_820AD184;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// addi r3,r11,12640
	ctx.r3.s64 = r11.s64 + 12640;
	// extsw r11,r10
	r11.s64 = ctx.r10.s32;
	// addi r5,r31,124
	ctx.r5.s64 = r31.s64 + 124;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// bl 0x820a0830
	sub_820A0830(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ad164
	if (cr6.getEQ()) goto loc_820AD164;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// b 0x820ad190
	goto loc_820AD190;
loc_820AD164:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// li r10,27
	ctx.r10.s64 = 27;
	// stb r23,14(r31)
	PPC_STORE_U8(r31.u32 + 14, r23.u8);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stb r15,12(r31)
	PPC_STORE_U8(r31.u32 + 12, r15.u8);
	// stw r10,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r10.u32);
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// b 0x820ad188
	goto loc_820AD188;
loc_820AD184:
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
loc_820AD188:
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
loc_820AD190:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,27
	cr6.compare<int32_t>(r11.s32, 27, xer);
	// bne cr6,0x820ad1e8
	if (!cr6.getEQ()) goto loc_820AD1E8;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// addi r3,r11,12856
	ctx.r3.s64 = r11.s64 + 12856;
	// extsw r11,r10
	r11.s64 = ctx.r10.s32;
	// addi r5,r31,124
	ctx.r5.s64 = r31.s64 + 124;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// bl 0x820a0830
	sub_820A0830(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ad1d8
	if (cr6.getEQ()) goto loc_820AD1D8;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// b 0x820ad1e8
	goto loc_820AD1E8;
loc_820AD1D8:
	// stb r15,14(r31)
	PPC_STORE_U8(r31.u32 + 14, r15.u8);
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
loc_820AD1E8:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,23
	cr6.compare<int32_t>(r11.s32, 23, xer);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r28,r11,12424
	r28.s64 = r11.s64 + 12424;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r29,r11,12208
	r29.s64 = r11.s64 + 12208;
	// bne cr6,0x820ad294
	if (!cr6.getEQ()) goto loc_820AD294;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820ad288
	if (!cr6.getGT()) goto loc_820AD288;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ad228
	if (cr6.getEQ()) goto loc_820AD228;
loc_820AD21C:
	// li r11,24
	r11.s64 = 24;
	// stw r11,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r11.u32);
	// b 0x820ad294
	goto loc_820AD294;
loc_820AD228:
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// addi r30,r31,124
	r30.s64 = r31.s64 + 124;
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// bl 0x820a0830
	sub_820A0830(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ad264
	if (cr6.getEQ()) goto loc_820AD264;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// b 0x820ad294
	goto loc_820AD294;
loc_820AD264:
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x820a0830
	sub_820A0830(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ad21c
	if (cr6.getEQ()) goto loc_820AD21C;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// b 0x820ad294
	goto loc_820AD294;
loc_820AD288:
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
loc_820AD294:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,24
	cr6.compare<int32_t>(r11.s32, 24, xer);
	// bne cr6,0x820ad31c
	if (!cr6.getEQ()) goto loc_820AD31C;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820ad310
	if (!cr6.getGT()) goto loc_820AD310;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// addi r5,r31,124
	ctx.r5.s64 = r31.s64 + 124;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// bl 0x820a0830
	sub_820A0830(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ad2e4
	if (cr6.getEQ()) goto loc_820AD2E4;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// b 0x820ad31c
	goto loc_820AD31C;
loc_820AD2E4:
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// stb r23,14(r31)
	PPC_STORE_U8(r31.u32 + 14, r23.u8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820ad2f8
	if (!cr6.getEQ()) goto loc_820AD2F8;
	// stb r15,12(r31)
	PPC_STORE_U8(r31.u32 + 12, r15.u8);
loc_820AD2F8:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// li r10,25
	ctx.r10.s64 = 25;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r10,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r10.u32);
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
	// b 0x820ad314
	goto loc_820AD314;
loc_820AD310:
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
loc_820AD314:
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
loc_820AD31C:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,25
	cr6.compare<int32_t>(r11.s32, 25, xer);
	// bne cr6,0x820ad370
	if (!cr6.getEQ()) goto loc_820AD370;
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// addi r5,r31,124
	ctx.r5.s64 = r31.s64 + 124;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// bl 0x820a0830
	sub_820A0830(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ad360
	if (cr6.getEQ()) goto loc_820AD360;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// b 0x820ad370
	goto loc_820AD370;
loc_820AD360:
	// stb r15,14(r31)
	PPC_STORE_U8(r31.u32 + 14, r15.u8);
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
loc_820AD370:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,28
	cr6.compare<int32_t>(r11.s32, 28, xer);
	// bne cr6,0x820ad424
	if (!cr6.getEQ()) goto loc_820AD424;
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bgt cr6,0x820ad3c4
	if (cr6.getGT()) goto loc_820AD3C4;
	// mulli r11,r27,56
	r11.s64 = r27.s64 * 56;
	// addi r10,r14,8
	ctx.r10.s64 = r14.s64 + 8;
	// lwzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820ad3a8
	if (!cr6.getEQ()) goto loc_820AD3A8;
	// addi r10,r14,12
	ctx.r10.s64 = r14.s64 + 12;
	// lwzx r11,r11,r10
	r11.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// b 0x820ad3ac
	goto loc_820AD3AC;
loc_820AD3A8:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_820AD3AC:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// rlwinm r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820ad3c4
	if (!cr6.getEQ()) goto loc_820AD3C4;
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
	// b 0x820ad41c
	goto loc_820AD41C;
loc_820AD3C4:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// addi r3,r11,13072
	ctx.r3.s64 = r11.s64 + 13072;
	// extsw r11,r10
	r11.s64 = ctx.r10.s32;
	// addi r5,r31,124
	ctx.r5.s64 = r31.s64 + 124;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// bl 0x820a0830
	sub_820A0830(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ad400
	if (cr6.getEQ()) goto loc_820AD400;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// b 0x820ad424
	goto loc_820AD424;
loc_820AD400:
	// lwz r11,44(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 44);
	// li r10,29
	ctx.r10.s64 = 29;
	// stb r23,14(r31)
	PPC_STORE_U8(r31.u32 + 14, r23.u8);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stb r15,12(r31)
	PPC_STORE_U8(r31.u32 + 12, r15.u8);
	// stw r10,36(r31)
	PPC_STORE_U32(r31.u32 + 36, ctx.r10.u32);
	// stw r11,44(r31)
	PPC_STORE_U32(r31.u32 + 44, r11.u32);
loc_820AD41C:
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
loc_820AD424:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,29
	cr6.compare<int32_t>(r11.s32, 29, xer);
	// bne cr6,0x820ad47c
	if (!cr6.getEQ()) goto loc_820AD47C;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// mr r6,r16
	ctx.r6.u64 = r16.u64;
	// addi r3,r11,13288
	ctx.r3.s64 = r11.s64 + 13288;
	// extsw r11,r10
	r11.s64 = ctx.r10.s32;
	// addi r5,r31,124
	ctx.r5.s64 = r31.s64 + 124;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f1,f0
	ctx.f1.f64 = double(float(f0.f64));
	// bl 0x820a0830
	sub_820A0830(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ad46c
	if (cr6.getEQ()) goto loc_820AD46C;
	// stw r15,188(r31)
	PPC_STORE_U32(r31.u32 + 188, r15.u32);
	// b 0x820ad47c
	goto loc_820AD47C;
loc_820AD46C:
	// stb r15,14(r31)
	PPC_STORE_U8(r31.u32 + 14, r15.u8);
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
loc_820AD47C:
	// lwz r11,36(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 36);
	// cmpwi cr6,r11,36
	cr6.compare<int32_t>(r11.s32, 36, xer);
	// bne cr6,0x820ad528
	if (!cr6.getEQ()) goto loc_820AD528;
	// cmpwi cr6,r27,46
	cr6.compare<int32_t>(r27.s32, 46, xer);
	// bne cr6,0x820ad4a4
	if (!cr6.getEQ()) goto loc_820AD4A4;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ad510
	if (!cr6.getEQ()) goto loc_820AD510;
	// bl 0x820aa778
	sub_820AA778(ctx, base);
	// b 0x820ad510
	goto loc_820AD510;
loc_820AD4A4:
	// cmpwi cr6,r27,44
	cr6.compare<int32_t>(r27.s32, 44, xer);
	// bne cr6,0x820ad4c0
	if (!cr6.getEQ()) goto loc_820AD4C0;
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ad510
	if (!cr6.getEQ()) goto loc_820AD510;
	// bl 0x820aad28
	sub_820AAD28(ctx, base);
	// b 0x820ad510
	goto loc_820AD510;
loc_820AD4C0:
	// cmpwi cr6,r27,39
	cr6.compare<int32_t>(r27.s32, 39, xer);
	// beq cr6,0x820ad4e8
	if (cr6.getEQ()) goto loc_820AD4E8;
	// cmpwi cr6,r27,55
	cr6.compare<int32_t>(r27.s32, 55, xer);
	// beq cr6,0x820ad4e8
	if (cr6.getEQ()) goto loc_820AD4E8;
	// cmpwi cr6,r27,38
	cr6.compare<int32_t>(r27.s32, 38, xer);
	// beq cr6,0x820ad4e8
	if (cr6.getEQ()) goto loc_820AD4E8;
	// cmpwi cr6,r27,50
	cr6.compare<int32_t>(r27.s32, 50, xer);
	// beq cr6,0x820ad4e8
	if (cr6.getEQ()) goto loc_820AD4E8;
	// cmpwi cr6,r27,73
	cr6.compare<int32_t>(r27.s32, 73, xer);
	// bne cr6,0x820ad510
	if (!cr6.getEQ()) goto loc_820AD510;
loc_820AD4E8:
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ad510
	if (!cr6.getEQ()) goto loc_820AD510;
	// bl 0x820cde10
	sub_820CDE10(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820ad510
	if (cr6.getEQ()) goto loc_820AD510;
	// lwz r11,8(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lbz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// ori r10,r10,64
	ctx.r10.u64 = ctx.r10.u64 | 64;
	// stb r10,2(r11)
	PPC_STORE_U8(r11.u32 + 2, ctx.r10.u8);
loc_820AD510:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ad528
	if (cr6.getEQ()) goto loc_820AD528;
	// stw r23,36(r31)
	PPC_STORE_U32(r31.u32 + 36, r23.u32);
	// stw r23,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r23.u32);
	// stw r23,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r23.u32);
loc_820AD528:
	// addi r1,r1,432
	ctx.r1.s64 = ctx.r1.s64 + 432;
	// addi r12,r1,-152
	r12.s64 = ctx.r1.s64 + -152;
	// bl 0x823ed578
	// b 0x823ed150
	return;
}

__attribute__((alias("__imp__sub_820AD538"))) PPC_WEAK_FUNC(sub_820AD538);
PPC_FUNC_IMPL(__imp__sub_820AD538) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r30,-32014
	r30.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r29,0
	r29.s64 = 0;
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r29.u32);
	// lwz r10,4228(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4228);
	// stw r10,4232(r11)
	PPC_STORE_U32(r11.u32 + 4232, ctx.r10.u32);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// stw r31,4228(r11)
	PPC_STORE_U32(r11.u32 + 4228, r31.u32);
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ad5b8
	if (cr6.getEQ()) goto loc_820AD5B8;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ad5b8
	if (cr6.getEQ()) goto loc_820AD5B8;
	// bl 0x820ca520
	sub_820CA520(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ad5b8
	if (cr6.getEQ()) goto loc_820AD5B8;
	// bl 0x820ca338
	sub_820CA338(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820ad5b8
	if (cr6.getEQ()) goto loc_820AD5B8;
	// cntlzw r11,r31
	r11.u64 = r31.u32 == 0 ? 32 : __builtin_clz(r31.u32);
	// addi r3,r3,2220
	ctx.r3.s64 = ctx.r3.s64 + 2220;
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r4,r11,1
	ctx.r4.u64 = r11.u64 ^ 1;
	// bl 0x82176c80
	sub_82176C80(ctx, base);
loc_820AD5B8:
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r10,4228(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4228);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x820ad5e0
	if (!cr6.getEQ()) goto loc_820AD5E0;
	// lwz r10,4232(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4232);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x820ad5e0
	if (cr6.getEQ()) goto loc_820AD5E0;
	// stw r4,4224(r11)
	PPC_STORE_U32(r11.u32 + 4224, ctx.r4.u32);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
loc_820AD5E0:
	// lwz r10,4228(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4228);
	// lis r28,-32014
	r28.s64 = -2098069504;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x820ad9cc
	if (cr6.getEQ()) goto loc_820AD9CC;
	// lwz r8,4236(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4236);
	// lwz r9,-6384(r28)
	ctx.r9.u64 = PPC_LOAD_U32(r28.u32 + -6384);
	// lwz r10,2344(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// lwz r7,3280(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 3280);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r9,4236(r11)
	PPC_STORE_U32(r11.u32 + 4236, ctx.r9.u32);
	// beq cr6,0x820ad970
	if (cr6.getEQ()) goto loc_820AD970;
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// beq cr6,0x820ad970
	if (cr6.getEQ()) goto loc_820AD970;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// mulli r9,r10,56
	ctx.r9.s64 = ctx.r10.s64 * 56;
	// addi r11,r11,6504
	r11.s64 = r11.s64 + 6504;
	// addi r10,r11,8
	ctx.r10.s64 = r11.s64 + 8;
	// lwzx r6,r9,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// addi r8,r10,1240
	ctx.r8.s64 = ctx.r10.s64 + 1240;
	// bne cr6,0x820ad648
	if (!cr6.getEQ()) goto loc_820AD648;
	// addi r10,r11,12
	ctx.r10.s64 = r11.s64 + 12;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// b 0x820ad64c
	goto loc_820AD64C;
loc_820AD648:
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
loc_820AD64C:
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm r10,r10,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820ad750
	if (cr6.getEQ()) goto loc_820AD750;
	// mulli r10,r7,56
	ctx.r10.s64 = ctx.r7.s64 * 56;
	// addi r5,r11,8
	ctx.r5.s64 = r11.s64 + 8;
	// lwzx r5,r10,r5
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x820ad67c
	if (!cr6.getEQ()) goto loc_820AD67C;
	// addi r5,r11,12
	ctx.r5.s64 = r11.s64 + 12;
	// lwzx r10,r10,r5
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r5.u32);
	// b 0x820ad680
	goto loc_820AD680;
loc_820AD67C:
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
loc_820AD680:
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm r10,r10,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820ad750
	if (cr6.getEQ()) goto loc_820AD750;
	// lwz r7,-1364(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lwz r11,4236(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4236);
	// cmpwi cr6,r11,20
	cr6.compare<int32_t>(r11.s32, 20, xer);
	// ble cr6,0x820ad6f0
	if (!cr6.getGT()) goto loc_820AD6F0;
	// lwz r11,4240(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subfic r3,r11,1
	xer.ca = r11.u32 <= 1;
	ctx.r3.s64 = 1 - r11.s64;
	// stwx r4,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, ctx.r4.u32);
	// bl 0x820aa880
	sub_820AA880(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ad8b4
	if (!cr6.getEQ()) goto loc_820AD8B4;
	// lwz r11,4240(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// mulli r11,r11,936
	r11.s64 = r11.s64 * 936;
	// subf r11,r11,r7
	r11.s64 = ctx.r7.s64 - r11.s64;
	// lwz r11,3296(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 3296);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ad9d0
	if (cr6.getEQ()) goto loc_820AD9D0;
	// lwz r11,4240(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// addi r10,r1,84
	ctx.r10.s64 = ctx.r1.s64 + 84;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// stw r4,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r4.u32);
	// b 0x820ad9d0
	goto loc_820AD9D0;
loc_820AD6F0:
	// lwz r11,4232(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4232);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ad730
	if (!cr6.getEQ()) goto loc_820AD730;
	// lwz r6,4240(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// subfic r3,r6,1
	xer.ca = ctx.r6.u32 <= 1;
	ctx.r3.s64 = 1 - ctx.r6.s64;
	// bl 0x820aa880
	sub_820AA880(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ad720
	if (!cr6.getEQ()) goto loc_820AD720;
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
	// bl 0x820aa880
	sub_820AA880(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ad730
	if (!cr6.getEQ()) goto loc_820AD730;
loc_820AD720:
	// lwz r11,4240(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// subfic r11,r11,1
	xer.ca = r11.u32 <= 1;
	r11.s64 = 1 - r11.s64;
	// stw r11,4240(r7)
	PPC_STORE_U32(ctx.r7.u32 + 4240, r11.u32);
	// lwz r7,-1364(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + -1364);
loc_820AD730:
	// lwz r11,4240(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// addi r10,r1,84
	ctx.r10.s64 = ctx.r1.s64 + 84;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// stwx r4,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r4.u32);
	// stw r29,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r29.u32);
	// b 0x820ad9d0
	goto loc_820AD9D0;
loc_820AD750:
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// bne cr6,0x820ad764
	if (!cr6.getEQ()) goto loc_820AD764;
	// addi r10,r11,12
	ctx.r10.s64 = r11.s64 + 12;
	// lwzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// b 0x820ad768
	goto loc_820AD768;
loc_820AD764:
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
loc_820AD768:
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm r10,r10,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820ad86c
	if (!cr6.getEQ()) goto loc_820AD86C;
	// mulli r10,r7,56
	ctx.r10.s64 = ctx.r7.s64 * 56;
	// addi r7,r11,8
	ctx.r7.s64 = r11.s64 + 8;
	// lwzx r7,r10,r7
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// bne cr6,0x820ad798
	if (!cr6.getEQ()) goto loc_820AD798;
	// addi r7,r11,12
	ctx.r7.s64 = r11.s64 + 12;
	// lwzx r10,r10,r7
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r7.u32);
	// b 0x820ad79c
	goto loc_820AD79C;
loc_820AD798:
	// mr r10,r8
	ctx.r10.u64 = ctx.r8.u64;
loc_820AD79C:
	// lwz r10,108(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 108);
	// rlwinm r10,r10,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820ad86c
	if (!cr6.getEQ()) goto loc_820AD86C;
	// lwz r7,-1364(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lwz r11,4236(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4236);
	// cmpwi cr6,r11,30
	cr6.compare<int32_t>(r11.s32, 30, xer);
	// ble cr6,0x820ad80c
	if (!cr6.getGT()) goto loc_820AD80C;
	// lwz r11,4240(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subfic r3,r11,1
	xer.ca = r11.u32 <= 1;
	ctx.r3.s64 = 1 - r11.s64;
	// stwx r4,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, ctx.r4.u32);
	// bl 0x820aa880
	sub_820AA880(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ad8b4
	if (!cr6.getEQ()) goto loc_820AD8B4;
	// lwz r11,4240(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// mulli r11,r11,936
	r11.s64 = r11.s64 * 936;
	// subf r11,r11,r7
	r11.s64 = ctx.r7.s64 - r11.s64;
	// lwz r11,3296(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 3296);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ad9d0
	if (cr6.getEQ()) goto loc_820AD9D0;
	// lwz r11,4240(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// addi r10,r1,84
	ctx.r10.s64 = ctx.r1.s64 + 84;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// stw r4,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r4.u32);
	// b 0x820ad9d0
	goto loc_820AD9D0;
loc_820AD80C:
	// lwz r11,4232(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4232);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ad84c
	if (!cr6.getEQ()) goto loc_820AD84C;
	// lwz r6,4240(r7)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// subfic r3,r6,1
	xer.ca = ctx.r6.u32 <= 1;
	ctx.r3.s64 = 1 - ctx.r6.s64;
	// bl 0x820aa880
	sub_820AA880(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ad83c
	if (!cr6.getEQ()) goto loc_820AD83C;
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
	// bl 0x820aa880
	sub_820AA880(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ad84c
	if (!cr6.getEQ()) goto loc_820AD84C;
loc_820AD83C:
	// lwz r11,4240(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// subfic r11,r11,1
	xer.ca = r11.u32 <= 1;
	r11.s64 = 1 - r11.s64;
	// stw r11,4240(r7)
	PPC_STORE_U32(ctx.r7.u32 + 4240, r11.u32);
	// lwz r7,-1364(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + -1364);
loc_820AD84C:
	// lwz r11,4240(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// addi r10,r1,84
	ctx.r10.s64 = ctx.r1.s64 + 84;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// stwx r4,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r4.u32);
	// stw r29,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r29.u32);
	// b 0x820ad9d0
	goto loc_820AD9D0;
loc_820AD86C:
	// lwz r7,-1364(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lwz r10,4236(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4236);
	// cmpwi cr6,r10,30
	cr6.compare<int32_t>(ctx.r10.s32, 30, xer);
	// ble cr6,0x820ad8cc
	if (!cr6.getGT()) goto loc_820AD8CC;
	// lwz r11,4240(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subfic r3,r11,1
	xer.ca = r11.u32 <= 1;
	ctx.r3.s64 = 1 - r11.s64;
	// stwx r4,r9,r10
	PPC_STORE_U32(ctx.r9.u32 + ctx.r10.u32, ctx.r4.u32);
	// bl 0x820aa880
	sub_820AA880(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ad8b4
	if (!cr6.getEQ()) goto loc_820AD8B4;
	// lwz r11,4240(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// mulli r11,r11,936
	r11.s64 = r11.s64 * 936;
	// subf r11,r11,r7
	r11.s64 = ctx.r7.s64 - r11.s64;
	// lwz r11,3296(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 3296);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ad9d0
	if (cr6.getEQ()) goto loc_820AD9D0;
loc_820AD8B4:
	// lwz r11,4240(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// addi r10,r1,84
	ctx.r10.s64 = ctx.r1.s64 + 84;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// stw r4,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r4.u32);
	// b 0x820ad9d0
	goto loc_820AD9D0;
loc_820AD8CC:
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// bne cr6,0x820ad8e0
	if (!cr6.getEQ()) goto loc_820AD8E0;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// b 0x820ad8e4
	goto loc_820AD8E4;
loc_820AD8E0:
	// mr r11,r8
	r11.u64 = ctx.r8.u64;
loc_820AD8E4:
	// lwz r11,108(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 108);
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm r6,r11,25,31,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 25) & 0x1;
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
	// bl 0x820aa880
	sub_820AA880(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ad948
	if (!cr6.getEQ()) goto loc_820AD948;
	// mulli r5,r6,936
	ctx.r5.s64 = ctx.r6.s64 * 936;
	// add r11,r5,r7
	r11.u64 = ctx.r5.u64 + ctx.r7.u64;
	// lwz r11,2360(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 2360);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ad948
	if (!cr6.getEQ()) goto loc_820AD948;
	// subfic r6,r6,1
	xer.ca = ctx.r6.u32 <= 1;
	ctx.r6.s64 = 1 - ctx.r6.s64;
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
	// bl 0x820aa880
	sub_820AA880(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820ad948
	if (!cr6.getEQ()) goto loc_820AD948;
	// subf r11,r5,r7
	r11.s64 = ctx.r7.s64 - ctx.r5.s64;
	// lwz r11,3296(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 3296);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ad948
	if (!cr6.getEQ()) goto loc_820AD948;
	// lwz r11,4240(r7)
	r11.u64 = PPC_LOAD_U32(ctx.r7.u32 + 4240);
	// subfic r11,r11,1
	xer.ca = r11.u32 <= 1;
	r11.s64 = 1 - r11.s64;
	// stw r11,4240(r7)
	PPC_STORE_U32(ctx.r7.u32 + 4240, r11.u32);
	// b 0x820ad94c
	goto loc_820AD94C;
loc_820AD948:
	// stw r6,4240(r7)
	PPC_STORE_U32(ctx.r7.u32 + 4240, ctx.r6.u32);
loc_820AD94C:
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// addi r10,r1,84
	ctx.r10.s64 = ctx.r1.s64 + 84;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lwz r11,4240(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4240);
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// stwx r4,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r4.u32);
	// stw r29,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r29.u32);
	// b 0x820ad9d0
	goto loc_820AD9D0;
loc_820AD970:
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lwz r10,4240(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4240);
	// mulli r10,r10,936
	ctx.r10.s64 = ctx.r10.s64 * 936;
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lwz r9,2344(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 2344);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x820ad9ac
	if (!cr6.getEQ()) goto loc_820AD9AC;
	// subf r10,r10,r11
	ctx.r10.s64 = r11.s64 - ctx.r10.s64;
	// lwz r10,3280(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 3280);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x820ad9ac
	if (cr6.getEQ()) goto loc_820AD9AC;
	// lwz r10,4240(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4240);
	// subfic r10,r10,1
	xer.ca = ctx.r10.u32 <= 1;
	ctx.r10.s64 = 1 - ctx.r10.s64;
	// stw r10,4240(r11)
	PPC_STORE_U32(r11.u32 + 4240, ctx.r10.u32);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
loc_820AD9AC:
	// lwz r11,4240(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4240);
	// addi r10,r1,84
	ctx.r10.s64 = ctx.r1.s64 + 84;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// stwx r4,r11,r9
	PPC_STORE_U32(r11.u32 + ctx.r9.u32, ctx.r4.u32);
	// stw r29,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r29.u32);
	// b 0x820ad9d0
	goto loc_820AD9D0;
loc_820AD9CC:
	// stw r29,4236(r11)
	PPC_STORE_U32(r11.u32 + 4236, r29.u32);
loc_820AD9D0:
	// li r3,0
	ctx.r3.s64 = 0;
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x820aae00
	sub_820AAE00(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x820aae00
	sub_820AAE00(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820a0c30
	sub_820A0C30(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x820a0c30
	sub_820A0C30(ctx, base);
	// bl 0x820a4390
	sub_820A4390(ctx, base);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lwz r10,4248(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4248);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x820ada28
	if (cr6.getEQ()) goto loc_820ADA28;
	// addi r31,r11,4244
	r31.s64 = r11.s64 + 4244;
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x820d4ad0
	sub_820D4AD0(ctx, base);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// stw r29,4248(r11)
	PPC_STORE_U32(r11.u32 + 4248, r29.u32);
	// b 0x820ada48
	goto loc_820ADA48;
loc_820ADA28:
	// addi r31,r1,80
	r31.s64 = ctx.r1.s64 + 80;
	// bl 0x820b3c98
	sub_820B3C98(ctx, base);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x820d4ad0
	sub_820D4AD0(ctx, base);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r11,4244
	ctx.r3.s64 = r11.s64 + 4244;
	// bl 0x820d4c88
	sub_820D4C88(ctx, base);
loc_820ADA48:
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lwz r4,3280(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 3280);
	// lwz r3,2344(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 2344);
	// bl 0x820c1ec0
	sub_820C1EC0(ctx, base);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lwz r10,4888(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4888);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blt cr6,0x820adb0c
	if (cr6.getLT()) goto loc_820ADB0C;
	// rotlwi r9,r10,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lwz r10,-6384(r28)
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + -6384);
	// addi r31,r11,2344
	r31.s64 = r11.s64 + 2344;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r10,4888(r11)
	PPC_STORE_U32(r11.u32 + 4888, ctx.r10.u32);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lwz r10,4888(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4888);
	// cmpwi cr6,r10,300
	cr6.compare<int32_t>(ctx.r10.s32, 300, xer);
	// bge cr6,0x820adae4
	if (!cr6.getLT()) goto loc_820ADAE4;
	// lwz r3,468(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 468);
	// addi r31,r31,468
	r31.s64 = r31.s64 + 468;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820adaa8
	if (cr6.getEQ()) goto loc_820ADAA8;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820adb0c
	if (!cr6.getEQ()) goto loc_820ADB0C;
loc_820ADAA8:
	// bl 0x8209f588
	sub_8209F588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820adb0c
	if (!cr6.getEQ()) goto loc_820ADB0C;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r8,6476
	ctx.r8.s64 = 6476;
	// addi r7,r11,13992
	ctx.r7.s64 = r11.s64 + 13992;
	// lis r11,-31994
	r11.s64 = -2096758784;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,246
	ctx.r4.s64 = 246;
	// lwz r6,19944(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + 19944);
	// lis r11,-31994
	r11.s64 = -2096758784;
	// lwz r3,19936(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 19936);
	// bl 0x82144920
	sub_82144920(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_820ADAE4:
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r10,4888(r11)
	PPC_STORE_U32(r11.u32 + 4888, ctx.r10.u32);
	// lwz r3,468(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 468);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820adb0c
	if (cr6.getEQ()) goto loc_820ADB0C;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820adb0c
	if (cr6.getEQ()) goto loc_820ADB0C;
	// lwz r3,468(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 468);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820ADB0C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820ADB18"))) PPC_WEAK_FUNC(sub_820ADB18);
PPC_FUNC_IMPL(__imp__sub_820ADB18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r31,0
	r31.s64 = 0;
	// lis r8,-32014
	ctx.r8.s64 = -2098069504;
	// mr r9,r31
	ctx.r9.u64 = r31.u64;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// addi r11,r11,-5968
	r11.s64 = r11.s64 + -5968;
	// stw r9,-5952(r8)
	PPC_STORE_U32(ctx.r8.u32 + -5952, ctx.r9.u32);
	// lis r8,-32014
	ctx.r8.s64 = -2098069504;
	// lbz r7,-3852(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + -3852);
	// stw r31,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r31.u32);
	// stw r31,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r31.u32);
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// stw r9,-3860(r8)
	PPC_STORE_U32(ctx.r8.u32 + -3860, ctx.r9.u32);
	// lis r8,-32014
	ctx.r8.s64 = -2098069504;
	// stw r31,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r31.u32);
	// stw r31,12(r11)
	PPC_STORE_U32(r11.u32 + 12, r31.u32);
	// stw r9,-3856(r8)
	PPC_STORE_U32(ctx.r8.u32 + -3856, ctx.r9.u32);
	// bne cr6,0x820adbd8
	if (!cr6.getEQ()) goto loc_820ADBD8;
	// li r11,1
	r11.s64 = 1;
	// mr r30,r31
	r30.u64 = r31.u64;
	// stb r11,-3852(r10)
	PPC_STORE_U8(ctx.r10.u32 + -3852, r11.u8);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r29,r11,1196
	r29.s64 = r11.s64 + 1196;
	// lwz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820adbc4
	if (cr6.getEQ()) goto loc_820ADBC4;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// mr r11,r31
	r11.u64 = r31.u64;
	// addi r28,r10,13948
	r28.s64 = ctx.r10.s64 + 13948;
loc_820ADB98:
	// addi r10,r29,4
	ctx.r10.s64 = r29.s64 + 4;
	// lwz r7,0(r3)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// lwz r6,8(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lwzx r4,r11,r10
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x8211db38
	sub_8211DB38(ctx, base);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// rlwinm r11,r30,3,0,28
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 3) & 0xFFFFFFF8;
	// lwzx r3,r11,r29
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x820adb98
	if (!cr6.getEQ()) goto loc_820ADB98;
loc_820ADBC4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820a0b78
	sub_820A0B78(ctx, base);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmpwi cr6,r31,89
	cr6.compare<int32_t>(r31.s32, 89, xer);
	// blt cr6,0x820adbc4
	if (cr6.getLT()) goto loc_820ADBC4;
loc_820ADBD8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820ADBE0"))) PPC_WEAK_FUNC(sub_820ADBE0);
PPC_FUNC_IMPL(__imp__sub_820ADBE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stfd f30,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f30.u64);
	// stfd f31,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, f31.u64);
	// stwu r1,-1088(r1)
	ea = -1088 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r30,0
	r30.s64 = 0;
	// li r29,-1
	r29.s64 = -1;
	// li r27,1
	r27.s64 = 1;
	// lfs f31,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f31,156(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 156, temp.u32);
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// stfs f31,160(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 160, temp.u32);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r29.u32);
	// stfs f31,164(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 164, temp.u32);
	// stw r30,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r30.u32);
	// stfs f31,168(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 168, temp.u32);
	// stb r30,92(r1)
	PPC_STORE_U8(ctx.r1.u32 + 92, r30.u8);
	// lfs f30,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f30.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f31,172(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 172, temp.u32);
	// stb r30,93(r1)
	PPC_STORE_U8(ctx.r1.u32 + 93, r30.u8);
	// stfs f31,176(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 176, temp.u32);
	// stb r27,94(r1)
	PPC_STORE_U8(ctx.r1.u32 + 94, r27.u8);
	// stfs f31,180(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 180, temp.u32);
	// stb r30,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, r30.u8);
	// stfs f31,184(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 184, temp.u32);
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r30.u32);
	// lfs f0,6580(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6580);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f31,188(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 188, temp.u32);
	// stw r30,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r30.u32);
	// stfs f31,192(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 192, temp.u32);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r30.u32);
	// stfs f31,196(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 196, temp.u32);
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// stfs f31,200(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 200, temp.u32);
	// stw r30,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r30.u32);
	// lfs f13,14452(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14452);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f13,328(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 328, temp.u32);
	// stw r30,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r30.u32);
	// stfs f30,204(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 204, temp.u32);
	// stw r30,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r30.u32);
	// stfs f31,208(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 208, temp.u32);
	// stw r30,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r30.u32);
	// stfs f31,212(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 212, temp.u32);
	// stw r30,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r30.u32);
	// lfs f13,14448(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14448);
	ctx.f13.f64 = double(temp.f32);
	// stw r30,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r30.u32);
	// stfs f31,216(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 216, temp.u32);
	// stw r30,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r30.u32);
	// stfs f31,220(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 220, temp.u32);
	// stw r30,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r30.u32);
	// stfs f30,224(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 224, temp.u32);
	// stw r30,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r30.u32);
	// stfs f31,228(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 228, temp.u32);
	// stw r30,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r30.u32);
	// stfs f31,232(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 232, temp.u32);
	// stw r30,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r30.u32);
	// stfs f31,236(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 236, temp.u32);
	// stw r30,268(r1)
	PPC_STORE_U32(ctx.r1.u32 + 268, r30.u32);
	// stfs f31,240(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 240, temp.u32);
	// stfs f30,244(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 244, temp.u32);
	// stfs f31,248(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 248, temp.u32);
	// stfs f31,252(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 252, temp.u32);
	// stfs f31,256(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 256, temp.u32);
	// stfs f31,260(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 260, temp.u32);
	// stfs f30,264(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 264, temp.u32);
	// stfs f31,272(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 272, temp.u32);
	// stfs f31,276(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 276, temp.u32);
	// stfs f31,280(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 280, temp.u32);
	// stfs f31,284(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 284, temp.u32);
	// stfs f31,288(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 288, temp.u32);
	// stfs f0,292(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 292, temp.u32);
	// stfs f31,296(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 296, temp.u32);
	// stfs f30,300(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 300, temp.u32);
	// stfs f31,304(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 304, temp.u32);
	// stfs f31,308(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 308, temp.u32);
	// stfs f31,312(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 312, temp.u32);
	// stfs f31,316(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 316, temp.u32);
	// stfs f31,320(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 320, temp.u32);
	// stfs f31,324(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 324, temp.u32);
	// stfs f31,332(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 332, temp.u32);
	// stfs f13,336(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 336, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f0,400(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 400, temp.u32);
	// stfs f0,412(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 412, temp.u32);
	// li r5,384
	ctx.r5.s64 = 384;
	// stfs f0,424(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 424, temp.u32);
	// li r4,0
	ctx.r4.s64 = 0;
	// stfs f0,436(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 436, temp.u32);
	// addi r3,r1,632
	ctx.r3.s64 = ctx.r1.s64 + 632;
	// stfs f31,340(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 340, temp.u32);
	// stw r30,488(r1)
	PPC_STORE_U32(ctx.r1.u32 + 488, r30.u32);
	// lfs f0,14108(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14108);
	f0.f64 = double(temp.f32);
	// stw r30,504(r1)
	PPC_STORE_U32(ctx.r1.u32 + 504, r30.u32);
	// stfs f31,344(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 344, temp.u32);
	// stw r30,548(r1)
	PPC_STORE_U32(ctx.r1.u32 + 548, r30.u32);
	// stfs f31,348(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 348, temp.u32);
	// stw r30,552(r1)
	PPC_STORE_U32(ctx.r1.u32 + 552, r30.u32);
	// stfs f31,352(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 352, temp.u32);
	// stw r30,556(r1)
	PPC_STORE_U32(ctx.r1.u32 + 556, r30.u32);
	// stfs f31,356(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 356, temp.u32);
	// stw r30,560(r1)
	PPC_STORE_U32(ctx.r1.u32 + 560, r30.u32);
	// stfs f31,360(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 360, temp.u32);
	// stb r29,564(r1)
	PPC_STORE_U8(ctx.r1.u32 + 564, r29.u8);
	// stfs f31,364(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 364, temp.u32);
	// stb r30,565(r1)
	PPC_STORE_U8(ctx.r1.u32 + 565, r30.u8);
	// stfs f31,368(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 368, temp.u32);
	// stw r30,620(r1)
	PPC_STORE_U32(ctx.r1.u32 + 620, r30.u32);
	// stfs f31,372(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 372, temp.u32);
	// stw r30,624(r1)
	PPC_STORE_U32(ctx.r1.u32 + 624, r30.u32);
	// stfs f31,376(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 376, temp.u32);
	// stw r30,628(r1)
	PPC_STORE_U32(ctx.r1.u32 + 628, r30.u32);
	// stfs f31,380(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 380, temp.u32);
	// stfs f31,384(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 384, temp.u32);
	// stfs f31,388(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 388, temp.u32);
	// stfs f31,392(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 392, temp.u32);
	// stfs f31,396(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 396, temp.u32);
	// stfs f31,404(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 404, temp.u32);
	// stfs f31,408(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 408, temp.u32);
	// stfs f31,416(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 416, temp.u32);
	// stfs f31,420(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 420, temp.u32);
	// stfs f31,428(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 428, temp.u32);
	// stfs f31,432(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 432, temp.u32);
	// stfs f31,440(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 440, temp.u32);
	// stfs f30,444(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 444, temp.u32);
	// stfs f31,448(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 448, temp.u32);
	// stfs f31,452(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 452, temp.u32);
	// stfs f30,456(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 456, temp.u32);
	// stfs f31,460(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 460, temp.u32);
	// stfs f31,464(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 464, temp.u32);
	// stfs f30,468(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 468, temp.u32);
	// stfs f31,472(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 472, temp.u32);
	// stfs f31,476(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 476, temp.u32);
	// stfs f30,480(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 480, temp.u32);
	// stfs f31,484(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 484, temp.u32);
	// stfs f31,492(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 492, temp.u32);
	// stfs f30,496(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 496, temp.u32);
	// stfs f30,500(r1)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r1.u32 + 500, temp.u32);
	// stfs f31,508(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 508, temp.u32);
	// stfs f31,512(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 512, temp.u32);
	// stfs f31,516(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 516, temp.u32);
	// stfs f31,520(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 520, temp.u32);
	// stfs f31,524(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 524, temp.u32);
	// stfs f31,528(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 528, temp.u32);
	// stfs f31,532(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 532, temp.u32);
	// stfs f31,536(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 536, temp.u32);
	// stfs f31,540(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 540, temp.u32);
	// stfs f0,544(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 544, temp.u32);
	// stfs f31,568(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 568, temp.u32);
	// stfs f31,572(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 572, temp.u32);
	// stfs f31,576(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 576, temp.u32);
	// stfs f31,580(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 580, temp.u32);
	// stfs f31,584(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 584, temp.u32);
	// stfs f31,588(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 588, temp.u32);
	// stfs f31,592(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 592, temp.u32);
	// stfs f31,596(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 596, temp.u32);
	// stfs f31,600(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 600, temp.u32);
	// stfs f31,604(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 604, temp.u32);
	// stfs f31,608(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 608, temp.u32);
	// stfs f31,612(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 612, temp.u32);
	// stfs f31,616(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 616, temp.u32);
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r28,r11,1180
	r28.s64 = r11.s64 + 1180;
	// lwz r3,0(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 0);
	// bl 0x8209cbc8
	sub_8209CBC8(ctx, base);
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r3,2328(r11)
	PPC_STORE_U32(r11.u32 + 2328, ctx.r3.u32);
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x820adeb8
	if (!cr6.getEQ()) goto loc_820ADEB8;
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,4(r28)
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + 4);
	// bl 0x8209cbc8
	sub_8209CBC8(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r3,2332(r11)
	PPC_STORE_U32(r11.u32 + 2332, ctx.r3.u32);
loc_820ADEB8:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r5,936
	ctx.r5.s64 = 936;
	// stw r30,2312(r11)
	PPC_STORE_U32(r11.u32 + 2312, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r30,2316(r11)
	PPC_STORE_U32(r11.u32 + 2316, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r30,2320(r11)
	PPC_STORE_U32(r11.u32 + 2320, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r30,2324(r11)
	PPC_STORE_U32(r11.u32 + 2324, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r29,8388(r11)
	PPC_STORE_U32(r11.u32 + 8388, r29.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r29,8392(r11)
	PPC_STORE_U32(r11.u32 + 8392, r29.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r30,8400(r11)
	PPC_STORE_U32(r11.u32 + 8400, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r30,8404(r11)
	PPC_STORE_U32(r11.u32 + 8404, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r3,r11,2344
	ctx.r3.s64 = r11.s64 + 2344;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r11,3280
	ctx.r3.s64 = r11.s64 + 3280;
	// li r5,936
	ctx.r5.s64 = 936;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// li r11,4580
	r11.s64 = 4580;
loc_820ADF24:
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stwx r30,r11,r10
	PPC_STORE_U32(r11.u32 + ctx.r10.u32, r30.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// cmpwi cr6,r11,4700
	cr6.compare<int32_t>(r11.s32, 4700, xer);
	// blt cr6,0x820adf24
	if (cr6.getLT()) goto loc_820ADF24;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// lis r11,-32014
	r11.s64 = -2098069504;
loc_820ADF40:
	// lwz r9,-908(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + -908);
	// stwx r30,r10,r9
	PPC_STORE_U32(ctx.r10.u32 + ctx.r9.u32, r30.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmpwi cr6,r10,28
	cr6.compare<int32_t>(ctx.r10.s32, 28, xer);
	// blt cr6,0x820adf40
	if (cr6.getLT()) goto loc_820ADF40;
	// lwz r10,-908(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -908);
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r30,108(r10)
	PPC_STORE_U32(ctx.r10.u32 + 108, r30.u32);
	// lwz r10,-908(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -908);
	// stw r30,28(r10)
	PPC_STORE_U32(ctx.r10.u32 + 28, r30.u32);
	// lwz r11,-908(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -908);
	// stw r30,32(r11)
	PPC_STORE_U32(r11.u32 + 32, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r30,8280(r11)
	PPC_STORE_U32(r11.u32 + 8280, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r30,8284(r11)
	PPC_STORE_U32(r11.u32 + 8284, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f30,4216(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r11.u32 + 4216, temp.u32);
	// stfs f30,4220(r11)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r11.u32 + 4220, temp.u32);
	// stw r30,4224(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4224, r30.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r11,255
	r11.s64 = 255;
	// stw r30,4228(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4228, r30.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r30,4232(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4232, r30.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r30,4236(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4236, r30.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r30,4240(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4240, r30.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stb r11,4244(r10)
	PPC_STORE_U8(ctx.r10.u32 + 4244, r11.u8);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stb r11,4245(r10)
	PPC_STORE_U8(ctx.r10.u32 + 4245, r11.u8);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stb r11,4246(r10)
	PPC_STORE_U8(ctx.r10.u32 + 4246, r11.u8);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stb r30,4247(r11)
	PPC_STORE_U8(r11.u32 + 4247, r30.u8);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,14064(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14064);
	f0.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r27,4248(r11)
	PPC_STORE_U32(r11.u32 + 4248, r27.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r30,4252(r11)
	PPC_STORE_U32(r11.u32 + 4252, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f31,4256(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4256, temp.u32);
	// stfs f31,4260(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4260, temp.u32);
	// stfs f31,4264(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4264, temp.u32);
	// stfs f31,4268(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4268, temp.u32);
	// stfs f0,4272(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4272, temp.u32);
	// stfs f31,4276(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4276, temp.u32);
	// stfs f31,4280(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4280, temp.u32);
	// stfs f31,4284(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4284, temp.u32);
	// stfs f31,4288(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4288, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,14444(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14444);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,4292(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4292, temp.u32);
	// stfs f31,4296(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4296, temp.u32);
	// stfs f13,4300(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 4300, temp.u32);
	// stfs f31,4304(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4304, temp.u32);
	// stw r30,4376(r11)
	PPC_STORE_U32(r11.u32 + 4376, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r29,4888(r11)
	PPC_STORE_U32(r11.u32 + 4888, r29.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f31,4388(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4388, temp.u32);
	// stfs f31,4392(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4392, temp.u32);
	// stfs f31,4396(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4396, temp.u32);
	// stw r30,4400(r11)
	PPC_STORE_U32(r11.u32 + 4400, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f31,4404(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4404, temp.u32);
	// stfs f31,4408(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 4408, temp.u32);
	// bl 0x820a6b98
	sub_820A6B98(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820a6b98
	sub_820A6B98(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x820a6b98
	sub_820A6B98(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x820a6b98
	sub_820A6B98(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x820a6b98
	sub_820A6B98(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x820a6b98
	sub_820A6B98(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r10,2
	ctx.r10.s64 = 2;
	// stw r30,4380(r11)
	PPC_STORE_U32(r11.u32 + 4380, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r10,4572(r11)
	PPC_STORE_U32(r11.u32 + 4572, ctx.r10.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,3144
	r11.s64 = r11.s64 + 3144;
	// lfs f0,52(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 52);
	f0.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,4412(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4412, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,5832
	r11.s64 = r11.s64 + 5832;
	// lfs f0,52(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 52);
	f0.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,4416(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4416, temp.u32);
	// addi r1,r1,1088
	ctx.r1.s64 = ctx.r1.s64 + 1088;
	// lfd f30,-64(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f31,-56(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820AE0D8"))) PPC_WEAK_FUNC(sub_820AE0D8);
PPC_FUNC_IMPL(__imp__sub_820AE0D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-3832(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -3832);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// bgt cr6,0x820ae0f0
	if (cr6.getGT()) goto loc_820AE0F0;
	// li r11,0
	r11.s64 = 0;
loc_820AE0F0:
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE0F8"))) PPC_WEAK_FUNC(sub_820AE0F8);
PPC_FUNC_IMPL(__imp__sub_820AE0F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stw r3,15876(r11)
	PPC_STORE_U32(r11.u32 + 15876, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE108"))) PPC_WEAK_FUNC(sub_820AE108);
PPC_FUNC_IMPL(__imp__sub_820AE108) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r3,15876(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 15876);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE118"))) PPC_WEAK_FUNC(sub_820AE118);
PPC_FUNC_IMPL(__imp__sub_820AE118) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,0
	r11.s64 = 0;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// li r31,0
	r31.s64 = 0;
	// stb r11,-3847(r10)
	PPC_STORE_U8(ctx.r10.u32 + -3847, r11.u8);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-3836(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -3836);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x820ae150
	if (cr6.getLT()) goto loc_820AE150;
	// mr r31,r11
	r31.u64 = r11.u64;
loc_820AE150:
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r30,r11,15876
	r30.s64 = r11.s64 + 15876;
	// lwz r11,-4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -4);
	// cmpwi cr6,r11,90
	cr6.compare<int32_t>(r11.s32, 90, xer);
	// bne cr6,0x820ae16c
	if (!cr6.getEQ()) goto loc_820AE16C;
	// li r31,0
	r31.s64 = 0;
	// b 0x820ae1c0
	goto loc_820AE1C0;
loc_820AE16C:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ae1a0
	if (cr6.getEQ()) goto loc_820AE1A0;
	// bl 0x820f6290
	sub_820F6290(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82160588
	sub_82160588(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ae1c0
	if (cr6.getEQ()) goto loc_820AE1C0;
	// cmpwi cr6,r31,2
	cr6.compare<int32_t>(r31.s32, 2, xer);
	// bge cr6,0x820ae1c0
	if (!cr6.getLT()) goto loc_820AE1C0;
	// li r31,2
	r31.s64 = 2;
	// b 0x820ae1c0
	goto loc_820AE1C0;
loc_820AE1A0:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x820ae1c0
	if (!cr6.getEQ()) goto loc_820AE1C0;
	// li r31,1
	r31.s64 = 1;
	// bl 0x820f6290
	sub_820F6290(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// ble cr6,0x820ae1c0
	if (!cr6.getGT()) goto loc_820AE1C0;
	// bl 0x820f6290
	sub_820F6290(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
loc_820AE1C0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820cb848
	sub_820CB848(ctx, base);
	// lwz r3,-4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + -4);
	// bl 0x8209f5d8
	sub_8209F5D8(ctx, base);
	// bl 0x823d22e0
	sub_823D22E0(ctx, base);
	// bl 0x820ebbf8
	sub_820EBBF8(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ae1e8
	if (cr6.getEQ()) goto loc_820AE1E8;
	// bl 0x820ca888
	sub_820CA888(ctx, base);
loc_820AE1E8:
	// bl 0x820ebb98
	sub_820EBB98(ctx, base);
	// clrlwi r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820ae218
	if (cr6.getEQ()) goto loc_820AE218;
	// lwz r11,-4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -4);
	// cmpwi cr6,r11,90
	cr6.compare<int32_t>(r11.s32, 90, xer);
	// beq cr6,0x820ae210
	if (cr6.getEQ()) goto loc_820AE210;
	// bl 0x8217f708
	sub_8217F708(ctx, base);
	// bl 0x82159248
	sub_82159248(ctx, base);
	// b 0x820ae218
	goto loc_820AE218;
loc_820AE210:
	// bl 0x8217f790
	sub_8217F790(ctx, base);
	// bl 0x821592c0
	sub_821592C0(ctx, base);
loc_820AE218:
	// lwz r11,-4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -4);
	// cmpwi cr6,r11,90
	cr6.compare<int32_t>(r11.s32, 90, xer);
	// beq cr6,0x820ae22c
	if (cr6.getEQ()) goto loc_820AE22C;
	// bl 0x8217c108
	sub_8217C108(ctx, base);
	// bl 0x8217c118
	sub_8217C118(ctx, base);
loc_820AE22C:
	// li r11,1
	r11.s64 = 1;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE250"))) PPC_WEAK_FUNC(sub_820AE250);
PPC_FUNC_IMPL(__imp__sub_820AE250) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// bl 0x82136c50
	sub_82136C50(ctx, base);
	// bl 0x8209fee0
	sub_8209FEE0(ctx, base);
	// bl 0x8209cb28
	sub_8209CB28(ctx, base);
	// bl 0x8209f900
	sub_8209F900(ctx, base);
	// bl 0x820c9fc8
	sub_820C9FC8(ctx, base);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r11,15872(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 15872);
	// cmpwi cr6,r11,90
	cr6.compare<int32_t>(r11.s32, 90, xer);
	// beq cr6,0x820ae2f0
	if (cr6.getEQ()) goto loc_820AE2F0;
	// bl 0x82103300
	sub_82103300(ctx, base);
	// bl 0x820cab70
	sub_820CAB70(ctx, base);
	// li r31,0
	r31.s64 = 0;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x820ae2f0
	if (!cr6.getGT()) goto loc_820AE2F0;
	// lis r30,-32014
	r30.s64 = -2098069504;
loc_820AE2AC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820ca0b0
	sub_820CA0B0(ctx, base);
	// bl 0x820c9b40
	sub_820C9B40(ctx, base);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lhz r4,2306(r11)
	ctx.r4.u64 = PPC_LOAD_U16(r11.u32 + 2306);
	// lhz r3,2304(r11)
	ctx.r3.u64 = PPC_LOAD_U16(r11.u32 + 2304);
	// bl 0x8210e1a8
	sub_8210E1A8(ctx, base);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lhz r4,2310(r11)
	ctx.r4.u64 = PPC_LOAD_U16(r11.u32 + 2310);
	// lhz r3,2308(r11)
	ctx.r3.u64 = PPC_LOAD_U16(r11.u32 + 2308);
	// bl 0x8210e228
	sub_8210E228(ctx, base);
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x8209f170
	sub_8209F170(ctx, base);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpw cr6,r31,r3
	cr6.compare<int32_t>(r31.s32, ctx.r3.s32, xer);
	// blt cr6,0x820ae2ac
	if (cr6.getLT()) goto loc_820AE2AC;
loc_820AE2F0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE310"))) PPC_WEAK_FUNC(sub_820AE310);
PPC_FUNC_IMPL(__imp__sub_820AE310) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lbz r3,-3848(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + -3848);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE320"))) PPC_WEAK_FUNC(sub_820AE320);
PPC_FUNC_IMPL(__imp__sub_820AE320) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// stb r3,-3848(r11)
	PPC_STORE_U8(r11.u32 + -3848, ctx.r3.u8);
	// bl 0x8209ec28
	sub_8209EC28(ctx, base);
	// bl 0x823d22e0
	sub_823D22E0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE350"))) PPC_WEAK_FUNC(sub_820AE350);
PPC_FUNC_IMPL(__imp__sub_820AE350) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// stw r3,15868(r11)
	PPC_STORE_U32(r11.u32 + 15868, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE360"))) PPC_WEAK_FUNC(sub_820AE360);
PPC_FUNC_IMPL(__imp__sub_820AE360) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r3,15872(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 15872);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE370"))) PPC_WEAK_FUNC(sub_820AE370);
PPC_FUNC_IMPL(__imp__sub_820AE370) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lwz r11,15872(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 15872);
	// addi r11,r11,-90
	r11.s64 = r11.s64 + -90;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE388"))) PPC_WEAK_FUNC(sub_820AE388);
PPC_FUNC_IMPL(__imp__sub_820AE388) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lbz r3,-3847(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + -3847);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE398"))) PPC_WEAK_FUNC(sub_820AE398);
PPC_FUNC_IMPL(__imp__sub_820AE398) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x823d22e0
	sub_823D22E0(ctx, base);
	// bl 0x823d22e0
	sub_823D22E0(ctx, base);
	// bl 0x82136b48
	sub_82136B48(ctx, base);
	// bl 0x823d22e0
	sub_823D22E0(ctx, base);
	// bl 0x820c9ac0
	sub_820C9AC0(ctx, base);
	// bl 0x82136b88
	sub_82136B88(ctx, base);
	// bl 0x82143a48
	sub_82143A48(ctx, base);
	// bl 0x823d22e0
	sub_823D22E0(ctx, base);
	// bl 0x82120f08
	sub_82120F08(ctx, base);
	// bl 0x82136550
	sub_82136550(ctx, base);
	// bl 0x820af3b0
	sub_820AF3B0(ctx, base);
	// bl 0x820ea948
	sub_820EA948(ctx, base);
	// bl 0x8235d778
	sub_8235D778(ctx, base);
	// bl 0x8238d000
	sub_8238D000(ctx, base);
	// bl 0x820ae118
	sub_820AE118(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE3F0"))) PPC_WEAK_FUNC(sub_820AE3F0);
PPC_FUNC_IMPL(__imp__sub_820AE3F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r31,r11,15868
	r31.s64 = r11.s64 + 15868;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r30,r11,-3828
	r30.s64 = r11.s64 + -3828;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// blt cr6,0x820ae490
	if (cr6.getLT()) goto loc_820AE490;
	// lis r9,-32190
	ctx.r9.s64 = -2109603840;
	// lwz r10,-4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + -4);
	// lwz r9,15880(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 15880);
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// bge cr6,0x820ae444
	if (!cr6.getLT()) goto loc_820AE444;
	// addi r11,r10,1
	r11.s64 = ctx.r10.s64 + 1;
	// stw r11,-4(r30)
	PPC_STORE_U32(r30.u32 + -4, r11.u32);
	// b 0x820ae4a8
	goto loc_820AE4A8;
loc_820AE444:
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bge cr6,0x820ae490
	if (!cr6.getLT()) goto loc_820AE490;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820ae484
	if (!cr6.getEQ()) goto loc_820AE484;
loc_820AE454:
	// bl 0x8209f4e0
	sub_8209F4E0(ctx, base);
	// bl 0x82144880
	sub_82144880(ctx, base);
	// bl 0x8209cd00
	sub_8209CD00(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// li r11,-1
	r11.s64 = -1;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x820ae118
	sub_820AE118(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bge cr6,0x820ae454
	if (!cr6.getLT()) goto loc_820AE454;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
loc_820AE484:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// b 0x820ae4a8
	goto loc_820AE4A8;
loc_820AE490:
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820ae4a4
	if (!cr6.getGT()) goto loc_820AE4A4;
	// li r11,0
	r11.s64 = 0;
	// stw r11,-4(r30)
	PPC_STORE_U32(r30.u32 + -4, r11.u32);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
loc_820AE4A4:
	// bl 0x820ae250
	sub_820AE250(ctx, base);
loc_820AE4A8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE4C0"))) PPC_WEAK_FUNC(sub_820AE4C0);
PPC_FUNC_IMPL(__imp__sub_820AE4C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// li r11,90
	r11.s64 = 90;
	// stw r11,15868(r10)
	PPC_STORE_U32(ctx.r10.u32 + 15868, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE4D0"))) PPC_WEAK_FUNC(sub_820AE4D0);
PPC_FUNC_IMPL(__imp__sub_820AE4D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820cc3e0
	sub_820CC3E0(ctx, base);
	// bl 0x820cc3d0
	sub_820CC3D0(ctx, base);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r31,r11,15868
	r31.s64 = r11.s64 + 15868;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r11,54
	cr6.compare<int32_t>(r11.s32, 54, xer);
	// beq cr6,0x820ae520
	if (cr6.getEQ()) goto loc_820AE520;
	// bl 0x820cc338
	sub_820CC338(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820ae520
	if (cr6.getEQ()) goto loc_820AE520;
	// bl 0x82108d50
	sub_82108D50(ctx, base);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// li r11,1
	r11.s64 = 1;
	// stb r11,-3847(r10)
	PPC_STORE_U8(ctx.r10.u32 + -3847, r11.u8);
	// bl 0x8217c108
	sub_8217C108(ctx, base);
	// bl 0x8217bcb0
	sub_8217BCB0(ctx, base);
loc_820AE520:
	// li r11,90
	r11.s64 = 90;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE540"))) PPC_WEAK_FUNC(sub_820AE540);
PPC_FUNC_IMPL(__imp__sub_820AE540) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lbz r10,1764(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 1764);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// stb r10,1764(r11)
	PPC_STORE_U8(r11.u32 + 1764, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE560"))) PPC_WEAK_FUNC(sub_820AE560);
PPC_FUNC_IMPL(__imp__sub_820AE560) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// addi r12,r1,-24
	r12.s64 = ctx.r1.s64 + -24;
	// bl 0x823ed548
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// rlwinm r9,r3,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// add r9,r9,r30
	ctx.r9.u64 = ctx.r9.u64 + r30.u64;
	// lfs f31,14028(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 14028);
	f31.f64 = double(temp.f32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f30,2776(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 2776);
	f30.f64 = double(temp.f32);
	// clrldi r8,r9,32
	ctx.r8.u64 = ctx.r9.u64 & 0xFFFFFFFF;
	// lwz r10,1724(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1724);
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f29,2692(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2692);
	f29.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f28,14460(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14460);
	f28.f64 = double(temp.f32);
	// lfd f0,80(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmsubs f0,f0,f31,f29
	f0.f64 = double(float(f0.f64 * f31.f64 - f29.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,1676(r9)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 1676, temp.u32);
	// lwz r11,1724(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1724);
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// stfs f30,1684(r11)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r11.u32 + 1684, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r8,r3,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r8,r8,r30
	ctx.r8.u64 = ctx.r8.u64 + r30.u64;
	// addi r9,r11,1724
	ctx.r9.s64 = r11.s64 + 1724;
	// clrldi r8,r8,32
	ctx.r8.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// lwz r10,1724(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1724);
	// rlwinm r7,r10,1,0,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// add r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 + ctx.r7.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmsubs f0,f0,f31,f29
	f0.f64 = double(float(f0.f64 * f31.f64 - f29.f64));
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,1700(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1700, temp.u32);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addi r11,r11,142
	r11.s64 = r11.s64 + 142;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfsx f30,r10,r11
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(ctx.r10.u32 + r11.u32, temp.u32);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820ae728
	if (cr6.getEQ()) goto loc_820AE728;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r9,r3,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r9,r9,r30
	ctx.r9.u64 = ctx.r9.u64 + r30.u64;
	// clrldi r8,r9,32
	ctx.r8.u64 = ctx.r9.u64 & 0xFFFFFFFF;
	// lwz r10,1724(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1724);
	// addi r10,r10,140
	ctx.r10.s64 = ctx.r10.s64 + 140;
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f13,f0,f31
	ctx.f13.f64 = double(float(f0.f64 * f31.f64));
	// lfs f0,3904(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3904);
	f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfsx f0,r9,r11
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r8,r3,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r8,r8,r30
	ctx.r8.u64 = ctx.r8.u64 + r30.u64;
	// addi r9,r11,1724
	ctx.r9.s64 = r11.s64 + 1724;
	// clrldi r7,r8,32
	ctx.r7.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// lwz r10,1724(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1724);
	// rlwinm r8,r10,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// std r7,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r7.u64);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f13,f0,f31
	ctx.f13.f64 = double(float(f0.f64 * f31.f64));
	// lfs f0,14456(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14456);
	f0.f64 = double(temp.f32);
	// b 0x820ae7cc
	goto loc_820AE7CC;
loc_820AE728:
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r9,r3,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r9,r9,r30
	ctx.r9.u64 = ctx.r9.u64 + r30.u64;
	// clrldi r8,r9,32
	ctx.r8.u64 = ctx.r9.u64 & 0xFFFFFFFF;
	// lwz r10,1724(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1724);
	// addi r10,r10,140
	ctx.r10.s64 = ctx.r10.s64 + 140;
	// std r8,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r8.u64);
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f13,f0,f31
	ctx.f13.f64 = double(float(f0.f64 * f31.f64));
	// lfs f0,14456(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14456);
	f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfsx f0,r9,r11
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, temp.u32);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r8,r3,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r8,r8,r30
	ctx.r8.u64 = ctx.r8.u64 + r30.u64;
	// addi r9,r11,1724
	ctx.r9.s64 = r11.s64 + 1724;
	// clrldi r7,r8,32
	ctx.r7.u64 = ctx.r8.u64 & 0xFFFFFFFF;
	// lwz r10,1724(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1724);
	// rlwinm r8,r10,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// std r7,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r7.u64);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// add r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 + r11.u64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,80(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f13,f0,f31
	ctx.f13.f64 = double(float(f0.f64 * f31.f64));
	// lfs f0,3904(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3904);
	f0.f64 = double(temp.f32);
loc_820AE7CC:
	// fmuls f0,f13,f0
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,1708(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1708, temp.u32);
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// subfic r11,r11,1
	xer.ca = r11.u32 <= 1;
	r11.s64 = 1 - r11.s64;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// addi r12,r1,-24
	r12.s64 = ctx.r1.s64 + -24;
	// bl 0x823ed594
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE800"))) PPC_WEAK_FUNC(sub_820AE800);
PPC_FUNC_IMPL(__imp__sub_820AE800) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// addi r8,r11,1540
	ctx.r8.s64 = r11.s64 + 1540;
	// lwz r9,1540(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 1540);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x820ae84c
	if (cr6.getEQ()) goto loc_820AE84C;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f0,2688(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	f0.f64 = double(temp.f32);
	// stfs f0,1608(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1608, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,14472(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14472);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,1612(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1612, temp.u32);
	// stfs f0,1616(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1616, temp.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r11.u32);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
loc_820AE84C:
	// lis r7,-32014
	ctx.r7.s64 = -2098069504;
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r8,-6384(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + -6384);
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// ble cr6,0x820ae8ac
	if (!cr6.getGT()) goto loc_820AE8AC;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lfs f0,14468(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 14468);
	f0.f64 = double(temp.f32);
loc_820AE868:
	// lfs f12,0(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lfs f13,1608(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1608);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f13,1608(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1608, temp.u32);
	// lfs f12,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,1612(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1612);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f13,1612(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1612, temp.u32);
	// lfs f13,1616(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1616);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f13,1616(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1616, temp.u32);
	// lwz r8,-6384(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + -6384);
	// cmpw cr6,r9,r8
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r8.s32, xer);
	// blt cr6,0x820ae868
	if (cr6.getLT()) goto loc_820AE868;
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
loc_820AE8AC:
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f13,1608(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1608);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,14464(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 14464);
	f0.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,1572(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1572, temp.u32);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// lfs f13,1612(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1612);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,1576(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1576, temp.u32);
	// lfs f13,1616(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1616);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,1580(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1580, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AE8E0"))) PPC_WEAK_FUNC(sub_820AE8E0);
PPC_FUNC_IMPL(__imp__sub_820AE8E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// addi r8,r11,1544
	ctx.r8.s64 = r11.s64 + 1544;
	// lwz r9,1544(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 1544);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f0,2776(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2776);
	f0.f64 = double(temp.f32);
	// beq cr6,0x820ae990
	if (cr6.getEQ()) goto loc_820AE990;
	// lfs f13,1556(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1556);
	ctx.f13.f64 = double(temp.f32);
	// addi r9,r11,1556
	ctx.r9.s64 = r11.s64 + 1556;
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fdivs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
	// stfs f13,1620(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1620, temp.u32);
	// lfs f12,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// fsubs f12,f0,f12
	ctx.f12.f64 = double(float(f0.f64 - ctx.f12.f64));
	// lfs f13,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 / ctx.f12.f64));
	// stfs f13,1624(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1624, temp.u32);
	// lfs f13,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fdivs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
	// stfs f13,1628(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1628, temp.u32);
	// lfs f13,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fdivs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
	// stfs f13,1632(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1632, temp.u32);
	// lfs f13,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// fdivs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
	// stfs f13,1636(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1636, temp.u32);
	// lfs f13,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fdivs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
	// stfs f13,1640(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1640, temp.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, r11.u32);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
loc_820AE990:
	// lis r7,-32014
	ctx.r7.s64 = -2098069504;
	// li r9,0
	ctx.r9.s64 = 0;
	// lwz r8,-6384(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + -6384);
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// ble cr6,0x820aea30
	if (!cr6.getGT()) goto loc_820AEA30;
loc_820AE9A4:
	// lfs f12,1556(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1556);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lfs f11,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,1620(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1620);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f12,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfs f13,1620(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1620, temp.u32);
	// lfs f12,1556(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1556);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,1624(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1624);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f12,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfs f13,1624(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1624, temp.u32);
	// lfs f12,1556(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1556);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,1628(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1628);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f12,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfs f13,1628(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1628, temp.u32);
	// lfs f12,1556(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1556);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,1632(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1632);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f12,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfs f13,1632(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1632, temp.u32);
	// lfs f12,1556(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1556);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	ctx.f11.f64 = double(temp.f32);
	// lfs f13,1636(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1636);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f12,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfs f13,1636(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1636, temp.u32);
	// lfs f13,1640(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1640);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,1556(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1556);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f13,f13,f12,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfs f13,1640(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1640, temp.u32);
	// lwz r8,-6384(r7)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r7.u32 + -6384);
	// cmpw cr6,r9,r8
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r8.s32, xer);
	// blt cr6,0x820ae9a4
	if (cr6.getLT()) goto loc_820AE9A4;
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
loc_820AEA30:
	// lfs f13,1556(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1556);
	ctx.f13.f64 = double(temp.f32);
	// addi r9,r11,1556
	ctx.r9.s64 = r11.s64 + 1556;
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,1620(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1620);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,1584(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1584, temp.u32);
	// lfs f12,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// fsubs f12,f0,f12
	ctx.f12.f64 = double(float(f0.f64 - ctx.f12.f64));
	// lfs f13,1624(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1624);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f13.f64));
	// stfs f13,1588(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1588, temp.u32);
	// lfs f13,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,1628(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1628);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,1592(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1592, temp.u32);
	// lfs f13,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,1632(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1632);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,1596(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1596, temp.u32);
	// lfs f13,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f12,1636(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1636);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// stfs f13,1600(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1600, temp.u32);
	// lfs f13,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f13,1640(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1640);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,1604(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1604, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AEAB8"))) PPC_WEAK_FUNC(sub_820AEAB8);
PPC_FUNC_IMPL(__imp__sub_820AEAB8) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r9,-1364(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// addi r11,r9,1556
	r11.s64 = ctx.r9.s64 + 1556;
	// lfs f0,1556(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 1556);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f1
	cr6.compare(f0.f64, ctx.f1.f64);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,1620(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 1620);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,2776(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 2776);
	f0.f64 = double(temp.f32);
	// fsubs f12,f0,f12
	ctx.f12.f64 = double(float(f0.f64 - ctx.f12.f64));
	// fsubs f13,f0,f1
	ctx.f13.f64 = double(float(f0.f64 - ctx.f1.f64));
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fdivs f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
	// stfs f12,1620(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 1620, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// rotlwi r9,r9,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// fsubs f12,f0,f12
	ctx.f12.f64 = double(float(f0.f64 - ctx.f12.f64));
	// lfs f11,1624(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 1624);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fdivs f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
	// stfs f12,1624(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 1624, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lwz r9,-1364(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// fsubs f12,f0,f12
	ctx.f12.f64 = double(float(f0.f64 - ctx.f12.f64));
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// lfs f11,1628(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 1628);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fdivs f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
	// stfs f12,1628(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 1628, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f0,f12
	ctx.f12.f64 = double(float(f0.f64 - ctx.f12.f64));
	// lfs f11,1632(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 1632);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fdivs f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
	// stfs f12,1632(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 1632, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f0,f12
	ctx.f12.f64 = double(float(f0.f64 - ctx.f12.f64));
	// lfs f11,1636(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 1636);
	ctx.f11.f64 = double(temp.f32);
	// fmuls f12,f12,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f11.f64));
	// fdivs f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
	// stfs f12,1636(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 1636, temp.u32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f0,f0,f12
	f0.f64 = double(float(f0.f64 - ctx.f12.f64));
	// lfs f12,1640(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 1640);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f0,f0,f12
	f0.f64 = double(float(f0.f64 * ctx.f12.f64));
	// fdivs f0,f0,f13
	f0.f64 = double(float(f0.f64 / ctx.f13.f64));
	// stfs f0,1640(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1640, temp.u32);
	// stfs f1,0(r11)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AEB80"))) PPC_WEAK_FUNC(sub_820AEB80);
PPC_FUNC_IMPL(__imp__sub_820AEB80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// addi r12,r1,-40
	r12.s64 = ctx.r1.s64 + -40;
	// bl 0x823ed544
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// fmr f28,f1
	ctx.fpscr.disableFlushMode();
	f28.f64 = ctx.f1.f64;
	// fmr f27,f2
	f27.f64 = ctx.f2.f64;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f29,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f29.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f29,112(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// stfs f29,116(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// stfs f29,80(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f29,88(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f31,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f31.f64 = double(temp.f32);
	// stfs f31,120(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// stfs f31,84(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// bl 0x8211aff0
	sub_8211AFF0(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// lwz r10,1552(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1552);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x820aec5c
	if (!cr6.getEQ()) goto loc_820AEC5C;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,2720(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2720);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f30,f0
	cr6.compare(f30.f64, f0.f64);
	// ble cr6,0x820aec0c
	if (!cr6.getGT()) goto loc_820AEC0C;
	// stfs f31,1564(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1564, temp.u32);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// fmr f0,f31
	f0.f64 = f31.f64;
	// stfs f0,1568(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1568, temp.u32);
	// b 0x820aec90
	goto loc_820AEC90;
loc_820AEC0C:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,13964(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 13964);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f30,f0
	cr6.compare(f30.f64, f0.f64);
	// ble cr6,0x820aec44
	if (!cr6.getGT()) goto loc_820AEC44;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fsubs f12,f30,f0
	ctx.f12.f64 = double(float(f30.f64 - f0.f64));
	// lfs f0,14488(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14488);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,14484(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14484);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f12,f0,f13
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// stfs f0,1564(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1564, temp.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,1568(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1568, temp.u32);
	// b 0x820aec90
	goto loc_820AEC90;
loc_820AEC44:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,14484(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14484);
	f0.f64 = double(temp.f32);
	// stfs f0,1564(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1564, temp.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,1568(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1568, temp.u32);
	// b 0x820aec90
	goto loc_820AEC90;
loc_820AEC5C:
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x820aec84
	if (!cr6.getEQ()) goto loc_820AEC84;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,14064(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14064);
	f0.f64 = double(temp.f32);
	// stfs f0,1564(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1564, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,1568(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1568, temp.u32);
	// b 0x820aec90
	goto loc_820AEC90;
loc_820AEC84:
	// stfs f31,1564(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1564, temp.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f31,1568(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1568, temp.u32);
loc_820AEC90:
	// li r10,1
	ctx.r10.s64 = 1;
	// stfs f29,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// li r30,0
	r30.s64 = 0;
	// stfs f29,100(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// addi r11,r1,172
	r11.s64 = ctx.r1.s64 + 172;
	// stfs f29,104(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// stw r10,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, ctx.r10.u32);
	// li r10,3
	ctx.r10.s64 = 3;
	// stw r30,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r30.u32);
	// stw r30,140(r1)
	PPC_STORE_U32(ctx.r1.u32 + 140, r30.u32);
	// stw r30,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r30.u32);
	// stw r30,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r30.u32);
	// stw r10,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, ctx.r10.u32);
	// stw r30,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r30.u32);
	// stw r30,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r30.u32);
	// stw r30,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r30.u32);
	// stw r30,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r30.u32);
	// stw r30,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, r30.u32);
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// bl 0x8211b628
	sub_8211B628(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r30,1548(r11)
	PPC_STORE_U32(r11.u32 + 1548, r30.u32);
	// bl 0x8211b618
	sub_8211B618(ctx, base);
	// lis r29,-32014
	r29.s64 = -2098069504;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// lwz r4,-6384(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + -6384);
	// bl 0x8211d7c0
	sub_8211D7C0(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8211b618
	sub_8211B618(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// bl 0x82119948
	sub_82119948(ctx, base);
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// addi r4,r11,1728
	ctx.r4.s64 = r11.s64 + 1728;
	// addi r11,r11,2048
	r11.s64 = r11.s64 + 2048;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// stw r10,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r10.u32);
	// stw r11,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, r11.u32);
	// bl 0x8211d328
	sub_8211D328(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// lfs f0,1660(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1660);
	f0.f64 = double(temp.f32);
	// stfs f0,1644(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1644, temp.u32);
	// lfs f0,1664(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1664);
	f0.f64 = double(temp.f32);
	// stfs f0,1648(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1648, temp.u32);
	// lfs f0,1668(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1668);
	f0.f64 = double(temp.f32);
	// stfs f0,1652(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1652, temp.u32);
	// bl 0x82119108
	sub_82119108(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f13,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f13.f64 = double(temp.f32);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// lfs f0,2096(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2096);
	f0.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// stfs f0,96(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// lfs f0,2104(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2104);
	f0.f64 = double(temp.f32);
	// lfs f13,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// bl 0x82119118
	sub_82119118(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// fcmpu cr6,f30,f29
	ctx.fpscr.disableFlushMode();
	cr6.compare(f30.f64, f29.f64);
	// ble cr6,0x820aef24
	if (!cr6.getGT()) goto loc_820AEF24;
	// lfs f0,2096(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2096);
	f0.f64 = double(temp.f32);
	// addi r10,r11,2096
	ctx.r10.s64 = r11.s64 + 2096;
	// fadds f0,f0,f27
	f0.f64 = double(float(f0.f64 + f27.f64));
	// stfs f0,2096(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2096, temp.u32);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// addi r9,r11,2104
	ctx.r9.s64 = r11.s64 + 2104;
	// lfs f0,2104(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2104);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f28
	f0.f64 = double(float(f0.f64 * f28.f64));
	// stfs f0,2104(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2104, temp.u32);
	// lwz r8,-6384(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + -6384);
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// ble cr6,0x820aee04
	if (!cr6.getGT()) goto loc_820AEE04;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-6368(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fdivs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 / f0.f64));
	// stfs f0,0(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lfs f13,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-6368(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fdivs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 / f0.f64));
	// stfs f0,0(r9)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lwz r8,-6384(r29)
	ctx.r8.u64 = PPC_LOAD_U32(r29.u32 + -6384);
loc_820AEE04:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f11,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f13,1656(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1656);
	ctx.f13.f64 = double(temp.f32);
	// lwz r7,1552(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 1552);
	// lfs f12,2100(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2100);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// lfs f0,1564(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1564);
	f0.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * f0.f64));
	// stfs f11,96(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// fmuls f11,f10,f0
	ctx.f11.f64 = double(float(ctx.f10.f64 * f0.f64));
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// stfs f11,104(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// fmadds f0,f12,f0,f13
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// lfs f0,2080(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2080);
	f0.f64 = double(temp.f32);
	// blt cr6,0x820aeee8
	if (cr6.getLT()) goto loc_820AEEE8;
	// lfs f13,1568(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1568);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lfs f13,1564(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1564);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,2084(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2084);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,116(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f0,2088(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2088);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f31
	f0.f64 = double(float(f0.f64 - f31.f64));
	// lfs f13,1564(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1564);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f0,f13,f31
	f0.f64 = double(float(f0.f64 * ctx.f13.f64 + f31.f64));
	// stfs f0,120(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f13,1564(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1564);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,2064(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2064);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,2068(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2068);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f31
	f0.f64 = double(float(f0.f64 - f31.f64));
	// lfs f13,1564(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1564);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f0,f13,f31
	f0.f64 = double(float(f0.f64 * ctx.f13.f64 + f31.f64));
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f0,2072(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2072);
	f0.f64 = double(temp.f32);
	// lfs f13,1564(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1564);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lwz r10,1560(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1560);
	// add r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 + ctx.r8.u64;
	// stw r10,1560(r11)
	PPC_STORE_U32(r11.u32 + 1560, ctx.r10.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r11,1560(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1560);
	// cmpwi cr6,r11,60
	cr6.compare<int32_t>(r11.s32, 60, xer);
	// ble cr6,0x820aeed8
	if (!cr6.getGT()) goto loc_820AEED8;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,14468(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14468);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x820aeab8
	sub_820AEAB8(ctx, base);
	// b 0x820af070
	goto loc_820AF070;
loc_820AEED8:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,14480(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14480);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x820aeab8
	sub_820AEAB8(ctx, base);
	// b 0x820af070
	goto loc_820AF070;
loc_820AEEE8:
	// stfs f0,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,2084(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2084);
	f0.f64 = double(temp.f32);
	// stfs f0,116(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lfs f0,2088(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2088);
	f0.f64 = double(temp.f32);
	// stfs f0,120(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 120, temp.u32);
	// lfs f0,2064(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2064);
	f0.f64 = double(temp.f32);
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// lfs f0,2068(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2068);
	f0.f64 = double(temp.f32);
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// lfs f0,2072(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2072);
	f0.f64 = double(temp.f32);
	// lfs f1,14476(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14476);
	ctx.f1.f64 = double(temp.f32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// bl 0x820aeab8
	sub_820AEAB8(ctx, base);
	// b 0x820af070
	goto loc_820AF070;
loc_820AEF24:
	// lfs f0,1660(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1660);
	f0.f64 = double(temp.f32);
	// stfs f0,1644(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1644, temp.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f29,96(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// stfs f29,104(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lfs f0,1664(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1664);
	f0.f64 = double(temp.f32);
	// stfs f0,1648(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1648, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,14480(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14480);
	ctx.f1.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,1668(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1668);
	f0.f64 = double(temp.f32);
	// stfs f0,1652(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1652, temp.u32);
	// lfs f0,1656(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1656);
	f0.f64 = double(temp.f32);
	// stw r30,1560(r11)
	PPC_STORE_U32(r11.u32 + 1560, r30.u32);
	// stfs f0,100(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 100, temp.u32);
	// bl 0x820aeab8
	sub_820AEAB8(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r30,r11,1672
	r30.s64 = r11.s64 + 1672;
	// bl 0x820b3cd0
	sub_820B3CD0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f11,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,14404(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14404);
	f0.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f13,-6368(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -6368);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,14408(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14408);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f0,f1,f0,f12
	f0.f64 = double(float(ctx.f1.f64 * f0.f64 + ctx.f12.f64));
	// fmadds f0,f0,f13,f11
	f0.f64 = double(float(f0.f64 * ctx.f13.f64 + ctx.f11.f64));
	// stfs f0,0(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 0, temp.u32);
	// fcmpu cr6,f0,f31
	cr6.compare(f0.f64, f31.f64);
	// blt cr6,0x820aefb8
	if (cr6.getLT()) goto loc_820AEFB8;
	// bl 0x820ae560
	sub_820AE560(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r30,r11,1672
	r30.s64 = r11.s64 + 1672;
	// lfs f0,1672(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1672);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f31
	f0.f64 = double(float(f0.f64 - f31.f64));
	// stfs f0,1672(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1672, temp.u32);
loc_820AEFB8:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// lfs f1,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lwz r10,1724(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1724);
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r9,r10,r11
	ctx.r9.s64 = r11.s64 - ctx.r10.s64;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// addi r4,r9,1688
	ctx.r4.s64 = ctx.r9.s64 + 1688;
	// addi r3,r11,1676
	ctx.r3.s64 = r11.s64 + 1676;
	// bl 0x8210af18
	sub_8210AF18(ctx, base);
	// bl 0x820b3cd0
	sub_820B3CD0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// lfs f30,2780(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2780);
	f30.f64 = double(temp.f32);
	// fmadds f0,f1,f30,f31
	f0.f64 = double(float(ctx.f1.f64 * f30.f64 + f31.f64));
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// bl 0x820b3cd0
	sub_820B3CD0(ctx, base);
	// fmadds f0,f1,f30,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 * f30.f64 + f31.f64));
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f13,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	ctx.f13.f64 = double(temp.f32);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,116(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 116, temp.u32);
	// lwz r10,1724(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1724);
	// lfs f1,1672(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1672);
	ctx.f1.f64 = double(temp.f32);
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r9,r10,r11
	ctx.r9.s64 = r11.s64 - ctx.r10.s64;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// addi r4,r9,1712
	ctx.r4.s64 = ctx.r9.s64 + 1712;
	// addi r3,r11,1700
	ctx.r3.s64 = r11.s64 + 1700;
	// bl 0x8210af18
	sub_8210AF18(ctx, base);
	// bl 0x820b3cd0
	sub_820B3CD0(ctx, base);
	// fmadds f0,f1,f30,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 * f30.f64 + f31.f64));
	// lfs f13,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// bl 0x820b3cd0
	sub_820B3CD0(ctx, base);
	// fmadds f0,f1,f30,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64 * f30.f64 + f31.f64));
	// lfs f13,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
loc_820AF070:
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// bl 0x820c3050
	sub_820C3050(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820af08c
	if (!cr6.getEQ()) goto loc_820AF08C;
	// stfs f29,80(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// stfs f31,84(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f29,88(r1)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
loc_820AF08C:
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x820ae800
	sub_820AE800(ctx, base);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x820ae8e0
	sub_820AE8E0(ctx, base);
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// addi r12,r1,-40
	r12.s64 = ctx.r1.s64 + -40;
	// bl 0x823ed590
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820AF0B0"))) PPC_WEAK_FUNC(sub_820AF0B0);
PPC_FUNC_IMPL(__imp__sub_820AF0B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f29.u64);
	// stfd f30,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, f30.u64);
	// stfd f31,-48(r1)
	PPC_STORE_U64(ctx.r1.u32 + -48, f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// li r30,0
	r30.s64 = 0;
	// addi r31,r11,15884
	r31.s64 = r11.s64 + 15884;
	// addi r11,r31,20
	r11.s64 = r31.s64 + 20;
	// lfs f0,36(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 36);
	f0.f64 = double(temp.f32);
	// fmuls f29,f0,f1
	f29.f64 = double(float(f0.f64 * ctx.f1.f64));
loc_820AF0E0:
	// lfs f0,-8(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -8);
	f0.f64 = double(temp.f32);
	// lfs f13,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// fcmpu cr6,f0,f29
	cr6.compare(f0.f64, f29.f64);
	// bge cr6,0x820af11c
	if (!cr6.getLT()) goto loc_820AF11C;
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// addi r10,r31,68
	ctx.r10.s64 = r31.s64 + 68;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// blt cr6,0x820af0e0
	if (cr6.getLT()) goto loc_820AF0E0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f29,-64(r1)
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f30,-56(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
loc_820AF11C:
	// lis r29,-32014
	r29.s64 = -2098069504;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// lfs f30,2692(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 2692);
	f30.f64 = double(temp.f32);
	// lfs f31,2688(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	f31.f64 = double(temp.f32);
	// lwz r10,1552(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1552);
	// cmpw cr6,r30,r10
	cr6.compare<int32_t>(r30.s32, ctx.r10.s32, xer);
	// beq cr6,0x820af218
	if (cr6.getEQ()) goto loc_820AF218;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blt cr6,0x820af1a0
	if (cr6.getLT()) goto loc_820AF1A0;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lfs f12,1768(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1768);
	ctx.f12.f64 = double(temp.f32);
	// addi r8,r31,4
	ctx.r8.s64 = r31.s64 + 4;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r6,r31,8
	ctx.r6.s64 = r31.s64 + 8;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r9,r30,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// add r9,r30,r9
	ctx.r9.u64 = r30.u64 + ctx.r9.u64;
	// addi r7,r31,4
	ctx.r7.s64 = r31.s64 + 4;
	// rlwinm r9,r9,3,0,28
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 3) & 0xFFFFFFF8;
	// addi r5,r31,8
	ctx.r5.s64 = r31.s64 + 8;
	// lfsx f0,r10,r8
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	f0.f64 = double(temp.f32);
	// lfsx f11,r10,r6
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r6.u32);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 - f0.f64));
	// fsubs f0,f11,f0
	f0.f64 = double(float(ctx.f11.f64 - f0.f64));
	// lfsx f13,r9,r7
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r7.u32);
	ctx.f13.f64 = double(temp.f32);
	// lfsx f10,r9,r5
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r5.u32);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f11,f10,f13
	ctx.f11.f64 = double(float(ctx.f10.f64 - ctx.f13.f64));
	// fdivs f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 / f0.f64));
	// fmadds f1,f0,f11,f13
	ctx.f1.f64 = double(float(f0.f64 * ctx.f11.f64 + ctx.f13.f64));
loc_820AF1A0:
	// lbz r9,1764(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 1764);
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// rlwinm r11,r30,1,0,30
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// fmr f2,f30
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = f30.f64;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// extsb r5,r9
	ctx.r5.s64 = ctx.r9.s8;
	// rlwinm r28,r11,3,0,28
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lfs f3,14492(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14492);
	ctx.f3.f64 = double(temp.f32);
	// lwzx r4,r28,r31
	ctx.r4.u64 = PPC_LOAD_U32(r28.u32 + r31.u32);
	// bl 0x8211d710
	sub_8211D710(ctx, base);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// fmr f2,f31
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = f31.f64;
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// addi r11,r31,4
	r11.s64 = r31.s64 + 4;
	// lfsx f1,r28,r11
	temp.u32 = PPC_LOAD_U32(r28.u32 + r11.u32);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8211b220
	sub_8211B220(ctx, base);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// addi r11,r31,8
	r11.s64 = r31.s64 + 8;
	// lfsx f1,r28,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + r11.u32);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8211d758
	sub_8211D758(ctx, base);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// addi r4,r10,-6848
	ctx.r4.s64 = ctx.r10.s64 + -6848;
	// bl 0x8211b238
	sub_8211B238(ctx, base);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// stw r30,1552(r11)
	PPC_STORE_U32(r11.u32 + 1552, r30.u32);
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
loc_820AF218:
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// fmr f2,f31
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = f31.f64;
	// rlwinm r11,r30,1,0,30
	r11.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r10,r31,12
	ctx.r10.s64 = r31.s64 + 12;
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// rlwinm r11,r11,3,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f0,r11,r10
	temp.u32 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	f0.f64 = double(temp.f32);
	// fdivs f0,f29,f0
	f0.f64 = double(float(f29.f64 / f0.f64));
	// fmuls f1,f0,f30
	ctx.f1.f64 = double(float(f0.f64 * f30.f64));
	// bl 0x8211b240
	sub_8211B240(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f29,-64(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f30,-56(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// lfd f31,-48(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820AF258"))) PPC_WEAK_FUNC(sub_820AF258);
PPC_FUNC_IMPL(__imp__sub_820AF258) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// lfs f3,14492(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14492);
	ctx.f3.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// fmuls f2,f2,f0
	ctx.f2.f64 = double(float(ctx.f2.f64 * f0.f64));
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// bl 0x8211d710
	sub_8211D710(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r10,1552(r11)
	PPC_STORE_U32(r11.u32 + 1552, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AF2B8"))) PPC_WEAK_FUNC(sub_820AF2B8);
PPC_FUNC_IMPL(__imp__sub_820AF2B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f2,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f2.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
	// fmuls f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 * f0.f64));
	// b 0x8211b240
	sub_8211B240(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820AF2E0"))) PPC_WEAK_FUNC(sub_820AF2E0);
PPC_FUNC_IMPL(__imp__sub_820AF2E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -24, f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r11,1552(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1552);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x820af380
	if (cr6.getLT()) goto loc_820AF380;
	// bl 0x820b3cd0
	sub_820B3CD0(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,14496(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14496);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,12008(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12008);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f31,f1,f0,f13
	f31.f64 = double(float(ctx.f1.f64 * f0.f64 + ctx.f13.f64));
	// bl 0x8211aff0
	sub_8211AFF0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f1,f0
	cr6.compare(ctx.f1.f64, f0.f64);
	// ble cr6,0x820af378
	if (!cr6.getGT()) goto loc_820AF378;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// addi r10,r10,15884
	ctx.r10.s64 = ctx.r10.s64 + 15884;
	// addi r9,r10,8
	ctx.r9.s64 = ctx.r10.s64 + 8;
	// lwz r11,1552(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1552);
	// addi r8,r10,4
	ctx.r8.s64 = ctx.r10.s64 + 4;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm r11,r11,3,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f0,r11,r9
	temp.u32 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	f0.f64 = double(temp.f32);
	// lfsx f13,r11,r8
	temp.u32 = PPC_LOAD_U32(r11.u32 + ctx.r8.u32);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// fdivs f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 / f0.f64));
	// fcmpu cr6,f1,f31
	cr6.compare(ctx.f1.f64, f31.f64);
	// bge cr6,0x820af388
	if (!cr6.getLT()) goto loc_820AF388;
loc_820AF378:
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// b 0x820af388
	goto loc_820AF388;
loc_820AF380:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f1.f64 = double(temp.f32);
loc_820AF388:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f31,-24(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AF3A0"))) PPC_WEAK_FUNC(sub_820AF3A0);
PPC_FUNC_IMPL(__imp__sub_820AF3A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r11,r11,15884
	r11.s64 = r11.s64 + 15884;
	// lfs f1,36(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 36);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AF3B0"))) PPC_WEAK_FUNC(sub_820AF3B0);
PPC_FUNC_IMPL(__imp__sub_820AF3B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// addi r11,r11,16224
	r11.s64 = r11.s64 + 16224;
	// stw r11,16248(r10)
	PPC_STORE_U32(ctx.r10.u32 + 16248, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AF3C8"))) PPC_WEAK_FUNC(sub_820AF3C8);
PPC_FUNC_IMPL(__imp__sub_820AF3C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r6
	r31.u64 = ctx.r6.u64;
	// li r11,0
	r11.s64 = 0;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// cmpw cr6,r30,r29
	cr6.compare<int32_t>(r30.s32, r29.s32, xer);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bge cr6,0x820af468
	if (!cr6.getLT()) goto loc_820AF468;
	// lis r11,-32141
	r11.s64 = -2106392576;
	// addi r27,r11,-21224
	r27.s64 = r11.s64 + -21224;
loc_820AF404:
	// addi r8,r1,80
	ctx.r8.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x821195f0
	sub_821195F0(ctx, base);
	// lhz r11,80(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 80);
	// lwz r6,0(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// extsh r7,r11
	ctx.r7.s64 = r11.s16;
	// lhz r11,82(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 82);
	// lwz r8,4(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpw cr6,r30,r29
	cr6.compare<int32_t>(r30.s32, r29.s32, xer);
	// extsh r9,r11
	ctx.r9.s64 = r11.s16;
	// lhz r11,84(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 84);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// add r7,r7,r6
	ctx.r7.u64 = ctx.r7.u64 + ctx.r6.u64;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// stw r7,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r7.u32);
	// stw r9,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r9.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// blt cr6,0x820af404
	if (cr6.getLT()) goto loc_820AF404;
loc_820AF468:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820AF470"))) PPC_WEAK_FUNC(sub_820AF470);
PPC_FUNC_IMPL(__imp__sub_820AF470) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stfd f29,-72(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -72, f29.u64);
	// stfd f30,-64(r1)
	PPC_STORE_U64(ctx.r1.u32 + -64, f30.u64);
	// stfd f31,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, f31.u64);
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r4,r11,16248
	ctx.r4.s64 = r11.s64 + 16248;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r5,r11,1916
	ctx.r5.s64 = r11.s64 + 1916;
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// bl 0x8211c960
	sub_8211C960(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f29,14176(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14176);
	f29.f64 = double(temp.f32);
	// fmr f1,f29
	ctx.f1.f64 = f29.f64;
	// bl 0x823ada90
	sub_823ADA90(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// lfs f30,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f30.f64 = double(temp.f32);
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// bl 0x8211b2f8
	sub_8211B2F8(ctx, base);
	// li r30,2048
	r30.s64 = 2048;
loc_820AF4E4:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// add r3,r30,r11
	ctx.r3.u64 = r30.u64 + r11.u64;
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// addi r30,r30,64
	r30.s64 = r30.s64 + 64;
	// cmpwi cr6,r30,2304
	cr6.compare<int32_t>(r30.s32, 2304, xer);
	// blt cr6,0x820af4e4
	if (cr6.getLT()) goto loc_820AF4E4;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r30,0
	r30.s64 = 0;
	// li r28,1
	r28.s64 = 1;
	// lfs f0,14468(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14468);
	f0.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r30,1552(r11)
	PPC_STORE_U32(r11.u32 + 1552, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,1556(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1556, temp.u32);
	// stw r30,1560(r11)
	PPC_STORE_U32(r11.u32 + 1560, r30.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f30,1564(r11)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r11.u32 + 1564, temp.u32);
	// stfs f30,1568(r11)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r11.u32 + 1568, temp.u32);
	// stfs f31,1572(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1572, temp.u32);
	// stfs f31,1576(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1576, temp.u32);
	// stfs f31,1580(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1580, temp.u32);
	// stfs f31,1584(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1584, temp.u32);
	// stfs f31,1588(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1588, temp.u32);
	// stfs f31,1592(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1592, temp.u32);
	// stfs f31,1596(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1596, temp.u32);
	// stfs f31,1600(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1600, temp.u32);
	// stfs f31,1604(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1604, temp.u32);
	// stfs f31,1608(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1608, temp.u32);
	// stfs f31,1612(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1612, temp.u32);
	// stfs f31,1616(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1616, temp.u32);
	// stfs f31,1620(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1620, temp.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,14472(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14472);
	f0.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f31,1624(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1624, temp.u32);
	// stfs f0,1628(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1628, temp.u32);
	// stfs f31,1632(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1632, temp.u32);
	// stfs f0,1636(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1636, temp.u32);
	// stfs f31,1640(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1640, temp.u32);
	// stw r28,1540(r11)
	PPC_STORE_U32(r11.u32 + 1540, r28.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r28,1544(r11)
	PPC_STORE_U32(r11.u32 + 1544, r28.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r28,1548(r11)
	PPC_STORE_U32(r11.u32 + 1548, r28.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f31,1644(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1644, temp.u32);
	// stfs f31,1648(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1648, temp.u32);
	// stfs f31,1652(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1652, temp.u32);
	// stfs f31,1656(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1656, temp.u32);
	// stfs f31,1660(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1660, temp.u32);
	// stfs f31,1664(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1664, temp.u32);
	// stfs f31,1668(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1668, temp.u32);
	// stfs f31,1672(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1672, temp.u32);
	// stfs f31,1676(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1676, temp.u32);
	// stfs f31,1680(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1680, temp.u32);
	// stfs f30,1684(r11)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r11.u32 + 1684, temp.u32);
	// stfs f31,1688(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1688, temp.u32);
	// stfs f31,1692(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1692, temp.u32);
	// stfs f30,1696(r11)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r11.u32 + 1696, temp.u32);
	// stfs f31,1700(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1700, temp.u32);
	// stfs f30,1704(r11)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r11.u32 + 1704, temp.u32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// addi r29,r11,15884
	r29.s64 = r11.s64 + 15884;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r27,r29,8
	r27.s64 = r29.s64 + 8;
	// stfs f31,1708(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1708, temp.u32);
	// stfs f31,1712(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1712, temp.u32);
	// stfs f30,1716(r11)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r11.u32 + 1716, temp.u32);
	// stfs f31,1720(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1720, temp.u32);
	// stw r30,1724(r11)
	PPC_STORE_U32(r11.u32 + 1724, r30.u32);
loc_820AF5FC:
	// addi r11,r1,84
	r11.s64 = ctx.r1.s64 + 84;
	// lfs f0,0(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + 0);
	f0.f64 = double(temp.f32);
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// lfs f13,-4(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + -4);
	ctx.f13.f64 = double(temp.f32);
	// fctiwz f13,f13
	ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f13.f64));
	// addi r6,r1,152
	ctx.r6.s64 = ctx.r1.s64 + 152;
	// lwz r3,-8(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + -8);
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r5,84(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// stfiwx f13,0,r11
	PPC_STORE_U32(r11.u32, ctx.f13.u32);
	// lwz r4,80(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x820af3c8
	sub_820AF3C8(ctx, base);
	// lwz r11,160(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// lfs f13,-4(r27)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r27.u32 + -4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,0(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 0);
	f0.f64 = double(temp.f32);
	// extsw r11,r11
	r11.s64 = r11.s32;
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// std r11,144(r1)
	PPC_STORE_U64(ctx.r1.u32 + 144, r11.u64);
	// addi r11,r29,56
	r11.s64 = r29.s64 + 56;
	// lfd f13,144(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 144);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 * f29.f64));
	// fdivs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 / f0.f64));
	// stfs f0,4(r27)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r27.u32 + 4, temp.u32);
	// addi r27,r27,24
	r27.s64 = r27.s64 + 24;
	// cmpw cr6,r27,r11
	cr6.compare<int32_t>(r27.s32, r11.s32, xer);
	// blt cr6,0x820af5fc
	if (cr6.getLT()) goto loc_820AF5FC;
	// lis r10,-32057
	ctx.r10.s64 = -2100887552;
	// stw r30,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r30.u32);
	// addi r11,r1,140
	r11.s64 = ctx.r1.s64 + 140;
	// stw r28,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r28.u32);
	// addi r4,r10,32216
	ctx.r4.s64 = ctx.r10.s64 + 32216;
	// stw r30,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r30.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// stw r30,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r30.u32);
	// stw r30,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r30.u32);
	// li r5,0
	ctx.r5.s64 = 0;
	// stw r30,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r30.u32);
	// fmr f3,f31
	ctx.f3.f64 = f31.f64;
	// stw r30,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r30.u32);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// stw r30,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r30.u32);
	// lfs f30,2692(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2692);
	f30.f64 = double(temp.f32);
	// li r10,3
	ctx.r10.s64 = 3;
	// stw r30,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r30.u32);
	// fmr f2,f30
	ctx.f2.f64 = f30.f64;
	// stw r30,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r30.u32);
	// stw r10,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r10.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r30,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r30.u32);
	// addi r3,r10,1728
	ctx.r3.s64 = ctx.r10.s64 + 1728;
	// bl 0x8211d710
	sub_8211D710(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// bl 0x82119948
	sub_82119948(ctx, base);
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// bl 0x8210b2b0
	sub_8210B2B0(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r10,r1,176
	ctx.r10.s64 = ctx.r1.s64 + 176;
	// addi r4,r11,1728
	ctx.r4.s64 = r11.s64 + 1728;
	// addi r11,r11,2048
	r11.s64 = r11.s64 + 2048;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// bl 0x8211d328
	sub_8211D328(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r9,r29,4
	ctx.r9.s64 = r29.s64 + 4;
	// li r5,0
	ctx.r5.s64 = 0;
	// fmr f3,f31
	ctx.fpscr.disableFlushMode();
	ctx.f3.f64 = f31.f64;
	// addi r10,r11,2100
	ctx.r10.s64 = r11.s64 + 2100;
	// fmr f2,f30
	ctx.f2.f64 = f30.f64;
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// lfs f0,2100(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2100);
	f0.f64 = double(temp.f32);
	// stfs f0,1656(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1656, temp.u32);
	// stfs f31,1660(r11)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r11.u32 + 1660, temp.u32);
	// lfs f0,2164(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2164);
	f0.f64 = double(temp.f32);
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// stfs f0,1664(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1664, temp.u32);
	// lfs f0,2168(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2168);
	f0.f64 = double(temp.f32);
	// lfs f13,2104(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2104);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// stfs f0,1668(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1668, temp.u32);
	// lwz r10,1552(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1552);
	// rlwinm r11,r10,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// rlwinm r11,r11,3,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f1,r11,r9
	temp.u32 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	ctx.f1.f64 = double(temp.f32);
	// lwzx r4,r11,r29
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// bl 0x8211d710
	sub_8211D710(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r9,r29,4
	ctx.r9.s64 = r29.s64 + 4;
	// fmr f2,f31
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = f31.f64;
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// lwz r10,1552(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1552);
	// rlwinm r11,r10,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// rlwinm r11,r11,3,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f1,r11,r9
	temp.u32 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8211b220
	sub_8211B220(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// lwz r10,1552(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1552);
	// addi r11,r29,8
	r11.s64 = r29.s64 + 8;
	// rlwinm r9,r10,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r10,3,0,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0xFFFFFFF8;
	// lfsx f1,r10,r11
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8211d758
	sub_8211D758(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lis r10,-32245
	ctx.r10.s64 = -2113208320;
	// addi r3,r11,1728
	ctx.r3.s64 = r11.s64 + 1728;
	// addi r4,r10,-6848
	ctx.r4.s64 = ctx.r10.s64 + -6848;
	// bl 0x8211b238
	sub_8211B238(ctx, base);
	// bl 0x820ae560
	sub_820AE560(ctx, base);
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// lfd f29,-72(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// lfd f30,-64(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f31,-56(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820AF7E8"))) PPC_WEAK_FUNC(sub_820AF7E8);
PPC_FUNC_IMPL(__imp__sub_820AF7E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lwz r11,24(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// extsb r10,r3
	ctx.r10.s64 = ctx.r3.s8;
	// extsb r11,r31
	r11.s64 = r31.s8;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AF838"))) PPC_WEAK_FUNC(sub_820AF838);
PPC_FUNC_IMPL(__imp__sub_820AF838) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1892(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1892);
	// cmpw cr6,r3,r11
	cr6.compare<int32_t>(ctx.r3.s32, r11.s32, xer);
	// bge cr6,0x820af85c
	if (!cr6.getLT()) goto loc_820AF85C;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// rlwinm r10,r3,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-3760
	r11.s64 = r11.s64 + -3760;
	// lwzx r3,r10,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// blr 
	return;
loc_820AF85C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AF868"))) PPC_WEAK_FUNC(sub_820AF868);
PPC_FUNC_IMPL(__imp__sub_820AF868) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r3,-1892(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + -1892);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820AF878"))) PPC_WEAK_FUNC(sub_820AF878);
PPC_FUNC_IMPL(__imp__sub_820AF878) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed10c
	// stfd f30,-144(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -144, f30.u64);
	// stfd f31,-136(r1)
	PPC_STORE_U64(ctx.r1.u32 + -136, f31.u64);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// mr r19,r3
	r19.u64 = ctx.r3.u64;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// li r26,1
	r26.s64 = 1;
	// li r27,0
	r27.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// bl 0x823ee680
	sub_823EE680(ctx, base);
	// lis r22,-32014
	r22.s64 = -2098069504;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r9,r3
	ctx.r9.u64 = ctx.r3.u64;
	// addi r3,r11,15052
	ctx.r3.s64 = r11.s64 + 15052;
	// rotlwi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// lwz r11,-1892(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + -1892);
	// lis r25,-32014
	r25.s64 = -2098069504;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// divw r8,r9,r11
	ctx.r8.s32 = ctx.r9.s32 / r11.s32;
	// twllei r11,0
	// mullw r8,r8,r11
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(r11.s32);
	// andc r11,r11,r10
	r11.u64 = r11.u64 & ~ctx.r10.u64;
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// twlgei r11,-1
	// lwz r11,-1364(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + -1364);
	// mr r4,r19
	ctx.r4.u64 = r19.u64;
	// stw r9,8288(r11)
	PPC_STORE_U32(r11.u32 + 8288, ctx.r9.u32);
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r18,r11,15028
	r18.s64 = r11.s64 + 15028;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r24,r11,14984
	r24.s64 = r11.s64 + 14984;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,14108(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14108);
	f30.f64 = double(temp.f32);
	// addi r21,r11,14936
	r21.s64 = r11.s64 + 14936;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r20,r11,-3760
	r20.s64 = r11.s64 + -3760;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r17,r11,-1384
	r17.s64 = r11.s64 + -1384;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r28,r11,14920
	r28.s64 = r11.s64 + 14920;
loc_820AF92C:
	// lwz r11,-1892(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + -1892);
	// cmpw cr6,r27,r11
	cr6.compare<int32_t>(r27.s32, r11.s32, xer);
	// bge cr6,0x820afa7c
	if (!cr6.getLT()) goto loc_820AFA7C;
	// lwz r11,-1364(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + -1364);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// lwz r10,8288(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8288);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8288(r11)
	PPC_STORE_U32(r11.u32 + 8288, ctx.r10.u32);
	// lwz r11,-1364(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + -1364);
	// lwz r9,8288(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8288);
	// lwz r11,-1892(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + -1892);
	// rotlwi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// divw r8,r9,r11
	ctx.r8.s32 = ctx.r9.s32 / r11.s32;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// mullw r8,r8,r11
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(r11.s32);
	// subf r30,r8,r9
	r30.s64 = ctx.r9.s64 - ctx.r8.s64;
	// twllei r11,0
	// andc r11,r11,r10
	r11.u64 = r11.u64 & ~ctx.r10.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// twlgei r11,-1
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// li r26,0
	r26.s64 = 0;
	// li r31,0
	r31.s64 = 0;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// ble cr6,0x820afa68
	if (!cr6.getGT()) goto loc_820AFA68;
	// mr r29,r17
	r29.u64 = r17.u64;
loc_820AF998:
	// cmpw cr6,r31,r19
	cr6.compare<int32_t>(r31.s32, r19.s32, xer);
	// beq cr6,0x820afa50
	if (cr6.getEQ()) goto loc_820AFA50;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r10,428(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820afa48
	if (cr6.getEQ()) goto loc_820AFA48;
	// rlwinm r8,r30,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,428(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwzx r11,r8,r20
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r20.u32);
	// lfs f4,20(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	ctx.f4.f64 = double(temp.f32);
	// lfs f0,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	f0.f64 = double(temp.f32);
	// lfs f13,20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// lfs f3,12(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// stfd f4,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.f4.u64);
	// ld r8,56(r1)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 56);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f0,f0,f12
	f0.f64 = double(float(f0.f64 - ctx.f12.f64));
	// lfs f11,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfd f3,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.f3.u64);
	// fmr f2,f11
	ctx.f2.f64 = ctx.f11.f64;
	// stfd f2,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.f2.u64);
	// fmr f1,f12
	ctx.f1.f64 = ctx.f12.f64;
	// stfd f1,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.f1.u64);
	// ld r7,48(r1)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r1.u32 + 48);
	// ld r6,40(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 40);
	// ld r5,32(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 32);
	// fmuls f0,f0,f0
	f0.f64 = double(float(f0.f64 * f0.f64));
	// fmadds f0,f13,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// fsqrts f31,f0
	f31.f64 = double(float(sqrt(f0.f64)));
	// fmr f5,f31
	ctx.f5.f64 = f31.f64;
	// stfd f5,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.f5.u64);
	// ld r9,64(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 64);
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// bge cr6,0x820afa50
	if (!cr6.getLT()) goto loc_820AFA50;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// li r26,1
	r26.s64 = 1;
	// b 0x820afa50
	goto loc_820AFA50;
loc_820AFA48:
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
loc_820AFA50:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmpw cr6,r31,r23
	cr6.compare<int32_t>(r31.s32, r23.s32, xer);
	// blt cr6,0x820af998
	if (cr6.getLT()) goto loc_820AF998;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// bne cr6,0x820af92c
	if (!cr6.getEQ()) goto loc_820AF92C;
loc_820AFA68:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// lfd f30,-144(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -144);
	// lfd f31,-136(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -136);
	// b 0x823ed15c
	return;
loc_820AFA7C:
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x820afa68
	if (cr6.getEQ()) goto loc_820AFA68;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r24,r10,14876
	r24.s64 = ctx.r10.s64 + 14876;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r28,r10,14844
	r28.s64 = ctx.r10.s64 + 14844;
	// lfs f30,2944(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2944);
	f30.f64 = double(temp.f32);
	// b 0x820afaa4
	goto loc_820AFAA4;
loc_820AFAA0:
	// lwz r11,-1892(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + -1892);
loc_820AFAA4:
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// cmpw cr6,r27,r11
	cr6.compare<int32_t>(r27.s32, r11.s32, xer);
	// bge cr6,0x820afbf4
	if (!cr6.getLT()) goto loc_820AFBF4;
	// lwz r11,-1364(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + -1364);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// lwz r10,8288(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8288);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,8288(r11)
	PPC_STORE_U32(r11.u32 + 8288, ctx.r10.u32);
	// lwz r11,-1364(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + -1364);
	// lwz r9,8288(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 8288);
	// lwz r11,-1892(r22)
	r11.u64 = PPC_LOAD_U32(r22.u32 + -1892);
	// rotlwi r10,r9,1
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 1);
	// divw r8,r9,r11
	ctx.r8.s32 = ctx.r9.s32 / r11.s32;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// mullw r8,r8,r11
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(r11.s32);
	// subf r30,r8,r9
	r30.s64 = ctx.r9.s64 - ctx.r8.s64;
	// twllei r11,0
	// andc r11,r11,r10
	r11.u64 = r11.u64 & ~ctx.r10.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// twlgei r11,-1
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// li r26,0
	r26.s64 = 0;
	// li r31,0
	r31.s64 = 0;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// ble cr6,0x820afa68
	if (!cr6.getGT()) goto loc_820AFA68;
	// mr r29,r17
	r29.u64 = r17.u64;
loc_820AFB10:
	// cmpw cr6,r31,r19
	cr6.compare<int32_t>(r31.s32, r19.s32, xer);
	// beq cr6,0x820afbc8
	if (cr6.getEQ()) goto loc_820AFBC8;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r10,428(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820afbc0
	if (cr6.getEQ()) goto loc_820AFBC0;
	// rlwinm r8,r30,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// lwz r9,428(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// lwzx r11,r8,r20
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + r20.u32);
	// lfs f4,20(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	ctx.f4.f64 = double(temp.f32);
	// lfs f0,12(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12);
	f0.f64 = double(temp.f32);
	// lfs f13,20(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// lfs f3,12(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	ctx.f3.f64 = double(temp.f32);
	// stfd f4,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.f4.u64);
	// ld r8,56(r1)
	ctx.r8.u64 = PPC_LOAD_U64(ctx.r1.u32 + 56);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f0,f0,f12
	f0.f64 = double(float(f0.f64 - ctx.f12.f64));
	// lfs f11,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fsubs f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// stfd f3,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.f3.u64);
	// fmr f2,f11
	ctx.f2.f64 = ctx.f11.f64;
	// stfd f2,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.f2.u64);
	// fmr f1,f12
	ctx.f1.f64 = ctx.f12.f64;
	// stfd f1,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.f1.u64);
	// ld r7,48(r1)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r1.u32 + 48);
	// ld r6,40(r1)
	ctx.r6.u64 = PPC_LOAD_U64(ctx.r1.u32 + 40);
	// ld r5,32(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 32);
	// fmuls f0,f0,f0
	f0.f64 = double(float(f0.f64 * f0.f64));
	// fmadds f0,f13,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// fsqrts f31,f0
	f31.f64 = double(float(sqrt(f0.f64)));
	// fmr f5,f31
	ctx.f5.f64 = f31.f64;
	// stfd f5,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.f5.u64);
	// ld r9,64(r1)
	ctx.r9.u64 = PPC_LOAD_U64(ctx.r1.u32 + 64);
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// bge cr6,0x820afbc8
	if (!cr6.getLT()) goto loc_820AFBC8;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// li r26,1
	r26.s64 = 1;
	// b 0x820afbc8
	goto loc_820AFBC8;
loc_820AFBC0:
	// mr r3,r18
	ctx.r3.u64 = r18.u64;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
loc_820AFBC8:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// addi r29,r29,4
	r29.s64 = r29.s64 + 4;
	// cmpw cr6,r31,r23
	cr6.compare<int32_t>(r31.s32, r23.s32, xer);
	// blt cr6,0x820afb10
	if (cr6.getLT()) goto loc_820AFB10;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// bne cr6,0x820afaa0
	if (!cr6.getEQ()) goto loc_820AFAA0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// lfd f30,-144(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -144);
	// lfd f31,-136(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -136);
	// b 0x823ed15c
	return;
loc_820AFBF4:
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x820afa68
	if (cr6.getEQ()) goto loc_820AFA68;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r19,1
	ctx.r4.s64 = r19.s64 + 1;
	// addi r3,r11,14768
	ctx.r3.s64 = r11.s64 + 14768;
	// bl 0x823ed380
	sub_823ED380(ctx, base);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r31,r3,31
	r31.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r10,-1892(r22)
	ctx.r10.u64 = PPC_LOAD_U32(r22.u32 + -1892);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// twllei r10,0
	// divwu r9,r11,r10
	ctx.r9.u32 = r11.u32 / ctx.r10.u32;
	// mullw r10,r9,r10
	ctx.r10.s64 = int64_t(ctx.r9.s32) * int64_t(ctx.r10.s32);
	// subf r3,r10,r11
	ctx.r3.s64 = r11.s64 - ctx.r10.s64;
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// lfd f30,-144(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -144);
	// lfd f31,-136(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -136);
	// b 0x823ed15c
	return;
}

__attribute__((alias("__imp__sub_820AFC48"))) PPC_WEAK_FUNC(sub_820AFC48);
PPC_FUNC_IMPL(__imp__sub_820AFC48) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// lis r31,-32014
	r31.s64 = -2098069504;
	// ble cr6,0x820afc84
	if (!cr6.getGT()) goto loc_820AFC84;
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// bl 0x820eb880
	sub_820EB880(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r3,1368(r11)
	PPC_STORE_U32(r11.u32 + 1368, ctx.r3.u32);
	// bl 0x820c9b80
	sub_820C9B80(ctx, base);
	// bl 0x820eb880
	sub_820EB880(ctx, base);
	// bl 0x820c2b30
	sub_820C2B30(ctx, base);
loc_820AFC84:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r7,2
	ctx.r7.s64 = 2;
	// li r9,1
	ctx.r9.s64 = 1;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,184(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 184, temp.u32);
	// stfs f0,188(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 188, temp.u32);
	// stfs f0,192(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 192, temp.u32);
	// stfs f0,196(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 196, temp.u32);
	// stfs f0,200(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 200, temp.u32);
	// li r11,0
	r11.s64 = 0;
	// stfs f0,204(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 204, temp.u32);
	// stfs f0,208(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 208, temp.u32);
	// stfs f0,212(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 212, temp.u32);
	// stfs f0,216(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 216, temp.u32);
	// stw r11,128(r10)
	PPC_STORE_U32(ctx.r10.u32 + 128, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,132(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 132, temp.u32);
	// stfs f0,136(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 136, temp.u32);
	// stfs f0,140(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 140, temp.u32);
	// stfs f0,144(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 144, temp.u32);
	// stfs f0,148(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 148, temp.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f13,152(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 152, temp.u32);
	// stw r11,180(r10)
	PPC_STORE_U32(ctx.r10.u32 + 180, r11.u32);
	// stfs f0,156(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 156, temp.u32);
	// stfs f13,160(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 160, temp.u32);
	// stfs f0,164(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 164, temp.u32);
	// stfs f0,168(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 168, temp.u32);
	// stfs f0,172(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 172, temp.u32);
	// stfs f0,176(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 176, temp.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,1260(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1260, temp.u32);
	// stfs f0,1264(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1264, temp.u32);
	// stfs f13,1268(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1268, temp.u32);
	// stfs f0,392(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 392, temp.u32);
	// stfs f0,396(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 396, temp.u32);
	// stw r11,400(r10)
	PPC_STORE_U32(ctx.r10.u32 + 400, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,404(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 404, temp.u32);
	// stw r11,408(r10)
	PPC_STORE_U32(ctx.r10.u32 + 408, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,412(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 412, temp.u32);
	// stfs f0,4892(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4892, temp.u32);
	// stfs f0,4896(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4896, temp.u32);
	// stfs f0,4900(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4900, temp.u32);
	// stw r7,416(r10)
	PPC_STORE_U32(ctx.r10.u32 + 416, ctx.r7.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stb r11,8520(r10)
	PPC_STORE_U8(ctx.r10.u32 + 8520, r11.u8);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r7,8316(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8316, ctx.r7.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,420(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 420, temp.u32);
	// stfs f0,424(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 424, temp.u32);
	// stw r9,432(r10)
	PPC_STORE_U32(ctx.r10.u32 + 432, ctx.r9.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,468(r10)
	PPC_STORE_U32(ctx.r10.u32 + 468, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,472(r10)
	PPC_STORE_U32(ctx.r10.u32 + 472, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,480(r10)
	PPC_STORE_U32(ctx.r10.u32 + 480, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f13,484(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 484, temp.u32);
	// stfs f0,488(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 488, temp.u32);
	// stfs f13,492(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 492, temp.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f12,6580(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6580);
	ctx.f12.f64 = double(temp.f32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,496(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 496, temp.u32);
	// stfs f13,500(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 500, temp.u32);
	// stfs f0,504(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 504, temp.u32);
	// stfs f12,508(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 508, temp.u32);
	// stfs f12,512(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 512, temp.u32);
	// stw r11,736(r10)
	PPC_STORE_U32(ctx.r10.u32 + 736, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,740(r10)
	PPC_STORE_U32(ctx.r10.u32 + 740, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,744(r10)
	PPC_STORE_U32(ctx.r10.u32 + 744, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// stw r9,748(r10)
	PPC_STORE_U32(ctx.r10.u32 + 748, ctx.r9.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,752(r10)
	PPC_STORE_U32(ctx.r10.u32 + 752, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,704(r10)
	PPC_STORE_U32(ctx.r10.u32 + 704, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,700(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 700, temp.u32);
	// stfs f0,600(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 600, temp.u32);
	// stfs f0,8516(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8516, temp.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f11,15088(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15088);
	ctx.f11.f64 = double(temp.f32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// fmr f10,f11
	ctx.f10.f64 = ctx.f11.f64;
	// stfs f13,604(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 604, temp.u32);
	// stfs f0,608(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 608, temp.u32);
	// stfs f11,612(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 612, temp.u32);
	// stfs f11,616(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 616, temp.u32);
	// lfs f11,14020(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 14020);
	ctx.f11.f64 = double(temp.f32);
	// li r8,-1
	ctx.r8.s64 = -1;
	// fadds f11,f10,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 + ctx.f11.f64));
	// stfs f11,616(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 616, temp.u32);
	// stfs f0,620(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 620, temp.u32);
	// stfs f0,8512(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8512, temp.u32);
	// stfs f13,624(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 624, temp.u32);
	// stfs f0,628(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 628, temp.u32);
	// stfs f0,632(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 632, temp.u32);
	// stfs f0,636(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 636, temp.u32);
	// stfs f0,640(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 640, temp.u32);
	// stfs f0,8396(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8396, temp.u32);
	// stfs f13,644(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 644, temp.u32);
	// stw r11,648(r10)
	PPC_STORE_U32(ctx.r10.u32 + 648, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,652(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 652, temp.u32);
	// stfs f0,656(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 656, temp.u32);
	// stfs f0,660(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 660, temp.u32);
	// stfs f0,664(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 664, temp.u32);
	// stfs f0,668(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 668, temp.u32);
	// stfs f0,672(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 672, temp.u32);
	// stfs f0,676(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 676, temp.u32);
	// stfs f0,680(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 680, temp.u32);
	// stw r11,524(r10)
	PPC_STORE_U32(ctx.r10.u32 + 524, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,528(r10)
	PPC_STORE_U32(ctx.r10.u32 + 528, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,532(r10)
	PPC_STORE_U32(ctx.r10.u32 + 532, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,536(r10)
	PPC_STORE_U32(ctx.r10.u32 + 536, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r9,540(r10)
	PPC_STORE_U32(ctx.r10.u32 + 540, ctx.r9.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r9,544(r10)
	PPC_STORE_U32(ctx.r10.u32 + 544, ctx.r9.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,548(r10)
	PPC_STORE_U32(ctx.r10.u32 + 548, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r9,552(r10)
	PPC_STORE_U32(ctx.r10.u32 + 552, ctx.r9.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,556(r10)
	PPC_STORE_U32(ctx.r10.u32 + 556, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r9,564(r10)
	PPC_STORE_U32(ctx.r10.u32 + 564, ctx.r9.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,572(r10)
	PPC_STORE_U32(ctx.r10.u32 + 572, r11.u32);
	// stfs f0,568(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 568, temp.u32);
	// lwz r6,-1364(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r10,255
	ctx.r10.s64 = 255;
	// stw r8,576(r6)
	PPC_STORE_U32(ctx.r6.u32 + 576, ctx.r8.u32);
	// lwz r6,-1364(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r9,580(r6)
	PPC_STORE_U32(ctx.r6.u32 + 580, ctx.r9.u32);
	// lwz r9,-1364(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,584(r9)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 584, temp.u32);
	// stw r11,588(r9)
	PPC_STORE_U32(ctx.r9.u32 + 588, r11.u32);
	// lwz r9,-1364(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r8,592(r9)
	PPC_STORE_U32(ctx.r9.u32 + 592, ctx.r8.u32);
	// lwz r9,-1364(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r10,1272(r9)
	PPC_STORE_U32(ctx.r9.u32 + 1272, ctx.r10.u32);
	// lwz r9,-1364(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r10,1276(r9)
	PPC_STORE_U32(ctx.r9.u32 + 1276, ctx.r10.u32);
	// lwz r9,-1364(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r10,1280(r9)
	PPC_STORE_U32(ctx.r9.u32 + 1280, ctx.r10.u32);
	// lwz r9,-1364(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,1284(r9)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 1284, temp.u32);
	// stfs f12,1288(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 1288, temp.u32);
	// stfs f12,1292(r9)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r9.u32 + 1292, temp.u32);
	// stw r10,1296(r9)
	PPC_STORE_U32(ctx.r9.u32 + 1296, ctx.r10.u32);
	// lwz r9,-1364(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r10,1300(r9)
	PPC_STORE_U32(ctx.r9.u32 + 1300, ctx.r10.u32);
	// lwz r9,-1364(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r10,1304(r9)
	PPC_STORE_U32(ctx.r9.u32 + 1304, ctx.r10.u32);
	// lwz r9,-1364(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r10,1308(r9)
	PPC_STORE_U32(ctx.r9.u32 + 1308, ctx.r10.u32);
	// lwz r9,-1364(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r10,1312(r9)
	PPC_STORE_U32(ctx.r9.u32 + 1312, ctx.r10.u32);
	// lwz r9,-1364(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r10,1316(r9)
	PPC_STORE_U32(ctx.r9.u32 + 1316, ctx.r10.u32);
	// li r9,8
	ctx.r9.s64 = 8;
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,1320(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1320, temp.u32);
	// stfs f0,1324(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1324, temp.u32);
	// stfs f12,684(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 684, temp.u32);
	// stfs f12,688(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 688, temp.u32);
	// stfs f0,692(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 692, temp.u32);
	// stfs f0,696(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 696, temp.u32);
	// stw r7,1364(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1364, ctx.r7.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,1368(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1368, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,808(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 808, temp.u32);
	// stfs f0,812(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 812, temp.u32);
	// stfs f0,816(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 816, temp.u32);
	// stfs f0,820(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 820, temp.u32);
	// stfs f0,824(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 824, temp.u32);
	// stw r11,828(r10)
	PPC_STORE_U32(ctx.r10.u32 + 828, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,836(r10)
	PPC_STORE_U32(ctx.r10.u32 + 836, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,840(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 840, temp.u32);
	// stw r11,800(r10)
	PPC_STORE_U32(ctx.r10.u32 + 800, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,804(r10)
	PPC_STORE_U32(ctx.r10.u32 + 804, r11.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,14436(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14436);
	ctx.f13.f64 = double(temp.f32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,1240(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1240, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,1244(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1244, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f13,8256(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8256, temp.u32);
	// sth r8,8324(r10)
	PPC_STORE_U16(ctx.r10.u32 + 8324, ctx.r8.u16);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,8328(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8328, temp.u32);
	// stfs f0,8332(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8332, temp.u32);
	// stw r11,8428(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8428, r11.u32);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r11,8432(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8432, r11.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stw r9,8524(r11)
	PPC_STORE_U32(r11.u32 + 8524, ctx.r9.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B0000"))) PPC_WEAK_FUNC(sub_820B0000);
PPC_FUNC_IMPL(__imp__sub_820B0000) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// lbz r9,8520(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 8520);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x820b002c
	if (cr6.getEQ()) goto loc_820B002C;
	// clrlwi r8,r4,24
	ctx.r8.u64 = ctx.r4.u32 & 0xFF;
	// cmplw cr6,r9,r8
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r8.u32, xer);
	// beq cr6,0x820b002c
	if (cr6.getEQ()) goto loc_820B002C;
	// lwz r9,416(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 416);
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
loc_820B002C:
	// lwz r9,416(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 416);
	// li r8,0
	ctx.r8.s64 = 0;
	// add r9,r9,r3
	ctx.r9.u64 = ctx.r9.u64 + ctx.r3.u64;
	// stw r9,416(r11)
	PPC_STORE_U32(r11.u32 + 416, ctx.r9.u32);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// lwz r9,416(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 416);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bge cr6,0x820b0054
	if (!cr6.getLT()) goto loc_820B0054;
	// stw r8,416(r11)
	PPC_STORE_U32(r11.u32 + 416, ctx.r8.u32);
	// b 0x820b0064
	goto loc_820B0064;
loc_820B0054:
	// cmpwi cr6,r9,2
	cr6.compare<int32_t>(ctx.r9.s32, 2, xer);
	// ble cr6,0x820b0068
	if (!cr6.getGT()) goto loc_820B0068;
	// li r9,2
	ctx.r9.s64 = 2;
	// stw r9,416(r11)
	PPC_STORE_U32(r11.u32 + 416, ctx.r9.u32);
loc_820B0064:
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
loc_820B0068:
	// lwz r10,416(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 416);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x820b007c
	if (!cr6.getEQ()) goto loc_820B007C;
	// stb r4,8520(r11)
	PPC_STORE_U8(r11.u32 + 8520, ctx.r4.u8);
	// blr 
	return;
loc_820B007C:
	// stb r8,8520(r11)
	PPC_STORE_U8(r11.u32 + 8520, ctx.r8.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B0088"))) PPC_WEAK_FUNC(sub_820B0088);
PPC_FUNC_IMPL(__imp__sub_820B0088) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,416(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 416);
	// lwz r3,8316(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 8316);
	// cmpw cr6,r10,r3
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r3.s32, xer);
	// bgelr cr6
	if (!cr6.getLT()) return;
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B00A8"))) PPC_WEAK_FUNC(sub_820B00A8);
PPC_FUNC_IMPL(__imp__sub_820B00A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f3,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lfs f0,132(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 132);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f3,f0
	cr6.compare(ctx.f3.f64, f0.f64);
	// bne cr6,0x820b0164
	if (!cr6.getEQ()) goto loc_820B0164;
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,136(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 136);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x820b0164
	if (!cr6.getEQ()) goto loc_820B0164;
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f13,140(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 140);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x820b0164
	if (!cr6.getEQ()) goto loc_820B0164;
	// lfs f0,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f13,144(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 144);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x820b0164
	if (!cr6.getEQ()) goto loc_820B0164;
	// lfs f0,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,148(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 148);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x820b0164
	if (!cr6.getEQ()) goto loc_820B0164;
	// lfs f0,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f13,152(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 152);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x820b0164
	if (!cr6.getEQ()) goto loc_820B0164;
	// lfs f0,0(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f13,156(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 156);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x820b0164
	if (!cr6.getEQ()) goto loc_820B0164;
	// lfs f0,4(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,160(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 160);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x820b0164
	if (!cr6.getEQ()) goto loc_820B0164;
	// lfs f0,8(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f13,164(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 164);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bne cr6,0x820b0164
	if (!cr6.getEQ()) goto loc_820B0164;
	// lwz r11,180(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 180);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x820b0260
	if (!cr6.getEQ()) goto loc_820B0260;
loc_820B0164:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f4,8(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// lfs f2,8(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// stw r6,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r6.u32);
	// lfs f1,0(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820b019c
	if (cr6.getEQ()) goto loc_820B019C;
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lfs f2,8(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210ee60
	sub_8210EE60(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// b 0x820b01dc
	goto loc_820B01DC;
loc_820B019C:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r10,180(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 180);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820b01dc
	if (cr6.getEQ()) goto loc_820B01DC;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lfs f4,8(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// lfs f3,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// lfs f2,140(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 140);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,132(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 132);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bne cr6,0x820b01e0
	if (!cr6.getEQ()) goto loc_820B01E0;
loc_820B01DC:
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_820B01E0:
	// stw r10,180(r11)
	PPC_STORE_U32(r11.u32 + 180, ctx.r10.u32);
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f0.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r10,r11,132
	ctx.r10.s64 = r11.s64 + 132;
	// addi r9,r11,140
	ctx.r9.s64 = r11.s64 + 140;
	// stfs f0,132(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 132, temp.u32);
	// lwz r3,180(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 180);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,136(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 136, temp.u32);
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,140(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 140, temp.u32);
	// lfs f0,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,144(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 144, temp.u32);
	// lfs f0,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,148(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 148, temp.u32);
	// lfs f0,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,152(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 152, temp.u32);
	// lfs f0,0(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,156(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 156, temp.u32);
	// lfs f0,4(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,160(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 160, temp.u32);
	// lfs f0,8(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,164(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 164, temp.u32);
	// lfs f0,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,168(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 168, temp.u32);
	// lfs f0,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,176(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 176, temp.u32);
	// lfs f2,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x821108b0
	sub_821108B0(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f1,172(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r11.u32 + 172, temp.u32);
loc_820B0260:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820B0268"))) PPC_WEAK_FUNC(sub_820B0268);
PPC_FUNC_IMPL(__imp__sub_820B0268) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r3,-1760(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + -1760);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B0278"))) PPC_WEAK_FUNC(sub_820B0278);
PPC_FUNC_IMPL(__imp__sub_820B0278) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f16{};
	PPCRegister f17{};
	PPCRegister f18{};
	PPCRegister f19{};
	PPCRegister f20{};
	PPCRegister f21{};
	PPCRegister f22{};
	PPCRegister f23{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed120
	// addi r12,r1,-88
	r12.s64 = ctx.r1.s64 + -88;
	// bl 0x823ed518
	// stwu r1,-384(r1)
	ea = -384 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// fmr f24,f1
	ctx.fpscr.disableFlushMode();
	f24.f64 = ctx.f1.f64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// mr r25,r7
	r25.u64 = ctx.r7.u64;
	// stw r3,-3668(r11)
	PPC_STORE_U32(r11.u32 + -3668, ctx.r3.u32);
	// lis r26,-32256
	r26.s64 = -2113929216;
	// lis r29,-32256
	r29.s64 = -2113929216;
	// lis r3,-32256
	ctx.r3.s64 = -2113929216;
	// lis r4,-32256
	ctx.r4.s64 = -2113929216;
	// lis r5,-32256
	ctx.r5.s64 = -2113929216;
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// lfs f19,12900(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 12900);
	f19.f64 = double(temp.f32);
	// lis r7,-32256
	ctx.r7.s64 = -2113929216;
	// lfs f18,14108(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 14108);
	f18.f64 = double(temp.f32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lfs f22,15100(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 15100);
	f22.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f23,15096(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 15096);
	f23.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f29,2776(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 2776);
	f29.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f31,2688(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 2688);
	f31.f64 = double(temp.f32);
	// lfs f16,14152(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 14152);
	f16.f64 = double(temp.f32);
	// li r24,0
	r24.s64 = 0;
	// lfs f20,6588(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 6588);
	f20.f64 = double(temp.f32);
	// li r22,0
	r22.s64 = 0;
	// lfs f27,14028(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 14028);
	f27.f64 = double(temp.f32);
	// addi r31,r11,-2976
	r31.s64 = r11.s64 + -2976;
	// lfs f17,15092(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15092);
	f17.f64 = double(temp.f32);
	// lis r23,-32014
	r23.s64 = -2098069504;
loc_820B030C:
	// lwz r11,-1364(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + -1364);
	// lfs f25,1496(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1496);
	f25.f64 = double(temp.f32);
	// fadds f26,f25,f17
	f26.f64 = double(float(f25.f64 + f17.f64));
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// li r26,0
	r26.s64 = 0;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,104(r1)
	PPC_STORE_U64(ctx.r1.u32 + 104, r11.u64);
	// lfd f0,104(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 104);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f0,f0,f27
	f0.f64 = double(float(f0.f64 * f27.f64));
	// fmuls f21,f0,f20
	f21.f64 = double(float(f0.f64 * f20.f64));
loc_820B034C:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// bne cr6,0x820b05b8
	if (!cr6.getEQ()) goto loc_820B05B8;
	// fadds f21,f21,f16
	ctx.fpscr.disableFlushMode();
	f21.f64 = double(float(f21.f64 + f16.f64));
	// fcmpu cr6,f21,f20
	cr6.compare(f21.f64, f20.f64);
	// blt cr6,0x820b0364
	if (cr6.getLT()) goto loc_820B0364;
	// fsubs f21,f21,f20
	f21.f64 = double(float(f21.f64 - f20.f64));
loc_820B0364:
	// fmr f30,f21
	ctx.fpscr.disableFlushMode();
	f30.f64 = f21.f64;
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// stfs f31,148(r1)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(ctx.r1.u32 + 148, temp.u32);
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfs f0,144(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 144, temp.u32);
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// lfs f0,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,132(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 132, temp.u32);
	// frsp f0,f1
	f0.f64 = double(float(ctx.f1.f64));
	// lfs f13,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fmadds f13,f12,f26,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * f26.f64 + ctx.f13.f64));
	// stfs f0,152(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 152, temp.u32);
	// stfs f13,128(r1)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r1.u32 + 128, temp.u32);
	// fmadds f0,f0,f26,f11
	f0.f64 = double(float(f0.f64 * f26.f64 + ctx.f11.f64));
	// stfs f0,136(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 136, temp.u32);
	// bl 0x8210f8f0
	sub_8210F8F0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r25,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r25.u32);
	// bl 0x820ce1f0
	sub_820CE1F0(ctx, base);
	// li r8,19
	ctx.r8.s64 = 19;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f2,8(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmr f8,f29
	ctx.f8.f64 = f29.f64;
	// lfs f4,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f4.f64 = double(temp.f32);
	// fmr f7,f31
	ctx.f7.f64 = f31.f64;
	// lfs f3,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f3.f64 = double(temp.f32);
	// fmr f6,f29
	ctx.f6.f64 = f29.f64;
	// fmr f5,f31
	ctx.f5.f64 = f31.f64;
	// bl 0x82112020
	sub_82112020(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x820ce1f0
	sub_820CE1F0(ctx, base);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// bne cr6,0x820b0440
	if (!cr6.getEQ()) goto loc_820B0440;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82121c68
	sub_82121C68(ctx, base);
	// lfs f12,128(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,0(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	f0.f64 = double(temp.f32);
	// fsubs f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 - f0.f64));
	// lfs f13,8(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// fmuls f0,f0,f0
	f0.f64 = double(float(f0.f64 * f0.f64));
	// fmadds f0,f13,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f13.f64 + f0.f64));
	// fsqrts f26,f0
	f26.f64 = double(float(sqrt(f0.f64)));
loc_820B0440:
	// fsubs f26,f26,f25
	ctx.fpscr.disableFlushMode();
	f26.f64 = double(float(f26.f64 - f25.f64));
	// fcmpu cr6,f26,f24
	cr6.compare(f26.f64, f24.f64);
	// blt cr6,0x820b05ac
	if (cr6.getLT()) goto loc_820B05AC;
	// fmr f28,f29
	f28.f64 = f29.f64;
loc_820B0450:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// bne cr6,0x820b05ac
	if (!cr6.getEQ()) goto loc_820B05AC;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// fsubs f0,f26,f24
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f26.f64 - f24.f64));
	// lfs f13,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lfs f12,144(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,152(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	ctx.f11.f64 = double(temp.f32);
	// li r4,0
	ctx.r4.s64 = 0;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// stw r25,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r25.u32);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// std r11,112(r1)
	PPC_STORE_U64(ctx.r1.u32 + 112, r11.u64);
	// lfd f10,112(r1)
	ctx.f10.u64 = PPC_LOAD_U64(ctx.r1.u32 + 112);
	// fcfid f10,f10
	ctx.f10.f64 = double(ctx.f10.s64);
	// frsp f10,f10
	ctx.f10.f64 = double(float(ctx.f10.f64));
	// fmuls f10,f10,f27
	ctx.f10.f64 = double(float(ctx.f10.f64 * f27.f64));
	// fmuls f0,f10,f0
	f0.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fmadds f0,f0,f28,f24
	f0.f64 = double(float(f0.f64 * f28.f64 + f24.f64));
	// fmadds f13,f0,f12,f13
	ctx.f13.f64 = double(float(f0.f64 * ctx.f12.f64 + ctx.f13.f64));
	// stfs f13,0(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// lfs f13,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,4(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f0,f11,f13
	f0.f64 = double(float(f0.f64 * ctx.f11.f64 + ctx.f13.f64));
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// bl 0x820ce1f0
	sub_820CE1F0(ctx, base);
	// li r8,19
	ctx.r8.s64 = 19;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f2,8(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmr f8,f29
	ctx.f8.f64 = f29.f64;
	// lfs f4,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// fmr f7,f31
	ctx.f7.f64 = f31.f64;
	// lfs f3,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmr f6,f29
	ctx.f6.f64 = f29.f64;
	// fmr f5,f31
	ctx.f5.f64 = f31.f64;
	// bl 0x82112020
	sub_82112020(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x820ce1f0
	sub_820CE1F0(ctx, base);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x820b05a0
	if (cr6.getEQ()) goto loc_820B05A0;
	// li r7,31
	ctx.r7.s64 = 31;
	// lfs f2,8(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// lfs f1,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmr f5,f29
	ctx.f5.f64 = f29.f64;
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// fmr f3,f25
	ctx.f3.f64 = f25.f64;
	// bl 0x821126c0
	sub_821126C0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge cr6,0x820b05a0
	if (!cr6.getLT()) goto loc_820B05A0;
	// lwz r3,96(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lfs f2,8(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x821108b0
	sub_821108B0(ctx, base);
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// fsubs f0,f23,f25
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(f23.f64 - f25.f64));
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, r11.u64);
	// lfd f13,120(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f13,f27
	ctx.f13.f64 = double(float(ctx.f13.f64 * f27.f64));
	// fmadds f0,f13,f0,f30
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 + f30.f64));
	// fadds f0,f0,f25
	f0.f64 = double(float(f0.f64 + f25.f64));
	// stfs f0,4(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// lfs f13,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// fcmpu cr6,f0,f22
	cr6.compare(f0.f64, f22.f64);
	// ble cr6,0x820b05a0
	if (!cr6.getGT()) goto loc_820B05A0;
	// fcmpu cr6,f0,f18
	cr6.compare(f0.f64, f18.f64);
	// bge cr6,0x820b05a0
	if (!cr6.getLT()) goto loc_820B05A0;
	// li r24,1
	r24.s64 = 1;
loc_820B05A0:
	// fsubs f28,f28,f19
	ctx.fpscr.disableFlushMode();
	f28.f64 = double(float(f28.f64 - f19.f64));
	// fcmpu cr6,f28,f31
	cr6.compare(f28.f64, f31.f64);
	// bgt cr6,0x820b0450
	if (cr6.getGT()) goto loc_820B0450;
loc_820B05AC:
	// addi r26,r26,1
	r26.s64 = r26.s64 + 1;
	// cmpwi cr6,r26,16
	cr6.compare<int32_t>(r26.s32, 16, xer);
	// blt cr6,0x820b034c
	if (cr6.getLT()) goto loc_820B034C;
loc_820B05B8:
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// cmpwi cr6,r22,128
	cr6.compare<int32_t>(r22.s32, 128, xer);
	// bgt cr6,0x820b05cc
	if (cr6.getGT()) goto loc_820B05CC;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// beq cr6,0x820b030c
	if (cr6.getEQ()) goto loc_820B030C;
loc_820B05CC:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// addi r1,r1,384
	ctx.r1.s64 = ctx.r1.s64 + 384;
	// addi r12,r1,-88
	r12.s64 = ctx.r1.s64 + -88;
	// bl 0x823ed564
	// b 0x823ed170
	return;
}

__attribute__((alias("__imp__sub_820B05E0"))) PPC_WEAK_FUNC(sub_820B05E0);
PPC_FUNC_IMPL(__imp__sub_820B05E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stfd f30,-64(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -64, f30.u64);
	// stfd f31,-56(r1)
	PPC_STORE_U64(ctx.r1.u32 + -56, f31.u64);
	// stwu r1,-192(r1)
	ea = -192 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r27,-32014
	r27.s64 = -2098069504;
	// rlwinm r28,r3,5,0,26
	r28.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 5) & 0xFFFFFFE0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// lwz r4,-1740(r27)
	ctx.r4.u64 = PPC_LOAD_U32(r27.u32 + -1740);
	// add r7,r28,r4
	ctx.r7.u64 = r28.u64 + ctx.r4.u64;
	// lfs f30,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f30.f64 = double(temp.f32);
	// fmr f31,f30
	f31.f64 = f30.f64;
	// lfs f0,24(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 24);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// ble cr6,0x820b0628
	if (!cr6.getGT()) goto loc_820B0628;
	// fdivs f31,f1,f0
	f31.f64 = double(float(ctx.f1.f64 / f0.f64));
loc_820B0628:
	// lis r31,-32014
	r31.s64 = -2098069504;
	// li r6,-1
	ctx.r6.s64 = -1;
	// li r8,-32
	ctx.r8.s64 = -32;
	// addi r9,r1,84
	ctx.r9.s64 = ctx.r1.s64 + 84;
	// lwz r5,-1364(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + -1364);
loc_820B063C:
	// mr r11,r7
	r11.u64 = ctx.r7.u64;
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// add r10,r8,r11
	ctx.r10.u64 = ctx.r8.u64 + r11.u64;
	// bge cr6,0x820b0664
	if (!cr6.getLT()) goto loc_820B0664;
	// cmplw cr6,r10,r4
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r4.u32, xer);
	// bge cr6,0x820b065c
	if (!cr6.getLT()) goto loc_820B065C;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// b 0x820b0688
	goto loc_820B0688;
loc_820B065C:
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// b 0x820b0688
	goto loc_820B0688;
loc_820B0664:
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x820b0688
	if (!cr6.getLT()) goto loc_820B0688;
loc_820B066C:
	// lwz r3,36(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// clrlwi r3,r3,31
	ctx.r3.u64 = ctx.r3.u32 & 0x1;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x820b0688
	if (!cr6.getEQ()) goto loc_820B0688;
	// addi r11,r11,32
	r11.s64 = r11.s64 + 32;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x820b066c
	if (cr6.getLT()) goto loc_820B066C;
loc_820B0688:
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// rlwinm r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x820b06d8
	if (cr6.getEQ()) goto loc_820B06D8;
	// lfs f13,16(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,1472(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 1472);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,1480(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 1480);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f13,f12,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + f0.f64));
	// stfs f0,-4(r9)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + -4, temp.u32);
	// lfs f0,12(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r9)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lfs f13,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,1472(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 1472);
	f0.f64 = double(temp.f32);
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// lfs f12,16(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,1480(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 1480);
	ctx.f13.f64 = double(temp.f32);
	// fmsubs f0,f13,f12,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 - f0.f64));
	// b 0x820b06ec
	goto loc_820B06EC;
loc_820B06D8:
	// lfs f0,8(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,-4(r9)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + -4, temp.u32);
	// lfs f0,12(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r9)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// lfs f0,16(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16);
	f0.f64 = double(temp.f32);
loc_820B06EC:
	// addi r8,r8,32
	ctx.r8.s64 = ctx.r8.s64 + 32;
	// stfs f0,4(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 4, temp.u32);
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
	// addi r9,r9,12
	ctx.r9.s64 = ctx.r9.s64 + 12;
	// cmpwi cr6,r8,96
	cr6.compare<int32_t>(ctx.r8.s32, 96, xer);
	// blt cr6,0x820b063c
	if (cr6.getLT()) goto loc_820B063C;
	// mr r9,r30
	ctx.r9.u64 = r30.u64;
	// lfs f2,20(r7)
	temp.u32 = PPC_LOAD_U32(ctx.r7.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// addi r6,r1,116
	ctx.r6.s64 = ctx.r1.s64 + 116;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// addi r5,r1,104
	ctx.r5.s64 = ctx.r1.s64 + 104;
	// addi r4,r1,92
	ctx.r4.s64 = ctx.r1.s64 + 92;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8210b020
	sub_8210B020(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f13,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,1260(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1260);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,0(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 0, temp.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f13,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,1264(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1264);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,4(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 4, temp.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,1268(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1268);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,8(r30)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r30.u32 + 8, temp.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,1260(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1260);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r29)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// lfs f0,1264(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1264);
	f0.f64 = double(temp.f32);
	// stfs f0,4(r29)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r29.u32 + 4, temp.u32);
	// lfs f0,1268(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1268);
	f0.f64 = double(temp.f32);
	// lwz r11,-1740(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + -1740);
	// stfs f0,8(r29)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r29.u32 + 8, temp.u32);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,36(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 36);
	// rlwinm r10,r10,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	// rlwinm r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820b07b4
	if (!cr6.getEQ()) goto loc_820B07B4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	f0.f64 = double(temp.f32);
	// beq cr6,0x820b07c8
	if (cr6.getEQ()) goto loc_820B07C8;
	// fsubs f0,f0,f31
	f0.f64 = double(float(f0.f64 - f31.f64));
	// b 0x820b07c8
	goto loc_820B07C8;
loc_820B07B4:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820b07c4
	if (cr6.getEQ()) goto loc_820B07C4;
	// fmr f0,f30
	ctx.fpscr.disableFlushMode();
	f0.f64 = f30.f64;
	// b 0x820b07c8
	goto loc_820B07C8;
loc_820B07C4:
	// fmr f0,f31
	ctx.fpscr.disableFlushMode();
	f0.f64 = f31.f64;
loc_820B07C8:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f11,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,1512(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1512);
	ctx.f12.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * f0.f64));
	// lfs f13,2956(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2956);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// fmadds f12,f12,f13,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + ctx.f11.f64));
	// stfs f12,0(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r29.u32 + 0, temp.u32);
	// lfs f12,1516(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1516);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 * f0.f64));
	// fmadds f12,f12,f13,f10
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + ctx.f10.f64));
	// stfs f12,4(r29)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r29.u32 + 4, temp.u32);
	// lfs f12,1520(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1520);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * f0.f64));
	// fmadds f0,f0,f13,f9
	f0.f64 = double(float(f0.f64 * ctx.f13.f64 + ctx.f9.f64));
	// stfs f0,8(r29)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r29.u32 + 8, temp.u32);
	// addi r1,r1,192
	ctx.r1.s64 = ctx.r1.s64 + 192;
	// lfd f30,-64(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -64);
	// lfd f31,-56(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -56);
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_820B0828"))) PPC_WEAK_FUNC(sub_820B0828);
PPC_FUNC_IMPL(__imp__sub_820B0828) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x820b085c
	if (!cr6.getEQ()) goto loc_820B085C;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r3,564(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 564);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820B085C:
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-908(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -908);
	// lbz r3,106(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 106);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B0878"))) PPC_WEAK_FUNC(sub_820B0878);
PPC_FUNC_IMPL(__imp__sub_820B0878) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r3,556(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 556);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B0888"))) PPC_WEAK_FUNC(sub_820B0888);
PPC_FUNC_IMPL(__imp__sub_820B0888) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// lwz r9,576(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 576);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// blt cr6,0x820b08b4
	if (cr6.getLT()) goto loc_820B08B4;
	// rotlwi r8,r9,0
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// lis r9,-32014
	ctx.r9.s64 = -2098069504;
	// lwz r9,-6384(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + -6384);
	// subf r9,r9,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r9.s64;
	// stw r9,576(r11)
	PPC_STORE_U32(r11.u32 + 576, ctx.r9.u32);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
loc_820B08B4:
	// lwz r9,572(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 572);
	// cmplw cr6,r3,r9
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, xer);
	// beq cr6,0x820b08e0
	if (cr6.getEQ()) goto loc_820B08E0;
	// lwz r9,576(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 576);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bgelr cr6
	if (!cr6.getLT()) return;
	// li r9,30
	ctx.r9.s64 = 30;
	// stw r9,576(r11)
	PPC_STORE_U32(r11.u32 + 576, ctx.r9.u32);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// stw r3,572(r11)
	PPC_STORE_U32(r11.u32 + 572, ctx.r3.u32);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
loc_820B08E0:
	// stfs f1,568(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r11.u32 + 568, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B08E8"))) PPC_WEAK_FUNC(sub_820B08E8);
PPC_FUNC_IMPL(__imp__sub_820B08E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820c9af0
	sub_820C9AF0(ctx, base);
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// bne cr6,0x820b091c
	if (!cr6.getEQ()) goto loc_820B091C;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r3,580(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 580);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820B091C:
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-908(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -908);
	// lbz r3,106(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 106);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B0938"))) PPC_WEAK_FUNC(sub_820B0938);
PPC_FUNC_IMPL(__imp__sub_820B0938) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// lwz r9,592(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 592);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// blt cr6,0x820b0964
	if (cr6.getLT()) goto loc_820B0964;
	// rotlwi r8,r9,0
	ctx.r8.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// lis r9,-32014
	ctx.r9.s64 = -2098069504;
	// lwz r9,-6384(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + -6384);
	// subf r9,r9,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r9.s64;
	// stw r9,592(r11)
	PPC_STORE_U32(r11.u32 + 592, ctx.r9.u32);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
loc_820B0964:
	// lwz r9,588(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 588);
	// cmplw cr6,r3,r9
	cr6.compare<uint32_t>(ctx.r3.u32, ctx.r9.u32, xer);
	// beq cr6,0x820b0990
	if (cr6.getEQ()) goto loc_820B0990;
	// lwz r9,592(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 592);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bgelr cr6
	if (!cr6.getLT()) return;
	// li r9,30
	ctx.r9.s64 = 30;
	// stw r9,592(r11)
	PPC_STORE_U32(r11.u32 + 592, ctx.r9.u32);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// stw r3,588(r11)
	PPC_STORE_U32(r11.u32 + 588, ctx.r3.u32);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
loc_820B0990:
	// stfs f1,584(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r11.u32 + 584, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B0998"))) PPC_WEAK_FUNC(sub_820B0998);
PPC_FUNC_IMPL(__imp__sub_820B0998) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,0(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,4(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 4, temp.u32);
	// lfs f0,4(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// lfs f12,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// stw r5,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r5.u32);
	// lfs f13,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f12,12(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 12, temp.u32);
	// stw r5,80(r3)
	PPC_STORE_U32(ctx.r3.u32 + 80, ctx.r5.u32);
	// lfs f12,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f10.f64 = double(temp.f32);
	// lfs f0,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f13,56(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 56, temp.u32);
	// stfs f0,60(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 60, temp.u32);
	// stfs f0,64(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 64, temp.u32);
	// stfs f0,68(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 68, temp.u32);
	// lfs f9,3112(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 3112);
	ctx.f9.f64 = double(temp.f32);
	// stfs f13,72(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 72, temp.u32);
	// stfs f0,76(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 76, temp.u32);
	// stfs f0,16(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 16, temp.u32);
	// stfs f0,20(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 20, temp.u32);
	// stfs f13,24(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 24, temp.u32);
	// stfs f9,40(r3)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r3.u32 + 40, temp.u32);
	// stfs f12,44(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 44, temp.u32);
	// stfs f11,48(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 48, temp.u32);
	// stfs f10,52(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 52, temp.u32);
	// stfs f12,28(r3)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r3.u32 + 28, temp.u32);
	// stfs f11,32(r3)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r3.u32 + 32, temp.u32);
	// stfs f10,36(r3)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r3.u32 + 36, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B0A20"))) PPC_WEAK_FUNC(sub_820B0A20);
PPC_FUNC_IMPL(__imp__sub_820B0A20) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1828(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1828);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820b0ad4
	if (cr6.getEQ()) goto loc_820B0AD4;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// lfs f0,6588(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6588);
	f0.f64 = double(temp.f32);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lfs f13,-1792(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -1792);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f1,f0,f13
	ctx.f1.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r30,4(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r29,4(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// bl 0x8210b8c8
	sub_8210B8C8(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f0,0(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	f0.f64 = double(temp.f32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// addi r31,r11,-3684
	r31.s64 = r11.s64 + -3684;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// stfs f0,0(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// stfs f0,4(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// lfs f13,0(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	f0.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// stfs f0,0(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// lfs f13,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,4(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 4);
	f0.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// stfs f0,4(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	f0.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
loc_820B0AD4:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820B0AE0"))) PPC_WEAK_FUNC(sub_820B0AE0);
PPC_FUNC_IMPL(__imp__sub_820B0AE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// addi r12,r1,-32
	r12.s64 = ctx.r1.s64 + -32;
	// bl 0x823ed544
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// fmr f31,f1
	ctx.fpscr.disableFlushMode();
	f31.f64 = ctx.f1.f64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lwz r11,-1828(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1828);
	// lwz r29,8(r11)
	r29.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x820d4ac0
	sub_820D4AC0(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f13,4(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// addi r11,r11,-3684
	r11.s64 = r11.s64 + -3684;
	// lfs f12,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	f0.f64 = double(temp.f32);
	// fsubs f30,f13,f0
	f30.f64 = double(float(ctx.f13.f64 - f0.f64));
	// lfs f13,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f29,f12,f0
	f29.f64 = double(float(ctx.f12.f64 - f0.f64));
	// lfs f0,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f12,24(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f28,f13,f0
	f28.f64 = double(float(ctx.f13.f64 - f0.f64));
	// fsubs f27,f12,f0
	f27.f64 = double(float(ctx.f12.f64 - f0.f64));
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// lfs f13,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f31,f13,f0
	f31.f64 = double(float(ctx.f13.f64 * f0.f64));
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// lwz r11,20(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 20);
	// fmuls f13,f31,f30
	ctx.f13.f64 = double(float(f31.f64 * f30.f64));
	// lfs f6,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// fmuls f12,f31,f29
	ctx.f12.f64 = double(float(f31.f64 * f29.f64));
	// fmuls f11,f31,f28
	ctx.f11.f64 = double(float(f31.f64 * f28.f64));
	// fmuls f10,f31,f27
	ctx.f10.f64 = double(float(f31.f64 * f27.f64));
	// lfs f9,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f0,f9,f0
	f0.f64 = double(float(ctx.f9.f64 * f0.f64));
	// fmuls f9,f0,f28
	ctx.f9.f64 = double(float(f0.f64 * f28.f64));
	// fmuls f7,f0,f29
	ctx.f7.f64 = double(float(f0.f64 * f29.f64));
	// fmuls f8,f0,f30
	ctx.f8.f64 = double(float(f0.f64 * f30.f64));
	// fmuls f0,f0,f27
	f0.f64 = double(float(f0.f64 * f27.f64));
	// fsubs f5,f13,f9
	ctx.f5.f64 = double(float(ctx.f13.f64 - ctx.f9.f64));
	// fsubs f9,f12,f9
	ctx.f9.f64 = double(float(ctx.f12.f64 - ctx.f9.f64));
	// fsubs f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 - f0.f64));
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// fadds f13,f5,f6
	ctx.f13.f64 = double(float(ctx.f5.f64 + ctx.f6.f64));
	// stfs f13,0(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f13,f8
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f8.f64));
	// fadds f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// stfs f13,4(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// lfs f13,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f9,f13
	ctx.f13.f64 = double(float(ctx.f9.f64 + ctx.f13.f64));
	// stfs f13,8(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f13,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f7.f64));
	// fadds f13,f13,f11
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f11.f64));
	// stfs f13,12(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 12, temp.u32);
	// lfs f13,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 + ctx.f13.f64));
	// stfs f13,16(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 16, temp.u32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f13,f10
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f10.f64));
	// fadds f13,f13,f7
	ctx.f13.f64 = double(float(ctx.f13.f64 + ctx.f7.f64));
	// stfs f13,20(r31)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r31.u32 + 20, temp.u32);
	// lfs f13,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,24(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 24, temp.u32);
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f10
	f0.f64 = double(float(f0.f64 + ctx.f10.f64));
	// fadds f0,f0,f8
	f0.f64 = double(float(f0.f64 + ctx.f8.f64));
	// stfs f0,28(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 28, temp.u32);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// addi r12,r1,-32
	r12.s64 = ctx.r1.s64 + -32;
	// bl 0x823ed590
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820B0C28"))) PPC_WEAK_FUNC(sub_820B0C28);
PPC_FUNC_IMPL(__imp__sub_820B0C28) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// addi r12,r1,-24
	r12.s64 = ctx.r1.s64 + -24;
	// bl 0x823ed544
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// fmr f29,f2
	f29.f64 = ctx.f2.f64;
	// mr r31,r9
	r31.u64 = ctx.r9.u64;
	// fmr f28,f3
	f28.f64 = ctx.f3.f64;
	// mr r30,r10
	r30.u64 = ctx.r10.u64;
	// fmr f27,f4
	f27.f64 = ctx.f4.f64;
	// lfs f8,2776(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f8.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmr f6,f8
	ctx.f6.f64 = ctx.f8.f64;
	// lfs f31,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f31.f64 = double(temp.f32);
	// fmr f7,f31
	ctx.f7.f64 = f31.f64;
	// fmr f5,f31
	ctx.f5.f64 = f31.f64;
	// bl 0x82112020
	sub_82112020(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820b0ca4
	if (!cr6.getEQ()) goto loc_820B0CA4;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x820b0ca4
	if (cr6.getEQ()) goto loc_820B0CA4;
	// stfs f30,0(r31)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// stfs f31,4(r31)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// stfs f29,8(r31)
	temp.f32 = float(f29.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// stfs f28,0(r30)
	temp.f32 = float(f28.f64);
	PPC_STORE_U32(r30.u32 + 0, temp.u32);
	// stfs f31,4(r30)
	temp.f32 = float(f31.f64);
	PPC_STORE_U32(r30.u32 + 4, temp.u32);
	// stfs f27,8(r30)
	temp.f32 = float(f27.f64);
	PPC_STORE_U32(r30.u32 + 8, temp.u32);
loc_820B0CA4:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// addi r12,r1,-24
	r12.s64 = ctx.r1.s64 + -24;
	// bl 0x823ed590
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B0CC8"))) PPC_WEAK_FUNC(sub_820B0CC8);
PPC_FUNC_IMPL(__imp__sub_820B0CC8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed12c
	// addi r12,r1,-64
	r12.s64 = ctx.r1.s64 + -64;
	// bl 0x823ed53c
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// fmr f25,f1
	ctx.fpscr.disableFlushMode();
	f25.f64 = ctx.f1.f64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r7
	r28.u64 = ctx.r7.u64;
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r27.u32);
	// li r25,0
	r25.s64 = 0;
	// bl 0x820b0ae0
	sub_820B0AE0(ctx, base);
	// lis r26,-32014
	r26.s64 = -2098069504;
	// lwz r3,-1828(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + -1828);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820b0d1c
	if (cr6.getEQ()) goto loc_820B0D1C;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x820ce1f0
	sub_820CE1F0(ctx, base);
loc_820B0D1C:
	// lfs f27,116(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	f27.f64 = double(temp.f32);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// lfs f26,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	f26.f64 = double(temp.f32);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r8,531
	ctx.r8.s64 = 531;
	// lfs f2,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// lfs f1,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// fmr f4,f27
	ctx.f4.f64 = f27.f64;
	// fmr f3,f26
	ctx.f3.f64 = f26.f64;
	// bl 0x820b0c28
	sub_820B0C28(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820b0f28
	if (cr6.getEQ()) goto loc_820B0F28;
	// lfs f31,124(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	f31.f64 = double(temp.f32);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// lfs f30,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	f30.f64 = double(temp.f32);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r8,531
	ctx.r8.s64 = 531;
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// fmr f3,f30
	ctx.f3.f64 = f30.f64;
	// fmr f2,f27
	ctx.f2.f64 = f27.f64;
	// fmr f1,f26
	ctx.f1.f64 = f26.f64;
	// bl 0x820b0c28
	sub_820B0C28(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820b0f28
	if (cr6.getEQ()) goto loc_820B0F28;
	// lfs f29,132(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	f29.f64 = double(temp.f32);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// lfs f28,128(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	f28.f64 = double(temp.f32);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r8,531
	ctx.r8.s64 = 531;
	// fmr f4,f29
	ctx.f4.f64 = f29.f64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// fmr f3,f28
	ctx.f3.f64 = f28.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// bl 0x820b0c28
	sub_820B0C28(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820b0f28
	if (cr6.getEQ()) goto loc_820B0F28;
	// lfs f31,140(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	f31.f64 = double(temp.f32);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// lfs f30,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	f30.f64 = double(temp.f32);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// li r8,531
	ctx.r8.s64 = 531;
	// fmr f4,f31
	ctx.f4.f64 = f31.f64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// fmr f3,f30
	ctx.f3.f64 = f30.f64;
	// fmr f2,f29
	ctx.f2.f64 = f29.f64;
	// fmr f1,f28
	ctx.f1.f64 = f28.f64;
	// bl 0x820b0c28
	sub_820B0C28(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820b0f28
	if (cr6.getEQ()) goto loc_820B0F28;
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// fmr f4,f27
	ctx.fpscr.disableFlushMode();
	ctx.f4.f64 = f27.f64;
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// fmr f3,f26
	ctx.f3.f64 = f26.f64;
	// li r8,531
	ctx.r8.s64 = 531;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// bl 0x820b0c28
	sub_820B0C28(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820b0f28
	if (cr6.getEQ()) goto loc_820B0F28;
	// lwz r11,-1828(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + -1828);
	// li r25,1
	r25.s64 = 1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820b0f3c
	if (cr6.getEQ()) goto loc_820B0F3C;
	// lwz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f0,-1792(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -1792);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r31,20(r10)
	r31.u64 = PPC_LOAD_U32(ctx.r10.u32 + 20);
	// fadds f0,f0,f25
	f0.f64 = double(float(f0.f64 + f25.f64));
	// lfs f13,6588(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6588);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// lwz r10,12(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// lwz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lwz r8,8(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,4(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r10,4(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// lwz r9,4(r8)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r8.u32 + 4);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fadds f11,f11,f12
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f12.f64));
	// lfs f10,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,2688(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 2688);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,92(r1)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r1.u32 + 92, temp.u32);
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// stfs f11,88(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f10,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// lfs f11,8(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	ctx.f11.f64 = double(temp.f32);
	// fadds f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 + ctx.f10.f64));
	// lfs f10,8(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 8);
	ctx.f10.f64 = double(temp.f32);
	// fsubs f11,f11,f10
	ctx.f11.f64 = double(float(ctx.f11.f64 - ctx.f10.f64));
	// stfs f11,96(r1)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// blt cr6,0x820b0eac
	if (cr6.getLT()) goto loc_820B0EAC;
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
loc_820B0EAC:
	// fcmpu cr6,f0,f12
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f12.f64);
	// bge cr6,0x820b0eb8
	if (!cr6.getLT()) goto loc_820B0EB8;
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
loc_820B0EB8:
	// addi r4,r1,112
	ctx.r4.s64 = ctx.r1.s64 + 112;
	// fsubs f1,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f13.f64 - f0.f64));
	// bl 0x8210b8c8
	sub_8210B8C8(ctx, base);
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x8210b5c8
	sub_8210B5C8(ctx, base);
	// lfs f0,20(r31)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	f0.f64 = double(temp.f32);
	// lfs f13,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// lfs f13,20(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 20);
	ctx.f13.f64 = double(temp.f32);
	// mr r9,r29
	ctx.r9.u64 = r29.u64;
	// lfs f12,96(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	ctx.f12.f64 = double(temp.f32);
	// li r8,531
	ctx.r8.s64 = 531;
	// fmuls f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f12.f64));
	// lfs f1,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f2.f64 = double(temp.f32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r27,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r27.u32);
	// fadds f3,f1,f0
	ctx.f3.f64 = double(float(ctx.f1.f64 + f0.f64));
	// stfs f3,88(r1)
	temp.f32 = float(ctx.f3.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// fadds f4,f2,f13
	ctx.f4.f64 = double(float(ctx.f2.f64 + ctx.f13.f64));
	// stfs f4,96(r1)
	temp.f32 = float(ctx.f4.f64);
	PPC_STORE_U32(ctx.r1.u32 + 96, temp.u32);
	// bl 0x820b0c28
	sub_820B0C28(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x820b0f28
	if (!cr6.getEQ()) goto loc_820B0F28;
	// li r25,0
	r25.s64 = 0;
loc_820B0F28:
	// lwz r3,-1828(r26)
	ctx.r3.u64 = PPC_LOAD_U32(r26.u32 + -1828);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820b0f3c
	if (cr6.getEQ()) goto loc_820B0F3C;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x820ce1f0
	sub_820CE1F0(ctx, base);
loc_820B0F3C:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// addi r12,r1,-64
	r12.s64 = ctx.r1.s64 + -64;
	// bl 0x823ed588
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_820B0F50"))) PPC_WEAK_FUNC(sub_820B0F50);
PPC_FUNC_IMPL(__imp__sub_820B0F50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lfs f4,8(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,0(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// lwz r10,1456(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1456);
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f2,1468(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1468);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,1460(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1460);
	ctx.f1.f64 = double(temp.f32);
	// lfs f8,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	ctx.f8.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmr f6,f8
	ctx.f6.f64 = ctx.f8.f64;
	// lfs f7,2688(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2688);
	ctx.f7.f64 = double(temp.f32);
	// fmr f5,f7
	ctx.f5.f64 = ctx.f7.f64;
	// bl 0x82112020
	sub_82112020(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820b0ff0
	if (cr6.getEQ()) goto loc_820B0FF0;
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r4,96(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// li r6,0
	ctx.r6.s64 = 0;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x820b0cc8
	sub_820B0CC8(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820b0ff0
	if (cr6.getEQ()) goto loc_820B0FF0;
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// li r3,1
	ctx.r3.s64 = 1;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// b 0x820b0ff4
	goto loc_820B0FF4;
loc_820B0FF0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_820B0FF4:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1010"))) PPC_WEAK_FUNC(sub_820B1010);
PPC_FUNC_IMPL(__imp__sub_820B1010) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r3,-1836(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + -1836);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1020"))) PPC_WEAK_FUNC(sub_820B1020);
PPC_FUNC_IMPL(__imp__sub_820B1020) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1836(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1836);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x820b103c
	if (!cr6.getEQ()) goto loc_820B103C;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r3,-1828(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + -1828);
	// blr 
	return;
loc_820B103C:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1048"))) PPC_WEAK_FUNC(sub_820B1048);
PPC_FUNC_IMPL(__imp__sub_820B1048) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f30,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, f30.u64);
	// stfd f31,-32(r1)
	PPC_STORE_U64(ctx.r1.u32 + -32, f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lfs f0,-1792(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -1792);
	f0.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f13,-1808(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -1808);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// lfs f13,6588(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6588);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820b1090
	if (cr6.getLT()) goto loc_820B1090;
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
loc_820B1090:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f12,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bge cr6,0x820b10a4
	if (!cr6.getLT()) goto loc_820B10A4;
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
loc_820B10A4:
	// fmr f31,f0
	ctx.fpscr.disableFlushMode();
	f31.f64 = f0.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// lis r30,-32014
	r30.s64 = -2098069504;
	// lfs f1,-1800(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + -1800);
	ctx.f1.f64 = double(temp.f32);
	// frsp f30,f0
	f30.f64 = double(float(f0.f64));
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmuls f0,f0,f30
	f0.f64 = double(float(f0.f64 * f30.f64));
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// stfs f0,0(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 0, temp.u32);
	// lfs f1,-1800(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + -1800);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// stfs f0,4(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 4, temp.u32);
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// fmr f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = ctx.f1.f64;
	// lfs f1,-1800(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + -1800);
	ctx.f1.f64 = double(temp.f32);
	// frsp f31,f0
	f31.f64 = double(float(f0.f64));
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// fmuls f0,f0,f31
	f0.f64 = double(float(f0.f64 * f31.f64));
	// stfs f0,8(r31)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r31.u32 + 8, temp.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f30,-40(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// lfd f31,-32(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1130"))) PPC_WEAK_FUNC(sub_820B1130);
PPC_FUNC_IMPL(__imp__sub_820B1130) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lhz r4,8324(r31)
	ctx.r4.u64 = PPC_LOAD_U16(r31.u32 + 8324);
	// lwz r3,428(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 428);
	// bl 0x820cebd0
	sub_820CEBD0(ctx, base);
	// li r11,-1
	r11.s64 = -1;
	// lwz r10,428(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 428);
	// sth r11,8324(r31)
	PPC_STORE_U16(r31.u32 + 8324, r11.u16);
	// lwz r3,8(r10)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820b1180
	if (cr6.getEQ()) goto loc_820B1180;
	// bl 0x8211e6f8
	sub_8211E6F8(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_820B1180:
	// lwz r11,1456(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 1456);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820b119c
	if (cr6.getEQ()) goto loc_820B119C;
	// lbz r4,3(r11)
	ctx.r4.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// mr r3,r10
	ctx.r3.u64 = ctx.r10.u64;
	// sth r4,8324(r31)
	PPC_STORE_U16(r31.u32 + 8324, ctx.r4.u16);
	// bl 0x820cead0
	sub_820CEAD0(ctx, base);
loc_820B119C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B11B0"))) PPC_WEAK_FUNC(sub_820B11B0);
PPC_FUNC_IMPL(__imp__sub_820B11B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// addi r9,r11,812
	ctx.r9.s64 = r11.s64 + 812;
	// beq cr6,0x820b11dc
	if (cr6.getEQ()) goto loc_820B11DC;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lfs f0,612(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 612);
	f0.f64 = double(temp.f32);
	// stfs f0,812(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 812, temp.u32);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lfs f0,15104(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 15104);
	f0.f64 = double(temp.f32);
	// b 0x820b11ec
	goto loc_820B11EC;
loc_820B11DC:
	// lfs f0,808(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 808);
	f0.f64 = double(temp.f32);
	// stfs f0,812(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 812, temp.u32);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// lfs f0,612(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 612);
	f0.f64 = double(temp.f32);
loc_820B11EC:
	// addi r10,r11,816
	ctx.r10.s64 = r11.s64 + 816;
	// stfs f0,816(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 816, temp.u32);
	// lfs f0,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f1,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f1.f64 = double(temp.f32);
	// fcmpu cr6,f0,f1
	cr6.compare(f0.f64, ctx.f1.f64);
	// bge cr6,0x820b1214
	if (!cr6.getLT()) goto loc_820B1214;
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
loc_820B1214:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,13960(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13960);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// blt cr6,0x820b1238
	if (cr6.getLT()) goto loc_820B1238;
	// fsubs f12,f0,f13
	ctx.f12.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
	// fmadds f1,f12,f0,f13
	ctx.f1.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// blr 
	return;
loc_820B1238:
	// fcmpu cr6,f0,f1
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f1.f64);
	// blelr cr6
	if (!cr6.getGT()) return;
	// fmr f1,f0
	ctx.f1.f64 = f0.f64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1248"))) PPC_WEAK_FUNC(sub_820B1248);
PPC_FUNC_IMPL(__imp__sub_820B1248) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lis r30,-32014
	r30.s64 = -2098069504;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r9,r11,612
	ctx.r9.s64 = r11.s64 + 612;
	// addi r8,r11,828
	ctx.r8.s64 = r11.s64 + 828;
	// lwz r10,828(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 828);
	// lfs f31,612(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 612);
	f31.f64 = double(temp.f32);
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// bne cr6,0x820b130c
	if (!cr6.getEQ()) goto loc_820B130C;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// lfs f12,820(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 820);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-6368(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + -6368);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,16792(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16792);
	f0.f64 = double(temp.f32);
	// addi r10,r11,820
	ctx.r10.s64 = r11.s64 + 820;
	// fmadds f13,f0,f13,f12
	ctx.f13.f64 = double(float(f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// stfs f13,820(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 820, temp.u32);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lfs f0,824(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 824);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820b1300
	if (!cr6.getLT()) goto loc_820B1300;
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fdivs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 / f0.f64));
	// lfs f13,14032(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14032);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f0,f13
	ctx.f1.f64 = double(float(f0.f64 * ctx.f13.f64));
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// frsp f11,f1
	ctx.fpscr.disableFlushMode();
	ctx.f11.f64 = double(float(ctx.f1.f64));
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f13,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,812(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 812);
	f0.f64 = double(temp.f32);
	// lfs f12,816(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 816);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 - f0.f64));
	// fsubs f11,f13,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// lfs f13,2692(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2692);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmadds f0,f12,f13,f0
	f0.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + f0.f64));
	// stfs f0,612(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 612, temp.u32);
	// b 0x820b13a0
	goto loc_820B13A0;
loc_820B1300:
	// lfs f0,816(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 816);
	f0.f64 = double(temp.f32);
	// li r10,3
	ctx.r10.s64 = 3;
	// b 0x820b1398
	goto loc_820B1398;
loc_820B130C:
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x820b13a4
	if (!cr6.getEQ()) goto loc_820B13A4;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// lfs f12,820(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 820);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,-6368(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + -6368);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,16792(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16792);
	f0.f64 = double(temp.f32);
	// addi r10,r11,820
	ctx.r10.s64 = r11.s64 + 820;
	// fmadds f13,f0,f13,f12
	ctx.f13.f64 = double(float(f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// stfs f13,820(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 820, temp.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,824(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 824);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820b1390
	if (!cr6.getLT()) goto loc_820B1390;
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fdivs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 / f0.f64));
	// lfs f13,14032(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14032);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f0,f13
	ctx.f1.f64 = double(float(f0.f64 * ctx.f13.f64));
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// frsp f11,f1
	ctx.fpscr.disableFlushMode();
	ctx.f11.f64 = double(float(ctx.f1.f64));
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f13,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,816(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 816);
	f0.f64 = double(temp.f32);
	// lfs f12,812(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 812);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 - f0.f64));
	// fsubs f11,f13,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 - ctx.f11.f64));
	// lfs f13,2692(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2692);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f11,f13
	ctx.f13.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// fmadds f0,f12,f13,f0
	f0.f64 = double(float(ctx.f12.f64 * ctx.f13.f64 + f0.f64));
	// stfs f0,612(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 612, temp.u32);
	// b 0x820b13a0
	goto loc_820B13A0;
loc_820B1390:
	// lfs f0,812(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 812);
	f0.f64 = double(temp.f32);
	// li r10,0
	ctx.r10.s64 = 0;
loc_820B1398:
	// stfs f0,0(r9)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 0, temp.u32);
	// stw r10,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r10.u32);
loc_820B13A0:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
loc_820B13A4:
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f0,612(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 612);
	f0.f64 = double(temp.f32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// addi r10,r11,612
	ctx.r10.s64 = r11.s64 + 612;
	// lfs f13,15112(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 15112);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f11,14216(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 14216);
	ctx.f11.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// lfs f12,14020(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 14020);
	ctx.f12.f64 = double(temp.f32);
	// bge cr6,0x820b13d8
	if (!cr6.getLT()) goto loc_820B13D8;
	// lfs f0,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f12
	f0.f64 = double(float(f0.f64 + ctx.f12.f64));
	// b 0x820b13e8
	goto loc_820B13E8;
loc_820B13D8:
	// fcmpu cr6,f0,f11
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f11.f64);
	// blt cr6,0x820b13f0
	if (cr6.getLT()) goto loc_820B13F0;
	// lfs f0,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f12
	f0.f64 = double(float(f0.f64 - ctx.f12.f64));
loc_820B13E8:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
loc_820B13F0:
	// lis r9,-32014
	ctx.r9.s64 = -2098069504;
	// lwz r9,-6384(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + -6384);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// ble cr6,0x820b1484
	if (!cr6.getGT()) goto loc_820B1484;
	// lfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fsubs f0,f0,f31
	f0.f64 = double(float(f0.f64 - f31.f64));
	// stfs f0,620(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 620, temp.u32);
	// lfs f13,2688(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2688);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820b1424
	if (!cr6.getLT()) goto loc_820B1424;
	// fadds f0,f0,f12
	f0.f64 = double(float(f0.f64 + ctx.f12.f64));
	// stfs f0,620(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 620, temp.u32);
loc_820B1424:
	// lfs f0,620(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 620);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f11
	cr6.compare(f0.f64, ctx.f11.f64);
	// ble cr6,0x820b1438
	if (!cr6.getGT()) goto loc_820B1438;
	// fsubs f0,f0,f12
	f0.f64 = double(float(f0.f64 - ctx.f12.f64));
	// stfs f0,620(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 620, temp.u32);
loc_820B1438:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,-6368(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + -6368);
	f0.f64 = double(temp.f32);
	// lfs f13,3060(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3060);
	ctx.f13.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// lfs f13,620(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 620);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 / f0.f64));
	// lfs f13,15108(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15108);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,620(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 620, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820b146c
	if (!cr6.getLT()) goto loc_820B146C;
	// stfs f13,620(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 620, temp.u32);
	// b 0x820b1484
	goto loc_820B1484;
loc_820B146C:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,620(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 620);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,2720(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2720);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820b1484
	if (!cr6.getGT()) goto loc_820B1484;
	// stfs f0,620(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 620, temp.u32);
loc_820B1484:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f31,-32(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B14A0"))) PPC_WEAK_FUNC(sub_820B14A0);
PPC_FUNC_IMPL(__imp__sub_820B14A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// stfs f0,4708(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4708, temp.u32);
	// stfs f2,4712(r10)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4712, temp.u32);
	// lfs f0,4716(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4716);
	f0.f64 = double(temp.f32);
	// stfs f0,4720(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4720, temp.u32);
	// stfs f1,4724(r11)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r11.u32 + 4724, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B14D0"))) PPC_WEAK_FUNC(sub_820B14D0);
PPC_FUNC_IMPL(__imp__sub_820B14D0) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// lfs f0,4708(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4708);
	f0.f64 = double(temp.f32);
	// lfs f13,4712(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4712);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820b14f0
	if (!cr6.getLT()) goto loc_820B14F0;
	// lfs f0,4724(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4724);
	f0.f64 = double(temp.f32);
	// b 0x820b14f4
	goto loc_820B14F4;
loc_820B14F0:
	// lfs f0,4716(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4716);
	f0.f64 = double(temp.f32);
loc_820B14F4:
	// fcmpu cr6,f1,f0
	ctx.fpscr.disableFlushMode();
	cr6.compare(ctx.f1.f64, f0.f64);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lfs f0,4716(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4716);
	f0.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// fcmpu cr6,f0,f1
	cr6.compare(f0.f64, ctx.f1.f64);
	// ble cr6,0x820b1514
	if (!cr6.getGT()) goto loc_820B1514;
	// fsubs f13,f0,f1
	ctx.f13.f64 = double(float(f0.f64 - ctx.f1.f64));
	// b 0x820b151c
	goto loc_820B151C;
loc_820B1514:
	// lfs f13,4716(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4716);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f1,f13
	ctx.f13.f64 = double(float(ctx.f1.f64 - ctx.f13.f64));
loc_820B151C:
	// lfs f0,2688(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	f0.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f0,4708(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4708, temp.u32);
	// lfs f0,2692(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2692);
	f0.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,4712(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4712, temp.u32);
	// lfs f0,4716(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4716);
	f0.f64 = double(temp.f32);
	// lwz r11,-1364(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1364);
	// stfs f0,4720(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4720, temp.u32);
	// stfs f1,4724(r11)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r11.u32 + 4724, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1548"))) PPC_WEAK_FUNC(sub_820B1548);
PPC_FUNC_IMPL(__imp__sub_820B1548) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820c35e8
	sub_820C35E8(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// addi r9,r10,4716
	ctx.r9.s64 = ctx.r10.s64 + 4716;
	// lfs f0,4716(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4716);
	f0.f64 = double(temp.f32);
	// fsubs f13,f1,f0
	ctx.f13.f64 = double(float(ctx.f1.f64 - f0.f64));
	// lfs f0,13960(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 13960);
	f0.f64 = double(temp.f32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// fsubs f12,f1,f0
	ctx.f12.f64 = double(float(ctx.f1.f64 - f0.f64));
	// lfs f0,14104(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 14104);
	f0.f64 = double(temp.f32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f13,2688(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 2688);
	ctx.f13.f64 = double(temp.f32);
	// fdivs f0,f0,f12
	f0.f64 = double(float(f0.f64 / ctx.f12.f64));
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820b159c
	if (!cr6.getLT()) goto loc_820B159C;
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
loc_820B159C:
	// stfs f13,4708(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4708, temp.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// stfs f0,4712(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4712, temp.u32);
	// lfs f0,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,4720(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4720, temp.u32);
	// stfs f1,4724(r11)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r11.u32 + 4724, temp.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B15C8"))) PPC_WEAK_FUNC(sub_820B15C8);
PPC_FUNC_IMPL(__imp__sub_820B15C8) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lfs f13,13960(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 13960);
	ctx.f13.f64 = double(temp.f32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// addi r9,r10,4716
	ctx.r9.s64 = ctx.r10.s64 + 4716;
	// lfs f0,4716(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 4716);
	f0.f64 = double(temp.f32);
	// fsubs f12,f13,f0
	ctx.f12.f64 = double(float(ctx.f13.f64 - f0.f64));
	// lfs f0,15116(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 15116);
	f0.f64 = double(temp.f32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// fmuls f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 * f0.f64));
	// lfs f12,2688(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 2688);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bge cr6,0x820b1604
	if (!cr6.getLT()) goto loc_820B1604;
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
loc_820B1604:
	// stfs f12,4708(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4708, temp.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// stfs f0,4712(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4712, temp.u32);
	// lfs f0,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,4720(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4720, temp.u32);
	// stfs f13,4724(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 4724, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1628"))) PPC_WEAK_FUNC(sub_820B1628);
PPC_FUNC_IMPL(__imp__sub_820B1628) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// li r3,1
	ctx.r3.s64 = 1;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lfs f0,4708(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4708);
	f0.f64 = double(temp.f32);
	// lfs f13,4712(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4712);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bltlr cr6
	if (cr6.getLT()) return;
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1650"))) PPC_WEAK_FUNC(sub_820B1650);
PPC_FUNC_IMPL(__imp__sub_820B1650) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r10,r11,4708
	ctx.r10.s64 = r11.s64 + 4708;
	// addi r8,r11,4712
	ctx.r8.s64 = r11.s64 + 4712;
	// lfs f0,4712(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4712);
	f0.f64 = double(temp.f32);
	// lfs f13,4708(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4708);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820b16fc
	if (!cr6.getLT()) goto loc_820B16FC;
	// lwz r11,744(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 744);
	// cmpwi cr6,r11,5
	cr6.compare<int32_t>(r11.s32, 5, xer);
	// beq cr6,0x820b16b0
	if (cr6.getEQ()) goto loc_820B16B0;
	// cmpwi cr6,r11,12
	cr6.compare<int32_t>(r11.s32, 12, xer);
	// beq cr6,0x820b16b0
	if (cr6.getEQ()) goto loc_820B16B0;
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lfs f12,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,16792(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16792);
	f0.f64 = double(temp.f32);
	// lis r11,-32055
	r11.s64 = -2100756480;
	// lfs f13,-21840(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -21840);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f0,f13,f12
	f0.f64 = double(float(f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// b 0x820b16c0
	goto loc_820B16C0;
loc_820B16B0:
	// lis r11,-32055
	r11.s64 = -2100756480;
	// lfs f13,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-21840(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -21840);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
loc_820B16C0:
	// stfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lfs f0,0(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	f0.f64 = double(temp.f32);
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// ble cr6,0x820b16d8
	if (!cr6.getGT()) goto loc_820B16D8;
	// stfs f0,0(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
loc_820B16D8:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f12,0(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,4720(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4720);
	f0.f64 = double(temp.f32);
	// lfs f13,4724(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4724);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 - f0.f64));
	// fdivs f13,f13,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 / ctx.f12.f64));
	// fmadds f0,f13,f11,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 + f0.f64));
	// b 0x820b1708
	goto loc_820B1708;
loc_820B16FC:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// stfs f0,0(r10)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lfs f0,4724(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4724);
	f0.f64 = double(temp.f32);
loc_820B1708:
	// addi r9,r11,4716
	ctx.r9.s64 = r11.s64 + 4716;
	// stfs f0,4716(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4716, temp.u32);
	// lfs f1,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x820c9c30
	sub_820C9C30(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f1,4716(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4716);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210e310
	sub_8210E310(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1738"))) PPC_WEAK_FUNC(sub_820B1738);
PPC_FUNC_IMPL(__imp__sub_820B1738) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,744(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 744);
	// cmpwi cr6,r10,4
	cr6.compare<int32_t>(ctx.r10.s32, 4, xer);
	// bne cr6,0x820b1774
	if (!cr6.getEQ()) goto loc_820B1774;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,4712(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4712);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,14104(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14104);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f13,4708(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4708);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fadds f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 + ctx.f13.f64));
	// lfs f0,15120(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15120);
	f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * f0.f64));
	// blr 
	return;
loc_820B1774:
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// bne cr6,0x820b1798
	if (!cr6.getEQ()) goto loc_820B1798;
	// lfs f0,4712(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4712);
	f0.f64 = double(temp.f32);
	// lfs f13,4708(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4708);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f13,f0,f13
	ctx.f13.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f0,15120(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15120);
	f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * f0.f64));
	// blr 
	return;
loc_820B1798:
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// beq cr6,0x820b17b4
	if (cr6.getEQ()) goto loc_820B17B4;
	// cmpwi cr6,r10,12
	cr6.compare<int32_t>(ctx.r10.s32, 12, xer);
	// beq cr6,0x820b17b4
	if (cr6.getEQ()) goto loc_820B17B4;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
loc_820B17B4:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,2776(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B17C0"))) PPC_WEAK_FUNC(sub_820B17C0);
PPC_FUNC_IMPL(__imp__sub_820B17C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x820a0a38
	sub_820A0A38(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// bl 0x8211c6c8
	sub_8211C6C8(ctx, base);
	// lis r31,-32014
	r31.s64 = -2098069504;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r5,r11,1040
	ctx.r5.s64 = r11.s64 + 1040;
	// addi r3,r11,852
	ctx.r3.s64 = r11.s64 + 852;
	// bl 0x8211c960
	sub_8211C960(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r3,r11,852
	ctx.r3.s64 = r11.s64 + 852;
	// lis r11,-32141
	r11.s64 = -2106392576;
	// addi r11,r11,-28640
	r11.s64 = r11.s64 + -28640;
	// lfs f0,1492(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1492);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,14176(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14176);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f1,f0,f13
	ctx.f1.f64 = double(float(f0.f64 * ctx.f13.f64));
	// bl 0x823ada90
	sub_823ADA90(ctx, base);
	// lis r11,-32056
	r11.s64 = -2100822016;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r11,-16188
	ctx.r4.s64 = r11.s64 + -16188;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f3,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f3.f64 = double(temp.f32);
	// lis r11,-32190
	r11.s64 = -2109603840;
	// fmr f1,f3
	ctx.f1.f64 = ctx.f3.f64;
	// lfs f0,16792(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16792);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,2692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// fmuls f2,f0,f13
	ctx.f2.f64 = double(float(f0.f64 * ctx.f13.f64));
	// addi r3,r11,852
	ctx.r3.s64 = r11.s64 + 852;
	// bl 0x8211d710
	sub_8211D710(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,836(r11)
	PPC_STORE_U32(r11.u32 + 836, ctx.r10.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1880"))) PPC_WEAK_FUNC(sub_820B1880);
PPC_FUNC_IMPL(__imp__sub_820B1880) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r8,-32014
	ctx.r8.s64 = -2098069504;
	// lwz r11,-1364(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1364);
	// lwz r10,836(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 836);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// cmpwi cr6,r10,3
	cr6.compare<int32_t>(ctx.r10.s32, 3, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// cmpwi cr6,r10,1
	cr6.compare<int32_t>(ctx.r10.s32, 1, xer);
	// lfs f2,2688(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	ctx.f2.f64 = double(temp.f32);
	// bne cr6,0x820b18ec
	if (!cr6.getEQ()) goto loc_820B18EC;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// lfs f13,848(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 848);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,840(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 840);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,16792(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16792);
	f0.f64 = double(temp.f32);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f0,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmadds f0,f13,f0,f12
	f0.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// lfs f13,2948(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2948);
	ctx.f13.f64 = double(temp.f32);
	// stfs f0,840(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 840, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820b192c
	if (!cr6.getGT()) goto loc_820B192C;
	// stfs f13,840(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 840, temp.u32);
	// li r10,3
	ctx.r10.s64 = 3;
	// b 0x820b1928
	goto loc_820B1928;
loc_820B18EC:
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// bne cr6,0x820b1930
	if (!cr6.getEQ()) goto loc_820B1930;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// lfs f13,848(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 848);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,840(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 840);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,16792(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 16792);
	f0.f64 = double(temp.f32);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// lfs f0,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fnmsubs f0,f13,f0,f12
	f0.f64 = double(float(-(ctx.f13.f64 * f0.f64 - ctx.f12.f64)));
	// stfs f0,840(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 840, temp.u32);
	// fcmpu cr6,f0,f2
	cr6.compare(f0.f64, ctx.f2.f64);
	// bge cr6,0x820b192c
	if (!cr6.getLT()) goto loc_820B192C;
	// stfs f2,840(r11)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(r11.u32 + 840, temp.u32);
	// li r10,0
	ctx.r10.s64 = 0;
loc_820B1928:
	// stw r10,836(r11)
	PPC_STORE_U32(r11.u32 + 836, ctx.r10.u32);
loc_820B192C:
	// lwz r11,-1364(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1364);
loc_820B1930:
	// lfs f1,840(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 840);
	ctx.f1.f64 = double(temp.f32);
	// addi r3,r11,852
	ctx.r3.s64 = r11.s64 + 852;
	// b 0x8211b4a0
	sub_8211B4A0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_820B193C"))) PPC_WEAK_FUNC(sub_820B193C);
PPC_FUNC_IMPL(__imp__sub_820B193C) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1940"))) PPC_WEAK_FUNC(sub_820B1940);
PPC_FUNC_IMPL(__imp__sub_820B1940) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r11,836(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + 836);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// beq cr6,0x820b197c
	if (cr6.getEQ()) goto loc_820B197C;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x820b197c
	if (cr6.getEQ()) goto loc_820B197C;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x820b1970
	if (!cr6.getEQ()) goto loc_820B1970;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,2776(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
loc_820B1970:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f1.f64 = double(temp.f32);
	// blr 
	return;
loc_820B197C:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,840(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 840);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,14116(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14116);
	f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * f0.f64));
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1990"))) PPC_WEAK_FUNC(sub_820B1990);
PPC_FUNC_IMPL(__imp__sub_820B1990) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r3,748(r11)
	PPC_STORE_U32(r11.u32 + 748, ctx.r3.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B19A0"))) PPC_WEAK_FUNC(sub_820B19A0);
PPC_FUNC_IMPL(__imp__sub_820B19A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820df500
	sub_820DF500(ctx, base);
	// bl 0x820df668
	sub_820DF668(ctx, base);
	// li r30,0
	r30.s64 = 0;
	// lis r29,-32014
	r29.s64 = -2098069504;
loc_820B19BC:
	// lwz r11,-1364(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + -1364);
	// add r11,r30,r11
	r11.u64 = r30.u64 + r11.u64;
	// addi r31,r11,2344
	r31.s64 = r11.s64 + 2344;
	// lwz r3,468(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 468);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820b19e8
	if (cr6.getEQ()) goto loc_820B19E8;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820b19e8
	if (cr6.getEQ()) goto loc_820B19E8;
	// lwz r3,468(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 468);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820B19E8:
	// addi r30,r30,936
	r30.s64 = r30.s64 + 936;
	// cmpwi cr6,r30,936
	cr6.compare<int32_t>(r30.s32, 936, xer);
	// ble cr6,0x820b19bc
	if (!cr6.getGT()) goto loc_820B19BC;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// addi r30,r11,-1820
	r30.s64 = r11.s64 + -1820;
	// mr r31,r30
	r31.u64 = r30.u64;
loc_820B1A00:
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820b1a20
	if (cr6.getEQ()) goto loc_820B1A20;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820b1a20
	if (cr6.getEQ()) goto loc_820B1A20;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820B1A20:
	// addi r31,r31,4
	r31.s64 = r31.s64 + 4;
	// addi r11,r30,4
	r11.s64 = r30.s64 + 4;
	// cmpw cr6,r31,r11
	cr6.compare<int32_t>(r31.s32, r11.s32, xer);
	// ble cr6,0x820b1a00
	if (!cr6.getGT()) goto loc_820B1A00;
	// bl 0x820cca38
	sub_820CCA38(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x820b1ab8
	if (cr6.getEQ()) goto loc_820B1AB8;
loc_820B1A40:
	// lbz r11,0(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// beq cr6,0x820b1aac
	if (cr6.getEQ()) goto loc_820B1AAC;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x820b1aac
	if (!cr6.getEQ()) goto loc_820B1AAC;
	// lwz r31,8(r30)
	r31.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lbz r11,3(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// cmplwi cr6,r11,39
	cr6.compare<uint32_t>(r11.u32, 39, xer);
	// bne cr6,0x820b1a84
	if (!cr6.getEQ()) goto loc_820B1A84;
	// lwz r3,184(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 184);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820b1aac
	if (cr6.getEQ()) goto loc_820B1AAC;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820b1aac
	if (cr6.getEQ()) goto loc_820B1AAC;
	// lwz r3,184(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 184);
	// b 0x820b1aa8
	goto loc_820B1AA8;
loc_820B1A84:
	// cmplwi cr6,r11,40
	cr6.compare<uint32_t>(r11.u32, 40, xer);
	// bne cr6,0x820b1aac
	if (!cr6.getEQ()) goto loc_820B1AAC;
	// lwz r3,176(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 176);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x820b1aac
	if (cr6.getEQ()) goto loc_820B1AAC;
	// bl 0x82144970
	sub_82144970(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820b1aac
	if (cr6.getEQ()) goto loc_820B1AAC;
	// lwz r3,176(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 176);
loc_820B1AA8:
	// bl 0x82144a08
	sub_82144A08(ctx, base);
loc_820B1AAC:
	// lwz r30,40(r30)
	r30.u64 = PPC_LOAD_U32(r30.u32 + 40);
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x820b1a40
	if (!cr6.getEQ()) goto loc_820B1A40;
loc_820B1AB8:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820B1AC0"))) PPC_WEAK_FUNC(sub_820B1AC0);
PPC_FUNC_IMPL(__imp__sub_820B1AC0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// li r10,1
	ctx.r10.s64 = 1;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r10,752(r11)
	PPC_STORE_U32(r11.u32 + 752, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1AD8"))) PPC_WEAK_FUNC(sub_820B1AD8);
PPC_FUNC_IMPL(__imp__sub_820B1AD8) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stfd f29,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, f29.u64);
	// stfd f30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, f30.u64);
	// stfd f31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// bl 0x8210e390
	sub_8210E390(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f30.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fcmpu cr6,f31,f30
	cr6.compare(f31.f64, f30.f64);
	// lfs f0,6576(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6576);
	f0.f64 = double(temp.f32);
	// fmuls f29,f1,f0
	f29.f64 = double(float(ctx.f1.f64 * f0.f64));
	// ble cr6,0x820b1b2c
	if (!cr6.getGT()) goto loc_820B1B2C;
	// bl 0x8210e390
	sub_8210E390(ctx, base);
	// fmuls f13,f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64 * f31.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,15128(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15128);
	f0.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// b 0x820b1b54
	goto loc_820B1B54;
loc_820B1B2C:
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// bge cr6,0x820b1b50
	if (!cr6.getLT()) goto loc_820B1B50;
	// bl 0x8210e390
	sub_8210E390(ctx, base);
	// fneg f0,f31
	ctx.fpscr.disableFlushMode();
	f0.u64 = f31.u64 ^ 0x8000000000000000;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f13,f1,f0
	ctx.f13.f64 = double(float(ctx.f1.f64 * f0.f64));
	// lfs f0,15124(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15124);
	f0.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// b 0x820b1b54
	goto loc_820B1B54;
loc_820B1B50:
	// fmr f13,f30
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = f30.f64;
loc_820B1B54:
	// lis r11,-32014
	r11.s64 = -2098069504;
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lfs f0,620(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 620);
	f0.f64 = double(temp.f32);
	// fmr f11,f0
	ctx.f11.f64 = f0.f64;
	// ble cr6,0x820b1ba8
	if (!cr6.getGT()) goto loc_820B1BA8;
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// lfs f0,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fmuls f12,f0,f29
	ctx.f12.f64 = double(float(f0.f64 * f29.f64));
	// ble cr6,0x820b1b8c
	if (!cr6.getGT()) goto loc_820B1B8C;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,14116(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14116);
	f0.f64 = double(temp.f32);
	// b 0x820b1b94
	goto loc_820B1B94;
loc_820B1B8C:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,14496(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14496);
	f0.f64 = double(temp.f32);
loc_820B1B94:
	// fnmsubs f0,f12,f0,f11
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(-(ctx.f12.f64 * f0.f64 - ctx.f11.f64)));
	// stfs f0,620(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 620, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820b1c28
	if (!cr6.getLT()) goto loc_820B1C28;
	// b 0x820b1c24
	goto loc_820B1C24;
loc_820B1BA8:
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// bge cr6,0x820b1be8
	if (!cr6.getLT()) goto loc_820B1BE8;
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// lfs f0,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fmuls f12,f0,f29
	ctx.f12.f64 = double(float(f0.f64 * f29.f64));
	// bge cr6,0x820b1bd4
	if (!cr6.getLT()) goto loc_820B1BD4;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,14116(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14116);
	f0.f64 = double(temp.f32);
	// fmadds f0,f12,f0,f11
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f11.f64));
	// stfs f0,620(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 620, temp.u32);
	// b 0x820b1c1c
	goto loc_820B1C1C;
loc_820B1BD4:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,14496(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14496);
	f0.f64 = double(temp.f32);
	// fmadds f0,f12,f0,f11
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f11.f64));
	// stfs f0,620(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 620, temp.u32);
	// b 0x820b1c1c
	goto loc_820B1C1C;
loc_820B1BE8:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// lfs f0,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmuls f12,f0,f29
	ctx.f12.f64 = double(float(f0.f64 * f29.f64));
	// lfs f0,14116(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14116);
	f0.f64 = double(temp.f32);
	// ble cr6,0x820b1c14
	if (!cr6.getGT()) goto loc_820B1C14;
	// fnmsubs f0,f12,f0,f11
	f0.f64 = double(float(-(ctx.f12.f64 * f0.f64 - ctx.f11.f64)));
	// stfs f0,620(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 620, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820b1c28
	if (!cr6.getLT()) goto loc_820B1C28;
	// b 0x820b1c24
	goto loc_820B1C24;
loc_820B1C14:
	// fmadds f0,f12,f0,f11
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f11.f64));
	// stfs f0,620(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 620, temp.u32);
loc_820B1C1C:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820b1c28
	if (!cr6.getGT()) goto loc_820B1C28;
loc_820B1C24:
	// stfs f13,620(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 620, temp.u32);
loc_820B1C28:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f29,-32(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// lfd f30,-24(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// lfd f31,-16(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1C48"))) PPC_WEAK_FUNC(sub_820B1C48);
PPC_FUNC_IMPL(__imp__sub_820B1C48) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stfd f29,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, f29.u64);
	// stfd f30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, f30.u64);
	// stfd f31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// bl 0x8210e390
	sub_8210E390(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f30.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fcmpu cr6,f31,f30
	cr6.compare(f31.f64, f30.f64);
	// lfs f0,6576(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6576);
	f0.f64 = double(temp.f32);
	// fmuls f29,f1,f0
	f29.f64 = double(float(ctx.f1.f64 * f0.f64));
	// ble cr6,0x820b1c9c
	if (!cr6.getGT()) goto loc_820B1C9C;
	// bl 0x8210e390
	sub_8210E390(ctx, base);
	// fmuls f13,f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64 * f31.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,15128(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15128);
	f0.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// b 0x820b1cc4
	goto loc_820B1CC4;
loc_820B1C9C:
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// bge cr6,0x820b1cc0
	if (!cr6.getLT()) goto loc_820B1CC0;
	// bl 0x8210e390
	sub_8210E390(ctx, base);
	// fneg f0,f31
	ctx.fpscr.disableFlushMode();
	f0.u64 = f31.u64 ^ 0x8000000000000000;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f13,f1,f0
	ctx.f13.f64 = double(float(ctx.f1.f64 * f0.f64));
	// lfs f0,15124(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15124);
	f0.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// b 0x820b1cc4
	goto loc_820B1CC4;
loc_820B1CC0:
	// fmr f13,f30
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = f30.f64;
loc_820B1CC4:
	// lis r11,-32014
	r11.s64 = -2098069504;
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lfs f0,8512(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8512);
	f0.f64 = double(temp.f32);
	// fmr f11,f0
	ctx.f11.f64 = f0.f64;
	// ble cr6,0x820b1d18
	if (!cr6.getGT()) goto loc_820B1D18;
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// lfs f0,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fmuls f12,f0,f29
	ctx.f12.f64 = double(float(f0.f64 * f29.f64));
	// ble cr6,0x820b1cfc
	if (!cr6.getGT()) goto loc_820B1CFC;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,14116(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14116);
	f0.f64 = double(temp.f32);
	// b 0x820b1d04
	goto loc_820B1D04;
loc_820B1CFC:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,14496(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14496);
	f0.f64 = double(temp.f32);
loc_820B1D04:
	// fnmsubs f0,f12,f0,f11
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(-(ctx.f12.f64 * f0.f64 - ctx.f11.f64)));
	// stfs f0,8512(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8512, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820b1d98
	if (!cr6.getLT()) goto loc_820B1D98;
	// b 0x820b1d94
	goto loc_820B1D94;
loc_820B1D18:
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// bge cr6,0x820b1d58
	if (!cr6.getLT()) goto loc_820B1D58;
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// lfs f0,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fmuls f12,f0,f29
	ctx.f12.f64 = double(float(f0.f64 * f29.f64));
	// bge cr6,0x820b1d44
	if (!cr6.getLT()) goto loc_820B1D44;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,14116(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14116);
	f0.f64 = double(temp.f32);
	// fmadds f0,f12,f0,f11
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f11.f64));
	// stfs f0,8512(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8512, temp.u32);
	// b 0x820b1d8c
	goto loc_820B1D8C;
loc_820B1D44:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,14496(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14496);
	f0.f64 = double(temp.f32);
	// fmadds f0,f12,f0,f11
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f11.f64));
	// stfs f0,8512(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8512, temp.u32);
	// b 0x820b1d8c
	goto loc_820B1D8C;
loc_820B1D58:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// lfs f0,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmuls f12,f0,f29
	ctx.f12.f64 = double(float(f0.f64 * f29.f64));
	// lfs f0,14116(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14116);
	f0.f64 = double(temp.f32);
	// ble cr6,0x820b1d84
	if (!cr6.getGT()) goto loc_820B1D84;
	// fnmsubs f0,f12,f0,f11
	f0.f64 = double(float(-(ctx.f12.f64 * f0.f64 - ctx.f11.f64)));
	// stfs f0,8512(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8512, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820b1d98
	if (!cr6.getLT()) goto loc_820B1D98;
	// b 0x820b1d94
	goto loc_820B1D94;
loc_820B1D84:
	// fmadds f0,f12,f0,f11
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f11.f64));
	// stfs f0,8512(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8512, temp.u32);
loc_820B1D8C:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820b1d98
	if (!cr6.getGT()) goto loc_820B1D98;
loc_820B1D94:
	// stfs f13,8512(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 8512, temp.u32);
loc_820B1D98:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f29,-32(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// lfd f30,-24(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// lfd f31,-16(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1DB8"))) PPC_WEAK_FUNC(sub_820B1DB8);
PPC_FUNC_IMPL(__imp__sub_820B1DB8) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stfd f31,-16(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -16, f31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	ctx.f1.f64 = double(temp.f32);
	// fcmpu cr6,f31,f1
	cr6.compare(f31.f64, ctx.f1.f64);
	// ble cr6,0x820b1df0
	if (!cr6.getGT()) goto loc_820B1DF0;
	// bl 0x8210e390
	sub_8210E390(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f13,f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64 * f31.f64));
	// lfs f0,15128(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15128);
	f0.f64 = double(temp.f32);
	// b 0x820b1e0c
	goto loc_820B1E0C;
loc_820B1DF0:
	// fcmpu cr6,f31,f1
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, ctx.f1.f64);
	// bge cr6,0x820b1e10
	if (!cr6.getLT()) goto loc_820B1E10;
	// bl 0x8210e390
	sub_8210E390(ctx, base);
	// fneg f0,f31
	ctx.fpscr.disableFlushMode();
	f0.u64 = f31.u64 ^ 0x8000000000000000;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f13,f1,f0
	ctx.f13.f64 = double(float(ctx.f1.f64 * f0.f64));
	// lfs f0,15124(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15124);
	f0.f64 = double(temp.f32);
loc_820B1E0C:
	// fmuls f1,f13,f0
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = double(float(ctx.f13.f64 * f0.f64));
loc_820B1E10:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f31,-16(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1E28"))) PPC_WEAK_FUNC(sub_820B1E28);
PPC_FUNC_IMPL(__imp__sub_820B1E28) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stfd f29,-32(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -32, f29.u64);
	// stfd f30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, f30.u64);
	// stfd f31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, f31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// fmr f29,f2
	f29.f64 = ctx.f2.f64;
	// bl 0x8210e390
	sub_8210E390(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f13,f1,f29
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64 * f29.f64));
	// lfs f30,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f30.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fcmpu cr6,f31,f30
	cr6.compare(f31.f64, f30.f64);
	// lfs f0,6576(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6576);
	f0.f64 = double(temp.f32);
	// fmuls f29,f13,f0
	f29.f64 = double(float(ctx.f13.f64 * f0.f64));
	// ble cr6,0x820b1e84
	if (!cr6.getGT()) goto loc_820B1E84;
	// bl 0x8210e390
	sub_8210E390(ctx, base);
	// fmuls f13,f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = double(float(ctx.f1.f64 * f31.f64));
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,15128(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15128);
	f0.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// b 0x820b1eac
	goto loc_820B1EAC;
loc_820B1E84:
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// bge cr6,0x820b1ea8
	if (!cr6.getLT()) goto loc_820B1EA8;
	// bl 0x8210e390
	sub_8210E390(ctx, base);
	// fneg f0,f31
	ctx.fpscr.disableFlushMode();
	f0.u64 = f31.u64 ^ 0x8000000000000000;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fmuls f13,f1,f0
	ctx.f13.f64 = double(float(ctx.f1.f64 * f0.f64));
	// lfs f0,15124(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15124);
	f0.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// b 0x820b1eac
	goto loc_820B1EAC;
loc_820B1EA8:
	// fmr f13,f30
	ctx.fpscr.disableFlushMode();
	ctx.f13.f64 = f30.f64;
loc_820B1EAC:
	// lis r11,-32014
	r11.s64 = -2098069504;
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lfs f0,8516(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8516);
	f0.f64 = double(temp.f32);
	// fmr f11,f0
	ctx.f11.f64 = f0.f64;
	// ble cr6,0x820b1f00
	if (!cr6.getGT()) goto loc_820B1F00;
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// lfs f0,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fmuls f12,f0,f29
	ctx.f12.f64 = double(float(f0.f64 * f29.f64));
	// ble cr6,0x820b1ee4
	if (!cr6.getGT()) goto loc_820B1EE4;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,14116(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14116);
	f0.f64 = double(temp.f32);
	// b 0x820b1eec
	goto loc_820B1EEC;
loc_820B1EE4:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,14496(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14496);
	f0.f64 = double(temp.f32);
loc_820B1EEC:
	// fnmsubs f0,f12,f0,f11
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(-(ctx.f12.f64 * f0.f64 - ctx.f11.f64)));
	// stfs f0,8516(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8516, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820b1f80
	if (!cr6.getLT()) goto loc_820B1F80;
	// b 0x820b1f7c
	goto loc_820B1F7C;
loc_820B1F00:
	// fcmpu cr6,f31,f30
	ctx.fpscr.disableFlushMode();
	cr6.compare(f31.f64, f30.f64);
	// bge cr6,0x820b1f40
	if (!cr6.getLT()) goto loc_820B1F40;
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// lfs f0,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fmuls f12,f0,f29
	ctx.f12.f64 = double(float(f0.f64 * f29.f64));
	// bge cr6,0x820b1f2c
	if (!cr6.getLT()) goto loc_820B1F2C;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,14116(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14116);
	f0.f64 = double(temp.f32);
	// fmadds f0,f12,f0,f11
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f11.f64));
	// stfs f0,8516(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8516, temp.u32);
	// b 0x820b1f74
	goto loc_820B1F74;
loc_820B1F2C:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,14496(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14496);
	f0.f64 = double(temp.f32);
	// fmadds f0,f12,f0,f11
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f11.f64));
	// stfs f0,8516(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8516, temp.u32);
	// b 0x820b1f74
	goto loc_820B1F74;
loc_820B1F40:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// lfs f0,-6368(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + -6368);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmuls f12,f0,f29
	ctx.f12.f64 = double(float(f0.f64 * f29.f64));
	// lfs f0,14116(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14116);
	f0.f64 = double(temp.f32);
	// ble cr6,0x820b1f6c
	if (!cr6.getGT()) goto loc_820B1F6C;
	// fnmsubs f0,f12,f0,f11
	f0.f64 = double(float(-(ctx.f12.f64 * f0.f64 - ctx.f11.f64)));
	// stfs f0,8516(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8516, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820b1f80
	if (!cr6.getLT()) goto loc_820B1F80;
	// b 0x820b1f7c
	goto loc_820B1F7C;
loc_820B1F6C:
	// fmadds f0,f12,f0,f11
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f11.f64));
	// stfs f0,8516(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8516, temp.u32);
loc_820B1F74:
	// fcmpu cr6,f0,f13
	ctx.fpscr.disableFlushMode();
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820b1f80
	if (!cr6.getGT()) goto loc_820B1F80;
loc_820B1F7C:
	// stfs f13,8516(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 8516, temp.u32);
loc_820B1F80:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f29,-32(r1)
	ctx.fpscr.disableFlushMode();
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// lfd f30,-24(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// lfd f31,-16(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B1FA0"))) PPC_WEAK_FUNC(sub_820B1FA0);
PPC_FUNC_IMPL(__imp__sub_820B1FA0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,1280(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1280);
	// lfs f4,1284(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1284);
	ctx.f4.f64 = double(temp.f32);
	// lwz r9,1276(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 1276);
	// lwz r11,1272(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1272);
	// extsw r10,r10
	ctx.r10.s64 = ctx.r10.s32;
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r10,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r10.u64);
	// std r9,88(r1)
	PPC_STORE_U64(ctx.r1.u32 + 88, ctx.r9.u64);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f0,80(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// lfd f13,88(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// lfd f12,96(r1)
	ctx.f12.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// fcfid f12,f12
	ctx.f12.f64 = double(ctx.f12.s64);
	// frsp f11,f0
	ctx.f11.f64 = double(float(f0.f64));
	// lfs f0,6592(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6592);
	f0.f64 = double(temp.f32);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// frsp f12,f12
	ctx.f12.f64 = double(float(ctx.f12.f64));
	// fmuls f3,f11,f0
	ctx.f3.f64 = double(float(ctx.f11.f64 * f0.f64));
	// fmuls f2,f13,f0
	ctx.f2.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fmuls f1,f12,f0
	ctx.f1.f64 = double(float(ctx.f12.f64 * f0.f64));
	// bl 0x82098290
	sub_82098290(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B2028"))) PPC_WEAK_FUNC(sub_820B2028);
PPC_FUNC_IMPL(__imp__sub_820B2028) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r3,1272(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1272, ctx.r3.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r4,1276(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1276, ctx.r4.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r5,1280(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1280, ctx.r5.u32);
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stfs f1,1284(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r11.u32 + 1284, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B2050"))) PPC_WEAK_FUNC(sub_820B2050);
PPC_FUNC_IMPL(__imp__sub_820B2050) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stfs f0,1288(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1288, temp.u32);
	// stfs f1,1292(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1292, temp.u32);
	// lwz r9,1272(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1272);
	// stw r9,1296(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1296, ctx.r9.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r4,1300(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1300, ctx.r4.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r9,1276(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1276);
	// stw r9,1304(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1304, ctx.r9.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r5,1308(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1308, ctx.r5.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r9,1280(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1280);
	// stw r9,1312(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1312, ctx.r9.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r6,1316(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1316, ctx.r6.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// lfs f0,1284(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 1284);
	f0.f64 = double(temp.f32);
	// stfs f0,1320(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1320, temp.u32);
	// stfs f2,1324(r11)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(r11.u32 + 1324, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B20B8"))) PPC_WEAK_FUNC(sub_820B20B8);
PPC_FUNC_IMPL(__imp__sub_820B20B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lfs f0,2688(r6)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 2688);
	f0.f64 = double(temp.f32);
	// addi r9,r10,1272
	ctx.r9.s64 = ctx.r10.s64 + 1272;
	// lwz r8,1272(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1272);
	// lwz r7,1276(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1276);
	// lwz r6,1280(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1280);
	// stfs f0,1288(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1288, temp.u32);
	// stfs f1,1292(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1292, temp.u32);
	// lwz r9,0(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r9,1296(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1296, ctx.r9.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r8,1300(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1300, ctx.r8.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r9,1276(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1276);
	// stw r9,1304(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1304, ctx.r9.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r7,1308(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1308, ctx.r7.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r9,1280(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1280);
	// stw r9,1312(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1312, ctx.r9.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stw r6,1316(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1316, ctx.r6.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// lfs f0,1284(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 1284);
	f0.f64 = double(temp.f32);
	// stfs f0,1320(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1320, temp.u32);
	// stfs f2,1324(r11)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(r11.u32 + 1324, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B2130"))) PPC_WEAK_FUNC(sub_820B2130);
PPC_FUNC_IMPL(__imp__sub_820B2130) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lfs f0,2688(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	f0.f64 = double(temp.f32);
	// lfs f13,1292(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 1292);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bltlr cr6
	if (cr6.getLT()) return;
	// lis r9,-32014
	ctx.r9.s64 = -2098069504;
	// lfs f13,1288(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 1288);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,-6368(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -6368);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,1288(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1288, temp.u32);
	// lfs f12,1292(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 1292);
	ctx.f12.f64 = double(temp.f32);
	// fcmpu cr6,f0,f12
	cr6.compare(f0.f64, ctx.f12.f64);
	// bge cr6,0x820b224c
	if (!cr6.getLT()) goto loc_820B224C;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// fdivs f0,f0,f12
	f0.f64 = double(float(f0.f64 / ctx.f12.f64));
	// addi r8,r1,-16
	ctx.r8.s64 = ctx.r1.s64 + -16;
	// lfs f13,1320(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 1320);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,1324(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 1324);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f13
	ctx.f12.f64 = double(float(ctx.f12.f64 - ctx.f13.f64));
	// fmadds f13,f12,f0,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// stfs f13,1284(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1284, temp.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r9,1296(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1296);
	// lwz r7,1300(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1300);
	// subf r7,r9,r7
	ctx.r7.s64 = ctx.r7.s64 - ctx.r9.s64;
	// extsw r7,r7
	ctx.r7.s64 = ctx.r7.s32;
	// std r7,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r7.u64);
	// lfd f13,-16(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fctiwz f13,f13
	ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f13.f64));
	// stfiwx f13,0,r8
	PPC_STORE_U32(ctx.r8.u32, ctx.f13.u32);
	// lwz r8,-16(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// addi r7,r1,-16
	ctx.r7.s64 = ctx.r1.s64 + -16;
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// stw r9,1272(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1272, ctx.r9.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r9,1304(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1304);
	// lwz r8,1308(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1308);
	// subf r8,r9,r8
	ctx.r8.s64 = ctx.r8.s64 - ctx.r9.s64;
	// extsw r8,r8
	ctx.r8.s64 = ctx.r8.s32;
	// std r8,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r8.u64);
	// lfd f13,-16(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fctiwz f13,f13
	ctx.f13.s64 = (ctx.f13.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&ctx.f13.f64));
	// stfiwx f13,0,r7
	PPC_STORE_U32(ctx.r7.u32, ctx.f13.u32);
	// lwz r8,-16(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// addi r7,r1,-16
	ctx.r7.s64 = ctx.r1.s64 + -16;
	// add r9,r8,r9
	ctx.r9.u64 = ctx.r8.u64 + ctx.r9.u64;
	// stw r9,1276(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1276, ctx.r9.u32);
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,1312(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1312);
	// lwz r9,1316(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 1316);
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// extsw r9,r9
	ctx.r9.s64 = ctx.r9.s32;
	// std r9,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r9.u64);
	// lfd f13,-16(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r7
	PPC_STORE_U32(ctx.r7.u32, f0.u32);
	// lwz r9,-16(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// stw r10,1280(r11)
	PPC_STORE_U32(r11.u32 + 1280, ctx.r10.u32);
	// blr 
	return;
loc_820B224C:
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f13,1324(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 1324);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,1284(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 1284, temp.u32);
	// lfs f0,6580(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 6580);
	f0.f64 = double(temp.f32);
	// lwz r9,1300(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1300);
	// stw r9,1272(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1272, ctx.r9.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r9,1308(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1308);
	// stw r9,1276(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1276, ctx.r9.u32);
	// lwz r10,-1364(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r9,1316(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1316);
	// stw r9,1280(r10)
	PPC_STORE_U32(ctx.r10.u32 + 1280, ctx.r9.u32);
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// stfs f0,1292(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1292, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B2290"))) PPC_WEAK_FUNC(sub_820B2290);
PPC_FUNC_IMPL(__imp__sub_820B2290) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r9,-1364(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lwz r10,428(r9)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r9.u32 + 428);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// rotlwi r10,r10,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// lwz r8,8(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// rotlwi r11,r9,0
	r11.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// lfs f0,2688(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2688);
	f0.f64 = double(temp.f32);
	// rotlwi r10,r9,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// stfs f0,684(r9)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r9.u32 + 684, temp.u32);
	// stfs f1,688(r10)
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(ctx.r10.u32 + 688, temp.u32);
	// lbz r10,12(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 12);
	// std r10,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, ctx.r10.u64);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfd f0,-16(r1)
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f13,f0
	ctx.f13.f64 = double(float(f0.f64));
	// lfs f0,6592(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 6592);
	f0.f64 = double(temp.f32);
	// rotlwi r10,r9,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,692(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 692, temp.u32);
	// stfs f2,696(r11)
	temp.f32 = float(ctx.f2.f64);
	PPC_STORE_U32(r11.u32 + 696, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B2308"))) PPC_WEAK_FUNC(sub_820B2308);
PPC_FUNC_IMPL(__imp__sub_820B2308) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r8,-32014
	ctx.r8.s64 = -2098069504;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lwz r11,-1364(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + -1364);
	// lfs f0,2688(r9)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2688);
	f0.f64 = double(temp.f32);
	// addi r10,r11,688
	ctx.r10.s64 = r11.s64 + 688;
	// lfs f13,688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 688);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bltlr cr6
	if (cr6.getLT()) return;
	// lis r9,-32014
	ctx.r9.s64 = -2098069504;
	// lfs f13,684(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 684);
	ctx.f13.f64 = double(temp.f32);
	// lwz r7,428(r11)
	ctx.r7.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// lfs f0,-6368(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + -6368);
	f0.f64 = double(temp.f32);
	// addi r9,r11,684
	ctx.r9.s64 = r11.s64 + 684;
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// lwz r7,8(r7)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r7.u32 + 8);
	// stfs f0,684(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 684, temp.u32);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lfs f13,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820b2374
	if (!cr6.getLT()) goto loc_820B2374;
	// lfs f0,692(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 692);
	f0.f64 = double(temp.f32);
	// lfs f12,696(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 696);
	ctx.f12.f64 = double(temp.f32);
	// fsubs f12,f12,f0
	ctx.f12.f64 = double(float(ctx.f12.f64 - f0.f64));
	// lfs f11,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f11.f64 = double(temp.f32);
	// fdivs f13,f12,f13
	ctx.f13.f64 = double(float(ctx.f12.f64 / ctx.f13.f64));
	// fmadds f0,f13,f11,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f11.f64 + f0.f64));
	// b 0x820b2384
	goto loc_820B2384;
loc_820B2374:
	// lfs f0,696(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 696);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,6580(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6580);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,0(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
loc_820B2384:
	// cmplwi cr6,r7,0
	cr6.compare<uint32_t>(ctx.r7.u32, 0, xer);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,6596(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 6596);
	ctx.f13.f64 = double(temp.f32);
	// addi r11,r1,-16
	r11.s64 = ctx.r1.s64 + -16;
	// fmuls f0,f0,f13
	f0.f64 = double(float(f0.f64 * ctx.f13.f64));
	// fctiwz f0,f0
	f0.s64 = (f0.f64 > double(INT_MAX)) ? INT_MAX : _mm_cvttsd_si32(_mm_load_sd(&f0.f64));
	// stfiwx f0,0,r11
	PPC_STORE_U32(r11.u32, f0.u32);
	// lwz r11,-16(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -16);
	// stb r11,12(r7)
	PPC_STORE_U8(ctx.r7.u32 + 12, r11.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B23B0"))) PPC_WEAK_FUNC(sub_820B23B0);
PPC_FUNC_IMPL(__imp__sub_820B23B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// addi r12,r1,-32
	r12.s64 = ctx.r1.s64 + -32;
	// bl 0x823ed544
	// stwu r1,-304(r1)
	ea = -304 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// fmr f30,f1
	ctx.fpscr.disableFlushMode();
	f30.f64 = ctx.f1.f64;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmr f29,f2
	f29.f64 = ctx.f2.f64;
	// fmr f27,f3
	f27.f64 = ctx.f3.f64;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f31,2688(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2688);
	f31.f64 = double(temp.f32);
	// fmr f28,f31
	f28.f64 = f31.f64;
	// lwz r9,480(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 480);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x820b2414
	if (!cr6.getEQ()) goto loc_820B2414;
	// bl 0x820af0b0
	sub_820AF0B0(ctx, base);
	// fcmpu cr6,f30,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f30.f64, f31.f64);
	// beq cr6,0x820b2404
	if (cr6.getEQ()) goto loc_820B2404;
	// fdivs f28,f29,f30
	f28.f64 = double(float(f29.f64 / f30.f64));
	// b 0x820b24a0
	goto loc_820B24A0;
loc_820B2404:
	// fcmpu cr6,f29,f31
	ctx.fpscr.disableFlushMode();
	cr6.compare(f29.f64, f31.f64);
	// bne cr6,0x820b24a0
	if (!cr6.getEQ()) goto loc_820B24A0;
	// fmr f28,f31
	f28.f64 = f31.f64;
	// b 0x820b24a0
	goto loc_820B24A0;
loc_820B2414:
	// lwz r11,1352(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1352);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820b2490
	if (cr6.getEQ()) goto loc_820B2490;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r30,r3,31
	r30.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// add r30,r11,r30
	r30.u64 = r11.u64 + r30.u64;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r29,r3,31
	r29.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// clrlwi r4,r30,31
	ctx.r4.u64 = r30.u32 & 0x1;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// lfs f2,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	ctx.f2.f64 = double(temp.f32);
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// addi r9,r10,16596
	ctx.r9.s64 = ctx.r10.s64 + 16596;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r10,-1720(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + -1720);
	// divwu r8,r11,r10
	ctx.r8.u32 = r11.u32 / ctx.r10.u32;
	// twllei r10,0
	// mullw r10,r8,r10
	ctx.r10.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r10.s32);
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r3,r11,r9
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + ctx.r9.u32);
	// bl 0x820af258
	sub_820AF258(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,1352(r11)
	PPC_STORE_U32(r11.u32 + 1352, ctx.r10.u32);
loc_820B2490:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f1,2692(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x820af2b8
	sub_820AF2B8(ctx, base);
	// fmr f27,f31
	ctx.fpscr.disableFlushMode();
	f27.f64 = f31.f64;
loc_820B24A0:
	// fmr f2,f27
	ctx.fpscr.disableFlushMode();
	ctx.f2.f64 = f27.f64;
	// fmr f1,f28
	ctx.f1.f64 = f28.f64;
	// bl 0x820aeb80
	sub_820AEB80(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// lfs f0,616(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 616);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f30,14020(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 14020);
	f30.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// fsubs f0,f30,f0
	f0.f64 = double(float(f30.f64 - f0.f64));
	// lfs f29,13980(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13980);
	f29.f64 = double(temp.f32);
	// fmuls f1,f0,f29
	ctx.f1.f64 = double(float(f0.f64 * f29.f64));
	// bl 0x8210b828
	sub_8210B828(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// fmr f3,f31
	ctx.fpscr.disableFlushMode();
	ctx.f3.f64 = f31.f64;
	// fmr f2,f31
	ctx.f2.f64 = f31.f64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// lfs f0,1592(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1592);
	f0.f64 = double(temp.f32);
	// fneg f6,f0
	ctx.f6.u64 = f0.u64 ^ 0x8000000000000000;
	// lfs f13,1588(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1588);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,1584(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1584);
	f0.f64 = double(temp.f32);
	// fneg f5,f13
	ctx.f5.u64 = ctx.f13.u64 ^ 0x8000000000000000;
	// lfs f9,1604(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1604);
	ctx.f9.f64 = double(temp.f32);
	// fneg f4,f0
	ctx.f4.u64 = f0.u64 ^ 0x8000000000000000;
	// lfs f8,1600(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1600);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,1596(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1596);
	ctx.f7.f64 = double(temp.f32);
	// bl 0x8210c040
	sub_8210C040(ctx, base);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r4,r1,160
	ctx.r4.s64 = ctx.r1.s64 + 160;
	// lfs f0,596(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 596);
	f0.f64 = double(temp.f32);
	// fsubs f0,f30,f0
	f0.f64 = double(float(f30.f64 - f0.f64));
	// fmuls f1,f0,f29
	ctx.f1.f64 = double(float(f0.f64 * f29.f64));
	// bl 0x8210b8c8
	sub_8210B8C8(ctx, base);
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// addi r3,r1,160
	ctx.r3.s64 = ctx.r1.s64 + 160;
	// bl 0x8210c730
	sub_8210C730(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,128(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	f0.f64 = double(temp.f32);
	// stfs f0,1512(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1512, temp.u32);
	// lfs f0,132(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	f0.f64 = double(temp.f32);
	// stfs f0,1516(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1516, temp.u32);
	// lfs f0,136(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	f0.f64 = double(temp.f32);
	// stfs f0,1520(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1520, temp.u32);
	// lfs f0,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	f0.f64 = double(temp.f32);
	// stfs f0,1524(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1524, temp.u32);
	// lfs f0,116(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	f0.f64 = double(temp.f32);
	// stfs f0,1528(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1528, temp.u32);
	// lfs f0,120(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	f0.f64 = double(temp.f32);
	// stfs f0,1532(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1532, temp.u32);
	// addi r1,r1,304
	ctx.r1.s64 = ctx.r1.s64 + 304;
	// addi r12,r1,-32
	r12.s64 = ctx.r1.s64 + -32;
	// bl 0x823ed590
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820B2588"))) PPC_WEAK_FUNC(sub_820B2588);
PPC_FUNC_IMPL(__imp__sub_820B2588) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1828(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1828);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x820b25d8
	if (cr6.getEQ()) goto loc_820B25D8;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// lwz r11,16(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 16);
	// lfs f2,20(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f2.f64 = double(temp.f32);
	// lwz r3,24(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// lfs f1,12(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x821108b0
	sub_821108B0(ctx, base);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lfs f0,-1824(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + -1824);
	f0.f64 = double(temp.f32);
	// fadds f1,f1,f0
	ctx.f1.f64 = double(float(ctx.f1.f64 + f0.f64));
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820B25D8:
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1364(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1364);
	// lwz r10,8428(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 8428);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x820b25f0
	if (cr6.getEQ()) goto loc_820B25F0;
	// lwz r3,8432(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 8432);
loc_820B25F0:
	// bl 0x821108b0
	sub_821108B0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B2608"))) PPC_WEAK_FUNC(sub_820B2608);
PPC_FUNC_IMPL(__imp__sub_820B2608) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lwz r10,-908(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -908);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,13968(r8)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 13968);
	f0.f64 = double(temp.f32);
	// addi r9,r11,8252
	ctx.r9.s64 = r11.s64 + 8252;
	// lfs f12,100(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 100);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,1576(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1576);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f13,f12,f0
	f0.f64 = double(float(ctx.f13.f64 * ctx.f12.f64 + f0.f64));
	// stfs f0,8252(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8252, temp.u32);
	// lfs f13,396(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 396);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,420(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 420);
	f0.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// lfs f13,100(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// fmadds f0,f0,f13,f12
	f0.f64 = double(float(f0.f64 * ctx.f13.f64 + ctx.f12.f64));
	// lfs f13,3112(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3112);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820b266c
	if (!cr6.getLT()) goto loc_820B266C;
	// fmr f0,f13
	f0.f64 = ctx.f13.f64;
loc_820B266C:
	// lfs f13,372(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 372);
	ctx.f13.f64 = double(temp.f32);
	// addi r9,r11,1464
	ctx.r9.s64 = r11.s64 + 1464;
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// stfs f0,1464(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1464, temp.u32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,-1760(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -1760);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// cmpwi cr6,r10,5
	cr6.compare<int32_t>(ctx.r10.s32, 5, xer);
	// beq cr6,0x820b26a0
	if (cr6.getEQ()) goto loc_820B26A0;
	// cmpwi cr6,r10,6
	cr6.compare<int32_t>(ctx.r10.s32, 6, xer);
	// beq cr6,0x820b26a0
	if (cr6.getEQ()) goto loc_820B26A0;
	// cmpwi cr6,r10,7
	cr6.compare<int32_t>(ctx.r10.s32, 7, xer);
	// bne cr6,0x820b26ac
	if (!cr6.getEQ()) goto loc_820B26AC;
loc_820B26A0:
	// lwz r10,476(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 476);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x820b26c8
	if (!cr6.getEQ()) goto loc_820B26C8;
loc_820B26AC:
	// lfs f0,1460(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1460);
	f0.f64 = double(temp.f32);
	// stfs f0,1500(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1500, temp.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	f0.f64 = double(temp.f32);
	// stfs f0,1504(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1504, temp.u32);
	// lfs f0,1468(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1468);
	f0.f64 = double(temp.f32);
	// stfs f0,1508(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1508, temp.u32);
loc_820B26C8:
	// lwz r10,480(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 480);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,2688(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2688);
	ctx.f13.f64 = double(temp.f32);
	// beq cr6,0x820b270c
	if (cr6.getEQ()) goto loc_820B270C;
	// lfs f0,8256(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8256);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// ble cr6,0x820b270c
	if (!cr6.getGT()) goto loc_820B270C;
	// fmr f12,f0
	ctx.f12.f64 = f0.f64;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,12900(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12900);
	f0.f64 = double(temp.f32);
	// fsubs f0,f12,f0
	f0.f64 = double(float(ctx.f12.f64 - f0.f64));
	// stfs f0,8256(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 8256, temp.u32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820b2708
	if (!cr6.getLT()) goto loc_820B2708;
	// stfs f13,8256(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 8256, temp.u32);
loc_820B2708:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
loc_820B270C:
	// lfs f0,612(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 612);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820b273c
	if (!cr6.getLT()) goto loc_820B273C;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,624(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 624);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,1504(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1504);
	ctx.f12.f64 = double(temp.f32);
	// lfs f0,2776(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	f0.f64 = double(temp.f32);
	// fsubs f0,f0,f13
	f0.f64 = double(float(f0.f64 - ctx.f13.f64));
	// lfs f13,8256(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8256);
	ctx.f13.f64 = double(temp.f32);
	// fnmsubs f0,f0,f13,f12
	f0.f64 = double(float(-(f0.f64 * ctx.f13.f64 - ctx.f12.f64)));
	// stfs f0,1504(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1504, temp.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
loc_820B273C:
	// lwz r10,1456(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 1456);
	// lis r30,-32010
	r30.s64 = -2097807360;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r29,21292(r30)
	r29.u64 = PPC_LOAD_U32(r30.u32 + 21292);
	// stw r10,21292(r30)
	PPC_STORE_U32(r30.u32 + 21292, ctx.r10.u32);
	// lfs f4,1508(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1508);
	ctx.f4.f64 = double(temp.f32);
	// lfs f3,1500(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1500);
	ctx.f3.f64 = double(temp.f32);
	// lfs f2,1468(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1468);
	ctx.f2.f64 = double(temp.f32);
	// lfs f1,1460(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1460);
	ctx.f1.f64 = double(temp.f32);
	// bl 0x8210f7c8
	sub_8210F7C8(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stw r29,21292(r30)
	PPC_STORE_U32(r30.u32 + 21292, r29.u32);
	// stw r10,1536(r11)
	PPC_STORE_U32(r11.u32 + 1536, ctx.r10.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// addi r10,r11,1500
	ctx.r10.s64 = r11.s64 + 1500;
	// addi r9,r11,1508
	ctx.r9.s64 = r11.s64 + 1508;
	// lfs f0,1500(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1500);
	f0.f64 = double(temp.f32);
	// lwz r3,1536(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 1536);
	// stfs f0,1484(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1484, temp.u32);
	// lfs f0,1508(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1508);
	f0.f64 = double(temp.f32);
	// stfs f0,1492(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1492, temp.u32);
	// lfs f1,0(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	ctx.f1.f64 = double(temp.f32);
	// lfs f2,0(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	ctx.f2.f64 = double(temp.f32);
	// bl 0x820b2588
	sub_820B2588(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// li r9,0
	ctx.r9.s64 = 0;
	// stfs f1,1488(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f1.f64);
	PPC_STORE_U32(r11.u32 + 1488, temp.u32);
	// lwz r10,428(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// lwz r11,1456(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1456);
	// stw r11,24(r10)
	PPC_STORE_U32(ctx.r10.u32 + 24, r11.u32);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lwz r10,-1364(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,1460(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1460);
	f0.f64 = double(temp.f32);
	// lwz r11,428(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// stfs f0,12(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 12, temp.u32);
	// lfs f0,1464(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 1464);
	f0.f64 = double(temp.f32);
	// stfs f0,16(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 16, temp.u32);
	// lfs f0,1468(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 1468);
	f0.f64 = double(temp.f32);
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// stfs f0,20(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 20, temp.u32);
	// lwz r11,-6384(r10)
	r11.u64 = PPC_LOAD_U32(ctx.r10.u32 + -6384);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x820b2840
	if (!cr6.getGT()) goto loc_820B2840;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,14064(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 14064);
	f0.f64 = double(temp.f32);
loc_820B2800:
	// lfs f12,1500(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1500);
	ctx.f12.f64 = double(temp.f32);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// lfs f13,1248(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1248);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f13,1248(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1248, temp.u32);
	// lfs f12,1504(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1504);
	ctx.f12.f64 = double(temp.f32);
	// lfs f13,1252(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1252);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f13,1252(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1252, temp.u32);
	// lfs f13,1256(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1256);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,1508(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1508);
	ctx.f12.f64 = double(temp.f32);
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// stfs f13,1256(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1256, temp.u32);
	// lwz r8,-6384(r10)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r10.u32 + -6384);
	// cmpw cr6,r9,r8
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r8.s32, xer);
	// blt cr6,0x820b2800
	if (cr6.getLT()) goto loc_820B2800;
loc_820B2840:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,1248(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1248);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,15132(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15132);
	f0.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,1260(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1260, temp.u32);
	// lfs f13,1252(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1252);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f13,f13,f0
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f13,1264(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1264, temp.u32);
	// lfs f13,1256(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 1256);
	ctx.f13.f64 = double(temp.f32);
	// fmuls f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfs f0,1268(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1268, temp.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_820B2878"))) PPC_WEAK_FUNC(sub_820B2878);
PPC_FUNC_IMPL(__imp__sub_820B2878) {
	PPC_FUNC_PROLOGUE();
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stfd f29,-40(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -40, f29.u64);
	// stfd f30,-32(r1)
	PPC_STORE_U64(ctx.r1.u32 + -32, f30.u64);
	// stfd f31,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, f31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-32014
	r31.s64 = -2098069504;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,15112(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15112);
	f0.f64 = double(temp.f32);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,612(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 612);
	ctx.f13.f64 = double(temp.f32);
	// lfs f29,14020(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14020);
	f29.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820b28cc
	if (!cr6.getLT()) goto loc_820B28CC;
loc_820B28B8:
	// lfs f13,612(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 612);
	ctx.f13.f64 = double(temp.f32);
	// fadds f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 + f29.f64));
	// stfs f13,612(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 612, temp.u32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x820b28b8
	if (cr6.getLT()) goto loc_820B28B8;
loc_820B28CC:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,612(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 612);
	ctx.f13.f64 = double(temp.f32);
	// lfs f0,14216(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14216);
	f0.f64 = double(temp.f32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// blt cr6,0x820b28f4
	if (cr6.getLT()) goto loc_820B28F4;
loc_820B28E0:
	// lfs f13,612(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 612);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f13,f13,f29
	ctx.f13.f64 = double(float(ctx.f13.f64 - f29.f64));
	// stfs f13,612(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 612, temp.u32);
	// fcmpu cr6,f13,f0
	cr6.compare(ctx.f13.f64, f0.f64);
	// bge cr6,0x820b28e0
	if (!cr6.getLT()) goto loc_820B28E0;
loc_820B28F4:
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f0,612(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 612);
	f0.f64 = double(temp.f32);
	// lfs f13,12448(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 12448);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bgt cr6,0x820b2918
	if (cr6.getGT()) goto loc_820B2918;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f13,15136(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 15136);
	ctx.f13.f64 = double(temp.f32);
	// fcmpu cr6,f0,f13
	cr6.compare(f0.f64, ctx.f13.f64);
	// bge cr6,0x820b291c
	if (!cr6.getLT()) goto loc_820B291C;
loc_820B2918:
	// stfs f13,612(r11)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 612, temp.u32);
loc_820B291C:
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lfs f0,596(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 596);
	f0.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,13980(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 13980);
	f31.f64 = double(temp.f32);
	// fmuls f1,f0,f31
	ctx.f1.f64 = double(float(f0.f64 * f31.f64));
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// stfs f0,604(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 604, temp.u32);
	// lfs f0,596(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 596);
	f0.f64 = double(temp.f32);
	// fmuls f1,f0,f31
	ctx.f1.f64 = double(float(f0.f64 * f31.f64));
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// stfs f0,608(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 608, temp.u32);
	// lfs f0,612(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 612);
	f0.f64 = double(temp.f32);
	// lfs f30,2688(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2688);
	f30.f64 = double(temp.f32);
	// stfs f0,616(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 616, temp.u32);
	// fcmpu cr6,f0,f30
	cr6.compare(f0.f64, f30.f64);
	// bge cr6,0x820b2978
	if (!cr6.getLT()) goto loc_820B2978;
	// fadds f0,f0,f29
	f0.f64 = double(float(f0.f64 + f29.f64));
	// stfs f0,616(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 616, temp.u32);
loc_820B2978:
	// lfs f0,616(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 616);
	f0.f64 = double(temp.f32);
	// fmuls f1,f0,f31
	ctx.f1.f64 = double(float(f0.f64 * f31.f64));
	// bl 0x823edcb0
	sub_823EDCB0(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// stfs f0,624(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 624, temp.u32);
	// lfs f0,616(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 616);
	f0.f64 = double(temp.f32);
	// fmuls f1,f0,f31
	ctx.f1.f64 = double(float(f0.f64 * f31.f64));
	// bl 0x823edbe0
	sub_823EDBE0(ctx, base);
	// lwz r11,-1364(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + -1364);
	// frsp f0,f1
	ctx.fpscr.disableFlushMode();
	f0.f64 = double(float(ctx.f1.f64));
	// stfs f0,628(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 628, temp.u32);
	// lfs f0,608(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 608);
	f0.f64 = double(temp.f32);
	// fneg f0,f0
	f0.u64 = f0.u64 ^ 0x8000000000000000;
	// stfs f0,1472(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1472, temp.u32);
	// stfs f30,1476(r11)
	temp.f32 = float(f30.f64);
	PPC_STORE_U32(r11.u32 + 1476, temp.u32);
	// lfs f0,604(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 604);
	f0.f64 = double(temp.f32);
	// stfs f0,1480(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1480, temp.u32);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// lfd f29,-40(r1)
	f29.u64 = PPC_LOAD_U64(ctx.r1.u32 + -40);
	// lfd f30,-32(r1)
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -32);
	// lfd f31,-24(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B29E0"))) PPC_WEAK_FUNC(sub_820B29E0);
PPC_FUNC_IMPL(__imp__sub_820B29E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, f31.u64);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r10,-3696(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -3696);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,-3696(r11)
	PPC_STORE_U32(r11.u32 + -3696, ctx.r10.u32);
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1840(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1840);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x820b2cac
	if (cr6.getEQ()) goto loc_820B2CAC;
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lwz r11,-1736(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1736);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x820b2cac
	if (!cr6.getEQ()) goto loc_820B2CAC;
	// lis r28,-32014
	r28.s64 = -2098069504;
	// lis r29,-32014
	r29.s64 = -2098069504;
	// lwz r11,-2980(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + -2980);
	// lwz r9,-6376(r29)
	ctx.r9.u64 = PPC_LOAD_U32(r29.u32 + -6376);
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// bge cr6,0x820b2cac
	if (!cr6.getLT()) goto loc_820B2CAC;
	// lis r30,-32014
	r30.s64 = -2098069504;
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// lwz r9,428(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// lfs f0,12(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	f0.f64 = double(temp.f32);
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// lwz r9,428(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// lfs f0,16(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 16);
	f0.f64 = double(temp.f32);
	// stfs f0,108(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lwz r11,428(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// lfs f0,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	f0.f64 = double(temp.f32);
	// srawi r11,r10,2
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x3) != 0);
	r11.s64 = ctx.r10.s32 >> 2;
	// stfs f0,112(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
	// addze r11,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	r11.s64 = temp.s64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// lfs f31,14028(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 14028);
	f31.f64 = double(temp.f32);
	// bgt cr6,0x820b2be4
	if (cr6.getGT()) goto loc_820B2BE4;
	// lis r12,-32245
	r12.s64 = -2113208320;
	// addi r12,r12,10908
	r12.s64 = r12.s64 + 10908;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_820B2AAC;
	case 1:
		goto loc_820B2AFC;
	case 2:
		goto loc_820B2B4C;
	case 3:
		goto loc_820B2B98;
	default:
		__builtin_unreachable();
	}
	// lwz r16,10924(r11)
	r16.u64 = PPC_LOAD_U32(r11.u32 + 10924);
	// lwz r16,11004(r11)
	r16.u64 = PPC_LOAD_U32(r11.u32 + 11004);
	// lwz r16,11084(r11)
	r16.u64 = PPC_LOAD_U32(r11.u32 + 11084);
	// lwz r16,11160(r11)
	r16.u64 = PPC_LOAD_U32(r11.u32 + 11160);
loc_820B2AAC:
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r31,r3,31
	r31.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f12,104(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f12.f64 = double(temp.f32);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f0,3032(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3032);
	f0.f64 = double(temp.f32);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * f31.f64));
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// lfs f0,15140(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15140);
	f0.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// b 0x820b2be4
	goto loc_820B2BE4;
loc_820B2AFC:
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r31,r3,31
	r31.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f0,3032(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3032);
	f0.f64 = double(temp.f32);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 * f31.f64));
	// lfs f13,15140(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15140);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f12,f0,f13
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// lfs f13,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
	// stfs f0,104(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 104, temp.u32);
	// b 0x820b2be4
	goto loc_820B2BE4;
loc_820B2B4C:
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r31,r3,31
	r31.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// lfs f12,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f12.f64 = double(temp.f32);
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f0,3032(r10)
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3032);
	f0.f64 = double(temp.f32);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f13,f13,f31
	ctx.f13.f64 = double(float(ctx.f13.f64 * f31.f64));
	// fmadds f13,f13,f0,f12
	ctx.f13.f64 = double(float(ctx.f13.f64 * f0.f64 + ctx.f12.f64));
	// lfs f0,15140(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15140);
	f0.f64 = double(temp.f32);
	// fadds f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 + f0.f64));
	// b 0x820b2be0
	goto loc_820B2BE0;
loc_820B2B98:
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r31,r3,31
	r31.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// lfs f0,3032(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 3032);
	f0.f64 = double(temp.f32);
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 * f31.f64));
	// lfs f13,15140(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 15140);
	ctx.f13.f64 = double(temp.f32);
	// fmadds f0,f12,f0,f13
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 + ctx.f13.f64));
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// fsubs f0,f13,f0
	f0.f64 = double(float(ctx.f13.f64 - f0.f64));
loc_820B2BE0:
	// stfs f0,112(r1)
	ctx.fpscr.disableFlushMode();
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 112, temp.u32);
loc_820B2BE4:
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r31,r3,31
	r31.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// li r9,0
	ctx.r9.s64 = 0;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
	// li r5,-1
	ctx.r5.s64 = -1;
	// lfs f0,2940(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2940);
	f0.f64 = double(temp.f32);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r9,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, ctx.r9.u8);
	// li r7,0
	ctx.r7.s64 = 0;
	// std r11,96(r1)
	PPC_STORE_U64(ctx.r1.u32 + 96, r11.u64);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// li r6,18
	ctx.r6.s64 = 18;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// addi r4,r1,104
	ctx.r4.s64 = ctx.r1.s64 + 104;
	// li r3,0
	ctx.r3.s64 = 0;
	// lfd f13,96(r1)
	ctx.f13.u64 = PPC_LOAD_U64(ctx.r1.u32 + 96);
	// fcfid f13,f13
	ctx.f13.f64 = double(ctx.f13.s64);
	// frsp f13,f13
	ctx.f13.f64 = double(float(ctx.f13.f64));
	// fmuls f12,f13,f31
	ctx.f12.f64 = double(float(ctx.f13.f64 * f31.f64));
	// lfs f13,2944(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2944);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,-1364(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + -1364);
	// fmsubs f0,f12,f0,f13
	f0.f64 = double(float(ctx.f12.f64 * f0.f64 - ctx.f13.f64));
	// lfs f13,108(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	ctx.f13.f64 = double(temp.f32);
	// fadds f0,f0,f13
	f0.f64 = double(float(f0.f64 + ctx.f13.f64));
	// stfs f0,108(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 108, temp.u32);
	// lwz r11,428(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 428);
	// addi r9,r11,48
	ctx.r9.s64 = r11.s64 + 48;
	// lwz r5,24(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 24);
	// bl 0x821427b8
	sub_821427B8(ctx, base);
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// clrlwi r31,r3,31
	r31.u64 = ctx.r3.u32 & 0x1;
	// bl 0x8238ce40
	sub_8238CE40(ctx, base);
	// rlwinm r11,r3,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r10,-30584
	ctx.r10.s64 = -2004353024;
	// add r11,r11,r31
	r11.u64 = r11.u64 + r31.u64;
	// ori r10,r10,34953
	ctx.r10.u64 = ctx.r10.u64 | 34953;
	// mulhwu r10,r11,r10
	ctx.r10.u64 = (uint64_t(r11.u32) * uint64_t(ctx.r10.u32)) >> 32;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// rlwinm r9,r10,4,0,27
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0xFFFFFFF0;
	// subf r9,r10,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r10.s64;
	// lwz r10,-6376(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + -6376);
	// subf r10,r9,r10
	ctx.r10.s64 = ctx.r10.s64 - ctx.r9.s64;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// addi r11,r11,15
	r11.s64 = r11.s64 + 15;
	// stw r11,-2980(r28)
	PPC_STORE_U32(r28.u32 + -2980, r11.u32);
loc_820B2CAC:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_820B2CB8"))) PPC_WEAK_FUNC(sub_820B2CB8);
PPC_FUNC_IMPL(__imp__sub_820B2CB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820eb800
	sub_820EB800(ctx, base);
	// addi r11,r3,-2
	r11.s64 = ctx.r3.s64 + -2;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_820B2CE8"))) PPC_WEAK_FUNC(sub_820B2CE8);
PPC_FUNC_IMPL(__imp__sub_820B2CE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x820eb800
	sub_820EB800(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq cr6,0x820b2d4c
	if (cr6.getEQ()) goto loc_820B2D4C;
	// bl 0x820eb800
	sub_820EB800(ctx, base);
	// cmpwi cr6,r3,4
	cr6.compare<int32_t>(ctx.r3.s32, 4, xer);
	// beq cr6,0x820b2d4c
	if (cr6.getEQ()) goto loc_820B2D4C;
	// bl 0x820eb800
	sub_820EB800(ctx, base);
	// cmpwi cr6,r3,2
	cr6.compare<int32_t>(ctx.r3.s32, 2, xer);
	// beq cr6,0x820b2d4c
	if (cr6.getEQ()) goto loc_820B2D4C;
	// bl 0x820ae360
	sub_820AE360(ctx, base);
	// cmpwi cr6,r3,54
	cr6.compare<int32_t>(ctx.r3.s32, 54, xer);
	// bne cr6,0x820b2d38
	if (!cr6.getEQ()) goto loc_820B2D38;
	// li r3,440
	ctx.r3.s64 = 440;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820B2D38:
	// li r3,320
	ctx.r3.s64 = 320;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
loc_820B2D4C:
	// li r3,159
	ctx.r3.s64 = 159;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

