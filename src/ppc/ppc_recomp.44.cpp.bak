#include "ppc_recomp_shared.h"

__attribute__((alias("__imp__sub_823FE618"))) PPC_WEAK_FUNC(sub_823FE618);
PPC_FUNC_IMPL(__imp__sub_823FE618) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r18{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// lwz r18,-1044(0)
	r18.u64 = PPC_LOAD_U32(-1044);
	// lwz r16,29808(r7)
	r16.u64 = PPC_LOAD_U32(ctx.r7.u32 + 29808);
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// addi r31,r1,-112
	r31.s64 = ctx.r1.s64 + -112;
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r30,132(r31)
	PPC_STORE_U32(r31.u32 + 132, r30.u32);
	// bl 0x823f4e20
	sub_823F4E20(ctx, base);
	// addi r11,r3,32
	r11.s64 = ctx.r3.s64 + 32;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// beq cr6,0x823fe6a0
	if (cr6.getEQ()) goto loc_823FE6A0;
	// bl 0x823f4e20
	sub_823F4E20(ctx, base);
	// addi r11,r3,64
	r11.s64 = ctx.r3.s64 + 64;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// beq cr6,0x823fe6a0
	if (cr6.getEQ()) goto loc_823FE6A0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x823fe674
	if (!cr6.getEQ()) goto loc_823FE674;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x823fe438
	sub_823FE438(ctx, base);
	// b 0x823fe6a4
	goto loc_823FE6A4;
loc_823FE674:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f4f98
	sub_823F4F98(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe3b8
	sub_823FE3B8(ctx, base);
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,112
	r12.s64 = r31.s64 + 112;
	// bl 0x823fe6dc
	sub_823FE6DC(ctx, base);
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// b 0x823fe6a4
	goto loc_823FE6A4;
loc_823FE6A0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_823FE6A4:
	// addi r1,r31,112
	ctx.r1.s64 = r31.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FE620"))) PPC_WEAK_FUNC(sub_823FE620);
PPC_FUNC_IMPL(__imp__sub_823FE620) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// addi r31,r1,-112
	r31.s64 = ctx.r1.s64 + -112;
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r30,132(r31)
	PPC_STORE_U32(r31.u32 + 132, r30.u32);
	// bl 0x823f4e20
	sub_823F4E20(ctx, base);
	// addi r11,r3,32
	r11.s64 = ctx.r3.s64 + 32;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// beq cr6,0x823fe6a0
	if (cr6.getEQ()) goto loc_823FE6A0;
	// bl 0x823f4e20
	sub_823F4E20(ctx, base);
	// addi r11,r3,64
	r11.s64 = ctx.r3.s64 + 64;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// beq cr6,0x823fe6a0
	if (cr6.getEQ()) goto loc_823FE6A0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x823fe674
	if (!cr6.getEQ()) goto loc_823FE674;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x823fe438
	sub_823FE438(ctx, base);
	// b 0x823fe6a4
	goto loc_823FE6A4;
loc_823FE674:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f4f98
	sub_823F4F98(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe3b8
	sub_823FE3B8(ctx, base);
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,112
	r12.s64 = r31.s64 + 112;
	// bl 0x823fe6dc
	sub_823FE6DC(ctx, base);
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// b 0x823fe6a4
	goto loc_823FE6A4;
loc_823FE6A0:
	// li r3,0
	ctx.r3.s64 = 0;
loc_823FE6A4:
	// addi r1,r31,112
	ctx.r1.s64 = r31.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FE6BC"))) PPC_WEAK_FUNC(sub_823FE6BC);
PPC_FUNC_IMPL(__imp__sub_823FE6BC) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-112
	r31.s64 = r12.s64 + -112;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,132(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 132);
	// b 0x823fe6f4
	goto loc_823FE6F4;
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-112
	r31.s64 = r12.s64 + -112;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
loc_823FE6F4:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5058
	sub_823F5058(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FE6DC"))) PPC_WEAK_FUNC(sub_823FE6DC);
PPC_FUNC_IMPL(__imp__sub_823FE6DC) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-112
	r31.s64 = r12.s64 + -112;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5058
	sub_823F5058(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FE718"))) PPC_WEAK_FUNC(sub_823FE718);
PPC_FUNC_IMPL(__imp__sub_823FE718) {
	PPC_FUNC_PROLOGUE();
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x823fe438
	sub_823FE438(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_823FE720"))) PPC_WEAK_FUNC(sub_823FE720);
PPC_FUNC_IMPL(__imp__sub_823FE720) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x823fe764
	if (!cr6.getEQ()) goto loc_823FE764;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x823fe768
	goto loc_823FE768;
loc_823FE764:
	// lwz r3,16(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 16);
loc_823FE768:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FE778"))) PPC_WEAK_FUNC(sub_823FE778);
PPC_FUNC_IMPL(__imp__sub_823FE778) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x823fe7a4
	if (!cr6.getEQ()) goto loc_823FE7A4;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x823fe7a4
	if (cr6.getEQ()) goto loc_823FE7A4;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x823fe888
	if (cr6.getEQ()) goto loc_823FE888;
	// b 0x823fe884
	goto loc_823FE884;
loc_823FE7A4:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x823fe7b4
	if (cr6.getEQ()) goto loc_823FE7B4;
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
loc_823FE7B4:
	// lis r10,32767
	ctx.r10.s64 = 2147418112;
	// ori r10,r10,65535
	ctx.r10.u64 = ctx.r10.u64 | 65535;
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// ble cr6,0x823fe7f4
	if (!cr6.getGT()) goto loc_823FE7F4;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,22
	ctx.r3.s64 = 22;
	// b 0x823fe88c
	goto loc_823FE88C;
loc_823FE7F4:
	// clrlwi r10,r6,16
	ctx.r10.u64 = ctx.r6.u32 & 0xFFFF;
	// cmplwi cr6,r10,255
	cr6.compare<uint32_t>(ctx.r10.u32, 255, xer);
	// ble cr6,0x823fe834
	if (!cr6.getGT()) goto loc_823FE834;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x823fe81c
	if (cr6.getEQ()) goto loc_823FE81C;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x823fe81c
	if (cr6.getEQ()) goto loc_823FE81C;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
loc_823FE81C:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,42
	r11.s64 = 42;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// b 0x823fe88c
	goto loc_823FE88C;
loc_823FE834:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x823fe878
	if (cr6.getEQ()) goto loc_823FE878;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x823fe874
	if (!cr6.getEQ()) goto loc_823FE874;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,34
	ctx.r10.s64 = 34;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,34
	ctx.r3.s64 = 34;
	// b 0x823fe88c
	goto loc_823FE88C;
loc_823FE874:
	// stb r6,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r6.u8);
loc_823FE878:
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x823fe888
	if (cr6.getEQ()) goto loc_823FE888;
	// li r11,1
	r11.s64 = 1;
loc_823FE884:
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
loc_823FE888:
	// li r3,0
	ctx.r3.s64 = 0;
loc_823FE88C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FE8A0"))) PPC_WEAK_FUNC(sub_823FE8A0);
PPC_FUNC_IMPL(__imp__sub_823FE8A0) {
	PPC_FUNC_PROLOGUE();
	// li r7,0
	ctx.r7.s64 = 0;
	// b 0x823fe778
	sub_823FE778(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_823FE8A8"))) PPC_WEAK_FUNC(sub_823FE8A8);
PPC_FUNC_IMPL(__imp__sub_823FE8A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32015
	r11.s64 = -2098135040;
	// rlwinm r10,r3,1,23,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 1) & 0x1FE;
	// lwz r11,-19456(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -19456);
	// lwz r11,200(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 200);
	// lhzx r11,r10,r11
	r11.u64 = PPC_LOAD_U16(ctx.r10.u32 + r11.u32);
	// rlwinm r3,r11,0,0,16
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF8000;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FE8C8"))) PPC_WEAK_FUNC(sub_823FE8C8);
PPC_FUNC_IMPL(__imp__sub_823FE8C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r6
	r31.u64 = ctx.r6.u64;
	// lwz r11,12(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 12);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823fe950
	if (cr0.getEQ()) goto loc_823FE950;
	// lwz r11,8(r28)
	r11.u64 = PPC_LOAD_U32(r28.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x823fe950
	if (!cr6.getEQ()) goto loc_823FE950;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x823fe958
	goto loc_823FE958;
loc_823FE90C:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lbz r3,0(r29)
	ctx.r3.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r30,r30,-1
	r30.s64 = r30.s64 + -1;
	// bl 0x823f5218
	sub_823F5218(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x823fe950
	if (!cr6.getEQ()) goto loc_823FE950;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmpwi cr6,r11,42
	cr6.compare<int32_t>(r11.s32, 42, xer);
	// bne cr6,0x823fe958
	if (!cr6.getEQ()) goto loc_823FE958;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// li r3,63
	ctx.r3.s64 = 63;
	// bl 0x823f5218
	sub_823F5218(ctx, base);
loc_823FE950:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bgt cr6,0x823fe90c
	if (cr6.getGT()) goto loc_823FE90C;
loc_823FE958:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_823FE960"))) PPC_WEAK_FUNC(sub_823FE960);
PPC_FUNC_IMPL(__imp__sub_823FE960) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed100
	// stwu r1,-1328(r1)
	ea = -1328 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r27,0
	r27.s64 = 0;
	// mr r23,r3
	r23.u64 = ctx.r3.u64;
	// mr r19,r4
	r19.u64 = ctx.r4.u64;
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// mr r25,r27
	r25.u64 = r27.u64;
	// stw r27,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r27.u32);
	// mr r16,r27
	r16.u64 = r27.u64;
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r27.u32);
	// cmplwi cr6,r23,0
	cr6.compare<uint32_t>(r23.u32, 0, xer);
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r27.u32);
	// stw r27,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r27.u32);
	// bne cr6,0x823fe9cc
	if (!cr6.getEQ()) goto loc_823FE9CC;
loc_823FE99C:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x823ff4e4
	goto loc_823FF4E4;
loc_823FE9CC:
	// lwz r11,12(r23)
	r11.u64 = PPC_LOAD_U32(r23.u32 + 12);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x823fea98
	if (!cr0.getEQ()) goto loc_823FEA98;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lis r11,-31987
	r11.s64 = -2096300032;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// addi r30,r11,-15840
	r30.s64 = r11.s64 + -15840;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r29,r11,-18648
	r29.s64 = r11.s64 + -18648;
	// beq cr6,0x823fea30
	if (cr6.getEQ()) goto loc_823FEA30;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x823fea30
	if (cr6.getEQ()) goto loc_823FEA30;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// rlwinm r31,r11,2,0,29
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r31,r30
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + r30.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// b 0x823fea34
	goto loc_823FEA34;
loc_823FEA30:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_823FEA34:
	// lbz r11,40(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 40);
	// rlwinm. r11,r11,0,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x823fe99c
	if (!cr0.getEQ()) goto loc_823FE99C;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x823fea88
	if (cr6.getEQ()) goto loc_823FEA88;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x823fea88
	if (cr6.getEQ()) goto loc_823FEA88;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// rlwinm r31,r11,2,0,29
	r31.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r31,r30
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + r30.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// b 0x823fea8c
	goto loc_823FEA8C;
loc_823FEA88:
	// mr r11,r29
	r11.u64 = r29.u64;
loc_823FEA8C:
	// lbz r11,40(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 40);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x823fe99c
	if (!cr0.getEQ()) goto loc_823FE99C;
loc_823FEA98:
	// cmplwi cr6,r19,0
	cr6.compare<uint32_t>(r19.u32, 0, xer);
	// beq cr6,0x823fe99c
	if (cr6.getEQ()) goto loc_823FE99C;
	// bl 0x823f4e20
	sub_823F4E20(ctx, base);
	// addi r11,r3,32
	r11.s64 = ctx.r3.s64 + 32;
	// cmplw cr6,r23,r11
	cr6.compare<uint32_t>(r23.u32, r11.u32, xer);
	// beq cr6,0x823ff4b0
	if (cr6.getEQ()) goto loc_823FF4B0;
	// bl 0x823f4e20
	sub_823F4E20(ctx, base);
	// addi r11,r3,64
	r11.s64 = ctx.r3.s64 + 64;
	// cmplw cr6,r23,r11
	cr6.compare<uint32_t>(r23.u32, r11.u32, xer);
	// beq cr6,0x823ff4b0
	if (cr6.getEQ()) goto loc_823FF4B0;
	// lbz r29,0(r19)
	r29.u64 = PPC_LOAD_U8(r19.u32 + 0);
	// mr r24,r27
	r24.u64 = r27.u64;
	// mr r8,r27
	ctx.r8.u64 = r27.u64;
	// stw r27,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r27.u32);
	// mr r15,r27
	r15.u64 = r27.u64;
	// stw r24,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r24.u32);
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
	// extsb. r10,r29
	ctx.r10.s64 = r29.s8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823ff4a8
	if (cr0.getEQ()) goto loc_823FF4A8;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// lwz r20,112(r1)
	r20.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lwz r28,112(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// lis r14,-32249
	r14.s64 = -2113470464;
	// addi r22,r11,-19456
	r22.s64 = r11.s64 + -19456;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// lis r17,-32249
	r17.s64 = -2113470464;
	// addi r21,r11,-20552
	r21.s64 = r11.s64 + -20552;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r18,r11,12088
	r18.s64 = r11.s64 + 12088;
loc_823FEB0C:
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// blt cr6,0x823ff494
	if (cr6.getLT()) goto loc_823FF494;
	// cmpwi cr6,r10,32
	cr6.compare<int32_t>(ctx.r10.s32, 32, xer);
	// blt cr6,0x823feb38
	if (cr6.getLT()) goto loc_823FEB38;
	// cmpwi cr6,r10,120
	cr6.compare<int32_t>(ctx.r10.s32, 120, xer);
	// bgt cr6,0x823feb38
	if (cr6.getGT()) goto loc_823FEB38;
	// add r11,r10,r18
	r11.u64 = ctx.r10.u64 + r18.u64;
	// lbz r11,-32(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + -32);
	// clrlwi r11,r11,28
	r11.u64 = r11.u32 & 0xF;
	// b 0x823feb3c
	goto loc_823FEB3C;
loc_823FEB38:
	// li r11,0
	r11.s64 = 0;
loc_823FEB3C:
	// lwz r9,100(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// mulli r11,r11,9
	r11.s64 = r11.s64 * 9;
	// add r11,r11,r9
	r11.u64 = r11.u64 + ctx.r9.u64;
	// lbzx r11,r11,r18
	r11.u64 = PPC_LOAD_U8(r11.u32 + r18.u32);
	// rlwinm r11,r11,28,4,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 28) & 0xFFFFFFF;
	// cmpwi cr6,r11,8
	cr6.compare<int32_t>(r11.s32, 8, xer);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// beq cr6,0x823fe99c
	if (cr6.getEQ()) goto loc_823FE99C;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// bgt cr6,0x823ff480
	if (cr6.getGT()) goto loc_823FF480;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// lis r12,-32249
	r12.s64 = -2113470464;
	// addi r12,r12,12296
	r12.s64 = r12.s64 + 12296;
	// rlwinm r0,r11,1,0,30
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-32192
	r12.s64 = -2109734912;
	// addi r12,r12,-5232
	r12.s64 = r12.s64 + -5232;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_823FED5C;
	case 1:
		goto loc_823FEB90;
	case 2:
		goto loc_823FEBB0;
	case 3:
		goto loc_823FEC00;
	case 4:
		goto loc_823FEC4C;
	case 5:
		goto loc_823FEC54;
	case 6:
		goto loc_823FEC8C;
	case 7:
		goto loc_823FEDAC;
	default:
		__builtin_unreachable();
	}
loc_823FEB90:
	// li r27,0
	r27.s64 = 0;
	// li r25,-1
	r25.s64 = -1;
	// mr r20,r27
	r20.u64 = r27.u64;
	// mr r16,r27
	r16.u64 = r27.u64;
	// stw r27,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r27.u32);
	// stw r27,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r27.u32);
	// stw r27,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r27.u32);
	// b 0x823ff480
	goto loc_823FF480;
loc_823FEBB0:
	// cmpwi cr6,r10,32
	cr6.compare<int32_t>(ctx.r10.s32, 32, xer);
	// beq cr6,0x823febf8
	if (cr6.getEQ()) goto loc_823FEBF8;
	// cmpwi cr6,r10,35
	cr6.compare<int32_t>(ctx.r10.s32, 35, xer);
	// beq cr6,0x823febf0
	if (cr6.getEQ()) goto loc_823FEBF0;
	// cmpwi cr6,r10,43
	cr6.compare<int32_t>(ctx.r10.s32, 43, xer);
	// beq cr6,0x823febe8
	if (cr6.getEQ()) goto loc_823FEBE8;
	// cmpwi cr6,r10,45
	cr6.compare<int32_t>(ctx.r10.s32, 45, xer);
	// beq cr6,0x823febe0
	if (cr6.getEQ()) goto loc_823FEBE0;
	// cmpwi cr6,r10,48
	cr6.compare<int32_t>(ctx.r10.s32, 48, xer);
	// bne cr6,0x823ff480
	if (!cr6.getEQ()) goto loc_823FF480;
	// ori r27,r27,8
	r27.u64 = r27.u64 | 8;
	// b 0x823ff480
	goto loc_823FF480;
loc_823FEBE0:
	// ori r27,r27,4
	r27.u64 = r27.u64 | 4;
	// b 0x823ff480
	goto loc_823FF480;
loc_823FEBE8:
	// ori r27,r27,1
	r27.u64 = r27.u64 | 1;
	// b 0x823ff480
	goto loc_823FF480;
loc_823FEBF0:
	// ori r27,r27,128
	r27.u64 = r27.u64 | 128;
	// b 0x823ff480
	goto loc_823FF480;
loc_823FEBF8:
	// ori r27,r27,2
	r27.u64 = r27.u64 | 2;
	// b 0x823ff480
	goto loc_823FF480;
loc_823FEC00:
	// cmpwi cr6,r10,42
	cr6.compare<int32_t>(ctx.r10.s32, 42, xer);
	// bne cr6,0x823fec34
	if (!cr6.getEQ()) goto loc_823FEC34;
	// addi r11,r26,7
	r11.s64 = r26.s64 + 7;
	// rlwinm r11,r11,0,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFF8;
	// addi r26,r11,8
	r26.s64 = r11.s64 + 8;
	// lwz r11,-4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + -4);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// bge 0x823ff480
	if (!cr0.getLT()) goto loc_823FF480;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// ori r27,r27,4
	r27.u64 = r27.u64 | 4;
	// neg r11,r11
	r11.s64 = -r11.s64;
	// b 0x823fec44
	goto loc_823FEC44;
loc_823FEC34:
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// mulli r11,r11,10
	r11.s64 = r11.s64 * 10;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r11,r11,-48
	r11.s64 = r11.s64 + -48;
loc_823FEC44:
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// b 0x823ff480
	goto loc_823FF480;
loc_823FEC4C:
	// li r25,0
	r25.s64 = 0;
	// b 0x823ff480
	goto loc_823FF480;
loc_823FEC54:
	// cmpwi cr6,r10,42
	cr6.compare<int32_t>(ctx.r10.s32, 42, xer);
	// bne cr6,0x823fec7c
	if (!cr6.getEQ()) goto loc_823FEC7C;
	// addi r11,r26,7
	r11.s64 = r26.s64 + 7;
	// rlwinm r11,r11,0,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFF8;
	// addi r26,r11,8
	r26.s64 = r11.s64 + 8;
	// lwz r25,-4(r26)
	r25.u64 = PPC_LOAD_U32(r26.u32 + -4);
	// cmpwi r25,0
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// bge 0x823ff480
	if (!cr0.getLT()) goto loc_823FF480;
	// li r25,-1
	r25.s64 = -1;
	// b 0x823ff480
	goto loc_823FF480;
loc_823FEC7C:
	// mulli r11,r25,10
	r11.s64 = r25.s64 * 10;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r25,r11,-48
	r25.s64 = r11.s64 + -48;
	// b 0x823ff480
	goto loc_823FF480;
loc_823FEC8C:
	// cmpwi cr6,r10,73
	cr6.compare<int32_t>(ctx.r10.s32, 73, xer);
	// beq cr6,0x823fecdc
	if (cr6.getEQ()) goto loc_823FECDC;
	// cmpwi cr6,r10,104
	cr6.compare<int32_t>(ctx.r10.s32, 104, xer);
	// beq cr6,0x823fecd4
	if (cr6.getEQ()) goto loc_823FECD4;
	// cmpwi cr6,r10,108
	cr6.compare<int32_t>(ctx.r10.s32, 108, xer);
	// beq cr6,0x823fecb4
	if (cr6.getEQ()) goto loc_823FECB4;
	// cmpwi cr6,r10,119
	cr6.compare<int32_t>(ctx.r10.s32, 119, xer);
	// bne cr6,0x823ff480
	if (!cr6.getEQ()) goto loc_823FF480;
	// ori r27,r27,2048
	r27.u64 = r27.u64 | 2048;
	// b 0x823ff480
	goto loc_823FF480;
loc_823FECB4:
	// lbz r11,0(r19)
	r11.u64 = PPC_LOAD_U8(r19.u32 + 0);
	// cmplwi cr6,r11,108
	cr6.compare<uint32_t>(r11.u32, 108, xer);
	// bne cr6,0x823feccc
	if (!cr6.getEQ()) goto loc_823FECCC;
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// ori r27,r27,4096
	r27.u64 = r27.u64 | 4096;
	// b 0x823ff480
	goto loc_823FF480;
loc_823FECCC:
	// ori r27,r27,16
	r27.u64 = r27.u64 | 16;
	// b 0x823ff480
	goto loc_823FF480;
loc_823FECD4:
	// ori r27,r27,32
	r27.u64 = r27.u64 | 32;
	// b 0x823ff480
	goto loc_823FF480;
loc_823FECDC:
	// lbz r11,0(r19)
	r11.u64 = PPC_LOAD_U8(r19.u32 + 0);
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,54
	cr6.compare<int32_t>(r11.s32, 54, xer);
	// bne cr6,0x823fed04
	if (!cr6.getEQ()) goto loc_823FED04;
	// lbz r10,1(r19)
	ctx.r10.u64 = PPC_LOAD_U8(r19.u32 + 1);
	// cmplwi cr6,r10,52
	cr6.compare<uint32_t>(ctx.r10.u32, 52, xer);
	// bne cr6,0x823fed04
	if (!cr6.getEQ()) goto loc_823FED04;
	// addi r19,r19,2
	r19.s64 = r19.s64 + 2;
	// ori r27,r27,32768
	r27.u64 = r27.u64 | 32768;
	// b 0x823ff480
	goto loc_823FF480;
loc_823FED04:
	// cmpwi cr6,r11,51
	cr6.compare<int32_t>(r11.s32, 51, xer);
	// bne cr6,0x823fed24
	if (!cr6.getEQ()) goto loc_823FED24;
	// lbz r10,1(r19)
	ctx.r10.u64 = PPC_LOAD_U8(r19.u32 + 1);
	// cmplwi cr6,r10,50
	cr6.compare<uint32_t>(ctx.r10.u32, 50, xer);
	// bne cr6,0x823fed24
	if (!cr6.getEQ()) goto loc_823FED24;
	// addi r19,r19,2
	r19.s64 = r19.s64 + 2;
	// rlwinm r27,r27,0,17,15
	r27.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFFFFFFFFF7FFF;
	// b 0x823ff480
	goto loc_823FF480;
loc_823FED24:
	// cmpwi cr6,r11,100
	cr6.compare<int32_t>(r11.s32, 100, xer);
	// beq cr6,0x823ff480
	if (cr6.getEQ()) goto loc_823FF480;
	// cmpwi cr6,r11,105
	cr6.compare<int32_t>(r11.s32, 105, xer);
	// beq cr6,0x823ff480
	if (cr6.getEQ()) goto loc_823FF480;
	// cmpwi cr6,r11,111
	cr6.compare<int32_t>(r11.s32, 111, xer);
	// beq cr6,0x823ff480
	if (cr6.getEQ()) goto loc_823FF480;
	// cmpwi cr6,r11,117
	cr6.compare<int32_t>(r11.s32, 117, xer);
	// beq cr6,0x823ff480
	if (cr6.getEQ()) goto loc_823FF480;
	// cmpwi cr6,r11,120
	cr6.compare<int32_t>(r11.s32, 120, xer);
	// beq cr6,0x823ff480
	if (cr6.getEQ()) goto loc_823FF480;
	// cmpwi cr6,r11,88
	cr6.compare<int32_t>(r11.s32, 88, xer);
	// beq cr6,0x823ff480
	if (cr6.getEQ()) goto loc_823FF480;
	// li r11,0
	r11.s64 = 0;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
loc_823FED5C:
	// clrlwi r3,r29,24
	ctx.r3.u64 = r29.u32 & 0xFF;
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// li r16,0
	r16.s64 = 0;
	// bl 0x823fe8a8
	sub_823FE8A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x823fed94
	if (cr0.getEQ()) goto loc_823FED94;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823f5218
	sub_823F5218(ctx, base);
	// lbz r29,0(r19)
	r29.u64 = PPC_LOAD_U8(r19.u32 + 0);
	// addi r19,r19,1
	r19.s64 = r19.s64 + 1;
	// cmplwi r29,0
	cr0.compare<uint32_t>(r29.u32, 0, xer);
	// beq 0x823fe99c
	if (cr0.getEQ()) goto loc_823FE99C;
loc_823FED94:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823f5218
	sub_823F5218(ctx, base);
	// lwz r24,80(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// b 0x823ff480
	goto loc_823FF480;
loc_823FEDAC:
	// addi r11,r10,-65
	r11.s64 = ctx.r10.s64 + -65;
	// cmplwi cr6,r11,55
	cr6.compare<uint32_t>(r11.u32, 55, xer);
	// bgt cr6,0x823ff2ac
	if (cr6.getGT()) goto loc_823FF2AC;
	// lis r12,-32249
	r12.s64 = -2113470464;
	// addi r12,r12,12184
	r12.s64 = r12.s64 + 12184;
	// rlwinm r0,r11,1,0,30
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-32192
	r12.s64 = -2109734912;
	// addi r12,r12,-4640
	r12.s64 = r12.s64 + -4640;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_823FEFBC;
	case 1:
		goto loc_823FF2AC;
	case 2:
		goto loc_823FEDE0;
	case 3:
		goto loc_823FF2AC;
	case 4:
		goto loc_823FEFBC;
	case 5:
		goto loc_823FF2AC;
	case 6:
		goto loc_823FEFBC;
	case 7:
		goto loc_823FF2AC;
	case 8:
		goto loc_823FF2AC;
	case 9:
		goto loc_823FF2AC;
	case 10:
		goto loc_823FF2AC;
	case 11:
		goto loc_823FF2AC;
	case 12:
		goto loc_823FF2AC;
	case 13:
		goto loc_823FF2AC;
	case 14:
		goto loc_823FF2AC;
	case 15:
		goto loc_823FF2AC;
	case 16:
		goto loc_823FF2AC;
	case 17:
		goto loc_823FF2AC;
	case 18:
		goto loc_823FEEC8;
	case 19:
		goto loc_823FF2AC;
	case 20:
		goto loc_823FF2AC;
	case 21:
		goto loc_823FF2AC;
	case 22:
		goto loc_823FF2AC;
	case 23:
		goto loc_823FF0FC;
	case 24:
		goto loc_823FF2AC;
	case 25:
		goto loc_823FEE4C;
	case 26:
		goto loc_823FF2AC;
	case 27:
		goto loc_823FF2AC;
	case 28:
		goto loc_823FF2AC;
	case 29:
		goto loc_823FF2AC;
	case 30:
		goto loc_823FF2AC;
	case 31:
		goto loc_823FF2AC;
	case 32:
		goto loc_823FEFC8;
	case 33:
		goto loc_823FF2AC;
	case 34:
		goto loc_823FEDF0;
	case 35:
		goto loc_823FF0EC;
	case 36:
		goto loc_823FEFC8;
	case 37:
		goto loc_823FEFC8;
	case 38:
		goto loc_823FEFC8;
	case 39:
		goto loc_823FF2AC;
	case 40:
		goto loc_823FF0EC;
	case 41:
		goto loc_823FF2AC;
	case 42:
		goto loc_823FF2AC;
	case 43:
		goto loc_823FF2AC;
	case 44:
		goto loc_823FF2AC;
	case 45:
		goto loc_823FEF80;
	case 46:
		goto loc_823FF134;
	case 47:
		goto loc_823FF0F8;
	case 48:
		goto loc_823FF2AC;
	case 49:
		goto loc_823FF2AC;
	case 50:
		goto loc_823FEED8;
	case 51:
		goto loc_823FF2AC;
	case 52:
		goto loc_823FF0F0;
	case 53:
		goto loc_823FF2AC;
	case 54:
		goto loc_823FF2AC;
	case 55:
		goto loc_823FF104;
	default:
		__builtin_unreachable();
	}
loc_823FEDE0:
	// andi. r11,r27,2096
	r11.u64 = r27.u64 & 2096;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x823fedf0
	if (!cr0.getEQ()) goto loc_823FEDF0;
	// ori r27,r27,2048
	r27.u64 = r27.u64 | 2048;
loc_823FEDF0:
	// andi. r11,r27,2064
	r11.u64 = r27.u64 & 2064;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r11,r26,7
	r11.s64 = r26.s64 + 7;
	// rlwinm r11,r11,0,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFF8;
	// addi r26,r11,8
	r26.s64 = r11.s64 + 8;
	// beq 0x823fee30
	if (cr0.getEQ()) goto loc_823FEE30;
	// li r5,512
	ctx.r5.s64 = 512;
	// lhz r6,-2(r26)
	ctx.r6.u64 = PPC_LOAD_U16(r26.u32 + -2);
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
	// addi r3,r1,84
	ctx.r3.s64 = ctx.r1.s64 + 84;
	// bl 0x823fe8a0
	sub_823FE8A0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x823fee40
	if (cr0.getEQ()) goto loc_823FEE40;
	// li r11,1
	r11.s64 = 1;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// b 0x823fee40
	goto loc_823FEE40;
loc_823FEE30:
	// lwz r11,-4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + -4);
	// li r10,1
	ctx.r10.s64 = 1;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// stb r11,144(r1)
	PPC_STORE_U8(ctx.r1.u32 + 144, r11.u8);
loc_823FEE40:
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r28,r1,144
	r28.s64 = ctx.r1.s64 + 144;
	// b 0x823ff2ac
	goto loc_823FF2AC;
loc_823FEE4C:
	// addi r11,r26,7
	r11.s64 = r26.s64 + 7;
	// rlwinm r11,r11,0,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFF8;
	// addi r26,r11,8
	r26.s64 = r11.s64 + 8;
	// lwz r11,-4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + -4);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x823fee9c
	if (cr0.getEQ()) goto loc_823FEE9C;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x823fee9c
	if (cr0.getEQ()) goto loc_823FEE9C;
	// rlwinm. r9,r27,0,20,20
	ctx.r9.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
	// beq 0x823fee90
	if (cr0.getEQ()) goto loc_823FEE90;
	// lha r11,0(r11)
	r11.s64 = int16_t(PPC_LOAD_U16(r11.u32 + 0));
	// li r16,1
	r16.s64 = 1;
	// srawi r11,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	r11.s64 = r11.s32 >> 1;
	// addze r8,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	ctx.r8.s64 = temp.s64;
	// b 0x823ff2a8
	goto loc_823FF2A8;
loc_823FEE90:
	// lha r8,0(r11)
	ctx.r8.s64 = int16_t(PPC_LOAD_U16(r11.u32 + 0));
	// li r16,0
	r16.s64 = 0;
	// b 0x823ff2a8
	goto loc_823FF2A8;
loc_823FEE9C:
	// lwz r28,10996(r17)
	r28.u64 = PPC_LOAD_U32(r17.u32 + 10996);
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_823FEEA8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x823feea8
	if (!cr6.getEQ()) goto loc_823FEEA8;
loc_823FEEB8:
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r8,r11,0
	ctx.r8.u64 = __builtin_rotateleft32(r11.u32, 0);
	// b 0x823ff2a8
	goto loc_823FF2A8;
loc_823FEEC8:
	// andi. r11,r27,2096
	r11.u64 = r27.u64 & 2096;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x823feed8
	if (!cr0.getEQ()) goto loc_823FEED8;
	// ori r27,r27,2048
	r27.u64 = r27.u64 | 2048;
loc_823FEED8:
	// cmpwi cr6,r25,-1
	cr6.compare<int32_t>(r25.s32, -1, xer);
	// bne cr6,0x823feeec
	if (!cr6.getEQ()) goto loc_823FEEEC;
	// lis r10,32767
	ctx.r10.s64 = 2147418112;
	// ori r10,r10,65535
	ctx.r10.u64 = ctx.r10.u64 | 65535;
	// b 0x823feef0
	goto loc_823FEEF0;
loc_823FEEEC:
	// mr r10,r25
	ctx.r10.u64 = r25.u64;
loc_823FEEF0:
	// addi r11,r26,7
	r11.s64 = r26.s64 + 7;
	// andi. r9,r27,2064
	ctx.r9.u64 = r27.u64 & 2064;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// rlwinm r11,r11,0,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFF8;
	// cmpwi r9,0
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r26,r11,8
	r26.s64 = r11.s64 + 8;
	// lwz r28,-4(r26)
	r28.u64 = PPC_LOAD_U32(r26.u32 + -4);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq 0x823fef4c
	if (cr0.getEQ()) goto loc_823FEF4C;
	// bne cr6,0x823fef18
	if (!cr6.getEQ()) goto loc_823FEF18;
	// lwz r28,11000(r14)
	r28.u64 = PPC_LOAD_U32(r14.u32 + 11000);
loc_823FEF18:
	// li r16,1
	r16.s64 = 1;
	// mr r11,r28
	r11.u64 = r28.u64;
	// b 0x823fef38
	goto loc_823FEF38;
loc_823FEF24:
	// lhz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U16(r11.u32 + 0);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// cmplwi r9,0
	cr0.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq 0x823fef40
	if (cr0.getEQ()) goto loc_823FEF40;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
loc_823FEF38:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x823fef24
	if (!cr6.getEQ()) goto loc_823FEF24;
loc_823FEF40:
	// subf r11,r28,r11
	r11.s64 = r11.s64 - r28.s64;
	// srawi r8,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r8.s64 = r11.s32 >> 1;
	// b 0x823ff2a8
	goto loc_823FF2A8;
loc_823FEF4C:
	// bne cr6,0x823fef54
	if (!cr6.getEQ()) goto loc_823FEF54;
	// lwz r28,10996(r17)
	r28.u64 = PPC_LOAD_U32(r17.u32 + 10996);
loc_823FEF54:
	// mr r11,r28
	r11.u64 = r28.u64;
	// b 0x823fef70
	goto loc_823FEF70;
loc_823FEF5C:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x823fef78
	if (cr6.getEQ()) goto loc_823FEF78;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_823FEF70:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x823fef5c
	if (!cr6.getEQ()) goto loc_823FEF5C;
loc_823FEF78:
	// subf r8,r28,r11
	ctx.r8.s64 = r11.s64 - r28.s64;
	// b 0x823ff2a8
	goto loc_823FF2A8;
loc_823FEF80:
	// addi r11,r26,7
	r11.s64 = r26.s64 + 7;
	// rlwinm r11,r11,0,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFF8;
	// addi r26,r11,8
	r26.s64 = r11.s64 + 8;
	// lwz r31,-4(r26)
	r31.u64 = PPC_LOAD_U32(r26.u32 + -4);
	// bl 0x823ed4a0
	sub_823ED4A0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x823fe99c
	if (cr0.getEQ()) goto loc_823FE99C;
	// rlwinm. r11,r27,0,26,26
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823fefac
	if (cr0.getEQ()) goto loc_823FEFAC;
	// sth r24,0(r31)
	PPC_STORE_U16(r31.u32 + 0, r24.u16);
	// b 0x823fefb0
	goto loc_823FEFB0;
loc_823FEFAC:
	// stw r24,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r24.u32);
loc_823FEFB0:
	// li r11,1
	r11.s64 = 1;
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// b 0x823ff46c
	goto loc_823FF46C;
loc_823FEFBC:
	// addi r11,r10,32
	r11.s64 = ctx.r10.s64 + 32;
	// li r20,1
	r20.s64 = 1;
	// extsb r29,r11
	r29.s64 = r11.s8;
loc_823FEFC8:
	// ori r27,r27,64
	r27.u64 = r27.u64 | 64;
	// addi r28,r1,144
	r28.s64 = ctx.r1.s64 + 144;
	// li r30,512
	r30.s64 = 512;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bge cr6,0x823fefe4
	if (!cr6.getLT()) goto loc_823FEFE4;
	// li r25,6
	r25.s64 = 6;
	// b 0x823ff034
	goto loc_823FF034;
loc_823FEFE4:
	// bne cr6,0x823feffc
	if (!cr6.getEQ()) goto loc_823FEFFC;
	// extsb r11,r29
	r11.s64 = r29.s8;
	// cmpwi cr6,r11,103
	cr6.compare<int32_t>(r11.s32, 103, xer);
	// bne cr6,0x823ff034
	if (!cr6.getEQ()) goto loc_823FF034;
	// li r25,1
	r25.s64 = 1;
	// b 0x823ff034
	goto loc_823FF034;
loc_823FEFFC:
	// cmpwi cr6,r25,512
	cr6.compare<int32_t>(r25.s32, 512, xer);
	// ble cr6,0x823ff008
	if (!cr6.getGT()) goto loc_823FF008;
	// li r25,512
	r25.s64 = 512;
loc_823FF008:
	// cmpwi cr6,r25,163
	cr6.compare<int32_t>(r25.s32, 163, xer);
	// ble cr6,0x823ff034
	if (!cr6.getGT()) goto loc_823FF034;
	// addi r31,r25,349
	r31.s64 = r25.s64 + 349;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ed2b0
	sub_823ED2B0(ctx, base);
	// mr. r15,r3
	r15.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r15.s32, 0, xer);
	// beq 0x823ff030
	if (cr0.getEQ()) goto loc_823FF030;
	// mr r28,r15
	r28.u64 = r15.u64;
	// mr r30,r31
	r30.u64 = r31.u64;
	// b 0x823ff034
	goto loc_823FF034;
loc_823FF030:
	// li r25,163
	r25.s64 = 163;
loc_823FF034:
	// addi r11,r26,7
	r11.s64 = r26.s64 + 7;
	// extsb r31,r29
	r31.s64 = r29.s8;
	// rlwinm r11,r11,0,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFF8;
	// mr r8,r20
	ctx.r8.u64 = r20.u64;
	// addi r26,r11,8
	r26.s64 = r11.s64 + 8;
	// lwz r11,24(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 24);
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// mr r7,r25
	ctx.r7.u64 = r25.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// ld r10,-8(r26)
	ctx.r10.u64 = PPC_LOAD_U64(r26.u32 + -8);
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// std r10,128(r1)
	PPC_STORE_U64(ctx.r1.u32 + 128, ctx.r10.u64);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// rlwinm. r30,r27,0,24,24
	r30.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// beq 0x823ff098
	if (cr0.getEQ()) goto loc_823FF098;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bne cr6,0x823ff098
	if (!cr6.getEQ()) goto loc_823FF098;
	// lwz r11,36(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 36);
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_823FF098:
	// cmpwi cr6,r31,103
	cr6.compare<int32_t>(r31.s32, 103, xer);
	// bne cr6,0x823ff0bc
	if (!cr6.getEQ()) goto loc_823FF0BC;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x823ff0bc
	if (!cr6.getEQ()) goto loc_823FF0BC;
	// lwz r11,32(r21)
	r11.u64 = PPC_LOAD_U32(r21.u32 + 32);
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_823FF0BC:
	// lbz r11,0(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 0);
	// cmplwi cr6,r11,45
	cr6.compare<uint32_t>(r11.u32, 45, xer);
	// bne cr6,0x823ff0d0
	if (!cr6.getEQ()) goto loc_823FF0D0;
	// ori r27,r27,256
	r27.u64 = r27.u64 | 256;
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
loc_823FF0D0:
	// mr r11,r28
	r11.u64 = r28.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_823FF0D8:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x823ff0d8
	if (!cr6.getEQ()) goto loc_823FF0D8;
	// b 0x823feeb8
	goto loc_823FEEB8;
loc_823FF0EC:
	// ori r27,r27,64
	r27.u64 = r27.u64 | 64;
loc_823FF0F0:
	// li r8,10
	ctx.r8.s64 = 10;
	// b 0x823ff144
	goto loc_823FF144;
loc_823FF0F8:
	// li r25,8
	r25.s64 = 8;
loc_823FF0FC:
	// li r11,7
	r11.s64 = 7;
	// b 0x823ff108
	goto loc_823FF108;
loc_823FF104:
	// li r11,39
	r11.s64 = 39;
loc_823FF108:
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
	// rlwinm. r10,r27,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// li r8,16
	ctx.r8.s64 = 16;
	// beq 0x823ff144
	if (cr0.getEQ()) goto loc_823FF144;
	// addi r11,r11,81
	r11.s64 = r11.s64 + 81;
	// li r10,48
	ctx.r10.s64 = 48;
	// stb r11,89(r1)
	PPC_STORE_U8(ctx.r1.u32 + 89, r11.u8);
	// li r11,2
	r11.s64 = 2;
	// stb r10,88(r1)
	PPC_STORE_U8(ctx.r1.u32 + 88, ctx.r10.u8);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// b 0x823ff144
	goto loc_823FF144;
loc_823FF134:
	// rlwinm. r11,r27,0,24,24
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r8,8
	ctx.r8.s64 = 8;
	// beq 0x823ff144
	if (cr0.getEQ()) goto loc_823FF144;
	// ori r27,r27,512
	r27.u64 = r27.u64 | 512;
loc_823FF144:
	// rlwinm. r11,r27,0,16,16
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x823ff154
	if (!cr0.getEQ()) goto loc_823FF154;
	// rlwinm. r11,r27,0,19,19
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ff168
	if (cr0.getEQ()) goto loc_823FF168;
loc_823FF154:
	// addi r11,r26,7
	r11.s64 = r26.s64 + 7;
	// rlwinm r11,r11,0,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFF8;
	// addi r26,r11,8
	r26.s64 = r11.s64 + 8;
	// ld r11,-8(r26)
	r11.u64 = PPC_LOAD_U64(r26.u32 + -8);
	// b 0x823ff1b8
	goto loc_823FF1B8;
loc_823FF168:
	// rlwinm. r11,r27,0,26,26
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ff198
	if (cr0.getEQ()) goto loc_823FF198;
	// rlwinm. r11,r27,0,25,25
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r11,r26,7
	r11.s64 = r26.s64 + 7;
	// rlwinm r11,r11,0,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFF8;
	// addi r26,r11,8
	r26.s64 = r11.s64 + 8;
	// lwz r11,-4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + -4);
	// beq 0x823ff190
	if (cr0.getEQ()) goto loc_823FF190;
	// extsh r11,r11
	r11.s64 = r11.s16;
	// b 0x823ff1b8
	goto loc_823FF1B8;
loc_823FF190:
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// b 0x823ff1b8
	goto loc_823FF1B8;
loc_823FF198:
	// rlwinm. r11,r27,0,25,25
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r11,r26,7
	r11.s64 = r26.s64 + 7;
	// rlwinm r11,r11,0,0,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFF8;
	// addi r26,r11,8
	r26.s64 = r11.s64 + 8;
	// beq 0x823ff1b4
	if (cr0.getEQ()) goto loc_823FF1B4;
	// lwa r11,-4(r26)
	r11.s64 = int32_t(PPC_LOAD_U32(r26.u32 + -4));
	// b 0x823ff1b8
	goto loc_823FF1B8;
loc_823FF1B4:
	// lwz r11,-4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + -4);
loc_823FF1B8:
	// rlwinm. r10,r27,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823ff1d0
	if (cr0.getEQ()) goto loc_823FF1D0;
	// cmpdi cr6,r11,0
	cr6.compare<int64_t>(r11.s64, 0, xer);
	// bge cr6,0x823ff1d0
	if (!cr6.getLT()) goto loc_823FF1D0;
	// neg r11,r11
	r11.s64 = -r11.s64;
	// ori r27,r27,256
	r27.u64 = r27.u64 | 256;
loc_823FF1D0:
	// rlwinm. r10,r27,0,16,16
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x823ff1e4
	if (!cr0.getEQ()) goto loc_823FF1E4;
	// rlwinm. r10,r27,0,19,19
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x823ff1e4
	if (!cr0.getEQ()) goto loc_823FF1E4;
	// clrldi r11,r11,32
	r11.u64 = r11.u64 & 0xFFFFFFFF;
loc_823FF1E4:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bge cr6,0x823ff1f4
	if (!cr6.getLT()) goto loc_823FF1F4;
	// li r25,1
	r25.s64 = 1;
	// b 0x823ff204
	goto loc_823FF204;
loc_823FF1F4:
	// rlwinm r27,r27,0,29,27
	r27.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF7;
	// cmpwi cr6,r25,512
	cr6.compare<int32_t>(r25.s32, 512, xer);
	// ble cr6,0x823ff204
	if (!cr6.getGT()) goto loc_823FF204;
	// li r25,512
	r25.s64 = 512;
loc_823FF204:
	// cmpldi cr6,r11,0
	cr6.compare<uint64_t>(r11.u64, 0, xer);
	// bne cr6,0x823ff214
	if (!cr6.getEQ()) goto loc_823FF214;
	// li r10,0
	ctx.r10.s64 = 0;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
loc_823FF214:
	// addi r9,r1,655
	ctx.r9.s64 = ctx.r1.s64 + 655;
loc_823FF218:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// addi r25,r25,-1
	r25.s64 = r25.s64 + -1;
	// bgt cr6,0x823ff22c
	if (cr6.getGT()) goto loc_823FF22C;
	// cmpldi cr6,r11,0
	cr6.compare<uint64_t>(r11.u64, 0, xer);
	// beq cr6,0x823ff26c
	if (cr6.getEQ()) goto loc_823FF26C;
loc_823FF22C:
	// extsw r10,r8
	ctx.r10.s64 = ctx.r8.s32;
	// divdu r7,r11,r10
	ctx.r7.u64 = r11.u64 / ctx.r10.u64;
	// tdllei r10,0
	// mulld r7,r7,r10
	ctx.r7.s64 = ctx.r7.s64 * ctx.r10.s64;
	// subf r7,r7,r11
	ctx.r7.s64 = r11.s64 - ctx.r7.s64;
	// divdu r11,r11,r10
	r11.u64 = r11.u64 / ctx.r10.u64;
	// tdllei r10,0
	// rotlwi r10,r7,0
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r7.u32, 0);
	// addi r10,r10,48
	ctx.r10.s64 = ctx.r10.s64 + 48;
	// cmpwi cr6,r10,57
	cr6.compare<int32_t>(ctx.r10.s32, 57, xer);
	// ble cr6,0x823ff260
	if (!cr6.getGT()) goto loc_823FF260;
	// lwz r7,108(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// add r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 + ctx.r7.u64;
loc_823FF260:
	// stb r10,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r10.u8);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// b 0x823ff218
	goto loc_823FF218;
loc_823FF26C:
	// addi r11,r1,655
	r11.s64 = ctx.r1.s64 + 655;
	// rlwinm. r10,r27,0,22,22
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// subf r8,r9,r11
	ctx.r8.s64 = r11.s64 - ctx.r9.s64;
	// addi r28,r9,1
	r28.s64 = ctx.r9.s64 + 1;
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
	// beq 0x823ff2ac
	if (cr0.getEQ()) goto loc_823FF2AC;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x823ff298
	if (cr6.getEQ()) goto loc_823FF298;
	// lbz r11,0(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 0);
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// beq cr6,0x823ff2ac
	if (cr6.getEQ()) goto loc_823FF2AC;
loc_823FF298:
	// addi r28,r28,-1
	r28.s64 = r28.s64 + -1;
	// li r11,48
	r11.s64 = 48;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// stb r11,0(r28)
	PPC_STORE_U8(r28.u32 + 0, r11.u8);
loc_823FF2A8:
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
loc_823FF2AC:
	// lwz r11,104(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823ff46c
	if (!cr6.getEQ()) goto loc_823FF46C;
	// rlwinm. r11,r27,0,25,25
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ff2fc
	if (cr0.getEQ()) goto loc_823FF2FC;
	// rlwinm. r11,r27,0,23,23
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ff2d0
	if (cr0.getEQ()) goto loc_823FF2D0;
	// li r11,45
	r11.s64 = 45;
	// b 0x823ff2dc
	goto loc_823FF2DC;
loc_823FF2D0:
	// clrlwi. r11,r27,31
	r11.u64 = r27.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ff2ec
	if (cr0.getEQ()) goto loc_823FF2EC;
	// li r11,43
	r11.s64 = 43;
loc_823FF2DC:
	// li r30,1
	r30.s64 = 1;
	// stb r11,88(r1)
	PPC_STORE_U8(ctx.r1.u32 + 88, r11.u8);
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// b 0x823ff300
	goto loc_823FF300;
loc_823FF2EC:
	// rlwinm. r11,r27,0,30,30
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ff2fc
	if (cr0.getEQ()) goto loc_823FF2FC;
	// li r11,32
	r11.s64 = 32;
	// b 0x823ff2dc
	goto loc_823FF2DC;
loc_823FF2FC:
	// lwz r30,92(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
loc_823FF300:
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// rlwinm. r10,r27,0,28,29
	ctx.r10.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0xC;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// subf r11,r8,r11
	r11.s64 = r11.s64 - ctx.r8.s64;
	// subf r29,r30,r11
	r29.s64 = r11.s64 - r30.s64;
	// bne 0x823ff348
	if (!cr0.getEQ()) goto loc_823FF348;
	// mr r31,r29
	r31.u64 = r29.u64;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// ble cr6,0x823ff348
	if (!cr6.getGT()) goto loc_823FF348;
loc_823FF320:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r3,32
	ctx.r3.s64 = 32;
	// addi r31,r31,-1
	r31.s64 = r31.s64 + -1;
	// bl 0x823f5218
	sub_823F5218(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x823ff348
	if (cr6.getEQ()) goto loc_823FF348;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bgt cr6,0x823ff320
	if (cr6.getGT()) goto loc_823FF320;
loc_823FF348:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x823fe8c8
	sub_823FE8C8(ctx, base);
	// rlwinm. r11,r27,0,28,28
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ff3a0
	if (cr0.getEQ()) goto loc_823FF3A0;
	// rlwinm. r11,r27,0,29,29
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x823ff3a0
	if (!cr0.getEQ()) goto loc_823FF3A0;
	// mr r31,r29
	r31.u64 = r29.u64;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// ble cr6,0x823ff3a0
	if (!cr6.getGT()) goto loc_823FF3A0;
loc_823FF378:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r3,48
	ctx.r3.s64 = 48;
	// addi r31,r31,-1
	r31.s64 = r31.s64 + -1;
	// bl 0x823f5218
	sub_823F5218(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// beq cr6,0x823ff3a0
	if (cr6.getEQ()) goto loc_823FF3A0;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bgt cr6,0x823ff378
	if (cr6.getGT()) goto loc_823FF378;
loc_823FF3A0:
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r16,0
	cr6.compare<int32_t>(r16.s32, 0, xer);
	// beq cr6,0x823ff414
	if (cr6.getEQ()) goto loc_823FF414;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// ble cr6,0x823ff414
	if (!cr6.getGT()) goto loc_823FF414;
	// mr r30,r28
	r30.u64 = r28.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
loc_823FF3BC:
	// li r5,6
	ctx.r5.s64 = 6;
	// lhz r6,0(r30)
	ctx.r6.u64 = PPC_LOAD_U16(r30.u32 + 0);
	// addi r4,r1,116
	ctx.r4.s64 = ctx.r1.s64 + 116;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// addi r31,r31,-1
	r31.s64 = r31.s64 + -1;
	// addi r30,r30,2
	r30.s64 = r30.s64 + 2;
	// bl 0x823fe8a0
	sub_823FE8A0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x823ff408
	if (!cr0.getEQ()) goto loc_823FF408;
	// lwz r4,112(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// beq cr6,0x823ff408
	if (cr6.getEQ()) goto loc_823FF408;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// addi r3,r1,116
	ctx.r3.s64 = ctx.r1.s64 + 116;
	// bl 0x823fe8c8
	sub_823FE8C8(ctx, base);
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x823ff3bc
	if (!cr6.getEQ()) goto loc_823FF3BC;
	// b 0x823ff424
	goto loc_823FF424;
loc_823FF408:
	// li r24,-1
	r24.s64 = -1;
	// stw r24,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r24.u32);
	// b 0x823ff428
	goto loc_823FF428;
loc_823FF414:
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x823fe8c8
	sub_823FE8C8(ctx, base);
loc_823FF424:
	// lwz r24,80(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_823FF428:
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// blt cr6,0x823ff46c
	if (cr6.getLT()) goto loc_823FF46C;
	// rlwinm. r11,r27,0,29,29
	r11.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ff46c
	if (cr0.getEQ()) goto loc_823FF46C;
	// mr r31,r29
	r31.u64 = r29.u64;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// ble cr6,0x823ff46c
	if (!cr6.getGT()) goto loc_823FF46C;
loc_823FF444:
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r3,32
	ctx.r3.s64 = 32;
	// addi r31,r31,-1
	r31.s64 = r31.s64 + -1;
	// bl 0x823f5218
	sub_823F5218(ctx, base);
	// lwz r24,80(r1)
	r24.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r24,-1
	cr6.compare<int32_t>(r24.s32, -1, xer);
	// beq cr6,0x823ff46c
	if (cr6.getEQ()) goto loc_823FF46C;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bgt cr6,0x823ff444
	if (cr6.getGT()) goto loc_823FF444;
loc_823FF46C:
	// cmplwi cr6,r15,0
	cr6.compare<uint32_t>(r15.u32, 0, xer);
	// beq cr6,0x823ff480
	if (cr6.getEQ()) goto loc_823FF480;
	// mr r3,r15
	ctx.r3.u64 = r15.u64;
	// bl 0x823ed250
	sub_823ED250(ctx, base);
	// li r15,0
	r15.s64 = 0;
loc_823FF480:
	// lbz r29,0(r19)
	r29.u64 = PPC_LOAD_U8(r19.u32 + 0);
	// extsb. r10,r29
	ctx.r10.s64 = r29.s8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823ff494
	if (cr0.getEQ()) goto loc_823FF494;
	// lwz r8,84(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// b 0x823feb0c
	goto loc_823FEB0C;
loc_823FF494:
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x823ff4a8
	if (cr6.getEQ()) goto loc_823FF4A8;
	// cmpwi cr6,r11,7
	cr6.compare<int32_t>(r11.s32, 7, xer);
	// bne cr6,0x823fe99c
	if (!cr6.getEQ()) goto loc_823FE99C;
loc_823FF4A8:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// b 0x823ff4e4
	goto loc_823FF4E4;
loc_823FF4B0:
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// mr r5,r19
	ctx.r5.u64 = r19.u64;
	// li r4,512
	ctx.r4.s64 = 512;
	// addi r3,r1,656
	ctx.r3.s64 = ctx.r1.s64 + 656;
	// bl 0x823eef48
	sub_823EEF48(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r31,-1
	cr6.compare<int32_t>(r31.s32, -1, xer);
	// bne cr6,0x823ff4d8
	if (!cr6.getEQ()) goto loc_823FF4D8;
	// li r31,511
	r31.s64 = 511;
	// stb r27,1167(r1)
	PPC_STORE_U8(ctx.r1.u32 + 1167, r27.u8);
loc_823FF4D8:
	// addi r3,r1,656
	ctx.r3.s64 = ctx.r1.s64 + 656;
	// bl 0x8235e140
	sub_8235E140(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_823FF4E4:
	// addi r1,r1,1328
	ctx.r1.s64 = ctx.r1.s64 + 1328;
	// b 0x823ed150
	return;
}

__attribute__((alias("__imp__sub_823FF4F0"))) PPC_WEAK_FUNC(sub_823FF4F0);
PPC_FUNC_IMPL(__imp__sub_823FF4F0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// std r4,80(r1)
	PPC_STORE_U64(ctx.r1.u32 + 80, ctx.r4.u64);
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// bl 0x824035c0
	sub_824035C0(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x823ff534
	if (!cr6.getEQ()) goto loc_823FF534;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x823ff598
	goto loc_823FF598;
loc_823FF534:
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// bl 0x8235ed68
	sub_8235ED68(ctx, base);
	// stw r3,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r3.u32);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x823ff568
	if (!cr6.getEQ()) goto loc_823FF568;
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x823ff568
	if (cr0.getEQ()) goto loc_823FF568;
	// bl 0x823f3e50
	sub_823F3E50(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x823ff598
	goto loc_823FF598;
loc_823FF568:
	// srawi r10,r31,5
	xer.ca = (r31.s32 < 0) & ((r31.u32 & 0x1F) != 0);
	ctx.r10.s64 = r31.s32 >> 5;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-15840
	r11.s64 = r11.s64 + -15840;
	// rlwinm r10,r31,6,21,25
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lbz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// rlwinm r10,r10,0,31,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFD;
	// stb r10,4(r11)
	PPC_STORE_U8(r11.u32 + 4, ctx.r10.u8);
	// ld r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
loc_823FF598:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FF5B0"))) PPC_WEAK_FUNC(sub_823FF5B0);
PPC_FUNC_IMPL(__imp__sub_823FF5B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r18{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// lwz r18,-1044(0)
	r18.u64 = PPC_LOAD_U32(-1044);
	// lwz r16,29832(r7)
	r16.u64 = PPC_LOAD_U32(ctx.r7.u32 + 29832);
	// mflr r12
	// bl 0x823ed128
	// addi r31,r1,-160
	r31.s64 = ctx.r1.s64 + -160;
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r30,180(r31)
	PPC_STORE_U32(r31.u32 + 180, r30.u32);
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// li r24,-1
	r24.s64 = -1;
	// std r24,80(r31)
	PPC_STORE_U64(r31.u32 + 80, r24.u64);
	// cmpwi cr6,r30,-2
	cr6.compare<int32_t>(r30.s32, -2, xer);
	// bne cr6,0x823ff60c
	if (!cr6.getEQ()) goto loc_823FF60C;
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x823ff6ec
	goto loc_823FF6EC;
loc_823FF60C:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x823ff624
	if (cr6.getLT()) goto loc_823FF624;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// lwz r11,-15860(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -15860);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x823ff660
	if (cr6.getLT()) goto loc_823FF660;
loc_823FF624:
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x823ff6ec
	goto loc_823FF6EC;
loc_823FF660:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// srawi r11,r30,5
	xer.ca = (r30.s32 < 0) & ((r30.u32 & 0x1F) != 0);
	r11.s64 = r30.s32 >> 5;
	// rlwinm r27,r11,2,0,29
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r30,6,21,25
	r28.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ff624
	if (cr0.getEQ()) goto loc_823FF624;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403690
	sub_82403690(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ff6c0
	if (cr0.getEQ()) goto loc_823FF6C0;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823ff4f0
	sub_823FF4F0(ctx, base);
	// std r3,80(r31)
	PPC_STORE_U64(r31.u32 + 80, ctx.r3.u64);
	// b 0x823ff6dc
	goto loc_823FF6DC;
loc_823FF6C0:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,9
	r11.s64 = 9;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// std r24,80(r31)
	PPC_STORE_U64(r31.u32 + 80, r24.u64);
loc_823FF6DC:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,160
	r12.s64 = r31.s64 + 160;
	// bl 0x823ff714
	sub_823FF714(ctx, base);
	// ld r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U64(r31.u32 + 80);
loc_823FF6EC:
	// addi r1,r31,160
	ctx.r1.s64 = r31.s64 + 160;
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_823FF5B8"))) PPC_WEAK_FUNC(sub_823FF5B8);
PPC_FUNC_IMPL(__imp__sub_823FF5B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// addi r31,r1,-160
	r31.s64 = ctx.r1.s64 + -160;
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r30,180(r31)
	PPC_STORE_U32(r31.u32 + 180, r30.u32);
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// li r24,-1
	r24.s64 = -1;
	// std r24,80(r31)
	PPC_STORE_U64(r31.u32 + 80, r24.u64);
	// cmpwi cr6,r30,-2
	cr6.compare<int32_t>(r30.s32, -2, xer);
	// bne cr6,0x823ff60c
	if (!cr6.getEQ()) goto loc_823FF60C;
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x823ff6ec
	goto loc_823FF6EC;
loc_823FF60C:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x823ff624
	if (cr6.getLT()) goto loc_823FF624;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// lwz r11,-15860(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -15860);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x823ff660
	if (cr6.getLT()) goto loc_823FF660;
loc_823FF624:
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x823ff6ec
	goto loc_823FF6EC;
loc_823FF660:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// srawi r11,r30,5
	xer.ca = (r30.s32 < 0) & ((r30.u32 & 0x1F) != 0);
	r11.s64 = r30.s32 >> 5;
	// rlwinm r27,r11,2,0,29
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r30,6,21,25
	r28.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ff624
	if (cr0.getEQ()) goto loc_823FF624;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403690
	sub_82403690(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ff6c0
	if (cr0.getEQ()) goto loc_823FF6C0;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823ff4f0
	sub_823FF4F0(ctx, base);
	// std r3,80(r31)
	PPC_STORE_U64(r31.u32 + 80, ctx.r3.u64);
	// b 0x823ff6dc
	goto loc_823FF6DC;
loc_823FF6C0:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,9
	r11.s64 = 9;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// std r24,80(r31)
	PPC_STORE_U64(r31.u32 + 80, r24.u64);
loc_823FF6DC:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,160
	r12.s64 = r31.s64 + 160;
	// bl 0x823ff714
	sub_823FF714(ctx, base);
	// ld r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U64(r31.u32 + 80);
loc_823FF6EC:
	// addi r1,r31,160
	ctx.r1.s64 = r31.s64 + 160;
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_823FF6F4"))) PPC_WEAK_FUNC(sub_823FF6F4);
PPC_FUNC_IMPL(__imp__sub_823FF6F4) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-160
	r31.s64 = r12.s64 + -160;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,180(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 180);
	// b 0x823ff72c
	goto loc_823FF72C;
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-160
	r31.s64 = r12.s64 + -160;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
loc_823FF72C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403788
	sub_82403788(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FF714"))) PPC_WEAK_FUNC(sub_823FF714);
PPC_FUNC_IMPL(__imp__sub_823FF714) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-160
	r31.s64 = r12.s64 + -160;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403788
	sub_82403788(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FF750"))) PPC_WEAK_FUNC(sub_823FF750);
PPC_FUNC_IMPL(__imp__sub_823FF750) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed11c
	// stwu r1,-1232(r1)
	ea = -1232 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r21,0
	r21.s64 = 0;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// mr r23,r21
	r23.u64 = r21.u64;
	// mr r22,r21
	r22.u64 = r21.u64;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x823ff780
	if (!cr6.getEQ()) goto loc_823FF780;
loc_823FF778:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x823ff998
	goto loc_823FF998;
loc_823FF780:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x823ff7c0
	if (!cr6.getEQ()) goto loc_823FF7C0;
loc_823FF788:
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// stw r21,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r21.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
loc_823FF7B8:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x823ff998
	goto loc_823FF998;
loc_823FF7C0:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// rlwinm r28,r3,6,21,25
	r28.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// rlwinm r27,r11,2,0,29
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r10,r11,r28
	ctx.r10.u64 = r11.u64 + r28.u64;
	// lbz r11,40(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 40);
	// rotlwi r11,r11,24
	r11.u64 = __builtin_rotateleft32(r11.u32, 24);
	// srawi r11,r11,25
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1FFFFFF) != 0);
	r11.s64 = r11.s32 >> 25;
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// beq cr6,0x823ff7fc
	if (cr6.getEQ()) goto loc_823FF7FC;
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x823ff808
	if (!cr6.getEQ()) goto loc_823FF808;
loc_823FF7FC:
	// not r11,r26
	r11.u64 = ~r26.u64;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ff788
	if (cr0.getEQ()) goto loc_823FF788;
loc_823FF808:
	// lbz r11,4(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 4);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ff820
	if (cr0.getEQ()) goto loc_823FF820;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x823ff4f0
	sub_823FF4F0(ctx, base);
loc_823FF820:
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// rlwinm. r10,r10,0,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFF80;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x823ff8e0
	if (cr0.getEQ()) goto loc_823FF8E0;
	// mr r25,r21
	r25.u64 = r21.u64;
	// mr r30,r24
	r30.u64 = r24.u64;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x823ff954
	if (cr6.getEQ()) goto loc_823FF954;
loc_823FF844:
	// addi r11,r1,96
	r11.s64 = ctx.r1.s64 + 96;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
	// subf r9,r24,r30
	ctx.r9.s64 = r30.s64 - r24.s64;
loc_823FF850:
	// cmplw cr6,r9,r26
	cr6.compare<uint32_t>(ctx.r9.u32, r26.u32, xer);
	// bge cr6,0x823ff894
	if (!cr6.getLT()) goto loc_823FF894;
	// lbz r8,0(r30)
	ctx.r8.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmplwi cr6,r8,10
	cr6.compare<uint32_t>(ctx.r8.u32, 10, xer);
	// bne cr6,0x823ff880
	if (!cr6.getEQ()) goto loc_823FF880;
	// li r7,13
	ctx.r7.s64 = 13;
	// addi r22,r22,1
	r22.s64 = r22.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stb r7,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r7.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
loc_823FF880:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stb r8,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r8.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r10,1024
	cr6.compare<uint32_t>(ctx.r10.u32, 1024, xer);
	// blt cr6,0x823ff850
	if (cr6.getLT()) goto loc_823FF850;
loc_823FF894:
	// addi r10,r1,96
	ctx.r10.s64 = ctx.r1.s64 + 96;
	// lwzx r9,r27,r29
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// subf r31,r10,r11
	r31.s64 = r11.s64 - ctx.r10.s64;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// addi r4,r1,96
	ctx.r4.s64 = ctx.r1.s64 + 96;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwzx r3,r9,r28
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + r28.u32);
	// bl 0x8235e018
	sub_8235E018(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x823ff90c
	if (cr0.getEQ()) goto loc_823FF90C;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// add r23,r11,r23
	r23.u64 = r11.u64 + r23.u64;
	// cmpw cr6,r11,r31
	cr6.compare<int32_t>(r11.s32, r31.s32, xer);
	// blt cr6,0x823ff914
	if (cr6.getLT()) goto loc_823FF914;
	// subf r11,r24,r30
	r11.s64 = r30.s64 - r24.s64;
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// blt cr6,0x823ff844
	if (cr6.getLT()) goto loc_823FF844;
	// b 0x823ff914
	goto loc_823FF914;
loc_823FF8E0:
	// li r7,0
	ctx.r7.s64 = 0;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
	// bl 0x8235e018
	sub_8235E018(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x823ff90c
	if (cr0.getEQ()) goto loc_823FF90C;
	// lwz r23,80(r1)
	r23.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// mr r25,r21
	r25.u64 = r21.u64;
	// b 0x823ff914
	goto loc_823FF914;
loc_823FF90C:
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
loc_823FF914:
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x823ff994
	if (!cr6.getEQ()) goto loc_823FF994;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x823ff954
	if (cr6.getEQ()) goto loc_823FF954;
	// cmplwi cr6,r25,5
	cr6.compare<uint32_t>(r25.u32, 5, xer);
	// bne cr6,0x823ff948
	if (!cr6.getEQ()) goto loc_823FF948;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,9
	r11.s64 = 9;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,5
	r11.s64 = 5;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// b 0x823ff7b8
	goto loc_823FF7B8;
loc_823FF948:
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x823f3e50
	sub_823F3E50(ctx, base);
	// b 0x823ff7b8
	goto loc_823FF7B8;
loc_823FF954:
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ff974
	if (cr0.getEQ()) goto loc_823FF974;
	// lbz r11,0(r24)
	r11.u64 = PPC_LOAD_U8(r24.u32 + 0);
	// cmplwi cr6,r11,26
	cr6.compare<uint32_t>(r11.u32, 26, xer);
	// beq cr6,0x823ff778
	if (cr6.getEQ()) goto loc_823FF778;
loc_823FF974:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,28
	r11.s64 = 28;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r21,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r21.u32);
	// b 0x823ff998
	goto loc_823FF998;
loc_823FF994:
	// subf r3,r22,r23
	ctx.r3.s64 = r23.s64 - r22.s64;
loc_823FF998:
	// addi r1,r1,1232
	ctx.r1.s64 = ctx.r1.s64 + 1232;
	// b 0x823ed16c
	return;
}

__attribute__((alias("__imp__sub_823FF9A0"))) PPC_WEAK_FUNC(sub_823FF9A0);
PPC_FUNC_IMPL(__imp__sub_823FF9A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r18{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// lwz r18,-1044(0)
	r18.u64 = PPC_LOAD_U32(-1044);
	// lwz r16,29856(r7)
	r16.u64 = PPC_LOAD_U32(ctx.r7.u32 + 29856);
	// mflr r12
	// bl 0x823ed12c
	// addi r31,r1,-160
	r31.s64 = ctx.r1.s64 + -160;
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r30,180(r31)
	PPC_STORE_U32(r31.u32 + 180, r30.u32);
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// cmpwi cr6,r30,-2
	cr6.compare<int32_t>(r30.s32, -2, xer);
	// bne cr6,0x823ff9f4
	if (!cr6.getEQ()) goto loc_823FF9F4;
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x823ffad8
	goto loc_823FFAD8;
loc_823FF9F4:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x823ffa0c
	if (cr6.getLT()) goto loc_823FFA0C;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// lwz r11,-15860(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -15860);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x823ffa48
	if (cr6.getLT()) goto loc_823FFA48;
loc_823FFA0C:
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x823ffad8
	goto loc_823FFAD8;
loc_823FFA48:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// srawi r11,r30,5
	xer.ca = (r30.s32 < 0) & ((r30.u32 & 0x1F) != 0);
	r11.s64 = r30.s32 >> 5;
	// rlwinm r27,r11,2,0,29
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r30,6,21,25
	r28.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ffa0c
	if (cr0.getEQ()) goto loc_823FFA0C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403690
	sub_82403690(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ffaa8
	if (cr0.getEQ()) goto loc_823FFAA8;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823ff750
	sub_823FF750(ctx, base);
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// b 0x823ffac8
	goto loc_823FFAC8;
loc_823FFAA8:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,9
	r11.s64 = 9;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// li r11,-1
	r11.s64 = -1;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
loc_823FFAC8:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,160
	r12.s64 = r31.s64 + 160;
	// bl 0x823ffb00
	sub_823FFB00(ctx, base);
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
loc_823FFAD8:
	// addi r1,r31,160
	ctx.r1.s64 = r31.s64 + 160;
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_823FF9A8"))) PPC_WEAK_FUNC(sub_823FF9A8);
PPC_FUNC_IMPL(__imp__sub_823FF9A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed12c
	// addi r31,r1,-160
	r31.s64 = ctx.r1.s64 + -160;
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r30,180(r31)
	PPC_STORE_U32(r31.u32 + 180, r30.u32);
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// cmpwi cr6,r30,-2
	cr6.compare<int32_t>(r30.s32, -2, xer);
	// bne cr6,0x823ff9f4
	if (!cr6.getEQ()) goto loc_823FF9F4;
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x823ffad8
	goto loc_823FFAD8;
loc_823FF9F4:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x823ffa0c
	if (cr6.getLT()) goto loc_823FFA0C;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// lwz r11,-15860(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -15860);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x823ffa48
	if (cr6.getLT()) goto loc_823FFA48;
loc_823FFA0C:
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x823ffad8
	goto loc_823FFAD8;
loc_823FFA48:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// srawi r11,r30,5
	xer.ca = (r30.s32 < 0) & ((r30.u32 & 0x1F) != 0);
	r11.s64 = r30.s32 >> 5;
	// rlwinm r27,r11,2,0,29
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r30,6,21,25
	r28.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ffa0c
	if (cr0.getEQ()) goto loc_823FFA0C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403690
	sub_82403690(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ffaa8
	if (cr0.getEQ()) goto loc_823FFAA8;
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823ff750
	sub_823FF750(ctx, base);
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// b 0x823ffac8
	goto loc_823FFAC8;
loc_823FFAA8:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,9
	r11.s64 = 9;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// li r11,-1
	r11.s64 = -1;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
loc_823FFAC8:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,160
	r12.s64 = r31.s64 + 160;
	// bl 0x823ffb00
	sub_823FFB00(ctx, base);
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
loc_823FFAD8:
	// addi r1,r31,160
	ctx.r1.s64 = r31.s64 + 160;
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_823FFAE0"))) PPC_WEAK_FUNC(sub_823FFAE0);
PPC_FUNC_IMPL(__imp__sub_823FFAE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-160
	r31.s64 = r12.s64 + -160;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,180(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 180);
	// b 0x823ffb18
	goto loc_823FFB18;
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-160
	r31.s64 = r12.s64 + -160;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
loc_823FFB18:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403788
	sub_82403788(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FFB00"))) PPC_WEAK_FUNC(sub_823FFB00);
PPC_FUNC_IMPL(__imp__sub_823FFB00) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-160
	r31.s64 = r12.s64 + -160;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403788
	sub_82403788(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FFB38"))) PPC_WEAK_FUNC(sub_823FFB38);
PPC_FUNC_IMPL(__imp__sub_823FFB38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,4096
	ctx.r3.s64 = 4096;
	// lwz r10,-20076(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + -20076);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,-20076(r11)
	PPC_STORE_U32(r11.u32 + -20076, ctx.r10.u32);
	// bl 0x823ed2b0
	sub_823ED2B0(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r3.u32);
	// beq 0x823ffb84
	if (cr0.getEQ()) goto loc_823FFB84;
	// li r10,4096
	ctx.r10.s64 = 4096;
	// ori r11,r11,8
	r11.u64 = r11.u64 | 8;
	// stw r10,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r10.u32);
	// b 0x823ffb98
	goto loc_823FFB98;
loc_823FFB84:
	// addi r10,r31,20
	ctx.r10.s64 = r31.s64 + 20;
	// li r9,2
	ctx.r9.s64 = 2;
	// ori r11,r11,4
	r11.u64 = r11.u64 | 4;
	// stw r10,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r10.u32);
	// stw r9,24(r31)
	PPC_STORE_U32(r31.u32 + 24, ctx.r9.u32);
loc_823FFB98:
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// li r10,0
	ctx.r10.s64 = 0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FFBC0"))) PPC_WEAK_FUNC(sub_823FFBC0);
PPC_FUNC_IMPL(__imp__sub_823FFBC0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// sth r27,166(r1)
	PPC_STORE_U16(ctx.r1.u32 + 166, r27.u16);
	// bl 0x823f4e20
	sub_823F4E20(ctx, base);
	// addi r11,r3,32
	r11.s64 = ctx.r3.s64 + 32;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// beq cr6,0x823ffe84
	if (cr6.getEQ()) goto loc_823FFE84;
	// bl 0x823f4e20
	sub_823F4E20(ctx, base);
	// addi r11,r3,64
	r11.s64 = ctx.r3.s64 + 64;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// beq cr6,0x823ffe84
	if (cr6.getEQ()) goto loc_823FFE84;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x823ffc70
	if (!cr0.getEQ()) goto loc_823FFC70;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lis r11,-31987
	r11.s64 = -2096300032;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// addi r30,r11,-15840
	r30.s64 = r11.s64 + -15840;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r28,r11,-18648
	r28.s64 = r11.s64 + -18648;
	// beq cr6,0x823ffc5c
	if (cr6.getEQ()) goto loc_823FFC5C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x823ffc5c
	if (cr6.getEQ()) goto loc_823FFC5C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r29,r11,2,0,29
	r29.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r29,r30
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + r30.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// b 0x823ffc60
	goto loc_823FFC60;
loc_823FFC5C:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_823FFC60:
	// lbz r11,40(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 40);
	// rlwinm r11,r11,0,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bne cr6,0x823ffcac
	if (!cr6.getEQ()) goto loc_823FFCAC;
loc_823FFC70:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addic. r11,r11,-2
	xer.ca = r11.u32 > 1;
	r11.s64 = r11.s64 + -2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// blt 0x823ffc98
	if (cr0.getLT()) goto loc_823FFC98;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// sth r27,0(r11)
	PPC_STORE_U16(r11.u32 + 0, r27.u16);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x823ffe98
	goto loc_823FFE98;
loc_823FFC98:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// clrlwi r3,r27,16
	ctx.r3.u64 = r27.u32 & 0xFFFF;
	// bl 0x824037b0
	sub_824037B0(ctx, base);
	// clrlwi r3,r3,16
	ctx.r3.u64 = ctx.r3.u32 & 0xFFFF;
	// b 0x823ffe9c
	goto loc_823FFE9C;
loc_823FFCAC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x823ffcf4
	if (cr6.getEQ()) goto loc_823FFCF4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x823ffcf4
	if (cr6.getEQ()) goto loc_823FFCF4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r29,r11,2,0,29
	r29.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r29,r30
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + r30.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// b 0x823ffcf8
	goto loc_823FFCF8;
loc_823FFCF4:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_823FFCF8:
	// lbz r11,40(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 40);
	// rlwinm r11,r11,0,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x823ffda4
	if (!cr6.getEQ()) goto loc_823FFDA4;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// blt 0x823ffd38
	if (cr0.getLT()) goto loc_823FFD38;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lbz r10,166(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 166);
	// stb r10,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r10.u8);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// lbz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// b 0x823ffd48
	goto loc_823FFD48;
loc_823FFD38:
	// lbz r11,166(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 166);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x823f5e28
	sub_823F5E28(ctx, base);
loc_823FFD48:
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x823ffd58
	if (!cr6.getEQ()) goto loc_823FFD58;
loc_823FFD50:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x823ffe9c
	goto loc_823FFE9C;
loc_823FFD58:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// blt 0x823ffd88
	if (cr0.getLT()) goto loc_823FFD88;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lbz r10,167(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 167);
	// stb r10,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r10.u8);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// lbz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// b 0x823ffd98
	goto loc_823FFD98;
loc_823FFD88:
	// lbz r11,167(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 167);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x823f5e28
	sub_823F5E28(ctx, base);
loc_823FFD98:
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x823ffe98
	if (!cr6.getEQ()) goto loc_823FFE98;
	// b 0x823ffd50
	goto loc_823FFD50;
loc_823FFDA4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x823ffdec
	if (cr6.getEQ()) goto loc_823FFDEC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x823ffdec
	if (cr6.getEQ()) goto loc_823FFDEC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r29,r11,2,0,29
	r29.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r29,r30
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + r30.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// b 0x823ffdf0
	goto loc_823FFDF0;
loc_823FFDEC:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_823FFDF0:
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// rlwinm. r11,r11,0,0,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x823ffc70
	if (cr0.getEQ()) goto loc_823FFC70;
	// mr r6,r27
	ctx.r6.u64 = r27.u64;
	// li r5,5
	ctx.r5.s64 = 5;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823fe8a0
	sub_823FE8A0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x823ffd50
	if (!cr0.getEQ()) goto loc_823FFD50;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// li r30,0
	r30.s64 = 0;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// ble cr6,0x823ffe98
	if (!cr6.getGT()) goto loc_823FFE98;
loc_823FFE28:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// addi r11,r1,84
	r11.s64 = ctx.r1.s64 + 84;
	// lbzx r11,r30,r11
	r11.u64 = PPC_LOAD_U8(r30.u32 + r11.u32);
	// blt 0x823ffe5c
	if (cr0.getLT()) goto loc_823FFE5C;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stb r11,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, r11.u8);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// lbz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// b 0x823ffe68
	goto loc_823FFE68;
loc_823FFE5C:
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x823f5e28
	sub_823F5E28(ctx, base);
loc_823FFE68:
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x823ffd50
	if (cr6.getEQ()) goto loc_823FFD50;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// cmpw cr6,r30,r11
	cr6.compare<int32_t>(r30.s32, r11.s32, xer);
	// blt cr6,0x823ffe28
	if (cr6.getLT()) goto loc_823FFE28;
	// b 0x823ffe98
	goto loc_823FFE98;
loc_823FFE84:
	// li r11,0
	r11.s64 = 0;
	// sth r27,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, r27.u16);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// sth r11,82(r1)
	PPC_STORE_U16(ctx.r1.u32 + 82, r11.u16);
	// bl 0x82408648
	sub_82408648(ctx, base);
loc_823FFE98:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
loc_823FFE9C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_823FFEA8"))) PPC_WEAK_FUNC(sub_823FFEA8);
PPC_FUNC_IMPL(__imp__sub_823FFEA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x823ffed4
	if (cr6.getEQ()) goto loc_823FFED4;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x823ffed4
	if (cr6.getEQ()) goto loc_823FFED4;
	// lbz r11,0(r4)
	r11.u64 = PPC_LOAD_U8(ctx.r4.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x823ffedc
	if (!cr0.getEQ()) goto loc_823FFEDC;
	// beq cr6,0x823ffed4
	if (cr6.getEQ()) goto loc_823FFED4;
	// li r11,0
	r11.s64 = 0;
	// sth r11,0(r3)
	PPC_STORE_U16(ctx.r3.u32 + 0, r11.u16);
loc_823FFED4:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
loc_823FFEDC:
	// beq cr6,0x823ffee8
	if (cr6.getEQ()) goto loc_823FFEE8;
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// sth r11,0(r3)
	PPC_STORE_U16(ctx.r3.u32 + 0, r11.u16);
loc_823FFEE8:
	// li r3,1
	ctx.r3.s64 = 1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FFEF0"))) PPC_WEAK_FUNC(sub_823FFEF0);
PPC_FUNC_IMPL(__imp__sub_823FFEF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// addi r11,r3,28
	r11.s64 = ctx.r3.s64 + 28;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,257
	ctx.r9.s64 = 257;
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
	// mtctr r9
	ctr.u64 = ctx.r9.u64;
loc_823FFF04:
	// stb r10,0(r8)
	PPC_STORE_U8(ctx.r8.u32 + 0, ctx.r10.u8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// bdnz 0x823fff04
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FFF04;
	// addi r9,r3,16
	ctx.r9.s64 = ctx.r3.s64 + 16;
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// stw r10,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, ctx.r10.u32);
	// stw r10,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, ctx.r10.u32);
	// li r8,6
	ctx.r8.s64 = 6;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
loc_823FFF30:
	// sth r7,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, ctx.r7.u16);
	// addi r10,r10,2
	ctx.r10.s64 = ctx.r10.s64 + 2;
	// bdnz 0x823fff30
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_823FFF30;
	// lis r10,-32015
	ctx.r10.s64 = -2098135040;
	// addi r9,r10,-18584
	ctx.r9.s64 = ctx.r10.s64 + -18584;
	// li r10,257
	ctx.r10.s64 = 257;
	// subf r9,r3,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r3.s64;
loc_823FFF4C:
	// lbzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + r11.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stb r8,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r8.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// bne 0x823fff4c
	if (!cr0.getEQ()) goto loc_823FFF4C;
	// addi r11,r3,285
	r11.s64 = ctx.r3.s64 + 285;
	// li r10,256
	ctx.r10.s64 = 256;
loc_823FFF68:
	// lbzx r8,r11,r9
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + ctx.r9.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stb r8,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r8.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// bne 0x823fff68
	if (!cr0.getEQ()) goto loc_823FFF68;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FFF80"))) PPC_WEAK_FUNC(sub_823FFF80);
PPC_FUNC_IMPL(__imp__sub_823FFF80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r6,-31987
	ctx.r6.s64 = -2096300032;
	// lwz r11,-15556(r6)
	r11.u64 = PPC_LOAD_U32(ctx.r6.u32 + -15556);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x823fffc8
	if (!cr6.getEQ()) goto loc_823FFFC8;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// lis r10,-31987
	ctx.r10.s64 = -2096300032;
	// lwz r3,-17520(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + -17520);
	// li r11,-3
	r11.s64 = -3;
	// stw r11,-16888(r10)
	PPC_STORE_U32(ctx.r10.u32 + -16888, r11.u32);
	// lis r10,-31987
	ctx.r10.s64 = -2096300032;
	// li r11,0
	r11.s64 = 0;
	// stw r11,-16904(r10)
	PPC_STORE_U32(ctx.r10.u32 + -16904, r11.u32);
	// bl 0x823ffef0
	sub_823FFEF0(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stw r11,-15556(r6)
	PPC_STORE_U32(ctx.r6.u32 + -15556, r11.u32);
loc_823FFFC8:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FFFE0"))) PPC_WEAK_FUNC(sub_823FFFE0);
PPC_FUNC_IMPL(__imp__sub_823FFFE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-31987
	r11.s64 = -2096300032;
	// lwz r3,-16868(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + -16868);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_823FFFF0"))) PPC_WEAK_FUNC(sub_823FFFF0);
PPC_FUNC_IMPL(__imp__sub_823FFFF0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r18{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// lwz r18,-1044(0)
	r18.u64 = PPC_LOAD_U32(-1044);
	// lwz r16,29880(r7)
	r16.u64 = PPC_LOAD_U32(ctx.r7.u32 + 29880);
	// mflr r12
	// bl 0x823ed130
	// addi r31,r1,-160
	r31.s64 = ctx.r1.s64 + -160;
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// stw r29,180(r31)
	PPC_STORE_U32(r31.u32 + 180, r29.u32);
	// li r26,0
	r26.s64 = 0;
	// mr r28,r26
	r28.u64 = r26.u64;
	// stw r28,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r28.u32);
	// mr r27,r26
	r27.u64 = r26.u64;
	// stw r27,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r27.u32);
	// cmpwi cr6,r29,11
	cr6.compare<int32_t>(r29.s32, 11, xer);
	// bgt cr6,0x824000d4
	if (cr6.getGT()) goto loc_824000D4;
	// beq cr6,0x82400050
	if (cr6.getEQ()) goto loc_82400050;
	// cmpwi cr6,r29,2
	cr6.compare<int32_t>(r29.s32, 2, xer);
	// beq cr6,0x82400068
	if (cr6.getEQ()) goto loc_82400068;
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// beq cr6,0x82400050
	if (cr6.getEQ()) goto loc_82400050;
	// cmpwi cr6,r29,6
	cr6.compare<int32_t>(r29.s32, 6, xer);
	// beq cr6,0x82400118
	if (cr6.getEQ()) goto loc_82400118;
	// cmpwi cr6,r29,8
	cr6.compare<int32_t>(r29.s32, 8, xer);
	// bne cr6,0x824000ec
	if (!cr6.getEQ()) goto loc_824000EC;
loc_82400050:
	// bl 0x823f28a8
	sub_823F28A8(ctx, base);
	// mr. r27,r3
	r27.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// stw r27,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r27.u32);
	// bne 0x82400078
	if (!cr0.getEQ()) goto loc_82400078;
loc_82400060:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82400294
	goto loc_82400294;
loc_82400068:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r30,r11,-16876
	r30.s64 = r11.s64 + -16876;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// b 0x82400150
	goto loc_82400150;
loc_82400078:
	// lwz r10,92(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 92);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// lis r9,-32015
	ctx.r9.s64 = -2098135040;
	// lwz r9,-18980(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + -18980);
loc_82400088:
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpw cr6,r8,r29
	cr6.compare<int32_t>(ctx.r8.s32, r29.s32, xer);
	// beq cr6,0x824000a8
	if (cr6.getEQ()) goto loc_824000A8;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// mulli r8,r9,12
	ctx.r8.s64 = ctx.r9.s64 * 12;
	// add r8,r8,r10
	ctx.r8.u64 = ctx.r8.u64 + ctx.r10.u64;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x82400088
	if (cr6.getLT()) goto loc_82400088;
loc_824000A8:
	// mulli r9,r9,12
	ctx.r9.s64 = ctx.r9.s64 * 12;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x824000c4
	if (!cr6.getLT()) goto loc_824000C4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpw cr6,r10,r29
	cr6.compare<int32_t>(ctx.r10.s32, r29.s32, xer);
	// beq cr6,0x824000c8
	if (cr6.getEQ()) goto loc_824000C8;
loc_824000C4:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_824000C8:
	// addi r30,r11,8
	r30.s64 = r11.s64 + 8;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// b 0x82400158
	goto loc_82400158;
loc_824000D4:
	// cmpwi cr6,r29,15
	cr6.compare<int32_t>(r29.s32, 15, xer);
	// beq cr6,0x82400140
	if (cr6.getEQ()) goto loc_82400140;
	// cmpwi cr6,r29,21
	cr6.compare<int32_t>(r29.s32, 21, xer);
	// beq cr6,0x8240012c
	if (cr6.getEQ()) goto loc_8240012C;
	// cmpwi cr6,r29,22
	cr6.compare<int32_t>(r29.s32, 22, xer);
	// beq cr6,0x82400118
	if (cr6.getEQ()) goto loc_82400118;
loc_824000EC:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// b 0x82400060
	goto loc_82400060;
loc_82400118:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r11,r11,-16876
	r11.s64 = r11.s64 + -16876;
	// addi r30,r11,8
	r30.s64 = r11.s64 + 8;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x82400150
	goto loc_82400150;
loc_8240012C:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r11,r11,-16876
	r11.s64 = r11.s64 + -16876;
	// addi r30,r11,4
	r30.s64 = r11.s64 + 4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// b 0x82400150
	goto loc_82400150;
loc_82400140:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r11,r11,-16876
	r11.s64 = r11.s64 + -16876;
	// addi r30,r11,12
	r30.s64 = r11.s64 + 12;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
loc_82400150:
	// li r28,1
	r28.s64 = 1;
	// stw r28,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r28.u32);
loc_82400158:
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x82400290
	if (cr6.getEQ()) goto loc_82400290;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82400174
	if (!cr6.getEQ()) goto loc_82400174;
	// li r3,3
	ctx.r3.s64 = 3;
	// bl 0x823ef820
	sub_823EF820(ctx, base);
loc_82400174:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x82400184
	if (cr6.getEQ()) goto loc_82400184;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x823f8040
	sub_823F8040(ctx, base);
loc_82400184:
	// nop 
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// cmpwi cr6,r29,8
	cr6.compare<int32_t>(r29.s32, 8, xer);
	// beq cr6,0x824001a4
	if (cr6.getEQ()) goto loc_824001A4;
	// cmpwi cr6,r29,11
	cr6.compare<int32_t>(r29.s32, 11, xer);
	// beq cr6,0x824001a4
	if (cr6.getEQ()) goto loc_824001A4;
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// bne cr6,0x824001c8
	if (!cr6.getEQ()) goto loc_824001C8;
loc_824001A4:
	// lwz r11,96(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 96);
	// stw r11,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r11.u32);
	// cmpwi cr6,r29,8
	cr6.compare<int32_t>(r29.s32, 8, xer);
	// stw r26,96(r27)
	PPC_STORE_U32(r27.u32 + 96, r26.u32);
	// bne cr6,0x82400218
	if (!cr6.getEQ()) goto loc_82400218;
	// li r11,140
	r11.s64 = 140;
	// lwz r10,100(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 100);
	// stw r10,100(r31)
	PPC_STORE_U32(r31.u32 + 100, ctx.r10.u32);
	// stw r11,100(r27)
	PPC_STORE_U32(r27.u32 + 100, r11.u32);
loc_824001C8:
	// cmpwi cr6,r29,8
	cr6.compare<int32_t>(r29.s32, 8, xer);
	// bne cr6,0x82400218
	if (!cr6.getEQ()) goto loc_82400218;
	// lis r8,-32015
	ctx.r8.s64 = -2098135040;
	// lwz r10,-18992(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18992);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// stw r11,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r11.u32);
	// lis r7,-32015
	ctx.r7.s64 = -2098135040;
loc_824001E4:
	// lwz r9,-18988(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + -18988);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bge cr6,0x8240021c
	if (!cr6.getLT()) goto loc_8240021C;
	// lwz r9,92(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 92);
	// mulli r10,r11,12
	ctx.r10.s64 = r11.s64 * 12;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r26,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r26.u32);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r11.u32);
	// lwz r10,-18992(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18992);
	// b 0x824001e4
	goto loc_824001E4;
loc_82400218:
	// stw r26,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r26.u32);
loc_8240021C:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,160
	r12.s64 = r31.s64 + 160;
	// bl 0x824002bc
	sub_824002BC(ctx, base);
	// lwz r30,180(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 180);
	// cmpwi cr6,r30,8
	cr6.compare<int32_t>(r30.s32, 8, xer);
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// bne cr6,0x82400250
	if (!cr6.getEQ()) goto loc_82400250;
	// lwz r29,88(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// lwz r4,100(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 100);
	// li r3,8
	ctx.r3.s64 = 8;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x82400260
	goto loc_82400260;
loc_82400250:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r29,88(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 88);
loc_82400260:
	// cmpwi cr6,r30,8
	cr6.compare<int32_t>(r30.s32, 8, xer);
	// beq cr6,0x82400278
	if (cr6.getEQ()) goto loc_82400278;
	// cmpwi cr6,r30,11
	cr6.compare<int32_t>(r30.s32, 11, xer);
	// beq cr6,0x82400278
	if (cr6.getEQ()) goto loc_82400278;
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// bne cr6,0x82400290
	if (!cr6.getEQ()) goto loc_82400290;
loc_82400278:
	// lwz r11,96(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// cmpwi cr6,r30,8
	cr6.compare<int32_t>(r30.s32, 8, xer);
	// stw r11,96(r29)
	PPC_STORE_U32(r29.u32 + 96, r11.u32);
	// bne cr6,0x82400290
	if (!cr6.getEQ()) goto loc_82400290;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// stw r11,100(r29)
	PPC_STORE_U32(r29.u32 + 100, r11.u32);
loc_82400290:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82400294:
	// addi r1,r31,160
	ctx.r1.s64 = r31.s64 + 160;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_823FFFF8"))) PPC_WEAK_FUNC(sub_823FFFF8);
PPC_FUNC_IMPL(__imp__sub_823FFFF8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// addi r31,r1,-160
	r31.s64 = ctx.r1.s64 + -160;
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// stw r29,180(r31)
	PPC_STORE_U32(r31.u32 + 180, r29.u32);
	// li r26,0
	r26.s64 = 0;
	// mr r28,r26
	r28.u64 = r26.u64;
	// stw r28,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r28.u32);
	// mr r27,r26
	r27.u64 = r26.u64;
	// stw r27,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r27.u32);
	// cmpwi cr6,r29,11
	cr6.compare<int32_t>(r29.s32, 11, xer);
	// bgt cr6,0x824000d4
	if (cr6.getGT()) goto loc_824000D4;
	// beq cr6,0x82400050
	if (cr6.getEQ()) goto loc_82400050;
	// cmpwi cr6,r29,2
	cr6.compare<int32_t>(r29.s32, 2, xer);
	// beq cr6,0x82400068
	if (cr6.getEQ()) goto loc_82400068;
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// beq cr6,0x82400050
	if (cr6.getEQ()) goto loc_82400050;
	// cmpwi cr6,r29,6
	cr6.compare<int32_t>(r29.s32, 6, xer);
	// beq cr6,0x82400118
	if (cr6.getEQ()) goto loc_82400118;
	// cmpwi cr6,r29,8
	cr6.compare<int32_t>(r29.s32, 8, xer);
	// bne cr6,0x824000ec
	if (!cr6.getEQ()) goto loc_824000EC;
loc_82400050:
	// bl 0x823f28a8
	sub_823F28A8(ctx, base);
	// mr. r27,r3
	r27.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// stw r27,88(r31)
	PPC_STORE_U32(r31.u32 + 88, r27.u32);
	// bne 0x82400078
	if (!cr0.getEQ()) goto loc_82400078;
loc_82400060:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82400294
	goto loc_82400294;
loc_82400068:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r30,r11,-16876
	r30.s64 = r11.s64 + -16876;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// b 0x82400150
	goto loc_82400150;
loc_82400078:
	// lwz r10,92(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 92);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// lis r9,-32015
	ctx.r9.s64 = -2098135040;
	// lwz r9,-18980(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + -18980);
loc_82400088:
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpw cr6,r8,r29
	cr6.compare<int32_t>(ctx.r8.s32, r29.s32, xer);
	// beq cr6,0x824000a8
	if (cr6.getEQ()) goto loc_824000A8;
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// mulli r8,r9,12
	ctx.r8.s64 = ctx.r9.s64 * 12;
	// add r8,r8,r10
	ctx.r8.u64 = ctx.r8.u64 + ctx.r10.u64;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x82400088
	if (cr6.getLT()) goto loc_82400088;
loc_824000A8:
	// mulli r9,r9,12
	ctx.r9.s64 = ctx.r9.s64 * 12;
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bge cr6,0x824000c4
	if (!cr6.getLT()) goto loc_824000C4;
	// lwz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// cmpw cr6,r10,r29
	cr6.compare<int32_t>(ctx.r10.s32, r29.s32, xer);
	// beq cr6,0x824000c8
	if (cr6.getEQ()) goto loc_824000C8;
loc_824000C4:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_824000C8:
	// addi r30,r11,8
	r30.s64 = r11.s64 + 8;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// b 0x82400158
	goto loc_82400158;
loc_824000D4:
	// cmpwi cr6,r29,15
	cr6.compare<int32_t>(r29.s32, 15, xer);
	// beq cr6,0x82400140
	if (cr6.getEQ()) goto loc_82400140;
	// cmpwi cr6,r29,21
	cr6.compare<int32_t>(r29.s32, 21, xer);
	// beq cr6,0x8240012c
	if (cr6.getEQ()) goto loc_8240012C;
	// cmpwi cr6,r29,22
	cr6.compare<int32_t>(r29.s32, 22, xer);
	// beq cr6,0x82400118
	if (cr6.getEQ()) goto loc_82400118;
loc_824000EC:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// b 0x82400060
	goto loc_82400060;
loc_82400118:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r11,r11,-16876
	r11.s64 = r11.s64 + -16876;
	// addi r30,r11,8
	r30.s64 = r11.s64 + 8;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// b 0x82400150
	goto loc_82400150;
loc_8240012C:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r11,r11,-16876
	r11.s64 = r11.s64 + -16876;
	// addi r30,r11,4
	r30.s64 = r11.s64 + 4;
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// b 0x82400150
	goto loc_82400150;
loc_82400140:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r11,r11,-16876
	r11.s64 = r11.s64 + -16876;
	// addi r30,r11,12
	r30.s64 = r11.s64 + 12;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
loc_82400150:
	// li r28,1
	r28.s64 = 1;
	// stw r28,84(r31)
	PPC_STORE_U32(r31.u32 + 84, r28.u32);
loc_82400158:
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x82400290
	if (cr6.getEQ()) goto loc_82400290;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82400174
	if (!cr6.getEQ()) goto loc_82400174;
	// li r3,3
	ctx.r3.s64 = 3;
	// bl 0x823ef820
	sub_823EF820(ctx, base);
loc_82400174:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x82400184
	if (cr6.getEQ()) goto loc_82400184;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x823f8040
	sub_823F8040(ctx, base);
loc_82400184:
	// nop 
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// cmpwi cr6,r29,8
	cr6.compare<int32_t>(r29.s32, 8, xer);
	// beq cr6,0x824001a4
	if (cr6.getEQ()) goto loc_824001A4;
	// cmpwi cr6,r29,11
	cr6.compare<int32_t>(r29.s32, 11, xer);
	// beq cr6,0x824001a4
	if (cr6.getEQ()) goto loc_824001A4;
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// bne cr6,0x824001c8
	if (!cr6.getEQ()) goto loc_824001C8;
loc_824001A4:
	// lwz r11,96(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 96);
	// stw r11,96(r31)
	PPC_STORE_U32(r31.u32 + 96, r11.u32);
	// cmpwi cr6,r29,8
	cr6.compare<int32_t>(r29.s32, 8, xer);
	// stw r26,96(r27)
	PPC_STORE_U32(r27.u32 + 96, r26.u32);
	// bne cr6,0x82400218
	if (!cr6.getEQ()) goto loc_82400218;
	// li r11,140
	r11.s64 = 140;
	// lwz r10,100(r27)
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + 100);
	// stw r10,100(r31)
	PPC_STORE_U32(r31.u32 + 100, ctx.r10.u32);
	// stw r11,100(r27)
	PPC_STORE_U32(r27.u32 + 100, r11.u32);
loc_824001C8:
	// cmpwi cr6,r29,8
	cr6.compare<int32_t>(r29.s32, 8, xer);
	// bne cr6,0x82400218
	if (!cr6.getEQ()) goto loc_82400218;
	// lis r8,-32015
	ctx.r8.s64 = -2098135040;
	// lwz r10,-18992(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18992);
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// stw r11,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r11.u32);
	// lis r7,-32015
	ctx.r7.s64 = -2098135040;
loc_824001E4:
	// lwz r9,-18988(r7)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r7.u32 + -18988);
	// add r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 + ctx.r10.u64;
	// cmpw cr6,r11,r10
	cr6.compare<int32_t>(r11.s32, ctx.r10.s32, xer);
	// bge cr6,0x8240021c
	if (!cr6.getLT()) goto loc_8240021C;
	// lwz r9,92(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + 92);
	// mulli r10,r11,12
	ctx.r10.s64 = r11.s64 * 12;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// stw r26,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r26.u32);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,92(r31)
	PPC_STORE_U32(r31.u32 + 92, r11.u32);
	// lwz r10,-18992(r8)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r8.u32 + -18992);
	// b 0x824001e4
	goto loc_824001E4;
loc_82400218:
	// stw r26,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r26.u32);
loc_8240021C:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,160
	r12.s64 = r31.s64 + 160;
	// bl 0x824002bc
	sub_824002BC(ctx, base);
	// lwz r30,180(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 180);
	// cmpwi cr6,r30,8
	cr6.compare<int32_t>(r30.s32, 8, xer);
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// bne cr6,0x82400250
	if (!cr6.getEQ()) goto loc_82400250;
	// lwz r29,88(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 88);
	// lwz r4,100(r29)
	ctx.r4.u64 = PPC_LOAD_U32(r29.u32 + 100);
	// li r3,8
	ctx.r3.s64 = 8;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// b 0x82400260
	goto loc_82400260;
loc_82400250:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lwz r29,88(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 88);
loc_82400260:
	// cmpwi cr6,r30,8
	cr6.compare<int32_t>(r30.s32, 8, xer);
	// beq cr6,0x82400278
	if (cr6.getEQ()) goto loc_82400278;
	// cmpwi cr6,r30,11
	cr6.compare<int32_t>(r30.s32, 11, xer);
	// beq cr6,0x82400278
	if (cr6.getEQ()) goto loc_82400278;
	// cmpwi cr6,r30,4
	cr6.compare<int32_t>(r30.s32, 4, xer);
	// bne cr6,0x82400290
	if (!cr6.getEQ()) goto loc_82400290;
loc_82400278:
	// lwz r11,96(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 96);
	// cmpwi cr6,r30,8
	cr6.compare<int32_t>(r30.s32, 8, xer);
	// stw r11,96(r29)
	PPC_STORE_U32(r29.u32 + 96, r11.u32);
	// bne cr6,0x82400290
	if (!cr6.getEQ()) goto loc_82400290;
	// lwz r11,100(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 100);
	// stw r11,100(r29)
	PPC_STORE_U32(r29.u32 + 100, r11.u32);
loc_82400290:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82400294:
	// addi r1,r31,160
	ctx.r1.s64 = r31.s64 + 160;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_8240029C"))) PPC_WEAK_FUNC(sub_8240029C);
PPC_FUNC_IMPL(__imp__sub_8240029C) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r12{};
	PPCRegister r28{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-160
	r31.s64 = r12.s64 + -160;
	// std r28,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r28.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r28,84(r31)
	r28.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// b 0x824002d4
	goto loc_824002D4;
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-160
	r31.s64 = r12.s64 + -160;
	// std r28,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r28.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
loc_824002D4:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x824002e4
	if (cr6.getEQ()) goto loc_824002E4;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x823f7ee0
	sub_823F7EE0(ctx, base);
loc_824002E4:
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r28,-16(r1)
	r28.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824002BC"))) PPC_WEAK_FUNC(sub_824002BC);
PPC_FUNC_IMPL(__imp__sub_824002BC) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r12{};
	PPCRegister r28{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-160
	r31.s64 = r12.s64 + -160;
	// std r28,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r28.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x824002e4
	if (cr6.getEQ()) goto loc_824002E4;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x823f7ee0
	sub_823F7EE0(ctx, base);
loc_824002E4:
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r28,-16(r1)
	r28.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82400300"))) PPC_WEAK_FUNC(sub_82400300);
PPC_FUNC_IMPL(__imp__sub_82400300) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	// mflr r12
	// bl 0x823ed114
	// lhz r10,10(r3)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r3.u32 + 10);
	// li r22,0
	r22.s64 = 0;
	// lhz r11,0(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 0);
	// rotlwi r10,r10,16
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 16);
	// lwz r9,2(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2);
	// rlwinm r19,r11,0,0,16
	r19.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF8000;
	// stw r10,-144(r1)
	PPC_STORE_U32(ctx.r1.u32 + -144, ctx.r10.u32);
	// clrlwi r10,r11,17
	ctx.r10.u64 = r11.u32 & 0x7FFF;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// stw r9,-152(r1)
	PPC_STORE_U32(ctx.r1.u32 + -152, ctx.r9.u32);
	// lwz r9,6(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 6);
	// addi r30,r10,-16383
	r30.s64 = ctx.r10.s64 + -16383;
	// addi r20,r11,-17312
	r20.s64 = r11.s64 + -17312;
	// cmpwi cr6,r30,-16383
	cr6.compare<int32_t>(r30.s32, -16383, xer);
	// stw r9,-148(r1)
	PPC_STORE_U32(ctx.r1.u32 + -148, ctx.r9.u32);
	// lwz r21,12(r20)
	r21.u64 = PPC_LOAD_U32(r20.u32 + 12);
	// bne cr6,0x82400390
	if (!cr6.getEQ()) goto loc_82400390;
	// mr r31,r22
	r31.u64 = r22.u64;
	// mr r11,r22
	r11.u64 = r22.u64;
	// addi r10,r1,-152
	ctx.r10.s64 = ctx.r1.s64 + -152;
loc_82400358:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82400378
	if (!cr6.getEQ()) goto loc_82400378;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82400358
	if (cr6.getLT()) goto loc_82400358;
	// b 0x824009c4
	goto loc_824009C4;
loc_82400378:
	// addi r11,r1,-152
	r11.s64 = ctx.r1.s64 + -152;
	// li r3,2
	ctx.r3.s64 = 2;
	// stw r22,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r22.u32);
	// stw r22,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r22.u32);
	// stw r22,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r22.u32);
	// b 0x824009c8
	goto loc_824009C8;
loc_82400390:
	// addi r11,r1,-152
	r11.s64 = ctx.r1.s64 + -152;
	// lwz r25,8(r20)
	r25.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// addi r10,r1,-136
	ctx.r10.s64 = ctx.r1.s64 + -136;
	// addi r26,r25,-1
	r26.s64 = r25.s64 + -1;
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r27,r1,-152
	r27.s64 = ctx.r1.s64 + -152;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r24,r30
	r24.u64 = r30.u64;
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// li r23,-1
	r23.s64 = -1;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// stw r11,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r11.u32);
	// addi r11,r26,1
	r11.s64 = r26.s64 + 1;
	// srawi r10,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	ctx.r10.s64 = r11.s32 >> 5;
	// addze r31,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	r31.s64 = temp.s64;
	// srawi r10,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	ctx.r10.s64 = r11.s32 >> 5;
	// rlwinm r28,r31,2,0,29
	r28.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// lwzx r10,r28,r27
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + r27.u32);
	// subfic r29,r11,31
	xer.ca = r11.u32 <= 31;
	r29.s64 = 31 - r11.s64;
	// slw r11,r3,r29
	r11.u64 = r29.u8 & 0x20 ? 0 : (ctx.r3.u32 << (r29.u8 & 0x3F));
	// and. r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824004e8
	if (cr0.getEQ()) goto loc_824004E8;
	// addi r11,r1,-152
	r11.s64 = ctx.r1.s64 + -152;
	// rlwinm r9,r31,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r10,r23,r29
	ctx.r10.u64 = r29.u8 & 0x20 ? 0 : (r23.u32 << (r29.u8 & 0x3F));
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// andc. r11,r11,r10
	r11.u64 = r11.u64 & ~ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82400450
	if (!cr0.getEQ()) goto loc_82400450;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x824004e8
	if (!cr6.getLT()) goto loc_824004E8;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
loc_82400430:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82400450
	if (!cr6.getEQ()) goto loc_82400450;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82400430
	if (cr6.getLT()) goto loc_82400430;
	// b 0x824004e8
	goto loc_824004E8;
loc_82400450:
	// srawi r11,r26,5
	xer.ca = (r26.s32 < 0) & ((r26.u32 & 0x1F) != 0);
	r11.s64 = r26.s32 >> 5;
	// addi r7,r1,-152
	ctx.r7.s64 = ctx.r1.s64 + -152;
	// addze r9,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	ctx.r9.s64 = temp.s64;
	// srawi r11,r26,5
	xer.ca = (r26.s32 < 0) & ((r26.u32 & 0x1F) != 0);
	r11.s64 = r26.s32 >> 5;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addze r11,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	r11.s64 = temp.s64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// rlwinm r11,r11,5,0,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// subf r11,r11,r26
	r11.s64 = r26.s64 - r11.s64;
	// subfic r11,r11,31
	xer.ca = r11.u32 <= 31;
	r11.s64 = 31 - r11.s64;
	// slw r6,r3,r11
	ctx.r6.u64 = r11.u8 & 0x20 ? 0 : (ctx.r3.u32 << (r11.u8 & 0x3F));
	// lwzx r11,r8,r7
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// add r10,r11,r6
	ctx.r10.u64 = r11.u64 + ctx.r6.u64;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x82400494
	if (cr6.getLT()) goto loc_82400494;
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// bge cr6,0x82400498
	if (!cr6.getLT()) goto loc_82400498;
loc_82400494:
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
loc_82400498:
	// addic. r11,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	r11.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stwx r10,r8,r7
	PPC_STORE_U32(ctx.r8.u32 + ctx.r7.u32, ctx.r10.u32);
	// blt 0x824004e8
	if (cr0.getLT()) goto loc_824004E8;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
loc_824004B0:
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq cr6,0x824004e8
	if (cr6.getEQ()) goto loc_824004E8;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// addi r8,r9,1
	ctx.r8.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x824004d4
	if (cr6.getLT()) goto loc_824004D4;
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// bge cr6,0x824004d8
	if (!cr6.getLT()) goto loc_824004D8;
loc_824004D4:
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
loc_824004D8:
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// bge 0x824004b0
	if (!cr0.getLT()) goto loc_824004B0;
loc_824004E8:
	// lwzx r10,r28,r27
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + r27.u32);
	// slw r9,r23,r29
	ctx.r9.u64 = r29.u8 & 0x20 ? 0 : (r23.u32 << (r29.u8 & 0x3F));
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// and r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 & ctx.r10.u64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// stwx r10,r28,r27
	PPC_STORE_U32(r28.u32 + r27.u32, ctx.r10.u32);
	// bge cr6,0x82400530
	if (!cr6.getLT()) goto loc_82400530;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// subfic r11,r11,3
	xer.ca = r11.u32 <= 3;
	r11.s64 = 3 - r11.s64;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82400530
	if (cr0.getEQ()) goto loc_82400530;
	// mtctr r11
	ctr.u64 = r11.u64;
loc_82400524:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x82400524
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400524;
loc_82400530:
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq cr6,0x8240053c
	if (cr6.getEQ()) goto loc_8240053C;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
loc_8240053C:
	// lwz r11,4(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 4);
	// subf r10,r25,r11
	ctx.r10.s64 = r11.s64 - r25.s64;
	// cmpw cr6,r30,r10
	cr6.compare<int32_t>(r30.s32, ctx.r10.s32, xer);
	// bge cr6,0x82400568
	if (!cr6.getLT()) goto loc_82400568;
	// addi r11,r1,-152
	r11.s64 = ctx.r1.s64 + -152;
	// mr r31,r22
	r31.u64 = r22.u64;
	// li r3,2
	ctx.r3.s64 = 2;
	// stw r22,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r22.u32);
	// stw r22,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r22.u32);
	// stw r22,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r22.u32);
	// b 0x824009c8
	goto loc_824009C8;
loc_82400568:
	// cmpw cr6,r30,r11
	cr6.compare<int32_t>(r30.s32, r11.s32, xer);
	// bgt cr6,0x82400844
	if (cr6.getGT()) goto loc_82400844;
	// subf r11,r24,r11
	r11.s64 = r11.s64 - r24.s64;
	// addi r10,r1,-136
	ctx.r10.s64 = ctx.r1.s64 + -136;
	// srawi r5,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	ctx.r5.s64 = r11.s32 >> 5;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// addze r31,r5
	temp.s64 = ctx.r5.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r5.u32;
	r31.s64 = temp.s64;
	// srawi r29,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	r29.s64 = r11.s32 >> 5;
	// lwz r30,0(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// li r27,-1
	r27.s64 = -1;
	// addze r29,r29
	temp.s64 = r29.s64 + xer.ca;
	xer.ca = temp.u32 < r29.u32;
	r29.s64 = temp.s64;
	// lwz r5,4(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r8,r1,-152
	ctx.r8.s64 = ctx.r1.s64 + -152;
	// li r7,3
	ctx.r7.s64 = 3;
	// stw r30,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r30.u32);
	// rlwinm r30,r29,5,0,26
	r30.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 5) & 0xFFFFFFE0;
	// stw r5,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r5.u32);
	// subf r11,r30,r11
	r11.s64 = r11.s64 - r30.s64;
	// stw r10,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, ctx.r10.u32);
	// subfic r10,r11,32
	xer.ca = r11.u32 <= 32;
	ctx.r10.s64 = 32 - r11.s64;
	// slw r9,r27,r11
	ctx.r9.u64 = r11.u8 & 0x20 ? 0 : (r27.u32 << (r11.u8 & 0x3F));
	// not r9,r9
	ctx.r9.u64 = ~ctx.r9.u64;
loc_824005C8:
	// lwz r5,0(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// and r30,r5,r9
	r30.u64 = ctx.r5.u64 & ctx.r9.u64;
	// stw r30,-160(r1)
	PPC_STORE_U32(ctx.r1.u32 + -160, r30.u32);
	// srw r5,r5,r11
	ctx.r5.u64 = r11.u8 & 0x20 ? 0 : (ctx.r5.u32 >> (r11.u8 & 0x3F));
	// or r6,r5,r6
	ctx.r6.u64 = ctx.r5.u64 | ctx.r6.u64;
	// stw r6,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r6.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// lwz r6,-160(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + -160);
	// slw r6,r6,r10
	ctx.r6.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r10.u8 & 0x3F));
	// bne 0x824005c8
	if (!cr0.getEQ()) goto loc_824005C8;
	// rlwinm r9,r31,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,-144
	ctx.r8.s64 = ctx.r1.s64 + -144;
	// li r10,2
	ctx.r10.s64 = 2;
	// addi r11,r1,-144
	r11.s64 = ctx.r1.s64 + -144;
	// subf r9,r9,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r9.s64;
loc_82400608:
	// cmpw cr6,r10,r31
	cr6.compare<int32_t>(ctx.r10.s32, r31.s32, xer);
	// blt cr6,0x8240061c
	if (cr6.getLT()) goto loc_8240061C;
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// b 0x82400620
	goto loc_82400620;
loc_8240061C:
	// stw r22,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r22.u32);
loc_82400620:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// bge 0x82400608
	if (!cr0.getLT()) goto loc_82400608;
	// addi r11,r26,1
	r11.s64 = r26.s64 + 1;
	// addi r28,r1,-152
	r28.s64 = ctx.r1.s64 + -152;
	// srawi r10,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	ctx.r10.s64 = r11.s32 >> 5;
	// addze r31,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	r31.s64 = temp.s64;
	// srawi r10,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	ctx.r10.s64 = r11.s32 >> 5;
	// rlwinm r29,r31,2,0,29
	r29.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// lwzx r10,r29,r28
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + r28.u32);
	// subfic r30,r11,31
	xer.ca = r11.u32 <= 31;
	r30.s64 = 31 - r11.s64;
	// slw r11,r3,r30
	r11.u64 = r30.u8 & 0x20 ? 0 : (ctx.r3.u32 << (r30.u8 & 0x3F));
	// and. r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82400754
	if (cr0.getEQ()) goto loc_82400754;
	// addi r11,r1,-152
	r11.s64 = ctx.r1.s64 + -152;
	// rlwinm r9,r31,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r10,r23,r30
	ctx.r10.u64 = r30.u8 & 0x20 ? 0 : (r23.u32 << (r30.u8 & 0x3F));
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// andc. r11,r11,r10
	r11.u64 = r11.u64 & ~ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824006b8
	if (!cr0.getEQ()) goto loc_824006B8;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82400754
	if (!cr6.getLT()) goto loc_82400754;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
loc_82400698:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x824006b8
	if (!cr6.getEQ()) goto loc_824006B8;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82400698
	if (cr6.getLT()) goto loc_82400698;
	// b 0x82400754
	goto loc_82400754;
loc_824006B8:
	// srawi r11,r26,5
	xer.ca = (r26.s32 < 0) & ((r26.u32 & 0x1F) != 0);
	r11.s64 = r26.s32 >> 5;
	// addi r7,r1,-152
	ctx.r7.s64 = ctx.r1.s64 + -152;
	// addze r9,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	ctx.r9.s64 = temp.s64;
	// srawi r11,r26,5
	xer.ca = (r26.s32 < 0) & ((r26.u32 & 0x1F) != 0);
	r11.s64 = r26.s32 >> 5;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addze r11,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	r11.s64 = temp.s64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// rlwinm r11,r11,5,0,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// subf r11,r11,r26
	r11.s64 = r26.s64 - r11.s64;
	// subfic r11,r11,31
	xer.ca = r11.u32 <= 31;
	r11.s64 = 31 - r11.s64;
	// slw r6,r3,r11
	ctx.r6.u64 = r11.u8 & 0x20 ? 0 : (ctx.r3.u32 << (r11.u8 & 0x3F));
	// lwzx r11,r8,r7
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// add r10,r11,r6
	ctx.r10.u64 = r11.u64 + ctx.r6.u64;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x824006fc
	if (cr6.getLT()) goto loc_824006FC;
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// bge cr6,0x82400700
	if (!cr6.getLT()) goto loc_82400700;
loc_824006FC:
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
loc_82400700:
	// addic. r11,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	r11.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stwx r10,r8,r7
	PPC_STORE_U32(ctx.r8.u32 + ctx.r7.u32, ctx.r10.u32);
	// blt 0x82400754
	if (cr0.getLT()) goto loc_82400754;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
loc_82400718:
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq cr6,0x82400754
	if (cr6.getEQ()) goto loc_82400754;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// addi r8,r9,1
	ctx.r8.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x8240073c
	if (cr6.getLT()) goto loc_8240073C;
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// bge cr6,0x82400740
	if (!cr6.getLT()) goto loc_82400740;
loc_8240073C:
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
loc_82400740:
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// bge 0x82400718
	if (!cr0.getLT()) goto loc_82400718;
loc_82400754:
	// lwzx r10,r29,r28
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + r28.u32);
	// slw r9,r23,r30
	ctx.r9.u64 = r30.u8 & 0x20 ? 0 : (r23.u32 << (r30.u8 & 0x3F));
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// and r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 & ctx.r10.u64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// stwx r10,r29,r28
	PPC_STORE_U32(r29.u32 + r28.u32, ctx.r10.u32);
	// bge cr6,0x8240079c
	if (!cr6.getLT()) goto loc_8240079C;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// subfic r11,r11,3
	xer.ca = r11.u32 <= 3;
	r11.s64 = 3 - r11.s64;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8240079c
	if (cr0.getEQ()) goto loc_8240079C;
	// mtctr r11
	ctr.u64 = r11.u64;
loc_82400790:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x82400790
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400790;
loc_8240079C:
	// addi r11,r21,1
	r11.s64 = r21.s64 + 1;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// srawi r7,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	ctx.r7.s64 = r11.s32 >> 5;
	// addi r10,r1,-152
	ctx.r10.s64 = ctx.r1.s64 + -152;
	// addze r3,r7
	temp.s64 = ctx.r7.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r7.u32;
	ctx.r3.s64 = temp.s64;
	// srawi r7,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	ctx.r7.s64 = r11.s32 >> 5;
	// li r9,3
	ctx.r9.s64 = 3;
	// addze r7,r7
	temp.s64 = ctx.r7.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r7.u32;
	ctx.r7.s64 = temp.s64;
	// rlwinm r7,r7,5,0,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// subf r11,r7,r11
	r11.s64 = r11.s64 - ctx.r7.s64;
	// subfic r6,r11,32
	xer.ca = r11.u32 <= 32;
	ctx.r6.s64 = 32 - r11.s64;
	// slw r7,r27,r11
	ctx.r7.u64 = r11.u8 & 0x20 ? 0 : (r27.u32 << (r11.u8 & 0x3F));
	// not r5,r7
	ctx.r5.u64 = ~ctx.r7.u64;
loc_824007D0:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// and r31,r7,r5
	r31.u64 = ctx.r7.u64 & ctx.r5.u64;
	// stw r31,-160(r1)
	PPC_STORE_U32(ctx.r1.u32 + -160, r31.u32);
	// srw r7,r7,r11
	ctx.r7.u64 = r11.u8 & 0x20 ? 0 : (ctx.r7.u32 >> (r11.u8 & 0x3F));
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r8,-160(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + -160);
	// slw r8,r8,r6
	ctx.r8.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r6.u8 & 0x3F));
	// bne 0x824007d0
	if (!cr0.getEQ()) goto loc_824007D0;
	// rlwinm r9,r3,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,-144
	ctx.r8.s64 = ctx.r1.s64 + -144;
	// li r10,2
	ctx.r10.s64 = 2;
	// addi r11,r1,-144
	r11.s64 = ctx.r1.s64 + -144;
	// subf r9,r9,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r9.s64;
loc_82400810:
	// cmpw cr6,r10,r3
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r3.s32, xer);
	// blt cr6,0x82400824
	if (cr6.getLT()) goto loc_82400824;
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// b 0x82400828
	goto loc_82400828;
loc_82400824:
	// stw r22,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r22.u32);
loc_82400828:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// bge 0x82400810
	if (!cr0.getLT()) goto loc_82400810;
	// mr r31,r22
	r31.u64 = r22.u64;
	// li r3,2
	ctx.r3.s64 = 2;
	// b 0x824009c8
	goto loc_824009C8;
loc_82400844:
	// lwz r29,0(r20)
	r29.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// cmpw cr6,r30,r29
	cr6.compare<int32_t>(r30.s32, r29.s32, xer);
	// blt cr6,0x82400914
	if (cr6.getLT()) goto loc_82400914;
	// srawi r10,r21,5
	xer.ca = (r21.s32 < 0) & ((r21.u32 & 0x1F) != 0);
	ctx.r10.s64 = r21.s32 >> 5;
	// addi r11,r1,-152
	r11.s64 = ctx.r1.s64 + -152;
	// addze r31,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	r31.s64 = temp.s64;
	// srawi r10,r21,5
	xer.ca = (r21.s32 < 0) & ((r21.u32 & 0x1F) != 0);
	ctx.r10.s64 = r21.s32 >> 5;
	// li r6,-1
	ctx.r6.s64 = -1;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// stw r22,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r22.u32);
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// stw r22,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r22.u32);
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// stw r22,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r22.u32);
	// lwz r11,-152(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -152);
	// subf r10,r10,r21
	ctx.r10.s64 = r21.s64 - ctx.r10.s64;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// oris r11,r11,32768
	r11.u64 = r11.u64 | 2147483648;
	// li r8,3
	ctx.r8.s64 = 3;
	// stw r11,-152(r1)
	PPC_STORE_U32(ctx.r1.u32 + -152, r11.u32);
	// slw r11,r6,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r10.u8 & 0x3F));
	// subfic r6,r10,32
	xer.ca = ctx.r10.u32 <= 32;
	ctx.r6.s64 = 32 - ctx.r10.s64;
	// not r5,r11
	ctx.r5.u64 = ~r11.u64;
loc_824008A0:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// and r30,r11,r5
	r30.u64 = r11.u64 & ctx.r5.u64;
	// stw r30,-160(r1)
	PPC_STORE_U32(ctx.r1.u32 + -160, r30.u32);
	// srw r11,r11,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r10.u8 & 0x3F));
	// or r11,r11,r7
	r11.u64 = r11.u64 | ctx.r7.u64;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lwz r11,-160(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -160);
	// slw r7,r11,r6
	ctx.r7.u64 = ctx.r6.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r6.u8 & 0x3F));
	// bne 0x824008a0
	if (!cr0.getEQ()) goto loc_824008A0;
	// rlwinm r9,r31,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,-144
	ctx.r8.s64 = ctx.r1.s64 + -144;
	// li r10,2
	ctx.r10.s64 = 2;
	// addi r11,r1,-144
	r11.s64 = ctx.r1.s64 + -144;
	// subf r9,r9,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r9.s64;
loc_824008E0:
	// cmpw cr6,r10,r31
	cr6.compare<int32_t>(ctx.r10.s32, r31.s32, xer);
	// blt cr6,0x824008f4
	if (cr6.getLT()) goto loc_824008F4;
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// b 0x824008f8
	goto loc_824008F8;
loc_824008F4:
	// stw r22,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r22.u32);
loc_824008F8:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// bge 0x824008e0
	if (!cr0.getLT()) goto loc_824008E0;
	// lwz r11,20(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 20);
	// add r31,r11,r29
	r31.u64 = r11.u64 + r29.u64;
	// b 0x824009c8
	goto loc_824009C8;
loc_82400914:
	// srawi r11,r21,5
	xer.ca = (r21.s32 < 0) & ((r21.u32 & 0x1F) != 0);
	r11.s64 = r21.s32 >> 5;
	// li r7,-1
	ctx.r7.s64 = -1;
	// addze r3,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	ctx.r3.s64 = temp.s64;
	// lwz r11,20(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 20);
	// srawi r10,r21,5
	xer.ca = (r21.s32 < 0) & ((r21.u32 & 0x1F) != 0);
	ctx.r10.s64 = r21.s32 >> 5;
	// add r31,r11,r30
	r31.u64 = r11.u64 + r30.u64;
	// addze r11,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	r11.s64 = temp.s64;
	// lwz r10,-152(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -152);
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// rlwinm r11,r11,5,0,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// clrlwi r10,r10,1
	ctx.r10.u64 = ctx.r10.u32 & 0x7FFFFFFF;
	// subf r11,r11,r21
	r11.s64 = r21.s64 - r11.s64;
	// li r9,3
	ctx.r9.s64 = 3;
	// subfic r6,r11,32
	xer.ca = r11.u32 <= 32;
	ctx.r6.s64 = 32 - r11.s64;
	// stw r10,-152(r1)
	PPC_STORE_U32(ctx.r1.u32 + -152, ctx.r10.u32);
	// addi r10,r1,-152
	ctx.r10.s64 = ctx.r1.s64 + -152;
	// slw r7,r7,r11
	ctx.r7.u64 = r11.u8 & 0x20 ? 0 : (ctx.r7.u32 << (r11.u8 & 0x3F));
	// not r5,r7
	ctx.r5.u64 = ~ctx.r7.u64;
loc_8240095C:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// and r30,r7,r5
	r30.u64 = ctx.r7.u64 & ctx.r5.u64;
	// stw r30,-160(r1)
	PPC_STORE_U32(ctx.r1.u32 + -160, r30.u32);
	// srw r7,r7,r11
	ctx.r7.u64 = r11.u8 & 0x20 ? 0 : (ctx.r7.u32 >> (r11.u8 & 0x3F));
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r8,-160(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + -160);
	// slw r8,r8,r6
	ctx.r8.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r6.u8 & 0x3F));
	// bne 0x8240095c
	if (!cr0.getEQ()) goto loc_8240095C;
	// rlwinm r9,r3,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,-144
	ctx.r8.s64 = ctx.r1.s64 + -144;
	// li r10,2
	ctx.r10.s64 = 2;
	// addi r11,r1,-144
	r11.s64 = ctx.r1.s64 + -144;
	// subf r9,r9,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r9.s64;
loc_8240099C:
	// cmpw cr6,r10,r3
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r3.s32, xer);
	// blt cr6,0x824009b0
	if (cr6.getLT()) goto loc_824009B0;
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// b 0x824009b4
	goto loc_824009B4;
loc_824009B0:
	// stw r22,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r22.u32);
loc_824009B4:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// bge 0x8240099c
	if (!cr0.getLT()) goto loc_8240099C;
loc_824009C4:
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
loc_824009C8:
	// subfic r11,r21,31
	xer.ca = r21.u32 <= 31;
	r11.s64 = 31 - r21.s64;
	// cmpwi cr6,r19,0
	cr6.compare<int32_t>(r19.s32, 0, xer);
	// lis r10,-32768
	ctx.r10.s64 = -2147483648;
	// bne cr6,0x824009dc
	if (!cr6.getEQ()) goto loc_824009DC;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
loc_824009DC:
	// slw r9,r31,r11
	ctx.r9.u64 = r11.u8 & 0x20 ? 0 : (r31.u32 << (r11.u8 & 0x3F));
	// lwz r11,16(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 16);
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// lwz r9,-152(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -152);
	// cmpwi cr6,r11,64
	cr6.compare<int32_t>(r11.s32, 64, xer);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// bne cr6,0x82400a04
	if (!cr6.getEQ()) goto loc_82400A04;
	// lwz r11,-148(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -148);
	// stw r11,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, r11.u32);
	// b 0x82400a0c
	goto loc_82400A0C;
loc_82400A04:
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// bne cr6,0x82400a10
	if (!cr6.getEQ()) goto loc_82400A10;
loc_82400A0C:
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
loc_82400A10:
	// b 0x823ed164
	return;
}

__attribute__((alias("__imp__sub_82400A18"))) PPC_WEAK_FUNC(sub_82400A18);
PPC_FUNC_IMPL(__imp__sub_82400A18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	// mflr r12
	// bl 0x823ed114
	// lhz r10,10(r3)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r3.u32 + 10);
	// li r22,0
	r22.s64 = 0;
	// lhz r11,0(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 0);
	// rotlwi r10,r10,16
	ctx.r10.u64 = __builtin_rotateleft32(ctx.r10.u32, 16);
	// lwz r9,2(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 2);
	// rlwinm r19,r11,0,0,16
	r19.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFF8000;
	// stw r10,-144(r1)
	PPC_STORE_U32(ctx.r1.u32 + -144, ctx.r10.u32);
	// clrlwi r10,r11,17
	ctx.r10.u64 = r11.u32 & 0x7FFF;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// stw r9,-152(r1)
	PPC_STORE_U32(ctx.r1.u32 + -152, ctx.r9.u32);
	// lwz r9,6(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 6);
	// addi r30,r10,-16383
	r30.s64 = ctx.r10.s64 + -16383;
	// addi r20,r11,-17288
	r20.s64 = r11.s64 + -17288;
	// cmpwi cr6,r30,-16383
	cr6.compare<int32_t>(r30.s32, -16383, xer);
	// stw r9,-148(r1)
	PPC_STORE_U32(ctx.r1.u32 + -148, ctx.r9.u32);
	// lwz r21,12(r20)
	r21.u64 = PPC_LOAD_U32(r20.u32 + 12);
	// bne cr6,0x82400aa8
	if (!cr6.getEQ()) goto loc_82400AA8;
	// mr r31,r22
	r31.u64 = r22.u64;
	// mr r11,r22
	r11.u64 = r22.u64;
	// addi r10,r1,-152
	ctx.r10.s64 = ctx.r1.s64 + -152;
loc_82400A70:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82400a90
	if (!cr6.getEQ()) goto loc_82400A90;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82400a70
	if (cr6.getLT()) goto loc_82400A70;
	// b 0x824010dc
	goto loc_824010DC;
loc_82400A90:
	// addi r11,r1,-152
	r11.s64 = ctx.r1.s64 + -152;
	// li r3,2
	ctx.r3.s64 = 2;
	// stw r22,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r22.u32);
	// stw r22,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r22.u32);
	// stw r22,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r22.u32);
	// b 0x824010e0
	goto loc_824010E0;
loc_82400AA8:
	// addi r11,r1,-152
	r11.s64 = ctx.r1.s64 + -152;
	// lwz r25,8(r20)
	r25.u64 = PPC_LOAD_U32(r20.u32 + 8);
	// addi r10,r1,-136
	ctx.r10.s64 = ctx.r1.s64 + -136;
	// addi r26,r25,-1
	r26.s64 = r25.s64 + -1;
	// li r3,1
	ctx.r3.s64 = 1;
	// addi r27,r1,-152
	r27.s64 = ctx.r1.s64 + -152;
	// lwz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// mr r24,r30
	r24.u64 = r30.u64;
	// lwz r8,4(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// li r23,-1
	r23.s64 = -1;
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// stw r8,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, ctx.r8.u32);
	// stw r11,8(r10)
	PPC_STORE_U32(ctx.r10.u32 + 8, r11.u32);
	// addi r11,r26,1
	r11.s64 = r26.s64 + 1;
	// srawi r10,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	ctx.r10.s64 = r11.s32 >> 5;
	// addze r31,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	r31.s64 = temp.s64;
	// srawi r10,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	ctx.r10.s64 = r11.s32 >> 5;
	// rlwinm r28,r31,2,0,29
	r28.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// lwzx r10,r28,r27
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + r27.u32);
	// subfic r29,r11,31
	xer.ca = r11.u32 <= 31;
	r29.s64 = 31 - r11.s64;
	// slw r11,r3,r29
	r11.u64 = r29.u8 & 0x20 ? 0 : (ctx.r3.u32 << (r29.u8 & 0x3F));
	// and. r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82400c00
	if (cr0.getEQ()) goto loc_82400C00;
	// addi r11,r1,-152
	r11.s64 = ctx.r1.s64 + -152;
	// rlwinm r9,r31,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r10,r23,r29
	ctx.r10.u64 = r29.u8 & 0x20 ? 0 : (r23.u32 << (r29.u8 & 0x3F));
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// andc. r11,r11,r10
	r11.u64 = r11.u64 & ~ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82400b68
	if (!cr0.getEQ()) goto loc_82400B68;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82400c00
	if (!cr6.getLT()) goto loc_82400C00;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
loc_82400B48:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82400b68
	if (!cr6.getEQ()) goto loc_82400B68;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82400b48
	if (cr6.getLT()) goto loc_82400B48;
	// b 0x82400c00
	goto loc_82400C00;
loc_82400B68:
	// srawi r11,r26,5
	xer.ca = (r26.s32 < 0) & ((r26.u32 & 0x1F) != 0);
	r11.s64 = r26.s32 >> 5;
	// addi r7,r1,-152
	ctx.r7.s64 = ctx.r1.s64 + -152;
	// addze r9,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	ctx.r9.s64 = temp.s64;
	// srawi r11,r26,5
	xer.ca = (r26.s32 < 0) & ((r26.u32 & 0x1F) != 0);
	r11.s64 = r26.s32 >> 5;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addze r11,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	r11.s64 = temp.s64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// rlwinm r11,r11,5,0,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// subf r11,r11,r26
	r11.s64 = r26.s64 - r11.s64;
	// subfic r11,r11,31
	xer.ca = r11.u32 <= 31;
	r11.s64 = 31 - r11.s64;
	// slw r6,r3,r11
	ctx.r6.u64 = r11.u8 & 0x20 ? 0 : (ctx.r3.u32 << (r11.u8 & 0x3F));
	// lwzx r11,r8,r7
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// add r10,r11,r6
	ctx.r10.u64 = r11.u64 + ctx.r6.u64;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x82400bac
	if (cr6.getLT()) goto loc_82400BAC;
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// bge cr6,0x82400bb0
	if (!cr6.getLT()) goto loc_82400BB0;
loc_82400BAC:
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
loc_82400BB0:
	// addic. r11,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	r11.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stwx r10,r8,r7
	PPC_STORE_U32(ctx.r8.u32 + ctx.r7.u32, ctx.r10.u32);
	// blt 0x82400c00
	if (cr0.getLT()) goto loc_82400C00;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
loc_82400BC8:
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq cr6,0x82400c00
	if (cr6.getEQ()) goto loc_82400C00;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// addi r8,r9,1
	ctx.r8.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x82400bec
	if (cr6.getLT()) goto loc_82400BEC;
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// bge cr6,0x82400bf0
	if (!cr6.getLT()) goto loc_82400BF0;
loc_82400BEC:
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
loc_82400BF0:
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// bge 0x82400bc8
	if (!cr0.getLT()) goto loc_82400BC8;
loc_82400C00:
	// lwzx r10,r28,r27
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + r27.u32);
	// slw r9,r23,r29
	ctx.r9.u64 = r29.u8 & 0x20 ? 0 : (r23.u32 << (r29.u8 & 0x3F));
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// and r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 & ctx.r10.u64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// stwx r10,r28,r27
	PPC_STORE_U32(r28.u32 + r27.u32, ctx.r10.u32);
	// bge cr6,0x82400c48
	if (!cr6.getLT()) goto loc_82400C48;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// subfic r11,r11,3
	xer.ca = r11.u32 <= 3;
	r11.s64 = 3 - r11.s64;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82400c48
	if (cr0.getEQ()) goto loc_82400C48;
	// mtctr r11
	ctr.u64 = r11.u64;
loc_82400C3C:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x82400c3c
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400C3C;
loc_82400C48:
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq cr6,0x82400c54
	if (cr6.getEQ()) goto loc_82400C54;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
loc_82400C54:
	// lwz r11,4(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 4);
	// subf r10,r25,r11
	ctx.r10.s64 = r11.s64 - r25.s64;
	// cmpw cr6,r30,r10
	cr6.compare<int32_t>(r30.s32, ctx.r10.s32, xer);
	// bge cr6,0x82400c80
	if (!cr6.getLT()) goto loc_82400C80;
	// addi r11,r1,-152
	r11.s64 = ctx.r1.s64 + -152;
	// mr r31,r22
	r31.u64 = r22.u64;
	// li r3,2
	ctx.r3.s64 = 2;
	// stw r22,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r22.u32);
	// stw r22,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r22.u32);
	// stw r22,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r22.u32);
	// b 0x824010e0
	goto loc_824010E0;
loc_82400C80:
	// cmpw cr6,r30,r11
	cr6.compare<int32_t>(r30.s32, r11.s32, xer);
	// bgt cr6,0x82400f5c
	if (cr6.getGT()) goto loc_82400F5C;
	// subf r11,r24,r11
	r11.s64 = r11.s64 - r24.s64;
	// addi r10,r1,-136
	ctx.r10.s64 = ctx.r1.s64 + -136;
	// srawi r5,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	ctx.r5.s64 = r11.s32 >> 5;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// addze r31,r5
	temp.s64 = ctx.r5.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r5.u32;
	r31.s64 = temp.s64;
	// srawi r29,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	r29.s64 = r11.s32 >> 5;
	// lwz r30,0(r10)
	r30.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// li r27,-1
	r27.s64 = -1;
	// addze r29,r29
	temp.s64 = r29.s64 + xer.ca;
	xer.ca = temp.u32 < r29.u32;
	r29.s64 = temp.s64;
	// lwz r5,4(r10)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + 4);
	// lwz r10,8(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 8);
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// addi r8,r1,-152
	ctx.r8.s64 = ctx.r1.s64 + -152;
	// li r7,3
	ctx.r7.s64 = 3;
	// stw r30,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r30.u32);
	// rlwinm r30,r29,5,0,26
	r30.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 5) & 0xFFFFFFE0;
	// stw r5,4(r9)
	PPC_STORE_U32(ctx.r9.u32 + 4, ctx.r5.u32);
	// subf r11,r30,r11
	r11.s64 = r11.s64 - r30.s64;
	// stw r10,8(r9)
	PPC_STORE_U32(ctx.r9.u32 + 8, ctx.r10.u32);
	// subfic r10,r11,32
	xer.ca = r11.u32 <= 32;
	ctx.r10.s64 = 32 - r11.s64;
	// slw r9,r27,r11
	ctx.r9.u64 = r11.u8 & 0x20 ? 0 : (r27.u32 << (r11.u8 & 0x3F));
	// not r9,r9
	ctx.r9.u64 = ~ctx.r9.u64;
loc_82400CE0:
	// lwz r5,0(r8)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r8.u32 + 0);
	// addic. r7,r7,-1
	xer.ca = ctx.r7.u32 > 0;
	ctx.r7.s64 = ctx.r7.s64 + -1;
	cr0.compare<int32_t>(ctx.r7.s32, 0, xer);
	// and r30,r5,r9
	r30.u64 = ctx.r5.u64 & ctx.r9.u64;
	// stw r30,-160(r1)
	PPC_STORE_U32(ctx.r1.u32 + -160, r30.u32);
	// srw r5,r5,r11
	ctx.r5.u64 = r11.u8 & 0x20 ? 0 : (ctx.r5.u32 >> (r11.u8 & 0x3F));
	// or r6,r5,r6
	ctx.r6.u64 = ctx.r5.u64 | ctx.r6.u64;
	// stw r6,0(r8)
	PPC_STORE_U32(ctx.r8.u32 + 0, ctx.r6.u32);
	// addi r8,r8,4
	ctx.r8.s64 = ctx.r8.s64 + 4;
	// lwz r6,-160(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + -160);
	// slw r6,r6,r10
	ctx.r6.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r10.u8 & 0x3F));
	// bne 0x82400ce0
	if (!cr0.getEQ()) goto loc_82400CE0;
	// rlwinm r9,r31,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,-144
	ctx.r8.s64 = ctx.r1.s64 + -144;
	// li r10,2
	ctx.r10.s64 = 2;
	// addi r11,r1,-144
	r11.s64 = ctx.r1.s64 + -144;
	// subf r9,r9,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r9.s64;
loc_82400D20:
	// cmpw cr6,r10,r31
	cr6.compare<int32_t>(ctx.r10.s32, r31.s32, xer);
	// blt cr6,0x82400d34
	if (cr6.getLT()) goto loc_82400D34;
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// b 0x82400d38
	goto loc_82400D38;
loc_82400D34:
	// stw r22,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r22.u32);
loc_82400D38:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// bge 0x82400d20
	if (!cr0.getLT()) goto loc_82400D20;
	// addi r11,r26,1
	r11.s64 = r26.s64 + 1;
	// addi r28,r1,-152
	r28.s64 = ctx.r1.s64 + -152;
	// srawi r10,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	ctx.r10.s64 = r11.s32 >> 5;
	// addze r31,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	r31.s64 = temp.s64;
	// srawi r10,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	ctx.r10.s64 = r11.s32 >> 5;
	// rlwinm r29,r31,2,0,29
	r29.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// lwzx r10,r29,r28
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + r28.u32);
	// subfic r30,r11,31
	xer.ca = r11.u32 <= 31;
	r30.s64 = 31 - r11.s64;
	// slw r11,r3,r30
	r11.u64 = r30.u8 & 0x20 ? 0 : (ctx.r3.u32 << (r30.u8 & 0x3F));
	// and. r11,r11,r10
	r11.u64 = r11.u64 & ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82400e6c
	if (cr0.getEQ()) goto loc_82400E6C;
	// addi r11,r1,-152
	r11.s64 = ctx.r1.s64 + -152;
	// rlwinm r9,r31,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// slw r10,r23,r30
	ctx.r10.u64 = r30.u8 & 0x20 ? 0 : (r23.u32 << (r30.u8 & 0x3F));
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// andc. r11,r11,r10
	r11.u64 = r11.u64 & ~ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82400dd0
	if (!cr0.getEQ()) goto loc_82400DD0;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bge cr6,0x82400e6c
	if (!cr6.getLT()) goto loc_82400E6C;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
loc_82400DB0:
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x82400dd0
	if (!cr6.getEQ()) goto loc_82400DD0;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// blt cr6,0x82400db0
	if (cr6.getLT()) goto loc_82400DB0;
	// b 0x82400e6c
	goto loc_82400E6C;
loc_82400DD0:
	// srawi r11,r26,5
	xer.ca = (r26.s32 < 0) & ((r26.u32 & 0x1F) != 0);
	r11.s64 = r26.s32 >> 5;
	// addi r7,r1,-152
	ctx.r7.s64 = ctx.r1.s64 + -152;
	// addze r9,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	ctx.r9.s64 = temp.s64;
	// srawi r11,r26,5
	xer.ca = (r26.s32 < 0) & ((r26.u32 & 0x1F) != 0);
	r11.s64 = r26.s32 >> 5;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// addze r11,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	r11.s64 = temp.s64;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// rlwinm r11,r11,5,0,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// subf r11,r11,r26
	r11.s64 = r26.s64 - r11.s64;
	// subfic r11,r11,31
	xer.ca = r11.u32 <= 31;
	r11.s64 = 31 - r11.s64;
	// slw r6,r3,r11
	ctx.r6.u64 = r11.u8 & 0x20 ? 0 : (ctx.r3.u32 << (r11.u8 & 0x3F));
	// lwzx r11,r8,r7
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + ctx.r7.u32);
	// add r10,r11,r6
	ctx.r10.u64 = r11.u64 + ctx.r6.u64;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x82400e14
	if (cr6.getLT()) goto loc_82400E14;
	// cmplw cr6,r10,r6
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r6.u32, xer);
	// bge cr6,0x82400e18
	if (!cr6.getLT()) goto loc_82400E18;
loc_82400E14:
	// mr r5,r3
	ctx.r5.u64 = ctx.r3.u64;
loc_82400E18:
	// addic. r11,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	r11.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stwx r10,r8,r7
	PPC_STORE_U32(ctx.r8.u32 + ctx.r7.u32, ctx.r10.u32);
	// blt 0x82400e6c
	if (cr0.getLT()) goto loc_82400E6C;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
loc_82400E30:
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq cr6,0x82400e6c
	if (cr6.getEQ()) goto loc_82400E6C;
	// lwz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// addi r8,r9,1
	ctx.r8.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x82400e54
	if (cr6.getLT()) goto loc_82400E54;
	// cmplwi cr6,r8,1
	cr6.compare<uint32_t>(ctx.r8.u32, 1, xer);
	// bge cr6,0x82400e58
	if (!cr6.getLT()) goto loc_82400E58;
loc_82400E54:
	// mr r7,r3
	ctx.r7.u64 = ctx.r3.u64;
loc_82400E58:
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r5,r7
	ctx.r5.u64 = ctx.r7.u64;
	// addi r10,r10,-4
	ctx.r10.s64 = ctx.r10.s64 + -4;
	// bge 0x82400e30
	if (!cr0.getLT()) goto loc_82400E30;
loc_82400E6C:
	// lwzx r10,r29,r28
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + r28.u32);
	// slw r9,r23,r30
	ctx.r9.u64 = r30.u8 & 0x20 ? 0 : (r23.u32 << (r30.u8 & 0x3F));
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// and r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 & ctx.r10.u64;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// stwx r10,r29,r28
	PPC_STORE_U32(r29.u32 + r28.u32, ctx.r10.u32);
	// bge cr6,0x82400eb4
	if (!cr6.getLT()) goto loc_82400EB4;
	// rlwinm r10,r11,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// subfic r11,r11,3
	xer.ca = r11.u32 <= 3;
	r11.s64 = 3 - r11.s64;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82400eb4
	if (cr0.getEQ()) goto loc_82400EB4;
	// mtctr r11
	ctr.u64 = r11.u64;
loc_82400EA8:
	// stw r9,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r9.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// bdnz 0x82400ea8
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82400EA8;
loc_82400EB4:
	// addi r11,r21,1
	r11.s64 = r21.s64 + 1;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// srawi r7,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	ctx.r7.s64 = r11.s32 >> 5;
	// addi r10,r1,-152
	ctx.r10.s64 = ctx.r1.s64 + -152;
	// addze r3,r7
	temp.s64 = ctx.r7.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r7.u32;
	ctx.r3.s64 = temp.s64;
	// srawi r7,r11,5
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1F) != 0);
	ctx.r7.s64 = r11.s32 >> 5;
	// li r9,3
	ctx.r9.s64 = 3;
	// addze r7,r7
	temp.s64 = ctx.r7.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r7.u32;
	ctx.r7.s64 = temp.s64;
	// rlwinm r7,r7,5,0,26
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 5) & 0xFFFFFFE0;
	// subf r11,r7,r11
	r11.s64 = r11.s64 - ctx.r7.s64;
	// subfic r6,r11,32
	xer.ca = r11.u32 <= 32;
	ctx.r6.s64 = 32 - r11.s64;
	// slw r7,r27,r11
	ctx.r7.u64 = r11.u8 & 0x20 ? 0 : (r27.u32 << (r11.u8 & 0x3F));
	// not r5,r7
	ctx.r5.u64 = ~ctx.r7.u64;
loc_82400EE8:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// and r31,r7,r5
	r31.u64 = ctx.r7.u64 & ctx.r5.u64;
	// stw r31,-160(r1)
	PPC_STORE_U32(ctx.r1.u32 + -160, r31.u32);
	// srw r7,r7,r11
	ctx.r7.u64 = r11.u8 & 0x20 ? 0 : (ctx.r7.u32 >> (r11.u8 & 0x3F));
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r8,-160(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + -160);
	// slw r8,r8,r6
	ctx.r8.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r6.u8 & 0x3F));
	// bne 0x82400ee8
	if (!cr0.getEQ()) goto loc_82400EE8;
	// rlwinm r9,r3,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,-144
	ctx.r8.s64 = ctx.r1.s64 + -144;
	// li r10,2
	ctx.r10.s64 = 2;
	// addi r11,r1,-144
	r11.s64 = ctx.r1.s64 + -144;
	// subf r9,r9,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r9.s64;
loc_82400F28:
	// cmpw cr6,r10,r3
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r3.s32, xer);
	// blt cr6,0x82400f3c
	if (cr6.getLT()) goto loc_82400F3C;
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// b 0x82400f40
	goto loc_82400F40;
loc_82400F3C:
	// stw r22,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r22.u32);
loc_82400F40:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// bge 0x82400f28
	if (!cr0.getLT()) goto loc_82400F28;
	// mr r31,r22
	r31.u64 = r22.u64;
	// li r3,2
	ctx.r3.s64 = 2;
	// b 0x824010e0
	goto loc_824010E0;
loc_82400F5C:
	// lwz r29,0(r20)
	r29.u64 = PPC_LOAD_U32(r20.u32 + 0);
	// cmpw cr6,r30,r29
	cr6.compare<int32_t>(r30.s32, r29.s32, xer);
	// blt cr6,0x8240102c
	if (cr6.getLT()) goto loc_8240102C;
	// srawi r10,r21,5
	xer.ca = (r21.s32 < 0) & ((r21.u32 & 0x1F) != 0);
	ctx.r10.s64 = r21.s32 >> 5;
	// addi r11,r1,-152
	r11.s64 = ctx.r1.s64 + -152;
	// addze r31,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	r31.s64 = temp.s64;
	// srawi r10,r21,5
	xer.ca = (r21.s32 < 0) & ((r21.u32 & 0x1F) != 0);
	ctx.r10.s64 = r21.s32 >> 5;
	// li r6,-1
	ctx.r6.s64 = -1;
	// addze r10,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r10.s64 = temp.s64;
	// stw r22,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r22.u32);
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// stw r22,4(r11)
	PPC_STORE_U32(r11.u32 + 4, r22.u32);
	// rlwinm r10,r10,5,0,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0xFFFFFFE0;
	// stw r22,8(r11)
	PPC_STORE_U32(r11.u32 + 8, r22.u32);
	// lwz r11,-152(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -152);
	// subf r10,r10,r21
	ctx.r10.s64 = r21.s64 - ctx.r10.s64;
	// addi r9,r1,-152
	ctx.r9.s64 = ctx.r1.s64 + -152;
	// oris r11,r11,32768
	r11.u64 = r11.u64 | 2147483648;
	// li r8,3
	ctx.r8.s64 = 3;
	// stw r11,-152(r1)
	PPC_STORE_U32(ctx.r1.u32 + -152, r11.u32);
	// slw r11,r6,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r6.u32 << (ctx.r10.u8 & 0x3F));
	// subfic r6,r10,32
	xer.ca = ctx.r10.u32 <= 32;
	ctx.r6.s64 = 32 - ctx.r10.s64;
	// not r5,r11
	ctx.r5.u64 = ~r11.u64;
loc_82400FB8:
	// lwz r11,0(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// addic. r8,r8,-1
	xer.ca = ctx.r8.u32 > 0;
	ctx.r8.s64 = ctx.r8.s64 + -1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// and r30,r11,r5
	r30.u64 = r11.u64 & ctx.r5.u64;
	// stw r30,-160(r1)
	PPC_STORE_U32(ctx.r1.u32 + -160, r30.u32);
	// srw r11,r11,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 >> (ctx.r10.u8 & 0x3F));
	// or r11,r11,r7
	r11.u64 = r11.u64 | ctx.r7.u64;
	// stw r11,0(r9)
	PPC_STORE_U32(ctx.r9.u32 + 0, r11.u32);
	// addi r9,r9,4
	ctx.r9.s64 = ctx.r9.s64 + 4;
	// lwz r11,-160(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -160);
	// slw r7,r11,r6
	ctx.r7.u64 = ctx.r6.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r6.u8 & 0x3F));
	// bne 0x82400fb8
	if (!cr0.getEQ()) goto loc_82400FB8;
	// rlwinm r9,r31,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,-144
	ctx.r8.s64 = ctx.r1.s64 + -144;
	// li r10,2
	ctx.r10.s64 = 2;
	// addi r11,r1,-144
	r11.s64 = ctx.r1.s64 + -144;
	// subf r9,r9,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r9.s64;
loc_82400FF8:
	// cmpw cr6,r10,r31
	cr6.compare<int32_t>(ctx.r10.s32, r31.s32, xer);
	// blt cr6,0x8240100c
	if (cr6.getLT()) goto loc_8240100C;
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// b 0x82401010
	goto loc_82401010;
loc_8240100C:
	// stw r22,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r22.u32);
loc_82401010:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// bge 0x82400ff8
	if (!cr0.getLT()) goto loc_82400FF8;
	// lwz r11,20(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 20);
	// add r31,r11,r29
	r31.u64 = r11.u64 + r29.u64;
	// b 0x824010e0
	goto loc_824010E0;
loc_8240102C:
	// srawi r11,r21,5
	xer.ca = (r21.s32 < 0) & ((r21.u32 & 0x1F) != 0);
	r11.s64 = r21.s32 >> 5;
	// li r7,-1
	ctx.r7.s64 = -1;
	// addze r3,r11
	temp.s64 = r11.s64 + xer.ca;
	xer.ca = temp.u32 < r11.u32;
	ctx.r3.s64 = temp.s64;
	// lwz r11,20(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 20);
	// srawi r10,r21,5
	xer.ca = (r21.s32 < 0) & ((r21.u32 & 0x1F) != 0);
	ctx.r10.s64 = r21.s32 >> 5;
	// add r31,r11,r30
	r31.u64 = r11.u64 + r30.u64;
	// addze r11,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	r11.s64 = temp.s64;
	// lwz r10,-152(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + -152);
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// rlwinm r11,r11,5,0,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 5) & 0xFFFFFFE0;
	// clrlwi r10,r10,1
	ctx.r10.u64 = ctx.r10.u32 & 0x7FFFFFFF;
	// subf r11,r11,r21
	r11.s64 = r21.s64 - r11.s64;
	// li r9,3
	ctx.r9.s64 = 3;
	// subfic r6,r11,32
	xer.ca = r11.u32 <= 32;
	ctx.r6.s64 = 32 - r11.s64;
	// stw r10,-152(r1)
	PPC_STORE_U32(ctx.r1.u32 + -152, ctx.r10.u32);
	// addi r10,r1,-152
	ctx.r10.s64 = ctx.r1.s64 + -152;
	// slw r7,r7,r11
	ctx.r7.u64 = r11.u8 & 0x20 ? 0 : (ctx.r7.u32 << (r11.u8 & 0x3F));
	// not r5,r7
	ctx.r5.u64 = ~ctx.r7.u64;
loc_82401074:
	// lwz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r10.u32 + 0);
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// and r30,r7,r5
	r30.u64 = ctx.r7.u64 & ctx.r5.u64;
	// stw r30,-160(r1)
	PPC_STORE_U32(ctx.r1.u32 + -160, r30.u32);
	// srw r7,r7,r11
	ctx.r7.u64 = r11.u8 & 0x20 ? 0 : (ctx.r7.u32 >> (r11.u8 & 0x3F));
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r8,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, ctx.r8.u32);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// lwz r8,-160(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + -160);
	// slw r8,r8,r6
	ctx.r8.u64 = ctx.r6.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r6.u8 & 0x3F));
	// bne 0x82401074
	if (!cr0.getEQ()) goto loc_82401074;
	// rlwinm r9,r3,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,-144
	ctx.r8.s64 = ctx.r1.s64 + -144;
	// li r10,2
	ctx.r10.s64 = 2;
	// addi r11,r1,-144
	r11.s64 = ctx.r1.s64 + -144;
	// subf r9,r9,r8
	ctx.r9.s64 = ctx.r8.s64 - ctx.r9.s64;
loc_824010B4:
	// cmpw cr6,r10,r3
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r3.s32, xer);
	// blt cr6,0x824010c8
	if (cr6.getLT()) goto loc_824010C8;
	// lwz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + 0);
	// stw r8,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r8.u32);
	// b 0x824010cc
	goto loc_824010CC;
loc_824010C8:
	// stw r22,0(r11)
	PPC_STORE_U32(r11.u32 + 0, r22.u32);
loc_824010CC:
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r9,r9,-4
	ctx.r9.s64 = ctx.r9.s64 + -4;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// bge 0x824010b4
	if (!cr0.getLT()) goto loc_824010B4;
loc_824010DC:
	// mr r3,r22
	ctx.r3.u64 = r22.u64;
loc_824010E0:
	// subfic r11,r21,31
	xer.ca = r21.u32 <= 31;
	r11.s64 = 31 - r21.s64;
	// cmpwi cr6,r19,0
	cr6.compare<int32_t>(r19.s32, 0, xer);
	// lis r10,-32768
	ctx.r10.s64 = -2147483648;
	// bne cr6,0x824010f4
	if (!cr6.getEQ()) goto loc_824010F4;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
loc_824010F4:
	// slw r9,r31,r11
	ctx.r9.u64 = r11.u8 & 0x20 ? 0 : (r31.u32 << (r11.u8 & 0x3F));
	// lwz r11,16(r20)
	r11.u64 = PPC_LOAD_U32(r20.u32 + 16);
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// lwz r9,-152(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + -152);
	// cmpwi cr6,r11,64
	cr6.compare<int32_t>(r11.s32, 64, xer);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// bne cr6,0x8240111c
	if (!cr6.getEQ()) goto loc_8240111C;
	// lwz r11,-148(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + -148);
	// stw r11,4(r4)
	PPC_STORE_U32(ctx.r4.u32 + 4, r11.u32);
	// b 0x82401124
	goto loc_82401124;
loc_8240111C:
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// bne cr6,0x82401128
	if (!cr6.getEQ()) goto loc_82401128;
loc_82401124:
	// stw r10,0(r4)
	PPC_STORE_U32(ctx.r4.u32 + 0, ctx.r10.u32);
loc_82401128:
	// b 0x823ed164
	return;
}

__attribute__((alias("__imp__sub_82401130"))) PPC_WEAK_FUNC(sub_82401130);
PPC_FUNC_IMPL(__imp__sub_82401130) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// li r30,0
	r30.s64 = 0;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// li r27,16462
	r27.s64 = 16462;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// stw r30,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r30.u32);
	// stw r30,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r30.u32);
	// stw r30,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r30.u32);
	// beq cr6,0x8240131c
	if (cr6.getEQ()) goto loc_8240131C;
loc_82401164:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// li r5,12
	ctx.r5.s64 = 12;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r8,r10,1,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// rlwinm r7,r9,1,0,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r9,r11,1,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// or r9,r10,r9
	ctx.r9.u64 = ctx.r10.u64 | ctx.r9.u64;
	// or r8,r7,r8
	ctx.r8.u64 = ctx.r7.u64 | ctx.r8.u64;
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r7,r11,1,31,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// rlwinm r11,r9,1,31,31
	r11.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0x1;
	// stw r9,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r9.u32);
	// rotlwi r9,r9,0
	ctx.r9.u64 = __builtin_rotateleft32(ctx.r9.u32, 0);
	// rlwinm r5,r8,1,0,30
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r8,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r8.u32);
	// rlwinm r9,r9,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r10,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r10.u32);
	// or r8,r5,r11
	ctx.r8.u64 = ctx.r5.u64 | r11.u64;
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// lwz r7,88(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// add r11,r10,r7
	r11.u64 = ctx.r10.u64 + ctx.r7.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// stw r8,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r8.u32);
	// stw r9,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r9.u32);
	// blt cr6,0x824011f0
	if (cr6.getLT()) goto loc_824011F0;
	// cmplw cr6,r11,r7
	cr6.compare<uint32_t>(r11.u32, ctx.r7.u32, xer);
	// bge cr6,0x824011f4
	if (!cr6.getLT()) goto loc_824011F4;
loc_824011F0:
	// li r6,1
	ctx.r6.s64 = 1;
loc_824011F4:
	// cmpwi cr6,r6,0
	cr6.compare<int32_t>(ctx.r6.s32, 0, xer);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// beq cr6,0x82401230
	if (cr6.getEQ()) goto loc_82401230;
	// addi r10,r9,1
	ctx.r10.s64 = ctx.r9.s64 + 1;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x82401218
	if (cr6.getLT()) goto loc_82401218;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bge cr6,0x8240121c
	if (!cr6.getLT()) goto loc_8240121C;
loc_82401218:
	// li r7,1
	ctx.r7.s64 = 1;
loc_8240121C:
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// beq cr6,0x82401230
	if (cr6.getEQ()) goto loc_82401230;
	// addi r10,r8,1
	ctx.r10.s64 = ctx.r8.s64 + 1;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
loc_82401230:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r8,r30
	ctx.r8.u64 = r30.u64;
	// lwz r7,84(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// add r9,r10,r7
	ctx.r9.u64 = ctx.r10.u64 + ctx.r7.u64;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// blt cr6,0x82401250
	if (cr6.getLT()) goto loc_82401250;
	// cmplw cr6,r9,r7
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r7.u32, xer);
	// bge cr6,0x82401254
	if (!cr6.getLT()) goto loc_82401254;
loc_82401250:
	// li r8,1
	ctx.r8.s64 = 1;
loc_82401254:
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// stw r9,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r9.u32);
	// beq cr6,0x8240126c
	if (cr6.getEQ()) goto loc_8240126C;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
loc_8240126C:
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r10,r11,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// lwz r7,80(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// rlwinm r9,r9,1,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0x1;
	// lwz r6,4(r31)
	ctx.r6.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// add r8,r8,r7
	ctx.r8.u64 = ctx.r8.u64 + ctx.r7.u64;
	// rlwinm r6,r6,1,0,30
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r5,r8,1,0,30
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 1) & 0xFFFFFFFE;
	// or r8,r6,r10
	ctx.r8.u64 = ctx.r6.u64 | ctx.r10.u64;
	// or r6,r5,r9
	ctx.r6.u64 = ctx.r5.u64 | ctx.r9.u64;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// stw r8,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r8.u32);
	// stw r6,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r6.u32);
	// lbz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U8(r29.u32 + 0);
	// extsb r9,r10
	ctx.r9.s64 = ctx.r10.s8;
	// add r10,r11,r9
	ctx.r10.u64 = r11.u64 + ctx.r9.u64;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// stw r9,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, ctx.r9.u32);
	// blt cr6,0x824012c8
	if (cr6.getLT()) goto loc_824012C8;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x824012cc
	if (!cr6.getLT()) goto loc_824012CC;
loc_824012C8:
	// li r7,1
	ctx.r7.s64 = 1;
loc_824012CC:
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// stw r10,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r10.u32);
	// beq cr6,0x82401308
	if (cr6.getEQ()) goto loc_82401308;
	// addi r11,r8,1
	r11.s64 = ctx.r8.s64 + 1;
	// mr r10,r30
	ctx.r10.u64 = r30.u64;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x824012f0
	if (cr6.getLT()) goto loc_824012F0;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bge cr6,0x824012f4
	if (!cr6.getLT()) goto loc_824012F4;
loc_824012F0:
	// li r10,1
	ctx.r10.s64 = 1;
loc_824012F4:
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// beq cr6,0x82401308
	if (cr6.getEQ()) goto loc_82401308;
	// addi r11,r6,1
	r11.s64 = ctx.r6.s64 + 1;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_82401308:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// bne 0x82401164
	if (!cr0.getEQ()) goto loc_82401164;
	// b 0x82401358
	goto loc_82401358;
loc_8240131C:
	// clrlwi r9,r27,16
	ctx.r9.u64 = r27.u32 & 0xFFFF;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addis r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 65536;
	// rlwinm r8,r10,16,16,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF;
	// addi r9,r9,-16
	ctx.r9.s64 = ctx.r9.s64 + -16;
	// rlwinm r10,r10,16,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 16) & 0xFFFF0000;
	// clrlwi r27,r9,16
	r27.u64 = ctx.r9.u32 & 0xFFFF;
	// rlwinm r9,r11,16,0,15
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF0000;
	// rlwinm r11,r11,16,16,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xFFFF;
	// or r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 | ctx.r8.u64;
	// stw r10,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r10.u32);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// stw r9,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r9.u32);
loc_82401358:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240131c
	if (cr6.getEQ()) goto loc_8240131C;
	// b 0x824013a8
	goto loc_824013A8;
loc_82401364:
	// clrlwi r9,r27,16
	ctx.r9.u64 = r27.u32 & 0xFFFF;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addis r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 65536;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r7,r8,1,0,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 1) & 0xFFFFFFFE;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// rlwinm r8,r10,1,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// clrlwi r27,r9,16
	r27.u64 = ctx.r9.u32 & 0xFFFF;
	// rlwinm r9,r11,1,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// or r11,r10,r9
	r11.u64 = ctx.r10.u64 | ctx.r9.u64;
	// or r10,r7,r8
	ctx.r10.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
loc_824013A8:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r11,r11,0,16,16
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82401364
	if (cr0.getEQ()) goto loc_82401364;
	// sth r27,0(r31)
	PPC_STORE_U16(r31.u32 + 0, r27.u16);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_824013C0"))) PPC_WEAK_FUNC(sub_824013C0);
PPC_FUNC_IMPL(__imp__sub_824013C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r28,r11,-18648
	r28.s64 = r11.s64 + -18648;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// bne 0x824014c0
	if (!cr0.getEQ()) goto loc_824014C0;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82401430
	if (cr6.getEQ()) goto loc_82401430;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x82401430
	if (cr6.getEQ()) goto loc_82401430;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r30,r29
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r29.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// b 0x82401434
	goto loc_82401434;
loc_82401430:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82401434:
	// lbz r11,40(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 40);
	// rlwinm. r11,r11,0,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824014c0
	if (cr0.getEQ()) goto loc_824014C0;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// blt 0x82401464
	if (cr0.getLT()) goto loc_82401464;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// lbz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// b 0x8240146c
	goto loc_8240146C;
loc_82401464:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824020c8
	sub_824020C8(ctx, base);
loc_8240146C:
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x8240147c
	if (!cr6.getEQ()) goto loc_8240147C;
loc_82401474:
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82401624
	goto loc_82401624;
loc_8240147C:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// stb r3,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r3.u8);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// blt 0x824014a4
	if (cr0.getLT()) goto loc_824014A4;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// lbz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// b 0x824014ac
	goto loc_824014AC;
loc_824014A4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824020c8
	sub_824020C8(ctx, base);
loc_824014AC:
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82401474
	if (cr6.getEQ()) goto loc_82401474;
	// stb r3,81(r1)
	PPC_STORE_U8(ctx.r1.u32 + 81, ctx.r3.u8);
loc_824014B8:
	// lhz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U16(ctx.r1.u32 + 80);
	// b 0x82401624
	goto loc_82401624;
loc_824014C0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824015f4
	if (!cr0.getEQ()) goto loc_824015F4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82401514
	if (cr6.getEQ()) goto loc_82401514;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x82401514
	if (cr6.getEQ()) goto loc_82401514;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r30,r29
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r29.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// b 0x82401518
	goto loc_82401518;
loc_82401514:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82401518:
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// rlwinm. r11,r11,0,0,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824015f4
	if (cr0.getEQ()) goto loc_824015F4;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// li r30,1
	r30.s64 = 1;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// blt 0x8240154c
	if (cr0.getLT()) goto loc_8240154C;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// lbz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// b 0x82401554
	goto loc_82401554;
loc_8240154C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824020c8
	sub_824020C8(ctx, base);
loc_82401554:
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82401474
	if (cr6.getEQ()) goto loc_82401474;
	// extsb r11,r3
	r11.s64 = ctx.r3.s8;
	// clrlwi r3,r11,24
	ctx.r3.u64 = r11.u32 & 0xFF;
	// stb r11,84(r1)
	PPC_STORE_U8(ctx.r1.u32 + 84, r11.u8);
	// bl 0x823fe8a8
	sub_823FE8A8(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824015c4
	if (cr0.getEQ()) goto loc_824015C4;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// blt 0x82401598
	if (cr0.getLT()) goto loc_82401598;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r11,1
	ctx.r10.s64 = r11.s64 + 1;
	// lbz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// b 0x824015a0
	goto loc_824015A0;
loc_82401598:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824020c8
	sub_824020C8(ctx, base);
loc_824015A0:
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x824015bc
	if (!cr6.getEQ()) goto loc_824015BC;
	// lbz r11,84(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x82402468
	sub_82402468(ctx, base);
	// b 0x82401474
	goto loc_82401474;
loc_824015BC:
	// stb r3,85(r1)
	PPC_STORE_U8(ctx.r1.u32 + 85, ctx.r3.u8);
	// li r30,2
	r30.s64 = 2;
loc_824015C4:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823ffea8
	sub_823FFEA8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x824014b8
	if (!cr6.getEQ()) goto loc_824014B8;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,42
	ctx.r10.s64 = 42;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x82401624
	goto loc_82401624;
loc_824015F4:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// addic. r11,r11,-2
	xer.ca = r11.u32 > 1;
	r11.s64 = r11.s64 + -2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// blt 0x82401618
	if (cr0.getLT()) goto loc_82401618;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lhz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U16(r11.u32 + 0);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x82401624
	goto loc_82401624;
loc_82401618:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82403980
	sub_82403980(ctx, base);
	// clrlwi r3,r3,16
	ctx.r3.u64 = ctx.r3.u32 & 0xFFFF;
loc_82401624:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_82401630"))) PPC_WEAK_FUNC(sub_82401630);
PPC_FUNC_IMPL(__imp__sub_82401630) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// clrlwi r27,r26,16
	r27.u64 = r26.u32 & 0xFFFF;
	// cmplwi cr6,r27,65535
	cr6.compare<uint32_t>(r27.u32, 65535, xer);
	// sth r26,182(r1)
	PPC_STORE_U16(ctx.r1.u32 + 182, r26.u16);
	// beq cr6,0x82401874
	if (cr6.getEQ()) goto loc_82401874;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82401670
	if (!cr0.getEQ()) goto loc_82401670;
	// rlwinm. r10,r11,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82401874
	if (cr0.getEQ()) goto loc_82401874;
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82401874
	if (!cr0.getEQ()) goto loc_82401874;
loc_82401670:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82401684
	if (!cr6.getEQ()) goto loc_82401684;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ffb38
	sub_823FFB38(ctx, base);
loc_82401684:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82401818
	if (!cr0.getEQ()) goto loc_82401818;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lis r11,-31987
	r11.s64 = -2096300032;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r28,r11,-18648
	r28.s64 = r11.s64 + -18648;
	// beq cr6,0x824016e8
	if (cr6.getEQ()) goto loc_824016E8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x824016e8
	if (cr6.getEQ()) goto loc_824016E8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r30,r29
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r29.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// b 0x824016ec
	goto loc_824016EC;
loc_824016E8:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_824016EC:
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// rlwinm. r11,r11,0,0,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFF80;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82401818
	if (cr0.getEQ()) goto loc_82401818;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82401740
	if (cr6.getEQ()) goto loc_82401740;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x82401740
	if (cr6.getEQ()) goto loc_82401740;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r30,r29
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r29.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// b 0x82401744
	goto loc_82401744;
loc_82401740:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82401744:
	// lbz r11,40(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 40);
	// rlwinm. r11,r11,0,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240176c
	if (cr0.getEQ()) goto loc_8240176C;
	// lbz r11,182(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 182);
	// li r10,2
	ctx.r10.s64 = 2;
	// stb r11,84(r1)
	PPC_STORE_U8(ctx.r1.u32 + 84, r11.u8);
	// lbz r11,183(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 183);
	// stw r10,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r10.u32);
	// stb r11,85(r1)
	PPC_STORE_U8(ctx.r1.u32 + 85, r11.u8);
	// b 0x8240178c
	goto loc_8240178C;
loc_8240176C:
	// mr r6,r26
	ctx.r6.u64 = r26.u64;
	// li r5,5
	ctx.r5.s64 = 5;
	// addi r4,r1,84
	ctx.r4.s64 = ctx.r1.s64 + 84;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823fe8a0
	sub_823FE8A0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82401874
	if (!cr0.getEQ()) goto loc_82401874;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_8240178C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// bge cr6,0x824017bc
	if (!cr6.getLT()) goto loc_824017BC;
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne cr6,0x82401874
	if (!cr6.getEQ()) goto loc_82401874;
	// lwz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmpw cr6,r10,r9
	cr6.compare<int32_t>(ctx.r10.s32, ctx.r9.s32, xer);
	// bgt cr6,0x82401874
	if (cr6.getGT()) goto loc_82401874;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_824017BC:
	// addic. r11,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	r11.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// blt 0x824017f0
	if (cr0.getLT()) goto loc_824017F0;
	// addi r10,r1,84
	ctx.r10.s64 = ctx.r1.s64 + 84;
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
loc_824017CC:
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lbz r8,0(r10)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// stb r8,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r8.u8);
	// bge 0x824017cc
	if (!cr0.getLT()) goto loc_824017CC;
	// lwz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
loc_824017F0:
	// lwz r9,12(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r8,1
	ctx.r8.s64 = 1;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// rlwimi r9,r8,0,31,31
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r8.u32, 0) & 0x1) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFFE);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwimi r9,r8,0,27,27
	ctx.r9.u64 = (__builtin_rotateleft32(ctx.r8.u32, 0) & 0x10) | (ctx.r9.u64 & 0xFFFFFFFFFFFFFFEF);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r9,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r9.u32);
	// b 0x82401878
	goto loc_82401878;
loc_82401818:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bge cr6,0x82401848
	if (!cr6.getLT()) goto loc_82401848;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x82401874
	if (!cr6.getEQ()) goto loc_82401874;
	// lwz r10,24(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// blt cr6,0x82401874
	if (cr6.getLT()) goto loc_82401874;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_82401848:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,-2
	r11.s64 = r11.s64 + -2;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// beq 0x82401880
	if (cr0.getEQ()) goto loc_82401880;
	// lhz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 0);
	// cmplw cr6,r10,r27
	cr6.compare<uint32_t>(ctx.r10.u32, r27.u32, xer);
	// beq cr6,0x82401884
	if (cr6.getEQ()) goto loc_82401884;
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_82401874:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82401878:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed180
	return;
loc_82401880:
	// sth r26,0(r11)
	PPC_STORE_U16(r11.u32 + 0, r26.u16);
loc_82401884:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// rlwimi r10,r9,0,31,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0x1) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFFE);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// rlwimi r10,r9,0,27,27
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0x10) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFEF);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r10,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r10.u32);
	// b 0x82401878
	goto loc_82401878;
}

__attribute__((alias("__imp__sub_824018B0"))) PPC_WEAK_FUNC(sub_824018B0);
PPC_FUNC_IMPL(__imp__sub_824018B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r11,0
	r11.s64 = 0;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x824018e4
	if (cr6.getEQ()) goto loc_824018E4;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82401a7c
	if (cr6.getEQ()) goto loc_82401A7C;
loc_824018E4:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x82401918
	if (!cr6.getEQ()) goto loc_82401918;
loc_824018EC:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// b 0x82401a78
	goto loc_82401A78;
loc_82401918:
	// lis r11,32767
	r11.s64 = 2147418112;
	// ori r11,r11,65535
	r11.u64 = r11.u64 | 65535;
	// cmplw cr6,r29,r11
	cr6.compare<uint32_t>(r29.u32, r11.u32, xer);
	// bgt cr6,0x824018ec
	if (cr6.getGT()) goto loc_824018EC;
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82401b20
	if (cr6.getEQ()) goto loc_82401B20;
	// lis r27,-32015
	r27.s64 = -2098135040;
	// lwz r9,-19456(r27)
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + -19456);
	// lwz r11,20(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 20);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8240197c
	if (!cr6.getEQ()) goto loc_8240197C;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82401a7c
	if (cr6.getEQ()) goto loc_82401A7C;
loc_8240194C:
	// lhz r11,0(r30)
	r11.u64 = PPC_LOAD_U16(r30.u32 + 0);
	// cmplwi cr6,r11,255
	cr6.compare<uint32_t>(r11.u32, 255, xer);
	// bgt cr6,0x82401a68
	if (cr6.getGT()) goto loc_82401A68;
	// stbx r11,r3,r28
	PPC_STORE_U8(ctx.r3.u32 + r28.u32, r11.u8);
	// lhz r11,0(r30)
	r11.u64 = PPC_LOAD_U16(r30.u32 + 0);
	// addi r30,r30,2
	r30.s64 = r30.s64 + 2;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82401a7c
	if (cr0.getEQ()) goto loc_82401A7C;
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// cmplw cr6,r3,r29
	cr6.compare<uint32_t>(ctx.r3.u32, r29.u32, xer);
	// blt cr6,0x8240194c
	if (cr6.getLT()) goto loc_8240194C;
	// b 0x82401a7c
	goto loc_82401A7C;
loc_8240197C:
	// lwz r11,172(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 172);
	// cmpwi cr6,r11,1
	cr6.compare<int32_t>(r11.s32, 1, xer);
	// bne cr6,0x82401a1c
	if (!cr6.getEQ()) goto loc_82401A1C;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x824019d0
	if (cr6.getEQ()) goto loc_824019D0;
	// mr r11,r30
	r11.u64 = r30.u64;
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
loc_82401998:
	// lhz r8,0(r11)
	ctx.r8.u64 = PPC_LOAD_U16(r11.u32 + 0);
	// cmplwi r8,0
	cr0.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq 0x824019b0
	if (cr0.getEQ()) goto loc_824019B0;
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// bne 0x82401998
	if (!cr0.getEQ()) goto loc_82401998;
loc_824019B0:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x824019d0
	if (cr6.getEQ()) goto loc_824019D0;
	// lhz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 0);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne 0x824019d0
	if (!cr0.getEQ()) goto loc_824019D0;
	// subf r11,r30,r11
	r11.s64 = r11.s64 - r30.s64;
	// srawi r11,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	r11.s64 = r11.s32 >> 1;
	// addi r29,r11,1
	r29.s64 = r11.s64 + 1;
loc_824019D0:
	// lwz r3,4(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8235ef90
	sub_8235EF90(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82401a68
	if (cr0.getEQ()) goto loc_82401A68;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82401a68
	if (!cr6.getEQ()) goto loc_82401A68;
	// add r11,r3,r28
	r11.u64 = ctx.r3.u64 + r28.u64;
	// lbz r11,-1(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + -1);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82401a7c
	if (!cr6.getEQ()) goto loc_82401A7C;
	// b 0x82401b78
	goto loc_82401B78;
loc_82401A1C:
	// lwz r3,4(r9)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r29
	ctx.r8.u64 = r29.u64;
	// mr r7,r28
	ctx.r7.u64 = r28.u64;
	// li r6,-1
	ctx.r6.s64 = -1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8235ef90
	sub_8235EF90(ctx, base);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne cr6,0x82401a68
	if (!cr6.getEQ()) goto loc_82401A68;
	// beq 0x82401a5c
	if (cr0.getEQ()) goto loc_82401A5C;
	// addi r3,r31,-1
	ctx.r3.s64 = r31.s64 + -1;
	// b 0x82401a7c
	goto loc_82401A7C;
loc_82401A5C:
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// cmplwi cr6,r3,122
	cr6.compare<uint32_t>(ctx.r3.u32, 122, xer);
	// beq cr6,0x82401b10
	if (cr6.getEQ()) goto loc_82401B10;
loc_82401A68:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,42
	ctx.r10.s64 = 42;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_82401A78:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82401A7C:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed184
	return;
loc_82401A84:
	// lwz r11,-19456(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + -19456);
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// li r9,0
	ctx.r9.s64 = 0;
	// addi r7,r1,84
	ctx.r7.s64 = ctx.r1.s64 + 84;
	// li r6,1
	ctx.r6.s64 = 1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r8,172(r11)
	ctx.r8.u64 = PPC_LOAD_U32(r11.u32 + 172);
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// bl 0x8235ef90
	sub_8235EF90(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82401a68
	if (cr0.getEQ()) goto loc_82401A68;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82401a68
	if (!cr6.getEQ()) goto loc_82401A68;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82401a68
	if (cr6.getLT()) goto loc_82401A68;
	// cmplwi cr6,r3,5
	cr6.compare<uint32_t>(ctx.r3.u32, 5, xer);
	// bgt cr6,0x82401a68
	if (cr6.getGT()) goto loc_82401A68;
	// add r11,r3,r31
	r11.u64 = ctx.r3.u64 + r31.u64;
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// bgt cr6,0x82401b18
	if (cr6.getGT()) goto loc_82401B18;
	// li r11,0
	r11.s64 = 0;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x82401b0c
	if (!cr6.getGT()) goto loc_82401B0C;
loc_82401AE8:
	// addi r10,r1,84
	ctx.r10.s64 = ctx.r1.s64 + 84;
	// lbzx r10,r11,r10
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + ctx.r10.u32);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// stbx r10,r31,r28
	PPC_STORE_U8(r31.u32 + r28.u32, ctx.r10.u8);
	// beq 0x82401b18
	if (cr0.getEQ()) goto loc_82401B18;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// cmpw cr6,r11,r3
	cr6.compare<int32_t>(r11.s32, ctx.r3.s32, xer);
	// blt cr6,0x82401ae8
	if (cr6.getLT()) goto loc_82401AE8;
loc_82401B0C:
	// addi r30,r30,2
	r30.s64 = r30.s64 + 2;
loc_82401B10:
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// blt cr6,0x82401a84
	if (cr6.getLT()) goto loc_82401A84;
loc_82401B18:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x82401a7c
	goto loc_82401A7C;
loc_82401B20:
	// lis r11,-32015
	r11.s64 = -2098135040;
	// lwz r11,-19456(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -19456);
	// lwz r10,20(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82401b40
	if (!cr6.getEQ()) goto loc_82401B40;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823edbb8
	sub_823EDBB8(ctx, base);
	// b 0x82401a7c
	goto loc_82401A7C;
loc_82401B40:
	// addi r10,r1,80
	ctx.r10.s64 = ctx.r1.s64 + 80;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,-1
	ctx.r6.s64 = -1;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8235ef90
	sub_8235EF90(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82401a68
	if (cr0.getEQ()) goto loc_82401A68;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82401a68
	if (!cr6.getEQ()) goto loc_82401A68;
loc_82401B78:
	// addi r3,r3,-1
	ctx.r3.s64 = ctx.r3.s64 + -1;
	// b 0x82401a7c
	goto loc_82401A7C;
}

__attribute__((alias("__imp__sub_82401B80"))) PPC_WEAK_FUNC(sub_82401B80);
PPC_FUNC_IMPL(__imp__sub_82401B80) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// li r28,0
	r28.s64 = 0;
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// mr r27,r28
	r27.u64 = r28.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82401c0c
	if (cr6.getEQ()) goto loc_82401C0C;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401c14
	if (cr6.getEQ()) goto loc_82401C14;
loc_82401BB8:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82401bc4
	if (cr6.getEQ()) goto loc_82401BC4;
	// stb r28,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r28.u8);
loc_82401BC4:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x82401bd0
	if (cr6.getEQ()) goto loc_82401BD0;
	// stw r28,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r28.u32);
loc_82401BD0:
	// cmplw cr6,r29,r30
	cr6.compare<uint32_t>(r29.u32, r30.u32, xer);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bgt cr6,0x82401be0
	if (cr6.getGT()) goto loc_82401BE0;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
loc_82401BE0:
	// mr r6,r8
	ctx.r6.u64 = ctx.r8.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824018b0
	sub_824018B0(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// bne cr6,0x82401c44
	if (!cr6.getEQ()) goto loc_82401C44;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82401c00
	if (cr6.getEQ()) goto loc_82401C00;
	// stb r28,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r28.u8);
loc_82401C00:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// lwz r3,0(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// b 0x82401cbc
	goto loc_82401CBC;
loc_82401C0C:
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82401bb8
	if (cr6.getEQ()) goto loc_82401BB8;
loc_82401C14:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,22
	ctx.r3.s64 = 22;
	// b 0x82401cbc
	goto loc_82401CBC;
loc_82401C44:
	// addi r11,r3,1
	r11.s64 = ctx.r3.s64 + 1;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82401cac
	if (cr6.getEQ()) goto loc_82401CAC;
	// cmplw cr6,r11,r30
	cr6.compare<uint32_t>(r11.u32, r30.u32, xer);
	// ble cr6,0x82401ca4
	if (!cr6.getGT()) goto loc_82401CA4;
	// cmpwi cr6,r29,-1
	cr6.compare<int32_t>(r29.s32, -1, xer);
	// beq cr6,0x82401c9c
	if (cr6.getEQ()) goto loc_82401C9C;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// stb r28,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r28.u8);
	// bgt cr6,0x82401c9c
	if (cr6.getGT()) goto loc_82401C9C;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,34
	ctx.r10.s64 = 34;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,34
	ctx.r3.s64 = 34;
	// b 0x82401cbc
	goto loc_82401CBC;
loc_82401C9C:
	// mr r11,r30
	r11.u64 = r30.u64;
	// li r27,80
	r27.s64 = 80;
loc_82401CA4:
	// add r10,r11,r31
	ctx.r10.u64 = r11.u64 + r31.u64;
	// stb r28,-1(r10)
	PPC_STORE_U8(ctx.r10.u32 + -1, r28.u8);
loc_82401CAC:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x82401cb8
	if (cr6.getEQ()) goto loc_82401CB8;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
loc_82401CB8:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
loc_82401CBC:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_82401CC8"))) PPC_WEAK_FUNC(sub_82401CC8);
PPC_FUNC_IMPL(__imp__sub_82401CC8) {
	PPC_FUNC_PROLOGUE();
	// li r8,0
	ctx.r8.s64 = 0;
	// b 0x82401b80
	sub_82401B80(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82401CD0"))) PPC_WEAK_FUNC(sub_82401CD0);
PPC_FUNC_IMPL(__imp__sub_82401CD0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// clrlwi r11,r3,16
	r11.u64 = ctx.r3.u32 & 0xFFFF;
	// cmplwi cr6,r11,48
	cr6.compare<uint32_t>(r11.u32, 48, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,58
	cr6.compare<uint32_t>(r11.u32, 58, xer);
	// bge cr6,0x82401cec
	if (!cr6.getLT()) goto loc_82401CEC;
	// addi r3,r11,-48
	ctx.r3.s64 = r11.s64 + -48;
	// blr 
	return;
loc_82401CEC:
	// cmplwi cr6,r11,65296
	cr6.compare<uint32_t>(r11.u32, 65296, xer);
	// bge cr6,0x82401e74
	if (!cr6.getLT()) goto loc_82401E74;
	// cmplwi cr6,r11,1632
	cr6.compare<uint32_t>(r11.u32, 1632, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,1642
	cr6.compare<uint32_t>(r11.u32, 1642, xer);
	// bge cr6,0x82401d0c
	if (!cr6.getLT()) goto loc_82401D0C;
	// addi r3,r11,-1632
	ctx.r3.s64 = r11.s64 + -1632;
	// blr 
	return;
loc_82401D0C:
	// cmplwi cr6,r11,1776
	cr6.compare<uint32_t>(r11.u32, 1776, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,1786
	cr6.compare<uint32_t>(r11.u32, 1786, xer);
	// bge cr6,0x82401d24
	if (!cr6.getLT()) goto loc_82401D24;
	// addi r3,r11,-1776
	ctx.r3.s64 = r11.s64 + -1776;
	// blr 
	return;
loc_82401D24:
	// cmplwi cr6,r11,2406
	cr6.compare<uint32_t>(r11.u32, 2406, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,2416
	cr6.compare<uint32_t>(r11.u32, 2416, xer);
	// bge cr6,0x82401d3c
	if (!cr6.getLT()) goto loc_82401D3C;
	// addi r3,r11,-2406
	ctx.r3.s64 = r11.s64 + -2406;
	// blr 
	return;
loc_82401D3C:
	// cmplwi cr6,r11,2534
	cr6.compare<uint32_t>(r11.u32, 2534, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,2544
	cr6.compare<uint32_t>(r11.u32, 2544, xer);
	// bge cr6,0x82401d54
	if (!cr6.getLT()) goto loc_82401D54;
	// addi r3,r11,-2534
	ctx.r3.s64 = r11.s64 + -2534;
	// blr 
	return;
loc_82401D54:
	// cmplwi cr6,r11,2662
	cr6.compare<uint32_t>(r11.u32, 2662, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,2672
	cr6.compare<uint32_t>(r11.u32, 2672, xer);
	// bge cr6,0x82401d6c
	if (!cr6.getLT()) goto loc_82401D6C;
	// addi r3,r11,-2662
	ctx.r3.s64 = r11.s64 + -2662;
	// blr 
	return;
loc_82401D6C:
	// cmplwi cr6,r11,2790
	cr6.compare<uint32_t>(r11.u32, 2790, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,2800
	cr6.compare<uint32_t>(r11.u32, 2800, xer);
	// bge cr6,0x82401d84
	if (!cr6.getLT()) goto loc_82401D84;
	// addi r3,r11,-2790
	ctx.r3.s64 = r11.s64 + -2790;
	// blr 
	return;
loc_82401D84:
	// cmplwi cr6,r11,2918
	cr6.compare<uint32_t>(r11.u32, 2918, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,2928
	cr6.compare<uint32_t>(r11.u32, 2928, xer);
	// bge cr6,0x82401d9c
	if (!cr6.getLT()) goto loc_82401D9C;
	// addi r3,r11,-2918
	ctx.r3.s64 = r11.s64 + -2918;
	// blr 
	return;
loc_82401D9C:
	// cmplwi cr6,r11,3174
	cr6.compare<uint32_t>(r11.u32, 3174, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,3184
	cr6.compare<uint32_t>(r11.u32, 3184, xer);
	// bge cr6,0x82401db4
	if (!cr6.getLT()) goto loc_82401DB4;
	// addi r3,r11,-3174
	ctx.r3.s64 = r11.s64 + -3174;
	// blr 
	return;
loc_82401DB4:
	// cmplwi cr6,r11,3302
	cr6.compare<uint32_t>(r11.u32, 3302, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,3312
	cr6.compare<uint32_t>(r11.u32, 3312, xer);
	// bge cr6,0x82401dcc
	if (!cr6.getLT()) goto loc_82401DCC;
	// addi r3,r11,-3302
	ctx.r3.s64 = r11.s64 + -3302;
	// blr 
	return;
loc_82401DCC:
	// cmplwi cr6,r11,3430
	cr6.compare<uint32_t>(r11.u32, 3430, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,3440
	cr6.compare<uint32_t>(r11.u32, 3440, xer);
	// bge cr6,0x82401de4
	if (!cr6.getLT()) goto loc_82401DE4;
	// addi r3,r11,-3430
	ctx.r3.s64 = r11.s64 + -3430;
	// blr 
	return;
loc_82401DE4:
	// cmplwi cr6,r11,3664
	cr6.compare<uint32_t>(r11.u32, 3664, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,3674
	cr6.compare<uint32_t>(r11.u32, 3674, xer);
	// bge cr6,0x82401dfc
	if (!cr6.getLT()) goto loc_82401DFC;
	// addi r3,r11,-3664
	ctx.r3.s64 = r11.s64 + -3664;
	// blr 
	return;
loc_82401DFC:
	// cmplwi cr6,r11,3792
	cr6.compare<uint32_t>(r11.u32, 3792, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,3802
	cr6.compare<uint32_t>(r11.u32, 3802, xer);
	// bge cr6,0x82401e14
	if (!cr6.getLT()) goto loc_82401E14;
	// addi r3,r11,-3792
	ctx.r3.s64 = r11.s64 + -3792;
	// blr 
	return;
loc_82401E14:
	// cmplwi cr6,r11,3872
	cr6.compare<uint32_t>(r11.u32, 3872, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,3882
	cr6.compare<uint32_t>(r11.u32, 3882, xer);
	// bge cr6,0x82401e2c
	if (!cr6.getLT()) goto loc_82401E2C;
	// addi r3,r11,-3872
	ctx.r3.s64 = r11.s64 + -3872;
	// blr 
	return;
loc_82401E2C:
	// cmplwi cr6,r11,4160
	cr6.compare<uint32_t>(r11.u32, 4160, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,4170
	cr6.compare<uint32_t>(r11.u32, 4170, xer);
	// bge cr6,0x82401e44
	if (!cr6.getLT()) goto loc_82401E44;
	// addi r3,r11,-4160
	ctx.r3.s64 = r11.s64 + -4160;
	// blr 
	return;
loc_82401E44:
	// cmplwi cr6,r11,6112
	cr6.compare<uint32_t>(r11.u32, 6112, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,6122
	cr6.compare<uint32_t>(r11.u32, 6122, xer);
	// bge cr6,0x82401e5c
	if (!cr6.getLT()) goto loc_82401E5C;
	// addi r3,r11,-6112
	ctx.r3.s64 = r11.s64 + -6112;
	// blr 
	return;
loc_82401E5C:
	// cmplwi cr6,r11,6160
	cr6.compare<uint32_t>(r11.u32, 6160, xer);
	// blt cr6,0x82401e88
	if (cr6.getLT()) goto loc_82401E88;
	// cmplwi cr6,r11,6170
	cr6.compare<uint32_t>(r11.u32, 6170, xer);
	// bge cr6,0x82401e88
	if (!cr6.getLT()) goto loc_82401E88;
	// addi r3,r11,-6160
	ctx.r3.s64 = r11.s64 + -6160;
	// blr 
	return;
loc_82401E74:
	// cmplwi cr6,r11,65306
	cr6.compare<uint32_t>(r11.u32, 65306, xer);
	// bge cr6,0x82401e88
	if (!cr6.getLT()) goto loc_82401E88;
	// addis r3,r11,-1
	ctx.r3.s64 = r11.s64 + -65536;
	// addi r3,r3,240
	ctx.r3.s64 = ctx.r3.s64 + 240;
	// blr 
	return;
loc_82401E88:
	// li r3,-1
	ctx.r3.s64 = -1;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82401E90"))) PPC_WEAK_FUNC(sub_82401E90);
PPC_FUNC_IMPL(__imp__sub_82401E90) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r7
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// stw r7,-88(r1)
	PPC_STORE_U32(ctx.r1.u32 + -88, ctx.r7.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// bl 0x823f9850
	sub_823F9850(ctx, base);
	// mr r12,r4
	r12.u64 = ctx.r4.u64;
	// stw r30,4(r1)
	PPC_STORE_U32(ctx.r1.u32 + 4, r30.u32);
	// mtlr r3
	// blrl 
__builtin_debugtrap();
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// cmplwi r31,256
	cr0.compare<uint32_t>(r31.u32, 256, xer);
	// bne 0x82401ed0
	if (!cr0.getEQ()) goto loc_82401ED0;
	// li r5,2
	ctx.r5.s64 = 2;
loc_82401ED0:
	// bl 0x823f9850
	sub_823F9850(ctx, base);
	// lwz r7,8(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 8);
	// mtlr r7
	// ld r30,80(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// ld r31,88(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + 88);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82401EEC"))) PPC_WEAK_FUNC(sub_82401EEC);
PPC_FUNC_IMPL(__imp__sub_82401EEC) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr1{};
	PPCCRRegister cr2{};
	PPCCRRegister cr3{};
	PPCCRRegister cr4{};
	PPCCRRegister cr5{};
	PPCCRRegister cr6{};
	PPCCRRegister cr7{};
	PPCRegister r2{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f14{};
	PPCRegister f15{};
	PPCRegister f16{};
	PPCRegister f17{};
	PPCRegister f18{};
	PPCRegister f19{};
	PPCRegister f20{};
	PPCRegister f21{};
	PPCRegister f22{};
	PPCRegister f23{};
	PPCRegister f24{};
	PPCRegister f25{};
	PPCRegister f26{};
	PPCRegister f27{};
	PPCRegister f28{};
	PPCRegister f29{};
	PPCRegister f30{};
	PPCRegister f31{};
	// lfd f14,408(r4)
	ctx.fpscr.disableFlushMode();
	f14.u64 = PPC_LOAD_U64(ctx.r4.u32 + 408);
	// lfd f15,416(r4)
	f15.u64 = PPC_LOAD_U64(ctx.r4.u32 + 416);
	// lfd f16,424(r4)
	f16.u64 = PPC_LOAD_U64(ctx.r4.u32 + 424);
	// lfd f17,432(r4)
	f17.u64 = PPC_LOAD_U64(ctx.r4.u32 + 432);
	// lfd f18,440(r4)
	f18.u64 = PPC_LOAD_U64(ctx.r4.u32 + 440);
	// lfd f19,448(r4)
	f19.u64 = PPC_LOAD_U64(ctx.r4.u32 + 448);
	// lfd f20,456(r4)
	f20.u64 = PPC_LOAD_U64(ctx.r4.u32 + 456);
	// lfd f21,464(r4)
	f21.u64 = PPC_LOAD_U64(ctx.r4.u32 + 464);
	// lfd f22,472(r4)
	f22.u64 = PPC_LOAD_U64(ctx.r4.u32 + 472);
	// lfd f23,480(r4)
	f23.u64 = PPC_LOAD_U64(ctx.r4.u32 + 480);
	// lfd f24,488(r4)
	f24.u64 = PPC_LOAD_U64(ctx.r4.u32 + 488);
	// lfd f25,496(r4)
	f25.u64 = PPC_LOAD_U64(ctx.r4.u32 + 496);
	// lfd f26,504(r4)
	f26.u64 = PPC_LOAD_U64(ctx.r4.u32 + 504);
	// lfd f27,512(r4)
	f27.u64 = PPC_LOAD_U64(ctx.r4.u32 + 512);
	// lfd f28,520(r4)
	f28.u64 = PPC_LOAD_U64(ctx.r4.u32 + 520);
	// lfd f29,528(r4)
	f29.u64 = PPC_LOAD_U64(ctx.r4.u32 + 528);
	// lfd f30,536(r4)
	f30.u64 = PPC_LOAD_U64(ctx.r4.u32 + 536);
	// lfd f31,544(r4)
	f31.u64 = PPC_LOAD_U64(ctx.r4.u32 + 544);
	// ld r14,136(r4)
	r14.u64 = PPC_LOAD_U64(ctx.r4.u32 + 136);
	// ld r15,144(r4)
	r15.u64 = PPC_LOAD_U64(ctx.r4.u32 + 144);
	// ld r16,152(r4)
	r16.u64 = PPC_LOAD_U64(ctx.r4.u32 + 152);
	// ld r17,160(r4)
	r17.u64 = PPC_LOAD_U64(ctx.r4.u32 + 160);
	// ld r18,168(r4)
	r18.u64 = PPC_LOAD_U64(ctx.r4.u32 + 168);
	// ld r19,176(r4)
	r19.u64 = PPC_LOAD_U64(ctx.r4.u32 + 176);
	// ld r20,184(r4)
	r20.u64 = PPC_LOAD_U64(ctx.r4.u32 + 184);
	// ld r21,192(r4)
	r21.u64 = PPC_LOAD_U64(ctx.r4.u32 + 192);
	// ld r22,200(r4)
	r22.u64 = PPC_LOAD_U64(ctx.r4.u32 + 200);
	// ld r23,208(r4)
	r23.u64 = PPC_LOAD_U64(ctx.r4.u32 + 208);
	// ld r24,216(r4)
	r24.u64 = PPC_LOAD_U64(ctx.r4.u32 + 216);
	// ld r25,224(r4)
	r25.u64 = PPC_LOAD_U64(ctx.r4.u32 + 224);
	// ld r26,232(r4)
	r26.u64 = PPC_LOAD_U64(ctx.r4.u32 + 232);
	// ld r27,240(r4)
	r27.u64 = PPC_LOAD_U64(ctx.r4.u32 + 240);
	// ld r28,248(r4)
	r28.u64 = PPC_LOAD_U64(ctx.r4.u32 + 248);
	// ld r29,256(r4)
	r29.u64 = PPC_LOAD_U64(ctx.r4.u32 + 256);
	// ld r30,264(r4)
	r30.u64 = PPC_LOAD_U64(ctx.r4.u32 + 264);
	// ld r31,272(r4)
	r31.u64 = PPC_LOAD_U64(ctx.r4.u32 + 272);
	// lfd f0,288(r4)
	f0.u64 = PPC_LOAD_U64(ctx.r4.u32 + 288);
	// lwz r5,280(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + 280);
	// lwz r6,284(r4)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r4.u32 + 284);
	// ld r7,16(r4)
	ctx.r7.u64 = PPC_LOAD_U64(ctx.r4.u32 + 16);
	// mtfsf 255,f0
	ctx.fpscr.storeFromGuest(f0.u32);
	// mtlr r3
	// mtcr r5
	cr0.getLT() = (ctx.r5.u32 & 0x80000000) != 0;
	cr0.getGT() = (ctx.r5.u32 & 0x40000000) != 0;
	cr0.getEQ() = (ctx.r5.u32 & 0x20000000) != 0;
	cr0.getSO() = (ctx.r5.u32 & 0x10000000) != 0;
	cr1.getLT() = (ctx.r5.u32 & 0x8000000) != 0;
	cr1.getGT() = (ctx.r5.u32 & 0x4000000) != 0;
	cr1.getEQ() = (ctx.r5.u32 & 0x2000000) != 0;
	cr1.getSO() = (ctx.r5.u32 & 0x1000000) != 0;
	cr2.getLT() = (ctx.r5.u32 & 0x800000) != 0;
	cr2.getGT() = (ctx.r5.u32 & 0x400000) != 0;
	cr2.getEQ() = (ctx.r5.u32 & 0x200000) != 0;
	cr2.getSO() = (ctx.r5.u32 & 0x100000) != 0;
	cr3.getLT() = (ctx.r5.u32 & 0x80000) != 0;
	cr3.getGT() = (ctx.r5.u32 & 0x40000) != 0;
	cr3.getEQ() = (ctx.r5.u32 & 0x20000) != 0;
	cr3.getSO() = (ctx.r5.u32 & 0x10000) != 0;
	cr4.getLT() = (ctx.r5.u32 & 0x8000) != 0;
	cr4.getGT() = (ctx.r5.u32 & 0x4000) != 0;
	cr4.getEQ() = (ctx.r5.u32 & 0x2000) != 0;
	cr4.getSO() = (ctx.r5.u32 & 0x1000) != 0;
	cr5.getLT() = (ctx.r5.u32 & 0x800) != 0;
	cr5.getGT() = (ctx.r5.u32 & 0x400) != 0;
	cr5.getEQ() = (ctx.r5.u32 & 0x200) != 0;
	cr5.getSO() = (ctx.r5.u32 & 0x100) != 0;
	cr6.getLT() = (ctx.r5.u32 & 0x80) != 0;
	cr6.getGT() = (ctx.r5.u32 & 0x40) != 0;
	cr6.getEQ() = (ctx.r5.u32 & 0x20) != 0;
	cr6.getSO() = (ctx.r5.u32 & 0x10) != 0;
	cr7.getLT() = (ctx.r5.u32 & 0x8) != 0;
	cr7.getGT() = (ctx.r5.u32 & 0x4) != 0;
	cr7.getEQ() = (ctx.r5.u32 & 0x2) != 0;
	cr7.getSO() = (ctx.r5.u32 & 0x1) != 0;
	// mtxer r6
	xer.so = (ctx.r6.u64 & 0x80000000) != 0;
	xer.ov = (ctx.r6.u64 & 0x40000000) != 0;
	xer.ca = (ctx.r6.u64 & 0x20000000) != 0;
	// mtctr r7
	ctr.u64 = ctx.r7.u64;
	// ld r2,40(r4)
	r2.u64 = PPC_LOAD_U64(ctx.r4.u32 + 40);
	// ld r1,32(r4)
	ctx.r1.u64 = PPC_LOAD_U64(ctx.r4.u32 + 32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82401FB0"))) PPC_WEAK_FUNC(sub_82401FB0);
PPC_FUNC_IMPL(__imp__sub_82401FB0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// li r11,1
	r11.s64 = 1;
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne cr6,0x82401fc0
	if (!cr6.getEQ()) goto loc_82401FC0;
	// li r11,0
	r11.s64 = 0;
loc_82401FC0:
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82401FD0"))) PPC_WEAK_FUNC(sub_82401FD0);
PPC_FUNC_IMPL(__imp__sub_82401FD0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// mflr r31
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// std r29,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r29.u64);
	// std r28,-32(r1)
	PPC_STORE_U64(ctx.r1.u32 + -32, r28.u64);
	// stwu r1,-5360(r1)
	ea = -5360 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// li r5,2624
	ctx.r5.s64 = 2624;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// addi r3,r1,2704
	ctx.r3.s64 = ctx.r1.s64 + 2704;
	// bl 0x8241020c
	__imp__RtlCaptureContext(ctx, base);
	// lis r4,-32192
	ctx.r4.s64 = -2109734912;
	// addi r4,r4,8244
	ctx.r4.s64 = ctx.r4.s64 + 8244;
	// stw r4,2712(r1)
	PPC_STORE_U32(ctx.r1.u32 + 2712, ctx.r4.u32);
	// bl 0x823f31a8
	sub_823F31A8(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// lis r4,-32192
	ctx.r4.s64 = -2109734912;
	// addi r4,r4,8244
	ctx.r4.s64 = ctx.r4.s64 + 8244;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// bl 0x824101fc
	__imp__RtlUnwind(ctx, base);
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// li r5,2624
	ctx.r5.s64 = 2624;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x823f31a8
	sub_823F31A8(ctx, base);
	// lwz r4,4(r30)
	ctx.r4.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r5,r4,0,31,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFD;
	// stw r5,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r5.u32);
	// mtlr r31
	// ld r28,5328(r1)
	r28.u64 = PPC_LOAD_U64(ctx.r1.u32 + 5328);
	// ld r29,5336(r1)
	r29.u64 = PPC_LOAD_U64(ctx.r1.u32 + 5336);
	// ld r30,5344(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + 5344);
	// ld r31,5352(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + 5352);
	// addi r1,r1,5360
	ctx.r1.s64 = ctx.r1.s64 + 5360;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82402074"))) PPC_WEAK_FUNC(sub_82402074);
PPC_FUNC_IMPL(__imp__sub_82402074) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r18{};
	// lwz r18,8352(0)
	r18.u64 = PPC_LOAD_U32(8352);
	// .long 0x0
}

__attribute__((alias("__imp__sub_8240207C"))) PPC_WEAK_FUNC(sub_8240207C);
PPC_FUNC_IMPL(__imp__sub_8240207C) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// mflr r31
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// stw r10,8(r1)
	PPC_STORE_U32(ctx.r1.u32 + 8, ctx.r10.u32);
	// bl 0x823fbc48
	sub_823FBC48(ctx, base);
	// mtlr r31
	// ld r31,80(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824020A0"))) PPC_WEAK_FUNC(sub_824020A0);
PPC_FUNC_IMPL(__imp__sub_824020A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, r31.u64);
	// mflr r31
	// stwu r1,-80(r1)
	ea = -80 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r5,-88(r4)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r4.u32 + -88);
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// bl 0x823fbb50
	sub_823FBB50(ctx, base);
	// mtlr r31
	// ld r31,8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + 8);
	// addi r1,r1,80
	ctx.r1.s64 = ctx.r1.s64 + 80;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824020C8"))) PPC_WEAK_FUNC(sub_824020C8);
PPC_FUNC_IMPL(__imp__sub_824020C8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240210c
	if (!cr6.getEQ()) goto loc_8240210C;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// b 0x8240227c
	goto loc_8240227C;
loc_8240210C:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// andi. r10,r11,131
	ctx.r10.u64 = r11.u64 & 131;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8240227c
	if (cr0.getEQ()) goto loc_8240227C;
	// rlwinm. r10,r11,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8240227c
	if (!cr0.getEQ()) goto loc_8240227C;
	// rlwinm. r10,r11,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402134
	if (cr0.getEQ()) goto loc_82402134;
	// ori r11,r11,32
	r11.u64 = r11.u64 | 32;
	// b 0x82402278
	goto loc_82402278;
loc_82402134:
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// andi. r10,r11,268
	ctx.r10.u64 = r11.u64 & 268;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82402154
	if (!cr0.getEQ()) goto loc_82402154;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ffb38
	sub_823FFB38(ctx, base);
	// b 0x8240215c
	goto loc_8240215C;
loc_82402154:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_8240215C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r30,24(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r29,8(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x82404188
	sub_82404188(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r3,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r3.u32);
	// beq 0x82402258
	if (cr0.getEQ()) goto loc_82402258;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82402258
	if (cr6.getEQ()) goto loc_82402258;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// andi. r11,r11,130
	r11.u64 = r11.u64 & 130;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82402210
	if (!cr0.getEQ()) goto loc_82402210;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x824021ec
	if (cr6.getEQ()) goto loc_824021EC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x824021ec
	if (cr6.getEQ()) goto loc_824021EC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r30,r11,-15840
	r30.s64 = r11.s64 + -15840;
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r29,r11,2,0,29
	r29.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r29,r30
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + r30.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// b 0x824021f4
	goto loc_824021F4;
loc_824021EC:
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r11,r11,-18648
	r11.s64 = r11.s64 + -18648;
loc_824021F4:
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// andi. r11,r11,130
	r11.u64 = r11.u64 & 130;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi cr6,r11,130
	cr6.compare<uint32_t>(r11.u32, 130, xer);
	// bne cr6,0x82402210
	if (!cr6.getEQ()) goto loc_82402210;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// ori r11,r11,8192
	r11.u64 = r11.u64 | 8192;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
loc_82402210:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmpwi cr6,r11,512
	cr6.compare<int32_t>(r11.s32, 512, xer);
	// bne cr6,0x82402238
	if (!cr6.getEQ()) goto loc_82402238;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm. r10,r11,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402238
	if (cr0.getEQ()) goto loc_82402238;
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82402238
	if (!cr0.getEQ()) goto loc_82402238;
	// li r11,4096
	r11.s64 = 4096;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
loc_82402238:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// lbz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x82402280
	goto loc_82402280;
loc_82402258:
	// subfic r11,r3,0
	xer.ca = ctx.r3.u32 <= 0;
	r11.s64 = 0 - ctx.r3.s64;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r9,0
	ctx.r9.s64 = 0;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// rlwinm r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// stw r9,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r9.u32);
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
loc_82402278:
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
loc_8240227C:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82402280:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82402288"))) PPC_WEAK_FUNC(sub_82402288);
PPC_FUNC_IMPL(__imp__sub_82402288) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240239c
	if (!cr0.getEQ()) goto loc_8240239C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lis r11,-31987
	r11.s64 = -2096300032;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r28,r11,-18648
	r28.s64 = r11.s64 + -18648;
	// beq cr6,0x82402300
	if (cr6.getEQ()) goto loc_82402300;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x82402300
	if (cr6.getEQ()) goto loc_82402300;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r30,r29
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r29.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// b 0x82402304
	goto loc_82402304;
loc_82402300:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_82402304:
	// lbz r11,40(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 40);
	// rlwinm. r11,r11,0,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82402368
	if (!cr0.getEQ()) goto loc_82402368;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82402358
	if (cr6.getEQ()) goto loc_82402358;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x82402358
	if (cr6.getEQ()) goto loc_82402358;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r30,r11,2,0,29
	r30.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r30,r29
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + r29.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// b 0x8240235c
	goto loc_8240235C;
loc_82402358:
	// mr r11,r28
	r11.u64 = r28.u64;
loc_8240235C:
	// lbz r11,40(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 40);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240239c
	if (cr0.getEQ()) goto loc_8240239C;
loc_82402368:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
loc_82402390:
	// li r3,-1
	ctx.r3.s64 = -1;
loc_82402394:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed184
	return;
loc_8240239C:
	// cmpwi cr6,r27,-1
	cr6.compare<int32_t>(r27.s32, -1, xer);
	// beq cr6,0x82402390
	if (cr6.getEQ()) goto loc_82402390;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x824023c0
	if (!cr0.getEQ()) goto loc_824023C0;
	// rlwinm. r10,r11,0,24,24
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82402390
	if (cr0.getEQ()) goto loc_82402390;
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82402390
	if (!cr0.getEQ()) goto loc_82402390;
loc_824023C0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824023d4
	if (!cr6.getEQ()) goto loc_824023D4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ffb38
	sub_823FFB38(ctx, base);
loc_824023D4:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x824023f8
	if (!cr6.getEQ()) goto loc_824023F8;
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x82402390
	if (!cr6.getEQ()) goto loc_82402390;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_824023F8:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// beq 0x82402430
	if (cr0.getEQ()) goto loc_82402430;
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// extsb r10,r27
	ctx.r10.s64 = r27.s8;
	// extsb r9,r9
	ctx.r9.s64 = ctx.r9.s8;
	// cmpw cr6,r9,r10
	cr6.compare<int32_t>(ctx.r9.s32, ctx.r10.s32, xer);
	// beq cr6,0x82402434
	if (cr6.getEQ()) goto loc_82402434;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x82402390
	goto loc_82402390;
loc_82402430:
	// stb r27,0(r11)
	PPC_STORE_U8(r11.u32 + 0, r27.u8);
loc_82402434:
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r9,1
	ctx.r9.s64 = 1;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi r3,r27,24
	ctx.r3.u64 = r27.u32 & 0xFF;
	// rlwimi r10,r9,0,31,31
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0x1) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFFE);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// rlwimi r10,r9,0,27,27
	ctx.r10.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0x10) | (ctx.r10.u64 & 0xFFFFFFFFFFFFFFEF);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r10,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r10.u32);
	// b 0x82402394
	goto loc_82402394;
}

__attribute__((alias("__imp__sub_82402460"))) PPC_WEAK_FUNC(sub_82402460);
PPC_FUNC_IMPL(__imp__sub_82402460) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r18{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// lwz r18,-1044(0)
	r18.u64 = PPC_LOAD_U32(-1044);
	// lwz r16,29904(r7)
	r16.u64 = PPC_LOAD_U32(ctx.r7.u32 + 29904);
	// mflr r12
	// bl 0x823ed13c
	// addi r31,r1,-128
	r31.s64 = ctx.r1.s64 + -128;
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// stw r30,156(r31)
	PPC_STORE_U32(r31.u32 + 156, r30.u32);
	// cntlzw r11,r30
	r11.u64 = r30.u32 == 0 ? 32 : __builtin_clz(r30.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824024c8
	if (!cr0.getEQ()) goto loc_824024C8;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x824024f4
	goto loc_824024F4;
loc_824024C8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f4f98
	sub_823F4F98(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82402288
	sub_82402288(ctx, base);
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,128
	r12.s64 = r31.s64 + 128;
	// bl 0x8240251c
	sub_8240251C(ctx, base);
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
loc_824024F4:
	// addi r1,r31,128
	ctx.r1.s64 = r31.s64 + 128;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82402468"))) PPC_WEAK_FUNC(sub_82402468);
PPC_FUNC_IMPL(__imp__sub_82402468) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// addi r31,r1,-128
	r31.s64 = ctx.r1.s64 + -128;
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// stw r30,156(r31)
	PPC_STORE_U32(r31.u32 + 156, r30.u32);
	// cntlzw r11,r30
	r11.u64 = r30.u32 == 0 ? 32 : __builtin_clz(r30.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824024c8
	if (!cr0.getEQ()) goto loc_824024C8;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x824024f4
	goto loc_824024F4;
loc_824024C8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f4f98
	sub_823F4F98(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82402288
	sub_82402288(ctx, base);
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,128
	r12.s64 = r31.s64 + 128;
	// bl 0x8240251c
	sub_8240251C(ctx, base);
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
loc_824024F4:
	// addi r1,r31,128
	ctx.r1.s64 = r31.s64 + 128;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_824024FC"))) PPC_WEAK_FUNC(sub_824024FC);
PPC_FUNC_IMPL(__imp__sub_824024FC) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-128
	r31.s64 = r12.s64 + -128;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,156(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 156);
	// b 0x82402534
	goto loc_82402534;
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-128
	r31.s64 = r12.s64 + -128;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
loc_82402534:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5058
	sub_823F5058(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240251C"))) PPC_WEAK_FUNC(sub_8240251C);
PPC_FUNC_IMPL(__imp__sub_8240251C) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-128
	r31.s64 = r12.s64 + -128;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5058
	sub_823F5058(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82402558"))) PPC_WEAK_FUNC(sub_82402558);
PPC_FUNC_IMPL(__imp__sub_82402558) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r14{};
	PPCRegister r15{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed100
	// stwu r1,-320(r1)
	ea = -320 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// std r3,336(r1)
	PPC_STORE_U64(ctx.r1.u32 + 336, ctx.r3.u64);
	// li r11,63
	r11.s64 = 63;
	// mr r31,r7
	r31.u64 = ctx.r7.u64;
	// stw r6,364(r1)
	PPC_STORE_U32(ctx.r1.u32 + 364, ctx.r6.u32);
	// li r8,1
	ctx.r8.s64 = 1;
	// std r4,344(r1)
	PPC_STORE_U64(ctx.r1.u32 + 344, ctx.r4.u64);
	// stw r5,356(r1)
	PPC_STORE_U32(ctx.r1.u32 + 356, ctx.r5.u32);
	// stb r11,136(r1)
	PPC_STORE_U8(ctx.r1.u32 + 136, r11.u8);
	// li r11,251
	r11.s64 = 251;
	// stw r31,372(r1)
	PPC_STORE_U32(ctx.r1.u32 + 372, r31.u32);
	// stw r8,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r8.u32);
	// stb r11,137(r1)
	PPC_STORE_U8(ctx.r1.u32 + 137, r11.u8);
	// li r11,204
	r11.s64 = 204;
	// stb r11,138(r1)
	PPC_STORE_U8(ctx.r1.u32 + 138, r11.u8);
	// stb r11,139(r1)
	PPC_STORE_U8(ctx.r1.u32 + 139, r11.u8);
	// stb r11,140(r1)
	PPC_STORE_U8(ctx.r1.u32 + 140, r11.u8);
	// stb r11,141(r1)
	PPC_STORE_U8(ctx.r1.u32 + 141, r11.u8);
	// stb r11,142(r1)
	PPC_STORE_U8(ctx.r1.u32 + 142, r11.u8);
	// stb r11,143(r1)
	PPC_STORE_U8(ctx.r1.u32 + 143, r11.u8);
	// stb r11,144(r1)
	PPC_STORE_U8(ctx.r1.u32 + 144, r11.u8);
	// stb r11,145(r1)
	PPC_STORE_U8(ctx.r1.u32 + 145, r11.u8);
	// stb r11,146(r1)
	PPC_STORE_U8(ctx.r1.u32 + 146, r11.u8);
	// stb r11,147(r1)
	PPC_STORE_U8(ctx.r1.u32 + 147, r11.u8);
	// li r11,45
	r11.s64 = 45;
	// lhz r10,336(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 336);
	// clrlwi r6,r10,17
	ctx.r6.u64 = ctx.r10.u32 & 0x7FFF;
	// rlwinm. r9,r10,0,0,16
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFF8000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// stw r9,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r9.u32);
	// bne 0x824025dc
	if (!cr0.getEQ()) goto loc_824025DC;
	// li r11,32
	r11.s64 = 32;
loc_824025DC:
	// stb r11,2(r31)
	PPC_STORE_U8(r31.u32 + 2, r11.u8);
	// clrlwi. r11,r6,16
	r11.u64 = ctx.r6.u32 & 0xFFFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lwz r5,342(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 342);
	// lwz r10,338(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 338);
	// bne 0x82402634
	if (!cr0.getEQ()) goto loc_82402634;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82402634
	if (!cr6.getEQ()) goto loc_82402634;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x82402634
	if (!cr6.getEQ()) goto loc_82402634;
	// li r22,0
	r22.s64 = 0;
	// cmplwi cr6,r9,32768
	cr6.compare<uint32_t>(ctx.r9.u32, 32768, xer);
	// li r11,45
	r11.s64 = 45;
	// sth r22,0(r31)
	PPC_STORE_U16(r31.u32 + 0, r22.u16);
	// beq cr6,0x82402618
	if (cr6.getEQ()) goto loc_82402618;
	// li r11,32
	r11.s64 = 32;
loc_82402618:
	// stb r11,2(r31)
	PPC_STORE_U8(r31.u32 + 2, r11.u8);
	// stb r8,3(r31)
	PPC_STORE_U8(r31.u32 + 3, ctx.r8.u8);
loc_82402620:
	// li r10,48
	ctx.r10.s64 = 48;
	// stb r22,5(r31)
	PPC_STORE_U8(r31.u32 + 5, r22.u8);
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r10,4(r31)
	PPC_STORE_U8(r31.u32 + 4, ctx.r10.u8);
	// b 0x824031b0
	goto loc_824031B0;
loc_82402634:
	// cmplwi cr6,r11,32767
	cr6.compare<uint32_t>(r11.u32, 32767, xer);
	// lis r14,-32768
	r14.s64 = -2147483648;
	// bne cr6,0x82402720
	if (!cr6.getEQ()) goto loc_82402720;
	// cmplw cr6,r10,r14
	cr6.compare<uint32_t>(ctx.r10.u32, r14.u32, xer);
	// sth r8,0(r31)
	PPC_STORE_U16(r31.u32 + 0, ctx.r8.u16);
	// bne cr6,0x82402654
	if (!cr6.getEQ()) goto loc_82402654;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x82402668
	if (cr6.getEQ()) goto loc_82402668;
loc_82402654:
	// rlwinm. r11,r10,0,1,1
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82402668
	if (!cr0.getEQ()) goto loc_82402668;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r5,r11,14696
	ctx.r5.s64 = r11.s64 + 14696;
	// b 0x824026e4
	goto loc_824026E4;
loc_82402668:
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82402690
	if (cr6.getEQ()) goto loc_82402690;
	// lis r11,-16384
	r11.s64 = -1073741824;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x82402690
	if (!cr6.getEQ()) goto loc_82402690;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x824026dc
	if (!cr6.getEQ()) goto loc_824026DC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r5,r11,14688
	ctx.r5.s64 = r11.s64 + 14688;
	// b 0x824026a8
	goto loc_824026A8;
loc_82402690:
	// cmplw cr6,r10,r14
	cr6.compare<uint32_t>(ctx.r10.u32, r14.u32, xer);
	// bne cr6,0x824026dc
	if (!cr6.getEQ()) goto loc_824026DC;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// bne cr6,0x824026dc
	if (!cr6.getEQ()) goto loc_824026DC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r5,r11,14680
	ctx.r5.s64 = r11.s64 + 14680;
loc_824026A8:
	// li r4,22
	ctx.r4.s64 = 22;
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// bl 0x823ee540
	sub_823EE540(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x824026d4
	if (cr0.getEQ()) goto loc_824026D4;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x823f3cf0
	sub_823F3CF0(ctx, base);
loc_824026D4:
	// li r11,5
	r11.s64 = 5;
	// b 0x82402714
	goto loc_82402714;
loc_824026DC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r5,r11,14672
	ctx.r5.s64 = r11.s64 + 14672;
loc_824026E4:
	// li r4,22
	ctx.r4.s64 = 22;
	// addi r3,r31,4
	ctx.r3.s64 = r31.s64 + 4;
	// bl 0x823ee540
	sub_823EE540(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82402710
	if (cr0.getEQ()) goto loc_82402710;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x823f3cf0
	sub_823F3CF0(ctx, base);
loc_82402710:
	// li r11,6
	r11.s64 = 6;
loc_82402714:
	// li r3,0
	ctx.r3.s64 = 0;
	// stb r11,3(r31)
	PPC_STORE_U8(r31.u32 + 3, r11.u8);
	// b 0x824031b0
	goto loc_824031B0;
loc_82402720:
	// rlwinm r7,r11,24,8,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 24) & 0xFFFFFF;
	// stw r10,90(r1)
	PPC_STORE_U32(ctx.r1.u32 + 90, ctx.r10.u32);
	// mulli r8,r11,19728
	ctx.r8.s64 = r11.s64 * 19728;
	// sth r6,88(r1)
	PPC_STORE_U16(ctx.r1.u32 + 88, ctx.r6.u16);
	// stw r5,94(r1)
	PPC_STORE_U32(ctx.r1.u32 + 94, ctx.r5.u32);
	// rlwinm r9,r10,9,23,30
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 9) & 0x1FE;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// li r22,0
	r22.s64 = 0;
	// add r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 + ctx.r7.u64;
	// addi r11,r11,-17264
	r11.s64 = r11.s64 + -17264;
	// mulli r9,r9,77
	ctx.r9.s64 = ctx.r9.s64 * 77;
	// sth r22,98(r1)
	PPC_STORE_U16(ctx.r1.u32 + 98, r22.u16);
	// addi r23,r11,-96
	r23.s64 = r11.s64 + -96;
	// lis r11,0
	r11.s64 = 0;
	// add r9,r9,r8
	ctx.r9.u64 = ctx.r9.u64 + ctx.r8.u64;
	// li r15,-32768
	r15.s64 = -32768;
	// ori r20,r11,49154
	r20.u64 = r11.u64 | 49154;
	// lis r11,0
	r11.s64 = 0;
	// addis r9,r9,-4931
	ctx.r9.s64 = ctx.r9.s64 + -323158016;
	// ori r21,r11,65535
	r21.u64 = r11.u64 | 65535;
	// addi r9,r9,-4852
	ctx.r9.s64 = ctx.r9.s64 + -4852;
	// lis r11,1
	r11.s64 = 65536;
	// srawi r10,r9,16
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0xFFFF) != 0);
	ctx.r10.s64 = ctx.r9.s32 >> 16;
	// ori r17,r11,32768
	r17.u64 = r11.u64 | 32768;
	// lis r11,0
	r11.s64 = 0;
	// extsh r19,r10
	r19.s64 = ctx.r10.s16;
	// ori r18,r11,32768
	r18.u64 = r11.u64 | 32768;
	// mr r24,r19
	r24.u64 = r19.u64;
	// lis r11,32767
	r11.s64 = 2147418112;
	// neg. r25,r24
	r25.s64 = -r24.s64;
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// ori r16,r11,32768
	r16.u64 = r11.u64 | 32768;
	// beq 0x82402b5c
	if (cr0.getEQ()) goto loc_82402B5C;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bge cr6,0x824027bc
	if (!cr6.getLT()) goto loc_824027BC;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// neg r25,r25
	r25.s64 = -r25.s64;
	// addi r11,r11,-16912
	r11.s64 = r11.s64 + -16912;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// addi r23,r11,-96
	r23.s64 = r11.s64 + -96;
loc_824027BC:
	// beq cr6,0x82402b5c
	if (cr6.getEQ()) goto loc_82402B5C;
	// lwz r29,96(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r30,92(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
loc_824027C8:
	// clrlwi. r11,r25,29
	r11.u64 = r25.u32 & 0x7;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// addi r23,r23,84
	r23.s64 = r23.s64 + 84;
	// srawi r25,r25,3
	xer.ca = (r25.s32 < 0) & ((r25.u32 & 0x7) != 0);
	r25.s64 = r25.s32 >> 3;
	// beq 0x82402b50
	if (cr0.getEQ()) goto loc_82402B50;
	// mulli r11,r11,12
	r11.s64 = r11.s64 * 12;
	// add r4,r11,r23
	ctx.r4.u64 = r11.u64 + r23.u64;
	// lhz r11,10(r4)
	r11.u64 = PPC_LOAD_U16(ctx.r4.u32 + 10);
	// cmplwi cr6,r11,32768
	cr6.compare<uint32_t>(r11.u32, 32768, xer);
	// blt cr6,0x82402808
	if (cr6.getLT()) goto loc_82402808;
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// li r5,12
	ctx.r5.s64 = 12;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lwz r11,158(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 158);
	// addi r4,r1,152
	ctx.r4.s64 = ctx.r1.s64 + 152;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// stw r11,158(r1)
	PPC_STORE_U32(ctx.r1.u32 + 158, r11.u32);
loc_82402808:
	// stw r22,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r22.u32);
	// mr r27,r22
	r27.u64 = r22.u64;
	// stw r22,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r22.u32);
	// stw r22,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r22.u32);
	// lhz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r4.u32 + 0);
	// lhz r11,88(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 88);
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// xor r10,r11,r10
	ctx.r10.u64 = r11.u64 ^ ctx.r10.u64;
	// clrlwi r11,r11,17
	r11.u64 = r11.u32 & 0x7FFF;
	// rlwinm r26,r10,0,16,16
	r26.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8000;
	// clrlwi r10,r8,17
	ctx.r10.u64 = ctx.r8.u32 & 0x7FFF;
	// cmplwi cr6,r11,32767
	cr6.compare<uint32_t>(r11.u32, 32767, xer);
	// add r9,r11,r10
	ctx.r9.u64 = r11.u64 + ctx.r10.u64;
	// clrlwi r28,r9,16
	r28.u64 = ctx.r9.u32 & 0xFFFF;
	// bge cr6,0x82402b30
	if (!cr6.getLT()) goto loc_82402B30;
	// cmplwi cr6,r10,32767
	cr6.compare<uint32_t>(ctx.r10.u32, 32767, xer);
	// bge cr6,0x82402b30
	if (!cr6.getLT()) goto loc_82402B30;
	// clrlwi r9,r28,16
	ctx.r9.u64 = r28.u32 & 0xFFFF;
	// cmplwi cr6,r9,49149
	cr6.compare<uint32_t>(ctx.r9.u32, 49149, xer);
	// bgt cr6,0x82402b30
	if (cr6.getGT()) goto loc_82402B30;
	// cmplwi cr6,r9,16319
	cr6.compare<uint32_t>(ctx.r9.u32, 16319, xer);
	// bgt cr6,0x82402868
	if (cr6.getGT()) goto loc_82402868;
loc_82402860:
	// stw r22,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r22.u32);
	// b 0x82402b40
	goto loc_82402B40;
loc_82402868:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8240289c
	if (!cr6.getEQ()) goto loc_8240289C;
	// addi r11,r9,1
	r11.s64 = ctx.r9.s64 + 1;
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// clrlwi r28,r11,16
	r28.u64 = r11.u32 & 0xFFFF;
	// clrlwi. r9,r9,1
	ctx.r9.u64 = ctx.r9.u32 & 0x7FFFFFFF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x8240289c
	if (!cr0.getEQ()) goto loc_8240289C;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8240289c
	if (!cr6.getEQ()) goto loc_8240289C;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x8240289c
	if (!cr6.getEQ()) goto loc_8240289C;
	// sth r22,88(r1)
	PPC_STORE_U16(ctx.r1.u32 + 88, r22.u16);
	// b 0x82402b50
	goto loc_82402B50;
loc_8240289C:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x824028d4
	if (!cr6.getEQ()) goto loc_824028D4;
	// lwz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	// clrlwi r11,r28,16
	r11.u64 = r28.u32 & 0xFFFF;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// clrlwi r28,r11,16
	r28.u64 = r11.u32 & 0xFFFF;
	// clrlwi. r10,r10,1
	ctx.r10.u64 = ctx.r10.u32 & 0x7FFFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x824028d4
	if (!cr0.getEQ()) goto loc_824028D4;
	// lwz r11,4(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824028d4
	if (!cr6.getEQ()) goto loc_824028D4;
	// lwz r11,8(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82402860
	if (cr6.getEQ()) goto loc_82402860;
loc_824028D4:
	// mr r31,r22
	r31.u64 = r22.u64;
	// addi r8,r1,110
	ctx.r8.s64 = ctx.r1.s64 + 110;
	// li r3,5
	ctx.r3.s64 = 5;
loc_824028E0:
	// rlwinm r11,r31,1,0,30
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// mtctr r3
	ctr.u64 = ctx.r3.u64;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x8240294c
	if (!cr6.getGT()) goto loc_8240294C;
	// addi r10,r1,98
	ctx.r10.s64 = ctx.r1.s64 + 98;
	// addi r5,r4,2
	ctx.r5.s64 = ctx.r4.s64 + 2;
	// subf r6,r11,r10
	ctx.r6.s64 = ctx.r10.s64 - r11.s64;
loc_824028FC:
	// lhz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r5.u32 + 0);
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// lhz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r6.u32 + 0);
	// lwz r11,2(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 2);
	// mullw r9,r10,r9
	ctx.r9.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
	// add r10,r11,r9
	ctx.r10.u64 = r11.u64 + ctx.r9.u64;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x82402924
	if (cr6.getLT()) goto loc_82402924;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x82402928
	if (!cr6.getLT()) goto loc_82402928;
loc_82402924:
	// li r7,1
	ctx.r7.s64 = 1;
loc_82402928:
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// stw r10,2(r8)
	PPC_STORE_U32(ctx.r8.u32 + 2, ctx.r10.u32);
	// beq cr6,0x82402940
	if (cr6.getEQ()) goto loc_82402940;
	// lhz r11,0(r8)
	r11.u64 = PPC_LOAD_U16(ctx.r8.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// sth r11,0(r8)
	PPC_STORE_U16(ctx.r8.u32 + 0, r11.u16);
loc_82402940:
	// addi r6,r6,-2
	ctx.r6.s64 = ctx.r6.s64 + -2;
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// bdnz 0x824028fc
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_824028FC;
loc_8240294C:
	// addic. r3,r3,-1
	xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// addi r8,r8,-2
	ctx.r8.s64 = ctx.r8.s64 + -2;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// bgt 0x824028e0
	if (cr0.getGT()) goto loc_824028E0;
	// clrlwi r11,r28,16
	r11.u64 = r28.u32 & 0xFFFF;
	// add r11,r11,r20
	r11.u64 = r11.u64 + r20.u64;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// extsh. r10,r11
	ctx.r10.s64 = r11.s16;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// ble 0x824029c0
	if (!cr0.getGT()) goto loc_824029C0;
loc_82402974:
	// lwz r6,104(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// rlwinm. r9,r6,0,0,0
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x824029c0
	if (!cr0.getEQ()) goto loc_824029C0;
	// lwz r7,108(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// rlwinm r9,r10,1,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// rlwinm r8,r7,1,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0x1;
	// rlwinm r7,r7,1,0,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r21
	r11.u64 = r11.u64 + r21.u64;
	// or r9,r7,r9
	ctx.r9.u64 = ctx.r7.u64 | ctx.r9.u64;
	// rlwinm r6,r6,1,0,30
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r9,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r9.u32);
	// or r9,r6,r8
	ctx.r9.u64 = ctx.r6.u64 | ctx.r8.u64;
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
	// stw r9,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r9.u32);
	// extsh. r9,r11
	ctx.r9.s64 = r11.s16;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bgt 0x82402974
	if (cr0.getGT()) goto loc_82402974;
loc_824029C0:
	// extsh. r9,r11
	ctx.r9.s64 = r11.s16;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bgt 0x82402a60
	if (cr0.getGT()) goto loc_82402A60;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// add r11,r11,r21
	r11.u64 = r11.u64 + r21.u64;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// extsh. r9,r11
	ctx.r9.s64 = r11.s16;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bge 0x82402a60
	if (!cr0.getLT()) goto loc_82402A60;
	// lwz r6,104(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r7,108(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
loc_824029E4:
	// lhz r9,114(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 114);
	// clrlwi. r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x824029f4
	if (cr0.getEQ()) goto loc_824029F4;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
loc_824029F4:
	// clrlwi. r9,r6,31
	ctx.r9.u64 = ctx.r6.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// mr r8,r14
	ctx.r8.u64 = r14.u64;
	// bne 0x82402a04
	if (!cr0.getEQ()) goto loc_82402A04;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
loc_82402A04:
	// clrlwi. r9,r7,31
	ctx.r9.u64 = ctx.r7.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// mr r9,r14
	ctx.r9.u64 = r14.u64;
	// bne 0x82402a14
	if (!cr0.getEQ()) goto loc_82402A14;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
loc_82402A14:
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// rlwinm r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// rlwinm r7,r7,31,1,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r6,r6,31,1,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 31) & 0x7FFFFFFF;
	// or r7,r7,r8
	ctx.r7.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
	// extsh. r9,r11
	ctx.r9.s64 = r11.s16;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// blt 0x824029e4
	if (cr0.getLT()) goto loc_824029E4;
	// stw r7,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, ctx.r7.u32);
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// stw r6,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, ctx.r6.u32);
	// beq cr6,0x82402a60
	if (cr6.getEQ()) goto loc_82402A60;
	// lhz r10,114(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 114);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// sth r10,114(r1)
	PPC_STORE_U16(ctx.r1.u32 + 114, ctx.r10.u16);
	// lwz r10,112(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
loc_82402A60:
	// lhz r9,114(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 114);
	// cmplwi cr6,r9,32768
	cr6.compare<uint32_t>(ctx.r9.u32, 32768, xer);
	// bgt cr6,0x82402a78
	if (cr6.getGT()) goto loc_82402A78;
	// clrlwi r10,r10,15
	ctx.r10.u64 = ctx.r10.u32 & 0x1FFFF;
	// cmplw cr6,r10,r17
	cr6.compare<uint32_t>(ctx.r10.u32, r17.u32, xer);
	// bne cr6,0x82402ad8
	if (!cr6.getEQ()) goto loc_82402AD8;
loc_82402A78:
	// lwz r10,110(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 110);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82402ad0
	if (!cr6.getEQ()) goto loc_82402AD0;
	// lwz r10,106(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 106);
	// stw r22,110(r1)
	PPC_STORE_U32(ctx.r1.u32 + 110, r22.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82402ac4
	if (!cr6.getEQ()) goto loc_82402AC4;
	// lhz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 104);
	// stw r22,106(r1)
	PPC_STORE_U32(ctx.r1.u32 + 106, r22.u32);
	// cmplwi cr6,r10,65535
	cr6.compare<uint32_t>(ctx.r10.u32, 65535, xer);
	// bne cr6,0x82402ab8
	if (!cr6.getEQ()) goto loc_82402AB8;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// sth r18,104(r1)
	PPC_STORE_U16(ctx.r1.u32 + 104, r18.u16);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// b 0x82402ad8
	goto loc_82402AD8;
loc_82402AB8:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// sth r10,104(r1)
	PPC_STORE_U16(ctx.r1.u32 + 104, ctx.r10.u16);
	// b 0x82402ad8
	goto loc_82402AD8;
loc_82402AC4:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,106(r1)
	PPC_STORE_U32(ctx.r1.u32 + 106, ctx.r10.u32);
	// b 0x82402ad8
	goto loc_82402AD8;
loc_82402AD0:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,110(r1)
	PPC_STORE_U32(ctx.r1.u32 + 110, ctx.r10.u32);
loc_82402AD8:
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// cmplwi cr6,r11,32767
	cr6.compare<uint32_t>(r11.u32, 32767, xer);
	// blt cr6,0x82402afc
	if (cr6.getLT()) goto loc_82402AFC;
	// clrlwi. r11,r26,16
	r11.u64 = r26.u32 & 0xFFFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r15,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r15.u32);
	// bne 0x82402af4
	if (!cr0.getEQ()) goto loc_82402AF4;
	// stw r16,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r16.u32);
loc_82402AF4:
	// lwz r31,372(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// b 0x82402b40
	goto loc_82402B40;
loc_82402AFC:
	// clrlwi r10,r26,16
	ctx.r10.u64 = r26.u32 & 0xFFFF;
	// lhz r9,112(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 112);
	// lwz r31,372(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// lwz r10,108(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	// sth r9,98(r1)
	PPC_STORE_U16(ctx.r1.u32 + 98, ctx.r9.u16);
	// stw r10,94(r1)
	PPC_STORE_U32(ctx.r1.u32 + 94, ctx.r10.u32);
	// lwz r10,104(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	// lwz r29,96(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// sth r11,88(r1)
	PPC_STORE_U16(ctx.r1.u32 + 88, r11.u16);
	// stw r10,90(r1)
	PPC_STORE_U32(ctx.r1.u32 + 90, ctx.r10.u32);
	// lwz r30,92(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// b 0x82402b50
	goto loc_82402B50;
loc_82402B30:
	// clrlwi. r11,r26,16
	r11.u64 = r26.u32 & 0xFFFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r15,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r15.u32);
	// bne 0x82402b40
	if (!cr0.getEQ()) goto loc_82402B40;
	// stw r16,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r16.u32);
loc_82402B40:
	// mr r29,r22
	r29.u64 = r22.u64;
	// mr r30,r22
	r30.u64 = r22.u64;
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
loc_82402B50:
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bne cr6,0x824027c8
	if (!cr6.getEQ()) goto loc_824027C8;
	// b 0x82402b64
	goto loc_82402B64;
loc_82402B5C:
	// lwz r29,96(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r30,92(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
loc_82402B64:
	// lhz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 88);
	// cmplwi cr6,r9,16383
	cr6.compare<uint32_t>(ctx.r9.u32, 16383, xer);
	// blt cr6,0x82402eb8
	if (cr6.getLT()) goto loc_82402EB8;
	// addi r8,r24,1
	ctx.r8.s64 = r24.s64 + 1;
	// lhz r11,136(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 136);
	// clrlwi r10,r9,17
	ctx.r10.u64 = ctx.r9.u32 & 0x7FFF;
	// stw r22,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r22.u32);
	// extsh r19,r8
	r19.s64 = ctx.r8.s16;
	// stw r22,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r22.u32);
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
	// stw r22,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r22.u32);
	// xor r11,r11,r9
	r11.u64 = r11.u64 ^ ctx.r9.u64;
	// mr r27,r22
	r27.u64 = r22.u64;
	// rlwinm r26,r11,0,16,16
	r26.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	// clrlwi r11,r8,17
	r11.u64 = ctx.r8.u32 & 0x7FFF;
	// cmplwi cr6,r10,32767
	cr6.compare<uint32_t>(ctx.r10.u32, 32767, xer);
	// add r9,r10,r11
	ctx.r9.u64 = ctx.r10.u64 + r11.u64;
	// clrlwi r28,r9,16
	r28.u64 = ctx.r9.u32 & 0xFFFF;
	// bge cr6,0x82402ea0
	if (!cr6.getLT()) goto loc_82402EA0;
	// cmplwi cr6,r11,32767
	cr6.compare<uint32_t>(r11.u32, 32767, xer);
	// bge cr6,0x82402ea0
	if (!cr6.getLT()) goto loc_82402EA0;
	// clrlwi r9,r28,16
	ctx.r9.u64 = r28.u32 & 0xFFFF;
	// cmplwi cr6,r9,49149
	cr6.compare<uint32_t>(ctx.r9.u32, 49149, xer);
	// bgt cr6,0x82402ea0
	if (cr6.getGT()) goto loc_82402EA0;
	// cmplwi cr6,r9,16319
	cr6.compare<uint32_t>(ctx.r9.u32, 16319, xer);
	// bgt cr6,0x82402bd4
	if (cr6.getGT()) goto loc_82402BD4;
loc_82402BCC:
	// stw r22,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r22.u32);
	// b 0x82402eb0
	goto loc_82402EB0;
loc_82402BD4:
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne cr6,0x82402c08
	if (!cr6.getEQ()) goto loc_82402C08;
	// addi r10,r9,1
	ctx.r10.s64 = ctx.r9.s64 + 1;
	// lwz r9,88(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// clrlwi r28,r10,16
	r28.u64 = ctx.r10.u32 & 0xFFFF;
	// clrlwi. r9,r9,1
	ctx.r9.u64 = ctx.r9.u32 & 0x7FFFFFFF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x82402c08
	if (!cr0.getEQ()) goto loc_82402C08;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x82402c08
	if (!cr6.getEQ()) goto loc_82402C08;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x82402c08
	if (!cr6.getEQ()) goto loc_82402C08;
	// sth r22,88(r1)
	PPC_STORE_U16(ctx.r1.u32 + 88, r22.u16);
	// b 0x82402eb8
	goto loc_82402EB8;
loc_82402C08:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82402c40
	if (!cr6.getEQ()) goto loc_82402C40;
	// lwz r10,136(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 136);
	// clrlwi r11,r28,16
	r11.u64 = r28.u32 & 0xFFFF;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// clrlwi r28,r11,16
	r28.u64 = r11.u32 & 0xFFFF;
	// clrlwi. r10,r10,1
	ctx.r10.u64 = ctx.r10.u32 & 0x7FFFFFFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82402c40
	if (!cr0.getEQ()) goto loc_82402C40;
	// lwz r11,140(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 140);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82402c40
	if (!cr6.getEQ()) goto loc_82402C40;
	// lwz r11,144(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 144);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82402bcc
	if (cr6.getEQ()) goto loc_82402BCC;
loc_82402C40:
	// mr r31,r22
	r31.u64 = r22.u64;
	// addi r8,r1,126
	ctx.r8.s64 = ctx.r1.s64 + 126;
	// li r4,5
	ctx.r4.s64 = 5;
loc_82402C4C:
	// rlwinm r11,r31,1,0,30
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// cmpwi cr6,r4,0
	cr6.compare<int32_t>(ctx.r4.s32, 0, xer);
	// ble cr6,0x82402cbc
	if (!cr6.getGT()) goto loc_82402CBC;
	// addi r10,r1,98
	ctx.r10.s64 = ctx.r1.s64 + 98;
	// addi r5,r1,138
	ctx.r5.s64 = ctx.r1.s64 + 138;
	// subf r6,r11,r10
	ctx.r6.s64 = ctx.r10.s64 - r11.s64;
loc_82402C68:
	// lhz r10,0(r5)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r5.u32 + 0);
	// mr r7,r22
	ctx.r7.u64 = r22.u64;
	// lhz r9,0(r6)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r6.u32 + 0);
	// lwz r11,2(r8)
	r11.u64 = PPC_LOAD_U32(ctx.r8.u32 + 2);
	// mullw r9,r10,r9
	ctx.r9.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
	// add r10,r11,r9
	ctx.r10.u64 = r11.u64 + ctx.r9.u64;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// blt cr6,0x82402c90
	if (cr6.getLT()) goto loc_82402C90;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x82402c94
	if (!cr6.getLT()) goto loc_82402C94;
loc_82402C90:
	// li r7,1
	ctx.r7.s64 = 1;
loc_82402C94:
	// cmpwi cr6,r7,0
	cr6.compare<int32_t>(ctx.r7.s32, 0, xer);
	// stw r10,2(r8)
	PPC_STORE_U32(ctx.r8.u32 + 2, ctx.r10.u32);
	// beq cr6,0x82402cac
	if (cr6.getEQ()) goto loc_82402CAC;
	// lhz r11,0(r8)
	r11.u64 = PPC_LOAD_U16(ctx.r8.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// sth r11,0(r8)
	PPC_STORE_U16(ctx.r8.u32 + 0, r11.u16);
loc_82402CAC:
	// addic. r3,r3,-1
	xer.ca = ctx.r3.u32 > 0;
	ctx.r3.s64 = ctx.r3.s64 + -1;
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// addi r6,r6,-2
	ctx.r6.s64 = ctx.r6.s64 + -2;
	// addi r5,r5,2
	ctx.r5.s64 = ctx.r5.s64 + 2;
	// bgt 0x82402c68
	if (cr0.getGT()) goto loc_82402C68;
loc_82402CBC:
	// addic. r4,r4,-1
	xer.ca = ctx.r4.u32 > 0;
	ctx.r4.s64 = ctx.r4.s64 + -1;
	cr0.compare<int32_t>(ctx.r4.s32, 0, xer);
	// addi r8,r8,-2
	ctx.r8.s64 = ctx.r8.s64 + -2;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// bgt 0x82402c4c
	if (cr0.getGT()) goto loc_82402C4C;
	// clrlwi r11,r28,16
	r11.u64 = r28.u32 & 0xFFFF;
	// add r11,r11,r20
	r11.u64 = r11.u64 + r20.u64;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// extsh. r10,r11
	ctx.r10.s64 = r11.s16;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
	// ble 0x82402d30
	if (!cr0.getGT()) goto loc_82402D30;
loc_82402CE4:
	// lwz r6,120(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// rlwinm. r9,r6,0,0,0
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x82402d30
	if (!cr0.getEQ()) goto loc_82402D30;
	// lwz r7,124(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// rlwinm r9,r10,1,31,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// rlwinm r8,r7,1,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0x1;
	// rlwinm r7,r7,1,0,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// add r11,r11,r21
	r11.u64 = r11.u64 + r21.u64;
	// or r9,r7,r9
	ctx.r9.u64 = ctx.r7.u64 | ctx.r9.u64;
	// rlwinm r6,r6,1,0,30
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 1) & 0xFFFFFFFE;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// stw r9,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r9.u32);
	// or r9,r6,r8
	ctx.r9.u64 = ctx.r6.u64 | ctx.r8.u64;
	// stw r10,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r10.u32);
	// stw r9,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r9.u32);
	// extsh. r9,r11
	ctx.r9.s64 = r11.s16;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bgt 0x82402ce4
	if (cr0.getGT()) goto loc_82402CE4;
loc_82402D30:
	// extsh. r9,r11
	ctx.r9.s64 = r11.s16;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bgt 0x82402dd0
	if (cr0.getGT()) goto loc_82402DD0;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// add r11,r11,r21
	r11.u64 = r11.u64 + r21.u64;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// extsh. r9,r11
	ctx.r9.s64 = r11.s16;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bge 0x82402dd0
	if (!cr0.getLT()) goto loc_82402DD0;
	// lwz r6,120(r1)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r7,124(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
loc_82402D54:
	// lhz r9,130(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 130);
	// clrlwi. r9,r9,31
	ctx.r9.u64 = ctx.r9.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82402d64
	if (cr0.getEQ()) goto loc_82402D64;
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
loc_82402D64:
	// clrlwi. r9,r6,31
	ctx.r9.u64 = ctx.r6.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// mr r8,r14
	ctx.r8.u64 = r14.u64;
	// bne 0x82402d74
	if (!cr0.getEQ()) goto loc_82402D74;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
loc_82402D74:
	// clrlwi. r9,r7,31
	ctx.r9.u64 = ctx.r7.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// mr r9,r14
	ctx.r9.u64 = r14.u64;
	// bne 0x82402d84
	if (!cr0.getEQ()) goto loc_82402D84;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
loc_82402D84:
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// rlwinm r10,r10,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x7FFFFFFF;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// rlwinm r7,r7,31,1,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r6,r6,31,1,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 31) & 0x7FFFFFFF;
	// or r7,r7,r8
	ctx.r7.u64 = ctx.r7.u64 | ctx.r8.u64;
	// stw r10,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r10.u32);
	// extsh. r9,r11
	ctx.r9.s64 = r11.s16;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// blt 0x82402d54
	if (cr0.getLT()) goto loc_82402D54;
	// stw r7,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r7.u32);
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// stw r6,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, ctx.r6.u32);
	// beq cr6,0x82402dd0
	if (cr6.getEQ()) goto loc_82402DD0;
	// lhz r10,130(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 130);
	// ori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 | 1;
	// sth r10,130(r1)
	PPC_STORE_U16(ctx.r1.u32 + 130, ctx.r10.u16);
	// lwz r10,128(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 128);
loc_82402DD0:
	// lhz r9,130(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 130);
	// cmplwi cr6,r9,32768
	cr6.compare<uint32_t>(ctx.r9.u32, 32768, xer);
	// bgt cr6,0x82402de8
	if (cr6.getGT()) goto loc_82402DE8;
	// clrlwi r10,r10,15
	ctx.r10.u64 = ctx.r10.u32 & 0x1FFFF;
	// cmplw cr6,r10,r17
	cr6.compare<uint32_t>(ctx.r10.u32, r17.u32, xer);
	// bne cr6,0x82402e48
	if (!cr6.getEQ()) goto loc_82402E48;
loc_82402DE8:
	// lwz r10,126(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 126);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82402e40
	if (!cr6.getEQ()) goto loc_82402E40;
	// lwz r10,122(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 122);
	// stw r22,126(r1)
	PPC_STORE_U32(ctx.r1.u32 + 126, r22.u32);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// bne cr6,0x82402e34
	if (!cr6.getEQ()) goto loc_82402E34;
	// lhz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 120);
	// stw r22,122(r1)
	PPC_STORE_U32(ctx.r1.u32 + 122, r22.u32);
	// cmplwi cr6,r10,65535
	cr6.compare<uint32_t>(ctx.r10.u32, 65535, xer);
	// bne cr6,0x82402e28
	if (!cr6.getEQ()) goto loc_82402E28;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// sth r18,120(r1)
	PPC_STORE_U16(ctx.r1.u32 + 120, r18.u16);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// b 0x82402e48
	goto loc_82402E48;
loc_82402E28:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// sth r10,120(r1)
	PPC_STORE_U16(ctx.r1.u32 + 120, ctx.r10.u16);
	// b 0x82402e48
	goto loc_82402E48;
loc_82402E34:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,122(r1)
	PPC_STORE_U32(ctx.r1.u32 + 122, ctx.r10.u32);
	// b 0x82402e48
	goto loc_82402E48;
loc_82402E40:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r10,126(r1)
	PPC_STORE_U32(ctx.r1.u32 + 126, ctx.r10.u32);
loc_82402E48:
	// clrlwi r11,r11,16
	r11.u64 = r11.u32 & 0xFFFF;
	// cmplwi cr6,r11,32767
	cr6.compare<uint32_t>(r11.u32, 32767, xer);
	// blt cr6,0x82402e6c
	if (cr6.getLT()) goto loc_82402E6C;
	// clrlwi. r11,r26,16
	r11.u64 = r26.u32 & 0xFFFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r15,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r15.u32);
	// bne 0x82402e64
	if (!cr0.getEQ()) goto loc_82402E64;
	// stw r16,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r16.u32);
loc_82402E64:
	// lwz r31,372(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// b 0x82402eb0
	goto loc_82402EB0;
loc_82402E6C:
	// clrlwi r10,r26,16
	ctx.r10.u64 = r26.u32 & 0xFFFF;
	// lhz r9,128(r1)
	ctx.r9.u64 = PPC_LOAD_U16(ctx.r1.u32 + 128);
	// lwz r31,372(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// lwz r10,124(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// sth r9,98(r1)
	PPC_STORE_U16(ctx.r1.u32 + 98, ctx.r9.u16);
	// stw r10,94(r1)
	PPC_STORE_U32(ctx.r1.u32 + 94, ctx.r10.u32);
	// lwz r10,120(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 120);
	// lwz r29,96(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// sth r11,88(r1)
	PPC_STORE_U16(ctx.r1.u32 + 88, r11.u16);
	// stw r10,90(r1)
	PPC_STORE_U32(ctx.r1.u32 + 90, ctx.r10.u32);
	// lwz r30,92(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// b 0x82402eb8
	goto loc_82402EB8;
loc_82402EA0:
	// clrlwi. r11,r26,16
	r11.u64 = r26.u32 & 0xFFFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r15,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r15.u32);
	// bne 0x82402eb0
	if (!cr0.getEQ()) goto loc_82402EB0;
	// stw r16,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r16.u32);
loc_82402EB0:
	// mr r29,r22
	r29.u64 = r22.u64;
	// mr r30,r22
	r30.u64 = r22.u64;
loc_82402EB8:
	// lwz r11,364(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 364);
	// sth r19,0(r31)
	PPC_STORE_U16(r31.u32 + 0, r19.u16);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82402f04
	if (cr0.getEQ()) goto loc_82402F04;
	// lwz r10,356(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// extsh r11,r19
	r11.s64 = r19.s16;
	// add. r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,356(r1)
	PPC_STORE_U32(ctx.r1.u32 + 356, r11.u32);
	// bgt 0x82402f08
	if (cr0.getGT()) goto loc_82402F08;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// sth r22,0(r31)
	PPC_STORE_U16(r31.u32 + 0, r22.u16);
	// cmplwi cr6,r11,32768
	cr6.compare<uint32_t>(r11.u32, 32768, xer);
	// li r11,45
	r11.s64 = 45;
	// beq cr6,0x82402ef4
	if (cr6.getEQ()) goto loc_82402EF4;
	// li r11,32
	r11.s64 = 32;
loc_82402EF4:
	// stb r11,2(r31)
	PPC_STORE_U8(r31.u32 + 2, r11.u8);
	// li r11,1
	r11.s64 = 1;
	// stb r11,3(r31)
	PPC_STORE_U8(r31.u32 + 3, r11.u8);
	// b 0x82402620
	goto loc_82402620;
loc_82402F04:
	// lwz r11,356(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
loc_82402F08:
	// cmpwi cr6,r11,21
	cr6.compare<int32_t>(r11.s32, 21, xer);
	// ble cr6,0x82402f18
	if (!cr6.getGT()) goto loc_82402F18;
	// li r11,21
	r11.s64 = 21;
	// stw r11,356(r1)
	PPC_STORE_U32(ctx.r1.u32 + 356, r11.u32);
loc_82402F18:
	// lhz r11,88(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 88);
	// sth r22,88(r1)
	PPC_STORE_U16(ctx.r1.u32 + 88, r22.u16);
	// addi r8,r11,-16382
	ctx.r8.s64 = r11.s64 + -16382;
	// lwz r31,88(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// li r11,8
	r11.s64 = 8;
loc_82402F2C:
	// rlwinm r10,r29,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0x1;
	// rlwinm r9,r30,1,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0x1;
	// rlwinm r7,r30,1,0,30
	ctx.r7.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r6,r31,1,0,30
	ctx.r6.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r29,r29,1,0,30
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// or r30,r7,r10
	r30.u64 = ctx.r7.u64 | ctx.r10.u64;
	// or r31,r6,r9
	r31.u64 = ctx.r6.u64 | ctx.r9.u64;
	// bne 0x82402f2c
	if (!cr0.getEQ()) goto loc_82402F2C;
	// stw r31,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r31.u32);
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// bge cr6,0x82402fb8
	if (!cr6.getLT()) goto loc_82402FB8;
	// neg r11,r8
	r11.s64 = -ctx.r8.s64;
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// ble 0x82402fb8
	if (!cr0.getGT()) goto loc_82402FB8;
loc_82402F70:
	// clrlwi. r10,r31,31
	ctx.r10.u64 = r31.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// mr r9,r14
	ctx.r9.u64 = r14.u64;
	// bne 0x82402f80
	if (!cr0.getEQ()) goto loc_82402F80;
	// mr r9,r22
	ctx.r9.u64 = r22.u64;
loc_82402F80:
	// clrlwi. r10,r30,31
	ctx.r10.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// mr r10,r14
	ctx.r10.u64 = r14.u64;
	// bne 0x82402f90
	if (!cr0.getEQ()) goto loc_82402F90;
	// mr r10,r22
	ctx.r10.u64 = r22.u64;
loc_82402F90:
	// rlwinm r8,r30,31,1,31
	ctx.r8.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 31) & 0x7FFFFFFF;
	// rlwinm r7,r29,31,1,31
	ctx.r7.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 31) & 0x7FFFFFFF;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// rlwinm r31,r31,31,1,31
	r31.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 31) & 0x7FFFFFFF;
	// or r30,r8,r9
	r30.u64 = ctx.r8.u64 | ctx.r9.u64;
	// or r29,r7,r10
	r29.u64 = ctx.r7.u64 | ctx.r10.u64;
	// bgt 0x82402f70
	if (cr0.getGT()) goto loc_82402F70;
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// stw r31,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r31.u32);
loc_82402FB8:
	// lwz r11,372(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// addi r26,r11,4
	r26.s64 = r11.s64 + 4;
	// lwz r11,356(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 356);
	// addic. r28,r11,1
	xer.ca = r11.u32 > 4294967294;
	r28.s64 = r11.s64 + 1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// mr r27,r26
	r27.u64 = r26.u64;
	// ble 0x824030cc
	if (!cr0.getGT()) goto loc_824030CC;
	// b 0x82402fd8
	goto loc_82402FD8;
loc_82402FD4:
	// lwz r31,88(r1)
	r31.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
loc_82402FD8:
	// addi r3,r1,152
	ctx.r3.s64 = ctx.r1.s64 + 152;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// li r5,12
	ctx.r5.s64 = 12;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// rlwinm r6,r30,1,0,30
	ctx.r6.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r11,r29,1,0,30
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r5,160(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 160);
	// rlwinm r10,r29,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0x1;
	// rlwinm r8,r30,1,31,31
	ctx.r8.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0x1;
	// rlwinm r4,r31,1,0,30
	ctx.r4.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 1) & 0xFFFFFFFE;
	// or r10,r6,r10
	ctx.r10.u64 = ctx.r6.u64 | ctx.r10.u64;
	// rlwinm r7,r11,1,31,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// or r8,r4,r8
	ctx.r8.u64 = ctx.r4.u64 | ctx.r8.u64;
	// rlwinm r6,r10,1,31,31
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0x1;
	// add r9,r5,r11
	ctx.r9.u64 = ctx.r5.u64 + r11.u64;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r8,r8,1,0,30
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 1) & 0xFFFFFFFE;
	// or r10,r10,r7
	ctx.r10.u64 = ctx.r10.u64 | ctx.r7.u64;
	// cmplw cr6,r9,r11
	cr6.compare<uint32_t>(ctx.r9.u32, r11.u32, xer);
	// or r6,r8,r6
	ctx.r6.u64 = ctx.r8.u64 | ctx.r6.u64;
	// blt cr6,0x82403038
	if (cr6.getLT()) goto loc_82403038;
	// cmplw cr6,r9,r5
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r5.u32, xer);
	// bge cr6,0x82403064
	if (!cr6.getLT()) goto loc_82403064;
loc_82403038:
	// addi r11,r10,1
	r11.s64 = ctx.r10.s64 + 1;
	// mr r8,r22
	ctx.r8.u64 = r22.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x82403050
	if (cr6.getLT()) goto loc_82403050;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bge cr6,0x82403054
	if (!cr6.getLT()) goto loc_82403054;
loc_82403050:
	// li r8,1
	ctx.r8.s64 = 1;
loc_82403054:
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq cr6,0x82403064
	if (cr6.getEQ()) goto loc_82403064;
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
loc_82403064:
	// lwz r8,156(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// add r11,r8,r10
	r11.u64 = ctx.r8.u64 + ctx.r10.u64;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// blt cr6,0x8240307c
	if (cr6.getLT()) goto loc_8240307C;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// bge cr6,0x82403080
	if (!cr6.getLT()) goto loc_82403080;
loc_8240307C:
	// addi r6,r6,1
	ctx.r6.s64 = ctx.r6.s64 + 1;
loc_82403080:
	// lwz r7,152(r1)
	ctx.r7.u64 = PPC_LOAD_U32(ctx.r1.u32 + 152);
	// rlwinm r10,r11,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// rlwinm r8,r9,1,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0x1;
	// add r7,r7,r6
	ctx.r7.u64 = ctx.r7.u64 + ctx.r6.u64;
	// rlwinm r6,r11,1,0,30
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r7,r7,1,0,30
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// rlwinm r29,r9,1,0,30
	r29.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0xFFFFFFFE;
	// or r11,r7,r10
	r11.u64 = ctx.r7.u64 | ctx.r10.u64;
	// or r30,r6,r8
	r30.u64 = ctx.r6.u64 | ctx.r8.u64;
	// addic. r28,r28,-1
	xer.ca = r28.u32 > 0;
	r28.s64 = r28.s64 + -1;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// stw r29,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r29.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// lbz r11,88(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 88);
	// stw r30,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r30.u32);
	// addi r11,r11,48
	r11.s64 = r11.s64 + 48;
	// stb r22,88(r1)
	PPC_STORE_U8(ctx.r1.u32 + 88, r22.u8);
	// stb r11,0(r27)
	PPC_STORE_U8(r27.u32 + 0, r11.u8);
	// addi r27,r27,1
	r27.s64 = r27.s64 + 1;
	// bgt 0x82402fd4
	if (cr0.getGT()) goto loc_82402FD4;
loc_824030CC:
	// addi r11,r27,-1
	r11.s64 = r27.s64 + -1;
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// cmpwi cr6,r10,53
	cr6.compare<int32_t>(ctx.r10.s32, 53, xer);
	// blt cr6,0x82403144
	if (cr6.getLT()) goto loc_82403144;
	// b 0x82403100
	goto loc_82403100;
loc_824030E8:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,57
	cr6.compare<uint32_t>(ctx.r10.u32, 57, xer);
	// bne cr6,0x82403108
	if (!cr6.getEQ()) goto loc_82403108;
	// li r10,48
	ctx.r10.s64 = 48;
	// stb r10,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r10.u8);
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
loc_82403100:
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// bge cr6,0x824030e8
	if (!cr6.getLT()) goto loc_824030E8;
loc_82403108:
	// lwz r9,372(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// bge cr6,0x82403124
	if (!cr6.getLT()) goto loc_82403124;
	// lhz r10,0(r9)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r9.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// sth r10,0(r9)
	PPC_STORE_U16(ctx.r9.u32 + 0, ctx.r10.u16);
loc_82403124:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stb r10,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r10.u8);
	// b 0x82403194
	goto loc_82403194;
loc_82403134:
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,48
	cr6.compare<uint32_t>(ctx.r10.u32, 48, xer);
	// bne cr6,0x8240314c
	if (!cr6.getEQ()) goto loc_8240314C;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
loc_82403144:
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// bge cr6,0x82403134
	if (!cr6.getLT()) goto loc_82403134;
loc_8240314C:
	// cmplw cr6,r11,r26
	cr6.compare<uint32_t>(r11.u32, r26.u32, xer);
	// bge cr6,0x82403190
	if (!cr6.getLT()) goto loc_82403190;
	// lwz r10,372(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,32768
	cr6.compare<uint32_t>(r11.u32, 32768, xer);
	// li r11,45
	r11.s64 = 45;
	// sth r22,0(r10)
	PPC_STORE_U16(ctx.r10.u32 + 0, r22.u16);
	// beq cr6,0x82403170
	if (cr6.getEQ()) goto loc_82403170;
	// li r11,32
	r11.s64 = 32;
loc_82403170:
	// stb r11,2(r10)
	PPC_STORE_U8(ctx.r10.u32 + 2, r11.u8);
	// li r9,48
	ctx.r9.s64 = 48;
	// li r11,1
	r11.s64 = 1;
	// stb r22,5(r10)
	PPC_STORE_U8(ctx.r10.u32 + 5, r22.u8);
	// li r3,1
	ctx.r3.s64 = 1;
	// stb r9,0(r26)
	PPC_STORE_U8(r26.u32 + 0, ctx.r9.u8);
	// stb r11,3(r10)
	PPC_STORE_U8(ctx.r10.u32 + 3, r11.u8);
	// b 0x824031b0
	goto loc_824031B0;
loc_82403190:
	// lwz r9,372(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 372);
loc_82403194:
	// subf r11,r9,r11
	r11.s64 = r11.s64 - ctx.r9.s64;
	// lwz r3,84(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// addi r11,r11,-3
	r11.s64 = r11.s64 + -3;
	// extsb r11,r11
	r11.s64 = r11.s8;
	// add r10,r11,r9
	ctx.r10.u64 = r11.u64 + ctx.r9.u64;
	// stb r11,3(r9)
	PPC_STORE_U8(ctx.r9.u32 + 3, r11.u8);
	// stb r22,4(r10)
	PPC_STORE_U8(ctx.r10.u32 + 4, r22.u8);
loc_824031B0:
	// addi r1,r1,320
	ctx.r1.s64 = ctx.r1.s64 + 320;
	// b 0x823ed150
	return;
}

__attribute__((alias("__imp__sub_824031B8"))) PPC_WEAK_FUNC(sub_824031B8);
PPC_FUNC_IMPL(__imp__sub_824031B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,-1
	r30.s64 = -1;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82403204
	if (!cr6.getEQ()) goto loc_82403204;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82403264
	goto loc_82403264;
loc_82403204:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r29,0
	r29.s64 = 0;
	// andi. r11,r11,131
	r11.u64 = r11.u64 & 131;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240325c
	if (cr0.getEQ()) goto loc_8240325C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe320
	sub_823FE320(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824045a0
	sub_824045A0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// bl 0x82404428
	sub_82404428(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82403248
	if (!cr0.getLT()) goto loc_82403248;
	// li r30,-1
	r30.s64 = -1;
	// b 0x8240325c
	goto loc_8240325C;
loc_82403248:
	// lwz r3,28(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x8240325c
	if (cr0.getEQ()) goto loc_8240325C;
	// bl 0x823ed250
	sub_823ED250(ctx, base);
	// stw r29,28(r31)
	PPC_STORE_U32(r31.u32 + 28, r29.u32);
loc_8240325C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// stw r29,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r29.u32);
loc_82403264:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82403270"))) PPC_WEAK_FUNC(sub_82403270);
PPC_FUNC_IMPL(__imp__sub_82403270) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r18{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// lwz r18,-1044(0)
	r18.u64 = PPC_LOAD_U32(-1044);
	// lwz r16,29928(r7)
	r16.u64 = PPC_LOAD_U32(ctx.r7.u32 + 29928);
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// addi r31,r1,-112
	r31.s64 = ctx.r1.s64 + -112;
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r30,132(r31)
	PPC_STORE_U32(r31.u32 + 132, r30.u32);
	// cntlzw r11,r30
	r11.u64 = r30.u32 == 0 ? 32 : __builtin_clz(r30.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r10,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r10.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824032e4
	if (!cr0.getEQ()) goto loc_824032E4;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82403324
	goto loc_82403324;
loc_824032E4:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824032fc
	if (cr0.getEQ()) goto loc_824032FC;
	// li r11,0
	r11.s64 = 0;
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
	// b 0x82403320
	goto loc_82403320;
loc_824032FC:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f4f98
	sub_823F4F98(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x824031b8
	sub_824031B8(ctx, base);
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,112
	r12.s64 = r31.s64 + 112;
	// bl 0x8240335c
	sub_8240335C(ctx, base);
loc_82403320:
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
loc_82403324:
	// addi r1,r31,112
	ctx.r1.s64 = r31.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82403278"))) PPC_WEAK_FUNC(sub_82403278);
PPC_FUNC_IMPL(__imp__sub_82403278) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// addi r31,r1,-112
	r31.s64 = ctx.r1.s64 + -112;
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r30,132(r31)
	PPC_STORE_U32(r31.u32 + 132, r30.u32);
	// cntlzw r11,r30
	r11.u64 = r30.u32 == 0 ? 32 : __builtin_clz(r30.u32);
	// li r10,-1
	ctx.r10.s64 = -1;
	// stw r10,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r10.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824032e4
	if (!cr0.getEQ()) goto loc_824032E4;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82403324
	goto loc_82403324;
loc_824032E4:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824032fc
	if (cr0.getEQ()) goto loc_824032FC;
	// li r11,0
	r11.s64 = 0;
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
	// b 0x82403320
	goto loc_82403320;
loc_824032FC:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f4f98
	sub_823F4F98(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x824031b8
	sub_824031B8(ctx, base);
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,112
	r12.s64 = r31.s64 + 112;
	// bl 0x8240335c
	sub_8240335C(ctx, base);
loc_82403320:
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
loc_82403324:
	// addi r1,r31,112
	ctx.r1.s64 = r31.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240333C"))) PPC_WEAK_FUNC(sub_8240333C);
PPC_FUNC_IMPL(__imp__sub_8240333C) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-112
	r31.s64 = r12.s64 + -112;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,132(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 132);
	// b 0x82403374
	goto loc_82403374;
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-112
	r31.s64 = r12.s64 + -112;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
loc_82403374:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5058
	sub_823F5058(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240335C"))) PPC_WEAK_FUNC(sub_8240335C);
PPC_FUNC_IMPL(__imp__sub_8240335C) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-112
	r31.s64 = r12.s64 + -112;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5058
	sub_823F5058(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82403398"))) PPC_WEAK_FUNC(sub_82403398);
PPC_FUNC_IMPL(__imp__sub_82403398) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r18{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// lwz r18,-1044(0)
	r18.u64 = PPC_LOAD_U32(-1044);
	// lwz r16,29952(r7)
	r16.u64 = PPC_LOAD_U32(ctx.r7.u32 + 29952);
	// mflr r12
	// bl 0x823ed134
	// addi r31,r1,-144
	r31.s64 = ctx.r1.s64 + -144;
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// stw r27,164(r31)
	PPC_STORE_U32(r31.u32 + 164, r27.u32);
	// cmpwi cr6,r27,-2
	cr6.compare<int32_t>(r27.s32, -2, xer);
	// bne cr6,0x824033d8
	if (!cr6.getEQ()) goto loc_824033D8;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x824034c4
	goto loc_824034C4;
loc_824033D8:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// blt cr6,0x824033f0
	if (cr6.getLT()) goto loc_824033F0;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// lwz r11,-15860(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -15860);
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x82403420
	if (cr6.getLT()) goto loc_82403420;
loc_824033F0:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x824034c4
	goto loc_824034C4;
loc_82403420:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r30,r11,-15840
	r30.s64 = r11.s64 + -15840;
	// srawi r11,r27,5
	xer.ca = (r27.s32 < 0) & ((r27.u32 & 0x1F) != 0);
	r11.s64 = r27.s32 >> 5;
	// rlwinm r28,r11,2,0,29
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r29,r27,6,21,25
	r29.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r28,r30
	r11.u64 = PPC_LOAD_U32(r28.u32 + r30.u32);
	// add r11,r29,r11
	r11.u64 = r29.u64 + r11.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824033f0
	if (cr0.getEQ()) goto loc_824033F0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82403690
	sub_82403690(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwzx r11,r28,r30
	r11.u64 = PPC_LOAD_U32(r28.u32 + r30.u32);
	// add r11,r29,r11
	r11.u64 = r29.u64 + r11.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824034a0
	if (cr0.getEQ()) goto loc_824034A0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x824035c0
	sub_824035C0(ctx, base);
	// bl 0x82408740
	sub_82408740(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82403488
	if (!cr0.getEQ()) goto loc_82403488;
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8240348c
	goto loc_8240348C;
loc_82403488:
	// li r30,0
	r30.s64 = 0;
loc_8240348C:
	// stw r30,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r30.u32);
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x824034b4
	if (cr6.getEQ()) goto loc_824034B4;
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_824034A0:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,9
	r11.s64 = 9;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// li r11,-1
	r11.s64 = -1;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
loc_824034B4:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,144
	r12.s64 = r31.s64 + 144;
	// bl 0x824034ec
	sub_824034EC(ctx, base);
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
loc_824034C4:
	// addi r1,r31,144
	ctx.r1.s64 = r31.s64 + 144;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_824033A0"))) PPC_WEAK_FUNC(sub_824033A0);
PPC_FUNC_IMPL(__imp__sub_824033A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// addi r31,r1,-144
	r31.s64 = ctx.r1.s64 + -144;
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// stw r27,164(r31)
	PPC_STORE_U32(r31.u32 + 164, r27.u32);
	// cmpwi cr6,r27,-2
	cr6.compare<int32_t>(r27.s32, -2, xer);
	// bne cr6,0x824033d8
	if (!cr6.getEQ()) goto loc_824033D8;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x824034c4
	goto loc_824034C4;
loc_824033D8:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// blt cr6,0x824033f0
	if (cr6.getLT()) goto loc_824033F0;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// lwz r11,-15860(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -15860);
	// cmplw cr6,r27,r11
	cr6.compare<uint32_t>(r27.u32, r11.u32, xer);
	// blt cr6,0x82403420
	if (cr6.getLT()) goto loc_82403420;
loc_824033F0:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x824034c4
	goto loc_824034C4;
loc_82403420:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r30,r11,-15840
	r30.s64 = r11.s64 + -15840;
	// srawi r11,r27,5
	xer.ca = (r27.s32 < 0) & ((r27.u32 & 0x1F) != 0);
	r11.s64 = r27.s32 >> 5;
	// rlwinm r28,r11,2,0,29
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r29,r27,6,21,25
	r29.u64 = __builtin_rotateleft64(r27.u32 | (r27.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r28,r30
	r11.u64 = PPC_LOAD_U32(r28.u32 + r30.u32);
	// add r11,r29,r11
	r11.u64 = r29.u64 + r11.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824033f0
	if (cr0.getEQ()) goto loc_824033F0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82403690
	sub_82403690(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwzx r11,r28,r30
	r11.u64 = PPC_LOAD_U32(r28.u32 + r30.u32);
	// add r11,r29,r11
	r11.u64 = r29.u64 + r11.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824034a0
	if (cr0.getEQ()) goto loc_824034A0;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x824035c0
	sub_824035C0(ctx, base);
	// bl 0x82408740
	sub_82408740(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82403488
	if (!cr0.getEQ()) goto loc_82403488;
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8240348c
	goto loc_8240348C;
loc_82403488:
	// li r30,0
	r30.s64 = 0;
loc_8240348C:
	// stw r30,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r30.u32);
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x824034b4
	if (cr6.getEQ()) goto loc_824034B4;
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// stw r30,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r30.u32);
loc_824034A0:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,9
	r11.s64 = 9;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// li r11,-1
	r11.s64 = -1;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
loc_824034B4:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,144
	r12.s64 = r31.s64 + 144;
	// bl 0x824034ec
	sub_824034EC(ctx, base);
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
loc_824034C4:
	// addi r1,r31,144
	ctx.r1.s64 = r31.s64 + 144;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_824034CC"))) PPC_WEAK_FUNC(sub_824034CC);
PPC_FUNC_IMPL(__imp__sub_824034CC) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-144
	r31.s64 = r12.s64 + -144;
	// std r27,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r27.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r27,164(r31)
	r27.u64 = PPC_LOAD_U32(r31.u32 + 164);
	// b 0x82403504
	goto loc_82403504;
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-144
	r31.s64 = r12.s64 + -144;
	// std r27,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r27.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
loc_82403504:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82403788
	sub_82403788(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r27,-16(r1)
	r27.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824034EC"))) PPC_WEAK_FUNC(sub_824034EC);
PPC_FUNC_IMPL(__imp__sub_824034EC) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-144
	r31.s64 = r12.s64 + -144;
	// std r27,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r27.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82403788
	sub_82403788(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r27,-16(r1)
	r27.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82403528"))) PPC_WEAK_FUNC(sub_82403528);
PPC_FUNC_IMPL(__imp__sub_82403528) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x8240358c
	if (cr6.getLT()) goto loc_8240358C;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// lwz r11,-15860(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -15860);
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// bge cr6,0x8240358c
	if (!cr6.getLT()) goto loc_8240358C;
	// srawi r10,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	ctx.r10.s64 = ctx.r3.s32 >> 5;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-15840
	r11.s64 = r11.s64 + -15840;
	// rlwinm r10,r3,6,21,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lbz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8240358c
	if (cr0.getEQ()) goto loc_8240358C;
	// lwz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// cmpwi cr6,r10,-1
	cr6.compare<int32_t>(ctx.r10.s32, -1, xer);
	// beq cr6,0x8240358c
	if (cr6.getEQ()) goto loc_8240358C;
	// li r10,-1
	ctx.r10.s64 = -1;
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x824035a8
	goto loc_824035A8;
loc_8240358C:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,9
	r11.s64 = 9;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r3,-1
	ctx.r3.s64 = -1;
loc_824035A8:
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824035C0"))) PPC_WEAK_FUNC(sub_824035C0);
PPC_FUNC_IMPL(__imp__sub_824035C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// bne cr6,0x824035f8
	if (!cr6.getEQ()) goto loc_824035F8;
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x82403678
	goto loc_82403678;
loc_824035F8:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82403610
	if (cr6.getLT()) goto loc_82403610;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// lwz r11,-15860(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -15860);
	// cmplw cr6,r3,r11
	cr6.compare<uint32_t>(ctx.r3.u32, r11.u32, xer);
	// blt cr6,0x8240364c
	if (cr6.getLT()) goto loc_8240364C;
loc_82403610:
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82403678
	goto loc_82403678;
loc_8240364C:
	// srawi r10,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	ctx.r10.s64 = ctx.r3.s32 >> 5;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-15840
	r11.s64 = r11.s64 + -15840;
	// rlwinm r10,r3,6,21,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// lbz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82403610
	if (cr0.getEQ()) goto loc_82403610;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 0);
loc_82403678:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82403688"))) PPC_WEAK_FUNC(sub_82403688);
PPC_FUNC_IMPL(__imp__sub_82403688) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r18{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// lwz r18,-1044(0)
	r18.u64 = PPC_LOAD_U32(-1044);
	// lwz r16,29976(r7)
	r16.u64 = PPC_LOAD_U32(ctx.r7.u32 + 29976);
	// mflr r12
	// bl 0x823ed13c
	// addi r31,r1,-128
	r31.s64 = ctx.r1.s64 + -128;
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// stw r3,148(r31)
	PPC_STORE_U32(r31.u32 + 148, ctx.r3.u32);
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r11,r11,-15840
	r11.s64 = r11.s64 + -15840;
	// srawi r10,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	ctx.r10.s64 = ctx.r3.s32 >> 5;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r3,6,21,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// li r29,1
	r29.s64 = 1;
	// stw r29,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r29.u32);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// add r30,r10,r9
	r30.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x82403720
	if (!cr6.getEQ()) goto loc_82403720;
	// li r3,10
	ctx.r3.s64 = 10;
	// bl 0x823f8040
	sub_823F8040(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82403714
	if (!cr6.getEQ()) goto loc_82403714;
	// li r4,4000
	ctx.r4.s64 = 4000;
	// addi r3,r30,12
	ctx.r3.s64 = r30.s64 + 12;
	// bl 0x823f81b0
	sub_823F81B0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82403708
	if (!cr0.getEQ()) goto loc_82403708;
	// li r11,0
	r11.s64 = 0;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
loc_82403708:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
loc_82403714:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,128
	r12.s64 = r31.s64 + 128;
	// bl 0x82403750
	sub_82403750(ctx, base);
loc_82403720:
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x82403744
	if (cr6.getEQ()) goto loc_82403744;
	// srawi r10,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	ctx.r10.s64 = ctx.r3.s32 >> 5;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r3,6,21,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r3,r11,12
	ctx.r3.s64 = r11.s64 + 12;
	// bl 0x8240f8bc
	__imp__RtlEnterCriticalSection(ctx, base);
loc_82403744:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r31,128
	ctx.r1.s64 = r31.s64 + 128;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82403690"))) PPC_WEAK_FUNC(sub_82403690);
PPC_FUNC_IMPL(__imp__sub_82403690) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// addi r31,r1,-128
	r31.s64 = ctx.r1.s64 + -128;
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// stw r3,148(r31)
	PPC_STORE_U32(r31.u32 + 148, ctx.r3.u32);
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r11,r11,-15840
	r11.s64 = r11.s64 + -15840;
	// srawi r10,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	ctx.r10.s64 = ctx.r3.s32 >> 5;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r9,r3,6,21,25
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// li r29,1
	r29.s64 = 1;
	// stw r29,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r29.u32);
	// lwzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// add r30,r10,r9
	r30.u64 = ctx.r10.u64 + ctx.r9.u64;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne cr6,0x82403720
	if (!cr6.getEQ()) goto loc_82403720;
	// li r3,10
	ctx.r3.s64 = 10;
	// bl 0x823f8040
	sub_823F8040(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// bne cr6,0x82403714
	if (!cr6.getEQ()) goto loc_82403714;
	// li r4,4000
	ctx.r4.s64 = 4000;
	// addi r3,r30,12
	ctx.r3.s64 = r30.s64 + 12;
	// bl 0x823f81b0
	sub_823F81B0(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82403708
	if (!cr0.getEQ()) goto loc_82403708;
	// li r11,0
	r11.s64 = 0;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
loc_82403708:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
loc_82403714:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,128
	r12.s64 = r31.s64 + 128;
	// bl 0x82403750
	sub_82403750(ctx, base);
loc_82403720:
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x82403744
	if (cr6.getEQ()) goto loc_82403744;
	// srawi r10,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	ctx.r10.s64 = ctx.r3.s32 >> 5;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r10,r3,6,21,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r3,r11,12
	ctx.r3.s64 = r11.s64 + 12;
	// bl 0x8240f8bc
	__imp__RtlEnterCriticalSection(ctx, base);
loc_82403744:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r31,128
	ctx.r1.s64 = r31.s64 + 128;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82403750"))) PPC_WEAK_FUNC(sub_82403750);
PPC_FUNC_IMPL(__imp__sub_82403750) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r29{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r3,10
	ctx.r3.s64 = 10;
	// bl 0x823f7ee0
	sub_823F7EE0(ctx, base);
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r11,r11,-15840
	r11.s64 = r11.s64 + -15840;
	// lwz r3,148(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 148);
	// lwz r29,80(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82403788"))) PPC_WEAK_FUNC(sub_82403788);
PPC_FUNC_IMPL(__imp__sub_82403788) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister r11{};
	// srawi r10,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	ctx.r10.s64 = ctx.r3.s32 >> 5;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-15840
	r11.s64 = r11.s64 + -15840;
	// rlwinm r10,r3,6,21,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// addi r3,r11,12
	ctx.r3.s64 = r11.s64 + 12;
	// b 0x8240f8ac
	__imp__RtlLeaveCriticalSection(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_824037B0"))) PPC_WEAK_FUNC(sub_824037B0);
PPC_FUNC_IMPL(__imp__sub_824037B0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// andi. r10,r11,130
	ctx.r10.u64 = r11.u64 & 130;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82403808
	if (!cr0.getEQ()) goto loc_82403808;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r10,9
	ctx.r10.s64 = 9;
loc_824037E8:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
loc_824037F0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
loc_824037F4:
	// ori r11,r11,32
	r11.u64 = r11.u64 | 32;
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,65535
	ctx.r3.u64 = ctx.r3.u64 | 65535;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// b 0x82403978
	goto loc_82403978;
loc_82403808:
	// rlwinm. r10,r11,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8240381c
	if (cr0.getEQ()) goto loc_8240381C;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r10,34
	ctx.r10.s64 = 34;
	// b 0x824037e8
	goto loc_824037E8;
loc_8240381C:
	// clrlwi. r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// li r10,0
	ctx.r10.s64 = 0;
	// beq 0x82403844
	if (cr0.getEQ()) goto loc_82403844;
	// rlwinm. r9,r11,0,27,27
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// beq 0x824037f4
	if (cr0.getEQ()) goto loc_824037F4;
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	// stw r9,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r9.u32);
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
loc_82403844:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// rlwinm r11,r11,0,28,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFEF;
	// ori r11,r11,2
	r11.u64 = r11.u64 | 2;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// andi. r10,r11,268
	ctx.r10.u64 = r11.u64 & 268;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x824038a0
	if (!cr0.getEQ()) goto loc_824038A0;
	// bl 0x823f4e20
	sub_823F4E20(ctx, base);
	// addi r11,r3,32
	r11.s64 = ctx.r3.s64 + 32;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// beq cr6,0x82403888
	if (cr6.getEQ()) goto loc_82403888;
	// bl 0x823f4e20
	sub_823F4E20(ctx, base);
	// addi r11,r3,64
	r11.s64 = ctx.r3.s64 + 64;
	// cmplw cr6,r31,r11
	cr6.compare<uint32_t>(r31.u32, r11.u32, xer);
	// bne cr6,0x82403898
	if (!cr6.getEQ()) goto loc_82403898;
loc_82403888:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82345d68
	sub_82345D68(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824038a0
	if (!cr0.getEQ()) goto loc_824038A0;
loc_82403898:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ffb38
	sub_823FFB38(ctx, base);
loc_824038A0:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// andi. r11,r11,264
	r11.u64 = r11.u64 & 264;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82403950
	if (cr0.getEQ()) goto loc_82403950;
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// addi r11,r11,-2
	r11.s64 = r11.s64 + -2;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// subf. r29,r4,r10
	r29.s64 = ctx.r10.s64 - ctx.r4.s64;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// addi r11,r4,2
	r11.s64 = ctx.r4.s64 + 2;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// ble 0x824038e8
	if (!cr0.getGT()) goto loc_824038E8;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823ff9a8
	sub_823FF9A8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// b 0x82403944
	goto loc_82403944;
loc_824038E8:
	// cmpwi cr6,r30,-1
	cr6.compare<int32_t>(r30.s32, -1, xer);
	// beq cr6,0x82403918
	if (cr6.getEQ()) goto loc_82403918;
	// cmpwi cr6,r30,-2
	cr6.compare<int32_t>(r30.s32, -2, xer);
	// beq cr6,0x82403918
	if (cr6.getEQ()) goto loc_82403918;
	// srawi r10,r30,5
	xer.ca = (r30.s32 < 0) & ((r30.u32 & 0x1F) != 0);
	ctx.r10.s64 = r30.s32 >> 5;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// rlwinm r9,r10,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r11,r11,-15840
	r11.s64 = r11.s64 + -15840;
	// rlwinm r10,r30,6,21,25
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r9,r11
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// b 0x82403920
	goto loc_82403920;
loc_82403918:
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r11,r11,-18648
	r11.s64 = r11.s64 + -18648;
loc_82403920:
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82403944
	if (cr0.getEQ()) goto loc_82403944;
	// li r5,2
	ctx.r5.s64 = 2;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823ff5b8
	sub_823FF5B8(ctx, base);
	// cmpdi cr6,r3,-1
	cr6.compare<int64_t>(ctx.r3.s64, -1, xer);
	// beq cr6,0x824037f0
	if (cr6.getEQ()) goto loc_824037F0;
loc_82403944:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// sth r27,0(r11)
	PPC_STORE_U16(r11.u32 + 0, r27.u16);
	// b 0x8240396c
	goto loc_8240396C;
loc_82403950:
	// li r5,2
	ctx.r5.s64 = 2;
	// sth r27,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, r27.u16);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// li r29,2
	r29.s64 = 2;
	// bl 0x823ff9a8
	sub_823FF9A8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
loc_8240396C:
	// cmpw cr6,r28,r29
	cr6.compare<int32_t>(r28.s32, r29.s32, xer);
	// bne cr6,0x824037f0
	if (!cr6.getEQ()) goto loc_824037F0;
	// clrlwi r3,r27,16
	ctx.r3.u64 = r27.u32 & 0xFFFF;
loc_82403978:
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_82403980"))) PPC_WEAK_FUNC(sub_82403980);
PPC_FUNC_IMPL(__imp__sub_82403980) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x824039c4
	if (!cr6.getEQ()) goto loc_824039C4;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// b 0x82403b3c
	goto loc_82403B3C;
loc_824039C4:
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// andi. r10,r11,131
	ctx.r10.u64 = r11.u64 & 131;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82403b3c
	if (cr0.getEQ()) goto loc_82403B3C;
	// rlwinm. r10,r11,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82403b3c
	if (!cr0.getEQ()) goto loc_82403B3C;
	// rlwinm. r10,r11,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824039ec
	if (cr0.getEQ()) goto loc_824039EC;
	// ori r11,r11,32
	r11.u64 = r11.u64 | 32;
	// b 0x82403b38
	goto loc_82403B38;
loc_824039EC:
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
	// andi. r10,r11,268
	ctx.r10.u64 = r11.u64 & 268;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82403a0c
	if (!cr0.getEQ()) goto loc_82403A0C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ffb38
	sub_823FFB38(ctx, base);
	// b 0x82403a14
	goto loc_82403A14;
loc_82403A0C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_82403A14:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r30,24(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// lwz r29,8(r31)
	r29.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// bl 0x82404188
	sub_82404188(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// stw r3,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r3.u32);
	// beq 0x82403b18
	if (cr0.getEQ()) goto loc_82403B18;
	// cmpwi cr6,r3,1
	cr6.compare<int32_t>(ctx.r3.s32, 1, xer);
	// beq cr6,0x82403b18
	if (cr6.getEQ()) goto loc_82403B18;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82403b18
	if (cr6.getEQ()) goto loc_82403B18;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// andi. r11,r11,130
	r11.u64 = r11.u64 & 130;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82403ad0
	if (!cr0.getEQ()) goto loc_82403AD0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82403aac
	if (cr6.getEQ()) goto loc_82403AAC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x82403aac
	if (cr6.getEQ()) goto loc_82403AAC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r30,r11,-15840
	r30.s64 = r11.s64 + -15840;
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r29,r11,2,0,29
	r29.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r29,r30
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + r30.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// b 0x82403ab4
	goto loc_82403AB4;
loc_82403AAC:
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r11,r11,-18648
	r11.s64 = r11.s64 + -18648;
loc_82403AB4:
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// andi. r11,r11,130
	r11.u64 = r11.u64 & 130;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmplwi cr6,r11,130
	cr6.compare<uint32_t>(r11.u32, 130, xer);
	// bne cr6,0x82403ad0
	if (!cr6.getEQ()) goto loc_82403AD0;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// ori r11,r11,8192
	r11.u64 = r11.u64 | 8192;
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
loc_82403AD0:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// cmpwi cr6,r11,512
	cr6.compare<int32_t>(r11.s32, 512, xer);
	// bne cr6,0x82403af8
	if (!cr6.getEQ()) goto loc_82403AF8;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// rlwinm. r10,r11,0,28,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82403af8
	if (cr0.getEQ()) goto loc_82403AF8;
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82403af8
	if (!cr0.getEQ()) goto loc_82403AF8;
	// li r11,4096
	r11.s64 = 4096;
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
loc_82403AF8:
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// stw r10,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r10.u32);
	// lhz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U16(r11.u32 + 0);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// b 0x82403b44
	goto loc_82403B44;
loc_82403B18:
	// subfic r11,r3,0
	xer.ca = ctx.r3.u32 <= 0;
	r11.s64 = 0 - ctx.r3.s64;
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r9,0
	ctx.r9.s64 = 0;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// rlwinm r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// stw r9,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r9.u32);
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
loc_82403B38:
	// stw r11,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r11.u32);
loc_82403B3C:
	// lis r3,0
	ctx.r3.s64 = 0;
	// ori r3,r3,65535
	ctx.r3.u64 = ctx.r3.u64 | 65535;
loc_82403B44:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82403B50"))) PPC_WEAK_FUNC(sub_82403B50);
PPC_FUNC_IMPL(__imp__sub_82403B50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r18{};
	PPCRegister r19{};
	PPCRegister r20{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed110
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r21,r3
	r21.u64 = ctx.r3.u64;
	// mr r31,r5
	r31.u64 = ctx.r5.u64;
	// mr r18,r4
	r18.u64 = ctx.r4.u64;
	// li r19,-2
	r19.s64 = -2;
	// mr r20,r31
	r20.u64 = r31.u64;
	// cmpwi cr6,r21,-2
	cr6.compare<int32_t>(r21.s32, -2, xer);
	// bne cr6,0x82403b9c
	if (!cr6.getEQ()) goto loc_82403B9C;
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r10,9
	ctx.r10.s64 = 9;
loc_82403B8C:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x82404178
	goto loc_82404178;
loc_82403B9C:
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// blt cr6,0x82403bb4
	if (cr6.getLT()) goto loc_82403BB4;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// lwz r11,-15860(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -15860);
	// cmplw cr6,r21,r11
	cr6.compare<uint32_t>(r21.u32, r11.u32, xer);
	// blt cr6,0x82403bf0
	if (cr6.getLT()) goto loc_82403BF0;
loc_82403BB4:
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r10,9
	ctx.r10.s64 = 9;
loc_82403BC8:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82404178
	goto loc_82404178;
loc_82403BF0:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// rlwinm r28,r21,6,21,25
	r28.u64 = __builtin_rotateleft64(r21.u32 | (r21.u64 << 32), 6) & 0x7C0;
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// srawi r11,r21,5
	xer.ca = (r21.s32 < 0) & ((r21.u32 & 0x1F) != 0);
	r11.s64 = r21.s32 >> 5;
	// rlwinm r27,r11,2,0,29
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// lbz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// clrlwi. r9,r10,31
	ctx.r9.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x82403bb4
	if (cr0.getEQ()) goto loc_82403BB4;
	// lis r9,32767
	ctx.r9.s64 = 2147418112;
	// ori r9,r9,65535
	ctx.r9.u64 = ctx.r9.u64 | 65535;
	// cmplw cr6,r31,r9
	cr6.compare<uint32_t>(r31.u32, ctx.r9.u32, xer);
	// ble cr6,0x82403c44
	if (!cr6.getGT()) goto loc_82403C44;
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
loc_82403C38:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r10,22
	ctx.r10.s64 = 22;
	// b 0x82403bc8
	goto loc_82403BC8;
loc_82403C44:
	// li r26,0
	r26.s64 = 0;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// mr r30,r26
	r30.u64 = r26.u64;
	// beq cr6,0x82404174
	if (cr6.getEQ()) goto loc_82404174;
	// rlwinm. r10,r10,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82404174
	if (!cr0.getEQ()) goto loc_82404174;
	// cmplwi cr6,r18,0
	cr6.compare<uint32_t>(r18.u32, 0, xer);
	// bne cr6,0x82403c70
	if (!cr6.getEQ()) goto loc_82403C70;
loc_82403C64:
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// stw r26,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r26.u32);
	// b 0x82403c38
	goto loc_82403C38;
loc_82403C70:
	// lbz r11,40(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 40);
	// rotlwi r11,r11,24
	r11.u64 = __builtin_rotateleft32(r11.u32, 24);
	// srawi r11,r11,25
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1FFFFFF) != 0);
	r11.s64 = r11.s32 >> 25;
	// extsb r22,r11
	r22.s64 = r11.s8;
	// cmpwi cr6,r22,1
	cr6.compare<int32_t>(r22.s32, 1, xer);
	// beq cr6,0x82403ca8
	if (cr6.getEQ()) goto loc_82403CA8;
	// cmpwi cr6,r22,2
	cr6.compare<int32_t>(r22.s32, 2, xer);
	// bne cr6,0x82403ca0
	if (!cr6.getEQ()) goto loc_82403CA0;
	// not r11,r31
	r11.u64 = ~r31.u64;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82403c64
	if (cr0.getEQ()) goto loc_82403C64;
	// rlwinm r31,r31,0,0,30
	r31.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0xFFFFFFFE;
loc_82403CA0:
	// mr r23,r18
	r23.u64 = r18.u64;
	// b 0x82403d08
	goto loc_82403D08;
loc_82403CA8:
	// not r11,r31
	r11.u64 = ~r31.u64;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82403c64
	if (cr0.getEQ()) goto loc_82403C64;
	// rlwinm r31,r31,31,1,31
	r31.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 31) & 0x7FFFFFFF;
	// cmplwi cr6,r31,4
	cr6.compare<uint32_t>(r31.u32, 4, xer);
	// bge cr6,0x82403cc4
	if (!cr6.getLT()) goto loc_82403CC4;
	// li r31,4
	r31.s64 = 4;
loc_82403CC4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ed2b0
	sub_823ED2B0(ctx, base);
	// mr. r23,r3
	r23.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r23.s32, 0, xer);
	// bne 0x82403cec
	if (!cr0.getEQ()) goto loc_82403CEC;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,12
	r11.s64 = 12;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r10,8
	ctx.r10.s64 = 8;
	// b 0x82403b8c
	goto loc_82403B8C;
loc_82403CEC:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x823ff4f0
	sub_823FF4F0(ctx, base);
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// std r3,48(r11)
	PPC_STORE_U64(r11.u32 + 48, ctx.r3.u64);
loc_82403D08:
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// li r24,10
	r24.s64 = 10;
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// lbz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// andi. r10,r10,72
	ctx.r10.u64 = ctx.r10.u64 & 72;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82403dd8
	if (cr0.getEQ()) goto loc_82403DD8;
	// lbz r11,5(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 5);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// beq cr6,0x82403dd8
	if (cr6.getEQ()) goto loc_82403DD8;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82403dd8
	if (cr6.getEQ()) goto loc_82403DD8;
	// stb r11,0(r23)
	PPC_STORE_U8(r23.u32 + 0, r11.u8);
	// addi r4,r23,1
	ctx.r4.s64 = r23.s64 + 1;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// li r30,1
	r30.s64 = 1;
	// addi r31,r31,-1
	r31.s64 = r31.s64 + -1;
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// stb r24,5(r11)
	PPC_STORE_U8(r11.u32 + 5, r24.u8);
	// beq cr6,0x82403dd8
	if (cr6.getEQ()) goto loc_82403DD8;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// lbz r11,41(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 41);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// beq cr6,0x82403dd8
	if (cr6.getEQ()) goto loc_82403DD8;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82403dd8
	if (cr6.getEQ()) goto loc_82403DD8;
	// stb r11,0(r4)
	PPC_STORE_U8(ctx.r4.u32 + 0, r11.u8);
	// li r30,2
	r30.s64 = 2;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// addi r31,r31,-1
	r31.s64 = r31.s64 + -1;
	// cmpwi cr6,r22,1
	cr6.compare<int32_t>(r22.s32, 1, xer);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// stb r24,41(r11)
	PPC_STORE_U8(r11.u32 + 41, r24.u8);
	// bne cr6,0x82403dd8
	if (!cr6.getEQ()) goto loc_82403DD8;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// lbz r11,42(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 42);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// beq cr6,0x82403dd8
	if (cr6.getEQ()) goto loc_82403DD8;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82403dd8
	if (cr6.getEQ()) goto loc_82403DD8;
	// stb r11,0(r4)
	PPC_STORE_U8(ctx.r4.u32 + 0, r11.u8);
	// li r30,3
	r30.s64 = 3;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// addi r31,r31,-1
	r31.s64 = r31.s64 + -1;
	// addi r4,r4,1
	ctx.r4.s64 = ctx.r4.s64 + 1;
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// stb r24,42(r11)
	PPC_STORE_U8(r11.u32 + 42, r24.u8);
loc_82403DD8:
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// lwzx r3,r28,r11
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// bl 0x8235d200
	sub_8235D200(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x82404140
	if (cr0.getEQ()) goto loc_82404140;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// blt cr6,0x82404140
	if (cr6.getLT()) goto loc_82404140;
	// cmplw cr6,r10,r31
	cr6.compare<uint32_t>(ctx.r10.u32, r31.u32, xer);
	// bgt cr6,0x82404140
	if (cr6.getGT()) goto loc_82404140;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r30,r10,r30
	r30.u64 = ctx.r10.u64 + r30.u64;
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// lbz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// rlwinm. r9,r9,0,0,24
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFF80;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq 0x824040f8
	if (cr0.getEQ()) goto loc_824040F8;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq cr6,0x82403e44
	if (cr6.getEQ()) goto loc_82403E44;
	// lbz r10,0(r23)
	ctx.r10.u64 = PPC_LOAD_U8(r23.u32 + 0);
	// cmplwi cr6,r10,10
	cr6.compare<uint32_t>(ctx.r10.u32, 10, xer);
	// bne cr6,0x82403e44
	if (!cr6.getEQ()) goto loc_82403E44;
	// lbz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// ori r10,r10,4
	ctx.r10.u64 = ctx.r10.u64 | 4;
	// b 0x82403e50
	goto loc_82403E50;
loc_82403E44:
	// lbz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// extsb r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	// rlwinm r10,r10,0,30,28
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFB;
loc_82403E50:
	// add r25,r23,r30
	r25.u64 = r23.u64 + r30.u64;
	// stb r10,4(r11)
	PPC_STORE_U8(r11.u32 + 4, ctx.r10.u8);
	// mr r31,r23
	r31.u64 = r23.u64;
	// mr r30,r23
	r30.u64 = r23.u64;
	// cmplw cr6,r23,r25
	cr6.compare<uint32_t>(r23.u32, r25.u32, xer);
	// bge cr6,0x82403fb0
	if (!cr6.getLT()) goto loc_82403FB0;
	// li r26,13
	r26.s64 = 13;
loc_82403E6C:
	// lbz r11,0(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// extsb r10,r11
	ctx.r10.s64 = r11.s8;
	// cmpwi cr6,r10,26
	cr6.compare<int32_t>(ctx.r10.s32, 26, xer);
	// beq cr6,0x82403f80
	if (cr6.getEQ()) goto loc_82403F80;
	// cmpwi cr6,r10,13
	cr6.compare<int32_t>(ctx.r10.s32, 13, xer);
	// beq cr6,0x82403e90
	if (cr6.getEQ()) goto loc_82403E90;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
loc_82403E88:
	// stb r11,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r11.u8);
	// b 0x82403f70
	goto loc_82403F70;
loc_82403E90:
	// addi r10,r25,-1
	ctx.r10.s64 = r25.s64 + -1;
	// cmplw cr6,r30,r10
	cr6.compare<uint32_t>(r30.u32, ctx.r10.u32, xer);
	// bge cr6,0x82403ec0
	if (!cr6.getLT()) goto loc_82403EC0;
	// lbz r9,1(r30)
	ctx.r9.u64 = PPC_LOAD_U8(r30.u32 + 1);
	// addi r10,r30,1
	ctx.r10.s64 = r30.s64 + 1;
	// cmplwi cr6,r9,10
	cr6.compare<uint32_t>(ctx.r9.u32, 10, xer);
	// bne cr6,0x82403eb8
	if (!cr6.getEQ()) goto loc_82403EB8;
	// addi r30,r30,2
	r30.s64 = r30.s64 + 2;
loc_82403EB0:
	// stb r24,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r24.u8);
	// b 0x82403f70
	goto loc_82403F70;
loc_82403EB8:
	// mr r30,r10
	r30.u64 = ctx.r10.u64;
	// b 0x82403e88
	goto loc_82403E88;
loc_82403EC0:
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r1,84
	ctx.r6.s64 = ctx.r1.s64 + 84;
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// addi r30,r30,1
	r30.s64 = r30.s64 + 1;
	// lwzx r3,r28,r11
	ctx.r3.u64 = PPC_LOAD_U32(r28.u32 + r11.u32);
	// bl 0x8235d200
	sub_8235D200(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x82403ef4
	if (!cr0.getEQ()) goto loc_82403EF4;
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x82403f6c
	if (!cr0.getEQ()) goto loc_82403F6C;
loc_82403EF4:
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x82403f6c
	if (cr6.getEQ()) goto loc_82403F6C;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// andi. r11,r11,72
	r11.u64 = r11.u64 & 72;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82403f3c
	if (cr0.getEQ()) goto loc_82403F3C;
	// lbz r11,80(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// beq cr6,0x82403eb0
	if (cr6.getEQ()) goto loc_82403EB0;
	// stb r26,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r26.u8);
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// lbz r10,80(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// stb r10,5(r11)
	PPC_STORE_U8(r11.u32 + 5, ctx.r10.u8);
	// b 0x82403f70
	goto loc_82403F70;
loc_82403F3C:
	// cmplw cr6,r31,r23
	cr6.compare<uint32_t>(r31.u32, r23.u32, xer);
	// bne cr6,0x82403f50
	if (!cr6.getEQ()) goto loc_82403F50;
	// lbz r11,80(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// beq cr6,0x82403eb0
	if (cr6.getEQ()) goto loc_82403EB0;
loc_82403F50:
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,-1
	ctx.r4.s64 = -1;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x823ff4f0
	sub_823FF4F0(ctx, base);
	// lbz r11,80(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,10
	cr6.compare<uint32_t>(r11.u32, 10, xer);
	// beq cr6,0x82403f74
	if (cr6.getEQ()) goto loc_82403F74;
loc_82403F6C:
	// stb r26,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r26.u8);
loc_82403F70:
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_82403F74:
	// cmplw cr6,r30,r25
	cr6.compare<uint32_t>(r30.u32, r25.u32, xer);
	// blt cr6,0x82403e6c
	if (cr6.getLT()) goto loc_82403E6C;
	// b 0x82403fb0
	goto loc_82403FB0;
loc_82403F80:
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// lbz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// rlwinm. r10,r10,0,25,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82403fa4
	if (!cr0.getEQ()) goto loc_82403FA4;
	// lbz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// ori r10,r10,2
	ctx.r10.u64 = ctx.r10.u64 | 2;
	// stb r10,4(r11)
	PPC_STORE_U8(r11.u32 + 4, ctx.r10.u8);
	// b 0x82403fb0
	goto loc_82403FB0;
loc_82403FA4:
	// lbz r11,0(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// stb r11,0(r31)
	PPC_STORE_U8(r31.u32 + 0, r11.u8);
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
loc_82403FB0:
	// subf r30,r23,r31
	r30.s64 = r31.s64 - r23.s64;
	// cmpwi cr6,r22,1
	cr6.compare<int32_t>(r22.s32, 1, xer);
	// bne cr6,0x824040f8
	if (!cr6.getEQ()) goto loc_824040F8;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x824040f8
	if (cr6.getEQ()) goto loc_824040F8;
	// addi r31,r31,-1
	r31.s64 = r31.s64 + -1;
	// lbz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// rlwinm. r11,r10,0,0,24
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFF80;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82403fdc
	if (!cr0.getEQ()) goto loc_82403FDC;
	// addi r31,r31,1
	r31.s64 = r31.s64 + 1;
	// b 0x824040c0
	goto loc_824040C0;
loc_82403FDC:
	// lis r11,-32015
	r11.s64 = -2098135040;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r11,r11,-16384
	r11.s64 = r11.s64 + -16384;
	// b 0x82404008
	goto loc_82404008;
loc_82403FEC:
	// cmpwi cr6,r8,4
	cr6.compare<int32_t>(ctx.r8.s32, 4, xer);
	// bgt cr6,0x82404014
	if (cr6.getGT()) goto loc_82404014;
	// cmplw cr6,r31,r23
	cr6.compare<uint32_t>(r31.u32, r23.u32, xer);
	// blt cr6,0x82404014
	if (cr6.getLT()) goto loc_82404014;
	// addi r31,r31,-1
	r31.s64 = r31.s64 + -1;
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
	// lbz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 0);
loc_82404008:
	// lbzx r10,r10,r11
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + r11.u32);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x82403fec
	if (cr6.getEQ()) goto loc_82403FEC;
loc_82404014:
	// lbz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
	// lbzx r11,r10,r11
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + r11.u32);
	// extsb. r11,r11
	r11.s64 = r11.s8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82404038
	if (!cr0.getEQ()) goto loc_82404038;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,42
	r11.s64 = 42;
loc_82404030:
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// b 0x824040f4
	goto loc_824040F4;
loc_82404038:
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmpw cr6,r11,r8
	cr6.compare<int32_t>(r11.s32, ctx.r8.s32, xer);
	// bne cr6,0x8240404c
	if (!cr6.getEQ()) goto loc_8240404C;
	// add r31,r8,r31
	r31.u64 = ctx.r8.u64 + r31.u64;
	// b 0x824040c0
	goto loc_824040C0;
loc_8240404C:
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r10,r28,r11
	ctx.r10.u64 = r28.u64 + r11.u64;
	// lbz r11,4(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 4);
	// andi. r11,r11,72
	r11.u64 = r11.u64 & 72;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824040ac
	if (cr0.getEQ()) goto loc_824040AC;
	// addi r11,r31,1
	r11.s64 = r31.s64 + 1;
	// stb r9,5(r10)
	PPC_STORE_U8(ctx.r10.u32 + 5, ctx.r9.u8);
	// cmpwi cr6,r8,2
	cr6.compare<int32_t>(ctx.r8.s32, 2, xer);
	// blt cr6,0x82404088
	if (cr6.getLT()) goto loc_82404088;
	// lwzx r10,r27,r29
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// add r10,r28,r10
	ctx.r10.u64 = r28.u64 + ctx.r10.u64;
	// stb r9,41(r10)
	PPC_STORE_U8(ctx.r10.u32 + 41, ctx.r9.u8);
loc_82404088:
	// cmpwi cr6,r8,3
	cr6.compare<int32_t>(ctx.r8.s32, 3, xer);
	// bne cr6,0x824040a4
	if (!cr6.getEQ()) goto loc_824040A4;
	// lwzx r10,r27,r29
	ctx.r10.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// add r10,r28,r10
	ctx.r10.u64 = r28.u64 + ctx.r10.u64;
	// stb r9,42(r10)
	PPC_STORE_U8(ctx.r10.u32 + 42, ctx.r9.u8);
loc_824040A4:
	// subf r31,r8,r11
	r31.s64 = r11.s64 - ctx.r8.s64;
	// b 0x824040c0
	goto loc_824040C0;
loc_824040AC:
	// neg r11,r8
	r11.s64 = -ctx.r8.s64;
	// li r5,1
	ctx.r5.s64 = 1;
	// extsw r4,r11
	ctx.r4.s64 = r11.s32;
	// mr r3,r21
	ctx.r3.u64 = r21.u64;
	// bl 0x823ff4f0
	sub_823FF4F0(ctx, base);
loc_824040C0:
	// subf r31,r23,r31
	r31.s64 = r31.s64 - r23.s64;
	// lis r3,0
	ctx.r3.s64 = 0;
	// rlwinm r8,r20,31,1,31
	ctx.r8.u64 = __builtin_rotateleft64(r20.u32 | (r20.u64 << 32), 31) & 0x7FFFFFFF;
	// mr r7,r18
	ctx.r7.u64 = r18.u64;
	// mr r5,r23
	ctx.r5.u64 = r23.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// ori r3,r3,65001
	ctx.r3.u64 = ctx.r3.u64 | 65001;
	// mr r6,r31
	ctx.r6.u64 = r31.u64;
	// bl 0x8235f148
	sub_8235F148(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// bne 0x8240411c
	if (!cr0.getEQ()) goto loc_8240411C;
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
loc_824040F0:
	// bl 0x823f3e50
	sub_823F3E50(ctx, base);
loc_824040F4:
	// li r19,-1
	r19.s64 = -1;
loc_824040F8:
	// cmplw cr6,r23,r18
	cr6.compare<uint32_t>(r23.u32, r18.u32, xer);
	// beq cr6,0x82404108
	if (cr6.getEQ()) goto loc_82404108;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x823ed250
	sub_823ED250(ctx, base);
loc_82404108:
	// cmpwi cr6,r19,-2
	cr6.compare<int32_t>(r19.s32, -2, xer);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// beq cr6,0x82404178
	if (cr6.getEQ()) goto loc_82404178;
	// mr r3,r19
	ctx.r3.u64 = r19.u64;
	// b 0x82404178
	goto loc_82404178;
loc_8240411C:
	// subf r10,r30,r31
	ctx.r10.s64 = r31.s64 - r30.s64;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// rlwinm r30,r30,1,0,30
	r30.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// add r11,r28,r11
	r11.u64 = r28.u64 + r11.u64;
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// xori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 ^ 1;
	// stw r10,56(r11)
	PPC_STORE_U32(r11.u32 + 56, ctx.r10.u32);
	// b 0x824040f8
	goto loc_824040F8;
loc_82404140:
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// cmplwi cr6,r3,5
	cr6.compare<uint32_t>(ctx.r3.u32, 5, xer);
	// bne cr6,0x82404164
	if (!cr6.getEQ()) goto loc_82404164;
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,9
	r11.s64 = 9;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,5
	r11.s64 = 5;
	// b 0x82404030
	goto loc_82404030;
loc_82404164:
	// cmplwi cr6,r3,109
	cr6.compare<uint32_t>(ctx.r3.u32, 109, xer);
	// bne cr6,0x824040f0
	if (!cr6.getEQ()) goto loc_824040F0;
	// mr r19,r26
	r19.u64 = r26.u64;
	// b 0x824040f8
	goto loc_824040F8;
loc_82404174:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82404178:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed160
	return;
}

__attribute__((alias("__imp__sub_82404180"))) PPC_WEAK_FUNC(sub_82404180);
PPC_FUNC_IMPL(__imp__sub_82404180) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r18{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// lwz r18,-1044(0)
	r18.u64 = PPC_LOAD_U32(-1044);
	// lwz r16,30000(r7)
	r16.u64 = PPC_LOAD_U32(ctx.r7.u32 + 30000);
	// mflr r12
	// bl 0x823ed12c
	// addi r31,r1,-160
	r31.s64 = ctx.r1.s64 + -160;
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r30,180(r31)
	PPC_STORE_U32(r31.u32 + 180, r30.u32);
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// cmpwi cr6,r30,-2
	cr6.compare<int32_t>(r30.s32, -2, xer);
	// bne cr6,0x824041d4
	if (!cr6.getEQ()) goto loc_824041D4;
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x824042e8
	goto loc_824042E8;
loc_824041D4:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x824041ec
	if (cr6.getLT()) goto loc_824041EC;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// lwz r11,-15860(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -15860);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x82404228
	if (cr6.getLT()) goto loc_82404228;
loc_824041EC:
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r10,9
	ctx.r10.s64 = 9;
loc_82404200:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x824042e8
	goto loc_824042E8;
loc_82404228:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// srawi r11,r30,5
	xer.ca = (r30.s32 < 0) & ((r30.u32 & 0x1F) != 0);
	r11.s64 = r30.s32 >> 5;
	// rlwinm r27,r11,2,0,29
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r30,6,21,25
	r28.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824041ec
	if (cr0.getEQ()) goto loc_824041EC;
	// lis r11,32767
	r11.s64 = 2147418112;
	// ori r11,r11,65535
	r11.u64 = r11.u64 | 65535;
	// subfc r11,r26,r11
	xer.ca = r11.u32 >= r26.u32;
	r11.s64 = r11.s64 - r26.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// addic. r11,r11,1
	xer.ca = r11.u32 > 4294967294;
	r11.s64 = r11.s64 + 1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82404280
	if (!cr0.getEQ()) goto loc_82404280;
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r10,22
	ctx.r10.s64 = 22;
	// b 0x82404200
	goto loc_82404200;
loc_82404280:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403690
	sub_82403690(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824042b8
	if (cr0.getEQ()) goto loc_824042B8;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403b50
	sub_82403B50(ctx, base);
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// b 0x824042d8
	goto loc_824042D8;
loc_824042B8:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,9
	r11.s64 = 9;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// li r11,-1
	r11.s64 = -1;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
loc_824042D8:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,160
	r12.s64 = r31.s64 + 160;
	// bl 0x82404310
	sub_82404310(ctx, base);
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
loc_824042E8:
	// addi r1,r31,160
	ctx.r1.s64 = r31.s64 + 160;
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_82404188"))) PPC_WEAK_FUNC(sub_82404188);
PPC_FUNC_IMPL(__imp__sub_82404188) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed12c
	// addi r31,r1,-160
	r31.s64 = ctx.r1.s64 + -160;
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r30,180(r31)
	PPC_STORE_U32(r31.u32 + 180, r30.u32);
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// cmpwi cr6,r30,-2
	cr6.compare<int32_t>(r30.s32, -2, xer);
	// bne cr6,0x824041d4
	if (!cr6.getEQ()) goto loc_824041D4;
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x824042e8
	goto loc_824042E8;
loc_824041D4:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x824041ec
	if (cr6.getLT()) goto loc_824041EC;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// lwz r11,-15860(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -15860);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x82404228
	if (cr6.getLT()) goto loc_82404228;
loc_824041EC:
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r10,9
	ctx.r10.s64 = 9;
loc_82404200:
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x824042e8
	goto loc_824042E8;
loc_82404228:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// srawi r11,r30,5
	xer.ca = (r30.s32 < 0) & ((r30.u32 & 0x1F) != 0);
	r11.s64 = r30.s32 >> 5;
	// rlwinm r27,r11,2,0,29
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r30,6,21,25
	r28.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824041ec
	if (cr0.getEQ()) goto loc_824041EC;
	// lis r11,32767
	r11.s64 = 2147418112;
	// ori r11,r11,65535
	r11.u64 = r11.u64 | 65535;
	// subfc r11,r26,r11
	xer.ca = r11.u32 >= r26.u32;
	r11.s64 = r11.s64 - r26.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// addic. r11,r11,1
	xer.ca = r11.u32 > 4294967294;
	r11.s64 = r11.s64 + 1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82404280
	if (!cr0.getEQ()) goto loc_82404280;
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r10,22
	ctx.r10.s64 = 22;
	// b 0x82404200
	goto loc_82404200;
loc_82404280:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403690
	sub_82403690(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824042b8
	if (cr0.getEQ()) goto loc_824042B8;
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403b50
	sub_82403B50(ctx, base);
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// b 0x824042d8
	goto loc_824042D8;
loc_824042B8:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,9
	r11.s64 = 9;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// li r11,-1
	r11.s64 = -1;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
loc_824042D8:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,160
	r12.s64 = r31.s64 + 160;
	// bl 0x82404310
	sub_82404310(ctx, base);
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
loc_824042E8:
	// addi r1,r31,160
	ctx.r1.s64 = r31.s64 + 160;
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_824042F0"))) PPC_WEAK_FUNC(sub_824042F0);
PPC_FUNC_IMPL(__imp__sub_824042F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-160
	r31.s64 = r12.s64 + -160;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,180(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 180);
	// b 0x82404328
	goto loc_82404328;
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-160
	r31.s64 = r12.s64 + -160;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
loc_82404328:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403788
	sub_82403788(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404310"))) PPC_WEAK_FUNC(sub_82404310);
PPC_FUNC_IMPL(__imp__sub_82404310) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-160
	r31.s64 = r12.s64 + -160;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403788
	sub_82403788(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404348"))) PPC_WEAK_FUNC(sub_82404348);
PPC_FUNC_IMPL(__imp__sub_82404348) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x824035c0
	sub_824035C0(ctx, base);
	// lis r11,-31987
	r11.s64 = -2096300032;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// beq cr6,0x824043d4
	if (cr6.getEQ()) goto loc_824043D4;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// cmpwi cr6,r31,1
	cr6.compare<int32_t>(r31.s32, 1, xer);
	// bne cr6,0x82404384
	if (!cr6.getEQ()) goto loc_82404384;
	// lbz r10,132(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 132);
	// clrlwi. r10,r10,31
	ctx.r10.u64 = ctx.r10.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82404398
	if (!cr0.getEQ()) goto loc_82404398;
loc_82404384:
	// cmpwi cr6,r31,2
	cr6.compare<int32_t>(r31.s32, 2, xer);
	// bne cr6,0x824043b4
	if (!cr6.getEQ()) goto loc_824043B4;
	// lbz r11,68(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 68);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824043b4
	if (cr0.getEQ()) goto loc_824043B4;
loc_82404398:
	// li r3,2
	ctx.r3.s64 = 2;
	// bl 0x824035c0
	sub_824035C0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,1
	ctx.r3.s64 = 1;
	// bl 0x824035c0
	sub_824035C0(ctx, base);
	// cmpw cr6,r3,r30
	cr6.compare<int32_t>(ctx.r3.s32, r30.s32, xer);
	// beq cr6,0x824043d4
	if (cr6.getEQ()) goto loc_824043D4;
loc_824043B4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824035c0
	sub_824035C0(ctx, base);
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824043d4
	if (!cr0.getEQ()) goto loc_824043D4;
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x824043d8
	goto loc_824043D8;
loc_824043D4:
	// li r30,0
	r30.s64 = 0;
loc_824043D8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82403528
	sub_82403528(ctx, base);
	// srawi r11,r31,5
	xer.ca = (r31.s32 < 0) & ((r31.u32 & 0x1F) != 0);
	r11.s64 = r31.s32 >> 5;
	// rlwinm r10,r31,6,21,25
	ctx.r10.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 6) & 0x7C0;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// lwzx r11,r11,r29
	r11.u64 = PPC_LOAD_U32(r11.u32 + r29.u32);
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// stb r10,4(r11)
	PPC_STORE_U8(r11.u32 + 4, ctx.r10.u8);
	// beq cr6,0x82404414
	if (cr6.getEQ()) goto loc_82404414;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f3e50
	sub_823F3E50(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x82404418
	goto loc_82404418;
loc_82404414:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82404418:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82404420"))) PPC_WEAK_FUNC(sub_82404420);
PPC_FUNC_IMPL(__imp__sub_82404420) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r18{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// lwz r18,-1044(0)
	r18.u64 = PPC_LOAD_U32(-1044);
	// lwz r16,30024(r7)
	r16.u64 = PPC_LOAD_U32(ctx.r7.u32 + 30024);
	// mflr r12
	// bl 0x823ed134
	// addi r31,r1,-144
	r31.s64 = ctx.r1.s64 + -144;
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r30,164(r31)
	PPC_STORE_U32(r31.u32 + 164, r30.u32);
	// cmpwi cr6,r30,-2
	cr6.compare<int32_t>(r30.s32, -2, xer);
	// bne cr6,0x8240446c
	if (!cr6.getEQ()) goto loc_8240446C;
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x8240453c
	goto loc_8240453C;
loc_8240446C:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x82404484
	if (cr6.getLT()) goto loc_82404484;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// lwz r11,-15860(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -15860);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x824044c0
	if (cr6.getLT()) goto loc_824044C0;
loc_82404484:
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x8240453c
	goto loc_8240453C;
loc_824044C0:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// srawi r11,r30,5
	xer.ca = (r30.s32 < 0) & ((r30.u32 & 0x1F) != 0);
	r11.s64 = r30.s32 >> 5;
	// rlwinm r27,r11,2,0,29
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r30,6,21,25
	r28.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82404484
	if (cr0.getEQ()) goto loc_82404484;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403690
	sub_82403690(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82404518
	if (cr0.getEQ()) goto loc_82404518;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82404348
	sub_82404348(ctx, base);
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// b 0x8240452c
	goto loc_8240452C;
loc_82404518:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,9
	r11.s64 = 9;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// li r11,-1
	r11.s64 = -1;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
loc_8240452C:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,144
	r12.s64 = r31.s64 + 144;
	// bl 0x82404564
	sub_82404564(ctx, base);
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
loc_8240453C:
	// addi r1,r31,144
	ctx.r1.s64 = r31.s64 + 144;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_82404428"))) PPC_WEAK_FUNC(sub_82404428);
PPC_FUNC_IMPL(__imp__sub_82404428) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// addi r31,r1,-144
	r31.s64 = ctx.r1.s64 + -144;
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// stw r30,164(r31)
	PPC_STORE_U32(r31.u32 + 164, r30.u32);
	// cmpwi cr6,r30,-2
	cr6.compare<int32_t>(r30.s32, -2, xer);
	// bne cr6,0x8240446c
	if (!cr6.getEQ()) goto loc_8240446C;
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r3,-1
	ctx.r3.s64 = -1;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// b 0x8240453c
	goto loc_8240453C;
loc_8240446C:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x82404484
	if (cr6.getLT()) goto loc_82404484;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// lwz r11,-15860(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -15860);
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// blt cr6,0x824044c0
	if (cr6.getLT()) goto loc_824044C0;
loc_82404484:
	// bl 0x823f3e18
	sub_823F3E18(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,9
	ctx.r10.s64 = 9;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x8240453c
	goto loc_8240453C;
loc_824044C0:
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// srawi r11,r30,5
	xer.ca = (r30.s32 < 0) & ((r30.u32 & 0x1F) != 0);
	r11.s64 = r30.s32 >> 5;
	// rlwinm r27,r11,2,0,29
	r27.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r28,r30,6,21,25
	r28.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 6) & 0x7C0;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82404484
	if (cr0.getEQ()) goto loc_82404484;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403690
	sub_82403690(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwzx r11,r27,r29
	r11.u64 = PPC_LOAD_U32(r27.u32 + r29.u32);
	// add r11,r11,r28
	r11.u64 = r11.u64 + r28.u64;
	// lbz r11,4(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82404518
	if (cr0.getEQ()) goto loc_82404518;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82404348
	sub_82404348(ctx, base);
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// b 0x8240452c
	goto loc_8240452C;
loc_82404518:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// li r11,9
	r11.s64 = 9;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// li r11,-1
	r11.s64 = -1;
	// stw r11,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r11.u32);
loc_8240452C:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,144
	r12.s64 = r31.s64 + 144;
	// bl 0x82404564
	sub_82404564(ctx, base);
	// lwz r3,80(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 80);
loc_8240453C:
	// addi r1,r31,144
	ctx.r1.s64 = r31.s64 + 144;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_82404544"))) PPC_WEAK_FUNC(sub_82404544);
PPC_FUNC_IMPL(__imp__sub_82404544) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-144
	r31.s64 = r12.s64 + -144;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,164(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 164);
	// b 0x8240457c
	goto loc_8240457C;
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-144
	r31.s64 = r12.s64 + -144;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
loc_8240457C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403788
	sub_82403788(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404564"))) PPC_WEAK_FUNC(sub_82404564);
PPC_FUNC_IMPL(__imp__sub_82404564) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-144
	r31.s64 = r12.s64 + -144;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82403788
	sub_82403788(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824045A0"))) PPC_WEAK_FUNC(sub_824045A0);
PPC_FUNC_IMPL(__imp__sub_824045A0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,12(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// andi. r10,r11,131
	ctx.r10.u64 = r11.u64 & 131;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824045f4
	if (cr0.getEQ()) goto loc_824045F4;
	// rlwinm. r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824045f4
	if (cr0.getEQ()) goto loc_824045F4;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// bl 0x823ed250
	sub_823ED250(ctx, base);
	// lwz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 12);
	// li r11,0
	r11.s64 = 0;
	// rlwinm r10,r10,0,29,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF7;
	// rlwinm r10,r10,0,22,20
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFFFFFFBFF;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r11,8(r31)
	PPC_STORE_U32(r31.u32 + 8, r11.u32);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// stw r10,12(r31)
	PPC_STORE_U32(r31.u32 + 12, ctx.r10.u32);
loc_824045F4:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404608"))) PPC_WEAK_FUNC(sub_82404608);
PPC_FUNC_IMPL(__imp__sub_82404608) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// bl 0x823fe620
	sub_823FE620(ctx, base);
	// bl 0x823f4e20
	sub_823F4E20(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r4,r11,64
	ctx.r4.s64 = r11.s64 + 64;
	// bl 0x8240bc60
	sub_8240BC60(ctx, base);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82404650
	if (!cr6.getEQ()) goto loc_82404650;
	// lis r11,-32252
	r11.s64 = -2113667072;
	// addi r31,r11,27144
	r31.s64 = r11.s64 + 27144;
loc_82404650:
	// bl 0x823f4e20
	sub_823F4E20(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,64
	ctx.r4.s64 = r11.s64 + 64;
	// bl 0x8240bc60
	sub_8240BC60(ctx, base);
	// bl 0x823f4e20
	sub_823F4E20(ctx, base);
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r4,r3,64
	ctx.r4.s64 = ctx.r3.s64 + 64;
	// addi r11,r11,23060
	r11.s64 = r11.s64 + 23060;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x8240bc60
	sub_8240BC60(ctx, base);
	// bl 0x823f7b08
	sub_823F7B08(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404698"))) PPC_WEAK_FUNC(sub_82404698);
PPC_FUNC_IMPL(__imp__sub_82404698) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r11,r11,14768
	r11.s64 = r11.s64 + 14768;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// bl 0x82404608
	sub_82404608(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824046D8"))) PPC_WEAK_FUNC(sub_824046D8);
PPC_FUNC_IMPL(__imp__sub_824046D8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// addi r11,r11,14780
	r11.s64 = r11.s64 + 14780;
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// beqlr cr6
	if (cr6.getEQ()) return;
	// lwz r3,4(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// b 0x823ed250
	sub_823ED250(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_824046F8"))) PPC_WEAK_FUNC(sub_824046F8);
PPC_FUNC_IMPL(__imp__sub_824046F8) {
	PPC_FUNC_PROLOGUE();
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404700"))) PPC_WEAK_FUNC(sub_82404700);
PPC_FUNC_IMPL(__imp__sub_82404700) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// lwz r3,4(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bnelr 
	if (!cr0.getEQ()) return;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r3,r11,14788
	ctx.r3.s64 = r11.s64 + 14788;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404718"))) PPC_WEAK_FUNC(sub_82404718);
PPC_FUNC_IMPL(__imp__sub_82404718) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r11,r11,14780
	r11.s64 = r11.s64 + 14780;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// cmpwi cr6,r10,0
	cr6.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// beq cr6,0x82404754
	if (cr6.getEQ()) goto loc_82404754;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// bl 0x823ed250
	sub_823ED250(ctx, base);
loc_82404754:
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82404764
	if (cr0.getEQ()) goto loc_82404764;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8209d150
	sub_8209D150(ctx, base);
loc_82404764:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404780"))) PPC_WEAK_FUNC(sub_82404780);
PPC_FUNC_IMPL(__imp__sub_82404780) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r11,r11,14780
	r11.s64 = r11.s64 + 14780;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stw r11,8(r30)
	PPC_STORE_U32(r30.u32 + 8, r11.u32);
	// lwz r11,4(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// beq 0x82404808
	if (cr0.getEQ()) goto loc_82404808;
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82404804
	if (cr0.getEQ()) goto loc_82404804;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_824047C0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x824047c0
	if (!cr6.getEQ()) goto loc_824047C0;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r11,r11,0
	r11.u64 = __builtin_rotateleft32(r11.u32, 0);
	// addi r31,r11,1
	r31.s64 = r11.s64 + 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x823ed2b0
	sub_823ED2B0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r3.u32);
	// beq 0x8240480c
	if (cr0.getEQ()) goto loc_8240480C;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// lwz r5,4(r29)
	ctx.r5.u64 = PPC_LOAD_U32(r29.u32 + 4);
	// bl 0x823ee540
	sub_823EE540(ctx, base);
	// b 0x8240480c
	goto loc_8240480C;
loc_82404804:
	// li r11,0
	r11.s64 = 0;
loc_82404808:
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
loc_8240480C:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82404818"))) PPC_WEAK_FUNC(sub_82404818);
PPC_FUNC_IMPL(__imp__sub_82404818) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r31{};
	uint32_t ea{};
	// lwz r17,13192(r31)
	r17.u64 = PPC_LOAD_U32(r31.u32 + 13192);
	// lwz r16,14832(r7)
	r16.u64 = PPC_LOAD_U32(ctx.r7.u32 + 14832);
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// addi r31,r1,-176
	r31.s64 = ctx.r1.s64 + -176;
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r3,r31,80
	ctx.r3.s64 = r31.s64 + 80;
	// addi r4,r11,14808
	ctx.r4.s64 = r11.s64 + 14808;
	// bl 0x82396d40
	sub_82396D40(ctx, base);
	// addi r4,r31,80
	ctx.r4.s64 = r31.s64 + 80;
	// addi r3,r31,112
	ctx.r3.s64 = r31.s64 + 112;
	// bl 0x82396bf0
	sub_82396BF0(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r3,r31,112
	ctx.r3.s64 = r31.s64 + 112;
	// addi r4,r11,30120
	ctx.r4.s64 = r11.s64 + 30120;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r11,r11,25020
	r11.s64 = r11.s64 + 25020;
	// stw r11,112(r31)
	PPC_STORE_U32(r31.u32 + 112, r11.u32);
	// bl 0x8240be90
	sub_8240BE90(ctx, base);
	// addi r31,r12,-176
	r31.s64 = r12.s64 + -176;
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r3,r31,80
	ctx.r3.s64 = r31.s64 + 80;
	// bl 0x82395e50
	sub_82395E50(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404820"))) PPC_WEAK_FUNC(sub_82404820);
PPC_FUNC_IMPL(__imp__sub_82404820) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// addi r31,r1,-176
	r31.s64 = ctx.r1.s64 + -176;
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r3,r31,80
	ctx.r3.s64 = r31.s64 + 80;
	// addi r4,r11,14808
	ctx.r4.s64 = r11.s64 + 14808;
	// bl 0x82396d40
	sub_82396D40(ctx, base);
	// addi r4,r31,80
	ctx.r4.s64 = r31.s64 + 80;
	// addi r3,r31,112
	ctx.r3.s64 = r31.s64 + 112;
	// bl 0x82396bf0
	sub_82396BF0(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r3,r31,112
	ctx.r3.s64 = r31.s64 + 112;
	// addi r4,r11,30120
	ctx.r4.s64 = r11.s64 + 30120;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r11,r11,25020
	r11.s64 = r11.s64 + 25020;
	// stw r11,112(r31)
	PPC_STORE_U32(r31.u32 + 112, r11.u32);
	// bl 0x8240be90
	sub_8240BE90(ctx, base);
}

__attribute__((alias("__imp__sub_8240486C"))) PPC_WEAK_FUNC(sub_8240486C);
PPC_FUNC_IMPL(__imp__sub_8240486C) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// addi r31,r12,-176
	r31.s64 = r12.s64 + -176;
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r3,r31,80
	ctx.r3.s64 = r31.s64 + 80;
	// bl 0x82395e50
	sub_82395E50(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404898"))) PPC_WEAK_FUNC(sub_82404898);
PPC_FUNC_IMPL(__imp__sub_82404898) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// lwz r17,13192(r31)
	r17.u64 = PPC_LOAD_U32(r31.u32 + 13192);
	// lwz r16,14888(r7)
	r16.u64 = PPC_LOAD_U32(ctx.r7.u32 + 14888);
	// mflr r12
	// bl 0x823ed13c
	// addi r31,r1,-112
	r31.s64 = ctx.r1.s64 + -112;
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// stw r30,132(r31)
	PPC_STORE_U32(r31.u32 + 132, r30.u32);
	// bl 0x82404780
	sub_82404780(ctx, base);
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r4,r29,12
	ctx.r4.s64 = r29.s64 + 12;
	// addi r11,r11,25008
	r11.s64 = r11.s64 + 25008;
	// addi r3,r30,12
	ctx.r3.s64 = r30.s64 + 12;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// bl 0x82396b98
	sub_82396B98(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r31,112
	ctx.r1.s64 = r31.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_824048A0"))) PPC_WEAK_FUNC(sub_824048A0);
PPC_FUNC_IMPL(__imp__sub_824048A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// addi r31,r1,-112
	r31.s64 = ctx.r1.s64 + -112;
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// stw r30,132(r31)
	PPC_STORE_U32(r31.u32 + 132, r30.u32);
	// bl 0x82404780
	sub_82404780(ctx, base);
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r4,r29,12
	ctx.r4.s64 = r29.s64 + 12;
	// addi r11,r11,25008
	r11.s64 = r11.s64 + 25008;
	// addi r3,r30,12
	ctx.r3.s64 = r30.s64 + 12;
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// bl 0x82396b98
	sub_82396B98(ctx, base);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r31,112
	ctx.r1.s64 = r31.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_824048E4"))) PPC_WEAK_FUNC(sub_824048E4);
PPC_FUNC_IMPL(__imp__sub_824048E4) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// addi r31,r12,-112
	r31.s64 = r12.s64 + -112;
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,132(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 132);
	// bl 0x824046d8
	sub_824046D8(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404910"))) PPC_WEAK_FUNC(sub_82404910);
PPC_FUNC_IMPL(__imp__sub_82404910) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x824048a0
	sub_824048A0(ctx, base);
	// lis r11,-32250
	r11.s64 = -2113536000;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,25020
	r11.s64 = r11.s64 + 25020;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404950"))) PPC_WEAK_FUNC(sub_82404950);
PPC_FUNC_IMPL(__imp__sub_82404950) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r17{};
	PPCRegister r31{};
	uint32_t ea{};
	// lwz r17,13192(r31)
	r17.u64 = PPC_LOAD_U32(r31.u32 + 13192);
	// lwz r16,14968(r7)
	r16.u64 = PPC_LOAD_U32(ctx.r7.u32 + 14968);
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// addi r31,r1,-176
	r31.s64 = ctx.r1.s64 + -176;
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r3,r31,80
	ctx.r3.s64 = r31.s64 + 80;
	// addi r4,r11,14936
	ctx.r4.s64 = r11.s64 + 14936;
	// bl 0x82396d40
	sub_82396D40(ctx, base);
	// addi r4,r31,80
	ctx.r4.s64 = r31.s64 + 80;
	// addi r3,r31,112
	ctx.r3.s64 = r31.s64 + 112;
	// bl 0x82396bf0
	sub_82396BF0(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r3,r31,112
	ctx.r3.s64 = r31.s64 + 112;
	// addi r4,r11,30208
	ctx.r4.s64 = r11.s64 + 30208;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r11,r11,25020
	r11.s64 = r11.s64 + 25020;
	// stw r11,112(r31)
	PPC_STORE_U32(r31.u32 + 112, r11.u32);
	// bl 0x8240be90
	sub_8240BE90(ctx, base);
	// addi r31,r12,-176
	r31.s64 = r12.s64 + -176;
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r3,r31,80
	ctx.r3.s64 = r31.s64 + 80;
	// bl 0x82395e50
	sub_82395E50(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404958"))) PPC_WEAK_FUNC(sub_82404958);
PPC_FUNC_IMPL(__imp__sub_82404958) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// addi r31,r1,-176
	r31.s64 = ctx.r1.s64 + -176;
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r3,r31,80
	ctx.r3.s64 = r31.s64 + 80;
	// addi r4,r11,14936
	ctx.r4.s64 = r11.s64 + 14936;
	// bl 0x82396d40
	sub_82396D40(ctx, base);
	// addi r4,r31,80
	ctx.r4.s64 = r31.s64 + 80;
	// addi r3,r31,112
	ctx.r3.s64 = r31.s64 + 112;
	// bl 0x82396bf0
	sub_82396BF0(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r3,r31,112
	ctx.r3.s64 = r31.s64 + 112;
	// addi r4,r11,30208
	ctx.r4.s64 = r11.s64 + 30208;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r11,r11,25020
	r11.s64 = r11.s64 + 25020;
	// stw r11,112(r31)
	PPC_STORE_U32(r31.u32 + 112, r11.u32);
	// bl 0x8240be90
	sub_8240BE90(ctx, base);
}

__attribute__((alias("__imp__sub_824049A4"))) PPC_WEAK_FUNC(sub_824049A4);
PPC_FUNC_IMPL(__imp__sub_824049A4) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// addi r31,r12,-176
	r31.s64 = r12.s64 + -176;
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r3,r31,80
	ctx.r3.s64 = r31.s64 + 80;
	// bl 0x82395e50
	sub_82395E50(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824049D0"))) PPC_WEAK_FUNC(sub_824049D0);
PPC_FUNC_IMPL(__imp__sub_824049D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r6,0(r3)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// li r3,0
	ctx.r3.s64 = 0;
	// rlwinm. r11,r6,0,16,16
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beqlr 
	if (cr0.getEQ()) return;
	// li r9,0
	ctx.r9.s64 = 0;
	// rlwinm r8,r6,16,16,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 16) & 0xFFFF;
	// rlwinm r7,r6,12,20,31
	ctx.r7.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 12) & 0xFFF;
loc_824049EC:
	// li r11,1
	r11.s64 = 1;
	// slw r11,r11,r9
	r11.u64 = ctx.r9.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r9.u8 & 0x3F));
	// and r10,r7,r11
	ctx.r10.u64 = ctx.r7.u64 & r11.u64;
	// and r11,r11,r8
	r11.u64 = r11.u64 & ctx.r8.u64;
	// clrlwi r10,r10,28
	ctx.r10.u64 = ctx.r10.u32 & 0xF;
	// clrlwi r11,r11,28
	r11.u64 = r11.u32 & 0xF;
	// cntlzw r10,r10
	ctx.r10.u64 = ctx.r10.u32 == 0 ? 32 : __builtin_clz(ctx.r10.u32);
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r10,r10,27,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 27) & 0x1;
	// rlwinm r11,r11,28,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 28) & 0x2;
	// xori r10,r10,1
	ctx.r10.u64 = ctx.r10.u64 ^ 1;
	// xori r11,r11,2
	r11.u64 = r11.u64 ^ 2;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// blt cr6,0x82404a50
	if (cr6.getLT()) goto loc_82404A50;
	// beq cr6,0x82404a48
	if (cr6.getEQ()) goto loc_82404A48;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// blt cr6,0x82404a40
	if (cr6.getLT()) goto loc_82404A40;
	// bne cr6,0x82404a5c
	if (!cr6.getEQ()) goto loc_82404A5C;
	// ori r3,r3,8
	ctx.r3.u64 = ctx.r3.u64 | 8;
	// b 0x82404a5c
	goto loc_82404A5C;
loc_82404A40:
	// ori r3,r3,1
	ctx.r3.u64 = ctx.r3.u64 | 1;
	// b 0x82404a5c
	goto loc_82404A5C;
loc_82404A48:
	// ori r3,r3,2
	ctx.r3.u64 = ctx.r3.u64 | 2;
	// b 0x82404a5c
	goto loc_82404A5C;
loc_82404A50:
	// rlwinm. r11,r6,0,17,17
	r11.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0x4000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82404a5c
	if (cr0.getEQ()) goto loc_82404A5C;
	// ori r3,r3,4
	ctx.r3.u64 = ctx.r3.u64 | 4;
loc_82404A5C:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmpwi cr6,r9,4
	cr6.compare<int32_t>(ctx.r9.s32, 4, xer);
	// blt cr6,0x824049ec
	if (cr6.getLT()) goto loc_824049EC;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404A70"))) PPC_WEAK_FUNC(sub_82404A70);
PPC_FUNC_IMPL(__imp__sub_82404A70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lbz r11,8(r3)
	r11.u64 = PPC_LOAD_U8(ctx.r3.u32 + 8);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x82404acc
	if (!cr6.getEQ()) goto loc_82404ACC;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// rlwinm. r10,r11,0,16,16
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82404ac0
	if (cr0.getEQ()) goto loc_82404AC0;
	// bl 0x824049d0
	sub_824049D0(ctx, base);
	// clrlwi. r11,r3,31
	r11.u64 = ctx.r3.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82404acc
	if (!cr0.getEQ()) goto loc_82404ACC;
	// rlwinm. r11,r3,0,30,30
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82404ab4
	if (cr0.getEQ()) goto loc_82404AB4;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82404ad0
	goto loc_82404AD0;
loc_82404AB4:
	// cntlzw r11,r3
	r11.u64 = ctx.r3.u32 == 0 ? 32 : __builtin_clz(ctx.r3.u32);
	// rlwinm r3,r11,27,31,31
	ctx.r3.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// b 0x82404ad0
	goto loc_82404AD0;
loc_82404AC0:
	// rlwinm. r11,r11,0,12,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// beq 0x82404ad0
	if (cr0.getEQ()) goto loc_82404AD0;
loc_82404ACC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_82404AD0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404AE0"))) PPC_WEAK_FUNC(sub_82404AE0);
PPC_FUNC_IMPL(__imp__sub_82404AE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-2160(r1)
	ea = -2160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82404bc4
	if (cr6.getEQ()) goto loc_82404BC4;
	// lwz r11,8236(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8236);
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// blt cr6,0x82404bc4
	if (cr6.getLT()) goto loc_82404BC4;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,2048
	ctx.r4.s64 = 2048;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8240fa0c
	__imp___vsnprintf(ctx, base);
	// mr. r30,r3
	r30.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// ble 0x82404bc4
	if (!cr0.getGT()) goto loc_82404BC4;
	// lbz r11,8233(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 8233);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82404ba0
	if (cr0.getEQ()) goto loc_82404BA0;
	// lbz r11,80(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// li r10,0
	ctx.r10.s64 = 0;
	// extsb r11,r11
	r11.s64 = r11.s8;
	// cmpwi cr6,r11,32
	cr6.compare<int32_t>(r11.s32, 32, xer);
	// stb r10,8233(r31)
	PPC_STORE_U8(r31.u32 + 8233, ctx.r10.u8);
	// beq cr6,0x82404b6c
	if (cr6.getEQ()) goto loc_82404B6C;
	// cmpwi cr6,r11,45
	cr6.compare<int32_t>(r11.s32, 45, xer);
	// beq cr6,0x82404b6c
	if (cr6.getEQ()) goto loc_82404B6C;
	// cmpwi cr6,r11,48
	cr6.compare<int32_t>(r11.s32, 48, xer);
	// blt cr6,0x82404b64
	if (cr6.getLT()) goto loc_82404B64;
	// cmpwi cr6,r11,57
	cr6.compare<int32_t>(r11.s32, 57, xer);
	// ble cr6,0x82404b6c
	if (!cr6.getGT()) goto loc_82404B6C;
loc_82404B64:
	// li r11,1
	r11.s64 = 1;
	// b 0x82404b70
	goto loc_82404B70;
loc_82404B6C:
	// li r11,0
	r11.s64 = 0;
loc_82404B70:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82404ba0
	if (!cr0.getEQ()) goto loc_82404BA0;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// lwz r3,8220(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8220);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r11,-21432
	ctx.r4.s64 = r11.s64 + -21432;
	// lwz r11,8216(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8216);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82404ba0
	if (!cr0.getLT()) goto loc_82404BA0;
	// stw r3,8236(r31)
	PPC_STORE_U32(r31.u32 + 8236, ctx.r3.u32);
loc_82404BA0:
	// lwz r3,8220(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8220);
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// lwz r11,8216(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8216);
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82404bc4
	if (!cr0.getLT()) goto loc_82404BC4;
	// stw r3,8236(r31)
	PPC_STORE_U32(r31.u32 + 8236, ctx.r3.u32);
loc_82404BC4:
	// addi r1,r1,2160
	ctx.r1.s64 = ctx.r1.s64 + 2160;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404BE0"))) PPC_WEAK_FUNC(sub_82404BE0);
PPC_FUNC_IMPL(__imp__sub_82404BE0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// li r9,0
	ctx.r9.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// stb r9,8232(r3)
	PPC_STORE_U8(ctx.r3.u32 + 8232, ctx.r9.u8);
	// bl 0x82404ae0
	sub_82404AE0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404C30"))) PPC_WEAK_FUNC(sub_82404C30);
PPC_FUNC_IMPL(__imp__sub_82404C30) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r27,r5
	r27.u64 = ctx.r5.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r29,r11,5360
	r29.s64 = r11.s64 + 5360;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r28,r11,5368
	r28.s64 = r11.s64 + 5368;
	// bne 0x82404c6c
	if (!cr0.getEQ()) goto loc_82404C6C;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// beq cr6,0x82404ca4
	if (cr6.getEQ()) goto loc_82404CA4;
loc_82404C6C:
	// clrlwi. r11,r6,24
	r11.u64 = ctx.r6.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82404c84
	if (cr0.getEQ()) goto loc_82404C84;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,8588
	ctx.r4.s64 = r11.s64 + 8588;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82404C84:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bne cr6,0x82404c94
	if (!cr6.getEQ()) goto loc_82404C94;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
loc_82404C94:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15560
	ctx.r4.s64 = r11.s64 + 15560;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82404CA4:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82404cb8
	if (!cr0.getEQ()) goto loc_82404CB8;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x82404cd8
	if (!cr6.getEQ()) goto loc_82404CD8;
loc_82404CB8:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
	// bne cr6,0x82404cc8
	if (!cr6.getEQ()) goto loc_82404CC8;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
loc_82404CC8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15532
	ctx.r4.s64 = r11.s64 + 15532;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82404CD8:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_82404CE0"))) PPC_WEAK_FUNC(sub_82404CE0);
PPC_FUNC_IMPL(__imp__sub_82404CE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82404d20
	if (cr0.getEQ()) goto loc_82404D20;
	// li r10,0
	ctx.r10.s64 = 0;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,8704
	ctx.r4.s64 = r11.s64 + 8704;
	// stb r10,8233(r31)
	PPC_STORE_U8(r31.u32 + 8233, ctx.r10.u8);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// li r11,1
	r11.s64 = 1;
	// stb r11,8233(r31)
	PPC_STORE_U8(r31.u32 + 8233, r11.u8);
loc_82404D20:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404D38"))) PPC_WEAK_FUNC(sub_82404D38);
PPC_FUNC_IMPL(__imp__sub_82404D38) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r4,r11,-19336
	ctx.r4.s64 = r11.s64 + -19336;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// bl 0x82404ce0
	sub_82404CE0(ctx, base);
	// clrlwi. r11,r30,24
	r11.u64 = r30.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82404d70
	if (cr0.getEQ()) goto loc_82404D70;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r6,r11,15588
	ctx.r6.s64 = r11.s64 + 15588;
	// b 0x82404d78
	goto loc_82404D78;
loc_82404D70:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r6,r11,2334
	ctx.r6.s64 = r11.s64 + 2334;
loc_82404D78:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r4,r11,8944
	ctx.r4.s64 = r11.s64 + 8944;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-19328
	ctx.r4.s64 = r11.s64 + -19328;
	// bl 0x82404ce0
	sub_82404CE0(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82404DA8"))) PPC_WEAK_FUNC(sub_82404DA8);
PPC_FUNC_IMPL(__imp__sub_82404DA8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r4,r11,15596
	ctx.r4.s64 = r11.s64 + 15596;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82404ce0
	sub_82404CE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r11,8704
	ctx.r4.s64 = r11.s64 + 8704;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-19328
	ctx.r4.s64 = r11.s64 + -19328;
	// bl 0x82404ce0
	sub_82404CE0(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404E10"))) PPC_WEAK_FUNC(sub_82404E10);
PPC_FUNC_IMPL(__imp__sub_82404E10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r10,8(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// rlwinm. r10,r10,0,26,26
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82404e50
	if (cr0.getEQ()) goto loc_82404E50;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// addi r4,r10,15604
	ctx.r4.s64 = ctx.r10.s64 + 15604;
	// addze r10,r9
	temp.s64 = ctx.r9.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r9.u32;
	ctx.r10.s64 = temp.s64;
	// srawi r9,r11,1
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1) != 0);
	ctx.r9.s64 = r11.s32 >> 1;
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// addze r5,r9
	temp.s64 = ctx.r9.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r9.u32;
	ctx.r5.s64 = temp.s64;
	// subf r6,r10,r11
	ctx.r6.s64 = r11.s64 - ctx.r10.s64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82404E50:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404E60"))) PPC_WEAK_FUNC(sub_82404E60);
PPC_FUNC_IMPL(__imp__sub_82404E60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r4,r11,-19320
	ctx.r4.s64 = r11.s64 + -19320;
	// bl 0x82404ce0
	sub_82404CE0(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15652
	ctx.r4.s64 = r11.s64 + 15652;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82404EA8"))) PPC_WEAK_FUNC(sub_82404EA8);
PPC_FUNC_IMPL(__imp__sub_82404EA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed11c
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// mr r11,r4
	r11.u64 = ctx.r4.u64;
	// addi r4,r10,-21432
	ctx.r4.s64 = ctx.r10.s64 + -21432;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// mr r24,r5
	r24.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// mr r22,r8
	r22.u64 = ctx.r8.u64;
	// mr r23,r9
	r23.u64 = ctx.r9.u64;
	// clrlwi r31,r11,26
	r31.u64 = r11.u32 & 0x3F;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// li r21,0
	r21.s64 = 0;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x82404ef8
	if (!cr6.getEQ()) goto loc_82404EF8;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// bne cr6,0x82404efc
	if (!cr6.getEQ()) goto loc_82404EFC;
loc_82404EF8:
	// mr r11,r21
	r11.u64 = r21.u64;
loc_82404EFC:
	// clrlwi r28,r11,24
	r28.u64 = r11.u32 & 0xFF;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// bne cr6,0x82404f20
	if (!cr6.getEQ()) goto loc_82404F20;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x82404f18
	if (cr6.getEQ()) goto loc_82404F18;
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// bne cr6,0x82404f20
	if (!cr6.getEQ()) goto loc_82404F20;
loc_82404F18:
	// li r11,1
	r11.s64 = 1;
	// b 0x82404f24
	goto loc_82404F24;
loc_82404F20:
	// mr r11,r21
	r11.u64 = r21.u64;
loc_82404F24:
	// clrlwi r25,r11,24
	r25.u64 = r11.u32 & 0xFF;
	// li r30,-1
	r30.s64 = -1;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x82404fdc
	if (cr6.getEQ()) goto loc_82404FDC;
	// cmpwi cr6,r31,32
	cr6.compare<int32_t>(r31.s32, 32, xer);
	// beq cr6,0x82404fd0
	if (cr6.getEQ()) goto loc_82404FD0;
	// ble cr6,0x82404f80
	if (!cr6.getGT()) goto loc_82404F80;
	// cmpwi cr6,r31,37
	cr6.compare<int32_t>(r31.s32, 37, xer);
	// ble cr6,0x82404f70
	if (!cr6.getGT()) goto loc_82404F70;
	// cmpwi cr6,r31,62
	cr6.compare<int32_t>(r31.s32, 62, xer);
	// beq cr6,0x82404f64
	if (cr6.getEQ()) goto loc_82404F64;
	// cmpwi cr6,r31,63
	cr6.compare<int32_t>(r31.s32, 63, xer);
	// bne cr6,0x82404f80
	if (!cr6.getEQ()) goto loc_82404F80;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r5,r11,10392
	ctx.r5.s64 = r11.s64 + 10392;
	// b 0x82404fe8
	goto loc_82404FE8;
loc_82404F64:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r5,r11,10400
	ctx.r5.s64 = r11.s64 + 10400;
	// b 0x82404fe8
	goto loc_82404FE8;
loc_82404F70:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r30,r31,-33
	r30.s64 = r31.s64 + -33;
	// addi r5,r11,31800
	ctx.r5.s64 = r11.s64 + 31800;
	// b 0x82404fe8
	goto loc_82404FE8;
loc_82404F80:
	// lwz r11,8(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 8);
	// rlwinm. r11,r11,29,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82404fc4
	if (cr0.getEQ()) goto loc_82404FC4;
	// lwz r11,0(r29)
	r11.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// rlwinm r10,r11,4,29,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0x7;
	// cmpw cr6,r31,r10
	cr6.compare<int32_t>(r31.s32, ctx.r10.s32, xer);
	// bge cr6,0x82404fa8
	if (!cr6.getLT()) goto loc_82404FA8;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r5,r11,10368
	ctx.r5.s64 = r11.s64 + 10368;
	// b 0x82404fe4
	goto loc_82404FE4;
loc_82404FA8:
	// cmpwi cr6,r31,61
	cr6.compare<int32_t>(r31.s32, 61, xer);
	// bne cr6,0x82404fc4
	if (!cr6.getEQ()) goto loc_82404FC4;
	// rlwinm. r11,r11,0,4,4
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82404fc4
	if (cr0.getEQ()) goto loc_82404FC4;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r5,r11,10360
	ctx.r5.s64 = r11.s64 + 10360;
	// b 0x82404fe8
	goto loc_82404FE8;
loc_82404FC4:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r5,r11,10324
	ctx.r5.s64 = r11.s64 + 10324;
	// b 0x82404fe4
	goto loc_82404FE4;
loc_82404FD0:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r5,r11,31804
	ctx.r5.s64 = r11.s64 + 31804;
	// b 0x82404fe8
	goto loc_82404FE8;
loc_82404FDC:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r5,r11,10420
	ctx.r5.s64 = r11.s64 + 10420;
loc_82404FE4:
	// mr r30,r31
	r30.u64 = r31.u64;
loc_82404FE8:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r4,r11,8704
	ctx.r4.s64 = r11.s64 + 8704;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// clrlwi. r31,r28,24
	r31.u64 = r28.u32 & 0xFF;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// beq 0x82405010
	if (cr0.getEQ()) goto loc_82405010;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r4,r11,-6772
	ctx.r4.s64 = r11.s64 + -6772;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82405010:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x82405030
	if (!cr6.getEQ()) goto loc_82405030;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// beq cr6,0x82405030
	if (cr6.getEQ()) goto loc_82405030;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r4,r11,15668
	ctx.r4.s64 = r11.s64 + 15668;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82405030:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x8240504c
	if (cr6.getLT()) goto loc_8240504C;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r11,5300
	ctx.r4.s64 = r11.s64 + 5300;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_8240504C:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82405064
	if (cr6.getEQ()) goto loc_82405064;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r4,r11,-6780
	ctx.r4.s64 = r11.s64 + -6780;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82405064:
	// clrlwi. r11,r25,24
	r11.u64 = r25.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82405078
	if (cr0.getEQ()) goto loc_82405078;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15664
	ctx.r4.s64 = r11.s64 + 15664;
	// b 0x8240520c
	goto loc_8240520C;
loc_82405078:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x824050f4
	if (!cr6.getEQ()) goto loc_824050F4;
	// cmpwi cr6,r24,15
	cr6.compare<int32_t>(r24.s32, 15, xer);
	// beq cr6,0x82405214
	if (cr6.getEQ()) goto loc_82405214;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r4,r11,-19388
	ctx.r4.s64 = r11.s64 + -19388;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// clrlwi. r11,r24,31
	r11.u64 = r24.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824050b0
	if (cr0.getEQ()) goto loc_824050B0;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r4,r11,31520
	ctx.r4.s64 = r11.s64 + 31520;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824050B0:
	// rlwinm. r11,r24,0,30,30
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824050c8
	if (cr0.getEQ()) goto loc_824050C8;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r4,r11,31516
	ctx.r4.s64 = r11.s64 + 31516;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824050C8:
	// rlwinm. r11,r24,0,29,29
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824050e0
	if (cr0.getEQ()) goto loc_824050E0;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r4,r11,31508
	ctx.r4.s64 = r11.s64 + 31508;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824050E0:
	// rlwinm. r11,r24,0,28,28
	r11.u64 = __builtin_rotateleft64(r24.u32 | (r24.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82405214
	if (cr0.getEQ()) goto loc_82405214;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r11,15264
	ctx.r4.s64 = r11.s64 + 15264;
	// b 0x8240520c
	goto loc_8240520C;
loc_824050F4:
	// cmpwi cr6,r24,15
	cr6.compare<int32_t>(r24.s32, 15, xer);
	// bne cr6,0x82405104
	if (!cr6.getEQ()) goto loc_82405104;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// beq cr6,0x82405214
	if (cr6.getEQ()) goto loc_82405214;
loc_82405104:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r4,r11,-19388
	ctx.r4.s64 = r11.s64 + -19388;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
	// addi r9,r11,15660
	ctx.r9.s64 = r11.s64 + 15660;
loc_82405120:
	// li r11,1
	r11.s64 = 1;
	// slw r11,r11,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (r11.u32 << (ctx.r10.u8 & 0x3F));
	// and. r8,r11,r24
	ctx.r8.u64 = r11.u64 & r24.u64;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// beq 0x82405148
	if (cr0.getEQ()) goto loc_82405148;
	// and. r11,r11,r23
	r11.u64 = r11.u64 & r23.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82405140
	if (cr0.getEQ()) goto loc_82405140;
	// li r11,49
	r11.s64 = 49;
	// b 0x8240516c
	goto loc_8240516C;
loc_82405140:
	// lbzx r11,r10,r9
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + ctx.r9.u32);
	// b 0x8240516c
	goto loc_8240516C;
loc_82405148:
	// and. r11,r11,r23
	r11.u64 = r11.u64 & r23.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82405158
	if (cr0.getEQ()) goto loc_82405158;
	// li r11,95
	r11.s64 = 95;
	// b 0x8240516c
	goto loc_8240516C;
loc_82405158:
	// subfic r11,r22,0
	xer.ca = r22.u32 <= 0;
	r11.s64 = 0 - r22.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// rlwinm r11,r11,0,31,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFF1;
	// rlwinm r11,r11,0,27,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFDF;
	// addi r11,r11,95
	r11.s64 = r11.s64 + 95;
loc_8240516C:
	// addi r8,r1,144
	ctx.r8.s64 = ctx.r1.s64 + 144;
	// stbx r11,r10,r8
	PPC_STORE_U8(ctx.r10.u32 + ctx.r8.u32, r11.u8);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r10,4
	cr6.compare<int32_t>(ctx.r10.s32, 4, xer);
	// blt cr6,0x82405120
	if (cr6.getLT()) goto loc_82405120;
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r8,r1,152
	ctx.r8.s64 = ctx.r1.s64 + 152;
	// mr r10,r21
	ctx.r10.u64 = r21.u64;
loc_8240518C:
	// addi r11,r1,144
	r11.s64 = ctx.r1.s64 + 144;
	// lbzx r9,r10,r11
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + r11.u32);
	// extsb r11,r9
	r11.s64 = ctx.r9.s8;
	// cmpwi cr6,r11,48
	cr6.compare<int32_t>(r11.s32, 48, xer);
	// beq cr6,0x824051c8
	if (cr6.getEQ()) goto loc_824051C8;
	// cmpwi cr6,r11,49
	cr6.compare<int32_t>(r11.s32, 49, xer);
	// beq cr6,0x824051c8
	if (cr6.getEQ()) goto loc_824051C8;
	// cmpwi cr6,r11,95
	cr6.compare<int32_t>(r11.s32, 95, xer);
	// beq cr6,0x824051b8
	if (cr6.getEQ()) goto loc_824051B8;
	// stb r9,0(r8)
	PPC_STORE_U8(ctx.r8.u32 + 0, ctx.r9.u8);
	// addi r8,r8,1
	ctx.r8.s64 = ctx.r8.s64 + 1;
loc_824051B8:
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmpwi cr6,r10,4
	cr6.compare<int32_t>(ctx.r10.s32, 4, xer);
	// blt cr6,0x8240518c
	if (cr6.getLT()) goto loc_8240518C;
	// b 0x824051cc
	goto loc_824051CC;
loc_824051C8:
	// mr r7,r21
	ctx.r7.u64 = r21.u64;
loc_824051CC:
	// clrlwi. r11,r7,24
	r11.u64 = ctx.r7.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824051e0
	if (cr0.getEQ()) goto loc_824051E0;
	// addi r4,r1,152
	ctx.r4.s64 = ctx.r1.s64 + 152;
	// stb r21,0(r8)
	PPC_STORE_U8(ctx.r8.u32 + 0, r21.u8);
	// b 0x8240520c
	goto loc_8240520C;
loc_824051E0:
	// stb r21,148(r1)
	PPC_STORE_U8(ctx.r1.u32 + 148, r21.u8);
	// li r11,3
	r11.s64 = 3;
loc_824051E8:
	// addi r10,r1,144
	ctx.r10.s64 = ctx.r1.s64 + 144;
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lbz r9,0(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// cmplwi cr6,r9,95
	cr6.compare<uint32_t>(ctx.r9.u32, 95, xer);
	// bne cr6,0x82405208
	if (!cr6.getEQ()) goto loc_82405208;
	// addic. r11,r11,-1
	xer.ca = r11.u32 > 0;
	r11.s64 = r11.s64 + -1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// stb r21,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, r21.u8);
	// bgt 0x824051e8
	if (cr0.getGT()) goto loc_824051E8;
loc_82405208:
	// addi r4,r1,144
	ctx.r4.s64 = ctx.r1.s64 + 144;
loc_8240520C:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82405214:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x823ed16c
	return;
}

__attribute__((alias("__imp__sub_82405220"))) PPC_WEAK_FUNC(sub_82405220);
PPC_FUNC_IMPL(__imp__sub_82405220) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed11c
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r22,r7
	r22.u64 = ctx.r7.u64;
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// bne cr6,0x8240524c
	if (!cr6.getEQ()) goto loc_8240524C;
	// cmpwi cr6,r8,0
	cr6.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne cr6,0x8240525c
	if (!cr6.getEQ()) goto loc_8240525C;
loc_8240524C:
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// bne cr6,0x82405264
	if (!cr6.getEQ()) goto loc_82405264;
	// rlwinm. r11,r5,0,24,24
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82405264
	if (cr0.getEQ()) goto loc_82405264;
loc_8240525C:
	// li r21,1
	r21.s64 = 1;
	// b 0x82405268
	goto loc_82405268;
loc_82405264:
	// li r21,0
	r21.s64 = 0;
loc_82405268:
	// srawi r10,r5,6
	xer.ca = (ctx.r5.s32 < 0) & ((ctx.r5.u32 & 0x3F) != 0);
	ctx.r10.s64 = ctx.r5.s32 >> 6;
	// subfic r8,r30,0
	xer.ca = r30.u32 <= 0;
	ctx.r8.s64 = 0 - r30.s64;
	// cntlzw r11,r30
	r11.u64 = r30.u32 == 0 ? 32 : __builtin_clz(r30.u32);
	// subfe r8,r8,r8
	temp.u8 = (~ctx.r8.u32 + ctx.r8.u32 < ~ctx.r8.u32) | (~ctx.r8.u32 + ctx.r8.u32 + xer.ca < xer.ca);
	ctx.r8.u64 = ~ctx.r8.u64 + ctx.r8.u64 + xer.ca;
	xer.ca = temp.u8;
	// rlwinm r7,r11,27,31,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// rlwinm r11,r8,0,0,25
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 0) & 0xFFFFFFC0;
	// and r10,r10,r30
	ctx.r10.u64 = ctx.r10.u64 & r30.u64;
	// rlwinm r11,r11,0,25,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFF7F;
	// clrlwi r27,r10,31
	r27.u64 = ctx.r10.u32 & 0x1;
	// addi r11,r11,255
	r11.s64 = r11.s64 + 255;
	// and r23,r7,r6
	r23.u64 = ctx.r7.u64 & ctx.r6.u64;
	// and r24,r11,r5
	r24.u64 = r11.u64 & ctx.r5.u64;
	// cmpwi cr6,r9,0
	cr6.compare<int32_t>(ctx.r9.s32, 0, xer);
	// beq cr6,0x824052b0
	if (cr6.getEQ()) goto loc_824052B0;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,8584
	ctx.r4.s64 = r11.s64 + 8584;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824052B0:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x824052c4
	if (!cr6.getEQ()) goto loc_824052C4;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// li r10,0
	ctx.r10.s64 = 0;
	// beq cr6,0x824052c8
	if (cr6.getEQ()) goto loc_824052C8;
loc_824052C4:
	// li r10,1
	ctx.r10.s64 = 1;
loc_824052C8:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// subfic r9,r30,0
	xer.ca = r30.u32 <= 0;
	ctx.r9.s64 = 0 - r30.s64;
	// addi r25,r11,-21324
	r25.s64 = r11.s64 + -21324;
	// subfe r11,r9,r9
	temp.u8 = (~ctx.r9.u32 + ctx.r9.u32 < ~ctx.r9.u32) | (~ctx.r9.u32 + ctx.r9.u32 + xer.ca < xer.ca);
	r11.u64 = ~ctx.r9.u64 + ctx.r9.u64 + xer.ca;
	xer.ca = temp.u8;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// clrlwi r11,r11,28
	r11.u64 = r11.u32 & 0xF;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r5,r11,99
	ctx.r5.s64 = r11.s64 + 99;
	// mr r30,r10
	r30.u64 = ctx.r10.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r26,r11,15672
	r26.s64 = r11.s64 + 15672;
	// clrlwi. r29,r30,24
	r29.u64 = r30.u32 & 0xFF;
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x82405324
	if (cr0.getEQ()) goto loc_82405324;
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// beq cr6,0x82405314
	if (cr6.getEQ()) goto loc_82405314;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82405314:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-6772
	ctx.r4.s64 = r11.s64 + -6772;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82405324:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r5,r24
	ctx.r5.u64 = r24.u64;
	// addi r4,r11,5300
	ctx.r4.s64 = r11.s64 + 5300;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// addi r30,r11,-6764
	r30.s64 = r11.s64 + -6764;
	// beq cr6,0x82405354
	if (cr6.getEQ()) goto loc_82405354;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82405354:
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// beq cr6,0x8240537c
	if (cr6.getEQ()) goto loc_8240537C;
	// cmpwi cr6,r22,0
	cr6.compare<int32_t>(r22.s32, 0, xer);
	// beq cr6,0x82405370
	if (cr6.getEQ()) goto loc_82405370;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r4,r11,-6776
	ctx.r4.s64 = r11.s64 + -6776;
	// b 0x82405374
	goto loc_82405374;
loc_82405370:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
loc_82405374:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_8240537C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82405390
	if (cr6.getEQ()) goto loc_82405390;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r4,r11,-6780
	ctx.r4.s64 = r11.s64 + -6780;
	// b 0x8240539c
	goto loc_8240539C;
loc_82405390:
	// cmpwi cr6,r21,0
	cr6.compare<int32_t>(r21.s32, 0, xer);
	// beq cr6,0x824053a4
	if (cr6.getEQ()) goto loc_824053A4;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
loc_8240539C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824053A4:
	// lwz r29,340(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 340);
	// cmpwi cr6,r29,4
	cr6.compare<int32_t>(r29.s32, 4, xer);
	// bge cr6,0x82405418
	if (!cr6.getLT()) goto loc_82405418;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-19388
	ctx.r4.s64 = r11.s64 + -19388;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// addi r30,r11,31464
	r30.s64 = r11.s64 + 31464;
	// srawi r11,r28,6
	xer.ca = (r28.s32 < 0) & ((r28.u32 & 0x3F) != 0);
	r11.s64 = r28.s32 >> 6;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// lbzx r11,r11,r30
	r11.u64 = PPC_LOAD_U8(r11.u32 + r30.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// cmpwi cr6,r29,1
	cr6.compare<int32_t>(r29.s32, 1, xer);
	// ble cr6,0x824054e0
	if (!cr6.getGT()) goto loc_824054E0;
	// lbz r11,351(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 351);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x8240540c
	if (cr0.getEQ()) goto loc_8240540C;
	// srawi r11,r28,4
	xer.ca = (r28.s32 < 0) & ((r28.u32 & 0xF) != 0);
	r11.s64 = r28.s32 >> 4;
	// addi r11,r11,-2
	r11.s64 = r11.s64 + -2;
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// b 0x82405410
	goto loc_82405410;
loc_8240540C:
	// clrlwi r11,r28,30
	r11.u64 = r28.u32 & 0x3;
loc_82405410:
	// lbzx r11,r11,r30
	r11.u64 = PPC_LOAD_U8(r11.u32 + r30.u32);
	// b 0x824054d0
	goto loc_824054D0;
loc_82405418:
	// cmpwi cr6,r28,0
	cr6.compare<int32_t>(r28.s32, 0, xer);
	// beq cr6,0x824054e0
	if (cr6.getEQ()) goto loc_824054E0;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-19388
	ctx.r4.s64 = r11.s64 + -19388;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// srawi r9,r28,2
	xer.ca = (r28.s32 < 0) & ((r28.u32 & 0x3) != 0);
	ctx.r9.s64 = r28.s32 >> 2;
	// addi r29,r11,31464
	r29.s64 = r11.s64 + 31464;
	// srawi r10,r28,4
	xer.ca = (r28.s32 < 0) & ((r28.u32 & 0xF) != 0);
	ctx.r10.s64 = r28.s32 >> 4;
	// srawi r11,r28,6
	xer.ca = (r28.s32 < 0) & ((r28.u32 & 0x3F) != 0);
	r11.s64 = r28.s32 >> 6;
	// clrlwi r30,r28,30
	r30.u64 = r28.u32 & 0x3;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// clrlwi r26,r11,30
	r26.u64 = r11.u32 & 0x3;
	// addi r10,r10,-2
	ctx.r10.s64 = ctx.r10.s64 + -2;
	// lbzx r11,r30,r29
	r11.u64 = PPC_LOAD_U8(r30.u32 + r29.u32);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// clrlwi r28,r9,30
	r28.u64 = ctx.r9.u32 & 0x3;
	// clrlwi r27,r10,30
	r27.u64 = ctx.r10.u32 & 0x3;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// cmpw cr6,r28,r30
	cr6.compare<int32_t>(r28.s32, r30.s32, xer);
	// bne cr6,0x8240548c
	if (!cr6.getEQ()) goto loc_8240548C;
	// cmpw cr6,r27,r30
	cr6.compare<int32_t>(r27.s32, r30.s32, xer);
	// bne cr6,0x8240548c
	if (!cr6.getEQ()) goto loc_8240548C;
	// cmpw cr6,r26,r30
	cr6.compare<int32_t>(r26.s32, r30.s32, xer);
	// beq cr6,0x824054e0
	if (cr6.getEQ()) goto loc_824054E0;
loc_8240548C:
	// lbzx r11,r28,r29
	r11.u64 = PPC_LOAD_U8(r28.u32 + r29.u32);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// cmpw cr6,r27,r28
	cr6.compare<int32_t>(r27.s32, r28.s32, xer);
	// bne cr6,0x824054b0
	if (!cr6.getEQ()) goto loc_824054B0;
	// cmpw cr6,r26,r28
	cr6.compare<int32_t>(r26.s32, r28.s32, xer);
	// beq cr6,0x824054e0
	if (cr6.getEQ()) goto loc_824054E0;
loc_824054B0:
	// lbzx r11,r27,r29
	r11.u64 = PPC_LOAD_U8(r27.u32 + r29.u32);
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// cmpw cr6,r26,r27
	cr6.compare<int32_t>(r26.s32, r27.s32, xer);
	// beq cr6,0x824054e0
	if (cr6.getEQ()) goto loc_824054E0;
	// lbzx r11,r26,r29
	r11.u64 = PPC_LOAD_U8(r26.u32 + r29.u32);
loc_824054D0:
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824054E0:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x823ed16c
	return;
}

__attribute__((alias("__imp__sub_824054E8"))) PPC_WEAK_FUNC(sub_824054E8);
PPC_FUNC_IMPL(__imp__sub_824054E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// srawi r11,r4,7
	xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0x7F) != 0);
	r11.s64 = ctx.r4.s32 >> 7;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// clrlwi r30,r4,26
	r30.u64 = ctx.r4.u32 & 0x3F;
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// clrlwi r27,r11,31
	r27.u64 = r11.u32 & 0x1;
	// beq cr6,0x8240551c
	if (cr6.getEQ()) goto loc_8240551C;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,8584
	ctx.r4.s64 = r11.s64 + 8584;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_8240551C:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// addi r28,r11,-6768
	r28.s64 = r11.s64 + -6768;
	// beq cr6,0x82405538
	if (cr6.getEQ()) goto loc_82405538;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82405538:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r11,-6736
	ctx.r4.s64 = r11.s64 + -6736;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-6780
	ctx.r4.s64 = r11.s64 + -6780;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// beq cr6,0x82405608
	if (cr6.getEQ()) goto loc_82405608;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-19388
	ctx.r4.s64 = r11.s64 + -19388;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// clrlwi r9,r29,30
	ctx.r9.u64 = r29.u32 & 0x3;
	// addi r11,r11,31464
	r11.s64 = r11.s64 + 31464;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r30,r10,-21324
	r30.s64 = ctx.r10.s64 + -21324;
	// lbzx r11,r9,r11
	r11.u64 = PPC_LOAD_U8(ctx.r9.u32 + r11.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// srawi r10,r29,2
	xer.ca = (r29.s32 < 0) & ((r29.u32 & 0x3) != 0);
	ctx.r10.s64 = r29.s32 >> 2;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// addi r11,r11,-6744
	r11.s64 = r11.s64 + -6744;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lbzx r11,r10,r11
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + r11.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// srawi r10,r29,4
	xer.ca = (r29.s32 < 0) & ((r29.u32 & 0xF) != 0);
	ctx.r10.s64 = r29.s32 >> 4;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// addi r11,r11,-6752
	r11.s64 = r11.s64 + -6752;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lbzx r11,r10,r11
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + r11.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// srawi r10,r29,6
	xer.ca = (r29.s32 < 0) & ((r29.u32 & 0x3F) != 0);
	ctx.r10.s64 = r29.s32 >> 6;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// addi r11,r11,-6760
	r11.s64 = r11.s64 + -6760;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lbzx r11,r10,r11
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + r11.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82405608:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// beq cr6,0x82405618
	if (cr6.getEQ()) goto loc_82405618;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// b 0x82405620
	goto loc_82405620;
loc_82405618:
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r11,2334
	ctx.r4.s64 = r11.s64 + 2334;
loc_82405620:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_82405630"))) PPC_WEAK_FUNC(sub_82405630);
PPC_FUNC_IMPL(__imp__sub_82405630) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r26,0
	r26.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r24,r26
	r24.u64 = r26.u64;
	// mr r25,r26
	r25.u64 = r26.u64;
	// bl 0x82404a70
	sub_82404A70(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82405678
	if (cr0.getEQ()) goto loc_82405678;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r5,0
	ctx.r5.s64 = 0;
	// addi r4,r11,11004
	ctx.r4.s64 = r11.s64 + 11004;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82404d38
	sub_82404D38(ctx, base);
	// b 0x82405a08
	goto loc_82405A08;
loc_82405678:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lis r8,-32768
	ctx.r8.s64 = -2147483648;
	// addi r10,r11,15296
	ctx.r10.s64 = r11.s64 + 15296;
	// lbz r11,8(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 8);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// lbzx r27,r11,r10
	r27.u64 = PPC_LOAD_U8(r11.u32 + ctx.r10.u32);
	// bne cr6,0x8240570c
	if (!cr6.getEQ()) goto loc_8240570C;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r10,r11,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFFFFFF;
	// xor r11,r10,r11
	r11.u64 = ctx.r10.u64 ^ r11.u64;
	// rlwinm. r11,r11,0,6,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240570c
	if (!cr0.getEQ()) goto loc_8240570C;
	// lbz r11,10(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 10);
	// lbz r10,9(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 9);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x8240570c
	if (!cr6.getEQ()) goto loc_8240570C;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r10,r11,31,1,1
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x40000000;
	// rlwinm r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x8240570c
	if (!cr6.getEQ()) goto loc_8240570C;
	// lbz r11,6(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 6);
	// lbz r10,5(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 5);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x8240570c
	if (!cr6.getEQ()) goto loc_8240570C;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,0,0,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x82405704
	if (cr6.getEQ()) goto loc_82405704;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r10,r11,31,1,1
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x40000000;
	// rlwinm r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x8240570c
	if (!cr6.getEQ()) goto loc_8240570C;
loc_82405704:
	// li r11,1
	r11.s64 = 1;
	// b 0x82405710
	goto loc_82405710;
loc_8240570C:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_82405710:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82405730
	if (cr0.getEQ()) goto loc_82405730;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,11000
	ctx.r4.s64 = r11.s64 + 11000;
loc_82405720:
	// lbz r11,0(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// li r27,1
	r27.s64 = 1;
	// clrlwi r5,r11,31
	ctx.r5.u64 = r11.u32 & 0x1;
	// b 0x824057e0
	goto loc_824057E0;
loc_82405730:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r9,r10,8,27,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0x1F;
	// cmplwi cr6,r9,29
	cr6.compare<uint32_t>(ctx.r9.u32, 29, xer);
	// bne cr6,0x824057b0
	if (!cr6.getEQ()) goto loc_824057B0;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r7,r11,31,1,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x7FFFFFFF;
	// xor r11,r7,r11
	r11.u64 = ctx.r7.u64 ^ r11.u64;
	// rlwinm. r11,r11,0,6,6
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824057b0
	if (!cr0.getEQ()) goto loc_824057B0;
	// lbz r11,10(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 10);
	// lbz r7,9(r31)
	ctx.r7.u64 = PPC_LOAD_U8(r31.u32 + 9);
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// bne cr6,0x824057b0
	if (!cr6.getEQ()) goto loc_824057B0;
	// rotlwi r11,r10,0
	r11.u64 = __builtin_rotateleft32(ctx.r10.u32, 0);
	// rlwinm r7,r11,31,1,1
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x40000000;
	// rlwinm r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// bne cr6,0x824057b0
	if (!cr6.getEQ()) goto loc_824057B0;
	// lbz r11,6(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 6);
	// lbz r7,5(r31)
	ctx.r7.u64 = PPC_LOAD_U8(r31.u32 + 5);
	// cmplw cr6,r7,r11
	cr6.compare<uint32_t>(ctx.r7.u32, r11.u32, xer);
	// bne cr6,0x824057b0
	if (!cr6.getEQ()) goto loc_824057B0;
	// rlwinm r11,r10,0,0,0
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80000000;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x824057a8
	if (cr6.getEQ()) goto loc_824057A8;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r10,r11,31,1,1
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x40000000;
	// rlwinm r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// bne cr6,0x824057b0
	if (!cr6.getEQ()) goto loc_824057B0;
loc_824057A8:
	// li r11,1
	r11.s64 = 1;
	// b 0x824057b4
	goto loc_824057B4;
loc_824057B0:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_824057B4:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824057c8
	if (cr0.getEQ()) goto loc_824057C8;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,10776
	ctx.r4.s64 = r11.s64 + 10776;
	// b 0x82405720
	goto loc_82405720;
loc_824057C8:
	// lis r11,-32015
	r11.s64 = -2098135040;
	// rlwinm r10,r9,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
	// lbz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// addi r11,r11,-15872
	r11.s64 = r11.s64 + -15872;
	// clrlwi r5,r9,31
	ctx.r5.u64 = ctx.r9.u32 & 0x1;
	// lwzx r4,r10,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
loc_824057E0:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82404d38
	sub_82404D38(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r10,1
	ctx.r10.s64 = 1;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// rlwinm r9,r11,12,28,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 12) & 0xF;
	// rlwinm r8,r11,18,31,31
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 18) & 0x1;
	// rlwinm r7,r11,26,31,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	// rlwinm r6,r11,17,31,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 17) & 0x1;
	// rlwinm r5,r11,16,28,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xF;
	// clrlwi r4,r11,26
	ctx.r4.u64 = r11.u32 & 0x3F;
	// bl 0x82404ea8
	sub_82404EA8(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r28,r11,-16560
	r28.s64 = r11.s64 + -16560;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm. r10,r11,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82405844
	if (!cr0.getEQ()) goto loc_82405844;
	// rlwinm. r10,r11,0,1,1
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82405844
	if (!cr0.getEQ()) goto loc_82405844;
	// rlwinm. r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82405844
	if (cr0.getEQ()) goto loc_82405844;
	// li r24,1
	r24.s64 = 1;
loc_82405844:
	// li r29,4
	r29.s64 = 4;
	// cmplwi cr6,r27,1
	cr6.compare<uint32_t>(r27.u32, 1, xer);
	// blt cr6,0x824058c0
	if (cr6.getLT()) goto loc_824058C0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,1,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// not r10,r11
	ctx.r10.u64 = ~r11.u64;
	// clrlwi r25,r10,31
	r25.u64 = ctx.r10.u32 & 0x1;
	// bne 0x82405888
	if (!cr0.getEQ()) goto loc_82405888;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// beq cr6,0x82405888
	if (cr6.getEQ()) goto loc_82405888;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lbz r6,5(r31)
	ctx.r6.u64 = PPC_LOAD_U8(r31.u32 + 5);
	// rlwinm r5,r11,6,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0x1;
	// lbz r4,9(r31)
	ctx.r4.u64 = PPC_LOAD_U8(r31.u32 + 9);
	// bl 0x824054e8
	sub_824054E8(ctx, base);
	// b 0x824058c0
	goto loc_824058C0;
loc_82405888:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r4,r9,1,31,31
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 1) & 0x1;
	// rlwinm r9,r11,6,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0x1;
	// lbz r5,9(r31)
	ctx.r5.u64 = PPC_LOAD_U8(r31.u32 + 9);
	// rlwinm r8,r10,25,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 25) & 0x1;
	// lbz r10,5(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 5);
	// rlwinm r7,r11,3,31,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0x1;
	// stb r26,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, r26.u8);
	// rlwinm r6,r11,1,31,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r29.u32);
	// bl 0x82405220
	sub_82405220(ctx, base);
loc_824058C0:
	// cmplwi cr6,r27,2
	cr6.compare<uint32_t>(r27.u32, 2, xer);
	// blt cr6,0x82405964
	if (cr6.getLT()) goto loc_82405964;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824058e0
	if (!cr0.getEQ()) goto loc_824058E0;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bne cr6,0x824058e0
	if (!cr6.getEQ()) goto loc_824058E0;
	// li r25,2
	r25.s64 = 2;
loc_824058E0:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,1,1
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240591c
	if (!cr0.getEQ()) goto loc_8240591C;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// beq cr6,0x8240591c
	if (cr6.getEQ()) goto loc_8240591C;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lbz r6,6(r31)
	ctx.r6.u64 = PPC_LOAD_U8(r31.u32 + 6);
	// rlwinm r5,r11,7,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 7) & 0x1;
	// lbz r4,10(r31)
	ctx.r4.u64 = PPC_LOAD_U8(r31.u32 + 10);
	// bl 0x824054e8
	sub_824054E8(ctx, base);
	// b 0x82405964
	goto loc_82405964;
loc_8240591C:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r25,2
	cr6.compare<int32_t>(r25.s32, 2, xer);
	// rlwinm r6,r11,1,31,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// beq cr6,0x82405930
	if (cr6.getEQ()) goto loc_82405930;
	// rlwinm r6,r11,2,31,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x1;
loc_82405930:
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r4,r9,2,31,31
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0x1;
	// rlwinm r9,r11,7,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 7) & 0x1;
	// lbz r5,10(r31)
	ctx.r5.u64 = PPC_LOAD_U8(r31.u32 + 10);
	// rlwinm r8,r10,25,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 25) & 0x1;
	// lbz r10,6(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 6);
	// rlwinm r7,r11,3,31,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0x1;
	// stb r26,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, r26.u8);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r29.u32);
	// bl 0x82405220
	sub_82405220(ctx, base);
loc_82405964:
	// cmplwi cr6,r27,3
	cr6.compare<uint32_t>(r27.u32, 3, xer);
	// blt cr6,0x82405a08
	if (cr6.getLT()) goto loc_82405A08;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82405984
	if (!cr0.getEQ()) goto loc_82405984;
	// cmpwi cr6,r25,0
	cr6.compare<int32_t>(r25.s32, 0, xer);
	// bne cr6,0x82405984
	if (!cr6.getEQ()) goto loc_82405984;
	// li r25,3
	r25.s64 = 3;
loc_82405984:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r10,0,2,2
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824059c0
	if (!cr0.getEQ()) goto loc_824059C0;
	// cmpwi cr6,r24,0
	cr6.compare<int32_t>(r24.s32, 0, xer);
	// beq cr6,0x824059c0
	if (cr6.getEQ()) goto loc_824059C0;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi r4,r10,24
	ctx.r4.u64 = ctx.r10.u32 & 0xFF;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// clrlwi r6,r11,24
	ctx.r6.u64 = r11.u32 & 0xFF;
	// rlwinm r5,r11,8,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 8) & 0x1;
	// bl 0x824054e8
	sub_824054E8(ctx, base);
	// b 0x82405a08
	goto loc_82405A08;
loc_824059C0:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r25,3
	cr6.compare<int32_t>(r25.s32, 3, xer);
	// rlwinm r6,r11,1,31,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// beq cr6,0x824059d4
	if (cr6.getEQ()) goto loc_824059D4;
	// rlwinm r6,r11,2,31,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x1;
loc_824059D4:
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi r5,r4,24
	ctx.r5.u64 = ctx.r4.u32 & 0xFF;
	// rlwinm r8,r10,25,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 25) & 0x1;
	// stb r26,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, r26.u8);
	// clrlwi r10,r11,24
	ctx.r10.u64 = r11.u32 & 0xFF;
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r29.u32);
	// rlwinm r9,r11,8,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 8) & 0x1;
	// rlwinm r7,r11,3,31,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0x1;
	// rlwinm r4,r4,3,31,31
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 3) & 0x1;
	// bl 0x82405220
	sub_82405220(ctx, base);
loc_82405A08:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_82405A10"))) PPC_WEAK_FUNC(sub_82405A10);
PPC_FUNC_IMPL(__imp__sub_82405A10) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed124
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// li r25,0
	r25.s64 = 0;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r23,r25
	r23.u64 = r25.u64;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm. r10,r11,0,0,0
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82405a4c
	if (!cr0.getEQ()) goto loc_82405A4C;
	// rlwinm. r10,r11,0,1,1
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82405a4c
	if (!cr0.getEQ()) goto loc_82405A4C;
	// rlwinm. r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82405a4c
	if (cr0.getEQ()) goto loc_82405A4C;
	// li r23,1
	r23.s64 = 1;
loc_82405A4C:
	// lbz r11,8(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 8);
	// mr r24,r25
	r24.u64 = r25.u64;
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// addi r11,r11,-11
	r11.s64 = r11.s64 + -11;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// bgt cr6,0x82405a68
	if (cr6.getGT()) goto loc_82405A68;
	// li r24,1
	r24.s64 = 1;
loc_82405A68:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi. r10,r24,24
	ctx.r10.u64 = r24.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// rlwinm r10,r11,26,6,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x3FFFFFF;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// clrlwi r10,r10,30
	ctx.r10.u64 = ctx.r10.u32 & 0x3;
	// beq 0x82405a88
	if (cr0.getEQ()) goto loc_82405A88;
	// rlwinm r11,r11,28,4,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 28) & 0xFFFFFFF;
	// addi r11,r11,-2
	r11.s64 = r11.s64 + -2;
loc_82405A88:
	// clrlwi r11,r11,30
	r11.u64 = r11.u32 & 0x3;
	// li r26,1
	r26.s64 = 1;
	// subf r11,r11,r10
	r11.s64 = ctx.r10.s64 - r11.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm. r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82405ac0
	if (cr0.getEQ()) goto loc_82405AC0;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r9,5120
	ctx.r9.s64 = 335544320;
	// rlwinm r8,r10,0,0,5
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFC000000;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// bne cr6,0x82405ac0
	if (!cr6.getEQ()) goto loc_82405AC0;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,32248
	ctx.r4.s64 = r11.s64 + 32248;
	// b 0x82405ae4
	goto loc_82405AE4;
loc_82405AC0:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82405b20
	if (cr6.getEQ()) goto loc_82405B20;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r9,23552
	ctx.r9.s64 = 1543503872;
	// rlwinm r8,r10,0,0,5
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFC000000;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// bne cr6,0x82405aec
	if (!cr6.getEQ()) goto loc_82405AEC;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,32240
	ctx.r4.s64 = r11.s64 + 32240;
loc_82405AE4:
	// rlwinm r5,r10,7,31,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0x1;
	// b 0x82405b14
	goto loc_82405B14;
loc_82405AEC:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82405b20
	if (cr6.getEQ()) goto loc_82405B20;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r10,24576
	ctx.r10.s64 = 1610612736;
	// rlwinm r9,r11,0,0,5
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFC000000;
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// bne cr6,0x82405b20
	if (!cr6.getEQ()) goto loc_82405B20;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// rlwinm r5,r11,7,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 7) & 0x1;
	// addi r4,r10,32232
	ctx.r4.s64 = ctx.r10.s64 + 32232;
loc_82405B14:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82404d38
	sub_82404D38(ctx, base);
	// b 0x82405b44
	goto loc_82405B44;
loc_82405B20:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lis r10,-32015
	ctx.r10.s64 = -2098135040;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r10,r10,-15744
	ctx.r10.s64 = ctx.r10.s64 + -15744;
	// rlwinm r9,r11,8,24,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 8) & 0xFC;
	// rlwinm r5,r11,7,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 7) & 0x1;
	// lwzx r4,r9,r10
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// bl 0x82404d38
	sub_82404D38(ctx, base);
	// mr r26,r25
	r26.u64 = r25.u64;
loc_82405B44:
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r7,r11,26,31,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	// rlwinm. r6,r11,17,31,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 17) & 0x1;
	cr0.compare<int32_t>(ctx.r6.s32, 0, xer);
	// bne 0x82405b58
	if (!cr0.getEQ()) goto loc_82405B58;
	// rlwinm r7,r11,18,31,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 18) & 0x1;
loc_82405B58:
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// clrlwi r4,r11,26
	ctx.r4.u64 = r11.u32 & 0x3F;
	// bne cr6,0x82405b68
	if (!cr6.getEQ()) goto loc_82405B68;
	// rlwinm r4,r11,24,26,31
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 24) & 0x3F;
loc_82405B68:
	// li r10,0
	ctx.r10.s64 = 0;
	// rlwinm r9,r11,16,28,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 16) & 0xF;
	// rlwinm r8,r11,18,31,31
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 18) & 0x1;
	// rlwinm r5,r11,12,28,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 12) & 0xF;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x82404ea8
	sub_82404EA8(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r28,r11,15392
	r28.s64 = r11.s64 + 15392;
	// rlwinm r10,r10,6,26,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0x3F;
	// addi r11,r28,-64
	r11.s64 = r28.s64 + -64;
	// lbzx r30,r10,r11
	r30.u64 = PPC_LOAD_U8(ctx.r10.u32 + r11.u32);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// cmpwi r30,0
	cr0.compare<int32_t>(r30.s32, 0, xer);
	// addi r29,r11,-16560
	r29.s64 = r11.s64 + -16560;
	// ble 0x82405bb4
	if (!cr0.getGT()) goto loc_82405BB4;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82405BB4:
	// cmpwi cr6,r30,1
	cr6.compare<int32_t>(r30.s32, 1, xer);
	// bne cr6,0x82405c9c
	if (!cr6.getEQ()) goto loc_82405C9C;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,0,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82405bd0
	if (!cr0.getEQ()) goto loc_82405BD0;
	// li r11,1
	r11.s64 = 1;
	// b 0x82405bf8
	goto loc_82405BF8;
loc_82405BD0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r10,r11,0,1,1
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82405be4
	if (!cr0.getEQ()) goto loc_82405BE4;
	// li r11,2
	r11.s64 = 2;
	// b 0x82405bf8
	goto loc_82405BF8;
loc_82405BE4:
	// rlwinm r11,r11,0,2,2
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20000000;
	// subfic r11,r11,0
	xer.ca = r11.u32 <= 0;
	r11.s64 = 0 - r11.s64;
	// subfe r11,r11,r11
	temp.u8 = (~r11.u32 + r11.u32 < ~r11.u32) | (~r11.u32 + r11.u32 + xer.ca < xer.ca);
	r11.u64 = ~r11.u64 + r11.u64 + xer.ca;
	xer.ca = temp.u8;
	// rlwinm r11,r11,0,31,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFFFFFFFFFD;
	// addi r11,r11,3
	r11.s64 = r11.s64 + 3;
loc_82405BF8:
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r9,r10,0,2,2
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x20000000;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x82405c28
	if (!cr0.getEQ()) goto loc_82405C28;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// beq cr6,0x82405c28
	if (cr6.getEQ()) goto loc_82405C28;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi r4,r10,24
	ctx.r4.u64 = ctx.r10.u32 & 0xFF;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// clrlwi r6,r11,24
	ctx.r6.u64 = r11.u32 & 0xFF;
	// rlwinm r5,r11,8,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 8) & 0x1;
	// bl 0x824054e8
	sub_824054E8(ctx, base);
	// b 0x82405d94
	goto loc_82405D94;
loc_82405C28:
	// clrlwi. r10,r26,24
	ctx.r10.u64 = r26.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82405c38
	if (cr0.getEQ()) goto loc_82405C38;
	// li r10,1
	ctx.r10.s64 = 1;
	// b 0x82405c44
	goto loc_82405C44;
loc_82405C38:
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm r10,r10,6,26,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0x3F;
	// lbzx r10,r10,r28
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + r28.u32);
loc_82405C44:
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x82405c58
	if (!cr6.getEQ()) goto loc_82405C58;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r6,r11,1,31,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// b 0x82405c64
	goto loc_82405C64;
loc_82405C58:
	// cmpwi cr6,r11,2
	cr6.compare<int32_t>(r11.s32, 2, xer);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r6,r11,2,31,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x1;
loc_82405C64:
	// lwz r4,8(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// lwz r9,0(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi r5,r4,24
	ctx.r5.u64 = ctx.r4.u32 & 0xFF;
	// rlwinm r8,r9,25,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 25) & 0x1;
	// stw r10,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r10.u32);
	// clrlwi r10,r11,24
	ctx.r10.u64 = r11.u32 & 0xFF;
	// stb r24,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, r24.u8);
	// rlwinm r9,r11,8,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 8) & 0x1;
	// rlwinm r7,r11,3,31,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0x1;
	// rlwinm r4,r4,3,31,31
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 3) & 0x1;
	// bl 0x82405220
	sub_82405220(ctx, base);
	// b 0x82405d94
	goto loc_82405D94;
loc_82405C9C:
	// cmpwi cr6,r30,2
	cr6.compare<int32_t>(r30.s32, 2, xer);
	// bne cr6,0x82405d94
	if (!cr6.getEQ()) goto loc_82405D94;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r10,r11,1,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// rlwinm r11,r11,2,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x1;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// addi r10,r11,4
	ctx.r10.s64 = r11.s64 + 4;
	// beq 0x82405ce0
	if (cr0.getEQ()) goto loc_82405CE0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm r11,r11,2,30,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x3;
	// not r11,r11
	r11.u64 = ~r11.u64;
	// rlwinm r11,r11,1,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x2;
	// cmpwi cr6,r11,3
	cr6.compare<int32_t>(r11.s32, 3, xer);
	// bne cr6,0x82405ce0
	if (!cr6.getEQ()) goto loc_82405CE0;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// rlwinm r6,r11,1,31,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0x1;
	// b 0x82405cec
	goto loc_82405CEC;
loc_82405CE0:
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmpwi cr6,r10,2
	cr6.compare<int32_t>(ctx.r10.s32, 2, xer);
	// rlwinm r6,r11,2,31,31
	ctx.r6.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x1;
loc_82405CEC:
	// lwz r8,0(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// rlwinm r30,r8,6,26,31
	r30.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 6) & 0x3F;
	// lwz r11,4(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// clrlwi r5,r10,24
	ctx.r5.u64 = ctx.r10.u32 & 0xFF;
	// stb r25,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, r25.u8);
	// clrlwi r10,r11,24
	ctx.r10.u64 = r11.u32 & 0xFF;
	// rlwinm r9,r11,8,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 8) & 0x1;
	// rlwinm r7,r11,3,31,31
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0x1;
	// lbzx r11,r30,r28
	r11.u64 = PPC_LOAD_U8(r30.u32 + r28.u32);
	// rlwinm r8,r8,25,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 25) & 0x1;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bl 0x82405220
	sub_82405220(ctx, base);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lwz r10,4(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// rlwimi r8,r9,30,4,4
	ctx.r8.u64 = (__builtin_rotateleft32(ctx.r9.u32, 30) & 0x8000000) | (ctx.r8.u64 & 0xFFFFFFFFF7FFFFFF);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// rlwimi r7,r8,6,30,31
	ctx.r7.u64 = (__builtin_rotateleft32(ctx.r8.u32, 6) & 0x3) | (ctx.r7.u64 & 0xFFFFFFFFFFFFFFFC);
	// rlwinm r10,r10,6,24,25
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0xC0;
	// clrlwi r5,r7,26
	ctx.r5.u64 = ctx.r7.u32 & 0x3F;
	// rlwinm. r11,r11,0,24,24
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82405d68
	if (cr0.getEQ()) goto loc_82405D68;
	// ori r5,r5,128
	ctx.r5.u64 = ctx.r5.u64 | 128;
loc_82405D68:
	// lbz r11,4(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 4);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// stb r25,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, r25.u8);
	// clrlwi r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	// li r11,1
	r11.s64 = 1;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// bl 0x82405220
	sub_82405220(ctx, base);
loc_82405D94:
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed174
	return;
}

__attribute__((alias("__imp__sub_82405DA0"))) PPC_WEAK_FUNC(sub_82405DA0);
PPC_FUNC_IMPL(__imp__sub_82405DA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r8,8(r3)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// addi r11,r11,5360
	r11.s64 = r11.s64 + 5360;
	// addi r10,r10,5368
	ctx.r10.s64 = ctx.r10.s64 + 5368;
	// mr r9,r4
	ctx.r9.u64 = ctx.r4.u64;
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
	// stw r10,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r10.u32);
	// rlwinm. r8,r8,26,31,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// bne 0x82405ddc
	if (!cr0.getEQ()) goto loc_82405DDC;
	// cmplw cr6,r5,r6
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r6.u32, xer);
	// beq cr6,0x82405df8
	if (cr6.getEQ()) goto loc_82405DF8;
loc_82405DDC:
	// rlwinm r10,r5,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r8,r1,112
	ctx.r8.s64 = ctx.r1.s64 + 112;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r5,r9
	ctx.r5.u64 = ctx.r9.u64;
	// addi r4,r11,15680
	ctx.r4.s64 = r11.s64 + 15680;
	// lwzx r6,r10,r8
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r8.u32);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82405DF8:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82405E08"))) PPC_WEAK_FUNC(sub_82405E08);
PPC_FUNC_IMPL(__imp__sub_82405E08) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r5,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.r5.u64);
	// std r6,40(r1)
	PPC_STORE_U64(ctx.r1.u32 + 40, ctx.r6.u64);
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r1,128
	ctx.r10.s64 = ctx.r1.s64 + 128;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r5,80(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x82404ae0
	sub_82404AE0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82405E50"))) PPC_WEAK_FUNC(sub_82405E50);
PPC_FUNC_IMPL(__imp__sub_82405E50) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82405e80
	if (cr0.getEQ()) goto loc_82405E80;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r4,r11,-19344
	ctx.r4.s64 = r11.s64 + -19344;
	// bl 0x82404ce0
	sub_82404CE0(ctx, base);
	// b 0x82405e8c
	goto loc_82405E8C;
loc_82405E80:
	// lis r11,-32255
	r11.s64 = -2113863680;
	// addi r4,r11,23060
	ctx.r4.s64 = r11.s64 + 23060;
	// bl 0x82405e08
	sub_82405E08(ctx, base);
loc_82405E8C:
	// li r11,1
	r11.s64 = 1;
	// stb r11,8232(r31)
	PPC_STORE_U8(r31.u32 + 8232, r11.u8);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82405EA8"))) PPC_WEAK_FUNC(sub_82405EA8);
PPC_FUNC_IMPL(__imp__sub_82405EA8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lbz r11,8232(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 8232);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x82405ecc
	if (!cr0.getEQ()) goto loc_82405ECC;
	// bl 0x82405e50
	sub_82405E50(ctx, base);
loc_82405ECC:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r10,r11,25,31,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 25) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82405f00
	if (cr0.getEQ()) goto loc_82405F00;
	// rlwinm. r11,r11,0,27,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq 0x82405ef4
	if (cr0.getEQ()) goto loc_82405EF4;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r4,r11,-19344
	ctx.r4.s64 = r11.s64 + -19344;
	// bl 0x82404ce0
	sub_82404CE0(ctx, base);
	// b 0x82405f00
	goto loc_82405F00;
loc_82405EF4:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15688
	ctx.r4.s64 = r11.s64 + 15688;
	// bl 0x82405e08
	sub_82405E08(ctx, base);
loc_82405F00:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82405F18"))) PPC_WEAK_FUNC(sub_82405F18);
PPC_FUNC_IMPL(__imp__sub_82405F18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r4,r11,-19328
	ctx.r4.s64 = r11.s64 + -19328;
	// bl 0x82404ce0
	sub_82404CE0(ctx, base);
	// lbz r11,8232(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 8232);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x82405f4c
	if (!cr0.getEQ()) goto loc_82405F4C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405e50
	sub_82405E50(ctx, base);
loc_82405F4C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82405F60"))) PPC_WEAK_FUNC(sub_82405F60);
PPC_FUNC_IMPL(__imp__sub_82405F60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// std r7,48(r1)
	PPC_STORE_U64(ctx.r1.u32 + 48, ctx.r7.u64);
	// std r8,56(r1)
	PPC_STORE_U64(ctx.r1.u32 + 56, ctx.r8.u64);
	// std r9,64(r1)
	PPC_STORE_U64(ctx.r1.u32 + 64, ctx.r9.u64);
	// std r10,72(r1)
	PPC_STORE_U64(ctx.r1.u32 + 72, ctx.r10.u64);
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// lbz r11,8232(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 8232);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x82405f9c
	if (!cr0.getEQ()) goto loc_82405F9C;
	// bl 0x82405e50
	sub_82405E50(ctx, base);
loc_82405F9C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404e60
	sub_82404E60(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// clrlwi. r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82405fc4
	if (cr0.getEQ()) goto loc_82405FC4;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// addi r4,r11,15712
	ctx.r4.s64 = r11.s64 + 15712;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// b 0x82405fe8
	goto loc_82405FE8;
loc_82405FC4:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// srawi r10,r30,1
	xer.ca = (r30.s32 < 0) & ((r30.u32 & 0x1) != 0);
	ctx.r10.s64 = r30.s32 >> 1;
	// addi r4,r11,15704
	ctx.r4.s64 = r11.s64 + 15704;
	// addze r11,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	r11.s64 = temp.s64;
	// srawi r10,r30,1
	xer.ca = (r30.s32 < 0) & ((r30.u32 & 0x1) != 0);
	ctx.r10.s64 = r30.s32 >> 1;
	// rlwinm r11,r11,1,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// addze r5,r10
	temp.s64 = ctx.r10.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r10.u32;
	ctx.r5.s64 = temp.s64;
	// subf r6,r11,r30
	ctx.r6.s64 = r30.s64 - r11.s64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82405FE8:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15692
	ctx.r4.s64 = r11.s64 + 15692;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// addi r11,r1,112
	r11.s64 = ctx.r1.s64 + 112;
	// addi r10,r1,208
	ctx.r10.s64 = ctx.r1.s64 + 208;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r5,112(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	// bl 0x82404ae0
	sub_82404AE0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405f18
	sub_82405F18(ctx, base);
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_82406028"))) PPC_WEAK_FUNC(sub_82406028);
PPC_FUNC_IMPL(__imp__sub_82406028) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r4,r11,-16560
	ctx.r4.s64 = r11.s64 + -16560;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lbz r11,8232(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 8232);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x8240605c
	if (!cr0.getEQ()) goto loc_8240605C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405e50
	sub_82405E50(ctx, base);
loc_8240605C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406078
	if (cr0.getEQ()) goto loc_82406078;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15636
	ctx.r4.s64 = r11.s64 + 15636;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406078:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-6424
	ctx.r4.s64 = r11.s64 + -6424;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824060A0"))) PPC_WEAK_FUNC(sub_824060A0);
PPC_FUNC_IMPL(__imp__sub_824060A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed120
	// stfd f31,-96(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -96, f31.u64);
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lis r10,-32768
	ctx.r10.s64 = -2147483648;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r11,r11,0,0,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x824060fc
	if (!cr6.getEQ()) goto loc_824060FC;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm. r11,r11,0,0,0
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x80000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824060ec
	if (cr0.getEQ()) goto loc_824060EC;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15580
	ctx.r4.s64 = r11.s64 + 15580;
	// b 0x824060f4
	goto loc_824060F4;
loc_824060EC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15572
	ctx.r4.s64 = r11.s64 + 15572;
loc_824060F4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824060FC:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// clrlwi r5,r11,27
	ctx.r5.u64 = r11.u32 & 0x1F;
	// bne cr6,0x82406940
	if (!cr6.getEQ()) goto loc_82406940;
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq cr6,0x8240695c
	if (cr6.getEQ()) goto loc_8240695C;
	// cmpwi cr6,r5,1
	cr6.compare<int32_t>(ctx.r5.s32, 1, xer);
	// beq cr6,0x82406148
	if (cr6.getEQ()) goto loc_82406148;
	// cmpwi cr6,r5,15
	cr6.compare<int32_t>(ctx.r5.s32, 15, xer);
	// ble cr6,0x8240613c
	if (!cr6.getGT()) goto loc_8240613C;
	// cmpwi cr6,r5,19
	cr6.compare<int32_t>(ctx.r5.s32, 19, xer);
	// ble cr6,0x82406148
	if (!cr6.getGT()) goto loc_82406148;
	// cmpwi cr6,r5,23
	cr6.compare<int32_t>(ctx.r5.s32, 23, xer);
	// ble cr6,0x8240613c
	if (!cr6.getGT()) goto loc_8240613C;
	// cmpwi cr6,r5,26
	cr6.compare<int32_t>(ctx.r5.s32, 26, xer);
	// ble cr6,0x82406148
	if (!cr6.getGT()) goto loc_82406148;
loc_8240613C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15972
	ctx.r4.s64 = r11.s64 + 15972;
	// b 0x82406950
	goto loc_82406950;
loc_82406148:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// cmplwi cr6,r5,19
	cr6.compare<uint32_t>(ctx.r5.u32, 19, xer);
	// addi r4,r11,-5916
	ctx.r4.s64 = r11.s64 + -5916;
	// bgt cr6,0x824061c4
	if (cr6.getGT()) goto loc_824061C4;
	// beq cr6,0x824061b8
	if (cr6.getEQ()) goto loc_824061B8;
	// cmplwi cr6,r5,1
	cr6.compare<uint32_t>(ctx.r5.u32, 1, xer);
	// beq cr6,0x824061a0
	if (cr6.getEQ()) goto loc_824061A0;
	// cmplwi cr6,r5,16
	cr6.compare<uint32_t>(ctx.r5.u32, 16, xer);
	// beq cr6,0x82406194
	if (cr6.getEQ()) goto loc_82406194;
	// cmplwi cr6,r5,17
	cr6.compare<uint32_t>(ctx.r5.u32, 17, xer);
	// beq cr6,0x82406188
	if (cr6.getEQ()) goto loc_82406188;
	// cmplwi cr6,r5,18
	cr6.compare<uint32_t>(ctx.r5.u32, 18, xer);
	// bne cr6,0x824061fc
	if (!cr6.getEQ()) goto loc_824061FC;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,32020
	ctx.r4.s64 = r11.s64 + 32020;
	// b 0x824061fc
	goto loc_824061FC;
loc_82406188:
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r11,r11,-14944
	r11.s64 = r11.s64 + -14944;
	// b 0x824061a8
	goto loc_824061A8;
loc_82406194:
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r11,r11,-14960
	r11.s64 = r11.s64 + -14960;
	// b 0x824061a8
	goto loc_824061A8;
loc_824061A0:
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r11,r11,-14976
	r11.s64 = r11.s64 + -14976;
loc_824061A8:
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r10,r10,20,28,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0xC;
	// lwzx r4,r10,r11
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// b 0x824061fc
	goto loc_824061FC;
loc_824061B8:
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r11,r11,-14992
	r11.s64 = r11.s64 + -14992;
	// b 0x824061a8
	goto loc_824061A8;
loc_824061C4:
	// cmplwi cr6,r5,24
	cr6.compare<uint32_t>(ctx.r5.u32, 24, xer);
	// beq cr6,0x824061f4
	if (cr6.getEQ()) goto loc_824061F4;
	// cmplwi cr6,r5,25
	cr6.compare<uint32_t>(ctx.r5.u32, 25, xer);
	// beq cr6,0x824061e8
	if (cr6.getEQ()) goto loc_824061E8;
	// cmplwi cr6,r5,26
	cr6.compare<uint32_t>(ctx.r5.u32, 26, xer);
	// bne cr6,0x824061fc
	if (!cr6.getEQ()) goto loc_824061FC;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,31912
	ctx.r4.s64 = r11.s64 + 31912;
	// b 0x824061fc
	goto loc_824061FC;
loc_824061E8:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,31928
	ctx.r4.s64 = r11.s64 + 31928;
	// b 0x824061fc
	goto loc_824061FC;
loc_824061F4:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,31944
	ctx.r4.s64 = r11.s64 + 31944;
loc_824061FC:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404d38
	sub_82404D38(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-21432
	ctx.r4.s64 = r11.s64 + -21432;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r10,r11,27
	ctx.r10.u64 = r11.u32 & 0x1F;
	// cmplwi cr6,r10,19
	cr6.compare<uint32_t>(ctx.r10.u32, 19, xer);
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r29,r10,-21324
	r29.s64 = ctx.r10.s64 + -21324;
	// lis r10,-32015
	ctx.r10.s64 = -2098135040;
	// addi r28,r10,-15888
	r28.s64 = ctx.r10.s64 + -15888;
	// lis r10,-32251
	ctx.r10.s64 = -2113601536;
	// addi r27,r10,-19388
	r27.s64 = ctx.r10.s64 + -19388;
	// bgt cr6,0x82406324
	if (cr6.getGT()) goto loc_82406324;
	// rlwinm. r10,r11,0,13,13
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// rlwinm r5,r11,20,26,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0x3F;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq 0x8240625c
	if (cr0.getEQ()) goto loc_8240625C;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r4,r11,-6724
	ctx.r4.s64 = r11.s64 + -6724;
	// b 0x82406264
	goto loc_82406264;
loc_8240625C:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r4,r11,-6728
	ctx.r4.s64 = r11.s64 + -6728;
loc_82406264:
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi. r10,r11,29
	ctx.r10.u64 = r11.u32 & 0x7;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82406298
	if (!cr0.getEQ()) goto loc_82406298;
	// rlwinm r10,r11,0,26,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x38;
	// cmplwi cr6,r10,8
	cr6.compare<uint32_t>(ctx.r10.u32, 8, xer);
	// bne cr6,0x82406298
	if (!cr6.getEQ()) goto loc_82406298;
	// rlwinm r10,r11,0,23,25
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1C0;
	// cmplwi cr6,r10,128
	cr6.compare<uint32_t>(ctx.r10.u32, 128, xer);
	// bne cr6,0x82406298
	if (!cr6.getEQ()) goto loc_82406298;
	// rlwinm r11,r11,0,20,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xE00;
	// cmplwi cr6,r11,1536
	cr6.compare<uint32_t>(r11.u32, 1536, xer);
	// beq cr6,0x82406314
	if (cr6.getEQ()) goto loc_82406314;
loc_82406298:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// clrlwi r11,r11,29
	r11.u64 = r11.u32 & 0x7;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lbzx r11,r11,r28
	r11.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r11,r11,29,29,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0x7;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lbzx r11,r11,r28
	r11.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r11,r11,26,29,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x7;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lbzx r11,r11,r28
	r11.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r11,r11,23,29,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 23) & 0x7;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lbzx r11,r11,r28
	r11.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406314:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-16560
	ctx.r4.s64 = r11.s64 + -16560;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406324:
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// li r8,0
	ctx.r8.s64 = 0;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// rlwinm r5,r11,27,25,25
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x40;
	// rlwinm r11,r11,27,26,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x3F;
	// stb r6,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, ctx.r6.u8);
	// li r7,0
	ctx.r7.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// or r5,r5,r11
	ctx.r5.u64 = ctx.r5.u64 | r11.u64;
	// bl 0x82405220
	sub_82405220(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r10,r11,27
	ctx.r10.u64 = r11.u32 & 0x1F;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// beq cr6,0x824063cc
	if (cr6.getEQ()) goto loc_824063CC;
	// rlwinm r11,r11,6,30,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0x3;
	// cmplwi cr6,r10,18
	cr6.compare<uint32_t>(ctx.r10.u32, 18, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lbzx r11,r11,r28
	r11.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// beq cr6,0x82406414
	if (cr6.getEQ()) goto loc_82406414;
	// cmplwi cr6,r10,24
	cr6.compare<uint32_t>(ctx.r10.u32, 24, xer);
	// beq cr6,0x82406438
	if (cr6.getEQ()) goto loc_82406438;
loc_824063A0:
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r11,r11,4,30,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0x3;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lbzx r11,r11,r28
	r11.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,2,30,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x3;
	// b 0x82406428
	goto loc_82406428;
loc_824063CC:
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r10,r10,18,30,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x3;
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// blt cr6,0x82406424
	if (cr6.getLT()) goto loc_82406424;
	// beq cr6,0x82406400
	if (cr6.getEQ()) goto loc_82406400;
	// cmplwi cr6,r10,4
	cr6.compare<uint32_t>(ctx.r10.u32, 4, xer);
	// bge cr6,0x8240643c
	if (!cr6.getLT()) goto loc_8240643C;
	// rlwinm r11,r11,6,30,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0x3;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lbzx r11,r11,r28
	r11.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// b 0x824063a0
	goto loc_824063A0;
loc_82406400:
	// rlwinm r11,r11,6,30,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0x3;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lbzx r11,r11,r28
	r11.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
loc_82406414:
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r11,r11,4,30,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0x3;
	// b 0x82406428
	goto loc_82406428;
loc_82406424:
	// rlwinm r11,r11,6,30,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0x3;
loc_82406428:
	// lbzx r11,r11,r28
	r11.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
loc_82406438:
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_8240643C:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r10,r11,27
	ctx.r10.u64 = r11.u32 & 0x1F;
	// cmplwi cr6,r10,19
	cr6.compare<uint32_t>(ctx.r10.u32, 19, xer);
	// bgt cr6,0x82406460
	if (cr6.getGT()) goto loc_82406460;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// rlwinm r5,r11,12,27,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 12) & 0x1F;
	// addi r4,r10,15964
	ctx.r4.s64 = ctx.r10.s64 + 15964;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406460:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r4,r11,30692
	ctx.r4.s64 = r11.s64 + 30692;
	// rlwinm r5,r10,13,31,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 13) & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405da0
	sub_82405DA0(ctx, base);
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r27,r10,15504
	r27.s64 = ctx.r10.s64 + 15504;
	// clrlwi r10,r11,27
	ctx.r10.u64 = r11.u32 & 0x1F;
	// lbzx r10,r10,r27
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + r27.u32);
	// andi. r10,r10,23
	ctx.r10.u64 = ctx.r10.u64 & 23;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824064b4
	if (cr0.getEQ()) goto loc_824064B4;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r4,r10,30708
	ctx.r4.s64 = ctx.r10.s64 + 30708;
	// rlwinm r5,r11,7,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 7) & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405da0
	sub_82405DA0(ctx, base);
loc_824064B4:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lbzx r11,r11,r27
	r11.u64 = PPC_LOAD_U8(r11.u32 + r27.u32);
	// andi. r11,r11,19
	r11.u64 = r11.u64 & 19;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r29,r11,15680
	r29.s64 = r11.s64 + 15680;
	// beq 0x82406510
	if (cr0.getEQ()) goto loc_82406510;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r9,r11,26,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// rlwinm r11,r10,20,30,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 20) & 0x3;
	// bne 0x824064f0
	if (!cr0.getEQ()) goto loc_824064F0;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x82406510
	if (cr6.getEQ()) goto loc_82406510;
loc_824064F0:
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r28,400
	ctx.r10.s64 = r28.s64 + 400;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r5,r11,30680
	ctx.r5.s64 = r11.s64 + 30680;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r6,r9,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406510:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lbzx r11,r11,r27
	r11.u64 = PPC_LOAD_U8(r11.u32 + r27.u32);
	// andi. r11,r11,19
	r11.u64 = r11.u64 & 19;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406564
	if (cr0.getEQ()) goto loc_82406564;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r9,r11,26,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// rlwinm r11,r10,18,30,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 18) & 0x3;
	// bne 0x82406544
	if (!cr0.getEQ()) goto loc_82406544;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x82406564
	if (cr6.getEQ()) goto loc_82406564;
loc_82406544:
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r28,416
	ctx.r10.s64 = r28.s64 + 416;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r5,r11,30668
	ctx.r5.s64 = r11.s64 + 30668;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r6,r9,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406564:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lbzx r11,r11,r27
	r11.u64 = PPC_LOAD_U8(r11.u32 + r27.u32);
	// andi. r11,r11,19
	r11.u64 = r11.u64 & 19;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824065b8
	if (cr0.getEQ()) goto loc_824065B8;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lhz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U16(r30.u32 + 4);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// clrlwi r11,r10,30
	r11.u64 = ctx.r10.u32 & 0x3;
	// bne 0x82406598
	if (!cr0.getEQ()) goto loc_82406598;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x824065b8
	if (cr6.getEQ()) goto loc_824065B8;
loc_82406598:
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r28,432
	ctx.r10.s64 = r28.s64 + 432;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r5,r11,30656
	ctx.r5.s64 = r11.s64 + 30656;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r6,r9,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824065B8:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lbzx r11,r11,r27
	r11.u64 = PPC_LOAD_U8(r11.u32 + r27.u32);
	// andi. r11,r11,23
	r11.u64 = r11.u64 & 23;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240660c
	if (cr0.getEQ()) goto loc_8240660C;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r9,r11,26,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// rlwinm r11,r10,14,29,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 14) & 0x7;
	// bne 0x824065ec
	if (!cr0.getEQ()) goto loc_824065EC;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// beq cr6,0x8240660c
	if (cr6.getEQ()) goto loc_8240660C;
loc_824065EC:
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r28,448
	ctx.r10.s64 = r28.s64 + 448;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r5,r11,30644
	ctx.r5.s64 = r11.s64 + 30644;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r6,r9,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_8240660C:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,16,17
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xC000;
	// cmplwi cr6,r11,32768
	cr6.compare<uint32_t>(r11.u32, 32768, xer);
	// blt cr6,0x82406670
	if (cr6.getLT()) goto loc_82406670;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lbzx r11,r11,r27
	r11.u64 = PPC_LOAD_U8(r11.u32 + r27.u32);
	// andi. r11,r11,23
	r11.u64 = r11.u64 & 23;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406670
	if (cr0.getEQ()) goto loc_82406670;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lbz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U8(r30.u32 + 4);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// clrlwi r11,r10,30
	r11.u64 = ctx.r10.u32 & 0x3;
	// bne 0x82406650
	if (!cr0.getEQ()) goto loc_82406650;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x82406670
	if (cr6.getEQ()) goto loc_82406670;
loc_82406650:
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r28,480
	ctx.r10.s64 = r28.s64 + 480;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r5,r11,30628
	ctx.r5.s64 = r11.s64 + 30628;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r6,r9,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406670:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r11,r11,0,16,17
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xC000;
	// cmplwi cr6,r11,32768
	cr6.compare<uint32_t>(r11.u32, 32768, xer);
	// blt cr6,0x824066d4
	if (cr6.getLT()) goto loc_824066D4;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lbzx r11,r11,r27
	r11.u64 = PPC_LOAD_U8(r11.u32 + r27.u32);
	// andi. r11,r11,23
	r11.u64 = r11.u64 & 23;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824066d4
	if (cr0.getEQ()) goto loc_824066D4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r9,r11,26,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// rlwinm r11,r10,6,30,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 6) & 0x3;
	// bne 0x824066b4
	if (!cr0.getEQ()) goto loc_824066B4;
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x824066d4
	if (cr6.getEQ()) goto loc_824066D4;
loc_824066B4:
	// rlwinm r9,r11,2,0,29
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// addi r10,r28,496
	ctx.r10.s64 = r28.s64 + 496;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// addi r5,r11,30612
	ctx.r5.s64 = r11.s64 + 30612;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwzx r6,r9,r10
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r9.u32 + ctx.r10.u32);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824066D4:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lbzx r11,r11,r27
	r11.u64 = PPC_LOAD_U8(r11.u32 + r27.u32);
	// andi. r11,r11,23
	r11.u64 = r11.u64 & 23;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406708
	if (cr0.getEQ()) goto loc_82406708;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r6,1
	ctx.r6.s64 = 1;
	// addi r4,r11,30596
	ctx.r4.s64 = r11.s64 + 30596;
	// rlwinm r5,r10,4,31,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 4) & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405da0
	sub_82405DA0(ctx, base);
loc_82406708:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lbzx r11,r11,r27
	r11.u64 = PPC_LOAD_U8(r11.u32 + r27.u32);
	// andi. r11,r11,23
	r11.u64 = r11.u64 & 23;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240673c
	if (cr0.getEQ()) goto loc_8240673C;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r4,r11,30580
	ctx.r4.s64 = r11.s64 + 30580;
	// rlwinm r5,r10,3,30,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 3) & 0x3;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405da0
	sub_82405DA0(ctx, base);
loc_8240673C:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lbzx r11,r11,r27
	r11.u64 = PPC_LOAD_U8(r11.u32 + r27.u32);
	// clrlwi. r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240676c
	if (cr0.getEQ()) goto loc_8240676C;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r4,r11,30556
	ctx.r4.s64 = r11.s64 + 30556;
	// clrlwi r5,r10,31
	ctx.r5.u64 = ctx.r10.u32 & 0x1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405da0
	sub_82405DA0(ctx, base);
loc_8240676C:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lbzx r11,r11,r27
	r11.u64 = PPC_LOAD_U8(r11.u32 + r27.u32);
	// andi. r11,r11,19
	r11.u64 = r11.u64 & 19;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824067e0
	if (cr0.getEQ()) goto loc_824067E0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240679c
	if (!cr0.getEQ()) goto loc_8240679C;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm. r11,r11,0,23,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1FC;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824067e0
	if (cr0.getEQ()) goto loc_824067E0;
loc_8240679C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15948
	ctx.r4.s64 = r11.s64 + 15948;
	// rlwinm r11,r10,23,0,8
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 23) & 0xFF800000;
	// srawi r11,r11,25
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1FFFFFF) != 0);
	r11.s64 = r11.s32 >> 25;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, r11.u64);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// lfd f0,120(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f13,f0
	ctx.f13.f64 = double(float(f0.f64));
	// lfs f0,-18868(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -18868);
	f0.f64 = double(temp.f32);
	// fmuls f1,f13,f0
	ctx.f1.f64 = double(float(ctx.f13.f64 * f0.f64));
	// stfd f1,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.f1.u64);
	// ld r5,32(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 32);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824067E0:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r11,r11,27
	r11.u64 = r11.u32 & 0x1F;
	// lbzx r11,r11,r27
	r11.u64 = PPC_LOAD_U8(r11.u32 + r27.u32);
	// andi. r11,r11,19
	r11.u64 = r11.u64 & 19;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f31,2692(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f31.f64 = double(temp.f32);
	// beq 0x82406854
	if (cr0.getEQ()) goto loc_82406854;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82406818
	if (!cr0.getEQ()) goto loc_82406818;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm. r11,r11,0,11,15
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1F0000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406854
	if (cr0.getEQ()) goto loc_82406854;
loc_82406818:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15932
	ctx.r4.s64 = r11.s64 + 15932;
	// rlwinm r11,r10,11,0,20
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 11) & 0xFFFFF800;
	// srawi r11,r11,27
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x7FFFFFF) != 0);
	r11.s64 = r11.s32 >> 27;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, r11.u64);
	// lfd f0,120(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f1,f0,f31
	ctx.f1.f64 = double(float(f0.f64 * f31.f64));
	// stfd f1,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.f1.u64);
	// ld r5,32(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 32);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406854:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r10,r11,0,16,17
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xC000;
	// cmplwi cr6,r10,16384
	cr6.compare<uint32_t>(ctx.r10.u32, 16384, xer);
	// blt cr6,0x824068c8
	if (cr6.getLT()) goto loc_824068C8;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r10,r10,27
	ctx.r10.u64 = ctx.r10.u32 & 0x1F;
	// lbzx r10,r10,r27
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + r27.u32);
	// andi. r10,r10,19
	ctx.r10.u64 = ctx.r10.u64 & 19;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824068c8
	if (cr0.getEQ()) goto loc_824068C8;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r10,r10,26,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82406890
	if (!cr0.getEQ()) goto loc_82406890;
	// rlwinm. r10,r11,0,6,10
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x3E00000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x824068c8
	if (cr0.getEQ()) goto loc_824068C8;
loc_82406890:
	// rlwinm r10,r11,6,0,25
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 6) & 0xFFFFFFC0;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15916
	ctx.r4.s64 = r11.s64 + 15916;
	// srawi r11,r10,27
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7FFFFFF) != 0);
	r11.s64 = ctx.r10.s32 >> 27;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, r11.u64);
	// lfd f0,120(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f1,f0,f31
	ctx.f1.f64 = double(float(f0.f64 * f31.f64));
	// stfd f1,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.f1.u64);
	// ld r5,32(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 32);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824068C8:
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm r10,r11,0,16,17
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xC000;
	// cmplwi cr6,r10,32768
	cr6.compare<uint32_t>(ctx.r10.u32, 32768, xer);
	// blt cr6,0x82406e88
	if (cr6.getLT()) goto loc_82406E88;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// clrlwi r10,r10,27
	ctx.r10.u64 = ctx.r10.u32 & 0x1F;
	// lbzx r10,r10,r27
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r10.u32 + r27.u32);
	// andi. r10,r10,19
	ctx.r10.u64 = ctx.r10.u64 & 19;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// cmpwi r10,0
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82406e88
	if (cr0.getEQ()) goto loc_82406E88;
	// lwz r10,8(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r10,r10,26,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82406904
	if (!cr0.getEQ()) goto loc_82406904;
	// rlwinm. r10,r11,0,1,5
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x7C000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82406e88
	if (cr0.getEQ()) goto loc_82406E88;
loc_82406904:
	// rlwinm r10,r11,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 1) & 0xFFFFFFFE;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15900
	ctx.r4.s64 = r11.s64 + 15900;
	// srawi r11,r10,27
	xer.ca = (ctx.r10.s32 < 0) & ((ctx.r10.u32 & 0x7FFFFFF) != 0);
	r11.s64 = ctx.r10.s32 >> 27;
	// extsw r11,r11
	r11.s64 = r11.s32;
	// std r11,120(r1)
	PPC_STORE_U64(ctx.r1.u32 + 120, r11.u64);
	// lfd f0,120(r1)
	ctx.fpscr.disableFlushMode();
	f0.u64 = PPC_LOAD_U64(ctx.r1.u32 + 120);
	// fcfid f0,f0
	f0.f64 = double(f0.s64);
	// frsp f0,f0
	f0.f64 = double(float(f0.f64));
	// fmuls f1,f0,f31
	ctx.f1.f64 = double(float(f0.f64 * f31.f64));
	// stfd f1,32(r1)
	PPC_STORE_U64(ctx.r1.u32 + 32, ctx.f1.u64);
	// ld r5,32(r1)
	ctx.r5.u64 = PPC_LOAD_U64(ctx.r1.u32 + 32);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// b 0x82406e88
	goto loc_82406E88;
loc_82406940:
	// cmpwi cr6,r5,0
	cr6.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq cr6,0x8240695c
	if (cr6.getEQ()) goto loc_8240695C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15868
	ctx.r4.s64 = r11.s64 + 15868;
loc_82406950:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// b 0x82406e88
	goto loc_82406E88;
loc_8240695C:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r26,0
	r26.s64 = 0;
	// mr r25,r26
	r25.u64 = r26.u64;
	// stb r26,112(r1)
	PPC_STORE_U8(ctx.r1.u32 + 112, r26.u8);
	// rlwinm. r24,r11,2,31,31
	r24.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x1;
	cr0.compare<int32_t>(r24.s32, 0, xer);
	// bne 0x824069b4
	if (!cr0.getEQ()) goto loc_824069B4;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824069b4
	if (!cr0.getEQ()) goto loc_824069B4;
	// lwz r11,8224(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8224);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x824069b4
	if (cr0.getEQ()) goto loc_824069B4;
	// lwz r3,8228(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8228);
	// li r7,1
	ctx.r7.s64 = 1;
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,3
	ctx.r4.s64 = 3;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x824069b4
	if (!cr0.getEQ()) goto loc_824069B4;
	// li r25,1
	r25.s64 = 1;
loc_824069B4:
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// bne cr6,0x824069c8
	if (!cr6.getEQ()) goto loc_824069C8;
	// clrlwi. r11,r25,24
	r11.u64 = r25.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x824069cc
	if (cr0.getEQ()) goto loc_824069CC;
loc_824069C8:
	// mr r11,r26
	r11.u64 = r26.u64;
loc_824069CC:
	// clrlwi r27,r11,24
	r27.u64 = r11.u32 & 0xFF;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x824069e4
	if (cr6.getEQ()) goto loc_824069E4;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,32208
	ctx.r4.s64 = r11.s64 + 32208;
	// b 0x82406a00
	goto loc_82406A00;
loc_824069E4:
	// clrlwi. r11,r25,24
	r11.u64 = r25.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824069f8
	if (cr0.getEQ()) goto loc_824069F8;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,32200
	ctx.r4.s64 = r11.s64 + 32200;
	// b 0x82406a00
	goto loc_82406A00;
loc_824069F8:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,32220
	ctx.r4.s64 = r11.s64 + 32220;
loc_82406A00:
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404d38
	sub_82404D38(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-21432
	ctx.r4.s64 = r11.s64 + -21432;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r5,r11,20,26,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0x3F;
	// rlwinm. r10,r11,0,13,13
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82406a3c
	if (cr0.getEQ()) goto loc_82406A3C;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r4,r11,-6724
	ctx.r4.s64 = r11.s64 + -6724;
	// b 0x82406a44
	goto loc_82406A44;
loc_82406A3C:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r4,r11,-6728
	ctx.r4.s64 = r11.s64 + -6728;
loc_82406A44:
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// clrlwi. r10,r11,29
	ctx.r10.u64 = r11.u32 & 0x7;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lis r10,-32015
	ctx.r10.s64 = -2098135040;
	// addi r28,r10,-15888
	r28.s64 = ctx.r10.s64 + -15888;
	// bne 0x82406a80
	if (!cr0.getEQ()) goto loc_82406A80;
	// rlwinm r10,r11,0,26,28
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x38;
	// cmplwi cr6,r10,8
	cr6.compare<uint32_t>(ctx.r10.u32, 8, xer);
	// bne cr6,0x82406a80
	if (!cr6.getEQ()) goto loc_82406A80;
	// rlwinm r10,r11,0,23,25
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1C0;
	// cmplwi cr6,r10,128
	cr6.compare<uint32_t>(ctx.r10.u32, 128, xer);
	// bne cr6,0x82406a80
	if (!cr6.getEQ()) goto loc_82406A80;
	// rlwinm r11,r11,0,20,22
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xE00;
	// cmplwi cr6,r11,1536
	cr6.compare<uint32_t>(r11.u32, 1536, xer);
	// beq cr6,0x82406b08
	if (cr6.getEQ()) goto loc_82406B08;
loc_82406A80:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-19388
	ctx.r4.s64 = r11.s64 + -19388;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// clrlwi r10,r11,29
	ctx.r10.u64 = r11.u32 & 0x7;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r29,r11,-21324
	r29.s64 = r11.s64 + -21324;
	// lbzx r11,r10,r28
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + r28.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r11,r11,29,29,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 29) & 0x7;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lbzx r11,r11,r28
	r11.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r11,r11,26,29,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x7;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lbzx r11,r11,r28
	r11.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r11,r11,23,29,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 23) & 0x7;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// lbzx r11,r11,r28
	r11.u64 = PPC_LOAD_U8(r11.u32 + r28.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406B08:
	// clrlwi. r22,r27,24
	r22.u64 = r27.u32 & 0xFF;
	cr0.compare<int32_t>(r22.s32, 0, xer);
	// bne 0x82406b18
	if (!cr0.getEQ()) goto loc_82406B18;
	// clrlwi. r11,r25,24
	r11.u64 = r25.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406b84
	if (cr0.getEQ()) goto loc_82406B84;
loc_82406B18:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-16560
	ctx.r4.s64 = r11.s64 + -16560;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// li r5,4
	ctx.r5.s64 = 4;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r10,0
	ctx.r10.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// stb r26,95(r1)
	PPC_STORE_U8(ctx.r1.u32 + 95, r26.u8);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// stw r5,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r5.u32);
	// rlwinm r5,r11,27,25,25
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x40;
	// rlwinm r11,r11,27,26,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x3F;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// or r5,r5,r11
	ctx.r5.u64 = ctx.r5.u64 | r11.u64;
	// bl 0x82405220
	sub_82405220(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r10,r11,2,30,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0x3;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r4,r11,-6400
	ctx.r4.s64 = r11.s64 + -6400;
	// lbzx r11,r10,r28
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + r28.u32);
	// extsb r5,r11
	ctx.r5.s64 = r11.s8;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406B84:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82406bb4
	if (cr6.getEQ()) goto loc_82406BB4;
	// lis r10,-32249
	ctx.r10.s64 = -2113470464;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r10,15860
	ctx.r4.s64 = ctx.r10.s64 + 15860;
	// rlwinm r10,r11,12,27,31
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 12) & 0x1F;
	// rlwinm r11,r11,7,30,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 7) & 0x3;
	// mulli r10,r10,3
	ctx.r10.s64 = ctx.r10.s64 * 3;
	// subfic r10,r10,95
	xer.ca = ctx.r10.u32 <= 95;
	ctx.r10.s64 = 95 - ctx.r10.s64;
	// subf r5,r11,r10
	ctx.r5.s64 = ctx.r10.s64 - r11.s64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406BB4:
	// clrlwi. r27,r25,24
	r27.u64 = r25.u32 & 0xFF;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// beq 0x82406bfc
	if (cr0.getEQ()) goto loc_82406BFC;
	// lis r10,-32253
	ctx.r10.s64 = -2113732608;
	// lbz r11,112(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 112);
	// addi r9,r28,800
	ctx.r9.s64 = r28.s64 + 800;
	// addi r4,r10,-11884
	ctx.r4.s64 = ctx.r10.s64 + -11884;
	// rlwinm r10,r11,30,2,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFFFFFC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// clrlwi r29,r11,28
	r29.u64 = r11.u32 & 0xF;
	// lwzx r5,r10,r9
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + ctx.r9.u32);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82406bfc
	if (cr6.getEQ()) goto loc_82406BFC;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r4,r11,5300
	ctx.r4.s64 = r11.s64 + 5300;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406BFC:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// addi r29,r11,5360
	r29.s64 = r11.s64 + 5360;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r26,r11,5368
	r26.s64 = r11.s64 + 5368;
	// bne cr6,0x82406c94
	if (!cr6.getEQ()) goto loc_82406C94;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82406c28
	if (!cr0.getEQ()) goto loc_82406C28;
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// bne cr6,0x82406c50
	if (!cr6.getEQ()) goto loc_82406C50;
loc_82406C28:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82406028
	sub_82406028(ctx, base);
	// cmpwi cr6,r23,0
	cr6.compare<int32_t>(r23.s32, 0, xer);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// beq cr6,0x82406c40
	if (cr6.getEQ()) goto loc_82406C40;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
loc_82406C40:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15840
	ctx.r4.s64 = r11.s64 + 15840;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406C50:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82406c68
	if (!cr0.getEQ()) goto loc_82406C68;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,16,16
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406c94
	if (cr0.getEQ()) goto loc_82406C94;
loc_82406C68:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82406028
	sub_82406028(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// rlwinm. r11,r11,0,16,16
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82406c84
	if (!cr0.getEQ()) goto loc_82406C84;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
loc_82406C84:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15824
	ctx.r4.s64 = r11.s64 + 15824;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406C94:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82406cac
	if (!cr0.getEQ()) goto loc_82406CAC;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,2,7
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x3F000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406cd0
	if (cr0.getEQ()) goto loc_82406CD0;
loc_82406CAC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82406028
	sub_82406028(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15808
	ctx.r4.s64 = r11.s64 + 15808;
	// rlwinm r11,r10,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// srawi r5,r11,26
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x3FFFFFF) != 0);
	ctx.r5.s64 = r11.s32 >> 26;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406CD0:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// bne cr6,0x82406e88
	if (!cr6.getEQ()) goto loc_82406E88;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-19320
	ctx.r4.s64 = r11.s64 + -19320;
	// bl 0x82404ce0
	sub_82404CE0(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82406d00
	if (!cr0.getEQ()) goto loc_82406D00;
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// rlwinm. r11,r11,0,1,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x7FFFFF00;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406d24
	if (cr0.getEQ()) goto loc_82406D24;
loc_82406D00:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82406028
	sub_82406028(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r10,8(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15796
	ctx.r4.s64 = r11.s64 + 15796;
	// rlwinm r11,r10,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// srawi r5,r11,9
	xer.ca = (r11.s32 < 0) & ((r11.u32 & 0x1FF) != 0);
	ctx.r5.s64 = r11.s32 >> 9;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406D24:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82406d3c
	if (!cr0.getEQ()) goto loc_82406D3C;
	// lhz r11,4(r30)
	r11.u64 = PPC_LOAD_U16(r30.u32 + 4);
	// clrlwi. r11,r11,26
	r11.u64 = r11.u32 & 0x3F;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406d64
	if (cr0.getEQ()) goto loc_82406D64;
loc_82406D3C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82406028
	sub_82406028(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r10,r28,528
	ctx.r10.s64 = r28.s64 + 528;
	// addi r4,r11,15780
	ctx.r4.s64 = r11.s64 + 15780;
	// lhz r11,4(r30)
	r11.u64 = PPC_LOAD_U16(r30.u32 + 4);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// rlwinm r11,r11,2,24,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFC;
	// lwzx r5,r11,r10
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r10.u32);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406D64:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82406da0
	if (cr6.getEQ()) goto loc_82406DA0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82406d84
	if (!cr0.getEQ()) goto loc_82406D84;
	// lbz r11,11(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 11);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82406da0
	if (cr0.getEQ()) goto loc_82406DA0;
loc_82406D84:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82406028
	sub_82406028(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lbz r5,11(r30)
	ctx.r5.u64 = PPC_LOAD_U8(r30.u32 + 11);
	// addi r4,r11,15768
	ctx.r4.s64 = r11.s64 + 15768;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406DA0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82406db8
	if (!cr0.getEQ()) goto loc_82406DB8;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406de4
	if (cr0.getEQ()) goto loc_82406DE4;
loc_82406DB8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82406028
	sub_82406028(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// mr r5,r26
	ctx.r5.u64 = r26.u64;
	// rlwinm. r11,r11,0,19,19
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x1000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82406dd4
	if (!cr0.getEQ()) goto loc_82406DD4;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
loc_82406DD4:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15756
	ctx.r4.s64 = r11.s64 + 15756;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406DE4:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82406dfc
	if (!cr0.getEQ()) goto loc_82406DFC;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,18,18
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406e34
	if (cr0.getEQ()) goto loc_82406E34;
loc_82406DFC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82406028
	sub_82406028(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,18,18
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406e1c
	if (cr0.getEQ()) goto loc_82406E1C;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r5,r11,30928
	ctx.r5.s64 = r11.s64 + 30928;
	// b 0x82406e24
	goto loc_82406E24;
loc_82406E1C:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r5,r11,30936
	ctx.r5.s64 = r11.s64 + 30936;
loc_82406E24:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15740
	ctx.r4.s64 = r11.s64 + 15740;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406E34:
	// cmplwi cr6,r22,0
	cr6.compare<uint32_t>(r22.u32, 0, xer);
	// beq cr6,0x82406e78
	if (cr6.getEQ()) goto loc_82406E78;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82406e54
	if (!cr0.getEQ()) goto loc_82406E54;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,2,4
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x38000000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406e78
	if (cr0.getEQ()) goto loc_82406E78;
loc_82406E54:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82406028
	sub_82406028(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15720
	ctx.r4.s64 = r11.s64 + 15720;
	// rlwinm r11,r10,5,29,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 5) & 0x7;
	// addi r5,r11,1
	ctx.r5.s64 = r11.s64 + 1;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406E78:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-19328
	ctx.r4.s64 = r11.s64 + -19328;
	// bl 0x82404ce0
	sub_82404CE0(ctx, base);
loc_82406E88:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// lfd f31,-96(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -96);
	// b 0x823ed170
	return;
}

__attribute__((alias("__imp__sub_82406E98"))) PPC_WEAK_FUNC(sub_82406E98);
PPC_FUNC_IMPL(__imp__sub_82406E98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r21{};
	PPCRegister r22{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed11c
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r22,r5
	r22.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// clrlwi. r11,r28,31
	r11.u64 = r28.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240773c
	if (cr0.getEQ()) goto loc_8240773C;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lbz r10,12(r31)
	ctx.r10.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// rlwinm r29,r11,20,28,31
	r29.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x82406f6c
	if (cr0.getEQ()) goto loc_82406F6C;
	// bl 0x82405ea8
	sub_82405EA8(ctx, base);
	// clrlwi r10,r22,27
	ctx.r10.u64 = r22.u32 & 0x1F;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r11,r22,27,5,31
	r11.u64 = __builtin_rotateleft64(r22.u32 | (r22.u64 << 32), 27) & 0x7FFFFFF;
	// addi r11,r11,6
	r11.s64 = r11.s64 + 6;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r11,r11,r31
	r11.u64 = PPC_LOAD_U32(r11.u32 + r31.u32);
	// slw r10,r9,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r10.u8 & 0x3F));
	// and. r11,r10,r11
	r11.u64 = ctx.r10.u64 & r11.u64;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406f4c
	if (cr0.getEQ()) goto loc_82406F4C;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82406f14
	if (cr0.getEQ()) goto loc_82406F14;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,16108
	ctx.r4.s64 = r11.s64 + 16108;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82406F14:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,10844
	ctx.r4.s64 = r11.s64 + 10844;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// addi r4,r11,16100
	ctx.r4.s64 = r11.s64 + 16100;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lbz r11,8232(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 8232);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x82406f4c
	if (!cr0.getEQ()) goto loc_82406F4C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405e50
	sub_82405E50(ctx, base);
loc_82406F4C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82406f60
	if (!cr0.getEQ()) goto loc_82406F60;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82406f6c
	if (cr6.getEQ()) goto loc_82406F6C;
loc_82406F60:
	// mr r4,r22
	ctx.r4.u64 = r22.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404e10
	sub_82404E10(ctx, base);
loc_82406F6C:
	// cmplwi cr6,r29,15
	cr6.compare<uint32_t>(r29.u32, 15, xer);
	// bgt cr6,0x824076f8
	if (cr6.getGT()) goto loc_824076F8;
	// lis r12,-32249
	r12.s64 = -2113470464;
	// addi r12,r12,15472
	r12.s64 = r12.s64 + 15472;
	// rlwinm r0,r29,1,0,30
	r0.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// lhzx r0,r12,r0
	r0.u64 = PPC_LOAD_U16(r12.u32 + r0.u32);
	// lis r12,-32192
	r12.s64 = -2109734912;
	// addi r12,r12,28572
	r12.s64 = r12.s64 + 28572;
	// add r12,r12,r0
	r12.u64 = r12.u64 + r0.u64;
	// mtctr r12
	ctr.u64 = r12.u64;
	// nop 
	// bctr 
	switch (r29.u64) {
	case 0:
		goto loc_82406F9C;
	case 1:
		goto loc_82406FD8;
	case 2:
		goto loc_82407024;
	case 3:
		goto loc_8240704C;
	case 4:
		goto loc_824070D0;
	case 5:
		goto loc_824070F8;
	case 6:
		goto loc_82407128;
	case 7:
		goto loc_82407158;
	case 8:
		goto loc_82407224;
	case 9:
		goto loc_824072E0;
	case 10:
		goto loc_824073E8;
	case 11:
		goto loc_82407410;
	case 12:
		goto loc_82407584;
	case 13:
		goto loc_82407630;
	case 14:
		goto loc_824076A8;
	case 15:
		goto loc_824076D0;
	default:
		__builtin_unreachable();
	}
loc_82406F9C:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,29,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-11904
	ctx.r4.s64 = r11.s64 + -11904;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,31904
	ctx.r4.s64 = r11.s64 + 31904;
loc_82406FCC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// b 0x82407a98
	goto loc_82407A98;
loc_82406FD8:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r4,r11,-11904
	ctx.r4.s64 = r11.s64 + -11904;
loc_82406FEC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,31896
	ctx.r4.s64 = r11.s64 + 31896;
loc_82406FFC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,0
	ctx.r6.s64 = 0;
	// rlwinm r5,r11,23,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 23) & 0x1;
	// rlwinm r4,r10,17,31,31
	ctx.r4.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 17) & 0x1;
loc_82407018:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404c30
	sub_82404C30(ctx, base);
	// b 0x82407a98
	goto loc_82407A98;
loc_82407024:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r4,r11,-11904
	ctx.r4.s64 = r11.s64 + -11904;
loc_82407038:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,31888
	ctx.r4.s64 = r11.s64 + 31888;
	// b 0x82406ffc
	goto loc_82406FFC;
loc_8240704C:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-11904
	ctx.r4.s64 = r11.s64 + -11904;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,31880
	ctx.r4.s64 = r11.s64 + 31880;
loc_82407070:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-21432
	ctx.r4.s64 = r11.s64 + -21432;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824070a4
	if (!cr0.getEQ()) goto loc_824070A4;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,16096
	ctx.r4.s64 = r11.s64 + 16096;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824070A4:
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-5444
	ctx.r4.s64 = r11.s64 + -5444;
	// rlwinm r5,r10,30,24,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0xFF;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// li r5,0
	ctx.r5.s64 = 0;
loc_824070C0:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r6,1
	ctx.r6.s64 = 1;
	// rlwinm r4,r11,17,31,31
	ctx.r4.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 17) & 0x1;
	// b 0x82407018
	goto loc_82407018;
loc_824070D0:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-11904
	ctx.r4.s64 = r11.s64 + -11904;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,31872
	ctx.r4.s64 = r11.s64 + 31872;
	// b 0x82407070
	goto loc_82407070;
loc_824070F8:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240711c
	if (cr0.getEQ()) goto loc_8240711C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15580
	ctx.r4.s64 = r11.s64 + 15580;
	// b 0x82406fec
	goto loc_82406FEC;
loc_8240711C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15572
	ctx.r4.s64 = r11.s64 + 15572;
	// b 0x82406fec
	goto loc_82406FEC;
loc_82407128:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240714c
	if (cr0.getEQ()) goto loc_8240714C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15580
	ctx.r4.s64 = r11.s64 + 15580;
	// b 0x82407038
	goto loc_82407038;
loc_8240714C:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15572
	ctx.r4.s64 = r11.s64 + 15572;
	// b 0x82407038
	goto loc_82407038;
loc_82407158:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-11904
	ctx.r4.s64 = r11.s64 + -11904;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,10864
	ctx.r4.s64 = r11.s64 + 10864;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-21432
	ctx.r4.s64 = r11.s64 + -21432;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,16088
	ctx.r4.s64 = r11.s64 + 16088;
	// lhz r11,0(r30)
	r11.u64 = PPC_LOAD_U16(r30.u32 + 0);
	// clrlwi r5,r11,27
	ctx.r5.u64 = r11.u32 & 0x1F;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// clrlwi r5,r10,19
	ctx.r5.u64 = ctx.r10.u32 & 0x1FFF;
	// addi r4,r11,15656
	ctx.r4.s64 = r11.s64 + 15656;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r9,r11,26,31,31
	ctx.r9.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// rlwinm r11,r10,19,31,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 19) & 0x1;
	// bne 0x824071e0
	if (!cr0.getEQ()) goto loc_824071E0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240720c
	if (cr6.getEQ()) goto loc_8240720C;
loc_824071E0:
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824071f4
	if (cr6.getEQ()) goto loc_824071F4;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r5,r11,5368
	ctx.r5.s64 = r11.s64 + 5368;
	// b 0x824071fc
	goto loc_824071FC;
loc_824071F4:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r5,r11,5360
	ctx.r5.s64 = r11.s64 + 5360;
loc_824071FC:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,16076
	ctx.r4.s64 = r11.s64 + 16076;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_8240720C:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r5,r11,21,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 21) & 0x1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r4,r11,-5624
	ctx.r4.s64 = r11.s64 + -5624;
	// b 0x82407730
	goto loc_82407730;
loc_82407224:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,10,10
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x200000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407260
	if (cr0.getEQ()) goto loc_82407260;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407254
	if (cr0.getEQ()) goto loc_82407254;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15580
	ctx.r4.s64 = r11.s64 + 15580;
	// b 0x82407268
	goto loc_82407268;
loc_82407254:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15572
	ctx.r4.s64 = r11.s64 + 15572;
	// b 0x82407268
	goto loc_82407268;
loc_82407260:
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r4,r11,-11904
	ctx.r4.s64 = r11.s64 + -11904;
loc_82407268:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,10852
	ctx.r4.s64 = r11.s64 + 10852;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-21432
	ctx.r4.s64 = r11.s64 + -21432;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,16088
	ctx.r4.s64 = r11.s64 + 16088;
	// lhz r11,0(r30)
	r11.u64 = PPC_LOAD_U16(r30.u32 + 0);
	// clrlwi r5,r11,27
	ctx.r5.u64 = r11.u32 & 0x1F;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// clrlwi r5,r10,19
	ctx.r5.u64 = ctx.r10.u32 & 0x1FFF;
	// addi r4,r11,15656
	ctx.r4.s64 = r11.s64 + 15656;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,16056
	ctx.r4.s64 = r11.s64 + 16056;
loc_824072D4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// b 0x82407a98
	goto loc_82407A98;
loc_824072E0:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r29,0
	r29.s64 = 0;
	// rlwinm. r11,r11,0,17,17
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407324
	if (cr0.getEQ()) goto loc_82407324;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r29,1
	r29.s64 = 1;
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407318
	if (cr0.getEQ()) goto loc_82407318;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15580
	ctx.r4.s64 = r11.s64 + 15580;
	// b 0x8240732c
	goto loc_8240732C;
loc_82407318:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15572
	ctx.r4.s64 = r11.s64 + 15572;
	// b 0x8240732c
	goto loc_8240732C;
loc_82407324:
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r4,r11,-11904
	ctx.r4.s64 = r11.s64 + -11904;
loc_8240732C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm. r11,r11,0,18,18
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824073b4
	if (!cr0.getEQ()) goto loc_824073B4;
	// clrlwi. r11,r29,24
	r11.u64 = r29.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824073b4
	if (!cr0.getEQ()) goto loc_824073B4;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,31864
	ctx.r4.s64 = r11.s64 + 31864;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-21432
	ctx.r4.s64 = r11.s64 + -21432;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407380
	if (cr0.getEQ()) goto loc_82407380;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r5,r11,2334
	ctx.r5.s64 = r11.s64 + 2334;
	// b 0x82407388
	goto loc_82407388;
loc_82407380:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r5,r11,16096
	ctx.r5.s64 = r11.s64 + 16096;
loc_82407388:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,8704
	ctx.r4.s64 = r11.s64 + 8704;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// rlwinm r5,r10,30,24,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0xFF;
	// addi r4,r11,16048
	ctx.r4.s64 = r11.s64 + 16048;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// b 0x824073d4
	goto loc_824073D4;
loc_824073B4:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,10880
	ctx.r4.s64 = r11.s64 + 10880;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-21432
	ctx.r4.s64 = r11.s64 + -21432;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824073D4:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15656
	ctx.r4.s64 = r11.s64 + 15656;
	// clrlwi r5,r10,19
	ctx.r5.u64 = ctx.r10.u32 & 0x1FFF;
	// b 0x82407730
	goto loc_82407730;
loc_824073E8:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-11904
	ctx.r4.s64 = r11.s64 + -11904;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,10860
	ctx.r4.s64 = r11.s64 + 10860;
	// b 0x82406fcc
	goto loc_82406FCC;
loc_82407410:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r29,0
	r29.s64 = 0;
	// rlwinm. r11,r11,0,17,17
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407454
	if (cr0.getEQ()) goto loc_82407454;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// li r29,1
	r29.s64 = 1;
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407448
	if (cr0.getEQ()) goto loc_82407448;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15580
	ctx.r4.s64 = r11.s64 + 15580;
	// b 0x8240745c
	goto loc_8240745C;
loc_82407448:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,15572
	ctx.r4.s64 = r11.s64 + 15572;
	// b 0x8240745c
	goto loc_8240745C;
loc_82407454:
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r4,r11,-11904
	ctx.r4.s64 = r11.s64 + -11904;
loc_8240745C:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r11,0
	r11.s64 = 0;
	// rlwinm. r10,r10,0,18,18
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x2000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8240747c
	if (!cr0.getEQ()) goto loc_8240747C;
	// clrlwi. r10,r29,24
	ctx.r10.u64 = r29.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82407480
	if (cr0.getEQ()) goto loc_82407480;
loc_8240747C:
	// li r11,1
	r11.s64 = 1;
loc_82407480:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq 0x824074ac
	if (cr0.getEQ()) goto loc_824074AC;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,31852
	ctx.r4.s64 = r11.s64 + 31852;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-21432
	ctx.r4.s64 = r11.s64 + -21432;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// b 0x82407510
	goto loc_82407510;
loc_824074AC:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,31856
	ctx.r4.s64 = r11.s64 + 31856;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-21432
	ctx.r4.s64 = r11.s64 + -21432;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824074e0
	if (cr0.getEQ()) goto loc_824074E0;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r5,r11,2334
	ctx.r5.s64 = r11.s64 + 2334;
	// b 0x824074e8
	goto loc_824074E8;
loc_824074E0:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r5,r11,16096
	ctx.r5.s64 = r11.s64 + 16096;
loc_824074E8:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,8704
	ctx.r4.s64 = r11.s64 + 8704;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// rlwinm r5,r10,30,24,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0xFF;
	// addi r4,r11,16048
	ctx.r4.s64 = r11.s64 + 16048;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82407510:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15656
	ctx.r4.s64 = r11.s64 + 15656;
	// clrlwi r5,r10,19
	ctx.r5.u64 = ctx.r10.u32 & 0x1FFF;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r10,r11,0,29,29
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82407560
	if (cr0.getEQ()) goto loc_82407560;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r10,r10,31,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x82407578
	if (!cr0.getEQ()) goto loc_82407578;
	// rlwinm. r11,r11,26,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 26) & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407560
	if (cr0.getEQ()) goto loc_82407560;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r5,r11,5360
	ctx.r5.s64 = r11.s64 + 5360;
loc_82407550:
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,16028
	ctx.r4.s64 = r11.s64 + 16028;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82407560:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r5,r11,21,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 21) & 0x1;
	cr0.compare<int32_t>(ctx.r5.s32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r4,r11,-5396
	ctx.r4.s64 = r11.s64 + -5396;
	// b 0x82407730
	goto loc_82407730;
loc_82407578:
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r5,r11,5368
	ctx.r5.s64 = r11.s64 + 5368;
	// b 0x82407550
	goto loc_82407550;
loc_82407584:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-11904
	ctx.r4.s64 = r11.s64 + -11904;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,31844
	ctx.r4.s64 = r11.s64 + 31844;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-21432
	ctx.r4.s64 = r11.s64 + -21432;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r9,8(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// lis r11,-32015
	r11.s64 = -2098135040;
	// rlwinm r29,r10,23,30,31
	r29.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 23) & 0x3;
	// rlwinm r10,r9,29,31,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 29) & 0x1;
	// lis r9,-32254
	ctx.r9.s64 = -2113798144;
	// addi r11,r11,-15024
	r11.s64 = r11.s64 + -15024;
	// addi r4,r9,8704
	ctx.r4.s64 = ctx.r9.s64 + 8704;
	// rlwinm r9,r29,1,0,30
	ctx.r9.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 + ctx.r9.u64;
	// rlwinm r10,r10,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r5,r10,r11
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r10.u32 + r11.u32);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// cmplwi cr6,r29,3
	cr6.compare<uint32_t>(r29.u32, 3, xer);
	// bne cr6,0x82407618
	if (!cr6.getEQ()) goto loc_82407618;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,16024
	ctx.r4.s64 = r11.s64 + 16024;
	// clrlwi r5,r10,29
	ctx.r5.u64 = ctx.r10.u32 & 0x7;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82407618:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r4,r11,16000
	ctx.r4.s64 = r11.s64 + 16000;
	// b 0x824072d4
	goto loc_824072D4;
loc_82407630:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-11904
	ctx.r4.s64 = r11.s64 + -11904;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,31880
	ctx.r4.s64 = r11.s64 + 31880;
loc_82407654:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-21432
	ctx.r4.s64 = r11.s64 + -21432;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,21,21
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82407688
	if (!cr0.getEQ()) goto loc_82407688;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,16096
	ctx.r4.s64 = r11.s64 + 16096;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82407688:
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-5444
	ctx.r4.s64 = r11.s64 + -5444;
	// rlwinm r5,r10,30,24,31
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 30) & 0xFF;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// b 0x824070c0
	goto loc_824070C0;
loc_824076A8:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-11904
	ctx.r4.s64 = r11.s64 + -11904;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,31872
	ctx.r4.s64 = r11.s64 + 31872;
	// b 0x82407654
	goto loc_82407654;
loc_824076D0:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-11904
	ctx.r4.s64 = r11.s64 + -11904;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// addi r4,r11,31836
	ctx.r4.s64 = r11.s64 + 31836;
	// b 0x82406fcc
	goto loc_82406FCC;
loc_824076F8:
	// lbz r11,12(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 12);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-11904
	ctx.r4.s64 = r11.s64 + -11904;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-5328
	ctx.r4.s64 = r11.s64 + -5328;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// lis r11,-32251
	r11.s64 = -2113601536;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// addi r4,r11,-5308
	ctx.r4.s64 = r11.s64 + -5308;
loc_82407730:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// b 0x82407a98
	goto loc_82407A98;
loc_8240773C:
	// rlwinm. r11,r28,0,29,30
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0x6;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// lwz r11,8240(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8240);
	// cmplw cr6,r11,r22
	cr6.compare<uint32_t>(r11.u32, r22.u32, xer);
	// bgt cr6,0x82407754
	if (cr6.getGT()) goto loc_82407754;
	// mr r11,r22
	r11.u64 = r22.u64;
loc_82407754:
	// rlwinm. r10,r28,0,30,30
	ctx.r10.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// stw r11,8240(r31)
	PPC_STORE_U32(r31.u32 + 8240, r11.u32);
	// rlwinm r21,r28,27,31,31
	r21.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 27) & 0x1;
	// beq 0x8240780c
	if (cr0.getEQ()) goto loc_8240780C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405ea8
	sub_82405EA8(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240778c
	if (cr0.getEQ()) goto loc_8240778C;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// addi r4,r11,15620
	ctx.r4.s64 = r11.s64 + 15620;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_8240778C:
	// clrlwi. r11,r21,24
	r11.u64 = r21.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r29,r11,-11904
	r29.s64 = r11.s64 + -11904;
	// beq 0x824077e8
	if (cr0.getEQ()) goto loc_824077E8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lis r11,-32253
	r11.s64 = -2113732608;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,-18036
	ctx.r4.s64 = r11.s64 + -18036;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// lbz r11,8232(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 8232);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x824077cc
	if (!cr0.getEQ()) goto loc_824077CC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405e50
	sub_82405E50(ctx, base);
loc_824077CC:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824077e8
	if (cr0.getEQ()) goto loc_824077E8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r4,r11,15636
	ctx.r4.s64 = r11.s64 + 15636;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824077E8:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// mr r6,r22
	ctx.r6.u64 = r22.u64;
	// rlwinm r5,r28,28,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 28) & 0x1;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x824060a0
	sub_824060A0(ctx, base);
	// b 0x82407a98
	goto loc_82407A98;
loc_8240780C:
	// rlwinm. r11,r28,0,29,29
	r11.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407a98
	if (cr0.getEQ()) goto loc_82407A98;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82404a70
	sub_82404A70(ctx, base);
	// lis r29,-14336
	r29.s64 = -939524096;
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r25,r11,15636
	r25.s64 = r11.s64 + 15636;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r26,r11,-18036
	r26.s64 = r11.s64 + -18036;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r27,r11,15620
	r27.s64 = r11.s64 + 15620;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r24,r11,15572
	r24.s64 = r11.s64 + 15572;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r23,r11,15580
	r23.s64 = r11.s64 + 15580;
	// lis r11,-32253
	r11.s64 = -2113732608;
	// addi r28,r11,-11904
	r28.s64 = r11.s64 + -11904;
	// beq 0x824078a0
	if (cr0.getEQ()) goto loc_824078A0;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r10,r11,0,0,5
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFC000000;
	// cmplw cr6,r10,r29
	cr6.compare<uint32_t>(ctx.r10.u32, r29.u32, xer);
	// bne cr6,0x82407894
	if (!cr6.getEQ()) goto loc_82407894;
	// rlwinm. r10,r11,0,16,16
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82407888
	if (cr0.getEQ()) goto loc_82407888;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x824049d0
	sub_824049D0(ctx, base);
	// not r11,r3
	r11.u64 = ~ctx.r3.u64;
	// rlwinm r11,r11,31,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// b 0x82407898
	goto loc_82407898;
loc_82407888:
	// rlwinm. r11,r11,0,8,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x82407898
	if (cr0.getEQ()) goto loc_82407898;
loc_82407894:
	// li r11,0
	r11.s64 = 0;
loc_82407898:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407954
	if (cr0.getEQ()) goto loc_82407954;
loc_824078A0:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405ea8
	sub_82405EA8(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824078c4
	if (cr0.getEQ()) goto loc_824078C4;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824078C4:
	// clrlwi. r11,r21,24
	r11.u64 = r21.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407910
	if (cr0.getEQ()) goto loc_82407910;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// lbz r11,8232(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 8232);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x824078f8
	if (!cr0.getEQ()) goto loc_824078F8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405e50
	sub_82405E50(ctx, base);
loc_824078F8:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407910
	if (cr0.getEQ()) goto loc_82407910;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82407910:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r11,r11,5,27,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 5) & 0x1F;
	// clrlwi r10,r11,30
	ctx.r10.u64 = r11.u32 & 0x3;
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// blt cr6,0x82407948
	if (cr6.getLT()) goto loc_82407948;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// bne 0x82407940
	if (!cr0.getEQ()) goto loc_82407940;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
loc_82407940:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82407948:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405630
	sub_82405630(ctx, base);
loc_82407954:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// rlwinm r10,r11,0,0,5
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFC000000;
	// cmplw cr6,r10,r29
	cr6.compare<uint32_t>(ctx.r10.u32, r29.u32, xer);
	// bne cr6,0x82407990
	if (!cr6.getEQ()) goto loc_82407990;
	// rlwinm. r10,r11,0,16,16
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x82407984
	if (cr0.getEQ()) goto loc_82407984;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x824049d0
	sub_824049D0(ctx, base);
	// not r11,r3
	r11.u64 = ~ctx.r3.u64;
	// rlwinm r11,r11,31,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 31) & 0x1;
	// clrlwi r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	// b 0x82407994
	goto loc_82407994;
loc_82407984:
	// rlwinm. r11,r11,0,8,11
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF00000;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// li r11,1
	r11.s64 = 1;
	// beq 0x82407994
	if (cr0.getEQ()) goto loc_82407994;
loc_82407990:
	// li r11,0
	r11.s64 = 0;
loc_82407994:
	// clrlwi. r11,r11,24
	r11.u64 = r11.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82407a98
	if (!cr0.getEQ()) goto loc_82407A98;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x82404a70
	sub_82404A70(ctx, base);
	// clrlwi. r11,r3,24
	r11.u64 = ctx.r3.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x824079e4
	if (!cr0.getEQ()) goto loc_824079E4;
	// lbz r11,8232(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 8232);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x824079c0
	if (!cr0.getEQ()) goto loc_824079C0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405e50
	sub_82405E50(ctx, base);
loc_824079C0:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x824079d8
	if (cr0.getEQ()) goto loc_824079D8;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_824079D8:
	// lis r11,-32251
	r11.s64 = -2113601536;
	// addi r4,r11,-5804
	ctx.r4.s64 = r11.s64 + -5804;
	// b 0x82407a58
	goto loc_82407A58;
loc_824079E4:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405ea8
	sub_82405EA8(ctx, base);
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407a08
	if (cr0.getEQ()) goto loc_82407A08;
	// mr r5,r22
	ctx.r5.u64 = r22.u64;
	// mr r4,r27
	ctx.r4.u64 = r27.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82407A08:
	// clrlwi. r11,r21,24
	r11.u64 = r21.u32 & 0xFF;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407a54
	if (cr0.getEQ()) goto loc_82407A54;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// bl 0x82404da8
	sub_82404DA8(ctx, base);
	// lbz r11,8232(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 8232);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x82407a3c
	if (!cr0.getEQ()) goto loc_82407A3C;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405e50
	sub_82405E50(ctx, base);
loc_82407A3C:
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,26,26
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x20;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407a54
	if (cr0.getEQ()) goto loc_82407A54;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82407A54:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
loc_82407A58:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r11,r11,5,27,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 5) & 0x1F;
	// clrlwi r10,r11,30
	ctx.r10.u64 = r11.u32 & 0x3;
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// blt cr6,0x82407a8c
	if (cr6.getLT()) goto loc_82407A8C;
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r4,r23
	ctx.r4.u64 = r23.u64;
	// bne 0x82407a84
	if (!cr0.getEQ()) goto loc_82407A84;
	// mr r4,r24
	ctx.r4.u64 = r24.u64;
loc_82407A84:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
loc_82407A8C:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405a10
	sub_82405A10(ctx, base);
loc_82407A98:
	// lbz r11,8232(r31)
	r11.u64 = PPC_LOAD_U8(r31.u32 + 8232);
	// cmplwi r11,0
	cr0.compare<uint32_t>(r11.u32, 0, xer);
	// bne 0x82407aac
	if (!cr0.getEQ()) goto loc_82407AAC;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405e50
	sub_82405E50(ctx, base);
loc_82407AAC:
	// lwz r3,8236(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8236);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed16c
	return;
}

__attribute__((alias("__imp__sub_82407AB8"))) PPC_WEAK_FUNC(sub_82407AB8);
PPC_FUNC_IMPL(__imp__sub_82407AB8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// clrlwi. r11,r4,31
	r11.u64 = ctx.r4.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407b48
	if (cr0.getEQ()) goto loc_82407B48;
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm. r11,r11,0,20,20
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x800;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407af8
	if (cr0.getEQ()) goto loc_82407AF8;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r6,r11,16116
	ctx.r6.s64 = r11.s64 + 16116;
	// bl 0x82405f60
	sub_82405F60(ctx, base);
loc_82407AF8:
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// rlwinm r11,r11,20,28,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 20) & 0xF;
	// cmplwi cr6,r11,7
	cr6.compare<uint32_t>(r11.u32, 7, xer);
	// beq cr6,0x82407b20
	if (cr6.getEQ()) goto loc_82407B20;
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// beq cr6,0x82407b20
	if (cr6.getEQ()) goto loc_82407B20;
	// cmplwi cr6,r11,9
	cr6.compare<uint32_t>(r11.u32, 9, xer);
	// beq cr6,0x82407b20
	if (cr6.getEQ()) goto loc_82407B20;
	// cmplwi cr6,r11,11
	cr6.compare<uint32_t>(r11.u32, 11, xer);
	// bne cr6,0x82407b48
	if (!cr6.getEQ()) goto loc_82407B48;
loc_82407B20:
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// clrlwi r10,r10,19
	ctx.r10.u64 = ctx.r10.u32 & 0x1FFF;
	// rlwinm r9,r10,29,3,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFC;
	// clrlwi r10,r10,27
	ctx.r10.u64 = ctx.r10.u32 & 0x1F;
	// slw r10,r8,r10
	ctx.r10.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r8.u32 << (ctx.r10.u8 & 0x3F));
	// lwzx r8,r9,r11
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// or r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 | ctx.r8.u64;
	// stwx r10,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r10.u32);
loc_82407B48:
	// li r3,0
	ctx.r3.s64 = 0;
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82407B68"))) PPC_WEAK_FUNC(sub_82407B68);
PPC_FUNC_IMPL(__imp__sub_82407B68) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// b 0x82406e98
	sub_82406E98(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82407B80"))) PPC_WEAK_FUNC(sub_82407B80);
PPC_FUNC_IMPL(__imp__sub_82407B80) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r3,r6
	ctx.r3.u64 = ctx.r6.u64;
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// mr r4,r11
	ctx.r4.u64 = r11.u64;
	// b 0x82407ab8
	sub_82407AB8(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82407B98"))) PPC_WEAK_FUNC(sub_82407B98);
PPC_FUNC_IMPL(__imp__sub_82407B98) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// lis r10,-32192
	ctx.r10.s64 = -2109734912;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r5
	ctx.r4.u64 = ctx.r5.u64;
	// li r9,1
	ctx.r9.s64 = 1;
	// addi r10,r10,31616
	ctx.r10.s64 = ctx.r10.s64 + 31616;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// bl 0x8218d380
	sub_8218D380(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82407BE8"))) PPC_WEAK_FUNC(sub_82407BE8);
PPC_FUNC_IMPL(__imp__sub_82407BE8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// not r11,r8
	r11.u64 = ~ctx.r8.u64;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// clrlwi r9,r11,31
	ctx.r9.u64 = r11.u32 & 0x1;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// li r10,1
	ctx.r10.s64 = 1;
	// li r11,0
	r11.s64 = 0;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// stw r4,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r4.u32);
	// stw r5,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r5.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// stw r30,16(r31)
	PPC_STORE_U32(r31.u32 + 16, r30.u32);
	// stw r8,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r8.u32);
	// stb r10,12(r31)
	PPC_STORE_U8(r31.u32 + 12, ctx.r10.u8);
	// stb r9,13(r31)
	PPC_STORE_U8(r31.u32 + 13, ctx.r9.u8);
	// stb r10,8232(r31)
	PPC_STORE_U8(r31.u32 + 8232, ctx.r10.u8);
	// stw r11,8240(r31)
	PPC_STORE_U32(r31.u32 + 8240, r11.u32);
	// stw r11,8236(r31)
	PPC_STORE_U32(r31.u32 + 8236, r11.u32);
	// bl 0x82407b98
	sub_82407B98(ctx, base);
	// lis r11,-32192
	r11.s64 = -2109734912;
	// stw r31,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r31.u32);
	// li r9,7
	ctx.r9.s64 = 7;
	// addi r10,r11,31592
	ctx.r10.s64 = r11.s64 + 31592;
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8218d380
	sub_8218D380(ctx, base);
	// mr. r27,r3
	r27.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r27.s32, 0, xer);
	// blt 0x82407cd0
	if (cr0.getLT()) goto loc_82407CD0;
	// lwz r11,8(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// rlwinm. r11,r11,0,23,23
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x100;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x82407cd0
	if (!cr0.getEQ()) goto loc_82407CD0;
	// lwz r11,8240(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 8240);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// mulli r28,r11,12
	r28.s64 = r11.s64 * 12;
	// addi r11,r28,12
	r11.s64 = r28.s64 + 12;
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// bgt cr6,0x82407cd0
	if (cr6.getGT()) goto loc_82407CD0;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405e50
	sub_82405E50(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// add r30,r28,r30
	r30.u64 = r28.u64 + r30.u64;
	// bl 0x82404e60
	sub_82404E60(ctx, base);
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lwz r7,8(r30)
	ctx.r7.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// addi r4,r11,16152
	ctx.r4.s64 = r11.s64 + 16152;
	// lwz r6,4(r30)
	ctx.r6.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// bl 0x82404be0
	sub_82404BE0(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82405f18
	sub_82405F18(ctx, base);
loc_82407CD0:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_82407CE0"))) PPC_WEAK_FUNC(sub_82407CE0);
PPC_FUNC_IMPL(__imp__sub_82407CE0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed12c
	// ld r12,-4096(r1)
	r12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -4096);
	// ld r12,-8192(r1)
	r12.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8192);
	// stwu r1,-8400(r1)
	ea = -8400 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r10
	r25.u64 = ctx.r10.u64;
	// lwz r10,8484(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 8484);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// clrlwi r11,r10,30
	r11.u64 = ctx.r10.u32 & 0x3;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r26,r9
	r26.u64 = ctx.r9.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// li r31,0
	r31.s64 = 0;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x82407d44
	if (cr6.getEQ()) goto loc_82407D44;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x82407d34
	if (!cr6.getEQ()) goto loc_82407D34;
	// li r31,8
	r31.s64 = 8;
	// b 0x82407d44
	goto loc_82407D44;
loc_82407D34:
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x82407d44
	if (cr6.getEQ()) goto loc_82407D44;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,87
	ctx.r3.u64 = ctx.r3.u64 | 87;
loc_82407D44:
	// rlwinm. r11,r10,0,28,28
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407d50
	if (cr0.getEQ()) goto loc_82407D50;
	// ori r31,r31,2
	r31.u64 = r31.u64 | 2;
loc_82407D50:
	// rlwinm. r11,r10,0,29,29
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x4;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407d5c
	if (cr0.getEQ()) goto loc_82407D5C;
	// ori r31,r31,4
	r31.u64 = r31.u64 | 4;
loc_82407D5C:
	// rlwinm. r11,r10,0,25,25
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407d68
	if (cr0.getEQ()) goto loc_82407D68;
	// ori r31,r31,32
	r31.u64 = r31.u64 | 32;
loc_82407D68:
	// rlwinm. r11,r10,0,27,27
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x10;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407d74
	if (cr0.getEQ()) goto loc_82407D74;
	// ori r31,r31,16
	r31.u64 = r31.u64 | 16;
loc_82407D74:
	// rlwinm. r11,r10,0,24,24
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x80;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407d80
	if (cr0.getEQ()) goto loc_82407D80;
	// ori r31,r31,64
	r31.u64 = r31.u64 | 64;
loc_82407D80:
	// rlwinm. r11,r10,0,22,22
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x200;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407d8c
	if (cr0.getEQ()) goto loc_82407D8C;
	// ori r31,r31,128
	r31.u64 = r31.u64 | 128;
loc_82407D8C:
	// rlwinm. r11,r10,0,21,21
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0x400;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x82407d98
	if (cr0.getEQ()) goto loc_82407D98;
	// ori r31,r31,256
	r31.u64 = r31.u64 | 256;
loc_82407D98:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82407dec
	if (cr6.getLT()) goto loc_82407DEC;
	// li r5,8192
	ctx.r5.s64 = 8192;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// lwz r11,8492(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 8492);
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// stw r26,8304(r1)
	PPC_STORE_U32(ctx.r1.u32 + 8304, r26.u32);
	// mr r7,r27
	ctx.r7.u64 = r27.u64;
	// stw r25,8308(r1)
	PPC_STORE_U32(ctx.r1.u32 + 8308, r25.u32);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// stw r11,8296(r1)
	PPC_STORE_U32(ctx.r1.u32 + 8296, r11.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r11,8500(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 8500);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r11,8300(r1)
	PPC_STORE_U32(ctx.r1.u32 + 8300, r11.u32);
	// li r11,0
	r11.s64 = 0;
	// stb r11,8313(r1)
	PPC_STORE_U8(ctx.r1.u32 + 8313, r11.u8);
	// bl 0x82407be8
	sub_82407BE8(ctx, base);
loc_82407DEC:
	// addi r1,r1,8400
	ctx.r1.s64 = ctx.r1.s64 + 8400;
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_82407DF8"))) PPC_WEAK_FUNC(sub_82407DF8);
PPC_FUNC_IMPL(__imp__sub_82407DF8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// rlwinm r30,r6,2,0,29
	r30.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// addi r4,r30,5
	ctx.r4.s64 = r30.s64 + 5;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// bl 0x8219d8f0
	sub_8219D8F0(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq 0x82407e8c
	if (cr0.getEQ()) goto loc_82407E8C;
	// lis r10,-32768
	ctx.r10.s64 = -2147483648;
	// addi r11,r3,4
	r11.s64 = ctx.r3.s64 + 4;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// mr r7,r10
	ctx.r7.u64 = ctx.r10.u64;
	// subfic r4,r11,-8
	xer.ca = r11.u32 <= 4294967288;
	ctx.r4.s64 = -8 - r11.s64;
	// rlwinm r6,r30,16,0,15
	ctx.r6.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 16) & 0xFFFF0000;
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// clrlwi r9,r4,28
	ctx.r9.u64 = ctx.r4.u32 & 0xF;
	// stw r8,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r8.u32);
	// rlwinm r10,r29,8,0,23
	ctx.r10.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 8) & 0xFFFFFF00;
	// stw r7,8(r11)
	PPC_STORE_U32(r11.u32 + 8, ctx.r7.u32);
	// add r11,r9,r11
	r11.u64 = ctx.r9.u64 + r11.u64;
	// lwz r8,12708(r31)
	ctx.r8.u64 = PPC_LOAD_U32(r31.u32 + 12708);
	// subf r5,r10,r28
	ctx.r5.s64 = r28.s64 - ctx.r10.s64;
	// addi r3,r11,8
	ctx.r3.s64 = r11.s64 + 8;
	// or r9,r8,r6
	ctx.r9.u64 = ctx.r8.u64 | ctx.r6.u64;
	// rlwinm r5,r5,2,21,29
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0x7FC;
	// oris r9,r9,49152
	ctx.r9.u64 = ctx.r9.u64 | 3221225472;
	// rlwinm r10,r30,2,0,29
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 2) & 0xFFFFFFFC;
	// ori r9,r9,11520
	ctx.r9.u64 = ctx.r9.u64 | 11520;
	// stw r5,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r5.u32);
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// add r11,r10,r3
	r11.u64 = ctx.r10.u64 + ctx.r3.u64;
	// addi r11,r11,-4
	r11.s64 = r11.s64 + -4;
	// stw r11,48(r31)
	PPC_STORE_U32(r31.u32 + 48, r11.u32);
loc_82407E8C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_82407E98"))) PPC_WEAK_FUNC(sub_82407E98);
PPC_FUNC_IMPL(__imp__sub_82407E98) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x823ed128
	// mullw r11,r6,r7
	r11.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r7.s32);
	// add r24,r11,r4
	r24.u64 = r11.u64 + ctx.r4.u64;
	// cmplw cr6,r4,r24
	cr6.compare<uint32_t>(ctx.r4.u32, r24.u32, xer);
	// bge cr6,0x82407f88
	if (!cr6.getLT()) goto loc_82407F88;
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r25,r7,1,0,30
	r25.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// add r26,r11,r4
	r26.u64 = r11.u64 + ctx.r4.u64;
loc_82407EBC:
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplw cr6,r4,r26
	cr6.compare<uint32_t>(ctx.r4.u32, r26.u32, xer);
	// bge cr6,0x82407f74
	if (!cr6.getLT()) goto loc_82407F74;
	// subf r10,r4,r26
	ctx.r10.s64 = r26.s64 - ctx.r4.s64;
	// addi r11,r4,4
	r11.s64 = ctx.r4.s64 + 4;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r27,r7,-4
	r27.s64 = ctx.r7.s64 + -4;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
loc_82407EE0:
	// lwzx r9,r27,r11
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r6,-4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + -4);
	// rlwinm r28,r9,30,2,25
	r28.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 30) & 0x3FFFFFC0;
	// lwzx r5,r11,r7
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// rlwinm r29,r6,30,2,25
	r29.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 30) & 0x3FFFFFC0;
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// clrlwi r6,r6,8
	ctx.r6.u64 = ctx.r6.u32 & 0xFFFFFF;
	// clrlwi r9,r9,8
	ctx.r9.u64 = ctx.r9.u32 & 0xFFFFFF;
	// rlwinm r6,r6,0,24,15
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFFFFFF00FF;
	// rlwinm r9,r9,0,24,15
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFFFFFFFFFFFF00FF;
	// rlwinm r28,r28,0,18,9
	r28.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFFFFC03FFF;
	// rlwinm r29,r29,0,18,9
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFFFFC03FFF;
	// add r9,r6,r9
	ctx.r9.u64 = ctx.r6.u64 + ctx.r9.u64;
	// add r29,r29,r28
	r29.u64 = r29.u64 + r28.u64;
	// rlwinm r28,r5,30,2,25
	r28.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 30) & 0x3FFFFFC0;
	// clrlwi r6,r5,8
	ctx.r6.u64 = ctx.r5.u32 & 0xFFFFFF;
	// rlwinm r28,r28,0,18,9
	r28.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFFFFC03FFF;
	// rlwinm r6,r6,0,24,15
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFFFFFF00FF;
	// add r5,r29,r28
	ctx.r5.u64 = r29.u64 + r28.u64;
	// add r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 + ctx.r6.u64;
	// rlwinm r29,r31,30,2,25
	r29.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 30) & 0x3FFFFFC0;
	// clrlwi r6,r31,8
	ctx.r6.u64 = r31.u32 & 0xFFFFFF;
	// rlwinm r29,r29,0,18,9
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFFFFC03FFF;
	// rlwinm r6,r6,0,24,15
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFFFFFFFFFFFF00FF;
	// add r5,r5,r29
	ctx.r5.u64 = ctx.r5.u64 + r29.u64;
	// add r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 + ctx.r6.u64;
	// addis r6,r5,128
	ctx.r6.s64 = ctx.r5.s64 + 8388608;
	// addis r9,r9,2
	ctx.r9.s64 = ctx.r9.s64 + 131072;
	// addi r6,r6,128
	ctx.r6.s64 = ctx.r6.s64 + 128;
	// addi r9,r9,2
	ctx.r9.s64 = ctx.r9.s64 + 2;
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// rlwimi r6,r9,30,24,31
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r9.u32, 30) & 0xFF) | (ctx.r6.u64 & 0xFFFFFFFFFFFFFF00);
	// rlwimi r6,r9,30,8,15
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r9.u32, 30) & 0xFF0000) | (ctx.r6.u64 & 0xFFFFFFFFFF00FFFF);
	// stw r6,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r6.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x82407ee0
	if (!cr0.getEQ()) goto loc_82407EE0;
loc_82407F74:
	// add r4,r25,r4
	ctx.r4.u64 = r25.u64 + ctx.r4.u64;
	// add r3,r3,r8
	ctx.r3.u64 = ctx.r3.u64 + ctx.r8.u64;
	// add r26,r26,r25
	r26.u64 = r26.u64 + r25.u64;
	// cmplw cr6,r4,r24
	cr6.compare<uint32_t>(ctx.r4.u32, r24.u32, xer);
	// blt cr6,0x82407ebc
	if (cr6.getLT()) goto loc_82407EBC;
loc_82407F88:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_82407F90"))) PPC_WEAK_FUNC(sub_82407F90);
PPC_FUNC_IMPL(__imp__sub_82407F90) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	// mflr r12
	// bl 0x823ed128
	// mullw r11,r6,r7
	r11.s64 = int64_t(ctx.r6.s32) * int64_t(ctx.r7.s32);
	// add r24,r11,r4
	r24.u64 = r11.u64 + ctx.r4.u64;
	// cmplw cr6,r4,r24
	cr6.compare<uint32_t>(ctx.r4.u32, r24.u32, xer);
	// bge cr6,0x8240806c
	if (!cr6.getLT()) goto loc_8240806C;
	// rlwinm r11,r5,2,0,29
	r11.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 2) & 0xFFFFFFFC;
	// rlwinm r25,r7,1,0,30
	r25.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 1) & 0xFFFFFFFE;
	// add r26,r11,r4
	r26.u64 = r11.u64 + ctx.r4.u64;
loc_82407FB4:
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmplw cr6,r4,r26
	cr6.compare<uint32_t>(ctx.r4.u32, r26.u32, xer);
	// bge cr6,0x82408058
	if (!cr6.getLT()) goto loc_82408058;
	// subf r10,r4,r26
	ctx.r10.s64 = r26.s64 - ctx.r4.s64;
	// addi r11,r4,4
	r11.s64 = ctx.r4.s64 + 4;
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// addi r27,r7,-4
	r27.s64 = ctx.r7.s64 + -4;
	// rlwinm r10,r10,29,3,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 29) & 0x1FFFFFFF;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
loc_82407FD8:
	// lwzx r9,r27,r11
	ctx.r9.u64 = PPC_LOAD_U32(r27.u32 + r11.u32);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// lwz r6,-4(r11)
	ctx.r6.u64 = PPC_LOAD_U32(r11.u32 + -4);
	// clrlwi r28,r9,8
	r28.u64 = ctx.r9.u32 & 0xFFFFFF;
	// lwzx r5,r11,r7
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + ctx.r7.u32);
	// clrlwi r29,r6,8
	r29.u64 = ctx.r6.u32 & 0xFFFFFF;
	// lwz r31,0(r11)
	r31.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// rlwinm r28,r28,0,24,15
	r28.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFFFFFF00FF;
	// rlwinm r29,r29,0,24,15
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFFFFFF00FF;
	// rlwinm r6,r6,0,16,23
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 0) & 0xFF00;
	// add r29,r29,r28
	r29.u64 = r29.u64 + r28.u64;
	// clrlwi r28,r5,8
	r28.u64 = ctx.r5.u32 & 0xFFFFFF;
	// rlwinm r9,r9,0,16,23
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 0) & 0xFF00;
	// rlwinm r28,r28,0,24,15
	r28.u64 = __builtin_rotateleft64(r28.u32 | (r28.u64 << 32), 0) & 0xFFFFFFFFFFFF00FF;
	// add r9,r6,r9
	ctx.r9.u64 = ctx.r6.u64 + ctx.r9.u64;
	// rlwinm r6,r5,0,16,23
	ctx.r6.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 0) & 0xFF00;
	// add r5,r29,r28
	ctx.r5.u64 = r29.u64 + r28.u64;
	// clrlwi r29,r31,8
	r29.u64 = r31.u32 & 0xFFFFFF;
	// add r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 + ctx.r6.u64;
	// rlwinm r29,r29,0,24,15
	r29.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 0) & 0xFFFFFFFFFFFF00FF;
	// rlwinm r6,r31,0,16,23
	ctx.r6.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0xFF00;
	// add r5,r5,r29
	ctx.r5.u64 = ctx.r5.u64 + r29.u64;
	// add r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 + ctx.r6.u64;
	// addis r6,r5,2
	ctx.r6.s64 = ctx.r5.s64 + 131072;
	// addi r9,r9,512
	ctx.r9.s64 = ctx.r9.s64 + 512;
	// addi r6,r6,2
	ctx.r6.s64 = ctx.r6.s64 + 2;
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// rlwimi r6,r9,0,14,21
	ctx.r6.u64 = (__builtin_rotateleft32(ctx.r9.u32, 0) & 0x3FC00) | (ctx.r6.u64 & 0xFFFFFFFFFFFC03FF);
	// rlwinm r9,r6,30,8,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r6.u32 | (ctx.r6.u64 << 32), 30) & 0xFFFFFF;
	// stw r9,0(r30)
	PPC_STORE_U32(r30.u32 + 0, ctx.r9.u32);
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
	// bne 0x82407fd8
	if (!cr0.getEQ()) goto loc_82407FD8;
loc_82408058:
	// add r4,r25,r4
	ctx.r4.u64 = r25.u64 + ctx.r4.u64;
	// add r3,r3,r8
	ctx.r3.u64 = ctx.r3.u64 + ctx.r8.u64;
	// add r26,r26,r25
	r26.u64 = r26.u64 + r25.u64;
	// cmplw cr6,r4,r24
	cr6.compare<uint32_t>(ctx.r4.u32, r24.u32, xer);
	// blt cr6,0x82407fb4
	if (cr6.getLT()) goto loc_82407FB4;
loc_8240806C:
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_82408078"))) PPC_WEAK_FUNC(sub_82408078);
PPC_FUNC_IMPL(__imp__sub_82408078) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32192
	ctx.r10.s64 = -2109734912;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r10,r10,32408
	ctx.r10.s64 = ctx.r10.s64 + 32408;
	// lis r9,-32192
	ctx.r9.s64 = -2109734912;
	// lis r31,-32015
	r31.s64 = -2098135040;
	// stw r10,-14924(r11)
	PPC_STORE_U32(r11.u32 + -14924, ctx.r10.u32);
	// addi r10,r9,32656
	ctx.r10.s64 = ctx.r9.s64 + 32656;
	// lwz r11,-14924(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -14924);
	// stw r10,-14920(r31)
	PPC_STORE_U32(r31.u32 + -14920, ctx.r10.u32);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824080C8"))) PPC_WEAK_FUNC(sub_824080C8);
PPC_FUNC_IMPL(__imp__sub_824080C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32192
	ctx.r10.s64 = -2109734912;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r10,r10,32656
	ctx.r10.s64 = ctx.r10.s64 + 32656;
	// lis r9,-32192
	ctx.r9.s64 = -2109734912;
	// lis r31,-32015
	r31.s64 = -2098135040;
	// stw r10,-14920(r11)
	PPC_STORE_U32(r11.u32 + -14920, ctx.r10.u32);
	// addi r10,r9,32408
	ctx.r10.s64 = ctx.r9.s64 + 32408;
	// lwz r11,-14920(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -14920);
	// stw r10,-14924(r31)
	PPC_STORE_U32(r31.u32 + -14924, ctx.r10.u32);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82408118"))) PPC_WEAK_FUNC(sub_82408118);
PPC_FUNC_IMPL(__imp__sub_82408118) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// mr r10,r3
	ctx.r10.u64 = ctx.r3.u64;
	// mftb r11
	r11.u64 = __rdtsc();
	// rotlwi. r9,r11,0
	ctx.r9.u64 = __builtin_rotateleft32(r11.u32, 0);
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// bne 0x8240812c
	if (!cr0.getEQ()) goto loc_8240812C;
	// mftb r11
	r11.u64 = __rdtsc();
loc_8240812C:
	// li r3,1
	ctx.r3.s64 = 1;
	// std r11,0(r10)
	PPC_STORE_U64(ctx.r10.u32 + 0, r11.u64);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82408138"))) PPC_WEAK_FUNC(sub_82408138);
PPC_FUNC_IMPL(__imp__sub_82408138) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// cmplwi cr6,r5,16
	cr6.compare<uint32_t>(ctx.r5.u32, 16, xer);
	// bge cr6,0x82408174
	if (!cr6.getLT()) goto loc_82408174;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x824082e0
	if (cr6.getEQ()) goto loc_824082E0;
	// extsb r10,r4
	ctx.r10.s64 = ctx.r4.s8;
	// cmplwi r5,0
	cr0.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq 0x824082e0
	if (cr0.getEQ()) goto loc_824082E0;
	// mtctr r5
	ctr.u64 = ctx.r5.u64;
loc_82408164:
	// stb r10,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r10.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// bdnz 0x82408164
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_82408164;
	// b 0x824082e0
	goto loc_824082E0;
loc_82408174:
	// neg r9,r3
	ctx.r9.s64 = -ctx.r3.s64;
	// vspltisb v0,4
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_set1_epi8(char(0x4)));
	// lvsl v13,r0,r4
	temp.u32 = ctx.r4.u32;
	_mm_store_si128((__m128i*)ctx.v13.u8, _mm_load_si128((__m128i*)&VectorShiftTableL[(temp.u32 & 0xF) * 16]));
	// clrlwi. r10,r9,28
	ctx.r10.u64 = ctx.r9.u32 & 0xF;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// srawi r9,r9,4
	xer.ca = (ctx.r9.s32 < 0) & ((ctx.r9.u32 & 0xF) != 0);
	ctx.r9.s64 = ctx.r9.s32 >> 4;
	// srawi r8,r4,4
	xer.ca = (ctx.r4.s32 < 0) & ((ctx.r4.u32 & 0xF) != 0);
	ctx.r8.s64 = ctx.r4.s32 >> 4;
	// clrlwi r9,r9,29
	ctx.r9.u64 = ctx.r9.u32 & 0x7;
	// lvsl v12,r0,r8
	temp.u32 = ctx.r8.u32;
	_mm_store_si128((__m128i*)ctx.v12.u8, _mm_load_si128((__m128i*)&VectorShiftTableL[(temp.u32 & 0xF) * 16]));
	// vslb v0,v12,v0
	ctx.v0.u8[0] = ctx.v12.u8[0] << (ctx.v0.u8[0] & 0x7);
	ctx.v0.u8[1] = ctx.v12.u8[1] << (ctx.v0.u8[1] & 0x7);
	ctx.v0.u8[2] = ctx.v12.u8[2] << (ctx.v0.u8[2] & 0x7);
	ctx.v0.u8[3] = ctx.v12.u8[3] << (ctx.v0.u8[3] & 0x7);
	ctx.v0.u8[4] = ctx.v12.u8[4] << (ctx.v0.u8[4] & 0x7);
	ctx.v0.u8[5] = ctx.v12.u8[5] << (ctx.v0.u8[5] & 0x7);
	ctx.v0.u8[6] = ctx.v12.u8[6] << (ctx.v0.u8[6] & 0x7);
	ctx.v0.u8[7] = ctx.v12.u8[7] << (ctx.v0.u8[7] & 0x7);
	ctx.v0.u8[8] = ctx.v12.u8[8] << (ctx.v0.u8[8] & 0x7);
	ctx.v0.u8[9] = ctx.v12.u8[9] << (ctx.v0.u8[9] & 0x7);
	ctx.v0.u8[10] = ctx.v12.u8[10] << (ctx.v0.u8[10] & 0x7);
	ctx.v0.u8[11] = ctx.v12.u8[11] << (ctx.v0.u8[11] & 0x7);
	ctx.v0.u8[12] = ctx.v12.u8[12] << (ctx.v0.u8[12] & 0x7);
	ctx.v0.u8[13] = ctx.v12.u8[13] << (ctx.v0.u8[13] & 0x7);
	ctx.v0.u8[14] = ctx.v12.u8[14] << (ctx.v0.u8[14] & 0x7);
	ctx.v0.u8[15] = ctx.v12.u8[15] << (ctx.v0.u8[15] & 0x7);
	// vor v0,v13,v0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_or_si128(_mm_load_si128((__m128i*)ctx.v13.u8), _mm_load_si128((__m128i*)ctx.v0.u8)));
	// vspltb v0,v0,0
	_mm_store_si128((__m128i*)ctx.v0.u8, _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_set1_epi8(char(0xF))));
	// beq 0x824081b0
	if (cr0.getEQ()) goto loc_824081B0;
	// subf r5,r10,r5
	ctx.r5.s64 = ctx.r5.s64 - ctx.r10.s64;
	// stvlx v0,0,r3
	ea = ctx.r3.u32;
	for (size_t i = 0; i < (16 - (ea & 0xF)); i++)
		PPC_STORE_U8(ea + i, ctx.v0.u8[15 - i]);
	// add r11,r10,r3
	r11.u64 = ctx.r10.u64 + ctx.r3.u64;
loc_824081B0:
	// rlwinm r10,r5,28,4,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 28) & 0xFFFFFFF;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// bge cr6,0x824081c0
	if (!cr6.getLT()) goto loc_824081C0;
	// mr r9,r10
	ctx.r9.u64 = ctx.r10.u64;
loc_824081C0:
	// lis r10,-32015
	ctx.r10.s64 = -2098135040;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// lwz r6,-14624(r10)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r10.u32 + -14624);
	// beq cr6,0x824081e4
	if (cr6.getEQ()) goto loc_824081E4;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
loc_824081D4:
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// add r11,r6,r11
	r11.u64 = ctx.r6.u64 + r11.u64;
	// bne 0x824081d4
	if (!cr0.getEQ()) goto loc_824081D4;
loc_824081E4:
	// rlwinm r10,r9,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 4) & 0xFFFFFFF0;
	// clrlwi. r9,r4,24
	ctx.r9.u64 = ctx.r4.u32 & 0xFF;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// subf r7,r10,r5
	ctx.r7.s64 = ctx.r5.s64 - ctx.r10.s64;
	// rlwinm r9,r7,25,7,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r7.u32 | (ctx.r7.u64 << 32), 25) & 0x1FFFFFF;
	// bne 0x82408218
	if (!cr0.getEQ()) goto loc_82408218;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x824082b4
	if (cr6.getEQ()) goto loc_824082B4;
	// mr r10,r9
	ctx.r10.u64 = ctx.r9.u64;
loc_82408204:
	// dcbzl r0,r11
	memset(base + ((r11.u32) & ~127), 0, 128);
	// addic. r10,r10,-1
	xer.ca = ctx.r10.u32 > 0;
	ctx.r10.s64 = ctx.r10.s64 + -1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// addi r11,r11,128
	r11.s64 = r11.s64 + 128;
	// bne 0x82408204
	if (!cr0.getEQ()) goto loc_82408204;
	// b 0x824082b4
	goto loc_824082B4;
loc_82408218:
	// cmplwi cr6,r9,4
	cr6.compare<uint32_t>(ctx.r9.u32, 4, xer);
	// mr r8,r9
	ctx.r8.u64 = ctx.r9.u64;
	// blt cr6,0x82408228
	if (cr6.getLT()) goto loc_82408228;
	// li r8,4
	ctx.r8.s64 = 4;
loc_82408228:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x82408248
	if (cr6.getEQ()) goto loc_82408248;
loc_82408234:
	// rlwinm r5,r10,7,0,24
	ctx.r5.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 7) & 0xFFFFFF80;
	// dcbzl r5,r11
	memset(base + ((ctx.r5.u32 + r11.u32) & ~127), 0, 128);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// cmplw cr6,r10,r8
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r8.u32, xer);
	// blt cr6,0x82408234
	if (cr6.getLT()) goto loc_82408234;
loc_82408248:
	// li r10,0
	ctx.r10.s64 = 0;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x824082b4
	if (cr6.getEQ()) goto loc_824082B4;
loc_82408254:
	// addi r8,r10,4
	ctx.r8.s64 = ctx.r10.s64 + 4;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// bge cr6,0x82408268
	if (!cr6.getLT()) goto loc_82408268;
	// li r8,512
	ctx.r8.s64 = 512;
	// dcbzl r8,r11
	memset(base + ((ctx.r8.u32 + r11.u32) & ~127), 0, 128);
loc_82408268:
	// li r8,16
	ctx.r8.s64 = 16;
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// li r5,32
	ctx.r5.s64 = 32;
	// li r4,48
	ctx.r4.s64 = 48;
	// li r31,64
	r31.s64 = 64;
	// li r30,80
	r30.s64 = 80;
	// li r29,96
	r29.s64 = 96;
	// stvx128 v0,r11,r8
	_mm_store_si128((__m128i*)(base + ((r11.u32 + ctx.r8.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// li r28,112
	r28.s64 = 112;
	// stvx128 v0,r11,r5
	_mm_store_si128((__m128i*)(base + ((r11.u32 + ctx.r5.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stvx128 v0,r11,r4
	_mm_store_si128((__m128i*)(base + ((r11.u32 + ctx.r4.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r11,r31
	_mm_store_si128((__m128i*)(base + ((r11.u32 + r31.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r11,r30
	_mm_store_si128((__m128i*)(base + ((r11.u32 + r30.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// stvx128 v0,r11,r29
	_mm_store_si128((__m128i*)(base + ((r11.u32 + r29.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// stvx128 v0,r11,r28
	_mm_store_si128((__m128i*)(base + ((r11.u32 + r28.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addi r11,r11,128
	r11.s64 = r11.s64 + 128;
	// blt cr6,0x82408254
	if (cr6.getLT()) goto loc_82408254;
loc_824082B4:
	// rlwinm r10,r9,7,0,24
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 7) & 0xFFFFFF80;
	// subf r10,r10,r7
	ctx.r10.s64 = ctx.r7.s64 - ctx.r10.s64;
	// cmplwi cr6,r10,16
	cr6.compare<uint32_t>(ctx.r10.u32, 16, xer);
	// blt cr6,0x824082dc
	if (cr6.getLT()) goto loc_824082DC;
	// rlwinm r9,r10,28,4,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 28) & 0xFFFFFFF;
loc_824082C8:
	// stvx128 v0,r0,r11
	_mm_store_si128((__m128i*)(base + ((r11.u32) & ~0xF)), _mm_shuffle_epi8(_mm_load_si128((__m128i*)ctx.v0.u8), _mm_load_si128((__m128i*)VectorMaskL)));
	// addic. r9,r9,-1
	xer.ca = ctx.r9.u32 > 0;
	ctx.r9.s64 = ctx.r9.s64 + -1;
	cr0.compare<int32_t>(ctx.r9.s32, 0, xer);
	// addi r10,r10,-16
	ctx.r10.s64 = ctx.r10.s64 + -16;
	// add r11,r6,r11
	r11.u64 = ctx.r6.u64 + r11.u64;
	// bne 0x824082c8
	if (!cr0.getEQ()) goto loc_824082C8;
loc_824082DC:
	// stvrx v0,r11,r10
	ea = r11.u32 + ctx.r10.u32;
	for (size_t i = 0; i < (ea & 0xF); i++)
		PPC_STORE_U8(ea - i - 1, ctx.v0.u8[i]);
loc_824082E0:
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_824082E8"))) PPC_WEAK_FUNC(sub_824082E8);
PPC_FUNC_IMPL(__imp__sub_824082E8) {
	PPC_FUNC_PROLOGUE();
	// mr r5,r4
	ctx.r5.u64 = ctx.r4.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// b 0x824101bc
	__imp__XamInputGetState(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_824082F8"))) PPC_WEAK_FUNC(sub_824082F8);
PPC_FUNC_IMPL(__imp__sub_824082F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lwz r11,1668(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 1668);
	// lhz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 0);
	// cmplwi cr6,r10,2
	cr6.compare<uint32_t>(ctx.r10.u32, 2, xer);
	// bne cr6,0x8240838c
	if (!cr6.getEQ()) goto loc_8240838C;
	// lhz r10,2(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 2);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// bne 0x8240838c
	if (!cr0.getEQ()) goto loc_8240838C;
	// lhz r11,4(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 4);
	// cmplwi cr6,r11,5611
	cr6.compare<uint32_t>(r11.u32, 5611, xer);
	// bge cr6,0x8240838c
	if (!cr6.getLT()) goto loc_8240838C;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x824101ac
	__imp__XamInputGetCapabilities(ctx, base);
	// cmplwi r3,0
	cr0.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// bne 0x8240838c
	if (!cr0.getEQ()) goto loc_8240838C;
	// lbz r11,97(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 97);
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// bne cr6,0x8240838c
	if (!cr6.getEQ()) goto loc_8240838C;
	// lhz r11,98(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 98);
	// clrlwi. r10,r11,31
	ctx.r10.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8240838c
	if (cr0.getEQ()) goto loc_8240838C;
	// rlwinm. r11,r11,0,30,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x2;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240838c
	if (cr0.getEQ()) goto loc_8240838C;
	// lhz r11,2(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 2);
	// sth r11,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, r11.u16);
	// lhz r11,0(r31)
	r11.u64 = PPC_LOAD_U16(r31.u32 + 0);
	// sth r11,82(r1)
	PPC_STORE_U16(ctx.r1.u32 + 82, r11.u16);
loc_8240838C:
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x824101cc
	__imp__XamInputSetState(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824083C0"))) PPC_WEAK_FUNC(sub_824083C0);
PPC_FUNC_IMPL(__imp__sub_824083C0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// bl 0x8241021c
	__imp__NtClearEvent(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824083e0
	if (cr0.getLT()) goto loc_824083E0;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x824083e8
	goto loc_824083E8;
loc_824083E0:
	// bl 0x8235f2d8
	sub_8235F2D8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_824083E8:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824083F8"))) PPC_WEAK_FUNC(sub_824083F8);
PPC_FUNC_IMPL(__imp__sub_824083F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8241022c
	__imp__NtCancelTimer(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x82408420
	if (!cr0.getLT()) goto loc_82408420;
	// bl 0x8235f2d8
	sub_8235F2D8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x82408424
	goto loc_82408424;
loc_82408420:
	// li r3,1
	ctx.r3.s64 = 1;
loc_82408424:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82408438"))) PPC_WEAK_FUNC(sub_82408438);
PPC_FUNC_IMPL(__imp__sub_82408438) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8241023c
	__imp__NtSetEvent(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x8240845c
	if (cr0.getLT()) goto loc_8240845C;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x82408464
	goto loc_82408464;
loc_8240845C:
	// bl 0x8235f2d8
	sub_8235F2D8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_82408464:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82408478"))) PPC_WEAK_FUNC(sub_82408478);
PPC_FUNC_IMPL(__imp__sub_82408478) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r9,r5
	ctx.r9.u64 = ctx.r5.u64;
	// mr r5,r6
	ctx.r5.u64 = ctx.r6.u64;
	// li r10,0
	ctx.r10.s64 = 0;
	// clrlwi r8,r8,24
	ctx.r8.u64 = ctx.r8.u32 & 0xFF;
	// li r6,1
	ctx.r6.s64 = 1;
	// bl 0x8241024c
	__imp__NtSetTimerEx(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge 0x824084b0
	if (!cr0.getLT()) goto loc_824084B0;
	// bl 0x8235f2d8
	sub_8235F2D8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// b 0x824084d0
	goto loc_824084D0;
loc_824084B0:
	// lis r11,16384
	r11.s64 = 1073741824;
	// ori r11,r11,37
	r11.u64 = r11.u64 | 37;
	// cmpw cr6,r3,r11
	cr6.compare<int32_t>(ctx.r3.s32, r11.s32, xer);
	// li r3,50
	ctx.r3.s64 = 50;
	// beq cr6,0x824084c8
	if (cr6.getEQ()) goto loc_824084C8;
	// li r3,0
	ctx.r3.s64 = 0;
loc_824084C8:
	// bl 0x8235f2b8
	sub_8235F2B8(ctx, base);
	// li r3,1
	ctx.r3.s64 = 1;
loc_824084D0:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824084E0"))) PPC_WEAK_FUNC(sub_824084E0);
PPC_FUNC_IMPL(__imp__sub_824084E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8235f730
	sub_8235F730(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8240fe4c
	__imp__ExTerminateThread(ctx, base);
}

__attribute__((alias("__imp__sub_82408508"))) PPC_WEAK_FUNC(sub_82408508);
PPC_FUNC_IMPL(__imp__sub_82408508) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x82408538
	if (cr6.getEQ()) goto loc_82408538;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8235f560
	sub_8235F560(ctx, base);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// b 0x8240853c
	goto loc_8240853C;
loc_82408538:
	// li r4,0
	ctx.r4.s64 = 0;
loc_8240853C:
	// cntlzw r11,r31
	r11.u64 = r31.u32 == 0 ? 32 : __builtin_clz(r31.u32);
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// rlwinm r5,r11,27,31,31
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// bl 0x8241025c
	__imp__NtCreateTimer(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82408574
	if (cr0.getLT()) goto loc_82408574;
	// lis r11,16384
	r11.s64 = 1073741824;
	// cmpw cr6,r3,r11
	cr6.compare<int32_t>(ctx.r3.s32, r11.s32, xer);
	// li r3,183
	ctx.r3.s64 = 183;
	// beq cr6,0x82408568
	if (cr6.getEQ()) goto loc_82408568;
	// li r3,0
	ctx.r3.s64 = 0;
loc_82408568:
	// bl 0x8235f2b8
	sub_8235F2B8(ctx, base);
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// b 0x8240857c
	goto loc_8240857C;
loc_82408574:
	// bl 0x8235f2d8
	sub_8235F2D8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240857C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82408590"))) PPC_WEAK_FUNC(sub_82408590);
PPC_FUNC_IMPL(__imp__sub_82408590) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// mr r5,r9
	ctx.r5.u64 = ctx.r9.u64;
	// bl 0x8240fd8c
	__imp__NtDuplicateObject(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x824085bc
	if (cr0.getLT()) goto loc_824085BC;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x824085c4
	goto loc_824085C4;
loc_824085BC:
	// bl 0x8235f2d8
	sub_8235F2D8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_824085C4:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824085D8"))) PPC_WEAK_FUNC(sub_824085D8);
PPC_FUNC_IMPL(__imp__sub_824085D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r10,32767
	ctx.r10.s64 = 2147418112;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// ori r9,r10,65517
	ctx.r9.u64 = ctx.r10.u64 | 65517;
	// lis r10,32767
	ctx.r10.s64 = 2147418112;
	// mullw r11,r11,r9
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r9.s32);
	// ori r10,r10,65475
	ctx.r10.u64 = ctx.r10.u64 | 65475;
	// add r8,r11,r10
	ctx.r8.u64 = r11.u64 + ctx.r10.u64;
	// lis r11,32767
	r11.s64 = 2147418112;
	// mr r6,r10
	ctx.r6.u64 = ctx.r10.u64;
	// ori r11,r11,65535
	r11.u64 = r11.u64 | 65535;
	// divwu r7,r8,r11
	ctx.r7.u32 = ctx.r8.u32 / r11.u32;
	// mullw r10,r7,r11
	ctx.r10.s64 = int64_t(ctx.r7.s32) * int64_t(r11.s32);
	// subf r10,r10,r8
	ctx.r10.s64 = ctx.r8.s64 - ctx.r10.s64;
	// mr r8,r11
	ctx.r8.u64 = r11.u64;
	// mr r7,r11
	ctx.r7.u64 = r11.u64;
	// mullw r9,r10,r9
	ctx.r9.s64 = int64_t(ctx.r10.s32) * int64_t(ctx.r9.s32);
	// stw r10,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r10.u32);
	// add r9,r9,r6
	ctx.r9.u64 = ctx.r9.u64 + ctx.r6.u64;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// divwu r8,r9,r8
	ctx.r8.u32 = ctx.r9.u32 / ctx.r8.u32;
	// addi r11,r11,-14616
	r11.s64 = r11.s64 + -14616;
	// mullw r8,r8,r7
	ctx.r8.s64 = int64_t(ctx.r8.s32) * int64_t(ctx.r7.s32);
	// subf r9,r8,r9
	ctx.r9.s64 = ctx.r9.s64 - ctx.r8.s64;
	// stw r9,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, ctx.r9.u32);
	// rlwinm r9,r9,2,23,29
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0x1FC;
	// lwzx r3,r9,r11
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r9.u32 + r11.u32);
	// stwx r10,r9,r11
	PPC_STORE_U32(ctx.r9.u32 + r11.u32, ctx.r10.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82408648"))) PPC_WEAK_FUNC(sub_82408648);
PPC_FUNC_IMPL(__imp__sub_82408648) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// addi r3,r1,88
	ctx.r3.s64 = ctx.r1.s64 + 88;
	// bl 0x8241028c
	__imp__RtlInitUnicodeString(ctx, base);
	// li r5,1
	ctx.r5.s64 = 1;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8241027c
	__imp__RtlUnicodeStringToAnsiString(ctx, base);
	// mr. r31,r3
	r31.u64 = ctx.r3.u64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bge 0x82408688
	if (!cr0.getLT()) goto loc_82408688;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r11,r11,2334
	r11.s64 = r11.s64 + 2334;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
loc_82408688:
	// lwz r3,84(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// bl 0x8235e140
	sub_8235E140(ctx, base);
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// blt cr6,0x824086a0
	if (cr6.getLT()) goto loc_824086A0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8241026c
	__imp__RtlFreeAnsiString(ctx, base);
loc_824086A0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824086B8"))) PPC_WEAK_FUNC(sub_824086B8);
PPC_FUNC_IMPL(__imp__sub_824086B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-176(r1)
	ea = -176 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// clrlwi r11,r4,31
	r11.u64 = ctx.r4.u32 & 0x1;
	// stw r3,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, ctx.r3.u32);
	// lis r10,-32191
	ctx.r10.s64 = -2109669376;
	// cmplwi cr6,r6,0
	cr6.compare<uint32_t>(ctx.r6.u32, 0, xer);
	// addi r10,r10,-31048
	ctx.r10.s64 = ctx.r10.s64 + -31048;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r10,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, ctx.r10.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// beq cr6,0x8240871c
	if (cr6.getEQ()) goto loc_8240871C;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// cmplwi cr6,r5,15
	cr6.compare<uint32_t>(ctx.r5.u32, 15, xer);
	// ble cr6,0x824086fc
	if (!cr6.getGT()) goto loc_824086FC;
	// li r11,15
	r11.s64 = 15;
loc_824086FC:
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82408720
	if (cr6.getEQ()) goto loc_82408720;
	// mr r4,r6
	ctx.r4.u64 = ctx.r6.u64;
	// addi r3,r1,100
	ctx.r3.s64 = ctx.r1.s64 + 100;
	// rlwinm r5,r11,2,0,29
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// bl 0x823ee498
	sub_823EE498(ctx, base);
	// b 0x82408720
	goto loc_82408720;
loc_8240871C:
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
loc_82408720:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x8240fe3c
	__imp__RtlRaiseException(ctx, base);
	// addi r1,r1,176
	ctx.r1.s64 = ctx.r1.s64 + 176;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82408738"))) PPC_WEAK_FUNC(sub_82408738);
PPC_FUNC_IMPL(__imp__sub_82408738) {
	PPC_FUNC_PROLOGUE();
	// b 0x8241029c
	__imp__KeQuerySystemTime(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_82408740"))) PPC_WEAK_FUNC(sub_82408740);
PPC_FUNC_IMPL(__imp__sub_82408740) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// bl 0x824102ac
	__imp__NtFlushBuffersFile(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt 0x82408764
	if (cr0.getLT()) goto loc_82408764;
	// li r3,1
	ctx.r3.s64 = 1;
	// b 0x8240876c
	goto loc_8240876C;
loc_82408764:
	// bl 0x8235f2d8
	sub_8235F2D8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240876C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82408780"))) PPC_WEAK_FUNC(sub_82408780);
PPC_FUNC_IMPL(__imp__sub_82408780) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x824087b4
	if (cr6.getEQ()) goto loc_824087B4;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x824087b4
	if (cr6.getEQ()) goto loc_824087B4;
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_824087B4:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824087C8"))) PPC_WEAK_FUNC(sub_824087C8);
PPC_FUNC_IMPL(__imp__sub_824087C8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32249
	r11.s64 = -2113470464;
	// li r10,-1
	ctx.r10.s64 = -1;
	// addi r11,r11,22704
	r11.s64 = r11.s64 + 22704;
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824087E0"))) PPC_WEAK_FUNC(sub_824087E0);
PPC_FUNC_IMPL(__imp__sub_824087E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lwz r11,4(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824087f8
	if (cr6.getEQ()) goto loc_824087F8;
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// li r3,1
	ctx.r3.s64 = 1;
	// bnelr cr6
	if (!cr6.getEQ()) return;
loc_824087F8:
	// li r3,0
	ctx.r3.s64 = 0;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82408800"))) PPC_WEAK_FUNC(sub_82408800);
PPC_FUNC_IMPL(__imp__sub_82408800) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// addi r11,r11,22704
	r11.s64 = r11.s64 + 22704;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// beq cr6,0x82408840
	if (cr6.getEQ()) goto loc_82408840;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82408840
	if (cr6.getEQ()) goto loc_82408840;
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_82408840:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82408858"))) PPC_WEAK_FUNC(sub_82408858);
PPC_FUNC_IMPL(__imp__sub_82408858) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r18{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// addi r4,r11,22744
	ctx.r4.s64 = r11.s64 + 22744;
	// li r5,7
	ctx.r5.s64 = 7;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// mr r26,r7
	r26.u64 = ctx.r7.u64;
	// mr r31,r8
	r31.u64 = ctx.r8.u64;
	// li r24,0
	r24.s64 = 0;
	// bl 0x823ee630
	sub_823EE630(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82408a8c
	if (!cr6.getEQ()) goto loc_82408A8C;
	// addi r11,r26,-1
	r11.s64 = r26.s64 + -1;
	// cmplwi cr6,r11,4
	cr6.compare<uint32_t>(r11.u32, 4, xer);
	// bgt cr6,0x82408a74
	if (cr6.getGT()) goto loc_82408A74;
	// lis r12,-32191
	r12.s64 = -2109669376;
	// addi r12,r12,-30528
	r12.s64 = r12.s64 + -30528;
	// rlwinm r0,r11,2,0,29
	r0.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// lwzx r0,r12,r0
	r0.u64 = PPC_LOAD_U32(r12.u32 + r0.u32);
	// mtctr r0
	ctr.u64 = r0.u64;
	// bctr 
	switch (r11.u64) {
	case 0:
		goto loc_824088D4;
	case 1:
		goto loc_824088DC;
	case 2:
		goto loc_824088E4;
	case 3:
		goto loc_824088EC;
	case 4:
		goto loc_824088F4;
	default:
		__builtin_unreachable();
	}
	// lwz r18,-30508(0)
	r18.u64 = PPC_LOAD_U32(-30508);
	// lwz r18,-30500(0)
	r18.u64 = PPC_LOAD_U32(-30500);
	// lwz r18,-30492(0)
	r18.u64 = PPC_LOAD_U32(-30492);
	// lwz r18,-30484(0)
	r18.u64 = PPC_LOAD_U32(-30484);
	// lwz r18,-30476(0)
	r18.u64 = PPC_LOAD_U32(-30476);
loc_824088D4:
	// li r28,2
	r28.s64 = 2;
	// b 0x82408904
	goto loc_82408904;
loc_824088DC:
	// li r28,5
	r28.s64 = 5;
	// b 0x82408904
	goto loc_82408904;
loc_824088E4:
	// li r28,1
	r28.s64 = 1;
	// b 0x82408904
	goto loc_82408904;
loc_824088EC:
	// li r28,3
	r28.s64 = 3;
	// b 0x82408904
	goto loc_82408904;
loc_824088F4:
	// rlwinm r11,r29,0,1,1
	r11.u64 = __builtin_rotateleft64(r29.u32 | (r29.u64 << 32), 0) & 0x40000000;
	// li r28,4
	r28.s64 = 4;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82408a74
	if (cr6.getEQ()) goto loc_82408A74;
loc_82408904:
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// addi r3,r1,104
	ctx.r3.s64 = ctx.r1.s64 + 104;
	// bl 0x8240fbdc
	__imp__RtlInitAnsiString(ctx, base);
	// lhz r11,104(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 104);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// ble cr6,0x82408930
	if (!cr6.getGT()) goto loc_82408930;
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// li r30,1
	r30.s64 = 1;
	// lbz r11,-1(r11)
	r11.u64 = PPC_LOAD_U8(r11.u32 + -1);
	// cmplwi cr6,r11,92
	cr6.compare<uint32_t>(r11.u32, 92, xer);
	// beq cr6,0x82408934
	if (cr6.getEQ()) goto loc_82408934;
loc_82408930:
	// mr r30,r24
	r30.u64 = r24.u64;
loc_82408934:
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// stw r24,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r24.u32);
	// rlwinm r9,r31,0,4,4
	ctx.r9.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0x8000000;
	// rlwimi r10,r31,28,4,4
	ctx.r10.u64 = (__builtin_rotateleft32(r31.u32, 28) & 0x8000000) | (ctx.r10.u64 & 0xFFFFFFFFF7FFFFFF);
	// rlwinm r8,r31,0,3,3
	ctx.r8.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0x10000000;
	// rlwinm r10,r10,31,3,5
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 31) & 0x1C000000;
	// rlwinm r11,r31,0,6,6
	r11.u64 = __builtin_rotateleft64(r31.u32 | (r31.u64 << 32), 0) & 0x2000000;
	// rlwinm r10,r10,0,5,3
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 0) & 0xFFFFFFFFF7FFFFFF;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// not r9,r31
	ctx.r9.u64 = ~r31.u64;
	// rlwinm r10,r10,24,8,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFFFFFF;
	// rlwinm r9,r9,7,26,26
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 7) & 0x20;
	// or r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 | ctx.r8.u64;
	// li r8,64
	ctx.r8.s64 = 64;
	// rlwinm r10,r10,26,6,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 26) & 0x3FFFFFF;
	// or r10,r10,r11
	ctx.r10.u64 = ctx.r10.u64 | r11.u64;
	// stw r8,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, ctx.r8.u32);
	// addi r8,r1,104
	ctx.r8.s64 = ctx.r1.s64 + 104;
	// rlwinm r11,r10,21,11,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 21) & 0x1FFFFF;
	// or r11,r11,r9
	r11.u64 = r11.u64 | ctx.r9.u64;
	// stw r8,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r8.u32);
	// bne cr6,0x82408994
	if (!cr6.getEQ()) goto loc_82408994;
	// ori r11,r11,64
	r11.u64 = r11.u64 | 64;
loc_82408994:
	// oris r4,r29,16
	ctx.r4.u64 = r29.u64 | 1048576;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// mr r9,r27
	ctx.r9.u64 = r27.u64;
	// andi. r8,r31,32679
	ctx.r8.u64 = r31.u64 & 32679;
	cr0.compare<int32_t>(ctx.r8.s32, 0, xer);
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r1,112
	ctx.r6.s64 = ctx.r1.s64 + 112;
	// addi r5,r1,120
	ctx.r5.s64 = ctx.r1.s64 + 120;
	// ori r4,r4,128
	ctx.r4.u64 = ctx.r4.u64 | 128;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x8240fc7c
	__imp__NtCreateFile(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// bge cr6,0x82408a24
	if (!cr6.getLT()) goto loc_82408A24;
	// bl 0x8235f2d8
	sub_8235F2D8(ctx, base);
	// lis r11,-16384
	r11.s64 = -1073741824;
	// ori r11,r11,53
	r11.u64 = r11.u64 | 53;
	// cmpw cr6,r31,r11
	cr6.compare<int32_t>(r31.s32, r11.s32, xer);
	// bne cr6,0x824089f4
	if (!cr6.getEQ()) goto loc_824089F4;
	// li r3,80
	ctx.r3.s64 = 80;
	// bl 0x8235f2b8
	sub_8235F2B8(ctx, base);
	// li r11,-1
	r11.s64 = -1;
	// stw r11,4(r25)
	PPC_STORE_U32(r25.u32 + 4, r11.u32);
	// b 0x82408ab0
	goto loc_82408AB0;
loc_824089F4:
	// lis r11,-16384
	r11.s64 = -1073741824;
	// ori r11,r11,186
	r11.u64 = r11.u64 | 186;
	// cmpw cr6,r31,r11
	cr6.compare<int32_t>(r31.s32, r11.s32, xer);
	// bne cr6,0x82408a80
	if (!cr6.getEQ()) goto loc_82408A80;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// li r3,3
	ctx.r3.s64 = 3;
	// bne cr6,0x82408a14
	if (!cr6.getEQ()) goto loc_82408A14;
	// li r3,5
	ctx.r3.s64 = 5;
loc_82408A14:
	// bl 0x8235f2b8
	sub_8235F2B8(ctx, base);
	// li r11,-1
	r11.s64 = -1;
	// stw r11,4(r25)
	PPC_STORE_U32(r25.u32 + 4, r11.u32);
	// b 0x82408ab0
	goto loc_82408AB0;
loc_82408A24:
	// cmplwi cr6,r26,2
	cr6.compare<uint32_t>(r26.u32, 2, xer);
	// bne cr6,0x82408a4c
	if (!cr6.getEQ()) goto loc_82408A4C;
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// cmplwi cr6,r11,3
	cr6.compare<uint32_t>(r11.u32, 3, xer);
	// beq cr6,0x82408a60
	if (cr6.getEQ()) goto loc_82408A60;
loc_82408A38:
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8235f2b8
	sub_8235F2B8(ctx, base);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,4(r25)
	PPC_STORE_U32(r25.u32 + 4, r11.u32);
	// b 0x82408ab0
	goto loc_82408AB0;
loc_82408A4C:
	// cmplwi cr6,r26,4
	cr6.compare<uint32_t>(r26.u32, 4, xer);
	// bne cr6,0x82408a38
	if (!cr6.getEQ()) goto loc_82408A38;
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x82408a38
	if (!cr6.getEQ()) goto loc_82408A38;
loc_82408A60:
	// li r3,183
	ctx.r3.s64 = 183;
	// bl 0x8235f2b8
	sub_8235F2B8(ctx, base);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// stw r11,4(r25)
	PPC_STORE_U32(r25.u32 + 4, r11.u32);
	// b 0x82408ab0
	goto loc_82408AB0;
loc_82408A74:
	// lis r3,-16384
	ctx.r3.s64 = -1073741824;
	// ori r3,r3,13
	ctx.r3.u64 = ctx.r3.u64 | 13;
	// bl 0x8235f2d8
	sub_8235F2D8(ctx, base);
loc_82408A80:
	// li r11,-1
	r11.s64 = -1;
	// stw r11,4(r25)
	PPC_STORE_U32(r25.u32 + 4, r11.u32);
	// b 0x82408ab0
	goto loc_82408AB0;
loc_82408A8C:
	// li r9,0
	ctx.r9.s64 = 0;
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// mr r7,r26
	ctx.r7.u64 = r26.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r27
	ctx.r5.u64 = r27.u64;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x8235d008
	sub_8235D008(ctx, base);
	// stw r3,4(r25)
	PPC_STORE_U32(r25.u32 + 4, ctx.r3.u32);
loc_82408AB0:
	// lwz r11,4(r25)
	r11.u64 = PPC_LOAD_U32(r25.u32 + 4);
	// cmpwi cr6,r11,-1
	cr6.compare<int32_t>(r11.s32, -1, xer);
	// bne cr6,0x82408ad8
	if (!cr6.getEQ()) goto loc_82408AD8;
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x82408adc
	if (!cr6.getGT()) goto loc_82408ADC;
	// clrlwi r11,r3,16
	r11.u64 = ctx.r3.u32 & 0xFFFF;
	// oris r3,r11,32775
	ctx.r3.u64 = r11.u64 | 2147942400;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed178
	return;
loc_82408AD8:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
loc_82408ADC:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_82408AE8"))) PPC_WEAK_FUNC(sub_82408AE8);
PPC_FUNC_IMPL(__imp__sub_82408AE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed12c
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r25,r6
	r25.u64 = ctx.r6.u64;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// lwz r3,4(r27)
	ctx.r3.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// mr r31,r7
	r31.u64 = ctx.r7.u64;
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// li r30,0
	r30.s64 = 0;
	// bl 0x8235d200
	sub_8235D200(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82408b48
	if (!cr6.getEQ()) goto loc_82408B48;
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// bne cr6,0x82408b64
	if (!cr6.getEQ()) goto loc_82408B64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82408b48
	if (!cr6.getEQ()) goto loc_82408B48;
loc_82408B38:
	// clrlwi r11,r3,16
	r11.u64 = ctx.r3.u32 & 0xFFFF;
	// oris r30,r11,32775
	r30.u64 = r11.u64 | 2147942400;
loc_82408B40:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x82408b58
	if (cr6.getLT()) goto loc_82408B58;
loc_82408B48:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x82408bd8
	if (cr6.getEQ()) goto loc_82408BD8;
	// stw r11,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r11.u32);
loc_82408B58:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed17c
	return;
loc_82408B64:
	// cmplwi cr6,r3,1450
	cr6.compare<uint32_t>(ctx.r3.u32, 1450, xer);
	// bne cr6,0x82408bc8
	if (!cr6.getEQ()) goto loc_82408BC8;
	// lis r26,16
	r26.s64 = 1048576;
loc_82408B70:
	// cmplw cr6,r29,r26
	cr6.compare<uint32_t>(r29.u32, r26.u32, xer);
	// mr r31,r29
	r31.u64 = r29.u64;
	// blt cr6,0x82408b80
	if (cr6.getLT()) goto loc_82408B80;
	// mr r31,r26
	r31.u64 = r26.u64;
loc_82408B80:
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// li r8,0
	ctx.r8.s64 = 0;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x82408b58
	if (cr6.getLT()) goto loc_82408B58;
	// subf r29,r31,r29
	r29.s64 = r29.s64 - r31.s64;
	// add r28,r31,r28
	r28.u64 = r31.u64 + r28.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x82408b70
	if (!cr6.getEQ()) goto loc_82408B70;
	// b 0x82408b40
	goto loc_82408B40;
loc_82408BC8:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bgt cr6,0x82408b38
	if (cr6.getGT()) goto loc_82408B38;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x82408b40
	goto loc_82408B40;
loc_82408BD8:
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// beq cr6,0x82408b58
	if (cr6.getEQ()) goto loc_82408B58;
	// lis r3,-32765
	ctx.r3.s64 = -2147287040;
	// ori r3,r3,30
	ctx.r3.u64 = ctx.r3.u64 | 30;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_82408BF0"))) PPC_WEAK_FUNC(sub_82408BF0);
PPC_FUNC_IMPL(__imp__sub_82408BF0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r30,0
	r30.s64 = 0;
	// lwz r3,4(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// addi r6,r1,80
	ctx.r6.s64 = ctx.r1.s64 + 80;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// mr r31,r7
	r31.u64 = ctx.r7.u64;
	// stw r30,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r30.u32);
	// bl 0x8235e018
	sub_8235E018(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82408c48
	if (!cr6.getEQ()) goto loc_82408C48;
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// cmplwi cr6,r3,997
	cr6.compare<uint32_t>(ctx.r3.u32, 997, xer);
	// bne cr6,0x82408c64
	if (!cr6.getEQ()) goto loc_82408C64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82408c48
	if (!cr6.getEQ()) goto loc_82408C48;
loc_82408C38:
	// clrlwi r11,r3,16
	r11.u64 = ctx.r3.u32 & 0xFFFF;
	// oris r30,r11,32775
	r30.u64 = r11.u64 | 2147942400;
loc_82408C40:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x82408c58
	if (cr6.getLT()) goto loc_82408C58;
loc_82408C48:
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x82408c74
	if (cr6.getEQ()) goto loc_82408C74;
	// stw r11,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r11.u32);
loc_82408C58:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_82408C64:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bgt cr6,0x82408c38
	if (cr6.getGT()) goto loc_82408C38;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x82408c40
	goto loc_82408C40;
loc_82408C74:
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// beq cr6,0x82408c58
	if (cr6.getEQ()) goto loc_82408C58;
	// lis r3,-32765
	ctx.r3.s64 = -2147287040;
	// ori r3,r3,29
	ctx.r3.u64 = ctx.r3.u64 | 29;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_82408C90"))) PPC_WEAK_FUNC(sub_82408C90);
PPC_FUNC_IMPL(__imp__sub_82408C90) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// lwz r3,4(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// mr r6,r5
	ctx.r6.u64 = ctx.r5.u64;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r31,0
	r31.s64 = 0;
	// bl 0x8235ed68
	sub_8235ED68(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,-1
	cr6.compare<int32_t>(r30.s32, -1, xer);
	// bne cr6,0x82408ce4
	if (!cr6.getEQ()) goto loc_82408CE4;
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bgt cr6,0x82408cd4
	if (cr6.getGT()) goto loc_82408CD4;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// b 0x82408cdc
	goto loc_82408CDC;
loc_82408CD4:
	// clrlwi r11,r3,16
	r11.u64 = ctx.r3.u32 & 0xFFFF;
	// oris r31,r11,32775
	r31.u64 = r11.u64 | 2147942400;
loc_82408CDC:
	// cmpwi cr6,r31,0
	cr6.compare<int32_t>(r31.s32, 0, xer);
	// blt cr6,0x82408cfc
	if (cr6.getLT()) goto loc_82408CFC;
loc_82408CE4:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// beq cr6,0x82408d00
	if (cr6.getEQ()) goto loc_82408D00;
	// stw r30,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r30.u32);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
loc_82408CFC:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82408D00:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82408D08"))) PPC_WEAK_FUNC(sub_82408D08);
PPC_FUNC_IMPL(__imp__sub_82408D08) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r3,4(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r31,0
	r31.s64 = 0;
	// bl 0x8235ecc0
	sub_8235ECC0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne cr6,0x82408d54
	if (!cr6.getEQ()) goto loc_82408D54;
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x82408d58
	if (!cr6.getGT()) goto loc_82408D58;
	// clrlwi r11,r3,16
	r11.u64 = ctx.r3.u32 & 0xFFFF;
	// oris r3,r11,32775
	ctx.r3.u64 = r11.u64 | 2147942400;
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
loc_82408D54:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
loc_82408D58:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82408D70"))) PPC_WEAK_FUNC(sub_82408D70);
PPC_FUNC_IMPL(__imp__sub_82408D70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// lwz r3,4(r3)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// li r4,0
	ctx.r4.s64 = 0;
	// li r30,0
	r30.s64 = 0;
	// bl 0x8235d468
	sub_8235D468(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// stw r3,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r3.u32);
	// bne cr6,0x82408dbc
	if (!cr6.getEQ()) goto loc_82408DBC;
	// bl 0x8235df68
	sub_8235DF68(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// ble cr6,0x82408dc0
	if (!cr6.getGT()) goto loc_82408DC0;
	// clrlwi r11,r3,16
	r11.u64 = ctx.r3.u32 & 0xFFFF;
	// oris r3,r11,32775
	ctx.r3.u64 = r11.u64 | 2147942400;
	// b 0x82408dc0
	goto loc_82408DC0;
loc_82408DBC:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_82408DC0:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82408DD8"))) PPC_WEAK_FUNC(sub_82408DD8);
PPC_FUNC_IMPL(__imp__sub_82408DD8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// addi r11,r11,22704
	r11.s64 = r11.s64 + 22704;
	// lwz r3,4(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// beq cr6,0x82408e20
	if (cr6.getEQ()) goto loc_82408E20;
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x82408e20
	if (cr6.getEQ()) goto loc_82408E20;
	// bl 0x8235d388
	sub_8235D388(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
loc_82408E20:
	// clrlwi r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82408e40
	if (cr6.getEQ()) goto loc_82408E40;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lis r5,24962
	ctx.r5.s64 = 1635909632;
	// addi r3,r11,-5060
	ctx.r3.s64 = r11.s64 + -5060;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// bl 0x82369440
	sub_82369440(ctx, base);
loc_82408E40:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82408E60"))) PPC_WEAK_FUNC(sub_82408E60);
PPC_FUNC_IMPL(__imp__sub_82408E60) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// add r10,r4,r30
	ctx.r10.u64 = ctx.r4.u64 + r30.u64;
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// lwz r11,20(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 20);
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// ble cr6,0x82408ea8
	if (!cr6.getGT()) goto loc_82408EA8;
	// cmplw cr6,r4,r11
	cr6.compare<uint32_t>(ctx.r4.u32, r11.u32, xer);
	// li r30,0
	r30.s64 = 0;
	// bge cr6,0x82408e9c
	if (!cr6.getLT()) goto loc_82408E9C;
	// subf r30,r4,r11
	r30.s64 = r11.s64 - ctx.r4.s64;
loc_82408E9C:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x82408f04
	if (cr6.getEQ()) goto loc_82408F04;
	// stw r30,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r30.u32);
loc_82408EA8:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// li r5,0
	ctx.r5.s64 = 0;
	// add r4,r11,r4
	ctx.r4.u64 = r11.u64 + ctx.r4.u64;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82408efc
	if (cr6.getLT()) goto loc_82408EFC;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
loc_82408EFC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_82408F04:
	// lis r3,-28655
	ctx.r3.s64 = -1877934080;
	// ori r3,r3,1
	ctx.r3.u64 = ctx.r3.u64 | 1;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_82408F18"))) PPC_WEAK_FUNC(sub_82408F18);
PPC_FUNC_IMPL(__imp__sub_82408F18) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r9,-1
	ctx.r9.s64 = -1;
	// addi r10,r11,532
	ctx.r10.s64 = r11.s64 + 532;
	// li r11,0
	r11.s64 = 0;
	// stw r10,4(r3)
	PPC_STORE_U32(ctx.r3.u32 + 4, ctx.r10.u32);
	// stw r11,8(r3)
	PPC_STORE_U32(ctx.r3.u32 + 8, r11.u32);
	// stw r11,12(r3)
	PPC_STORE_U32(ctx.r3.u32 + 12, r11.u32);
	// stw r11,16(r3)
	PPC_STORE_U32(ctx.r3.u32 + 16, r11.u32);
	// stw r11,20(r3)
	PPC_STORE_U32(ctx.r3.u32 + 20, r11.u32);
	// stw r11,24(r3)
	PPC_STORE_U32(ctx.r3.u32 + 24, r11.u32);
	// stw r11,28(r3)
	PPC_STORE_U32(ctx.r3.u32 + 28, r11.u32);
	// stw r10,32(r3)
	PPC_STORE_U32(ctx.r3.u32 + 32, ctx.r10.u32);
	// stw r11,36(r3)
	PPC_STORE_U32(ctx.r3.u32 + 36, r11.u32);
	// stw r11,40(r3)
	PPC_STORE_U32(ctx.r3.u32 + 40, r11.u32);
	// stw r11,44(r3)
	PPC_STORE_U32(ctx.r3.u32 + 44, r11.u32);
	// stw r11,48(r3)
	PPC_STORE_U32(ctx.r3.u32 + 48, r11.u32);
	// stw r11,52(r3)
	PPC_STORE_U32(ctx.r3.u32 + 52, r11.u32);
	// stw r11,56(r3)
	PPC_STORE_U32(ctx.r3.u32 + 56, r11.u32);
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// stw r9,60(r3)
	PPC_STORE_U32(ctx.r3.u32 + 60, ctx.r9.u32);
	// stw r11,64(r3)
	PPC_STORE_U32(ctx.r3.u32 + 64, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82408F70"))) PPC_WEAK_FUNC(sub_82408F70);
PPC_FUNC_IMPL(__imp__sub_82408F70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// lwz r4,64(r3)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r3.u32 + 64);
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// lhz r11,16(r4)
	r11.u64 = PPC_LOAD_U16(ctx.r4.u32 + 16);
	// addi r31,r11,18
	r31.s64 = r11.s64 + 18;
	// beq cr6,0x82408fd0
	if (cr6.getEQ()) goto loc_82408FD0;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82408fd0
	if (cr6.getEQ()) goto loc_82408FD0;
	// cmplw cr6,r30,r31
	cr6.compare<uint32_t>(r30.u32, r31.u32, xer);
	// blt cr6,0x82408fb0
	if (cr6.getLT()) goto loc_82408FB0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
loc_82408FB0:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// cmplw cr6,r30,r31
	cr6.compare<uint32_t>(r30.u32, r31.u32, xer);
	// ble cr6,0x82408fd0
	if (!cr6.getGT()) goto loc_82408FD0;
	// subf r5,r31,r30
	ctx.r5.s64 = r30.s64 - r31.s64;
	// li r4,0
	ctx.r4.s64 = 0;
	// add r3,r31,r29
	ctx.r3.u64 = r31.u64 + r29.u64;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
loc_82408FD0:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// beq cr6,0x82408fe0
	if (cr6.getEQ()) goto loc_82408FE0;
	// stw r31,0(r28)
	PPC_STORE_U32(r28.u32 + 0, r31.u32);
loc_82408FE0:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_82408FE8"))) PPC_WEAK_FUNC(sub_82408FE8);
PPC_FUNC_IMPL(__imp__sub_82408FE8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// li r30,0
	r30.s64 = 0;
	// lwz r3,0(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x82409024
	if (cr6.getEQ()) goto loc_82409024;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,4(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// stw r30,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r30.u32);
loc_82409024:
	// lwz r4,64(r31)
	ctx.r4.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x82409044
	if (cr6.getEQ()) goto loc_82409044;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lis r5,24962
	ctx.r5.s64 = 1635909632;
	// addi r3,r11,-5060
	ctx.r3.s64 = r11.s64 + -5060;
	// bl 0x82369440
	sub_82369440(ctx, base);
	// stw r30,64(r31)
	PPC_STORE_U32(r31.u32 + 64, r30.u32);
loc_82409044:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_82409060"))) PPC_WEAK_FUNC(sub_82409060);
PPC_FUNC_IMPL(__imp__sub_82409060) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// bl 0x82408fe8
	sub_82408FE8(ctx, base);
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r11,r11,532
	r11.s64 = r11.s64 + 532;
	// stw r11,32(r31)
	PPC_STORE_U32(r31.u32 + 32, r11.u32);
	// stw r11,4(r31)
	PPC_STORE_U32(r31.u32 + 4, r11.u32);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824090A0"))) PPC_WEAK_FUNC(sub_824090A0);
PPC_FUNC_IMPL(__imp__sub_824090A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// li r30,0
	r30.s64 = 0;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r28,r6
	r28.u64 = ctx.r6.u64;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// std r30,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r30.u64);
	// lis r11,19794
	r11.s64 = 1297219584;
	// stw r4,4(r31)
	PPC_STORE_U32(r31.u32 + 4, ctx.r4.u32);
	// stw r5,8(r31)
	PPC_STORE_U32(r31.u32 + 8, ctx.r5.u32);
	// ori r29,r11,20294
	r29.u64 = r11.u64 | 20294;
	// beq cr6,0x824090fc
	if (cr6.getEQ()) goto loc_824090FC;
	// lis r10,17990
	ctx.r10.s64 = 1178992640;
	// lwz r11,12(r4)
	r11.u64 = PPC_LOAD_U32(ctx.r4.u32 + 12);
	// lwz r30,16(r4)
	r30.u64 = PPC_LOAD_U32(ctx.r4.u32 + 16);
	// ori r10,r10,18770
	ctx.r10.u64 = ctx.r10.u64 | 18770;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824090f8
	if (cr6.getEQ()) goto loc_824090F8;
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// bne cr6,0x824090fc
	if (!cr6.getEQ()) goto loc_824090FC;
loc_824090F8:
	// addi r30,r30,4
	r30.s64 = r30.s64 + 4;
loc_824090FC:
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,20(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 20);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x8240921c
	if (cr6.getLT()) goto loc_8240921C;
	// lwz r3,8(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 8);
	// li r8,1
	ctx.r8.s64 = 1;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,8
	ctx.r5.s64 = 8;
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// mtctr r11
	ctr.u64 = r11.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x8240921c
	if (cr6.getLT()) goto loc_8240921C;
	// lwz r9,4(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 4);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x8240918c
	if (cr6.getEQ()) goto loc_8240918C;
	// lwz r11,12(r9)
	r11.u64 = PPC_LOAD_U32(ctx.r9.u32 + 12);
	// cmplw cr6,r11,r29
	cr6.compare<uint32_t>(r11.u32, r29.u32, xer);
	// bne cr6,0x8240918c
	if (!cr6.getEQ()) goto loc_8240918C;
	// lbz r10,83(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 83);
	// lbz r11,80(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// stb r10,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r10.u8);
	// lbz r10,82(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 82);
	// stb r11,83(r1)
	PPC_STORE_U8(ctx.r1.u32 + 83, r11.u8);
	// lbz r11,81(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 81);
	// stb r10,81(r1)
	PPC_STORE_U8(ctx.r1.u32 + 81, ctx.r10.u8);
	// b 0x824091c8
	goto loc_824091C8;
loc_8240918C:
	// lbz r8,83(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 83);
	// lbz r11,80(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 80);
	// lbz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 84);
	// stb r8,80(r1)
	PPC_STORE_U8(ctx.r1.u32 + 80, ctx.r8.u8);
	// lbz r8,87(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 87);
	// stb r11,83(r1)
	PPC_STORE_U8(ctx.r1.u32 + 83, r11.u8);
	// lbz r11,81(r1)
	r11.u64 = PPC_LOAD_U8(ctx.r1.u32 + 81);
	// stb r10,87(r1)
	PPC_STORE_U8(ctx.r1.u32 + 87, ctx.r10.u8);
	// lbz r10,85(r1)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r1.u32 + 85);
	// stb r8,84(r1)
	PPC_STORE_U8(ctx.r1.u32 + 84, ctx.r8.u8);
	// lbz r8,82(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 82);
	// stb r8,81(r1)
	PPC_STORE_U8(ctx.r1.u32 + 81, ctx.r8.u8);
	// lbz r8,86(r1)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r1.u32 + 86);
	// stb r10,86(r1)
	PPC_STORE_U8(ctx.r1.u32 + 86, ctx.r10.u8);
	// stb r8,85(r1)
	PPC_STORE_U8(ctx.r1.u32 + 85, ctx.r8.u8);
loc_824091C8:
	// stb r11,82(r1)
	PPC_STORE_U8(ctx.r1.u32 + 82, r11.u8);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r28,r11
	cr6.compare<uint32_t>(r28.u32, r11.u32, xer);
	// beq cr6,0x824091fc
	if (cr6.getEQ()) goto loc_824091FC;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x824091f0
	if (cr6.getEQ()) goto loc_824091F0;
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// add r11,r11,r30
	r11.u64 = r11.u64 + r30.u64;
	// addi r30,r11,8
	r30.s64 = r11.s64 + 8;
	// b 0x824090fc
	goto loc_824090FC;
loc_824091F0:
	// lis r3,-28655
	ctx.r3.s64 = -1877934080;
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
loc_824091FC:
	// lwz r11,24(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 24);
	// addi r10,r30,8
	ctx.r10.s64 = r30.s64 + 8;
	// lwz r9,84(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// ori r11,r11,1
	r11.u64 = r11.u64 | 1;
	// stw r28,12(r31)
	PPC_STORE_U32(r31.u32 + 12, r28.u32);
	// stw r10,16(r31)
	PPC_STORE_U32(r31.u32 + 16, ctx.r10.u32);
	// stw r9,20(r31)
	PPC_STORE_U32(r31.u32 + 20, ctx.r9.u32);
	// stw r11,24(r31)
	PPC_STORE_U32(r31.u32 + 24, r11.u32);
loc_8240921C:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_82409228"))) PPC_WEAK_FUNC(sub_82409228);
PPC_FUNC_IMPL(__imp__sub_82409228) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// mr r27,r6
	r27.u64 = ctx.r6.u64;
	// addi r11,r11,532
	r11.s64 = r11.s64 + 532;
	// lis r6,8308
	ctx.r6.s64 = 544473088;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// lwz r5,0(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r4,r3,4
	ctx.r4.s64 = ctx.r3.s64 + 4;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// li r11,0
	r11.s64 = 0;
	// ori r6,r6,28006
	ctx.r6.u64 = ctx.r6.u64 | 28006;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// bl 0x824090a0
	sub_824090A0(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// blt cr6,0x824093ac
	if (cr6.getLT()) goto loc_824093AC;
	// lwz r28,100(r1)
	r28.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82409390
	if (cr6.getEQ()) goto loc_82409390;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82409390
	if (cr6.getEQ()) goto loc_82409390;
	// cmplw cr6,r28,r30
	cr6.compare<uint32_t>(r28.u32, r30.u32, xer);
	// mr r6,r28
	ctx.r6.u64 = r28.u64;
	// blt cr6,0x824092b0
	if (cr6.getLT()) goto loc_824092B0;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
loc_824092B0:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82408e60
	sub_82408E60(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// blt cr6,0x824093ac
	if (cr6.getLT()) goto loc_824093AC;
	// cmplw cr6,r30,r28
	cr6.compare<uint32_t>(r30.u32, r28.u32, xer);
	// ble cr6,0x824092e8
	if (!cr6.getGT()) goto loc_824092E8;
	// subf r5,r28,r30
	ctx.r5.s64 = r30.s64 - r28.s64;
	// li r4,0
	ctx.r4.s64 = 0;
	// add r3,r28,r31
	ctx.r3.u64 = r28.u64 + r31.u64;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
loc_824092E8:
	// lbz r4,1(r31)
	ctx.r4.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// addi r9,r31,2
	ctx.r9.s64 = r31.s64 + 2;
	// lbz r5,0(r31)
	ctx.r5.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// addi r11,r31,4
	r11.s64 = r31.s64 + 4;
	// addi r10,r31,8
	ctx.r10.s64 = r31.s64 + 8;
	// addi r8,r31,12
	ctx.r8.s64 = r31.s64 + 12;
	// addi r7,r31,14
	ctx.r7.s64 = r31.s64 + 14;
	// stb r4,0(r31)
	PPC_STORE_U8(r31.u32 + 0, ctx.r4.u8);
	// addi r6,r31,16
	ctx.r6.s64 = r31.s64 + 16;
	// stb r5,1(r31)
	PPC_STORE_U8(r31.u32 + 1, ctx.r5.u8);
	// lbz r4,1(r9)
	ctx.r4.u64 = PPC_LOAD_U8(ctx.r9.u32 + 1);
	// lbz r5,0(r9)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// stb r4,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r4.u8);
	// stb r5,1(r9)
	PPC_STORE_U8(ctx.r9.u32 + 1, ctx.r5.u8);
	// lbz r5,3(r11)
	ctx.r5.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// stb r5,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r5.u8);
	// stb r9,3(r11)
	PPC_STORE_U8(r11.u32 + 3, ctx.r9.u8);
	// lbz r5,2(r11)
	ctx.r5.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// lbz r9,1(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// stb r5,1(r11)
	PPC_STORE_U8(r11.u32 + 1, ctx.r5.u8);
	// stb r9,2(r11)
	PPC_STORE_U8(r11.u32 + 2, ctx.r9.u8);
	// lbz r9,3(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// stb r9,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r9.u8);
	// lbz r9,2(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 2);
	// stb r11,3(r10)
	PPC_STORE_U8(ctx.r10.u32 + 3, r11.u8);
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// stb r9,1(r10)
	PPC_STORE_U8(ctx.r10.u32 + 1, ctx.r9.u8);
	// stb r11,2(r10)
	PPC_STORE_U8(ctx.r10.u32 + 2, r11.u8);
	// lbz r10,1(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 1);
	// lbz r11,0(r8)
	r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// stb r10,0(r8)
	PPC_STORE_U8(ctx.r8.u32 + 0, ctx.r10.u8);
	// stb r11,1(r8)
	PPC_STORE_U8(ctx.r8.u32 + 1, r11.u8);
	// lbz r10,1(r7)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r7.u32 + 1);
	// lbz r11,0(r7)
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 0);
	// stb r10,0(r7)
	PPC_STORE_U8(ctx.r7.u32 + 0, ctx.r10.u8);
	// stb r11,1(r7)
	PPC_STORE_U8(ctx.r7.u32 + 1, r11.u8);
	// lbz r10,1(r6)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r6.u32 + 1);
	// lbz r11,0(r6)
	r11.u64 = PPC_LOAD_U8(ctx.r6.u32 + 0);
	// stb r10,0(r6)
	PPC_STORE_U8(ctx.r6.u32 + 0, ctx.r10.u8);
	// stb r11,1(r6)
	PPC_STORE_U8(ctx.r6.u32 + 1, r11.u8);
loc_82409390:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x824093ac
	if (cr6.getEQ()) goto loc_824093AC;
	// cmplwi cr6,r28,18
	cr6.compare<uint32_t>(r28.u32, 18, xer);
	// mr r11,r28
	r11.u64 = r28.u64;
	// bgt cr6,0x824093a8
	if (cr6.getGT()) goto loc_824093A8;
	// li r11,18
	r11.s64 = 18;
loc_824093A8:
	// stw r11,0(r27)
	PPC_STORE_U32(r27.u32 + 0, r11.u32);
loc_824093AC:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_824093B8"))) PPC_WEAK_FUNC(sub_824093B8);
PPC_FUNC_IMPL(__imp__sub_824093B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed130
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r31,0
	r31.s64 = 0;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// mr r28,r4
	r28.u64 = ctx.r4.u64;
	// addi r10,r10,532
	ctx.r10.s64 = ctx.r10.s64 + 532;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// stw r31,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r31.u32);
	// std r31,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r31.u64);
	// mr r26,r6
	r26.u64 = ctx.r6.u64;
	// std r31,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r31.u64);
	// mr r27,r31
	r27.u64 = r31.u64;
	// stw r31,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r31.u32);
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// stw r31,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r31.u32);
	// stw r31,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r31.u32);
	// stw r31,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r31.u32);
	// stw r31,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r31.u32);
	// stw r31,16(r11)
	PPC_STORE_U32(r11.u32 + 16, r31.u32);
	// beq cr6,0x82409544
	if (cr6.getEQ()) goto loc_82409544;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// beq cr6,0x82409544
	if (cr6.getEQ()) goto loc_82409544;
	// lis r6,19789
	ctx.r6.s64 = 1296891904;
	// lwz r5,0(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r4,r3,4
	ctx.r4.s64 = ctx.r3.s64 + 4;
	// ori r6,r6,20291
	ctx.r6.u64 = ctx.r6.u64 | 20291;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x824090a0
	sub_824090A0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82409564
	if (cr6.getLT()) goto loc_82409564;
	// lwz r29,132(r1)
	r29.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// li r6,20
	ctx.r6.s64 = 20;
	// cmplwi cr6,r29,20
	cr6.compare<uint32_t>(r29.u32, 20, xer);
	// bgt cr6,0x82409450
	if (cr6.getGT()) goto loc_82409450;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
loc_82409450:
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82408e60
	sub_82408E60(ctx, base);
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// blt cr6,0x82409560
	if (cr6.getLT()) goto loc_82409560;
	// cmplwi cr6,r29,20
	cr6.compare<uint32_t>(r29.u32, 20, xer);
	// bge cr6,0x8240948c
	if (!cr6.getLT()) goto loc_8240948C;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// subfic r5,r29,20
	xer.ca = r29.u32 <= 20;
	ctx.r5.s64 = 20 - r29.s64;
	// li r4,0
	ctx.r4.s64 = 0;
	// add r3,r29,r11
	ctx.r3.u64 = r29.u64 + r11.u64;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
loc_8240948C:
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824094b8
	if (cr6.getEQ()) goto loc_824094B8;
	// lis r10,17742
	ctx.r10.s64 = 1162739712;
	// ori r10,r10,20302
	ctx.r10.u64 = ctx.r10.u64 | 20302;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x824094b8
	if (cr6.getEQ()) goto loc_824094B8;
	// lis r3,-28655
	ctx.r3.s64 = -1877934080;
	// ori r3,r3,2
	ctx.r3.u64 = ctx.r3.u64 | 2;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed180
	return;
loc_824094B8:
	// lhz r11,88(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 88);
	// li r5,1
	ctx.r5.s64 = 1;
	// lwz r9,90(r1)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r1.u32 + 90);
	// cmplwi cr6,r30,18
	cr6.compare<uint32_t>(r30.u32, 18, xer);
	// clrlwi r11,r11,17
	r11.u64 = r11.u32 & 0x7FFF;
	// lhz r10,86(r1)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r1.u32 + 86);
	// sth r31,96(r1)
	PPC_STORE_U16(ctx.r1.u32 + 96, r31.u16);
	// subfic r8,r11,16414
	xer.ca = r11.u32 <= 16414;
	ctx.r8.s64 = 16414 - r11.s64;
	// lhz r11,80(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 80);
	// mr r6,r10
	ctx.r6.u64 = ctx.r10.u64;
	// sth r5,80(r1)
	PPC_STORE_U16(ctx.r1.u32 + 80, ctx.r5.u16);
	// mr r7,r11
	ctx.r7.u64 = r11.u64;
	// sth r10,94(r1)
	PPC_STORE_U16(ctx.r1.u32 + 94, ctx.r10.u16);
	// li r5,18
	ctx.r5.s64 = 18;
	// mullw r7,r7,r6
	ctx.r7.s64 = int64_t(ctx.r7.s32) * int64_t(ctx.r6.s32);
	// sth r11,82(r1)
	PPC_STORE_U16(ctx.r1.u32 + 82, r11.u16);
	// srawi r7,r7,3
	xer.ca = (ctx.r7.s32 < 0) & ((ctx.r7.u32 & 0x7) != 0);
	ctx.r7.s64 = ctx.r7.s32 >> 3;
	// addze r10,r7
	temp.s64 = ctx.r7.s64 + xer.ca;
	xer.ca = temp.u32 < ctx.r7.u32;
	ctx.r10.s64 = temp.s64;
	// srw r11,r9,r8
	r11.u64 = ctx.r8.u8 & 0x20 ? 0 : (ctx.r9.u32 >> (ctx.r8.u8 & 0x3F));
	// clrlwi r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// mullw r11,r10,r11
	r11.s64 = int64_t(ctx.r10.s32) * int64_t(r11.s32);
	// sth r10,92(r1)
	PPC_STORE_U16(ctx.r1.u32 + 92, ctx.r10.u16);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// bgt cr6,0x82409520
	if (cr6.getGT()) goto loc_82409520;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
loc_82409520:
	// addi r4,r1,80
	ctx.r4.s64 = ctx.r1.s64 + 80;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// cmplwi cr6,r30,18
	cr6.compare<uint32_t>(r30.u32, 18, xer);
	// ble cr6,0x82409544
	if (!cr6.getGT()) goto loc_82409544;
	// addi r5,r30,-18
	ctx.r5.s64 = r30.s64 + -18;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r28,18
	ctx.r3.s64 = r28.s64 + 18;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
loc_82409544:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// beq cr6,0x82409564
	if (cr6.getEQ()) goto loc_82409564;
	// li r11,18
	r11.s64 = 18;
	// stw r11,0(r26)
	PPC_STORE_U32(r26.u32 + 0, r11.u32);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed180
	return;
loc_82409560:
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
loc_82409564:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed180
	return;
}

__attribute__((alias("__imp__sub_82409570"))) PPC_WEAK_FUNC(sub_82409570);
PPC_FUNC_IMPL(__imp__sub_82409570) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// lwz r5,0(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lis r6,12865
	ctx.r6.s64 = 843120640;
	// addi r11,r11,532
	r11.s64 = r11.s64 + 532;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// addi r4,r3,4
	ctx.r4.s64 = ctx.r3.s64 + 4;
	// ori r6,r6,19800
	ctx.r6.u64 = ctx.r6.u64 | 19800;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// bl 0x824090a0
	sub_824090A0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x824095d4
	if (cr6.getLT()) goto loc_824095D4;
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_824095D4:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824095E8"))) PPC_WEAK_FUNC(sub_824095E8);
PPC_FUNC_IMPL(__imp__sub_824095E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r31,0
	r31.s64 = 0;
	// addi r11,r11,532
	r11.s64 = r11.s64 + 532;
	// lis r6,12865
	ctx.r6.s64 = 843120640;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r5,0(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r4,r3,4
	ctx.r4.s64 = ctx.r3.s64 + 4;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// ori r6,r6,19800
	ctx.r6.u64 = ctx.r6.u64 | 19800;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r31,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r31.u32);
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// stw r31,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r31.u32);
	// stw r31,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r31.u32);
	// stw r31,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r31.u32);
	// bl 0x824090a0
	sub_824090A0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82409660
	if (cr6.getLT()) goto loc_82409660;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82408e60
	sub_82408E60(ctx, base);
loc_82409660:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82409668"))) PPC_WEAK_FUNC(sub_82409668);
PPC_FUNC_IMPL(__imp__sub_82409668) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// lwz r5,0(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// lis r6,27493
	ctx.r6.s64 = 1801781248;
	// addi r11,r11,532
	r11.s64 = r11.s64 + 532;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// addi r4,r3,4
	ctx.r4.s64 = ctx.r3.s64 + 4;
	// ori r6,r6,25971
	ctx.r6.u64 = ctx.r6.u64 | 25971;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// li r11,0
	r11.s64 = 0;
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// bl 0x824090a0
	sub_824090A0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x824096cc
	if (cr6.getLT()) goto loc_824096CC;
	// lwz r11,100(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_824096CC:
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_824096E0"))) PPC_WEAK_FUNC(sub_824096E0);
PPC_FUNC_IMPL(__imp__sub_824096E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r31,0
	r31.s64 = 0;
	// addi r11,r11,532
	r11.s64 = r11.s64 + 532;
	// lis r6,27493
	ctx.r6.s64 = 1801781248;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r5,0(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r4,r3,4
	ctx.r4.s64 = ctx.r3.s64 + 4;
	// stw r31,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r31.u32);
	// ori r6,r6,25971
	ctx.r6.u64 = ctx.r6.u64 | 25971;
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r31,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r31.u32);
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// stw r31,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r31.u32);
	// stw r31,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r31.u32);
	// stw r31,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r31.u32);
	// bl 0x824090a0
	sub_824090A0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82409758
	if (cr6.getLT()) goto loc_82409758;
	// addi r7,r1,80
	ctx.r7.s64 = ctx.r1.s64 + 80;
	// stw r31,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r31.u32);
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82408e60
	sub_82408E60(ctx, base);
loc_82409758:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_82409760"))) PPC_WEAK_FUNC(sub_82409760);
PPC_FUNC_IMPL(__imp__sub_82409760) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed124
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// li r29,0
	r29.s64 = 0;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// addi r10,r10,532
	ctx.r10.s64 = ctx.r10.s64 + 532;
	// lis r6,28781
	ctx.r6.s64 = 1886191616;
	// mr r24,r4
	r24.u64 = ctx.r4.u64;
	// mr r23,r5
	r23.u64 = ctx.r5.u64;
	// lwz r5,0(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// addi r4,r3,4
	ctx.r4.s64 = ctx.r3.s64 + 4;
	// std r29,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r29.u64);
	// ori r6,r6,29559
	ctx.r6.u64 = ctx.r6.u64 | 29559;
	// std r29,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r29.u64);
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// stw r10,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, ctx.r10.u32);
	// stw r29,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r29.u32);
	// stw r29,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r29.u32);
	// stw r29,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r29.u32);
	// stw r29,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r29.u32);
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r29.u32);
	// stw r29,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r29.u32);
	// bl 0x824090a0
	sub_824090A0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82409a10
	if (cr6.getLT()) goto loc_82409A10;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lwz r30,116(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// lis r5,24962
	ctx.r5.s64 = 1635909632;
	// addi r25,r11,-5060
	r25.s64 = r11.s64 + -5060;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82369430
	sub_82369430(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x824097fc
	if (!cr6.getEQ()) goto loc_824097FC;
	// lis r26,-32761
	r26.s64 = -2147024896;
	// ori r26,r26,14
	r26.u64 = r26.u64 | 14;
	// b 0x824099f4
	goto loc_824099F4;
loc_824097FC:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,96
	ctx.r3.s64 = ctx.r1.s64 + 96;
	// bl 0x82408e60
	sub_82408E60(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// blt cr6,0x824099f4
	if (cr6.getLT()) goto loc_824099F4;
	// lbz r7,3(r31)
	ctx.r7.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// addi r9,r31,4
	ctx.r9.s64 = r31.s64 + 4;
	// lbz r6,0(r31)
	ctx.r6.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// addi r8,r31,6
	ctx.r8.s64 = r31.s64 + 6;
	// addi r11,r31,8
	r11.s64 = r31.s64 + 8;
	// addi r10,r31,12
	ctx.r10.s64 = r31.s64 + 12;
	// addi r30,r31,16
	r30.s64 = r31.s64 + 16;
	// stb r7,0(r31)
	PPC_STORE_U8(r31.u32 + 0, ctx.r7.u8);
	// mr r7,r29
	ctx.r7.u64 = r29.u64;
	// stb r6,3(r31)
	PPC_STORE_U8(r31.u32 + 3, ctx.r6.u8);
	// lbz r5,2(r31)
	ctx.r5.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// lbz r6,1(r31)
	ctx.r6.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// stb r5,1(r31)
	PPC_STORE_U8(r31.u32 + 1, ctx.r5.u8);
	// stb r6,2(r31)
	PPC_STORE_U8(r31.u32 + 2, ctx.r6.u8);
	// lbz r5,1(r9)
	ctx.r5.u64 = PPC_LOAD_U8(ctx.r9.u32 + 1);
	// lbz r6,0(r9)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// stb r5,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r5.u8);
	// stb r6,1(r9)
	PPC_STORE_U8(ctx.r9.u32 + 1, ctx.r6.u8);
	// lbz r6,1(r8)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r8.u32 + 1);
	// lbz r9,0(r8)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// stb r6,0(r8)
	PPC_STORE_U8(ctx.r8.u32 + 0, ctx.r6.u8);
	// stb r9,1(r8)
	PPC_STORE_U8(ctx.r8.u32 + 1, ctx.r9.u8);
	// lbz r8,3(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// stb r8,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r8.u8);
	// lbz r8,2(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// stb r9,3(r11)
	PPC_STORE_U8(r11.u32 + 3, ctx.r9.u8);
	// lbz r9,1(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// stb r8,1(r11)
	PPC_STORE_U8(r11.u32 + 1, ctx.r8.u8);
	// stb r9,2(r11)
	PPC_STORE_U8(r11.u32 + 2, ctx.r9.u8);
	// lbz r9,3(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// stb r9,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r9.u8);
	// lbz r9,2(r10)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r10.u32 + 2);
	// stb r11,3(r10)
	PPC_STORE_U8(ctx.r10.u32 + 3, r11.u8);
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// stb r9,1(r10)
	PPC_STORE_U8(ctx.r10.u32 + 1, ctx.r9.u8);
	// stb r11,2(r10)
	PPC_STORE_U8(ctx.r10.u32 + 2, r11.u8);
	// lbz r10,3(r30)
	ctx.r10.u64 = PPC_LOAD_U8(r30.u32 + 3);
	// lbz r11,0(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// stb r10,0(r30)
	PPC_STORE_U8(r30.u32 + 0, ctx.r10.u8);
	// lbz r10,2(r30)
	ctx.r10.u64 = PPC_LOAD_U8(r30.u32 + 2);
	// stb r11,3(r30)
	PPC_STORE_U8(r30.u32 + 3, r11.u8);
	// lbz r11,1(r30)
	r11.u64 = PPC_LOAD_U8(r30.u32 + 1);
	// stb r10,1(r30)
	PPC_STORE_U8(r30.u32 + 1, ctx.r10.u8);
	// stb r11,2(r30)
	PPC_STORE_U8(r30.u32 + 2, r11.u8);
	// lwz r11,16(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 16);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x8240997c
	if (!cr6.getGT()) goto loc_8240997C;
	// addi r11,r31,25
	r11.s64 = r31.s64 + 25;
loc_824098E8:
	// lbz r9,-2(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + -2);
	// addi r7,r7,1
	ctx.r7.s64 = ctx.r7.s64 + 1;
	// lbz r10,-5(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + -5);
	// stb r9,-5(r11)
	PPC_STORE_U8(r11.u32 + -5, ctx.r9.u8);
	// stb r10,-2(r11)
	PPC_STORE_U8(r11.u32 + -2, ctx.r10.u8);
	// lbz r9,-3(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + -3);
	// lbz r10,-4(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + -4);
	// stb r9,-4(r11)
	PPC_STORE_U8(r11.u32 + -4, ctx.r9.u8);
	// stb r10,-3(r11)
	PPC_STORE_U8(r11.u32 + -3, ctx.r10.u8);
	// lbz r9,2(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// lbz r10,-1(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + -1);
	// stb r9,-1(r11)
	PPC_STORE_U8(r11.u32 + -1, ctx.r9.u8);
	// stb r10,2(r11)
	PPC_STORE_U8(r11.u32 + 2, ctx.r10.u8);
	// lbz r9,1(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// lbz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// stb r9,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r9.u8);
	// stb r10,1(r11)
	PPC_STORE_U8(r11.u32 + 1, ctx.r10.u8);
	// lbz r9,6(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 6);
	// lbz r10,3(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// stb r9,3(r11)
	PPC_STORE_U8(r11.u32 + 3, ctx.r9.u8);
	// lbz r9,5(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 5);
	// stb r10,6(r11)
	PPC_STORE_U8(r11.u32 + 6, ctx.r10.u8);
	// lbz r10,4(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// stb r9,4(r11)
	PPC_STORE_U8(r11.u32 + 4, ctx.r9.u8);
	// stb r10,5(r11)
	PPC_STORE_U8(r11.u32 + 5, ctx.r10.u8);
	// lbz r9,10(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 10);
	// lbz r10,7(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 7);
	// stb r9,7(r11)
	PPC_STORE_U8(r11.u32 + 7, ctx.r9.u8);
	// lbz r9,9(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 9);
	// stb r10,10(r11)
	PPC_STORE_U8(r11.u32 + 10, ctx.r10.u8);
	// lbz r10,8(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 8);
	// stb r9,8(r11)
	PPC_STORE_U8(r11.u32 + 8, ctx.r9.u8);
	// stb r10,9(r11)
	PPC_STORE_U8(r11.u32 + 9, ctx.r10.u8);
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplw cr6,r7,r10
	cr6.compare<uint32_t>(ctx.r7.u32, ctx.r10.u32, xer);
	// blt cr6,0x824098e8
	if (cr6.getLT()) goto loc_824098E8;
loc_8240997C:
	// lwz r27,0(r30)
	r27.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x824099cc
	if (cr6.getEQ()) goto loc_824099CC;
	// addi r28,r31,20
	r28.s64 = r31.s64 + 20;
loc_8240998C:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// li r5,16
	ctx.r5.s64 = 16;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x824099cc
	if (cr6.getEQ()) goto loc_824099CC;
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// beq cr6,0x824099cc
	if (cr6.getEQ()) goto loc_824099CC;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,16
	r28.s64 = r28.s64 + 16;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplw cr6,r29,r27
	cr6.compare<uint32_t>(r29.u32, r27.u32, xer);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// blt cr6,0x8240998c
	if (cr6.getLT()) goto loc_8240998C;
loc_824099CC:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x824099e4
	if (!cr6.getEQ()) goto loc_824099E4;
	// lis r26,-28655
	r26.s64 = -1877934080;
	// ori r26,r26,3
	r26.u64 = r26.u64 | 3;
	// b 0x824099f4
	goto loc_824099F4;
loc_824099E4:
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// stw r11,0(r24)
	PPC_STORE_U32(r24.u32 + 0, r11.u32);
	// stw r10,0(r23)
	PPC_STORE_U32(r23.u32 + 0, ctx.r10.u32);
loc_824099F4:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82409a0c
	if (cr6.getEQ()) goto loc_82409A0C;
	// lis r5,24962
	ctx.r5.s64 = 1635909632;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// bl 0x82369440
	sub_82369440(ctx, base);
loc_82409A0C:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_82409A10:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed174
	return;
}

__attribute__((alias("__imp__sub_82409A18"))) PPC_WEAK_FUNC(sub_82409A18);
PPC_FUNC_IMPL(__imp__sub_82409A18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r23{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed124
	// stwu r1,-224(r1)
	ea = -224 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r29,0
	r29.s64 = 0;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// lis r6,27760
	ctx.r6.s64 = 1819279360;
	// addi r10,r10,532
	ctx.r10.s64 = ctx.r10.s64 + 532;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r29.u32);
	// mr r24,r5
	r24.u64 = ctx.r5.u64;
	// lwz r5,0(r3)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// std r29,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r29.u64);
	// addi r4,r3,4
	ctx.r4.s64 = ctx.r3.s64 + 4;
	// std r29,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r29.u64);
	// ori r6,r6,28019
	ctx.r6.u64 = ctx.r6.u64 | 28019;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// std r29,16(r11)
	PPC_STORE_U64(r11.u32 + 16, r29.u64);
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
	// stw r29,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r29.u32);
	// stw r29,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r29.u32);
	// stw r29,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r29.u32);
	// stw r29,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r29.u32);
	// stw r29,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r29.u32);
	// bl 0x824090a0
	sub_824090A0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x82409d94
	if (cr6.getLT()) goto loc_82409D94;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lwz r30,132(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lis r5,24962
	ctx.r5.s64 = 1635909632;
	// addi r23,r11,-5060
	r23.s64 = r11.s64 + -5060;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82369430
	sub_82369430(ctx, base);
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x82409ab8
	if (!cr6.getEQ()) goto loc_82409AB8;
	// lis r26,-32761
	r26.s64 = -2147024896;
	// ori r26,r26,14
	r26.u64 = r26.u64 | 14;
	// b 0x82409d78
	goto loc_82409D78;
loc_82409AB8:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82408e60
	sub_82408E60(ctx, base);
	// mr r26,r3
	r26.u64 = ctx.r3.u64;
	// cmpwi cr6,r26,0
	cr6.compare<int32_t>(r26.s32, 0, xer);
	// blt cr6,0x82409d78
	if (cr6.getLT()) goto loc_82409D78;
	// lbz r5,3(r31)
	ctx.r5.u64 = PPC_LOAD_U8(r31.u32 + 3);
	// addi r11,r31,4
	r11.s64 = r31.s64 + 4;
	// lbz r6,0(r31)
	ctx.r6.u64 = PPC_LOAD_U8(r31.u32 + 0);
	// addi r10,r31,8
	ctx.r10.s64 = r31.s64 + 8;
	// addi r9,r31,12
	ctx.r9.s64 = r31.s64 + 12;
	// addi r8,r31,16
	ctx.r8.s64 = r31.s64 + 16;
	// addi r7,r31,20
	ctx.r7.s64 = r31.s64 + 20;
	// stb r5,0(r31)
	PPC_STORE_U8(r31.u32 + 0, ctx.r5.u8);
	// addi r30,r31,28
	r30.s64 = r31.s64 + 28;
	// stb r6,3(r31)
	PPC_STORE_U8(r31.u32 + 3, ctx.r6.u8);
	// lbz r5,2(r31)
	ctx.r5.u64 = PPC_LOAD_U8(r31.u32 + 2);
	// lbz r6,1(r31)
	ctx.r6.u64 = PPC_LOAD_U8(r31.u32 + 1);
	// stb r5,1(r31)
	PPC_STORE_U8(r31.u32 + 1, ctx.r5.u8);
	// stb r6,2(r31)
	PPC_STORE_U8(r31.u32 + 2, ctx.r6.u8);
	// lbz r5,3(r11)
	ctx.r5.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// lbz r6,0(r11)
	ctx.r6.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// stb r5,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r5.u8);
	// stb r6,3(r11)
	PPC_STORE_U8(r11.u32 + 3, ctx.r6.u8);
	// lbz r5,2(r11)
	ctx.r5.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// lbz r6,1(r11)
	ctx.r6.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// stb r5,1(r11)
	PPC_STORE_U8(r11.u32 + 1, ctx.r5.u8);
	// stb r6,2(r11)
	PPC_STORE_U8(r11.u32 + 2, ctx.r6.u8);
	// lbz r6,3(r10)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r10.u32 + 3);
	// lbz r11,0(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// stb r6,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r6.u8);
	// stb r11,3(r10)
	PPC_STORE_U8(ctx.r10.u32 + 3, r11.u8);
	// lbz r6,2(r10)
	ctx.r6.u64 = PPC_LOAD_U8(ctx.r10.u32 + 2);
	// lbz r11,1(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 1);
	// stb r6,1(r10)
	PPC_STORE_U8(ctx.r10.u32 + 1, ctx.r6.u8);
	// stb r11,2(r10)
	PPC_STORE_U8(ctx.r10.u32 + 2, r11.u8);
	// lbz r10,3(r9)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + 3);
	// lbz r11,0(r9)
	r11.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// stb r10,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r10.u8);
	// stb r11,3(r9)
	PPC_STORE_U8(ctx.r9.u32 + 3, r11.u8);
	// lbz r10,2(r9)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + 2);
	// lbz r11,1(r9)
	r11.u64 = PPC_LOAD_U8(ctx.r9.u32 + 1);
	// stb r10,1(r9)
	PPC_STORE_U8(ctx.r9.u32 + 1, ctx.r10.u8);
	// stb r11,2(r9)
	PPC_STORE_U8(ctx.r9.u32 + 2, r11.u8);
	// lbz r10,3(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 3);
	// lbz r11,0(r8)
	r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 0);
	// stb r10,0(r8)
	PPC_STORE_U8(ctx.r8.u32 + 0, ctx.r10.u8);
	// stb r11,3(r8)
	PPC_STORE_U8(ctx.r8.u32 + 3, r11.u8);
	// lbz r10,2(r8)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r8.u32 + 2);
	// lbz r11,1(r8)
	r11.u64 = PPC_LOAD_U8(ctx.r8.u32 + 1);
	// stb r10,1(r8)
	PPC_STORE_U8(ctx.r8.u32 + 1, ctx.r10.u8);
	// stb r11,2(r8)
	PPC_STORE_U8(ctx.r8.u32 + 2, r11.u8);
	// lbz r10,3(r7)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r7.u32 + 3);
	// lbz r11,0(r7)
	r11.u64 = PPC_LOAD_U8(ctx.r7.u32 + 0);
	// stb r10,0(r7)
	PPC_STORE_U8(ctx.r7.u32 + 0, ctx.r10.u8);
	// stb r11,3(r7)
	PPC_STORE_U8(ctx.r7.u32 + 3, r11.u8);
	// addi r11,r31,32
	r11.s64 = r31.s64 + 32;
	// lbz r10,2(r7)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r7.u32 + 2);
	// lbz r9,1(r7)
	ctx.r9.u64 = PPC_LOAD_U8(ctx.r7.u32 + 1);
	// stb r10,1(r7)
	PPC_STORE_U8(ctx.r7.u32 + 1, ctx.r10.u8);
	// mr r10,r29
	ctx.r10.u64 = r29.u64;
	// stb r9,2(r7)
	PPC_STORE_U8(ctx.r7.u32 + 2, ctx.r9.u8);
	// lbz r8,27(r31)
	ctx.r8.u64 = PPC_LOAD_U8(r31.u32 + 27);
	// lbz r9,24(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 24);
	// stb r8,24(r31)
	PPC_STORE_U8(r31.u32 + 24, ctx.r8.u8);
	// stb r9,27(r31)
	PPC_STORE_U8(r31.u32 + 27, ctx.r9.u8);
	// lbz r8,26(r31)
	ctx.r8.u64 = PPC_LOAD_U8(r31.u32 + 26);
	// lbz r9,25(r31)
	ctx.r9.u64 = PPC_LOAD_U8(r31.u32 + 25);
	// stb r8,25(r31)
	PPC_STORE_U8(r31.u32 + 25, ctx.r8.u8);
	// stb r9,26(r31)
	PPC_STORE_U8(r31.u32 + 26, ctx.r9.u8);
	// lbz r8,3(r30)
	ctx.r8.u64 = PPC_LOAD_U8(r30.u32 + 3);
	// lbz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U8(r30.u32 + 0);
	// stb r8,0(r30)
	PPC_STORE_U8(r30.u32 + 0, ctx.r8.u8);
	// lbz r8,2(r30)
	ctx.r8.u64 = PPC_LOAD_U8(r30.u32 + 2);
	// stb r9,3(r30)
	PPC_STORE_U8(r30.u32 + 3, ctx.r9.u8);
	// lbz r9,1(r30)
	ctx.r9.u64 = PPC_LOAD_U8(r30.u32 + 1);
	// stb r8,1(r30)
	PPC_STORE_U8(r30.u32 + 1, ctx.r8.u8);
	// stb r9,2(r30)
	PPC_STORE_U8(r30.u32 + 2, ctx.r9.u8);
	// lbz r8,3(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// stb r8,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r8.u8);
	// lbz r8,2(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// stb r9,3(r11)
	PPC_STORE_U8(r11.u32 + 3, ctx.r9.u8);
	// lbz r9,1(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// stb r8,1(r11)
	PPC_STORE_U8(r11.u32 + 1, ctx.r8.u8);
	// stb r9,2(r11)
	PPC_STORE_U8(r11.u32 + 2, ctx.r9.u8);
	// lwz r11,28(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 28);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// ble cr6,0x82409d00
	if (!cr6.getGT()) goto loc_82409D00;
	// addi r11,r31,41
	r11.s64 = r31.s64 + 41;
loc_82409C2C:
	// lbz r8,-2(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + -2);
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// lbz r9,-5(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + -5);
	// stb r8,-5(r11)
	PPC_STORE_U8(r11.u32 + -5, ctx.r8.u8);
	// stb r9,-2(r11)
	PPC_STORE_U8(r11.u32 + -2, ctx.r9.u8);
	// lbz r8,-3(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + -3);
	// lbz r9,-4(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + -4);
	// stb r8,-4(r11)
	PPC_STORE_U8(r11.u32 + -4, ctx.r8.u8);
	// stb r9,-3(r11)
	PPC_STORE_U8(r11.u32 + -3, ctx.r9.u8);
	// lbz r8,2(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 2);
	// lbz r9,-1(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + -1);
	// stb r8,-1(r11)
	PPC_STORE_U8(r11.u32 + -1, ctx.r8.u8);
	// stb r9,2(r11)
	PPC_STORE_U8(r11.u32 + 2, ctx.r9.u8);
	// lbz r8,1(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// stb r8,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r8.u8);
	// stb r9,1(r11)
	PPC_STORE_U8(r11.u32 + 1, ctx.r9.u8);
	// lbz r8,6(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 6);
	// lbz r9,3(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 3);
	// stb r8,3(r11)
	PPC_STORE_U8(r11.u32 + 3, ctx.r8.u8);
	// stb r9,6(r11)
	PPC_STORE_U8(r11.u32 + 6, ctx.r9.u8);
	// lbz r8,5(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 5);
	// lbz r9,4(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 4);
	// stb r8,4(r11)
	PPC_STORE_U8(r11.u32 + 4, ctx.r8.u8);
	// stb r9,5(r11)
	PPC_STORE_U8(r11.u32 + 5, ctx.r9.u8);
	// lbz r8,10(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 10);
	// lbz r9,7(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 7);
	// stb r8,7(r11)
	PPC_STORE_U8(r11.u32 + 7, ctx.r8.u8);
	// stb r9,10(r11)
	PPC_STORE_U8(r11.u32 + 10, ctx.r9.u8);
	// lbz r8,9(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 9);
	// lbz r9,8(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 8);
	// stb r8,8(r11)
	PPC_STORE_U8(r11.u32 + 8, ctx.r8.u8);
	// stb r9,9(r11)
	PPC_STORE_U8(r11.u32 + 9, ctx.r9.u8);
	// lbz r8,14(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 14);
	// lbz r9,11(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 11);
	// stb r8,11(r11)
	PPC_STORE_U8(r11.u32 + 11, ctx.r8.u8);
	// lbz r8,13(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 13);
	// stb r9,14(r11)
	PPC_STORE_U8(r11.u32 + 14, ctx.r9.u8);
	// lbz r9,12(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 12);
	// stb r8,12(r11)
	PPC_STORE_U8(r11.u32 + 12, ctx.r8.u8);
	// stb r9,13(r11)
	PPC_STORE_U8(r11.u32 + 13, ctx.r9.u8);
	// lbz r8,18(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 18);
	// lbz r9,15(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 15);
	// stb r8,15(r11)
	PPC_STORE_U8(r11.u32 + 15, ctx.r8.u8);
	// lbz r8,17(r11)
	ctx.r8.u64 = PPC_LOAD_U8(r11.u32 + 17);
	// stb r9,18(r11)
	PPC_STORE_U8(r11.u32 + 18, ctx.r9.u8);
	// lbz r9,16(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 16);
	// stb r8,16(r11)
	PPC_STORE_U8(r11.u32 + 16, ctx.r8.u8);
	// stb r9,17(r11)
	PPC_STORE_U8(r11.u32 + 17, ctx.r9.u8);
	// addi r11,r11,24
	r11.s64 = r11.s64 + 24;
	// lwz r9,0(r30)
	ctx.r9.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x82409c2c
	if (cr6.getLT()) goto loc_82409C2C;
loc_82409D00:
	// lwz r27,0(r30)
	r27.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x82409d48
	if (cr6.getEQ()) goto loc_82409D48;
	// addi r28,r31,36
	r28.s64 = r31.s64 + 36;
loc_82409D10:
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// li r5,24
	ctx.r5.s64 = 24;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x82409d48
	if (cr6.getEQ()) goto loc_82409D48;
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r29,r29,1
	r29.s64 = r29.s64 + 1;
	// addi r28,r28,24
	r28.s64 = r28.s64 + 24;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// cmplw cr6,r29,r27
	cr6.compare<uint32_t>(r29.u32, r27.u32, xer);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// blt cr6,0x82409d10
	if (cr6.getLT()) goto loc_82409D10;
loc_82409D48:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x82409d60
	if (!cr6.getEQ()) goto loc_82409D60;
	// lis r26,-28655
	r26.s64 = -1877934080;
	// ori r26,r26,3
	r26.u64 = r26.u64 | 3;
	// b 0x82409d78
	goto loc_82409D78;
loc_82409D60:
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// lwz r10,92(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	// subf r10,r11,r10
	ctx.r10.s64 = ctx.r10.s64 - r11.s64;
	// addi r10,r10,1
	ctx.r10.s64 = ctx.r10.s64 + 1;
	// stw r11,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r11.u32);
	// stw r10,0(r24)
	PPC_STORE_U32(r24.u32 + 0, ctx.r10.u32);
loc_82409D78:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x82409d90
	if (cr6.getEQ()) goto loc_82409D90;
	// lis r5,24962
	ctx.r5.s64 = 1635909632;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mr r3,r23
	ctx.r3.u64 = r23.u64;
	// bl 0x82369440
	sub_82369440(ctx, base);
loc_82409D90:
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
loc_82409D94:
	// addi r1,r1,224
	ctx.r1.s64 = ctx.r1.s64 + 224;
	// b 0x823ed174
	return;
}

__attribute__((alias("__imp__sub_82409DA0"))) PPC_WEAK_FUNC(sub_82409DA0);
PPC_FUNC_IMPL(__imp__sub_82409DA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// stwu r1,-256(r1)
	ea = -256 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r31,0
	r31.s64 = 0;
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// lis r10,-32250
	ctx.r10.s64 = -2113536000;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r10,r10,532
	ctx.r10.s64 = ctx.r10.s64 + 532;
	// addi r29,r30,4
	r29.s64 = r30.s64 + 4;
	// stw r31,148(r1)
	PPC_STORE_U32(ctx.r1.u32 + 148, r31.u32);
	// lis r6,21587
	ctx.r6.s64 = 1414725632;
	// std r31,0(r11)
	PPC_STORE_U64(r11.u32 + 0, r31.u64);
	// mr r26,r4
	r26.u64 = ctx.r4.u64;
	// std r31,8(r11)
	PPC_STORE_U64(r11.u32 + 8, r31.u64);
	// ori r6,r6,20041
	ctx.r6.u64 = ctx.r6.u64 | 20041;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// stw r10,144(r1)
	PPC_STORE_U32(ctx.r1.u32 + 144, ctx.r10.u32);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// stw r31,152(r1)
	PPC_STORE_U32(ctx.r1.u32 + 152, r31.u32);
	// mr r25,r5
	r25.u64 = ctx.r5.u64;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// stw r31,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, r31.u32);
	// li r28,-1
	r28.s64 = -1;
	// stw r31,160(r1)
	PPC_STORE_U32(ctx.r1.u32 + 160, r31.u32);
	// stw r31,164(r1)
	PPC_STORE_U32(ctx.r1.u32 + 164, r31.u32);
	// stw r31,168(r1)
	PPC_STORE_U32(ctx.r1.u32 + 168, r31.u32);
	// stw r10,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, ctx.r10.u32);
	// stw r31,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r31.u32);
	// stw r31,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r31.u32);
	// stw r31,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r31.u32);
	// stw r31,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r31.u32);
	// stw r31,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r31.u32);
	// stw r31,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r31.u32);
	// stw r31,16(r11)
	PPC_STORE_U32(r11.u32 + 16, r31.u32);
	// bl 0x824090a0
	sub_824090A0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x8240a01c
	if (cr6.getLT()) goto loc_8240A01C;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,20
	ctx.r6.s64 = 20;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,144
	ctx.r3.s64 = ctx.r1.s64 + 144;
	// bl 0x82408e60
	sub_82408E60(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x8240a01c
	if (cr6.getLT()) goto loc_8240A01C;
	// lhz r11,88(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 88);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x82409eb8
	if (!cr6.getEQ()) goto loc_82409EB8;
	// addi r27,r1,88
	r27.s64 = ctx.r1.s64 + 88;
loc_82409E64:
	// lis r6,19282
	ctx.r6.s64 = 1263665152;
	// lwz r5,0(r30)
	ctx.r5.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// ori r6,r6,16717
	ctx.r6.u64 = ctx.r6.u64 | 16717;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x824090a0
	sub_824090A0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x8240a01c
	if (cr6.getLT()) goto loc_8240A01C;
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lwz r30,132(r1)
	r30.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// lis r5,24962
	ctx.r5.s64 = 1635909632;
	// addi r24,r11,-5060
	r24.s64 = r11.s64 + -5060;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82369430
	sub_82369430(ctx, base);
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// bne cr6,0x82409edc
	if (!cr6.getEQ()) goto loc_82409EDC;
	// lis r30,-32761
	r30.s64 = -2147024896;
	// ori r30,r30,14
	r30.u64 = r30.u64 | 14;
	// b 0x8240a000
	goto loc_8240A000;
loc_82409EB8:
	// lhz r11,94(r1)
	r11.u64 = PPC_LOAD_U16(ctx.r1.u32 + 94);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x82409ecc
	if (!cr6.getEQ()) goto loc_82409ECC;
	// addi r27,r1,94
	r27.s64 = ctx.r1.s64 + 94;
	// b 0x82409e64
	goto loc_82409E64;
loc_82409ECC:
	// lis r3,-28655
	ctx.r3.s64 = -1877934080;
	// ori r3,r3,3
	ctx.r3.u64 = ctx.r3.u64 | 3;
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x823ed178
	return;
loc_82409EDC:
	// li r7,0
	ctx.r7.s64 = 0;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82408e60
	sub_82408E60(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x8240a000
	if (cr6.getLT()) goto loc_8240A000;
	// lhz r9,0(r29)
	ctx.r9.u64 = PPC_LOAD_U16(r29.u32 + 0);
	// addi r11,r29,2
	r11.s64 = r29.s64 + 2;
	// mr r10,r31
	ctx.r10.u64 = r31.u64;
	// mr r7,r11
	ctx.r7.u64 = r11.u64;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82409f54
	if (cr6.getEQ()) goto loc_82409F54;
	// lhz r6,2(r27)
	ctx.r6.u64 = PPC_LOAD_U16(r27.u32 + 2);
loc_82409F1C:
	// lhz r8,0(r7)
	ctx.r8.u64 = PPC_LOAD_U16(ctx.r7.u32 + 0);
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// beq cr6,0x82409f50
	if (cr6.getEQ()) goto loc_82409F50;
	// clrlwi r8,r10,16
	ctx.r8.u64 = ctx.r10.u32 & 0xFFFF;
	// lbz r10,6(r7)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r7.u32 + 6);
	// addi r5,r8,1
	ctx.r5.s64 = ctx.r8.s64 + 1;
	// add r8,r10,r7
	ctx.r8.u64 = ctx.r10.u64 + ctx.r7.u64;
	// clrlwi r10,r5,16
	ctx.r10.u64 = ctx.r5.u32 & 0xFFFF;
	// addi r7,r8,8
	ctx.r7.s64 = ctx.r8.s64 + 8;
	// mr r8,r10
	ctx.r8.u64 = ctx.r10.u64;
	// cmplw cr6,r8,r9
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r9.u32, xer);
	// blt cr6,0x82409f1c
	if (cr6.getLT()) goto loc_82409F1C;
	// b 0x82409f54
	goto loc_82409F54;
loc_82409F50:
	// mr r28,r10
	r28.u64 = ctx.r10.u64;
loc_82409F54:
	// clrlwi r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x82409f6c
	if (cr6.getLT()) goto loc_82409F6C;
	// lis r30,-28655
	r30.s64 = -1877934080;
	// ori r30,r30,3
	r30.u64 = r30.u64 | 3;
	// b 0x8240a000
	goto loc_8240A000;
loc_82409F6C:
	// mr r8,r31
	ctx.r8.u64 = r31.u64;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// beq cr6,0x82409fb4
	if (cr6.getEQ()) goto loc_82409FB4;
	// clrlwi r6,r28,16
	ctx.r6.u64 = r28.u32 & 0xFFFF;
loc_82409F7C:
	// cmplw cr6,r31,r6
	cr6.compare<uint32_t>(r31.u32, ctx.r6.u32, xer);
	// beq cr6,0x82409f94
	if (cr6.getEQ()) goto loc_82409F94;
	// lhz r10,4(r27)
	ctx.r10.u64 = PPC_LOAD_U16(r27.u32 + 4);
	// lhz r5,0(r11)
	ctx.r5.u64 = PPC_LOAD_U16(r11.u32 + 0);
	// cmplw cr6,r5,r10
	cr6.compare<uint32_t>(ctx.r5.u32, ctx.r10.u32, xer);
	// beq cr6,0x82409fb4
	if (cr6.getEQ()) goto loc_82409FB4;
loc_82409F94:
	// addi r8,r31,1
	ctx.r8.s64 = r31.s64 + 1;
	// lbz r10,6(r11)
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + 6);
	// clrlwi r8,r8,16
	ctx.r8.u64 = ctx.r8.u32 & 0xFFFF;
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// mr r31,r8
	r31.u64 = ctx.r8.u64;
	// addi r11,r11,8
	r11.s64 = r11.s64 + 8;
	// cmplw cr6,r31,r9
	cr6.compare<uint32_t>(r31.u32, ctx.r9.u32, xer);
	// blt cr6,0x82409f7c
	if (cr6.getLT()) goto loc_82409F7C;
loc_82409FB4:
	// clrlwi r10,r8,16
	ctx.r10.u64 = ctx.r8.u32 & 0xFFFF;
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x82409fcc
	if (cr6.getLT()) goto loc_82409FCC;
	// lis r30,-28655
	r30.s64 = -1877934080;
	// ori r30,r30,3
	r30.u64 = r30.u64 | 3;
	// b 0x8240a000
	goto loc_8240A000;
loc_82409FCC:
	// lwz r10,2(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 2);
	// lwz r9,2(r11)
	ctx.r9.u64 = PPC_LOAD_U32(r11.u32 + 2);
	// cmplw cr6,r10,r9
	cr6.compare<uint32_t>(ctx.r10.u32, ctx.r9.u32, xer);
	// blt cr6,0x82409fe8
	if (cr6.getLT()) goto loc_82409FE8;
	// lis r30,-28655
	r30.s64 = -1877934080;
	// ori r30,r30,3
	r30.u64 = r30.u64 | 3;
	// b 0x8240a000
	goto loc_8240A000;
loc_82409FE8:
	// lwz r10,2(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 2);
	// stw r10,0(r26)
	PPC_STORE_U32(r26.u32 + 0, ctx.r10.u32);
	// lwz r11,2(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 2);
	// lwz r10,2(r7)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r7.u32 + 2);
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// stw r11,0(r25)
	PPC_STORE_U32(r25.u32 + 0, r11.u32);
loc_8240A000:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8240a018
	if (cr6.getEQ()) goto loc_8240A018;
	// lis r5,24962
	ctx.r5.s64 = 1635909632;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// bl 0x82369440
	sub_82369440(ctx, base);
loc_8240A018:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8240A01C:
	// addi r1,r1,256
	ctx.r1.s64 = ctx.r1.s64 + 256;
	// b 0x823ed178
	return;
}

__attribute__((alias("__imp__sub_8240A028"))) PPC_WEAK_FUNC(sub_8240A028);
PPC_FUNC_IMPL(__imp__sub_8240A028) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed12c
	// stwu r1,-208(r1)
	ea = -208 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32250
	r11.s64 = -2113536000;
	// li r29,0
	r29.s64 = 0;
	// addi r26,r11,532
	r26.s64 = r11.s64 + 532;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r25,r29
	r25.u64 = r29.u64;
	// stw r29,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r29.u32);
	// stw r26,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r26.u32);
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r29.u32);
	// stw r29,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r29.u32);
	// stw r29,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r29.u32);
	// stw r29,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r29.u32);
	// stw r29,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r29.u32);
	// stw r29,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r29.u32);
	// stw r29,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r29.u32);
	// bl 0x82408fe8
	sub_82408FE8(ctx, base);
	// addi r28,r31,4
	r28.s64 = r31.s64 + 4;
	// stw r30,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r30.u32);
	// lis r6,17990
	ctx.r6.s64 = 1178992640;
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// ori r6,r6,18770
	ctx.r6.u64 = ctx.r6.u64 | 18770;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x824090a0
	sub_824090A0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x8240a0a8
	if (cr6.getLT()) goto loc_8240A0A8;
	// stw r29,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r29.u32);
	// b 0x8240a0d4
	goto loc_8240A0D4;
loc_8240A0A8:
	// lis r6,19794
	ctx.r6.s64 = 1297219584;
	// lwz r5,0(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// li r4,0
	ctx.r4.s64 = 0;
	// ori r6,r6,20294
	ctx.r6.u64 = ctx.r6.u64 | 20294;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x824090a0
	sub_824090A0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x8240a0d4
	if (cr6.getLT()) goto loc_8240A0D4;
	// li r11,1
	r11.s64 = 1;
	// stw r11,60(r31)
	PPC_STORE_U32(r31.u32 + 60, r11.u32);
loc_8240A0D4:
	// lis r11,-28655
	r11.s64 = -1877934080;
	// cmpw cr6,r30,r11
	cr6.compare<int32_t>(r30.s32, r11.s32, xer);
	// bne cr6,0x8240a0ec
	if (!cr6.getEQ()) goto loc_8240A0EC;
	// lis r30,-28655
	r30.s64 = -1877934080;
	// ori r30,r30,2
	r30.u64 = r30.u64 | 2;
	// b 0x8240a250
	goto loc_8240A250;
loc_8240A0EC:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x8240a250
	if (cr6.getLT()) goto loc_8240A250;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,80
	ctx.r5.s64 = ctx.r1.s64 + 80;
	// li r4,0
	ctx.r4.s64 = 0;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x82408e60
	sub_82408E60(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x8240a250
	if (cr6.getLT()) goto loc_8240A250;
	// mr r11,r29
	r11.u64 = r29.u64;
	// addi r10,r1,83
	ctx.r10.s64 = ctx.r1.s64 + 83;
loc_8240A120:
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// lbz r7,0(r10)
	ctx.r7.u64 = PPC_LOAD_U8(ctx.r10.u32 + 0);
	// add r9,r11,r9
	ctx.r9.u64 = r11.u64 + ctx.r9.u64;
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r11,2
	cr6.compare<uint32_t>(r11.u32, 2, xer);
	// lbz r8,0(r9)
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + 0);
	// stb r7,0(r9)
	PPC_STORE_U8(ctx.r9.u32 + 0, ctx.r7.u8);
	// stb r8,0(r10)
	PPC_STORE_U8(ctx.r10.u32 + 0, ctx.r8.u8);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// blt cr6,0x8240a120
	if (cr6.getLT()) goto loc_8240A120;
	// lwz r9,60(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// lis r11,17222
	r11.s64 = 1128660992;
	// ori r10,r11,18753
	ctx.r10.u64 = r11.u64 | 18753;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8240a17c
	if (!cr6.getEQ()) goto loc_8240A17C;
	// lis r11,17750
	r11.s64 = 1163264000;
	// ori r8,r11,16727
	ctx.r8.u64 = r11.u64 | 16727;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x8240a1a4
	if (cr6.getEQ()) goto loc_8240A1A4;
	// lis r30,-28655
	r30.s64 = -1877934080;
	// ori r30,r30,2
	r30.u64 = r30.u64 | 2;
	// b 0x8240a250
	goto loc_8240A250;
loc_8240A17C:
	// lis r11,17990
	r11.s64 = 1178992640;
	// ori r8,r11,18753
	ctx.r8.u64 = r11.u64 | 18753;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// beq cr6,0x8240a1a4
	if (cr6.getEQ()) goto loc_8240A1A4;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// beq cr6,0x8240a1a4
	if (cr6.getEQ()) goto loc_8240A1A4;
	// lis r30,-28655
	r30.s64 = -1877934080;
	// ori r30,r30,2
	r30.u64 = r30.u64 | 2;
	// b 0x8240a250
	goto loc_8240A250;
loc_8240A1A4:
	// cmplwi cr6,r9,1
	cr6.compare<uint32_t>(ctx.r9.u32, 1, xer);
	// bne cr6,0x8240a21c
	if (!cr6.getEQ()) goto loc_8240A21C;
	// cmplw cr6,r11,r10
	cr6.compare<uint32_t>(r11.u32, ctx.r10.u32, xer);
	// bne cr6,0x8240a21c
	if (!cr6.getEQ()) goto loc_8240A21C;
	// lis r6,21061
	ctx.r6.s64 = 1380253696;
	// lwz r5,0(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// ori r6,r6,22098
	ctx.r6.u64 = ctx.r6.u64 | 22098;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x824090a0
	sub_824090A0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x8240a250
	if (cr6.getLT()) goto loc_8240A250;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,4
	ctx.r6.s64 = 4;
	// addi r5,r1,84
	ctx.r5.s64 = ctx.r1.s64 + 84;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// bl 0x82408e60
	sub_82408E60(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x8240a250
	if (cr6.getLT()) goto loc_8240A250;
	// lis r11,-23936
	r11.s64 = -1568669696;
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// ori r11,r11,20800
	r11.u64 = r11.u64 | 20800;
	// cmplw cr6,r10,r11
	cr6.compare<uint32_t>(ctx.r10.u32, r11.u32, xer);
	// beq cr6,0x8240a21c
	if (cr6.getEQ()) goto loc_8240A21C;
	// lis r30,-28655
	r30.s64 = -1877934080;
	// ori r30,r30,2
	r30.u64 = r30.u64 | 2;
	// b 0x8240a250
	goto loc_8240A250;
loc_8240A21C:
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8240a234
	if (!cr6.getEQ()) goto loc_8240A234;
	// lis r6,24948
	ctx.r6.s64 = 1634992128;
	// ori r6,r6,24932
	ctx.r6.u64 = ctx.r6.u64 | 24932;
	// b 0x8240a23c
	goto loc_8240A23C;
loc_8240A234:
	// lis r6,17486
	ctx.r6.s64 = 1145962496;
	// ori r6,r6,21331
	ctx.r6.u64 = ctx.r6.u64 | 21331;
loc_8240A23C:
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// lwz r5,0(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r3,r31,32
	ctx.r3.s64 = r31.s64 + 32;
	// bl 0x824090a0
	sub_824090A0(ctx, base);
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
loc_8240A250:
	// mr r27,r29
	r27.u64 = r29.u64;
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x8240a3e8
	if (cr6.getLT()) goto loc_8240A3E8;
	// addi r4,r1,88
	ctx.r4.s64 = ctx.r1.s64 + 88;
	// stw r29,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r29.u32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82409570
	sub_82409570(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x8240a2c0
	if (cr6.getLT()) goto loc_8240A2C0;
	// lwz r11,88(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240a2c0
	if (cr6.getEQ()) goto loc_8240A2C0;
	// li r27,1
	r27.s64 = 1;
	// li r25,18
	r25.s64 = 18;
loc_8240A288:
	// cmpwi cr6,r30,0
	cr6.compare<int32_t>(r30.s32, 0, xer);
	// blt cr6,0x8240a3e8
	if (cr6.getLT()) goto loc_8240A3E8;
loc_8240A290:
	// lis r11,-31991
	r11.s64 = -2096562176;
	// lis r5,24962
	ctx.r5.s64 = 1635909632;
	// addi r3,r11,-5060
	ctx.r3.s64 = r11.s64 + -5060;
	// mr r4,r25
	ctx.r4.u64 = r25.u64;
	// bl 0x82369430
	sub_82369430(ctx, base);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// stw r3,64(r31)
	PPC_STORE_U32(r31.u32 + 64, ctx.r3.u32);
	// bne cr6,0x8240a32c
	if (!cr6.getEQ()) goto loc_8240A32C;
	// lis r3,-32761
	ctx.r3.s64 = -2147024896;
	// ori r3,r3,14
	ctx.r3.u64 = ctx.r3.u64 | 14;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed17c
	return;
loc_8240A2C0:
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8240a324
	if (!cr6.getEQ()) goto loc_8240A324;
	// lis r6,8308
	ctx.r6.s64 = 544473088;
	// lwz r5,0(r31)
	ctx.r5.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// stw r26,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r26.u32);
	// ori r6,r6,28006
	ctx.r6.u64 = ctx.r6.u64 | 28006;
	// stw r29,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, r29.u32);
	// addi r3,r1,112
	ctx.r3.s64 = ctx.r1.s64 + 112;
	// stw r29,120(r1)
	PPC_STORE_U32(ctx.r1.u32 + 120, r29.u32);
	// stw r29,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, r29.u32);
	// stw r29,128(r1)
	PPC_STORE_U32(ctx.r1.u32 + 128, r29.u32);
	// stw r29,132(r1)
	PPC_STORE_U32(ctx.r1.u32 + 132, r29.u32);
	// stw r29,136(r1)
	PPC_STORE_U32(ctx.r1.u32 + 136, r29.u32);
	// bl 0x824090a0
	sub_824090A0(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x8240a31c
	if (cr6.getLT()) goto loc_8240A31C;
	// lwz r11,132(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 132);
	// cmplwi cr6,r11,18
	cr6.compare<uint32_t>(r11.u32, 18, xer);
	// mr r25,r11
	r25.u64 = r11.u64;
	// bgt cr6,0x8240a31c
	if (cr6.getGT()) goto loc_8240A31C;
	// li r25,18
	r25.s64 = 18;
loc_8240A31C:
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// b 0x8240a288
	goto loc_8240A288;
loc_8240A324:
	// li r25,18
	r25.s64 = 18;
	// b 0x8240a290
	goto loc_8240A290;
loc_8240A32C:
	// cmpwi cr6,r27,0
	cr6.compare<int32_t>(r27.s32, 0, xer);
	// bne cr6,0x8240a3c0
	if (!cr6.getEQ()) goto loc_8240A3C0;
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// mr r4,r3
	ctx.r4.u64 = ctx.r3.u64;
	// li r6,0
	ctx.r6.s64 = 0;
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// mr r5,r25
	ctx.r5.u64 = r25.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bne cr6,0x8240a3b8
	if (!cr6.getEQ()) goto loc_8240A3B8;
	// bl 0x82409228
	sub_82409228(ctx, base);
loc_8240A354:
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// blt cr6,0x8240a3dc
	if (cr6.getLT()) goto loc_8240A3DC;
loc_8240A360:
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// cmplwi cr6,r11,1
	cr6.compare<uint32_t>(r11.u32, 1, xer);
	// bne cr6,0x8240a3dc
	if (!cr6.getEQ()) goto loc_8240A3DC;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,8
	ctx.r6.s64 = 8;
	// addi r5,r1,96
	ctx.r5.s64 = ctx.r1.s64 + 96;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r3,r31,32
	ctx.r3.s64 = r31.s64 + 32;
	// bl 0x82408e60
	sub_82408E60(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x8240a3ec
	if (cr6.getLT()) goto loc_8240A3EC;
	// lwz r10,48(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 48);
	// lwz r11,96(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r9,52(r31)
	ctx.r9.u64 = PPC_LOAD_U32(r31.u32 + 52);
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// subf r11,r11,r9
	r11.s64 = ctx.r9.s64 - r11.s64;
	// addi r10,r10,8
	ctx.r10.s64 = ctx.r10.s64 + 8;
	// addi r11,r11,-8
	r11.s64 = r11.s64 + -8;
	// stw r10,48(r31)
	PPC_STORE_U32(r31.u32 + 48, ctx.r10.u32);
	// stw r11,52(r31)
	PPC_STORE_U32(r31.u32 + 52, r11.u32);
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed17c
	return;
loc_8240A3B8:
	// bl 0x824093b8
	sub_824093B8(ctx, base);
	// b 0x8240a354
	goto loc_8240A354;
loc_8240A3C0:
	// li r5,18
	ctx.r5.s64 = 18;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x823edf70
	sub_823EDF70(ctx, base);
	// lwz r11,64(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// li r10,357
	ctx.r10.s64 = 357;
	// sth r10,0(r11)
	PPC_STORE_U16(r11.u32 + 0, ctx.r10.u16);
	// b 0x8240a360
	goto loc_8240A360;
loc_8240A3DC:
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed17c
	return;
loc_8240A3E8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
loc_8240A3EC:
	// addi r1,r1,208
	ctx.r1.s64 = ctx.r1.s64 + 208;
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_8240A3F8"))) PPC_WEAK_FUNC(sub_8240A3F8);
PPC_FUNC_IMPL(__imp__sub_8240A3F8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// lwz r11,60(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// bne cr6,0x8240a43c
	if (!cr6.getEQ()) goto loc_8240A43C;
	// bl 0x82409760
	sub_82409760(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge cr6,0x8240a448
	if (!cr6.getLT()) goto loc_8240A448;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82409a18
	sub_82409A18(ctx, base);
	// b 0x8240a440
	goto loc_8240A440;
loc_8240A43C:
	// bl 0x82409da0
	sub_82409DA0(ctx, base);
loc_8240A440:
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x8240a470
	if (cr6.getLT()) goto loc_8240A470;
loc_8240A448:
	// lwz r11,64(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// lwz r10,0(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// lhz r11,12(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 12);
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// lwz r11,64(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// lwz r10,0(r29)
	ctx.r10.u64 = PPC_LOAD_U32(r29.u32 + 0);
	// lhz r11,12(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 12);
	// mullw r11,r11,r10
	r11.s64 = int64_t(r11.s32) * int64_t(ctx.r10.s32);
	// stw r11,0(r29)
	PPC_STORE_U32(r29.u32 + 0, r11.u32);
loc_8240A470:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_8240A478"))) PPC_WEAK_FUNC(sub_8240A478);
PPC_FUNC_IMPL(__imp__sub_8240A478) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// stw r6,156(r1)
	PPC_STORE_U32(ctx.r1.u32 + 156, ctx.r6.u32);
	// mr r29,r7
	r29.u64 = ctx.r7.u64;
	// addi r7,r1,156
	ctx.r7.s64 = ctx.r1.s64 + 156;
	// addi r3,r31,32
	ctx.r3.s64 = r31.s64 + 32;
	// mr r30,r5
	r30.u64 = ctx.r5.u64;
	// bl 0x82408e60
	sub_82408E60(ctx, base);
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// blt cr6,0x8240a54c
	if (cr6.getLT()) goto loc_8240A54C;
	// lwz r11,64(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 64);
	// lwz r8,156(r1)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r1.u32 + 156);
	// lhz r10,0(r11)
	ctx.r10.u64 = PPC_LOAD_U16(r11.u32 + 0);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// bne cr6,0x8240a540
	if (!cr6.getEQ()) goto loc_8240A540;
	// lwz r10,60(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 60);
	// lhz r11,14(r11)
	r11.u64 = PPC_LOAD_U16(r11.u32 + 14);
	// cmplwi cr6,r10,1
	cr6.compare<uint32_t>(ctx.r10.u32, 1, xer);
	// blt cr6,0x8240a500
	if (cr6.getLT()) goto loc_8240A500;
	// bne cr6,0x8240a540
	if (!cr6.getEQ()) goto loc_8240A540;
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// bne cr6,0x8240a540
	if (!cr6.getEQ()) goto loc_8240A540;
	// li r11,0
	r11.s64 = 0;
	// cmplwi cr6,r8,0
	cr6.compare<uint32_t>(ctx.r8.u32, 0, xer);
	// beq cr6,0x8240a540
	if (cr6.getEQ()) goto loc_8240A540;
loc_8240A4E4:
	// lbzx r10,r11,r30
	ctx.r10.u64 = PPC_LOAD_U8(r11.u32 + r30.u32);
	// addi r10,r10,128
	ctx.r10.s64 = ctx.r10.s64 + 128;
	// stbx r10,r11,r30
	PPC_STORE_U8(r11.u32 + r30.u32, ctx.r10.u8);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplw cr6,r11,r8
	cr6.compare<uint32_t>(r11.u32, ctx.r8.u32, xer);
	// blt cr6,0x8240a4e4
	if (cr6.getLT()) goto loc_8240A4E4;
	// b 0x8240a540
	goto loc_8240A540;
loc_8240A500:
	// cmplwi cr6,r11,8
	cr6.compare<uint32_t>(r11.u32, 8, xer);
	// beq cr6,0x8240a540
	if (cr6.getEQ()) goto loc_8240A540;
	// cmplwi cr6,r11,16
	cr6.compare<uint32_t>(r11.u32, 16, xer);
	// bne cr6,0x8240a540
	if (!cr6.getEQ()) goto loc_8240A540;
	// rlwinm r10,r8,31,1,31
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 31) & 0x7FFFFFFF;
	// mr r11,r30
	r11.u64 = r30.u64;
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq cr6,0x8240a540
	if (cr6.getEQ()) goto loc_8240A540;
loc_8240A520:
	// lbz r7,1(r11)
	ctx.r7.u64 = PPC_LOAD_U8(r11.u32 + 1);
	// addi r10,r10,-1
	ctx.r10.s64 = ctx.r10.s64 + -1;
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// cmplwi cr6,r10,0
	cr6.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// stb r7,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r7.u8);
	// stb r9,1(r11)
	PPC_STORE_U8(r11.u32 + 1, ctx.r9.u8);
	// addi r11,r11,2
	r11.s64 = r11.s64 + 2;
	// bne cr6,0x8240a520
	if (!cr6.getEQ()) goto loc_8240A520;
loc_8240A540:
	// cmplwi cr6,r29,0
	cr6.compare<uint32_t>(r29.u32, 0, xer);
	// beq cr6,0x8240a54c
	if (cr6.getEQ()) goto loc_8240A54C;
	// stw r8,0(r29)
	PPC_STORE_U32(r29.u32 + 0, ctx.r8.u32);
loc_8240A54C:
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_8240A558"))) PPC_WEAK_FUNC(sub_8240A558);
PPC_FUNC_IMPL(__imp__sub_8240A558) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r10,-32015
	ctx.r10.s64 = -2098135040;
	// clrlwi r9,r4,29
	ctx.r9.u64 = ctx.r4.u32 & 0x7;
	// addi r10,r10,-14104
	ctx.r10.s64 = ctx.r10.s64 + -14104;
	// rlwinm r11,r4,29,3,31
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 29) & 0x1FFFFFFF;
	// lbzx r10,r9,r10
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r10.u32);
	// lbzx r9,r11,r3
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + ctx.r3.u32);
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// stbx r10,r11,r3
	PPC_STORE_U8(r11.u32 + ctx.r3.u32, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A580"))) PPC_WEAK_FUNC(sub_8240A580);
PPC_FUNC_IMPL(__imp__sub_8240A580) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCRegister r11{};
	PPCRegister temp{};
	// li r9,128
	ctx.r9.s64 = 128;
	// clrlwi r10,r4,29
	ctx.r10.u64 = ctx.r4.u32 & 0x7;
	// rlwinm r11,r4,29,3,31
	r11.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 29) & 0x1FFFFFFF;
	// sraw r10,r9,r10
	temp.u32 = ctx.r10.u32 & 0x3F;
	if (temp.u32 > 0x1F) temp.u32 = 0x1F;
	xer.ca = (ctx.r9.s32 < 0) & (((ctx.r9.s32 >> temp.u32) << temp.u32) != ctx.r9.s32);
	ctx.r10.s64 = ctx.r9.s32 >> temp.u32;
	// lbzx r9,r11,r3
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + ctx.r3.u32);
	// andc r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 & ~ctx.r10.u64;
	// stbx r10,r11,r3
	PPC_STORE_U8(r11.u32 + ctx.r3.u32, ctx.r10.u8);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A5A0"))) PPC_WEAK_FUNC(sub_8240A5A0);
PPC_FUNC_IMPL(__imp__sub_8240A5A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32015
	r11.s64 = -2098135040;
	// clrlwi r10,r4,29
	ctx.r10.u64 = ctx.r4.u32 & 0x7;
	// addi r11,r11,-14104
	r11.s64 = r11.s64 + -14104;
	// rlwinm r9,r4,29,3,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r4.u32 | (ctx.r4.u64 << 32), 29) & 0x1FFFFFFF;
	// lbzx r11,r10,r11
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + r11.u32);
	// lbzx r10,r9,r3
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r3.u32);
	// and r3,r11,r10
	ctx.r3.u64 = r11.u64 & ctx.r10.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A5C0"))) PPC_WEAK_FUNC(sub_8240A5C0);
PPC_FUNC_IMPL(__imp__sub_8240A5C0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f13,2776(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2776);
	ctx.f13.f64 = double(temp.f32);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// stfs f13,0(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f13,16(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 16, temp.u32);
	// stfs f13,32(r3)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r3.u32 + 32, temp.u32);
	// lfs f0,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// stfs f0,12(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 12, temp.u32);
	// stfs f0,24(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 24, temp.u32);
	// stfs f0,4(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 4, temp.u32);
	// stfs f0,28(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 28, temp.u32);
	// stfs f0,8(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// stfs f0,20(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 20, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A5F8"))) PPC_WEAK_FUNC(sub_8240A5F8);
PPC_FUNC_IMPL(__imp__sub_8240A5F8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister f0{};
	PPCRegister temp{};
	// lfs f0,12(r3)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	f0.f64 = double(temp.f32);
	// lfs f13,24(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f12.f64 = double(temp.f32);
	// lfs f11,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f8.f64 = double(temp.f32);
	// lfs f7,32(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,0(r4)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(ctx.r4.u32 + 0, temp.u32);
	// stfs f0,4(r4)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r4.u32 + 4, temp.u32);
	// stfs f13,8(r4)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r4.u32 + 8, temp.u32);
	// stfs f12,12(r4)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r4.u32 + 12, temp.u32);
	// stfs f11,16(r4)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r4.u32 + 16, temp.u32);
	// stfs f10,20(r4)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(ctx.r4.u32 + 20, temp.u32);
	// stfs f9,24(r4)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(ctx.r4.u32 + 24, temp.u32);
	// stfs f8,28(r4)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(ctx.r4.u32 + 28, temp.u32);
	// stfs f7,32(r4)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(ctx.r4.u32 + 32, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A648"))) PPC_WEAK_FUNC(sub_8240A648);
PPC_FUNC_IMPL(__imp__sub_8240A648) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// lis r11,-32256
	r11.s64 = -2113929216;
	// lfs f0,2688(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// stfs f0,0(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 0, temp.u32);
	// stfs f0,4(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 4, temp.u32);
	// stfs f0,8(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 8, temp.u32);
	// stfs f0,12(r3)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r3.u32 + 12, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A668"))) PPC_WEAK_FUNC(sub_8240A668);
PPC_FUNC_IMPL(__imp__sub_8240A668) {
	PPC_FUNC_PROLOGUE();
	PPCRegister f0{};
	PPCRegister temp{};
	// lfs f0,4(r4)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f11,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,8(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * f0.f64));
	// lfs f10,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// lfs f5,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f10,f10,f0
	ctx.f10.f64 = double(float(ctx.f10.f64 * f0.f64));
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f13,0(r4)
	temp.u32 = PPC_LOAD_U32(ctx.r4.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// lfs f9,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,24(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// lfs f4,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f4.f64 = double(temp.f32);
	// lfs f7,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,32(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f3,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f11,f9,f13,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 + ctx.f11.f64));
	// fmadds f10,f8,f13,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f13.f64 + ctx.f10.f64));
	// fmadds f9,f4,f0,f5
	ctx.f9.f64 = double(float(ctx.f4.f64 * f0.f64 + ctx.f5.f64));
	// fmadds f0,f7,f12,f11
	f0.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f11.f64));
	// stfs f0,4(r5)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r5.u32 + 4, temp.u32);
	// fmadds f12,f6,f12,f10
	ctx.f12.f64 = double(float(ctx.f6.f64 * ctx.f12.f64 + ctx.f10.f64));
	// stfs f12,8(r5)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r5.u32 + 8, temp.u32);
	// fmadds f13,f3,f13,f9
	ctx.f13.f64 = double(float(ctx.f3.f64 * ctx.f13.f64 + ctx.f9.f64));
	// stfs f13,0(r5)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r5.u32 + 0, temp.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A6D0"))) PPC_WEAK_FUNC(sub_8240A6D0);
PPC_FUNC_IMPL(__imp__sub_8240A6D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister f0{};
	PPCRegister temp{};
	// li r8,0
	ctx.r8.s64 = 0;
	// cmpwi cr6,r6,4
	cr6.compare<int32_t>(ctx.r6.s32, 4, xer);
	// blt cr6,0x8240a88c
	if (cr6.getLT()) goto loc_8240A88C;
	// addi r11,r6,-4
	r11.s64 = ctx.r6.s64 + -4;
	// addi r10,r5,12
	ctx.r10.s64 = ctx.r5.s64 + 12;
	// rlwinm r11,r11,30,2,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 30) & 0x3FFFFFFF;
	// subf r7,r4,r5
	ctx.r7.s64 = ctx.r5.s64 - ctx.r4.s64;
	// addi r9,r11,1
	ctx.r9.s64 = r11.s64 + 1;
	// addi r11,r4,4
	r11.s64 = ctx.r4.s64 + 4;
	// rlwinm r8,r9,2,0,29
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 2) & 0xFFFFFFFC;
loc_8240A6F8:
	// lfs f13,0(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f13.f64 = double(temp.f32);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// lfs f11,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// lfs f12,-4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -4);
	ctx.f12.f64 = double(temp.f32);
	// fmuls f11,f13,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f11.f64));
	// lfs f10,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// lfs f5,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f10,f13,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f10.f64));
	// fmuls f5,f5,f12
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f12.f64));
	// lfs f0,4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f9,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// lfs f8,24(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// lfs f4,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f4.f64 = double(temp.f32);
	// lfs f7,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,32(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f3,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f11,f9,f0,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 * f0.f64 + ctx.f11.f64));
	// fmadds f10,f8,f12,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f10.f64));
	// fmadds f9,f4,f0,f5
	ctx.f9.f64 = double(float(ctx.f4.f64 * f0.f64 + ctx.f5.f64));
	// fmadds f12,f12,f7,f11
	ctx.f12.f64 = double(float(ctx.f12.f64 * ctx.f7.f64 + ctx.f11.f64));
	// stfsx f12,r11,r7
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, temp.u32);
	// fmadds f0,f6,f0,f10
	f0.f64 = double(float(ctx.f6.f64 * f0.f64 + ctx.f10.f64));
	// stfs f0,-4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + -4, temp.u32);
	// fmadds f13,f13,f3,f9
	ctx.f13.f64 = double(float(ctx.f13.f64 * ctx.f3.f64 + ctx.f9.f64));
	// stfs f13,-12(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + -12, temp.u32);
	// lfs f13,12(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 12);
	ctx.f13.f64 = double(temp.f32);
	// lfs f11,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// lfs f0,16(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 16);
	f0.f64 = double(temp.f32);
	// fmuls f11,f11,f13
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f13.f64));
	// lfs f10,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// lfs f5,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f10,f10,f13
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f13.f64));
	// fmuls f5,f5,f0
	ctx.f5.f64 = double(float(ctx.f5.f64 * f0.f64));
	// lfs f9,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// lfs f12,8(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 8);
	ctx.f12.f64 = double(temp.f32);
	// lfs f8,24(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// lfs f4,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f4.f64 = double(temp.f32);
	// lfs f7,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,32(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f3,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f11,f9,f0,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 * f0.f64 + ctx.f11.f64));
	// fmadds f10,f8,f12,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 * ctx.f12.f64 + ctx.f10.f64));
	// fmadds f9,f4,f13,f5
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f13.f64 + ctx.f5.f64));
	// fmadds f13,f12,f7,f11
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f7.f64 + ctx.f11.f64));
	// stfs f13,4(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// fmadds f0,f6,f0,f10
	f0.f64 = double(float(ctx.f6.f64 * f0.f64 + ctx.f10.f64));
	// stfs f0,8(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// fmadds f12,f3,f12,f9
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f9.f64));
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lfs f0,24(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 24);
	f0.f64 = double(temp.f32);
	// lfs f11,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// lfs f9,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f11,f11,f0
	ctx.f11.f64 = double(float(ctx.f11.f64 * f0.f64));
	// fmuls f9,f9,f0
	ctx.f9.f64 = double(float(ctx.f9.f64 * f0.f64));
	// lfs f13,28(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 28);
	ctx.f13.f64 = double(temp.f32);
	// lfs f10,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f10.f64 = double(temp.f32);
	// lfs f12,20(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 20);
	ctx.f12.f64 = double(temp.f32);
	// lfs f7,24(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f7.f64 = double(temp.f32);
	// lfs f8,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f8.f64 = double(temp.f32);
	// lfs f6,32(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	ctx.f6.f64 = double(temp.f32);
	// fmadds f11,f10,f13,f11
	ctx.f11.f64 = double(float(ctx.f10.f64 * ctx.f13.f64 + ctx.f11.f64));
	// fmadds f10,f7,f12,f9
	ctx.f10.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + ctx.f9.f64));
	// lfs f9,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f9.f64 = double(temp.f32);
	// fmuls f9,f9,f13
	ctx.f9.f64 = double(float(ctx.f9.f64 * ctx.f13.f64));
	// lfs f7,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f7.f64 = double(temp.f32);
	// fmadds f11,f12,f8,f11
	ctx.f11.f64 = double(float(ctx.f12.f64 * ctx.f8.f64 + ctx.f11.f64));
	// lfs f8,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f8.f64 = double(temp.f32);
	// fmadds f13,f6,f13,f10
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f10.f64));
	// stfs f11,16(r10)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(ctx.r10.u32 + 16, temp.u32);
	// fmadds f0,f8,f0,f9
	f0.f64 = double(float(ctx.f8.f64 * f0.f64 + ctx.f9.f64));
	// stfs f13,20(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 20, temp.u32);
	// fmadds f0,f7,f12,f0
	f0.f64 = double(float(ctx.f7.f64 * ctx.f12.f64 + f0.f64));
	// stfs f0,12(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 12, temp.u32);
	// lfs f0,32(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 32);
	f0.f64 = double(temp.f32);
	// lfs f13,40(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 40);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,36(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 36);
	ctx.f12.f64 = double(temp.f32);
	// addi r11,r11,48
	r11.s64 = r11.s64 + 48;
	// lfs f11,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f10.f64 = double(temp.f32);
	// lfs f9,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f9.f64 = double(temp.f32);
	// lfs f5,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f11,f11,f12
	ctx.f11.f64 = double(float(ctx.f11.f64 * ctx.f12.f64));
	// fmuls f10,f10,f12
	ctx.f10.f64 = double(float(ctx.f10.f64 * ctx.f12.f64));
	// lfs f8,24(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// fmuls f5,f5,f13
	ctx.f5.f64 = double(float(ctx.f5.f64 * ctx.f13.f64));
	// lfs f4,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f4.f64 = double(temp.f32);
	// lfs f7,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,32(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	ctx.f6.f64 = double(temp.f32);
	// lfs f3,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f11,f9,f13,f11
	ctx.f11.f64 = double(float(ctx.f9.f64 * ctx.f13.f64 + ctx.f11.f64));
	// fmadds f10,f8,f0,f10
	ctx.f10.f64 = double(float(ctx.f8.f64 * f0.f64 + ctx.f10.f64));
	// fmadds f9,f4,f12,f5
	ctx.f9.f64 = double(float(ctx.f4.f64 * ctx.f12.f64 + ctx.f5.f64));
	// fmadds f12,f0,f7,f11
	ctx.f12.f64 = double(float(f0.f64 * ctx.f7.f64 + ctx.f11.f64));
	// stfs f12,28(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 28, temp.u32);
	// fmadds f13,f6,f13,f10
	ctx.f13.f64 = double(float(ctx.f6.f64 * ctx.f13.f64 + ctx.f10.f64));
	// stfs f13,32(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 32, temp.u32);
	// fmadds f0,f3,f0,f9
	f0.f64 = double(float(ctx.f3.f64 * f0.f64 + ctx.f9.f64));
	// stfs f0,24(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 24, temp.u32);
	// addi r10,r10,48
	ctx.r10.s64 = ctx.r10.s64 + 48;
	// bne cr6,0x8240a6f8
	if (!cr6.getEQ()) goto loc_8240A6F8;
loc_8240A88C:
	// cmplw cr6,r8,r6
	cr6.compare<uint32_t>(ctx.r8.u32, ctx.r6.u32, xer);
	// bgelr cr6
	if (!cr6.getLT()) return;
	// rlwinm r11,r8,1,0,30
	r11.u64 = __builtin_rotateleft64(ctx.r8.u32 | (ctx.r8.u64 << 32), 1) & 0xFFFFFFFE;
	// subf r9,r8,r6
	ctx.r9.s64 = ctx.r6.s64 - ctx.r8.s64;
	// add r11,r8,r11
	r11.u64 = ctx.r8.u64 + r11.u64;
	// subf r7,r4,r5
	ctx.r7.s64 = ctx.r5.s64 - ctx.r4.s64;
	// rlwinm r11,r11,2,0,29
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// add r8,r11,r4
	ctx.r8.u64 = r11.u64 + ctx.r4.u64;
	// add r10,r11,r5
	ctx.r10.u64 = r11.u64 + ctx.r5.u64;
	// addi r11,r8,4
	r11.s64 = ctx.r8.s64 + 4;
loc_8240A8B4:
	// lfs f0,4(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 4);
	f0.f64 = double(temp.f32);
	// addi r9,r9,-1
	ctx.r9.s64 = ctx.r9.s64 + -1;
	// lfs f11,20(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 20);
	ctx.f11.f64 = double(temp.f32);
	// lfs f10,32(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 32);
	ctx.f10.f64 = double(temp.f32);
	// fmuls f11,f0,f11
	ctx.f11.f64 = double(float(f0.f64 * ctx.f11.f64));
	// lfs f5,8(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 8);
	ctx.f5.f64 = double(temp.f32);
	// fmuls f10,f0,f10
	ctx.f10.f64 = double(float(f0.f64 * ctx.f10.f64));
	// fmuls f0,f5,f0
	f0.f64 = double(float(ctx.f5.f64 * f0.f64));
	// lfs f13,-4(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + -4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f9,12(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 12);
	ctx.f9.f64 = double(temp.f32);
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// lfs f8,24(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 24);
	ctx.f8.f64 = double(temp.f32);
	// lfs f4,0(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	ctx.f4.f64 = double(temp.f32);
	// lfs f12,0(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// lfs f7,16(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 16);
	ctx.f7.f64 = double(temp.f32);
	// lfs f6,28(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 28);
	ctx.f6.f64 = double(temp.f32);
	// lfs f3,4(r3)
	temp.u32 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	ctx.f3.f64 = double(temp.f32);
	// fmadds f11,f13,f9,f11
	ctx.f11.f64 = double(float(ctx.f13.f64 * ctx.f9.f64 + ctx.f11.f64));
	// fmadds f10,f13,f8,f10
	ctx.f10.f64 = double(float(ctx.f13.f64 * ctx.f8.f64 + ctx.f10.f64));
	// fmadds f9,f13,f4,f0
	ctx.f9.f64 = double(float(ctx.f13.f64 * ctx.f4.f64 + f0.f64));
	// fmadds f0,f12,f7,f11
	f0.f64 = double(float(ctx.f12.f64 * ctx.f7.f64 + ctx.f11.f64));
	// stfsx f0,r11,r7
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + ctx.r7.u32, temp.u32);
	// fmadds f13,f12,f6,f10
	ctx.f13.f64 = double(float(ctx.f12.f64 * ctx.f6.f64 + ctx.f10.f64));
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// fmadds f12,f3,f12,f9
	ctx.f12.f64 = double(float(ctx.f3.f64 * ctx.f12.f64 + ctx.f9.f64));
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// bne cr6,0x8240a8b4
	if (!cr6.getEQ()) goto loc_8240A8B4;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A930"))) PPC_WEAK_FUNC(sub_8240A930);
PPC_FUNC_IMPL(__imp__sub_8240A930) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// mr r3,r4
	ctx.r3.u64 = ctx.r4.u64;
	// bl 0x8239c368
	sub_8239C368(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8239c338
	sub_8239C338(ctx, base);
	// lis r11,-32250
	r11.s64 = -2113536000;
	// addi r3,r11,11952
	ctx.r3.s64 = r11.s64 + 11952;
	// bl 0x8239c308
	sub_8239C308(ctx, base);
	// li r3,4
	ctx.r3.s64 = 4;
	// bl 0x8239c1e8
	sub_8239C1E8(ctx, base);
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8239c2a0
	sub_8239C2A0(ctx, base);
	// lis r11,-31991
	r11.s64 = -2096562176;
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,13356(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 13356);
	// bl 0x82192f50
	sub_82192F50(ctx, base);
	// lis r11,-31987
	r11.s64 = -2096300032;
	// li r4,16
	ctx.r4.s64 = 16;
	// addi r3,r11,-16196
	ctx.r3.s64 = r11.s64 + -16196;
	// bl 0x823ada60
	sub_823ADA60(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240A9A8"))) PPC_WEAK_FUNC(sub_8240A9A8);
PPC_FUNC_IMPL(__imp__sub_8240A9A8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// clrlwi r10,r6,24
	ctx.r10.u64 = ctx.r6.u32 & 0xFF;
	// mr r11,r5
	r11.u64 = ctx.r5.u64;
	// rlwimi r3,r10,8,0,23
	ctx.r3.u64 = (__builtin_rotateleft32(ctx.r10.u32, 8) & 0xFFFFFF00) | (ctx.r3.u64 & 0xFFFFFFFF000000FF);
	// cmplwi cr6,r10,255
	cr6.compare<uint32_t>(ctx.r10.u32, 255, xer);
	// rlwimi r4,r3,8,0,23
	ctx.r4.u64 = (__builtin_rotateleft32(ctx.r3.u32, 8) & 0xFFFFFF00) | (ctx.r4.u64 & 0xFFFFFFFF000000FF);
	// lis r10,-31987
	ctx.r10.s64 = -2096300032;
	// rlwimi r11,r4,8,0,23
	r11.u64 = (__builtin_rotateleft32(ctx.r4.u32, 8) & 0xFFFFFF00) | (r11.u64 & 0xFFFFFFFF000000FF);
	// lis r31,-31991
	r31.s64 = -2096562176;
	// li r4,1
	ctx.r4.s64 = 1;
	// stw r11,-16164(r10)
	PPC_STORE_U32(ctx.r10.u32 + -16164, r11.u32);
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bne cr6,0x8240aa08
	if (!cr6.getEQ()) goto loc_8240AA08;
	// bl 0x821936a0
	sub_821936A0(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x821936e0
	sub_821936E0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82192fe8
	sub_82192FE8(ctx, base);
	// b 0x8240aa3c
	goto loc_8240AA3C;
loc_8240AA08:
	// bl 0x82192fe8
	sub_82192FE8(ctx, base);
	// li r4,6
	ctx.r4.s64 = 6;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82193108
	sub_82193108(ctx, base);
	// li r4,7
	ctx.r4.s64 = 7;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82193198
	sub_82193198(ctx, base);
	// li r4,1
	ctx.r4.s64 = 1;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x821936a0
	sub_821936A0(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x821936e0
	sub_821936E0(ctx, base);
loc_8240AA3C:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240AA50"))) PPC_WEAK_FUNC(sub_8240AA50);
PPC_FUNC_IMPL(__imp__sub_8240AA50) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// addi r31,r11,-16196
	r31.s64 = r11.s64 + -16196;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// mr r29,r5
	r29.u64 = ctx.r5.u64;
	// li r5,3
	ctx.r5.s64 = 3;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8239bf98
	sub_8239BF98(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,4(r28)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r28.u32 + 4);
	f0.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f13,8(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f12,0(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lfs f0,4(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,8(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f13,4(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,4(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,8(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c170
	sub_8239C170(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_8240AC28"))) PPC_WEAK_FUNC(sub_8240AC28);
PPC_FUNC_IMPL(__imp__sub_8240AC28) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stwu r1,-128(r1)
	ea = -128 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// addi r31,r11,-16196
	r31.s64 = r11.s64 + -16196;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// mr r28,r5
	r28.u64 = ctx.r5.u64;
	// li r5,1
	ctx.r5.s64 = 1;
	// li r4,4
	ctx.r4.s64 = 4;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8239bf98
	sub_8239BF98(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,4(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c170
	sub_8239C170(ctx, base);
	// addi r1,r1,128
	ctx.r1.s64 = ctx.r1.s64 + 128;
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_8240AD30"))) PPC_WEAK_FUNC(sub_8240AD30);
PPC_FUNC_IMPL(__imp__sub_8240AD30) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed13c
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// addi r31,r11,-16196
	r31.s64 = r11.s64 + -16196;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r5,12
	ctx.r5.s64 = 12;
	// li r4,2
	ctx.r4.s64 = 2;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8239bf98
	sub_8239BF98(ctx, base);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,4(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lfs f0,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f13,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,4(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,8(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,4(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,4(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f13,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,4(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,8(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,4(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,4(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f13,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,4(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,8(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,4(r30)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,4(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lwz r11,32(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,4
	ctx.r10.s64 = ctx.r10.s64 + 4;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// lfs f0,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	f0.f64 = double(temp.f32);
	// lfs f13,4(r29)
	temp.u32 = PPC_LOAD_U32(r29.u32 + 4);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r10)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(ctx.r10.u32 + 0, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// stfs f13,4(r10)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(ctx.r10.u32 + 4, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,8(r10)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r10.u32 + 8, temp.u32);
	// lwz r10,0(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r10,r10,12
	ctx.r10.s64 = ctx.r10.s64 + 12;
	// stw r10,0(r31)
	PPC_STORE_U32(r31.u32 + 0, ctx.r10.u32);
	// stw r11,0(r10)
	PPC_STORE_U32(ctx.r10.u32 + 0, r11.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8239c170
	sub_8239C170(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// b 0x823ed18c
	return;
}

__attribute__((alias("__imp__sub_8240B3D0"))) PPC_WEAK_FUNC(sub_8240B3D0);
PPC_FUNC_IMPL(__imp__sub_8240B3D0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f30{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed12c
	// stfd f30,-80(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -80, f30.u64);
	// stfd f31,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, f31.u64);
	// stwu r1,-352(r1)
	ea = -352 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r31,r7
	r31.u64 = ctx.r7.u64;
	// fmr f31,f1
	f31.f64 = ctx.f1.f64;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r27,r4
	r27.u64 = ctx.r4.u64;
	// mr r26,r5
	r26.u64 = ctx.r5.u64;
	// mr r29,r6
	r29.u64 = ctx.r6.u64;
	// mr r28,r9
	r28.u64 = ctx.r9.u64;
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8240b548
	if (cr6.getEQ()) goto loc_8240B548;
	// addi r5,r1,224
	ctx.r5.s64 = ctx.r1.s64 + 224;
	// bl 0x8238c4e0
	sub_8238C4E0(ctx, base);
	// lis r11,-32256
	r11.s64 = -2113929216;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// lfs f0,2692(r11)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2692);
	f0.f64 = double(temp.f32);
	// fmuls f30,f31,f0
	f30.f64 = double(float(f31.f64 * f0.f64));
	// fmr f1,f30
	ctx.f1.f64 = f30.f64;
	// bl 0x8238c580
	sub_8238C580(ctx, base);
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x8238c750
	sub_8238C750(ctx, base);
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// mr r4,r26
	ctx.r4.u64 = r26.u64;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8238c4e0
	sub_8238C4E0(ctx, base);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x8238c580
	sub_8238C580(ctx, base);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// bl 0x8238c750
	sub_8238C750(ctx, base);
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8238c4e0
	sub_8238C4E0(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// fmr f1,f30
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f30.f64;
	// bl 0x8238c580
	sub_8238C580(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// bl 0x8238c750
	sub_8238C750(ctx, base);
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x8238c580
	sub_8238C580(ctx, base);
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// addi r3,r1,176
	ctx.r3.s64 = ctx.r1.s64 + 176;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x8238c580
	sub_8238C580(ctx, base);
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// addi r3,r1,128
	ctx.r3.s64 = ctx.r1.s64 + 128;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// bl 0x8238c580
	sub_8238C580(ctx, base);
	// addi r31,r31,-1
	r31.s64 = r31.s64 + -1;
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// addi r4,r1,224
	ctx.r4.s64 = ctx.r1.s64 + 224;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// bl 0x8240b3d0
	sub_8240B3D0(ctx, base);
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,224
	ctx.r5.s64 = ctx.r1.s64 + 224;
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8240b3d0
	sub_8240B3D0(ctx, base);
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,176
	ctx.r5.s64 = ctx.r1.s64 + 176;
	// addi r4,r1,128
	ctx.r4.s64 = ctx.r1.s64 + 128;
	// mr r3,r26
	ctx.r3.u64 = r26.u64;
	// bl 0x8240b3d0
	sub_8240B3D0(ctx, base);
	// mr r9,r28
	ctx.r9.u64 = r28.u64;
	// mr r7,r31
	ctx.r7.u64 = r31.u64;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r5,r1,128
	ctx.r5.s64 = ctx.r1.s64 + 128;
	// addi r4,r1,176
	ctx.r4.s64 = ctx.r1.s64 + 176;
	// addi r3,r1,224
	ctx.r3.s64 = ctx.r1.s64 + 224;
	// bl 0x8240b3d0
	sub_8240B3D0(ctx, base);
	// b 0x8240b71c
	goto loc_8240B71C;
loc_8240B548:
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// addi r31,r1,80
	r31.s64 = ctx.r1.s64 + 80;
	// li r25,3
	r25.s64 = 3;
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// lwz r11,4(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// stw r11,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, r11.u32);
	// lwz r11,8(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 8);
	// stw r11,88(r1)
	PPC_STORE_U32(ctx.r1.u32 + 88, r11.u32);
	// lwz r11,0(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 0);
	// stw r11,92(r1)
	PPC_STORE_U32(ctx.r1.u32 + 92, r11.u32);
	// lwz r11,4(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 4);
	// stw r11,96(r1)
	PPC_STORE_U32(ctx.r1.u32 + 96, r11.u32);
	// lwz r11,8(r27)
	r11.u64 = PPC_LOAD_U32(r27.u32 + 8);
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
	// lwz r11,0(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 0);
	// stw r11,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r11.u32);
	// lwz r11,4(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 4);
	// stw r11,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r11.u32);
	// lwz r11,8(r26)
	r11.u64 = PPC_LOAD_U32(r26.u32 + 8);
	// stw r11,112(r1)
	PPC_STORE_U32(ctx.r1.u32 + 112, r11.u32);
loc_8240B598:
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8238c4e0
	sub_8238C4E0(ctx, base);
	// addic. r25,r25,-1
	xer.ca = r25.u32 > 0;
	r25.s64 = r25.s64 + -1;
	cr0.compare<int32_t>(r25.s32, 0, xer);
	// addi r31,r31,12
	r31.s64 = r31.s64 + 12;
	// bne 0x8240b598
	if (!cr0.getEQ()) goto loc_8240B598;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r31,r11,-16196
	r31.s64 = r11.s64 + -16196;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8239c0d0
	sub_8239C0D0(ctx, base);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// lfs f0,84(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	f0.f64 = double(temp.f32);
	// lwz r10,32(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 32);
	// lfs f13,88(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 88);
	ctx.f13.f64 = double(temp.f32);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// lfs f12,80(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 8, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// beq cr6,0x8240b63c
	if (cr6.getEQ()) goto loc_8240B63C;
	// lfs f0,4(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 8, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_8240B63C:
	// lfs f0,96(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	f0.f64 = double(temp.f32);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// lfs f13,100(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 100);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,92(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 92);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 8, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// beq cr6,0x8240b6ac
	if (cr6.getEQ()) goto loc_8240B6AC;
	// lfs f0,4(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 8, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_8240B6AC:
	// lfs f0,108(r1)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 108);
	f0.f64 = double(temp.f32);
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// lfs f13,112(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 112);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,104(r1)
	temp.u32 = PPC_LOAD_U32(ctx.r1.u32 + 104);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 8, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// beq cr6,0x8240b71c
	if (cr6.getEQ()) goto loc_8240B71C;
	// lfs f0,4(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 4);
	f0.f64 = double(temp.f32);
	// lfs f13,8(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 8);
	ctx.f13.f64 = double(temp.f32);
	// lfs f12,0(r26)
	temp.u32 = PPC_LOAD_U32(r26.u32 + 0);
	ctx.f12.f64 = double(temp.f32);
	// stfs f12,0(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 0, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f0,4(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 4, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// stfs f13,8(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 8, temp.u32);
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// addi r11,r11,12
	r11.s64 = r11.s64 + 12;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
loc_8240B71C:
	// addi r1,r1,352
	ctx.r1.s64 = ctx.r1.s64 + 352;
	// lfd f30,-80(r1)
	ctx.fpscr.disableFlushMode();
	f30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -80);
	// lfd f31,-72(r1)
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -72);
	// b 0x823ed17c
	return;
}

__attribute__((alias("__imp__sub_8240B730"))) PPC_WEAK_FUNC(sub_8240B730);
PPC_FUNC_IMPL(__imp__sub_8240B730) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister f31{};
	PPCRegister temp{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed138
	// stfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	PPC_STORE_U64(ctx.r1.u32 + -48, f31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32256
	r11.s64 = -2113929216;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// li r9,1
	ctx.r9.s64 = 1;
	// rlwinm r10,r30,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(r30.u32 | (r30.u64 << 32), 1) & 0xFFFFFFFE;
	// mr r29,r3
	r29.u64 = ctx.r3.u64;
	// lfs f0,2688(r11)
	temp.u32 = PPC_LOAD_U32(r11.u32 + 2688);
	f0.f64 = double(temp.f32);
	// lis r11,-31987
	r11.s64 = -2096300032;
	// li r4,4
	ctx.r4.s64 = 4;
	// stfs f0,80(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 80, temp.u32);
	// addi r28,r11,-16196
	r28.s64 = r11.s64 + -16196;
	// stfs f0,84(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 84, temp.u32);
	// stfs f0,88(r1)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(ctx.r1.u32 + 88, temp.u32);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// slw r11,r9,r10
	r11.u64 = ctx.r10.u8 & 0x20 ? 0 : (ctx.r9.u32 << (ctx.r10.u8 & 0x3F));
	// rlwinm r5,r11,3,0,28
	ctx.r5.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 3) & 0xFFFFFFF8;
	// bl 0x8239bf98
	sub_8239BF98(ctx, base);
	// lis r11,-32015
	r11.s64 = -2098135040;
	// lis r10,-32256
	ctx.r10.s64 = -2113929216;
	// addi r31,r11,-14092
	r31.s64 = r11.s64 + -14092;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// addi r4,r31,24
	ctx.r4.s64 = r31.s64 + 24;
	// lfs f31,2776(r10)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(ctx.r10.u32 + 2776);
	f31.f64 = double(temp.f32);
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// fmr f1,f31
	ctx.f1.f64 = f31.f64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r3,r11,12
	ctx.r3.s64 = r11.s64 + 12;
	// bl 0x8240b3d0
	sub_8240B3D0(ctx, base);
	// addi r10,r31,24
	ctx.r10.s64 = r31.s64 + 24;
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r4,r10,12
	ctx.r4.s64 = ctx.r10.s64 + 12;
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// bl 0x8240b3d0
	sub_8240B3D0(ctx, base);
	// addi r10,r31,24
	ctx.r10.s64 = r31.s64 + 24;
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r4,r10,24
	ctx.r4.s64 = ctx.r10.s64 + 24;
	// addi r3,r11,36
	ctx.r3.s64 = r11.s64 + 36;
	// bl 0x8240b3d0
	sub_8240B3D0(ctx, base);
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// mr r5,r31
	ctx.r5.u64 = r31.u64;
	// addi r4,r11,36
	ctx.r4.s64 = r11.s64 + 36;
	// bl 0x8240b3d0
	sub_8240B3D0(ctx, base);
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// addi r5,r31,12
	ctx.r5.s64 = r31.s64 + 12;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// addi r3,r31,24
	ctx.r3.s64 = r31.s64 + 24;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r4,r11,12
	ctx.r4.s64 = r11.s64 + 12;
	// bl 0x8240b3d0
	sub_8240B3D0(ctx, base);
	// addi r10,r31,24
	ctx.r10.s64 = r31.s64 + 24;
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// addi r5,r31,12
	ctx.r5.s64 = r31.s64 + 12;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r4,r10,24
	ctx.r4.s64 = ctx.r10.s64 + 24;
	// addi r3,r11,12
	ctx.r3.s64 = r11.s64 + 12;
	// bl 0x8240b3d0
	sub_8240B3D0(ctx, base);
	// addi r10,r31,24
	ctx.r10.s64 = r31.s64 + 24;
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// addi r5,r31,12
	ctx.r5.s64 = r31.s64 + 12;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r4,r10,36
	ctx.r4.s64 = ctx.r10.s64 + 36;
	// addi r3,r11,24
	ctx.r3.s64 = r11.s64 + 24;
	// bl 0x8240b3d0
	sub_8240B3D0(ctx, base);
	// addi r11,r31,24
	r11.s64 = r31.s64 + 24;
	// addi r5,r31,12
	ctx.r5.s64 = r31.s64 + 12;
	// fmr f1,f31
	ctx.fpscr.disableFlushMode();
	ctx.f1.f64 = f31.f64;
	// addi r4,r31,24
	ctx.r4.s64 = r31.s64 + 24;
	// addi r9,r1,80
	ctx.r9.s64 = ctx.r1.s64 + 80;
	// mr r7,r30
	ctx.r7.u64 = r30.u64;
	// mr r6,r29
	ctx.r6.u64 = r29.u64;
	// addi r3,r11,36
	ctx.r3.s64 = r11.s64 + 36;
	// bl 0x8240b3d0
	sub_8240B3D0(ctx, base);
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x8239c170
	sub_8239C170(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lfd f31,-48(r1)
	ctx.fpscr.disableFlushMode();
	f31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -48);
	// b 0x823ed188
	return;
}

__attribute__((alias("__imp__sub_8240B8D8"))) PPC_WEAK_FUNC(sub_8240B8D8);
PPC_FUNC_IMPL(__imp__sub_8240B8D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r31,-31991
	r31.s64 = -2096562176;
	// li r4,37
	ctx.r4.s64 = 37;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82192f80
	sub_82192F80(ctx, base);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// li r3,0
	ctx.r3.s64 = 0;
	// bl 0x8240b730
	sub_8240B730(ctx, base);
	// li r4,0
	ctx.r4.s64 = 0;
	// lwz r3,13356(r31)
	ctx.r3.u64 = PPC_LOAD_U32(r31.u32 + 13356);
	// bl 0x82192f80
	sub_82192F80(ctx, base);
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240B930"))) PPC_WEAK_FUNC(sub_8240B930);
PPC_FUNC_IMPL(__imp__sub_8240B930) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	// li r11,0
	r11.s64 = 0;
	// b 0x8240b958
	goto loc_8240B958;
loc_8240B938:
	// rlwinm r11,r11,4,0,27
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// addi r3,r3,1
	ctx.r3.s64 = ctx.r3.s64 + 1;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm. r10,r11,0,0,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8240b958
	if (cr0.getEQ()) goto loc_8240B958;
	// rlwinm r9,r10,8,24,31
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFF;
	// or r10,r9,r10
	ctx.r10.u64 = ctx.r9.u64 | ctx.r10.u64;
	// xor r11,r10,r11
	r11.u64 = ctx.r10.u64 ^ r11.u64;
loc_8240B958:
	// lbz r10,0(r3)
	ctx.r10.u64 = PPC_LOAD_U8(ctx.r3.u32 + 0);
	// extsb. r10,r10
	ctx.r10.s64 = ctx.r10.s8;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// bne 0x8240b938
	if (!cr0.getEQ()) goto loc_8240B938;
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240B970"))) PPC_WEAK_FUNC(sub_8240B970);
PPC_FUNC_IMPL(__imp__sub_8240B970) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// li r11,0
	r11.s64 = 0;
	// li r9,0
	ctx.r9.s64 = 0;
	// cmplwi cr6,r4,0
	cr6.compare<uint32_t>(ctx.r4.u32, 0, xer);
	// beq cr6,0x8240b9b0
	if (cr6.getEQ()) goto loc_8240B9B0;
loc_8240B980:
	// lbzx r8,r9,r3
	ctx.r8.u64 = PPC_LOAD_U8(ctx.r9.u32 + ctx.r3.u32);
	// rlwinm r10,r11,4,0,27
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 4) & 0xFFFFFFF0;
	// extsb r11,r8
	r11.s64 = ctx.r8.s8;
	// add r11,r11,r10
	r11.u64 = r11.u64 + ctx.r10.u64;
	// rlwinm. r10,r11,0,0,3
	ctx.r10.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xF0000000;
	cr0.compare<int32_t>(ctx.r10.s32, 0, xer);
	// beq 0x8240b9a4
	if (cr0.getEQ()) goto loc_8240B9A4;
	// rlwinm r8,r10,8,24,31
	ctx.r8.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 8) & 0xFF;
	// or r10,r8,r10
	ctx.r10.u64 = ctx.r8.u64 | ctx.r10.u64;
	// xor r11,r10,r11
	r11.u64 = ctx.r10.u64 ^ r11.u64;
loc_8240B9A4:
	// addi r9,r9,1
	ctx.r9.s64 = ctx.r9.s64 + 1;
	// cmplw cr6,r9,r4
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r4.u32, xer);
	// blt cr6,0x8240b980
	if (cr6.getLT()) goto loc_8240B980;
loc_8240B9B0:
	// mr r3,r11
	ctx.r3.u64 = r11.u64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240B9B8"))) PPC_WEAK_FUNC(sub_8240B9B8);
PPC_FUNC_IMPL(__imp__sub_8240B9B8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	// cmplwi cr6,r4,2
	cr6.compare<uint32_t>(ctx.r4.u32, 2, xer);
	// beq cr6,0x8240ba70
	if (cr6.getEQ()) goto loc_8240BA70;
	// cmplwi cr6,r4,4
	cr6.compare<uint32_t>(ctx.r4.u32, 4, xer);
	// beq cr6,0x8240ba48
	if (cr6.getEQ()) goto loc_8240BA48;
	// cmplwi cr6,r4,8
	cr6.compare<uint32_t>(ctx.r4.u32, 8, xer);
	// bnelr cr6
	if (!cr6.getEQ()) return;
	// li r12,255
	r12.s64 = 255;
	// ld r11,0(r3)
	r11.u64 = PPC_LOAD_U64(ctx.r3.u32 + 0);
	// rldicr r12,r12,48,15
	r12.u64 = __builtin_rotateleft64(r12.u64, 48) & 0xFFFF000000000000;
	// rldicl r9,r11,48,16
	ctx.r9.u64 = __builtin_rotateleft64(r11.u64, 48) & 0xFFFFFFFFFFFF;
	// and r10,r11,r12
	ctx.r10.u64 = r11.u64 & r12.u64;
	// li r12,255
	r12.s64 = 255;
	// rlwinm r8,r11,0,16,23
	ctx.r8.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFF00;
	// rldicr r7,r11,16,47
	ctx.r7.u64 = __builtin_rotateleft64(r11.u64, 16) & 0xFFFFFFFFFFFF0000;
	// rldicr r12,r12,40,23
	r12.u64 = __builtin_rotateleft64(r12.u64, 40) & 0xFFFFFF0000000000;
	// or r10,r10,r9
	ctx.r10.u64 = ctx.r10.u64 | ctx.r9.u64;
	// or r9,r8,r7
	ctx.r9.u64 = ctx.r8.u64 | ctx.r7.u64;
	// and r8,r11,r12
	ctx.r8.u64 = r11.u64 & r12.u64;
	// li r12,255
	r12.s64 = 255;
	// rlwinm r7,r11,0,8,15
	ctx.r7.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFF0000;
	// rldicl r10,r10,48,16
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u64, 48) & 0xFFFFFFFFFFFF;
	// rldicr r9,r9,16,47
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u64, 16) & 0xFFFFFFFFFFFF0000;
	// rldicr r12,r12,32,31
	r12.u64 = __builtin_rotateleft64(r12.u64, 32) & 0xFFFFFFFF00000000;
	// or r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 | ctx.r8.u64;
	// or r9,r9,r7
	ctx.r9.u64 = ctx.r9.u64 | ctx.r7.u64;
	// and r8,r11,r12
	ctx.r8.u64 = r11.u64 & r12.u64;
	// rlwinm r11,r11,0,0,7
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFF000000;
	// rldicl r10,r10,48,16
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u64, 48) & 0xFFFFFFFFFFFF;
	// rldicr r9,r9,16,47
	ctx.r9.u64 = __builtin_rotateleft64(ctx.r9.u64, 16) & 0xFFFFFFFFFFFF0000;
	// or r10,r10,r8
	ctx.r10.u64 = ctx.r10.u64 | ctx.r8.u64;
	// or r11,r9,r11
	r11.u64 = ctx.r9.u64 | r11.u64;
	// rldicl r10,r10,56,8
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u64, 56) & 0xFFFFFFFFFFFFFF;
	// rldicr r11,r11,8,55
	r11.u64 = __builtin_rotateleft64(r11.u64, 8) & 0xFFFFFFFFFFFFFF00;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// std r11,0(r3)
	PPC_STORE_U64(ctx.r3.u32 + 0, r11.u64);
	// blr 
	return;
loc_8240BA48:
	// lwz r11,0(r3)
	r11.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
	// mr r9,r11
	ctx.r9.u64 = r11.u64;
	// rlwimi r10,r11,16,16,31
	ctx.r10.u64 = (__builtin_rotateleft32(r11.u32, 16) & 0xFFFF) | (ctx.r10.u64 & 0xFFFFFFFFFFFF0000);
	// rlwimi r9,r11,16,0,15
	ctx.r9.u64 = (__builtin_rotateleft32(r11.u32, 16) & 0xFFFF0000) | (ctx.r9.u64 & 0xFFFFFFFF0000FFFF);
	// rlwinm r11,r10,24,16,31
	r11.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 24) & 0xFFFF;
	// rlwinm r10,r9,8,0,15
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r9.u32 | (ctx.r9.u64 << 32), 8) & 0xFFFF0000;
	// or r11,r11,r10
	r11.u64 = r11.u64 | ctx.r10.u64;
	// stw r11,0(r3)
	PPC_STORE_U32(ctx.r3.u32 + 0, r11.u32);
	// blr 
	return;
loc_8240BA70:
	// lhz r11,0(r3)
	r11.u64 = PPC_LOAD_U16(ctx.r3.u32 + 0);
	// rotlwi r10,r11,8
	ctx.r10.u64 = __builtin_rotateleft32(r11.u32, 8);
	// rlwinm r11,r11,24,8,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 24) & 0xFFFFFF;
	// clrlwi r10,r10,16
	ctx.r10.u64 = ctx.r10.u32 & 0xFFFF;
	// or r11,r10,r11
	r11.u64 = ctx.r10.u64 | r11.u64;
	// sth r11,0(r3)
	PPC_STORE_U16(ctx.r3.u32 + 0, r11.u16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240BA90"))) PPC_WEAK_FUNC(sub_8240BA90);
PPC_FUNC_IMPL(__imp__sub_8240BA90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x82408118
	sub_82408118(ctx, base);
	// ld r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U64(ctx.r1.u32 + 80);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240BAB8"))) PPC_WEAK_FUNC(sub_8240BAB8);
PPC_FUNC_IMPL(__imp__sub_8240BAB8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lhz r10,0(r4)
	ctx.r10.u64 = PPC_LOAD_U16(ctx.r4.u32 + 0);
	// clrlwi r11,r3,16
	r11.u64 = ctx.r3.u32 & 0xFFFF;
	// subf r3,r10,r11
	ctx.r3.s64 = r11.s64 - ctx.r10.s64;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240BAC8"))) PPC_WEAK_FUNC(sub_8240BAC8);
PPC_FUNC_IMPL(__imp__sub_8240BAC8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// stwu r1,-160(r1)
	ea = -160 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// addi r11,r5,-1
	r11.s64 = ctx.r5.s64 + -1;
	// mr r25,r3
	r25.u64 = ctx.r3.u64;
	// mullw r11,r11,r30
	r11.s64 = int64_t(r11.s32) * int64_t(r30.s32);
	// add r27,r11,r4
	r27.u64 = r11.u64 + ctx.r4.u64;
	// mr r24,r7
	r24.u64 = ctx.r7.u64;
	// mr r29,r4
	r29.u64 = ctx.r4.u64;
	// cmplw cr6,r4,r27
	cr6.compare<uint32_t>(ctx.r4.u32, r27.u32, xer);
	// bgt cr6,0x8240bb5c
	if (cr6.getGT()) goto loc_8240BB5C;
loc_8240BAF8:
	// rlwinm. r28,r5,31,1,31
	r28.u64 = __builtin_rotateleft64(ctx.r5.u32 | (ctx.r5.u64 << 32), 31) & 0x7FFFFFFF;
	cr0.compare<int32_t>(r28.s32, 0, xer);
	// beq 0x8240bb70
	if (cr0.getEQ()) goto loc_8240BB70;
	// clrlwi. r26,r5,31
	r26.u64 = ctx.r5.u32 & 0x1;
	cr0.compare<int32_t>(r26.s32, 0, xer);
	// mr r11,r28
	r11.u64 = r28.u64;
	// bne 0x8240bb10
	if (!cr0.getEQ()) goto loc_8240BB10;
	// addi r11,r28,-1
	r11.s64 = r28.s64 + -1;
loc_8240BB10:
	// mullw r11,r11,r30
	r11.s64 = int64_t(r11.s32) * int64_t(r30.s32);
	// add r31,r11,r29
	r31.u64 = r11.u64 + r29.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mr r4,r31
	ctx.r4.u64 = r31.u64;
	// mtctr r24
	ctr.u64 = r24.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// beq 0x8240bb68
	if (cr0.getEQ()) goto loc_8240BB68;
	// cmpwi cr6,r3,0
	cr6.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bge cr6,0x8240bb4c
	if (!cr6.getLT()) goto loc_8240BB4C;
	// subf r27,r30,r31
	r27.s64 = r31.s64 - r30.s64;
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// bne cr6,0x8240bb50
	if (!cr6.getEQ()) goto loc_8240BB50;
	// addi r5,r28,-1
	ctx.r5.s64 = r28.s64 + -1;
	// b 0x8240bb54
	goto loc_8240BB54;
loc_8240BB4C:
	// add r29,r31,r30
	r29.u64 = r31.u64 + r30.u64;
loc_8240BB50:
	// mr r5,r28
	ctx.r5.u64 = r28.u64;
loc_8240BB54:
	// cmplw cr6,r29,r27
	cr6.compare<uint32_t>(r29.u32, r27.u32, xer);
	// ble cr6,0x8240baf8
	if (!cr6.getGT()) goto loc_8240BAF8;
loc_8240BB5C:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240BB60:
	// addi r1,r1,160
	ctx.r1.s64 = ctx.r1.s64 + 160;
	// b 0x823ed178
	return;
loc_8240BB68:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// b 0x8240bb60
	goto loc_8240BB60;
loc_8240BB70:
	// cmplwi cr6,r5,0
	cr6.compare<uint32_t>(ctx.r5.u32, 0, xer);
	// beq cr6,0x8240bb5c
	if (cr6.getEQ()) goto loc_8240BB5C;
	// mr r4,r29
	ctx.r4.u64 = r29.u64;
	// mr r3,r25
	ctx.r3.u64 = r25.u64;
	// mtctr r24
	ctr.u64 = r24.u64;
	// bctrl 
	PPC_CALL_INDIRECT_FUNC(ctr.u32);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// li r3,0
	ctx.r3.s64 = 0;
	// bne 0x8240bb60
	if (!cr0.getEQ()) goto loc_8240BB60;
	// mr r3,r29
	ctx.r3.u64 = r29.u64;
	// b 0x8240bb60
	goto loc_8240BB60;
}

__attribute__((alias("__imp__sub_8240BBA0"))) PPC_WEAK_FUNC(sub_8240BBA0);
PPC_FUNC_IMPL(__imp__sub_8240BBA0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// stw r3,116(r1)
	PPC_STORE_U32(ctx.r1.u32 + 116, ctx.r3.u32);
	// stw r4,124(r1)
	PPC_STORE_U32(ctx.r1.u32 + 124, ctx.r4.u32);
	// lwz r11,116(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 116);
	// stw r11,80(r1)
	PPC_STORE_U32(ctx.r1.u32 + 80, r11.u32);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240bc3c
	if (cr6.getEQ()) goto loc_8240BC3C;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,12(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 12);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240bbe8
	if (cr6.getEQ()) goto loc_8240BBE8;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r11,r11,-14016
	r11.s64 = r11.s64 + -14016;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// b 0x8240bc48
	goto loc_8240BC48;
loc_8240BBE8:
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r7,r11,-17736
	ctx.r7.s64 = r11.s64 + -17736;
	// li r6,6
	ctx.r6.s64 = 6;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r11,0(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 0);
	// lwz r5,4(r11)
	ctx.r5.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r4,4(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + 4);
	// lwz r3,124(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 124);
	// bl 0x8240bac8
	sub_8240BAC8(ctx, base);
	// stw r3,84(r1)
	PPC_STORE_U32(ctx.r1.u32 + 84, ctx.r3.u32);
	// lwz r11,84(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// cmplwi cr6,r11,0
	cr6.compare<uint32_t>(r11.u32, 0, xer);
	// beq cr6,0x8240bc3c
	if (cr6.getEQ()) goto loc_8240BC3C;
	// lwz r11,80(r1)
	r11.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// lwz r10,84(r1)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r10,2(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 2);
	// rlwinm r10,r10,1,0,30
	ctx.r10.u64 = __builtin_rotateleft64(ctx.r10.u32 | (ctx.r10.u64 << 32), 1) & 0xFFFFFFFE;
	// lwz r11,8(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 8);
	// add r3,r11,r10
	ctx.r3.u64 = r11.u64 + ctx.r10.u64;
	// b 0x8240bc48
	goto loc_8240BC48;
loc_8240BC3C:
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r11,r11,-14016
	r11.s64 = r11.s64 + -14016;
	// lwz r3,0(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 0);
loc_8240BC48:
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240BC58"))) PPC_WEAK_FUNC(sub_8240BC58);
PPC_FUNC_IMPL(__imp__sub_8240BC58) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r18{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// lwz r18,-1044(0)
	r18.u64 = PPC_LOAD_U32(-1044);
	// lwz r16,30048(r7)
	r16.u64 = PPC_LOAD_U32(ctx.r7.u32 + 30048);
	// mflr r12
	// bl 0x823ed134
	// addi r31,r1,-144
	r31.s64 = ctx.r1.s64 + -144;
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// stw r30,172(r31)
	PPC_STORE_U32(r31.u32 + 172, r30.u32);
	// cntlzw r11,r27
	r11.u64 = r27.u32 == 0 ? 32 : __builtin_clz(r27.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240bcc0
	if (!cr0.getEQ()) goto loc_8240BCC0;
loc_8240BC90:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x8240be30
	goto loc_8240BE30;
loc_8240BCC0:
	// cntlzw r11,r30
	r11.u64 = r30.u32 == 0 ? 32 : __builtin_clz(r30.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240bc90
	if (cr0.getEQ()) goto loc_8240BC90;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240bda8
	if (!cr0.getEQ()) goto loc_8240BDA8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8240bd38
	if (cr6.getEQ()) goto loc_8240BD38;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x8240bd38
	if (cr6.getEQ()) goto loc_8240BD38;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// rlwinm r28,r11,2,0,29
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r28,r29
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + r29.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r28,r11,-18648
	r28.s64 = r11.s64 + -18648;
	// b 0x8240bd4c
	goto loc_8240BD4C;
loc_8240BD38:
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r28,r11,-18648
	r28.s64 = r11.s64 + -18648;
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
loc_8240BD4C:
	// lbz r11,40(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 40);
	// rlwinm. r11,r11,0,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240bc90
	if (!cr0.getEQ()) goto loc_8240BC90;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8240bd9c
	if (cr6.getEQ()) goto loc_8240BD9C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x8240bd9c
	if (cr6.getEQ()) goto loc_8240BD9C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// rlwinm r28,r11,2,0,29
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r28,r29
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + r29.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r28,r11,r10
	r28.u64 = r11.u64 + ctx.r10.u64;
loc_8240BD9C:
	// lbz r11,40(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 40);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240bc90
	if (!cr0.getEQ()) goto loc_8240BC90;
loc_8240BDA8:
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_8240BDB0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8240bdb0
	if (!cr6.getEQ()) goto loc_8240BDB0;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r29,r11,0
	r29.u64 = __builtin_rotateleft32(r11.u32, 0);
	// stw r29,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r29.u32);
	// bl 0x823f4f98
	sub_823F4F98(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f50c8
	sub_823F50C8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8240bf70
	sub_8240BF70(ctx, base);
	// stw r3,84(r31)
	PPC_STORE_U32(r31.u32 + 84, ctx.r3.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x823f51b0
	sub_823F51B0(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,144
	r12.s64 = r31.s64 + 144;
	// bl 0x8240be58
	sub_8240BE58(ctx, base);
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// lwz r10,84(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// addi r3,r11,-1
	ctx.r3.s64 = r11.s64 + -1;
loc_8240BE30:
	// addi r1,r31,144
	ctx.r1.s64 = r31.s64 + 144;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_8240BC60"))) PPC_WEAK_FUNC(sub_8240BC60);
PPC_FUNC_IMPL(__imp__sub_8240BC60) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed134
	// addi r31,r1,-144
	r31.s64 = ctx.r1.s64 + -144;
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r27,r3
	r27.u64 = ctx.r3.u64;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// stw r30,172(r31)
	PPC_STORE_U32(r31.u32 + 172, r30.u32);
	// cntlzw r11,r27
	r11.u64 = r27.u32 == 0 ? 32 : __builtin_clz(r27.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240bcc0
	if (!cr0.getEQ()) goto loc_8240BCC0;
loc_8240BC90:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
	// li r3,-1
	ctx.r3.s64 = -1;
	// b 0x8240be30
	goto loc_8240BE30;
loc_8240BCC0:
	// cntlzw r11,r30
	r11.u64 = r30.u32 == 0 ? 32 : __builtin_clz(r30.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// xori r11,r11,1
	r11.u64 = r11.u64 ^ 1;
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240bc90
	if (cr0.getEQ()) goto loc_8240BC90;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// rlwinm. r11,r11,0,25,25
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x40;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240bda8
	if (!cr0.getEQ()) goto loc_8240BDA8;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8240bd38
	if (cr6.getEQ()) goto loc_8240BD38;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x8240bd38
	if (cr6.getEQ()) goto loc_8240BD38;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// rlwinm r28,r11,2,0,29
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r28,r29
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + r29.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r10,r11,r10
	ctx.r10.u64 = r11.u64 + ctx.r10.u64;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r28,r11,-18648
	r28.s64 = r11.s64 + -18648;
	// b 0x8240bd4c
	goto loc_8240BD4C;
loc_8240BD38:
	// lis r11,-32015
	r11.s64 = -2098135040;
	// addi r28,r11,-18648
	r28.s64 = r11.s64 + -18648;
	// mr r10,r28
	ctx.r10.u64 = r28.u64;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r29,r11,-15840
	r29.s64 = r11.s64 + -15840;
loc_8240BD4C:
	// lbz r11,40(r10)
	r11.u64 = PPC_LOAD_U8(ctx.r10.u32 + 40);
	// rlwinm. r11,r11,0,0,30
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0xFFFFFFFE;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240bc90
	if (!cr0.getEQ()) goto loc_8240BC90;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8240bd9c
	if (cr6.getEQ()) goto loc_8240BD9C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// cmpwi cr6,r3,-2
	cr6.compare<int32_t>(ctx.r3.s32, -2, xer);
	// beq cr6,0x8240bd9c
	if (cr6.getEQ()) goto loc_8240BD9C;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// srawi r11,r3,5
	xer.ca = (ctx.r3.s32 < 0) & ((ctx.r3.u32 & 0x1F) != 0);
	r11.s64 = ctx.r3.s32 >> 5;
	// rlwinm r28,r11,2,0,29
	r28.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 2) & 0xFFFFFFFC;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// lwzx r10,r28,r29
	ctx.r10.u64 = PPC_LOAD_U32(r28.u32 + r29.u32);
	// rlwinm r11,r3,6,21,25
	r11.u64 = __builtin_rotateleft64(ctx.r3.u32 | (ctx.r3.u64 << 32), 6) & 0x7C0;
	// add r28,r11,r10
	r28.u64 = r11.u64 + ctx.r10.u64;
loc_8240BD9C:
	// lbz r11,40(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 40);
	// clrlwi. r11,r11,31
	r11.u64 = r11.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// bne 0x8240bc90
	if (!cr0.getEQ()) goto loc_8240BC90;
loc_8240BDA8:
	// mr r11,r27
	r11.u64 = r27.u64;
	// mr r10,r11
	ctx.r10.u64 = r11.u64;
loc_8240BDB0:
	// lbz r9,0(r11)
	ctx.r9.u64 = PPC_LOAD_U8(r11.u32 + 0);
	// addi r11,r11,1
	r11.s64 = r11.s64 + 1;
	// cmplwi cr6,r9,0
	cr6.compare<uint32_t>(ctx.r9.u32, 0, xer);
	// bne cr6,0x8240bdb0
	if (!cr6.getEQ()) goto loc_8240BDB0;
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// addi r11,r11,-1
	r11.s64 = r11.s64 + -1;
	// rotlwi r29,r11,0
	r29.u64 = __builtin_rotateleft32(r11.u32, 0);
	// stw r29,80(r31)
	PPC_STORE_U32(r31.u32 + 80, r29.u32);
	// bl 0x823f4f98
	sub_823F4F98(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f50c8
	sub_823F50C8(ctx, base);
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r6,r30
	ctx.r6.u64 = r30.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// li r4,1
	ctx.r4.s64 = 1;
	// mr r3,r27
	ctx.r3.u64 = r27.u64;
	// bl 0x8240bf70
	sub_8240BF70(ctx, base);
	// stw r3,84(r31)
	PPC_STORE_U32(r31.u32 + 84, ctx.r3.u32);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// mr r3,r28
	ctx.r3.u64 = r28.u64;
	// bl 0x823f51b0
	sub_823F51B0(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,144
	r12.s64 = r31.s64 + 144;
	// bl 0x8240be58
	sub_8240BE58(ctx, base);
	// lwz r11,80(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 80);
	// lwz r10,84(r31)
	ctx.r10.u64 = PPC_LOAD_U32(r31.u32 + 84);
	// subf r11,r10,r11
	r11.s64 = r11.s64 - ctx.r10.s64;
	// cntlzw r11,r11
	r11.u64 = r11.u32 == 0 ? 32 : __builtin_clz(r11.u32);
	// rlwinm r11,r11,27,31,31
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 27) & 0x1;
	// addi r3,r11,-1
	ctx.r3.s64 = r11.s64 + -1;
loc_8240BE30:
	// addi r1,r31,144
	ctx.r1.s64 = r31.s64 + 144;
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_8240BE38"))) PPC_WEAK_FUNC(sub_8240BE38);
PPC_FUNC_IMPL(__imp__sub_8240BE38) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-144
	r31.s64 = r12.s64 + -144;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lwz r30,172(r31)
	r30.u64 = PPC_LOAD_U32(r31.u32 + 172);
	// b 0x8240be70
	goto loc_8240BE70;
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-144
	r31.s64 = r12.s64 + -144;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
loc_8240BE70:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5058
	sub_823F5058(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240BE58"))) PPC_WEAK_FUNC(sub_8240BE58);
PPC_FUNC_IMPL(__imp__sub_8240BE58) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-8(r1)
	PPC_STORE_U64(ctx.r1.u32 + -8, r31.u64);
	// addi r31,r12,-144
	r31.s64 = r12.s64 + -144;
	// std r30,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r30.u64);
	// mflr r12
	// stw r12,-24(r1)
	PPC_STORE_U32(ctx.r1.u32 + -24, r12.u32);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823f5058
	sub_823F5058(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// ld r31,-8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -8);
	// ld r30,-16(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// lwz r12,-24(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -24);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240BE90"))) PPC_WEAK_FUNC(sub_8240BE90);
PPC_FUNC_IMPL(__imp__sub_8240BE90) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-144(r1)
	ea = -144 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// mr r31,r4
	r31.u64 = ctx.r4.u64;
	// addi r4,r11,27048
	ctx.r4.s64 = r11.s64 + 27048;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// li r5,32
	ctx.r5.s64 = 32;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// stw r30,104(r1)
	PPC_STORE_U32(ctx.r1.u32 + 104, r30.u32);
	// stw r31,108(r1)
	PPC_STORE_U32(ctx.r1.u32 + 108, r31.u32);
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// beq cr6,0x8240bee8
	if (cr6.getEQ()) goto loc_8240BEE8;
	// lwz r11,0(r31)
	r11.u64 = PPC_LOAD_U32(r31.u32 + 0);
	// rlwinm. r11,r11,0,28,28
	r11.u64 = __builtin_rotateleft64(r11.u32 | (r11.u64 << 32), 0) & 0x8;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240bee8
	if (cr0.getEQ()) goto loc_8240BEE8;
	// lis r11,409
	r11.s64 = 26804224;
	// ori r11,r11,16384
	r11.u64 = r11.u64 | 16384;
	// stw r11,100(r1)
	PPC_STORE_U32(ctx.r1.u32 + 100, r11.u32);
loc_8240BEE8:
	// addi r6,r1,100
	ctx.r6.s64 = ctx.r1.s64 + 100;
	// lwz r5,96(r1)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r1.u32 + 96);
	// lwz r4,84(r1)
	ctx.r4.u64 = PPC_LOAD_U32(ctx.r1.u32 + 84);
	// lwz r3,80(r1)
	ctx.r3.u64 = PPC_LOAD_U32(ctx.r1.u32 + 80);
	// bl 0x824086b8
	sub_824086B8(ctx, base);
	// addi r1,r1,144
	ctx.r1.s64 = ctx.r1.s64 + 144;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240BF18"))) PPC_WEAK_FUNC(sub_8240BF18);
PPC_FUNC_IMPL(__imp__sub_8240BF18) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-32249
	r11.s64 = -2113470464;
	// mr r31,r3
	r31.u64 = ctx.r3.u64;
	// addi r11,r11,27080
	r11.s64 = r11.s64 + 27080;
	// mr r30,r4
	r30.u64 = ctx.r4.u64;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x8240c1e8
	sub_8240C1E8(ctx, base);
	// clrlwi. r11,r30,31
	r11.u64 = r30.u32 & 0x1;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240bf54
	if (cr0.getEQ()) goto loc_8240BF54;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x8209d150
	sub_8209D150(ctx, base);
loc_8240BF54:
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// addi r1,r1,112
	ctx.r1.s64 = ctx.r1.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240BF70"))) PPC_WEAK_FUNC(sub_8240BF70);
PPC_FUNC_IMPL(__imp__sub_8240BF70) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r24{};
	PPCRegister r25{};
	PPCRegister r26{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// bl 0x823ed128
	// stwu r1,-416(r1)
	ea = -416 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r25,r4
	r25.u64 = ctx.r4.u64;
	// mr r28,r3
	r28.u64 = ctx.r3.u64;
	// mr r24,r5
	r24.u64 = ctx.r5.u64;
	// mr r30,r6
	r30.u64 = ctx.r6.u64;
	// cmplwi cr6,r25,0
	cr6.compare<uint32_t>(r25.u32, 0, xer);
	// beq cr6,0x8240bfcc
	if (cr6.getEQ()) goto loc_8240BFCC;
	// cmplwi cr6,r24,0
	cr6.compare<uint32_t>(r24.u32, 0, xer);
	// beq cr6,0x8240bfcc
	if (cr6.getEQ()) goto loc_8240BFCC;
	// cmplwi cr6,r30,0
	cr6.compare<uint32_t>(r30.u32, 0, xer);
	// bne cr6,0x8240bfd8
	if (!cr6.getEQ()) goto loc_8240BFD8;
loc_8240BFA4:
	// bl 0x823f3de0
	sub_823F3DE0(ctx, base);
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// li r10,22
	ctx.r10.s64 = 22;
	// li r7,0
	ctx.r7.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r4,0
	ctx.r4.s64 = 0;
	// li r3,0
	ctx.r3.s64 = 0;
	// stw r10,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r10.u32);
	// bl 0x823f3ca8
	sub_823F3CA8(ctx, base);
loc_8240BFCC:
	// li r3,0
	ctx.r3.s64 = 0;
loc_8240BFD0:
	// addi r1,r1,416
	ctx.r1.s64 = ctx.r1.s64 + 416;
	// b 0x823ed178
	return;
loc_8240BFD8:
	// cmplwi cr6,r28,0
	cr6.compare<uint32_t>(r28.u32, 0, xer);
	// beq cr6,0x8240bfa4
	if (cr6.getEQ()) goto loc_8240BFA4;
	// li r11,-1
	r11.s64 = -1;
	// twllei r25,0
	// divwu r11,r11,r25
	r11.u32 = r11.u32 / r25.u32;
	// cmplw cr6,r24,r11
	cr6.compare<uint32_t>(r24.u32, r11.u32, xer);
	// bgt cr6,0x8240bfa4
	if (cr6.getGT()) goto loc_8240BFA4;
	// mullw r26,r25,r24
	r26.s64 = int64_t(r25.s32) * int64_t(r24.s32);
	// mr r31,r26
	r31.u64 = r26.u64;
	// bl 0x823f4e20
	sub_823F4E20(ctx, base);
	// addi r11,r3,32
	r11.s64 = ctx.r3.s64 + 32;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// beq cr6,0x8240c190
	if (cr6.getEQ()) goto loc_8240C190;
	// bl 0x823f4e20
	sub_823F4E20(ctx, base);
	// addi r11,r3,64
	r11.s64 = ctx.r3.s64 + 64;
	// cmplw cr6,r30,r11
	cr6.compare<uint32_t>(r30.u32, r11.u32, xer);
	// beq cr6,0x8240c190
	if (cr6.getEQ()) goto loc_8240C190;
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// andi. r11,r11,268
	r11.u64 = r11.u64 & 268;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240c034
	if (cr0.getEQ()) goto loc_8240C034;
	// lwz r27,24(r30)
	r27.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// b 0x8240c038
	goto loc_8240C038;
loc_8240C034:
	// li r27,4096
	r27.s64 = 4096;
loc_8240C038:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x8240c1d4
	if (cr6.getEQ()) goto loc_8240C1D4;
loc_8240C040:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// andi. r11,r11,264
	r11.u64 = r11.u64 & 264;
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// beq 0x8240c0a4
	if (cr0.getEQ()) goto loc_8240C0A4;
	// lwz r29,4(r30)
	r29.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmpwi r29,0
	cr0.compare<int32_t>(r29.s32, 0, xer);
	// beq 0x8240c0a4
	if (cr0.getEQ()) goto loc_8240C0A4;
	// cmpwi cr6,r29,0
	cr6.compare<int32_t>(r29.s32, 0, xer);
	// blt cr6,0x8240c124
	if (cr6.getLT()) goto loc_8240C124;
	// cmplw cr6,r31,r29
	cr6.compare<uint32_t>(r31.u32, r29.u32, xer);
	// bge cr6,0x8240c070
	if (!cr6.getLT()) goto loc_8240C070;
	// mr r29,r31
	r29.u64 = r31.u64;
loc_8240C070:
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// lwz r3,0(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// lwz r11,0(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 0);
	// subf r31,r29,r31
	r31.s64 = r31.s64 - r29.s64;
	// subf r10,r29,r10
	ctx.r10.s64 = ctx.r10.s64 - r29.s64;
	// add r11,r11,r29
	r11.u64 = r11.u64 + r29.u64;
	// add r28,r29,r28
	r28.u64 = r29.u64 + r28.u64;
	// stw r10,4(r30)
	PPC_STORE_U32(r30.u32 + 4, ctx.r10.u32);
	// stw r11,0(r30)
	PPC_STORE_U32(r30.u32 + 0, r11.u32);
	// b 0x8240c174
	goto loc_8240C174;
loc_8240C0A4:
	// cmplw cr6,r31,r27
	cr6.compare<uint32_t>(r31.u32, r27.u32, xer);
	// blt cr6,0x8240c140
	if (cr6.getLT()) goto loc_8240C140;
	// cmpwi cr6,r11,0
	cr6.compare<int32_t>(r11.s32, 0, xer);
	// beq cr6,0x8240c0c4
	if (cr6.getEQ()) goto loc_8240C0C4;
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe320
	sub_823FE320(ctx, base);
	// cmpwi r3,0
	cr0.compare<int32_t>(ctx.r3.s32, 0, xer);
	// bne 0x8240c180
	if (!cr0.getEQ()) goto loc_8240C180;
loc_8240C0C4:
	// cmplwi cr6,r27,0
	cr6.compare<uint32_t>(r27.u32, 0, xer);
	// beq cr6,0x8240c0e4
	if (cr6.getEQ()) goto loc_8240C0E4;
	// divwu r11,r31,r27
	r11.u32 = r31.u32 / r27.u32;
	// twllei r27,0
	// mullw r11,r11,r27
	r11.s64 = int64_t(r11.s32) * int64_t(r27.s32);
	// subf r11,r11,r31
	r11.s64 = r31.s64 - r11.s64;
	// subf r29,r11,r31
	r29.s64 = r31.s64 - r11.s64;
	// b 0x8240c0e8
	goto loc_8240C0E8;
loc_8240C0E4:
	// mr r29,r31
	r29.u64 = r31.u64;
loc_8240C0E8:
	// mr r3,r30
	ctx.r3.u64 = r30.u64;
	// bl 0x823fe720
	sub_823FE720(ctx, base);
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// mr r5,r29
	ctx.r5.u64 = r29.u64;
	// bl 0x823ff9a8
	sub_823FF9A8(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8240c124
	if (cr6.getEQ()) goto loc_8240C124;
	// cmplw cr6,r3,r29
	cr6.compare<uint32_t>(ctx.r3.u32, r29.u32, xer);
	// mr r11,r29
	r11.u64 = r29.u64;
	// bgt cr6,0x8240c114
	if (cr6.getGT()) goto loc_8240C114;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
loc_8240C114:
	// subf r31,r11,r31
	r31.s64 = r31.s64 - r11.s64;
	// add r28,r11,r28
	r28.u64 = r11.u64 + r28.u64;
	// cmplw cr6,r3,r29
	cr6.compare<uint32_t>(ctx.r3.u32, r29.u32, xer);
	// bge cr6,0x8240c174
	if (!cr6.getLT()) goto loc_8240C174;
loc_8240C124:
	// lwz r11,12(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 12);
	// subf r10,r31,r26
	ctx.r10.s64 = r26.s64 - r31.s64;
	// twllei r25,0
	// ori r11,r11,32
	r11.u64 = r11.u64 | 32;
	// divwu r3,r10,r25
	ctx.r3.u32 = ctx.r10.u32 / r25.u32;
	// stw r11,12(r30)
	PPC_STORE_U32(r30.u32 + 12, r11.u32);
	// b 0x8240bfd0
	goto loc_8240BFD0;
loc_8240C140:
	// lbz r11,0(r28)
	r11.u64 = PPC_LOAD_U8(r28.u32 + 0);
	// mr r4,r30
	ctx.r4.u64 = r30.u64;
	// extsb r3,r11
	ctx.r3.s64 = r11.s8;
	// bl 0x823f5e28
	sub_823F5E28(ctx, base);
	// cmpwi cr6,r3,-1
	cr6.compare<int32_t>(ctx.r3.s32, -1, xer);
	// beq cr6,0x8240c180
	if (cr6.getEQ()) goto loc_8240C180;
	// lwz r11,24(r30)
	r11.u64 = PPC_LOAD_U32(r30.u32 + 24);
	// addi r28,r28,1
	r28.s64 = r28.s64 + 1;
	// addi r31,r31,-1
	r31.s64 = r31.s64 + -1;
	// cmpwi r11,0
	cr0.compare<int32_t>(r11.s32, 0, xer);
	// mr r27,r11
	r27.u64 = r11.u64;
	// bgt 0x8240c174
	if (cr0.getGT()) goto loc_8240C174;
	// li r27,1
	r27.s64 = 1;
loc_8240C174:
	// cmplwi cr6,r31,0
	cr6.compare<uint32_t>(r31.u32, 0, xer);
	// bne cr6,0x8240c040
	if (!cr6.getEQ()) goto loc_8240C040;
	// b 0x8240c1d4
	goto loc_8240C1D4;
loc_8240C180:
	// subf r11,r31,r26
	r11.s64 = r26.s64 - r31.s64;
	// twllei r25,0
	// divwu r3,r11,r25
	ctx.r3.u32 = r11.u32 / r25.u32;
	// b 0x8240bfd0
	goto loc_8240BFD0;
loc_8240C190:
	// cmplwi cr6,r26,0
	cr6.compare<uint32_t>(r26.u32, 0, xer);
	// beq cr6,0x8240c1d4
	if (cr6.getEQ()) goto loc_8240C1D4;
loc_8240C198:
	// cmplwi cr6,r31,255
	cr6.compare<uint32_t>(r31.u32, 255, xer);
	// mr r30,r31
	r30.u64 = r31.u64;
	// blt cr6,0x8240c1a8
	if (cr6.getLT()) goto loc_8240C1A8;
	// li r30,255
	r30.s64 = 255;
loc_8240C1A8:
	// mr r5,r30
	ctx.r5.u64 = r30.u64;
	// mr r4,r28
	ctx.r4.u64 = r28.u64;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// bl 0x823ee010
	sub_823EE010(ctx, base);
	// addi r11,r1,80
	r11.s64 = ctx.r1.s64 + 80;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r3,r1,80
	ctx.r3.s64 = ctx.r1.s64 + 80;
	// stbx r10,r30,r11
	PPC_STORE_U8(r30.u32 + r11.u32, ctx.r10.u8);
	// bl 0x8235e140
	sub_8235E140(ctx, base);
	// subf. r31,r30,r31
	r31.s64 = r31.s64 - r30.s64;
	cr0.compare<int32_t>(r31.s32, 0, xer);
	// bne 0x8240c198
	if (!cr0.getEQ()) goto loc_8240C198;
loc_8240C1D4:
	// mr r3,r24
	ctx.r3.u64 = r24.u64;
	// b 0x8240bfd0
	goto loc_8240BFD0;
}

__attribute__((alias("__imp__sub_8240C1E0"))) PPC_WEAK_FUNC(sub_8240C1E0);
PPC_FUNC_IMPL(__imp__sub_8240C1E0) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r16{};
	PPCRegister r18{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// lwz r18,-1044(0)
	r18.u64 = PPC_LOAD_U32(-1044);
	// lwz r16,30072(r7)
	r16.u64 = PPC_LOAD_U32(ctx.r7.u32 + 30072);
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// addi r31,r1,-112
	r31.s64 = ctx.r1.s64 + -112;
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,14
	ctx.r3.s64 = 14;
	// bl 0x823f8040
	sub_823F8040(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8240c268
	if (cr0.getEQ()) goto loc_8240C268;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r11,r11,-16032
	r11.s64 = r11.s64 + -16032;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 4);
loc_8240C228:
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8240c258
	if (cr6.getEQ()) goto loc_8240C258;
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// beq cr6,0x8240c24c
	if (cr6.getEQ()) goto loc_8240C24C;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// b 0x8240c228
	goto loc_8240C228;
loc_8240C24C:
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// bl 0x823ed250
	sub_823ED250(ctx, base);
loc_8240C258:
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x823ed250
	sub_823ED250(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
loc_8240C268:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,112
	r12.s64 = r31.s64 + 112;
	// bl 0x8240c28c
	sub_8240C28C(ctx, base);
	// addi r1,r31,112
	ctx.r1.s64 = r31.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C1E8"))) PPC_WEAK_FUNC(sub_8240C1E8);
PPC_FUNC_IMPL(__imp__sub_8240C1E8) {
	PPC_FUNC_PROLOGUE();
	PPCXERRegister xer{};
	PPCCRRegister cr0{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r30{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r30,-24(r1)
	PPC_STORE_U64(ctx.r1.u32 + -24, r30.u64);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// addi r31,r1,-112
	r31.s64 = ctx.r1.s64 + -112;
	// stwu r1,-112(r1)
	ea = -112 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// mr r30,r3
	r30.u64 = ctx.r3.u64;
	// li r3,14
	ctx.r3.s64 = 14;
	// bl 0x823f8040
	sub_823F8040(ctx, base);
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// lwz r10,4(r30)
	ctx.r10.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// cmplwi r10,0
	cr0.compare<uint32_t>(ctx.r10.u32, 0, xer);
	// beq 0x8240c268
	if (cr0.getEQ()) goto loc_8240C268;
	// lis r11,-31987
	r11.s64 = -2096300032;
	// addi r11,r11,-16032
	r11.s64 = r11.s64 + -16032;
	// lwz r3,4(r11)
	ctx.r3.u64 = PPC_LOAD_U32(r11.u32 + 4);
loc_8240C228:
	// stw r3,80(r31)
	PPC_STORE_U32(r31.u32 + 80, ctx.r3.u32);
	// cmplwi cr6,r3,0
	cr6.compare<uint32_t>(ctx.r3.u32, 0, xer);
	// beq cr6,0x8240c258
	if (cr6.getEQ()) goto loc_8240C258;
	// lwz r9,0(r3)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r3.u32 + 0);
	// cmplw cr6,r9,r10
	cr6.compare<uint32_t>(ctx.r9.u32, ctx.r10.u32, xer);
	// beq cr6,0x8240c24c
	if (cr6.getEQ()) goto loc_8240C24C;
	// mr r11,r3
	r11.u64 = ctx.r3.u64;
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// b 0x8240c228
	goto loc_8240C228;
loc_8240C24C:
	// lwz r10,4(r3)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r3.u32 + 4);
	// stw r10,4(r11)
	PPC_STORE_U32(r11.u32 + 4, ctx.r10.u32);
	// bl 0x823ed250
	sub_823ED250(ctx, base);
loc_8240C258:
	// lwz r3,4(r30)
	ctx.r3.u64 = PPC_LOAD_U32(r30.u32 + 4);
	// bl 0x823ed250
	sub_823ED250(ctx, base);
	// li r11,0
	r11.s64 = 0;
	// stw r11,4(r30)
	PPC_STORE_U32(r30.u32 + 4, r11.u32);
loc_8240C268:
	// mr r8,r8
	ctx.r8.u64 = ctx.r8.u64;
	// addi r12,r31,112
	r12.s64 = r31.s64 + 112;
	// bl 0x8240c28c
	sub_8240C28C(ctx, base);
	// addi r1,r31,112
	ctx.r1.s64 = r31.s64 + 112;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r30,-24(r1)
	r30.u64 = PPC_LOAD_U64(ctx.r1.u32 + -24);
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C28C"))) PPC_WEAK_FUNC(sub_8240C28C);
PPC_FUNC_IMPL(__imp__sub_8240C28C) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r3,14
	ctx.r3.s64 = 14;
	// bl 0x823f7ee0
	sub_823F7EE0(ctx, base);
	// lwz r1,0(r1)
	ctx.r1.u64 = PPC_LOAD_U32(ctx.r1.u32 + 0);
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C2B0"))) PPC_WEAK_FUNC(sub_8240C2B0);
PPC_FUNC_IMPL(__imp__sub_8240C2B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r31{};
	uint32_t ea{};
	// std r31,-72(r1)
	PPC_STORE_U64(ctx.r1.u32 + -72, r31.u64);
	// mflr r31
	// stwu r1,-80(r1)
	ea = -80 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// li r5,0
	ctx.r5.s64 = 0;
	// li r6,0
	ctx.r6.s64 = 0;
	// bl 0x824101fc
	__imp__RtlUnwind(ctx, base);
	// mtlr r31
	// ld r31,8(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + 8);
	// addi r1,r1,80
	ctx.r1.s64 = ctx.r1.s64 + 80;
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C2D8"))) PPC_WEAK_FUNC(sub_8240C2D8);
PPC_FUNC_IMPL(__imp__sub_8240C2D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4520
	ctx.r3.s64 = r11.s64 + -4520;
	// b 0x823edef0
	sub_823EDEF0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8240C2E8"))) PPC_WEAK_FUNC(sub_8240C2E8);
PPC_FUNC_IMPL(__imp__sub_8240C2E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// lis r11,-32015
	r11.s64 = -2098135040;
	// lis r9,-32015
	ctx.r9.s64 = -2098135040;
	// addi r11,r11,-6080
	r11.s64 = r11.s64 + -6080;
	// lwz r10,1076(r10)
	ctx.r10.u64 = PPC_LOAD_U32(ctx.r10.u32 + 1076);
	// add r11,r10,r11
	r11.u64 = ctx.r10.u64 + r11.u64;
	// stw r11,-5056(r9)
	PPC_STORE_U32(ctx.r9.u32 + -5056, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C308"))) PPC_WEAK_FUNC(sub_8240C308);
PPC_FUNC_IMPL(__imp__sub_8240C308) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32190
	r11.s64 = -2109603840;
	// lis r10,-32014
	ctx.r10.s64 = -2098069504;
	// lwz r11,17980(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + 17980);
	// stw r11,-1540(r10)
	PPC_STORE_U32(ctx.r10.u32 + -1540, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C320"))) PPC_WEAK_FUNC(sub_8240C320);
PPC_FUNC_IMPL(__imp__sub_8240C320) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32014
	r11.s64 = -2098069504;
	// lis r10,-32190
	ctx.r10.s64 = -2109603840;
	// addi r10,r10,19176
	ctx.r10.s64 = ctx.r10.s64 + 19176;
	// lwz r11,-1392(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -1392);
	// stw r11,4(r10)
	PPC_STORE_U32(ctx.r10.u32 + 4, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C338"))) PPC_WEAK_FUNC(sub_8240C338);
PPC_FUNC_IMPL(__imp__sub_8240C338) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32141
	r11.s64 = -2106392576;
	// lis r10,-32010
	ctx.r10.s64 = -2097807360;
	// lwz r11,-19160(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -19160);
	// stw r11,12448(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12448, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C350"))) PPC_WEAK_FUNC(sub_8240C350);
PPC_FUNC_IMPL(__imp__sub_8240C350) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32141
	r11.s64 = -2106392576;
	// lis r10,-32010
	ctx.r10.s64 = -2097807360;
	// lwz r11,-19156(r11)
	r11.u64 = PPC_LOAD_U32(r11.u32 + -19156);
	// stw r11,12444(r10)
	PPC_STORE_U32(ctx.r10.u32 + 12444, r11.u32);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240C368"))) PPC_WEAK_FUNC(sub_8240C368);
PPC_FUNC_IMPL(__imp__sub_8240C368) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r27{};
	PPCRegister r28{};
	PPCRegister r29{};
	PPCRegister r30{};
	PPCRegister r31{};
	PPCRegister f0{};
	PPCRegister temp{};
	// mflr r12
	// bl 0x823ed134
	// lis r9,-32128
	ctx.r9.s64 = -2105540608;
	// lis r11,-32123
	r11.s64 = -2105212928;
	// li r10,0
	ctx.r10.s64 = 0;
	// addi r11,r11,32656
	r11.s64 = r11.s64 + 32656;
	// li r29,20
	r29.s64 = 20;
	// lwz r9,-7728(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + -7728);
	// lis r8,-32038
	ctx.r8.s64 = -2099642368;
	// lis r7,-32088
	ctx.r7.s64 = -2102919168;
	// addi r8,r8,31432
	ctx.r8.s64 = ctx.r8.s64 + 31432;
	// addi r7,r7,-23232
	ctx.r7.s64 = ctx.r7.s64 + -23232;
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// stw r9,20(r11)
	PPC_STORE_U32(r11.u32 + 20, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stw r10,44(r11)
	PPC_STORE_U32(r11.u32 + 44, ctx.r10.u32);
	// addi r6,r6,28060
	ctx.r6.s64 = ctx.r6.s64 + 28060;
	// stw r10,48(r11)
	PPC_STORE_U32(r11.u32 + 48, ctx.r10.u32);
	// addi r9,r9,28052
	ctx.r9.s64 = ctx.r9.s64 + 28052;
	// stw r10,52(r11)
	PPC_STORE_U32(r11.u32 + 52, ctx.r10.u32);
	// stw r29,56(r11)
	PPC_STORE_U32(r11.u32 + 56, r29.u32);
	// lis r29,-32256
	r29.s64 = -2113929216;
	// lis r5,-32037
	ctx.r5.s64 = -2099576832;
	// lis r4,-32083
	ctx.r4.s64 = -2102591488;
	// addi r5,r5,-5952
	ctx.r5.s64 = ctx.r5.s64 + -5952;
	// addi r4,r4,-19328
	ctx.r4.s64 = ctx.r4.s64 + -19328;
	// lfs f0,28048(r29)
	ctx.fpscr.disableFlushMode();
	temp.u32 = PPC_LOAD_U32(r29.u32 + 28048);
	f0.f64 = double(temp.f32);
	// lis r3,-32256
	ctx.r3.s64 = -2113929216;
	// stfs f0,64(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 64, temp.u32);
	// stw r9,60(r11)
	PPC_STORE_U32(r11.u32 + 60, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r3,r3,28040
	ctx.r3.s64 = ctx.r3.s64 + 28040;
	// lis r31,-32053
	r31.s64 = -2100625408;
	// lis r30,-32119
	r30.s64 = -2104950784;
	// addi r31,r31,7416
	r31.s64 = r31.s64 + 7416;
	// lfs f0,2776(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2776);
	f0.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f0,68(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 68, temp.u32);
	// addi r30,r30,-28608
	r30.s64 = r30.s64 + -28608;
	// lfs f13,28036(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 28036);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32124
	ctx.r9.s64 = -2105278464;
	// stfs f13,72(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 72, temp.u32);
	// lwz r9,29448(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 29448);
	// stw r9,76(r11)
	PPC_STORE_U32(r11.u32 + 76, ctx.r9.u32);
	// li r9,22
	ctx.r9.s64 = 22;
	// stw r8,80(r11)
	PPC_STORE_U32(r11.u32 + 80, ctx.r8.u32);
	// stw r10,84(r11)
	PPC_STORE_U32(r11.u32 + 84, ctx.r10.u32);
	// stw r7,88(r11)
	PPC_STORE_U32(r11.u32 + 88, ctx.r7.u32);
	// stw r10,92(r11)
	PPC_STORE_U32(r11.u32 + 92, ctx.r10.u32);
	// stw r10,96(r11)
	PPC_STORE_U32(r11.u32 + 96, ctx.r10.u32);
	// stw r10,100(r11)
	PPC_STORE_U32(r11.u32 + 100, ctx.r10.u32);
	// stw r10,104(r11)
	PPC_STORE_U32(r11.u32 + 104, ctx.r10.u32);
	// stw r10,108(r11)
	PPC_STORE_U32(r11.u32 + 108, ctx.r10.u32);
	// stw r9,112(r11)
	PPC_STORE_U32(r11.u32 + 112, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f13,28032(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 28032);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f13,120(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 120, temp.u32);
	// stw r6,116(r11)
	PPC_STORE_U32(r11.u32 + 116, ctx.r6.u32);
	// stfs f0,124(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 124, temp.u32);
	// lfs f13,28028(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 28028);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32123
	ctx.r9.s64 = -2105212928;
	// stfs f13,128(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 128, temp.u32);
	// lwz r9,9212(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 9212);
	// stw r9,132(r11)
	PPC_STORE_U32(r11.u32 + 132, ctx.r9.u32);
	// li r9,23
	ctx.r9.s64 = 23;
	// stw r5,136(r11)
	PPC_STORE_U32(r11.u32 + 136, ctx.r5.u32);
	// stw r10,140(r11)
	PPC_STORE_U32(r11.u32 + 140, ctx.r10.u32);
	// stw r4,144(r11)
	PPC_STORE_U32(r11.u32 + 144, ctx.r4.u32);
	// stw r10,148(r11)
	PPC_STORE_U32(r11.u32 + 148, ctx.r10.u32);
	// stw r10,152(r11)
	PPC_STORE_U32(r11.u32 + 152, ctx.r10.u32);
	// stw r10,156(r11)
	PPC_STORE_U32(r11.u32 + 156, ctx.r10.u32);
	// stw r10,160(r11)
	PPC_STORE_U32(r11.u32 + 160, ctx.r10.u32);
	// stw r10,164(r11)
	PPC_STORE_U32(r11.u32 + 164, ctx.r10.u32);
	// stw r9,168(r11)
	PPC_STORE_U32(r11.u32 + 168, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f13,28024(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 28024);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,176(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 176, temp.u32);
	// stw r3,172(r11)
	PPC_STORE_U32(r11.u32 + 172, ctx.r3.u32);
	// stfs f0,180(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 180, temp.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// li r5,24
	ctx.r5.s64 = 24;
	// lis r8,-32054
	ctx.r8.s64 = -2100690944;
	// lis r7,-32035
	ctx.r7.s64 = -2099445760;
	// lis r6,-32122
	ctx.r6.s64 = -2105147392;
	// lfs f13,28020(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 28020);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32139
	ctx.r9.s64 = -2106261504;
	// stfs f13,184(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 184, temp.u32);
	// addi r8,r8,5248
	ctx.r8.s64 = ctx.r8.s64 + 5248;
	// addi r7,r7,-31168
	ctx.r7.s64 = ctx.r7.s64 + -31168;
	// addi r6,r6,13648
	ctx.r6.s64 = ctx.r6.s64 + 13648;
	// lis r4,-32034
	ctx.r4.s64 = -2099380224;
	// lwz r9,5416(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 5416);
	// lis r3,-32101
	ctx.r3.s64 = -2103771136;
	// addi r4,r4,-1680
	ctx.r4.s64 = ctx.r4.s64 + -1680;
	// addi r3,r3,23744
	ctx.r3.s64 = ctx.r3.s64 + 23744;
	// stw r9,188(r11)
	PPC_STORE_U32(r11.u32 + 188, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stw r31,192(r11)
	PPC_STORE_U32(r11.u32 + 192, r31.u32);
	// lis r31,-32256
	r31.s64 = -2113929216;
	// stw r10,196(r11)
	PPC_STORE_U32(r11.u32 + 196, ctx.r10.u32);
	// stw r30,200(r11)
	PPC_STORE_U32(r11.u32 + 200, r30.u32);
	// li r30,25
	r30.s64 = 25;
	// stw r10,204(r11)
	PPC_STORE_U32(r11.u32 + 204, ctx.r10.u32);
	// addi r31,r31,28008
	r31.s64 = r31.s64 + 28008;
	// lfs f13,28016(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 28016);
	ctx.f13.f64 = double(temp.f32);
	// stw r10,208(r11)
	PPC_STORE_U32(r11.u32 + 208, ctx.r10.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stw r10,212(r11)
	PPC_STORE_U32(r11.u32 + 212, ctx.r10.u32);
	// stw r10,216(r11)
	PPC_STORE_U32(r11.u32 + 216, ctx.r10.u32);
	// stw r10,220(r11)
	PPC_STORE_U32(r11.u32 + 220, ctx.r10.u32);
	// stfs f13,232(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 232, temp.u32);
	// stfs f0,236(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 236, temp.u32);
	// lfs f13,28004(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 28004);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f13,240(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 240, temp.u32);
	// stw r5,224(r11)
	PPC_STORE_U32(r11.u32 + 224, ctx.r5.u32);
	// addi r9,r9,27992
	ctx.r9.s64 = ctx.r9.s64 + 27992;
	// lis r5,-32045
	ctx.r5.s64 = -2100101120;
	// addi r5,r5,-15384
	ctx.r5.s64 = ctx.r5.s64 + -15384;
	// stw r9,228(r11)
	PPC_STORE_U32(r11.u32 + 228, ctx.r9.u32);
	// lis r9,-32140
	ctx.r9.s64 = -2106327040;
	// lwz r9,-3960(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + -3960);
	// stw r9,244(r11)
	PPC_STORE_U32(r11.u32 + 244, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stw r8,248(r11)
	PPC_STORE_U32(r11.u32 + 248, ctx.r8.u32);
	// lis r8,-32036
	ctx.r8.s64 = -2099511296;
	// stw r7,252(r11)
	PPC_STORE_U32(r11.u32 + 252, ctx.r7.u32);
	// addi r9,r9,27984
	ctx.r9.s64 = ctx.r9.s64 + 27984;
	// stw r6,256(r11)
	PPC_STORE_U32(r11.u32 + 256, ctx.r6.u32);
	// lis r7,-32081
	ctx.r7.s64 = -2102460416;
	// stw r10,260(r11)
	PPC_STORE_U32(r11.u32 + 260, ctx.r10.u32);
	// addi r8,r8,7248
	ctx.r8.s64 = ctx.r8.s64 + 7248;
	// stw r10,264(r11)
	PPC_STORE_U32(r11.u32 + 264, ctx.r10.u32);
	// addi r7,r7,-10928
	ctx.r7.s64 = ctx.r7.s64 + -10928;
	// stw r10,268(r11)
	PPC_STORE_U32(r11.u32 + 268, ctx.r10.u32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// stw r10,272(r11)
	PPC_STORE_U32(r11.u32 + 272, ctx.r10.u32);
	// stw r10,276(r11)
	PPC_STORE_U32(r11.u32 + 276, ctx.r10.u32);
	// stw r30,280(r11)
	PPC_STORE_U32(r11.u32 + 280, r30.u32);
	// lis r30,-32256
	r30.s64 = -2113929216;
	// addi r6,r6,27976
	ctx.r6.s64 = ctx.r6.s64 + 27976;
	// lfs f13,27972(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 27972);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,288(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 288, temp.u32);
	// stw r9,284(r11)
	PPC_STORE_U32(r11.u32 + 284, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f0,292(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 292, temp.u32);
	// lfs f13,27968(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27968);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32123
	ctx.r9.s64 = -2105212928;
	// stfs f13,296(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 296, temp.u32);
	// lwz r9,32568(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 32568);
	// stw r9,300(r11)
	PPC_STORE_U32(r11.u32 + 300, ctx.r9.u32);
	// stw r8,304(r11)
	PPC_STORE_U32(r11.u32 + 304, ctx.r8.u32);
	// stw r10,308(r11)
	PPC_STORE_U32(r11.u32 + 308, ctx.r10.u32);
	// stw r7,312(r11)
	PPC_STORE_U32(r11.u32 + 312, ctx.r7.u32);
	// stw r10,316(r11)
	PPC_STORE_U32(r11.u32 + 316, ctx.r10.u32);
	// stw r10,320(r11)
	PPC_STORE_U32(r11.u32 + 320, ctx.r10.u32);
	// stw r10,324(r11)
	PPC_STORE_U32(r11.u32 + 324, ctx.r10.u32);
	// stw r10,328(r11)
	PPC_STORE_U32(r11.u32 + 328, ctx.r10.u32);
	// li r9,26
	ctx.r9.s64 = 26;
	// stw r10,332(r11)
	PPC_STORE_U32(r11.u32 + 332, ctx.r10.u32);
	// lis r8,-32033
	ctx.r8.s64 = -2099314688;
	// lis r7,-32092
	ctx.r7.s64 = -2103181312;
	// addi r8,r8,-12520
	ctx.r8.s64 = ctx.r8.s64 + -12520;
	// addi r7,r7,12752
	ctx.r7.s64 = ctx.r7.s64 + 12752;
	// stw r9,336(r11)
	PPC_STORE_U32(r11.u32 + 336, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// li r28,28
	r28.s64 = 28;
	// lis r30,-32034
	r30.s64 = -2099380224;
	// lis r29,-32103
	r29.s64 = -2103902208;
	// addi r30,r30,-24520
	r30.s64 = r30.s64 + -24520;
	// lfs f13,27964(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27964);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f13,344(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 344, temp.u32);
	// stw r6,340(r11)
	PPC_STORE_U32(r11.u32 + 340, ctx.r6.u32);
	// stfs f0,348(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 348, temp.u32);
	// lis r6,-32127
	ctx.r6.s64 = -2105475072;
	// addi r29,r29,-27824
	r29.s64 = r29.s64 + -27824;
	// lfs f13,27960(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27960);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32132
	ctx.r9.s64 = -2105802752;
	// stfs f13,352(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 352, temp.u32);
	// lwz r6,-27016(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + -27016);
	// lwz r9,23584(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 23584);
	// stw r9,356(r11)
	PPC_STORE_U32(r11.u32 + 356, ctx.r9.u32);
	// li r9,27
	ctx.r9.s64 = 27;
	// stw r5,360(r11)
	PPC_STORE_U32(r11.u32 + 360, ctx.r5.u32);
	// lis r5,-32043
	ctx.r5.s64 = -2099970048;
	// stw r4,364(r11)
	PPC_STORE_U32(r11.u32 + 364, ctx.r4.u32);
	// lis r4,-32096
	ctx.r4.s64 = -2103443456;
	// stw r3,368(r11)
	PPC_STORE_U32(r11.u32 + 368, ctx.r3.u32);
	// lis r3,-32256
	ctx.r3.s64 = -2113929216;
	// stw r10,372(r11)
	PPC_STORE_U32(r11.u32 + 372, ctx.r10.u32);
	// addi r5,r5,19520
	ctx.r5.s64 = ctx.r5.s64 + 19520;
	// stw r10,376(r11)
	PPC_STORE_U32(r11.u32 + 376, ctx.r10.u32);
	// addi r4,r4,19920
	ctx.r4.s64 = ctx.r4.s64 + 19920;
	// stw r10,380(r11)
	PPC_STORE_U32(r11.u32 + 380, ctx.r10.u32);
	// addi r3,r3,27952
	ctx.r3.s64 = ctx.r3.s64 + 27952;
	// stw r10,384(r11)
	PPC_STORE_U32(r11.u32 + 384, ctx.r10.u32);
	// stw r10,388(r11)
	PPC_STORE_U32(r11.u32 + 388, ctx.r10.u32);
	// stw r9,392(r11)
	PPC_STORE_U32(r11.u32 + 392, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f13,27948(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27948);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f13,400(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 400, temp.u32);
	// stw r31,396(r11)
	PPC_STORE_U32(r11.u32 + 396, r31.u32);
	// stfs f0,404(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 404, temp.u32);
	// lis r31,-32046
	r31.s64 = -2100166656;
	// addi r31,r31,-5568
	r31.s64 = r31.s64 + -5568;
	// lfs f13,27944(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27944);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32041
	ctx.r9.s64 = -2099838976;
	// stfs f13,408(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 408, temp.u32);
	// stw r6,412(r11)
	PPC_STORE_U32(r11.u32 + 412, ctx.r6.u32);
	// addi r9,r9,19472
	ctx.r9.s64 = ctx.r9.s64 + 19472;
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// addi r6,r6,27936
	ctx.r6.s64 = ctx.r6.s64 + 27936;
	// stw r9,416(r11)
	PPC_STORE_U32(r11.u32 + 416, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stw r8,420(r11)
	PPC_STORE_U32(r11.u32 + 420, ctx.r8.u32);
	// lis r8,-32050
	ctx.r8.s64 = -2100428800;
	// stw r7,424(r11)
	PPC_STORE_U32(r11.u32 + 424, ctx.r7.u32);
	// addi r9,r9,27928
	ctx.r9.s64 = ctx.r9.s64 + 27928;
	// stw r10,428(r11)
	PPC_STORE_U32(r11.u32 + 428, ctx.r10.u32);
	// lis r7,-32113
	ctx.r7.s64 = -2104557568;
	// stw r10,432(r11)
	PPC_STORE_U32(r11.u32 + 432, ctx.r10.u32);
	// addi r8,r8,-26232
	ctx.r8.s64 = ctx.r8.s64 + -26232;
	// stw r10,436(r11)
	PPC_STORE_U32(r11.u32 + 436, ctx.r10.u32);
	// addi r7,r7,-31936
	ctx.r7.s64 = ctx.r7.s64 + -31936;
	// stw r10,440(r11)
	PPC_STORE_U32(r11.u32 + 440, ctx.r10.u32);
	// stw r10,444(r11)
	PPC_STORE_U32(r11.u32 + 444, ctx.r10.u32);
	// stw r28,448(r11)
	PPC_STORE_U32(r11.u32 + 448, r28.u32);
	// lis r28,-32256
	r28.s64 = -2113929216;
	// lfs f13,27924(r28)
	temp.u32 = PPC_LOAD_U32(r28.u32 + 27924);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,456(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 456, temp.u32);
	// stw r9,452(r11)
	PPC_STORE_U32(r11.u32 + 452, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f0,460(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 460, temp.u32);
	// lfs f13,27920(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27920);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32137
	ctx.r9.s64 = -2106130432;
	// stfs f13,464(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 464, temp.u32);
	// li r27,31
	r27.s64 = 31;
	// lis r28,-32106
	r28.s64 = -2104098816;
	// addi r28,r28,-28240
	r28.s64 = r28.s64 + -28240;
	// lwz r9,28800(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 28800);
	// stw r9,468(r11)
	PPC_STORE_U32(r11.u32 + 468, ctx.r9.u32);
	// li r9,29
	ctx.r9.s64 = 29;
	// stw r8,472(r11)
	PPC_STORE_U32(r11.u32 + 472, ctx.r8.u32);
	// lis r8,-32034
	ctx.r8.s64 = -2099380224;
	// stw r10,476(r11)
	PPC_STORE_U32(r11.u32 + 476, ctx.r10.u32);
	// stw r7,480(r11)
	PPC_STORE_U32(r11.u32 + 480, ctx.r7.u32);
	// lis r7,-32094
	ctx.r7.s64 = -2103312384;
	// stw r10,484(r11)
	PPC_STORE_U32(r11.u32 + 484, ctx.r10.u32);
	// addi r8,r8,27960
	ctx.r8.s64 = ctx.r8.s64 + 27960;
	// stw r10,488(r11)
	PPC_STORE_U32(r11.u32 + 488, ctx.r10.u32);
	// addi r7,r7,-5632
	ctx.r7.s64 = ctx.r7.s64 + -5632;
	// stw r10,492(r11)
	PPC_STORE_U32(r11.u32 + 492, ctx.r10.u32);
	// stw r10,496(r11)
	PPC_STORE_U32(r11.u32 + 496, ctx.r10.u32);
	// stw r10,500(r11)
	PPC_STORE_U32(r11.u32 + 500, ctx.r10.u32);
	// stw r9,504(r11)
	PPC_STORE_U32(r11.u32 + 504, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f13,27916(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27916);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f13,512(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 512, temp.u32);
	// stw r6,508(r11)
	PPC_STORE_U32(r11.u32 + 508, ctx.r6.u32);
	// stfs f0,516(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 516, temp.u32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// addi r6,r6,27904
	ctx.r6.s64 = ctx.r6.s64 + 27904;
	// lfs f13,27912(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27912);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32129
	ctx.r9.s64 = -2105606144;
	// stfs f13,520(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 520, temp.u32);
	// lwz r9,-14532(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + -14532);
	// stw r9,524(r11)
	PPC_STORE_U32(r11.u32 + 524, ctx.r9.u32);
	// li r9,30
	ctx.r9.s64 = 30;
	// stw r5,528(r11)
	PPC_STORE_U32(r11.u32 + 528, ctx.r5.u32);
	// lis r5,-32048
	ctx.r5.s64 = -2100297728;
	// stw r10,532(r11)
	PPC_STORE_U32(r11.u32 + 532, ctx.r10.u32);
	// stw r4,536(r11)
	PPC_STORE_U32(r11.u32 + 536, ctx.r4.u32);
	// lis r4,-32035
	ctx.r4.s64 = -2099445760;
	// stw r10,540(r11)
	PPC_STORE_U32(r11.u32 + 540, ctx.r10.u32);
	// addi r5,r5,-9256
	ctx.r5.s64 = ctx.r5.s64 + -9256;
	// stw r10,544(r11)
	PPC_STORE_U32(r11.u32 + 544, ctx.r10.u32);
	// addi r4,r4,13576
	ctx.r4.s64 = ctx.r4.s64 + 13576;
	// stw r10,548(r11)
	PPC_STORE_U32(r11.u32 + 548, ctx.r10.u32);
	// stw r10,552(r11)
	PPC_STORE_U32(r11.u32 + 552, ctx.r10.u32);
	// stw r10,556(r11)
	PPC_STORE_U32(r11.u32 + 556, ctx.r10.u32);
	// stw r9,560(r11)
	PPC_STORE_U32(r11.u32 + 560, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f13,27900(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27900);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f13,568(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 568, temp.u32);
	// stw r3,564(r11)
	PPC_STORE_U32(r11.u32 + 564, ctx.r3.u32);
	// stfs f0,572(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 572, temp.u32);
	// lis r3,-32108
	ctx.r3.s64 = -2104229888;
	// addi r3,r3,15104
	ctx.r3.s64 = ctx.r3.s64 + 15104;
	// lfs f13,27896(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27896);
	ctx.f13.f64 = double(temp.f32);
	// lis r9,-32133
	ctx.r9.s64 = -2105868288;
	// stfs f13,576(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 576, temp.u32);
	// lwz r9,27056(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 27056);
	// stw r9,580(r11)
	PPC_STORE_U32(r11.u32 + 580, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stw r31,584(r11)
	PPC_STORE_U32(r11.u32 + 584, r31.u32);
	// lis r31,-32256
	r31.s64 = -2113929216;
	// stw r30,588(r11)
	PPC_STORE_U32(r11.u32 + 588, r30.u32);
	// lis r30,-32047
	r30.s64 = -2100232192;
	// stw r29,592(r11)
	PPC_STORE_U32(r11.u32 + 592, r29.u32);
	// lis r29,-32035
	r29.s64 = -2099445760;
	// stw r10,596(r11)
	PPC_STORE_U32(r11.u32 + 596, ctx.r10.u32);
	// addi r9,r9,27888
	ctx.r9.s64 = ctx.r9.s64 + 27888;
	// stw r10,600(r11)
	PPC_STORE_U32(r11.u32 + 600, ctx.r10.u32);
	// addi r31,r31,27884
	r31.s64 = r31.s64 + 27884;
	// stw r10,604(r11)
	PPC_STORE_U32(r11.u32 + 604, ctx.r10.u32);
	// addi r30,r30,5616
	r30.s64 = r30.s64 + 5616;
	// stw r10,608(r11)
	PPC_STORE_U32(r11.u32 + 608, ctx.r10.u32);
	// addi r29,r29,27392
	r29.s64 = r29.s64 + 27392;
	// stw r10,612(r11)
	PPC_STORE_U32(r11.u32 + 612, ctx.r10.u32);
	// stw r27,616(r11)
	PPC_STORE_U32(r11.u32 + 616, r27.u32);
	// lis r27,-32256
	r27.s64 = -2113929216;
	// lfs f13,27880(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 27880);
	ctx.f13.f64 = double(temp.f32);
	// stfs f13,624(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 624, temp.u32);
	// stw r9,620(r11)
	PPC_STORE_U32(r11.u32 + 620, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f0,628(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 628, temp.u32);
	// lfs f11,27876(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27876);
	ctx.f11.f64 = double(temp.f32);
	// lis r9,-32129
	ctx.r9.s64 = -2105606144;
	// stfs f11,632(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r11.u32 + 632, temp.u32);
	// lwz r9,4304(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 4304);
	// stw r9,636(r11)
	PPC_STORE_U32(r11.u32 + 636, ctx.r9.u32);
	// li r9,32
	ctx.r9.s64 = 32;
	// stw r10,640(r11)
	PPC_STORE_U32(r11.u32 + 640, ctx.r10.u32);
	// stw r8,644(r11)
	PPC_STORE_U32(r11.u32 + 644, ctx.r8.u32);
	// lis r8,-32051
	ctx.r8.s64 = -2100494336;
	// stw r7,648(r11)
	PPC_STORE_U32(r11.u32 + 648, ctx.r7.u32);
	// lis r7,-32035
	ctx.r7.s64 = -2099445760;
	// stw r10,652(r11)
	PPC_STORE_U32(r11.u32 + 652, ctx.r10.u32);
	// addi r8,r8,-31632
	ctx.r8.s64 = ctx.r8.s64 + -31632;
	// stw r10,656(r11)
	PPC_STORE_U32(r11.u32 + 656, ctx.r10.u32);
	// addi r7,r7,-18032
	ctx.r7.s64 = ctx.r7.s64 + -18032;
	// stw r10,660(r11)
	PPC_STORE_U32(r11.u32 + 660, ctx.r10.u32);
	// stw r10,664(r11)
	PPC_STORE_U32(r11.u32 + 664, ctx.r10.u32);
	// stw r10,668(r11)
	PPC_STORE_U32(r11.u32 + 668, ctx.r10.u32);
	// stw r9,672(r11)
	PPC_STORE_U32(r11.u32 + 672, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f12,27872(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27872);
	ctx.f12.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f12,680(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 680, temp.u32);
	// stw r6,676(r11)
	PPC_STORE_U32(r11.u32 + 676, ctx.r6.u32);
	// stfs f0,684(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 684, temp.u32);
	// lis r6,-32117
	ctx.r6.s64 = -2104819712;
	// addi r6,r6,29632
	ctx.r6.s64 = ctx.r6.s64 + 29632;
	// lfs f12,27868(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27868);
	ctx.f12.f64 = double(temp.f32);
	// lis r9,-32135
	ctx.r9.s64 = -2105999360;
	// stfs f12,688(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 688, temp.u32);
	// lwz r9,704(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 704);
	// stw r9,692(r11)
	PPC_STORE_U32(r11.u32 + 692, ctx.r9.u32);
	// li r9,33
	ctx.r9.s64 = 33;
	// stw r5,696(r11)
	PPC_STORE_U32(r11.u32 + 696, ctx.r5.u32);
	// lis r5,-32256
	ctx.r5.s64 = -2113929216;
	// stw r4,700(r11)
	PPC_STORE_U32(r11.u32 + 700, ctx.r4.u32);
	// stw r3,704(r11)
	PPC_STORE_U32(r11.u32 + 704, ctx.r3.u32);
	// stw r10,708(r11)
	PPC_STORE_U32(r11.u32 + 708, ctx.r10.u32);
	// stw r10,712(r11)
	PPC_STORE_U32(r11.u32 + 712, ctx.r10.u32);
	// stw r10,716(r11)
	PPC_STORE_U32(r11.u32 + 716, ctx.r10.u32);
	// stw r10,720(r11)
	PPC_STORE_U32(r11.u32 + 720, ctx.r10.u32);
	// stw r10,724(r11)
	PPC_STORE_U32(r11.u32 + 724, ctx.r10.u32);
	// stw r9,728(r11)
	PPC_STORE_U32(r11.u32 + 728, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f12,27860(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27860);
	ctx.f12.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f12,736(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 736, temp.u32);
	// stw r31,732(r11)
	PPC_STORE_U32(r11.u32 + 732, r31.u32);
	// lfs f12,12892(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 12892);
	ctx.f12.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f12,740(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 740, temp.u32);
	// lfs f10,2944(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 2944);
	ctx.f10.f64 = double(temp.f32);
	// lis r9,-32134
	ctx.r9.s64 = -2105933824;
	// stfs f10,744(r11)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(r11.u32 + 744, temp.u32);
	// lfs f10,27864(r5)
	temp.u32 = PPC_LOAD_U32(ctx.r5.u32 + 27864);
	ctx.f10.f64 = double(temp.f32);
	// li r5,34
	ctx.r5.s64 = 34;
	// lwz r9,25236(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25236);
	// stw r9,748(r11)
	PPC_STORE_U32(r11.u32 + 748, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stw r30,752(r11)
	PPC_STORE_U32(r11.u32 + 752, r30.u32);
	// stw r29,756(r11)
	PPC_STORE_U32(r11.u32 + 756, r29.u32);
	// addi r9,r9,27848
	ctx.r9.s64 = ctx.r9.s64 + 27848;
	// stw r28,760(r11)
	PPC_STORE_U32(r11.u32 + 760, r28.u32);
	// stw r10,764(r11)
	PPC_STORE_U32(r11.u32 + 764, ctx.r10.u32);
	// stw r10,768(r11)
	PPC_STORE_U32(r11.u32 + 768, ctx.r10.u32);
	// stw r10,772(r11)
	PPC_STORE_U32(r11.u32 + 772, ctx.r10.u32);
	// stw r10,776(r11)
	PPC_STORE_U32(r11.u32 + 776, ctx.r10.u32);
	// stw r10,780(r11)
	PPC_STORE_U32(r11.u32 + 780, ctx.r10.u32);
	// stfs f10,792(r11)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(r11.u32 + 792, temp.u32);
	// stw r5,784(r11)
	PPC_STORE_U32(r11.u32 + 784, ctx.r5.u32);
	// stfs f0,796(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 796, temp.u32);
	// stw r9,788(r11)
	PPC_STORE_U32(r11.u32 + 788, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// li r30,35
	r30.s64 = 35;
	// lis r31,-32256
	r31.s64 = -2113929216;
	// addi r31,r31,27836
	r31.s64 = r31.s64 + 27836;
	// lfs f10,27844(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27844);
	ctx.f10.f64 = double(temp.f32);
	// lis r9,-32138
	ctx.r9.s64 = -2106195968;
	// stfs f10,800(r11)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(r11.u32 + 800, temp.u32);
	// lwz r9,25016(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 25016);
	// stw r9,804(r11)
	PPC_STORE_U32(r11.u32 + 804, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stw r8,808(r11)
	PPC_STORE_U32(r11.u32 + 808, ctx.r8.u32);
	// lis r8,-32042
	ctx.r8.s64 = -2099904512;
	// stw r7,812(r11)
	PPC_STORE_U32(r11.u32 + 812, ctx.r7.u32);
	// addi r9,r9,27828
	ctx.r9.s64 = ctx.r9.s64 + 27828;
	// stw r6,816(r11)
	PPC_STORE_U32(r11.u32 + 816, ctx.r6.u32);
	// addi r6,r8,-15816
	ctx.r6.s64 = ctx.r8.s64 + -15816;
	// stw r10,820(r11)
	PPC_STORE_U32(r11.u32 + 820, ctx.r10.u32);
	// lis r8,-32033
	ctx.r8.s64 = -2099314688;
	// stw r10,824(r11)
	PPC_STORE_U32(r11.u32 + 824, ctx.r10.u32);
	// lis r7,-32040
	ctx.r7.s64 = -2099773440;
	// stw r10,828(r11)
	PPC_STORE_U32(r11.u32 + 828, ctx.r10.u32);
	// addi r5,r8,-28632
	ctx.r5.s64 = ctx.r8.s64 + -28632;
	// stw r10,832(r11)
	PPC_STORE_U32(r11.u32 + 832, ctx.r10.u32);
	// lis r8,-32093
	ctx.r8.s64 = -2103246848;
	// stw r10,836(r11)
	PPC_STORE_U32(r11.u32 + 836, ctx.r10.u32);
	// stw r30,840(r11)
	PPC_STORE_U32(r11.u32 + 840, r30.u32);
	// lis r30,-32256
	r30.s64 = -2113929216;
	// addi r4,r8,-32752
	ctx.r4.s64 = ctx.r8.s64 + -32752;
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// addi r3,r7,22504
	ctx.r3.s64 = ctx.r7.s64 + 22504;
	// addi r8,r8,27816
	ctx.r8.s64 = ctx.r8.s64 + 27816;
	// lfs f10,27824(r30)
	temp.u32 = PPC_LOAD_U32(r30.u32 + 27824);
	ctx.f10.f64 = double(temp.f32);
	// lis r7,-32090
	ctx.r7.s64 = -2103050240;
	// stfs f10,848(r11)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(r11.u32 + 848, temp.u32);
	// stw r9,844(r11)
	PPC_STORE_U32(r11.u32 + 844, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f0,852(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 852, temp.u32);
	// addi r7,r7,-8336
	ctx.r7.s64 = ctx.r7.s64 + -8336;
	// lfs f10,27812(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27812);
	ctx.f10.f64 = double(temp.f32);
	// lis r9,-32129
	ctx.r9.s64 = -2105606144;
	// stfs f10,856(r11)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(r11.u32 + 856, temp.u32);
	// lwz r9,21452(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + 21452);
	// stw r9,860(r11)
	PPC_STORE_U32(r11.u32 + 860, ctx.r9.u32);
	// li r9,36
	ctx.r9.s64 = 36;
	// stw r6,864(r11)
	PPC_STORE_U32(r11.u32 + 864, ctx.r6.u32);
	// stw r5,868(r11)
	PPC_STORE_U32(r11.u32 + 868, ctx.r5.u32);
	// stw r4,872(r11)
	PPC_STORE_U32(r11.u32 + 872, ctx.r4.u32);
	// stw r10,876(r11)
	PPC_STORE_U32(r11.u32 + 876, ctx.r10.u32);
	// stw r10,880(r11)
	PPC_STORE_U32(r11.u32 + 880, ctx.r10.u32);
	// stw r10,884(r11)
	PPC_STORE_U32(r11.u32 + 884, ctx.r10.u32);
	// stw r10,888(r11)
	PPC_STORE_U32(r11.u32 + 888, ctx.r10.u32);
	// stw r10,892(r11)
	PPC_STORE_U32(r11.u32 + 892, ctx.r10.u32);
	// stw r9,896(r11)
	PPC_STORE_U32(r11.u32 + 896, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f10,27808(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27808);
	ctx.f10.f64 = double(temp.f32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stfs f10,904(r11)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(r11.u32 + 904, temp.u32);
	// stw r8,900(r11)
	PPC_STORE_U32(r11.u32 + 900, ctx.r8.u32);
	// stfs f12,908(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 908, temp.u32);
	// lfs f9,27804(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27804);
	ctx.f9.f64 = double(temp.f32);
	// lis r9,-32126
	ctx.r9.s64 = -2105409536;
	// stfs f9,912(r11)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(r11.u32 + 912, temp.u32);
	// lwz r9,-9392(r9)
	ctx.r9.u64 = PPC_LOAD_U32(ctx.r9.u32 + -9392);
	// stw r9,916(r11)
	PPC_STORE_U32(r11.u32 + 916, ctx.r9.u32);
	// li r9,37
	ctx.r9.s64 = 37;
	// stw r3,920(r11)
	PPC_STORE_U32(r11.u32 + 920, ctx.r3.u32);
	// stw r10,924(r11)
	PPC_STORE_U32(r11.u32 + 924, ctx.r10.u32);
	// stw r7,928(r11)
	PPC_STORE_U32(r11.u32 + 928, ctx.r7.u32);
	// stw r10,932(r11)
	PPC_STORE_U32(r11.u32 + 932, ctx.r10.u32);
	// stw r10,936(r11)
	PPC_STORE_U32(r11.u32 + 936, ctx.r10.u32);
	// stw r10,940(r11)
	PPC_STORE_U32(r11.u32 + 940, ctx.r10.u32);
	// stw r10,944(r11)
	PPC_STORE_U32(r11.u32 + 944, ctx.r10.u32);
	// stw r10,948(r11)
	PPC_STORE_U32(r11.u32 + 948, ctx.r10.u32);
	// stw r9,952(r11)
	PPC_STORE_U32(r11.u32 + 952, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lfs f8,27800(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27800);
	ctx.f8.f64 = double(temp.f32);
	// stfs f8,960(r11)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(r11.u32 + 960, temp.u32);
	// stfs f0,964(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 964, temp.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lis r5,-32130
	ctx.r5.s64 = -2105671680;
	// lis r6,-32098
	ctx.r6.s64 = -2103574528;
	// li r27,38
	r27.s64 = 38;
	// addi r6,r6,32496
	ctx.r6.s64 = ctx.r6.s64 + 32496;
	// lfs f7,27796(r9)
	temp.u32 = PPC_LOAD_U32(ctx.r9.u32 + 27796);
	ctx.f7.f64 = double(temp.f32);
	// lis r9,-32044
	ctx.r9.s64 = -2100035584;
	// lwz r5,-14632(r5)
	ctx.r5.u64 = PPC_LOAD_U32(ctx.r5.u32 + -14632);
	// stfs f7,968(r11)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(r11.u32 + 968, temp.u32);
	// addi r9,r9,17472
	ctx.r9.s64 = ctx.r9.s64 + 17472;
	// stw r31,956(r11)
	PPC_STORE_U32(r11.u32 + 956, r31.u32);
	// lis r28,-32111
	r28.s64 = -2104426496;
	// addi r28,r28,-25200
	r28.s64 = r28.s64 + -25200;
	// stw r5,972(r11)
	PPC_STORE_U32(r11.u32 + 972, ctx.r5.u32);
	// stw r9,976(r11)
	PPC_STORE_U32(r11.u32 + 976, ctx.r9.u32);
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// stw r10,980(r11)
	PPC_STORE_U32(r11.u32 + 980, ctx.r10.u32);
	// stw r6,984(r11)
	PPC_STORE_U32(r11.u32 + 984, ctx.r6.u32);
	// addi r6,r9,27784
	ctx.r6.s64 = ctx.r9.s64 + 27784;
	// stw r10,988(r11)
	PPC_STORE_U32(r11.u32 + 988, ctx.r10.u32);
	// lis r9,-32034
	ctx.r9.s64 = -2099380224;
	// stw r10,992(r11)
	PPC_STORE_U32(r11.u32 + 992, ctx.r10.u32);
	// stw r10,996(r11)
	PPC_STORE_U32(r11.u32 + 996, ctx.r10.u32);
	// addi r5,r9,6616
	ctx.r5.s64 = ctx.r9.s64 + 6616;
	// stw r10,1000(r11)
	PPC_STORE_U32(r11.u32 + 1000, ctx.r10.u32);
	// lis r9,-32098
	ctx.r9.s64 = -2103574528;
	// stw r10,1004(r11)
	PPC_STORE_U32(r11.u32 + 1004, ctx.r10.u32);
	// stw r27,1008(r11)
	PPC_STORE_U32(r11.u32 + 1008, r27.u32);
	// lis r27,-32256
	r27.s64 = -2113929216;
	// addi r4,r9,13952
	ctx.r4.s64 = ctx.r9.s64 + 13952;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// addi r3,r9,27772
	ctx.r3.s64 = ctx.r9.s64 + 27772;
	// lfs f6,27780(r27)
	temp.u32 = PPC_LOAD_U32(r27.u32 + 27780);
	ctx.f6.f64 = double(temp.f32);
	// lis r9,-32049
	ctx.r9.s64 = -2100363264;
	// stfs f6,1016(r11)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(r11.u32 + 1016, temp.u32);
	// stw r6,1012(r11)
	PPC_STORE_U32(r11.u32 + 1012, ctx.r6.u32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// stfs f0,1020(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1020, temp.u32);
	// addi r31,r9,-3040
	r31.s64 = ctx.r9.s64 + -3040;
	// lis r9,-32035
	ctx.r9.s64 = -2099445760;
	// addi r30,r9,7448
	r30.s64 = ctx.r9.s64 + 7448;
	// lfs f6,27768(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 27768);
	ctx.f6.f64 = double(temp.f32);
	// lis r6,-32132
	ctx.r6.s64 = -2105802752;
	// stfs f6,1024(r11)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(r11.u32 + 1024, temp.u32);
	// lis r9,-32111
	ctx.r9.s64 = -2104426496;
	// addi r29,r9,-3392
	r29.s64 = ctx.r9.s64 + -3392;
	// lis r9,-32256
	ctx.r9.s64 = -2113929216;
	// lwz r6,31192(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 31192);
	// addi r9,r9,2334
	ctx.r9.s64 = ctx.r9.s64 + 2334;
	// stw r6,1028(r11)
	PPC_STORE_U32(r11.u32 + 1028, ctx.r6.u32);
	// li r6,39
	ctx.r6.s64 = 39;
	// stw r10,1032(r11)
	PPC_STORE_U32(r11.u32 + 1032, ctx.r10.u32);
	// stw r5,1036(r11)
	PPC_STORE_U32(r11.u32 + 1036, ctx.r5.u32);
	// stw r4,1040(r11)
	PPC_STORE_U32(r11.u32 + 1040, ctx.r4.u32);
	// stw r10,1044(r11)
	PPC_STORE_U32(r11.u32 + 1044, ctx.r10.u32);
	// stw r10,1048(r11)
	PPC_STORE_U32(r11.u32 + 1048, ctx.r10.u32);
	// stw r10,1052(r11)
	PPC_STORE_U32(r11.u32 + 1052, ctx.r10.u32);
	// stw r10,1056(r11)
	PPC_STORE_U32(r11.u32 + 1056, ctx.r10.u32);
	// stw r10,1060(r11)
	PPC_STORE_U32(r11.u32 + 1060, ctx.r10.u32);
	// stw r6,1064(r11)
	PPC_STORE_U32(r11.u32 + 1064, ctx.r6.u32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// lfs f6,27764(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 27764);
	ctx.f6.f64 = double(temp.f32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// stfs f6,1072(r11)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(r11.u32 + 1072, temp.u32);
	// stw r3,1068(r11)
	PPC_STORE_U32(r11.u32 + 1068, ctx.r3.u32);
	// stfs f0,1076(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1076, temp.u32);
	// lfs f6,27760(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 27760);
	ctx.f6.f64 = double(temp.f32);
	// lis r6,-32136
	ctx.r6.s64 = -2106064896;
	// stfs f6,1080(r11)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(r11.u32 + 1080, temp.u32);
	// lwz r6,10360(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 10360);
	// stw r6,1084(r11)
	PPC_STORE_U32(r11.u32 + 1084, ctx.r6.u32);
	// stw r31,1088(r11)
	PPC_STORE_U32(r11.u32 + 1088, r31.u32);
	// stw r30,1092(r11)
	PPC_STORE_U32(r11.u32 + 1092, r30.u32);
	// stw r29,1096(r11)
	PPC_STORE_U32(r11.u32 + 1096, r29.u32);
	// stw r10,1100(r11)
	PPC_STORE_U32(r11.u32 + 1100, ctx.r10.u32);
	// stw r10,1104(r11)
	PPC_STORE_U32(r11.u32 + 1104, ctx.r10.u32);
	// stw r10,1108(r11)
	PPC_STORE_U32(r11.u32 + 1108, ctx.r10.u32);
	// stw r10,1112(r11)
	PPC_STORE_U32(r11.u32 + 1112, ctx.r10.u32);
	// stw r10,1116(r11)
	PPC_STORE_U32(r11.u32 + 1116, ctx.r10.u32);
	// li r6,40
	ctx.r6.s64 = 40;
	// li r31,41
	r31.s64 = 41;
	// lis r5,-32049
	ctx.r5.s64 = -2100363264;
	// lis r4,-32109
	ctx.r4.s64 = -2104295424;
	// addi r5,r5,19208
	ctx.r5.s64 = ctx.r5.s64 + 19208;
	// stw r6,1120(r11)
	PPC_STORE_U32(r11.u32 + 1120, ctx.r6.u32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// addi r4,r4,14256
	ctx.r4.s64 = ctx.r4.s64 + 14256;
	// lis r3,-32039
	ctx.r3.s64 = -2099707904;
	// addi r3,r3,15568
	ctx.r3.s64 = ctx.r3.s64 + 15568;
	// lfs f6,27756(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 27756);
	ctx.f6.f64 = double(temp.f32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// stfs f6,1128(r11)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(r11.u32 + 1128, temp.u32);
	// stw r9,1124(r11)
	PPC_STORE_U32(r11.u32 + 1124, ctx.r9.u32);
	// stfs f0,1132(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1132, temp.u32);
	// lfs f6,27752(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 27752);
	ctx.f6.f64 = double(temp.f32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// stfs f6,1136(r11)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(r11.u32 + 1136, temp.u32);
	// stw r10,1140(r11)
	PPC_STORE_U32(r11.u32 + 1140, ctx.r10.u32);
	// stw r10,1144(r11)
	PPC_STORE_U32(r11.u32 + 1144, ctx.r10.u32);
	// addi r6,r6,27744
	ctx.r6.s64 = ctx.r6.s64 + 27744;
	// stw r10,1148(r11)
	PPC_STORE_U32(r11.u32 + 1148, ctx.r10.u32);
	// stw r28,1152(r11)
	PPC_STORE_U32(r11.u32 + 1152, r28.u32);
	// stw r10,1156(r11)
	PPC_STORE_U32(r11.u32 + 1156, ctx.r10.u32);
	// stw r10,1160(r11)
	PPC_STORE_U32(r11.u32 + 1160, ctx.r10.u32);
	// stw r10,1164(r11)
	PPC_STORE_U32(r11.u32 + 1164, ctx.r10.u32);
	// stw r10,1168(r11)
	PPC_STORE_U32(r11.u32 + 1168, ctx.r10.u32);
	// stw r10,1172(r11)
	PPC_STORE_U32(r11.u32 + 1172, ctx.r10.u32);
	// stw r31,1176(r11)
	PPC_STORE_U32(r11.u32 + 1176, r31.u32);
	// lis r31,-32256
	r31.s64 = -2113929216;
	// lfs f6,27740(r31)
	temp.u32 = PPC_LOAD_U32(r31.u32 + 27740);
	ctx.f6.f64 = double(temp.f32);
	// stfs f6,1184(r11)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(r11.u32 + 1184, temp.u32);
	// stw r6,1180(r11)
	PPC_STORE_U32(r11.u32 + 1180, ctx.r6.u32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// stfs f0,1188(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1188, temp.u32);
	// lfs f6,27736(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 27736);
	ctx.f6.f64 = double(temp.f32);
	// lis r6,-32135
	ctx.r6.s64 = -2105999360;
	// stfs f6,1192(r11)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(r11.u32 + 1192, temp.u32);
	// lwz r6,-29796(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + -29796);
	// stw r6,1196(r11)
	PPC_STORE_U32(r11.u32 + 1196, ctx.r6.u32);
	// li r6,42
	ctx.r6.s64 = 42;
	// stw r5,1200(r11)
	PPC_STORE_U32(r11.u32 + 1200, ctx.r5.u32);
	// stw r10,1204(r11)
	PPC_STORE_U32(r11.u32 + 1204, ctx.r10.u32);
	// stw r4,1208(r11)
	PPC_STORE_U32(r11.u32 + 1208, ctx.r4.u32);
	// stw r10,1212(r11)
	PPC_STORE_U32(r11.u32 + 1212, ctx.r10.u32);
	// stw r10,1216(r11)
	PPC_STORE_U32(r11.u32 + 1216, ctx.r10.u32);
	// stw r10,1220(r11)
	PPC_STORE_U32(r11.u32 + 1220, ctx.r10.u32);
	// stw r10,1224(r11)
	PPC_STORE_U32(r11.u32 + 1224, ctx.r10.u32);
	// stw r10,1228(r11)
	PPC_STORE_U32(r11.u32 + 1228, ctx.r10.u32);
	// stw r6,1232(r11)
	PPC_STORE_U32(r11.u32 + 1232, ctx.r6.u32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// lfs f6,27732(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 27732);
	ctx.f6.f64 = double(temp.f32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// stfs f6,1240(r11)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(r11.u32 + 1240, temp.u32);
	// stw r9,1236(r11)
	PPC_STORE_U32(r11.u32 + 1236, ctx.r9.u32);
	// stfs f0,1244(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1244, temp.u32);
	// lfs f6,27728(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 27728);
	ctx.f6.f64 = double(temp.f32);
	// lis r6,-32125
	ctx.r6.s64 = -2105344000;
	// stfs f6,1248(r11)
	temp.f32 = float(ctx.f6.f64);
	PPC_STORE_U32(r11.u32 + 1248, temp.u32);
	// lwz r6,10448(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 10448);
	// stw r6,1252(r11)
	PPC_STORE_U32(r11.u32 + 1252, ctx.r6.u32);
	// li r6,43
	ctx.r6.s64 = 43;
	// stw r10,1256(r11)
	PPC_STORE_U32(r11.u32 + 1256, ctx.r10.u32);
	// stw r10,1260(r11)
	PPC_STORE_U32(r11.u32 + 1260, ctx.r10.u32);
	// stw r10,1264(r11)
	PPC_STORE_U32(r11.u32 + 1264, ctx.r10.u32);
	// stw r10,1268(r11)
	PPC_STORE_U32(r11.u32 + 1268, ctx.r10.u32);
	// stw r10,1272(r11)
	PPC_STORE_U32(r11.u32 + 1272, ctx.r10.u32);
	// stw r10,1276(r11)
	PPC_STORE_U32(r11.u32 + 1276, ctx.r10.u32);
	// stw r10,1280(r11)
	PPC_STORE_U32(r11.u32 + 1280, ctx.r10.u32);
	// stw r10,1284(r11)
	PPC_STORE_U32(r11.u32 + 1284, ctx.r10.u32);
	// stw r6,1288(r11)
	PPC_STORE_U32(r11.u32 + 1288, ctx.r6.u32);
	// stfs f10,1296(r11)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(r11.u32 + 1296, temp.u32);
	// stw r8,1292(r11)
	PPC_STORE_U32(r11.u32 + 1292, ctx.r8.u32);
	// lis r8,-32125
	ctx.r8.s64 = -2105344000;
	// stfs f12,1300(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 1300, temp.u32);
	// stfs f9,1304(r11)
	temp.f32 = float(ctx.f9.f64);
	PPC_STORE_U32(r11.u32 + 1304, temp.u32);
	// lwz r8,8232(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8232);
	// stw r8,1308(r11)
	PPC_STORE_U32(r11.u32 + 1308, ctx.r8.u32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// stw r3,1312(r11)
	PPC_STORE_U32(r11.u32 + 1312, ctx.r3.u32);
	// lis r6,-32035
	ctx.r6.s64 = -2099445760;
	// stw r10,1316(r11)
	PPC_STORE_U32(r11.u32 + 1316, ctx.r10.u32);
	// stw r7,1320(r11)
	PPC_STORE_U32(r11.u32 + 1320, ctx.r7.u32);
	// addi r4,r6,-4024
	ctx.r4.s64 = ctx.r6.s64 + -4024;
	// stw r10,1324(r11)
	PPC_STORE_U32(r11.u32 + 1324, ctx.r10.u32);
	// li r6,45
	ctx.r6.s64 = 45;
	// stw r10,1328(r11)
	PPC_STORE_U32(r11.u32 + 1328, ctx.r10.u32);
	// lfs f12,27724(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 27724);
	ctx.f12.f64 = double(temp.f32);
	// stw r10,1332(r11)
	PPC_STORE_U32(r11.u32 + 1332, ctx.r10.u32);
	// li r8,44
	ctx.r8.s64 = 44;
	// stw r10,1336(r11)
	PPC_STORE_U32(r11.u32 + 1336, ctx.r10.u32);
	// lis r7,-32034
	ctx.r7.s64 = -2099380224;
	// stw r10,1340(r11)
	PPC_STORE_U32(r11.u32 + 1340, ctx.r10.u32);
	// stfs f13,1352(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1352, temp.u32);
	// addi r5,r7,14752
	ctx.r5.s64 = ctx.r7.s64 + 14752;
	// stfs f0,1356(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1356, temp.u32);
	// lis r7,-32122
	ctx.r7.s64 = -2105147392;
	// stfs f12,1360(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 1360, temp.u32);
	// stw r8,1344(r11)
	PPC_STORE_U32(r11.u32 + 1344, ctx.r8.u32);
	// stw r9,1348(r11)
	PPC_STORE_U32(r11.u32 + 1348, ctx.r9.u32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// stw r10,1364(r11)
	PPC_STORE_U32(r11.u32 + 1364, ctx.r10.u32);
	// addi r7,r7,-27152
	ctx.r7.s64 = ctx.r7.s64 + -27152;
	// stw r10,1368(r11)
	PPC_STORE_U32(r11.u32 + 1368, ctx.r10.u32);
	// addi r8,r8,27716
	ctx.r8.s64 = ctx.r8.s64 + 27716;
	// stw r10,1372(r11)
	PPC_STORE_U32(r11.u32 + 1372, ctx.r10.u32);
	// stw r10,1376(r11)
	PPC_STORE_U32(r11.u32 + 1376, ctx.r10.u32);
	// stw r10,1380(r11)
	PPC_STORE_U32(r11.u32 + 1380, ctx.r10.u32);
	// stw r10,1384(r11)
	PPC_STORE_U32(r11.u32 + 1384, ctx.r10.u32);
	// stw r10,1388(r11)
	PPC_STORE_U32(r11.u32 + 1388, ctx.r10.u32);
	// stw r10,1392(r11)
	PPC_STORE_U32(r11.u32 + 1392, ctx.r10.u32);
	// stw r10,1396(r11)
	PPC_STORE_U32(r11.u32 + 1396, ctx.r10.u32);
	// stw r6,1400(r11)
	PPC_STORE_U32(r11.u32 + 1400, ctx.r6.u32);
	// lis r6,-32256
	ctx.r6.s64 = -2113929216;
	// lfs f10,27712(r6)
	temp.u32 = PPC_LOAD_U32(ctx.r6.u32 + 27712);
	ctx.f10.f64 = double(temp.f32);
	// lis r6,-32141
	ctx.r6.s64 = -2106392576;
	// stfs f10,1408(r11)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(r11.u32 + 1408, temp.u32);
	// stw r8,1404(r11)
	PPC_STORE_U32(r11.u32 + 1404, ctx.r8.u32);
	// stfs f0,1412(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1412, temp.u32);
	// stfs f11,1416(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r11.u32 + 1416, temp.u32);
	// lwz r6,5912(r6)
	ctx.r6.u64 = PPC_LOAD_U32(ctx.r6.u32 + 5912);
	// stw r6,1420(r11)
	PPC_STORE_U32(r11.u32 + 1420, ctx.r6.u32);
	// stw r10,1424(r11)
	PPC_STORE_U32(r11.u32 + 1424, ctx.r10.u32);
	// stw r5,1428(r11)
	PPC_STORE_U32(r11.u32 + 1428, ctx.r5.u32);
	// li r5,46
	ctx.r5.s64 = 46;
	// stw r7,1432(r11)
	PPC_STORE_U32(r11.u32 + 1432, ctx.r7.u32);
	// stw r10,1436(r11)
	PPC_STORE_U32(r11.u32 + 1436, ctx.r10.u32);
	// stw r10,1440(r11)
	PPC_STORE_U32(r11.u32 + 1440, ctx.r10.u32);
	// stw r10,1444(r11)
	PPC_STORE_U32(r11.u32 + 1444, ctx.r10.u32);
	// stw r10,1448(r11)
	PPC_STORE_U32(r11.u32 + 1448, ctx.r10.u32);
	// stw r10,1452(r11)
	PPC_STORE_U32(r11.u32 + 1452, ctx.r10.u32);
	// stw r5,1456(r11)
	PPC_STORE_U32(r11.u32 + 1456, ctx.r5.u32);
	// stfs f10,1464(r11)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(r11.u32 + 1464, temp.u32);
	// stw r8,1460(r11)
	PPC_STORE_U32(r11.u32 + 1460, ctx.r8.u32);
	// stfs f0,1468(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1468, temp.u32);
	// stfs f11,1472(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r11.u32 + 1472, temp.u32);
	// stw r6,1476(r11)
	PPC_STORE_U32(r11.u32 + 1476, ctx.r6.u32);
	// stw r10,1480(r11)
	PPC_STORE_U32(r11.u32 + 1480, ctx.r10.u32);
	// li r5,47
	ctx.r5.s64 = 47;
	// stw r4,1484(r11)
	PPC_STORE_U32(r11.u32 + 1484, ctx.r4.u32);
	// stw r7,1488(r11)
	PPC_STORE_U32(r11.u32 + 1488, ctx.r7.u32);
	// stw r10,1492(r11)
	PPC_STORE_U32(r11.u32 + 1492, ctx.r10.u32);
	// stw r10,1496(r11)
	PPC_STORE_U32(r11.u32 + 1496, ctx.r10.u32);
	// stw r10,1500(r11)
	PPC_STORE_U32(r11.u32 + 1500, ctx.r10.u32);
	// stw r10,1504(r11)
	PPC_STORE_U32(r11.u32 + 1504, ctx.r10.u32);
	// stw r10,1508(r11)
	PPC_STORE_U32(r11.u32 + 1508, ctx.r10.u32);
	// stw r5,1512(r11)
	PPC_STORE_U32(r11.u32 + 1512, ctx.r5.u32);
	// stfs f13,1520(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1520, temp.u32);
	// stw r9,1516(r11)
	PPC_STORE_U32(r11.u32 + 1516, ctx.r9.u32);
	// stfs f0,1524(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1524, temp.u32);
	// stfs f12,1528(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 1528, temp.u32);
	// stw r10,1532(r11)
	PPC_STORE_U32(r11.u32 + 1532, ctx.r10.u32);
	// stw r10,1536(r11)
	PPC_STORE_U32(r11.u32 + 1536, ctx.r10.u32);
	// stw r10,1540(r11)
	PPC_STORE_U32(r11.u32 + 1540, ctx.r10.u32);
	// stw r10,1544(r11)
	PPC_STORE_U32(r11.u32 + 1544, ctx.r10.u32);
	// li r30,48
	r30.s64 = 48;
	// stw r10,1548(r11)
	PPC_STORE_U32(r11.u32 + 1548, ctx.r10.u32);
	// lis r5,-32036
	ctx.r5.s64 = -2099511296;
	// stw r10,1552(r11)
	PPC_STORE_U32(r11.u32 + 1552, ctx.r10.u32);
	// lis r4,-32256
	ctx.r4.s64 = -2113929216;
	// stw r10,1556(r11)
	PPC_STORE_U32(r11.u32 + 1556, ctx.r10.u32);
	// addi r5,r5,23744
	ctx.r5.s64 = ctx.r5.s64 + 23744;
	// stw r10,1560(r11)
	PPC_STORE_U32(r11.u32 + 1560, ctx.r10.u32);
	// addi r4,r4,27704
	ctx.r4.s64 = ctx.r4.s64 + 27704;
	// stw r10,1564(r11)
	PPC_STORE_U32(r11.u32 + 1564, ctx.r10.u32);
	// stw r30,1568(r11)
	PPC_STORE_U32(r11.u32 + 1568, r30.u32);
	// stfs f10,1576(r11)
	temp.f32 = float(ctx.f10.f64);
	PPC_STORE_U32(r11.u32 + 1576, temp.u32);
	// stw r8,1572(r11)
	PPC_STORE_U32(r11.u32 + 1572, ctx.r8.u32);
	// stfs f0,1580(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1580, temp.u32);
	// stfs f11,1584(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r11.u32 + 1584, temp.u32);
	// stw r6,1588(r11)
	PPC_STORE_U32(r11.u32 + 1588, ctx.r6.u32);
	// stw r10,1592(r11)
	PPC_STORE_U32(r11.u32 + 1592, ctx.r10.u32);
	// li r8,49
	ctx.r8.s64 = 49;
	// stw r5,1596(r11)
	PPC_STORE_U32(r11.u32 + 1596, ctx.r5.u32);
	// lis r3,-32034
	ctx.r3.s64 = -2099380224;
	// stw r7,1600(r11)
	PPC_STORE_U32(r11.u32 + 1600, ctx.r7.u32);
	// lis r31,-32096
	r31.s64 = -2103443456;
	// stw r10,1604(r11)
	PPC_STORE_U32(r11.u32 + 1604, ctx.r10.u32);
	// addi r3,r3,20984
	ctx.r3.s64 = ctx.r3.s64 + 20984;
	// stw r10,1608(r11)
	PPC_STORE_U32(r11.u32 + 1608, ctx.r10.u32);
	// addi r31,r31,-8320
	r31.s64 = r31.s64 + -8320;
	// stw r10,1612(r11)
	PPC_STORE_U32(r11.u32 + 1612, ctx.r10.u32);
	// stw r10,1616(r11)
	PPC_STORE_U32(r11.u32 + 1616, ctx.r10.u32);
	// stw r10,1620(r11)
	PPC_STORE_U32(r11.u32 + 1620, ctx.r10.u32);
	// stw r8,1624(r11)
	PPC_STORE_U32(r11.u32 + 1624, ctx.r8.u32);
	// stfs f13,1632(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1632, temp.u32);
	// stw r9,1628(r11)
	PPC_STORE_U32(r11.u32 + 1628, ctx.r9.u32);
	// stfs f0,1636(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1636, temp.u32);
	// stfs f12,1640(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 1640, temp.u32);
	// stw r10,1644(r11)
	PPC_STORE_U32(r11.u32 + 1644, ctx.r10.u32);
	// stw r10,1648(r11)
	PPC_STORE_U32(r11.u32 + 1648, ctx.r10.u32);
	// li r8,50
	ctx.r8.s64 = 50;
	// stw r10,1652(r11)
	PPC_STORE_U32(r11.u32 + 1652, ctx.r10.u32);
	// stw r10,1656(r11)
	PPC_STORE_U32(r11.u32 + 1656, ctx.r10.u32);
	// stw r10,1660(r11)
	PPC_STORE_U32(r11.u32 + 1660, ctx.r10.u32);
	// stw r10,1664(r11)
	PPC_STORE_U32(r11.u32 + 1664, ctx.r10.u32);
	// stw r10,1668(r11)
	PPC_STORE_U32(r11.u32 + 1668, ctx.r10.u32);
	// stw r10,1672(r11)
	PPC_STORE_U32(r11.u32 + 1672, ctx.r10.u32);
	// stw r10,1676(r11)
	PPC_STORE_U32(r11.u32 + 1676, ctx.r10.u32);
	// stw r8,1680(r11)
	PPC_STORE_U32(r11.u32 + 1680, ctx.r8.u32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// lfs f11,27700(r8)
	temp.u32 = PPC_LOAD_U32(ctx.r8.u32 + 27700);
	ctx.f11.f64 = double(temp.f32);
	// lis r8,-32130
	ctx.r8.s64 = -2105671680;
	// stfs f11,1688(r11)
	temp.f32 = float(ctx.f11.f64);
	PPC_STORE_U32(r11.u32 + 1688, temp.u32);
	// stw r4,1684(r11)
	PPC_STORE_U32(r11.u32 + 1684, ctx.r4.u32);
	// stfs f0,1692(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1692, temp.u32);
	// stfs f12,1696(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 1696, temp.u32);
	// lwz r8,8904(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + 8904);
	// stw r8,1700(r11)
	PPC_STORE_U32(r11.u32 + 1700, ctx.r8.u32);
	// li r8,51
	ctx.r8.s64 = 51;
	// stw r10,1704(r11)
	PPC_STORE_U32(r11.u32 + 1704, ctx.r10.u32);
	// stw r3,1708(r11)
	PPC_STORE_U32(r11.u32 + 1708, ctx.r3.u32);
	// stw r31,1712(r11)
	PPC_STORE_U32(r11.u32 + 1712, r31.u32);
	// stw r10,1716(r11)
	PPC_STORE_U32(r11.u32 + 1716, ctx.r10.u32);
	// stw r10,1720(r11)
	PPC_STORE_U32(r11.u32 + 1720, ctx.r10.u32);
	// stw r10,1724(r11)
	PPC_STORE_U32(r11.u32 + 1724, ctx.r10.u32);
	// stw r10,1728(r11)
	PPC_STORE_U32(r11.u32 + 1728, ctx.r10.u32);
	// stw r10,1732(r11)
	PPC_STORE_U32(r11.u32 + 1732, ctx.r10.u32);
	// stfs f13,1744(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1744, temp.u32);
	// stfs f0,1748(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1748, temp.u32);
	// stfs f12,1752(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 1752, temp.u32);
	// stw r8,1736(r11)
	PPC_STORE_U32(r11.u32 + 1736, ctx.r8.u32);
	// stw r9,1740(r11)
	PPC_STORE_U32(r11.u32 + 1740, ctx.r9.u32);
	// lis r8,-32256
	ctx.r8.s64 = -2113929216;
	// stw r10,1756(r11)
	PPC_STORE_U32(r11.u32 + 1756, ctx.r10.u32);
	// stw r10,1760(r11)
	PPC_STORE_U32(r11.u32 + 1760, ctx.r10.u32);
	// addi r8,r8,27684
	ctx.r8.s64 = ctx.r8.s64 + 27684;
	// stw r10,1764(r11)
	PPC_STORE_U32(r11.u32 + 1764, ctx.r10.u32);
	// stw r10,1768(r11)
	PPC_STORE_U32(r11.u32 + 1768, ctx.r10.u32);
	// stw r10,1772(r11)
	PPC_STORE_U32(r11.u32 + 1772, ctx.r10.u32);
	// stw r10,1776(r11)
	PPC_STORE_U32(r11.u32 + 1776, ctx.r10.u32);
	// stw r10,1780(r11)
	PPC_STORE_U32(r11.u32 + 1780, ctx.r10.u32);
	// li r5,52
	ctx.r5.s64 = 52;
	// stw r10,1784(r11)
	PPC_STORE_U32(r11.u32 + 1784, ctx.r10.u32);
	// lis r7,-32044
	ctx.r7.s64 = -2100035584;
	// stw r10,1788(r11)
	PPC_STORE_U32(r11.u32 + 1788, ctx.r10.u32);
	// lis r6,-32096
	ctx.r6.s64 = -2103443456;
	// addi r7,r7,26776
	ctx.r7.s64 = ctx.r7.s64 + 26776;
	// stw r5,1792(r11)
	PPC_STORE_U32(r11.u32 + 1792, ctx.r5.u32);
	// stfs f13,1800(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1800, temp.u32);
	// stw r9,1796(r11)
	PPC_STORE_U32(r11.u32 + 1796, ctx.r9.u32);
	// stfs f0,1804(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1804, temp.u32);
	// stfs f12,1808(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 1808, temp.u32);
	// stw r10,1812(r11)
	PPC_STORE_U32(r11.u32 + 1812, ctx.r10.u32);
	// stw r10,1816(r11)
	PPC_STORE_U32(r11.u32 + 1816, ctx.r10.u32);
	// li r5,53
	ctx.r5.s64 = 53;
	// stw r10,1820(r11)
	PPC_STORE_U32(r11.u32 + 1820, ctx.r10.u32);
	// addi r6,r6,-12320
	ctx.r6.s64 = ctx.r6.s64 + -12320;
	// stw r10,1824(r11)
	PPC_STORE_U32(r11.u32 + 1824, ctx.r10.u32);
	// stw r10,1828(r11)
	PPC_STORE_U32(r11.u32 + 1828, ctx.r10.u32);
	// stw r10,1832(r11)
	PPC_STORE_U32(r11.u32 + 1832, ctx.r10.u32);
	// stw r10,1836(r11)
	PPC_STORE_U32(r11.u32 + 1836, ctx.r10.u32);
	// stw r10,1840(r11)
	PPC_STORE_U32(r11.u32 + 1840, ctx.r10.u32);
	// stw r10,1844(r11)
	PPC_STORE_U32(r11.u32 + 1844, ctx.r10.u32);
	// stw r5,1848(r11)
	PPC_STORE_U32(r11.u32 + 1848, ctx.r5.u32);
	// stfs f13,1856(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1856, temp.u32);
	// stw r9,1852(r11)
	PPC_STORE_U32(r11.u32 + 1852, ctx.r9.u32);
	// stfs f0,1860(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1860, temp.u32);
	// stfs f12,1864(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 1864, temp.u32);
	// stw r10,1868(r11)
	PPC_STORE_U32(r11.u32 + 1868, ctx.r10.u32);
	// stw r10,1872(r11)
	PPC_STORE_U32(r11.u32 + 1872, ctx.r10.u32);
	// li r5,54
	ctx.r5.s64 = 54;
	// stw r10,1876(r11)
	PPC_STORE_U32(r11.u32 + 1876, ctx.r10.u32);
	// stw r10,1880(r11)
	PPC_STORE_U32(r11.u32 + 1880, ctx.r10.u32);
	// stw r10,1884(r11)
	PPC_STORE_U32(r11.u32 + 1884, ctx.r10.u32);
	// stw r10,1888(r11)
	PPC_STORE_U32(r11.u32 + 1888, ctx.r10.u32);
	// stw r10,1892(r11)
	PPC_STORE_U32(r11.u32 + 1892, ctx.r10.u32);
	// stw r10,1896(r11)
	PPC_STORE_U32(r11.u32 + 1896, ctx.r10.u32);
	// stw r10,1900(r11)
	PPC_STORE_U32(r11.u32 + 1900, ctx.r10.u32);
	// stw r5,1904(r11)
	PPC_STORE_U32(r11.u32 + 1904, ctx.r5.u32);
	// stfs f8,1912(r11)
	temp.f32 = float(ctx.f8.f64);
	PPC_STORE_U32(r11.u32 + 1912, temp.u32);
	// stw r8,1908(r11)
	PPC_STORE_U32(r11.u32 + 1908, ctx.r8.u32);
	// lis r8,-32130
	ctx.r8.s64 = -2105671680;
	// stfs f0,1916(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1916, temp.u32);
	// stfs f7,1920(r11)
	temp.f32 = float(ctx.f7.f64);
	PPC_STORE_U32(r11.u32 + 1920, temp.u32);
	// lwz r8,-6960(r8)
	ctx.r8.u64 = PPC_LOAD_U32(ctx.r8.u32 + -6960);
	// stw r8,1924(r11)
	PPC_STORE_U32(r11.u32 + 1924, ctx.r8.u32);
	// li r8,55
	ctx.r8.s64 = 55;
	// stw r7,1928(r11)
	PPC_STORE_U32(r11.u32 + 1928, ctx.r7.u32);
	// stw r10,1932(r11)
	PPC_STORE_U32(r11.u32 + 1932, ctx.r10.u32);
	// stw r6,1936(r11)
	PPC_STORE_U32(r11.u32 + 1936, ctx.r6.u32);
	// stw r10,1940(r11)
	PPC_STORE_U32(r11.u32 + 1940, ctx.r10.u32);
	// stw r10,1944(r11)
	PPC_STORE_U32(r11.u32 + 1944, ctx.r10.u32);
	// stw r10,1948(r11)
	PPC_STORE_U32(r11.u32 + 1948, ctx.r10.u32);
	// stw r10,1952(r11)
	PPC_STORE_U32(r11.u32 + 1952, ctx.r10.u32);
	// stw r10,1956(r11)
	PPC_STORE_U32(r11.u32 + 1956, ctx.r10.u32);
	// stw r8,1960(r11)
	PPC_STORE_U32(r11.u32 + 1960, ctx.r8.u32);
	// stfs f13,1968(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 1968, temp.u32);
	// stw r9,1964(r11)
	PPC_STORE_U32(r11.u32 + 1964, ctx.r9.u32);
	// stfs f0,1972(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 1972, temp.u32);
	// stfs f12,1976(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 1976, temp.u32);
	// stw r10,1980(r11)
	PPC_STORE_U32(r11.u32 + 1980, ctx.r10.u32);
	// stw r10,1984(r11)
	PPC_STORE_U32(r11.u32 + 1984, ctx.r10.u32);
	// li r8,56
	ctx.r8.s64 = 56;
	// stw r10,1988(r11)
	PPC_STORE_U32(r11.u32 + 1988, ctx.r10.u32);
	// stw r10,1992(r11)
	PPC_STORE_U32(r11.u32 + 1992, ctx.r10.u32);
	// stw r10,1996(r11)
	PPC_STORE_U32(r11.u32 + 1996, ctx.r10.u32);
	// stw r10,2000(r11)
	PPC_STORE_U32(r11.u32 + 2000, ctx.r10.u32);
	// stw r10,2004(r11)
	PPC_STORE_U32(r11.u32 + 2004, ctx.r10.u32);
	// stw r10,2008(r11)
	PPC_STORE_U32(r11.u32 + 2008, ctx.r10.u32);
	// stw r10,2012(r11)
	PPC_STORE_U32(r11.u32 + 2012, ctx.r10.u32);
	// stw r8,2016(r11)
	PPC_STORE_U32(r11.u32 + 2016, ctx.r8.u32);
	// stfs f13,2024(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 2024, temp.u32);
	// stw r9,2020(r11)
	PPC_STORE_U32(r11.u32 + 2020, ctx.r9.u32);
	// stfs f0,2028(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2028, temp.u32);
	// stfs f12,2032(r11)
	temp.f32 = float(ctx.f12.f64);
	PPC_STORE_U32(r11.u32 + 2032, temp.u32);
	// stw r10,2036(r11)
	PPC_STORE_U32(r11.u32 + 2036, ctx.r10.u32);
	// stw r10,2040(r11)
	PPC_STORE_U32(r11.u32 + 2040, ctx.r10.u32);
	// li r8,57
	ctx.r8.s64 = 57;
	// stw r10,2044(r11)
	PPC_STORE_U32(r11.u32 + 2044, ctx.r10.u32);
	// stw r10,2048(r11)
	PPC_STORE_U32(r11.u32 + 2048, ctx.r10.u32);
	// stw r10,2052(r11)
	PPC_STORE_U32(r11.u32 + 2052, ctx.r10.u32);
	// stw r10,2056(r11)
	PPC_STORE_U32(r11.u32 + 2056, ctx.r10.u32);
	// stw r10,2060(r11)
	PPC_STORE_U32(r11.u32 + 2060, ctx.r10.u32);
	// stw r10,2064(r11)
	PPC_STORE_U32(r11.u32 + 2064, ctx.r10.u32);
	// stw r10,2068(r11)
	PPC_STORE_U32(r11.u32 + 2068, ctx.r10.u32);
	// stw r8,2072(r11)
	PPC_STORE_U32(r11.u32 + 2072, ctx.r8.u32);
	// stfs f13,2080(r11)
	temp.f32 = float(ctx.f13.f64);
	PPC_STORE_U32(r11.u32 + 2080, temp.u32);
	// stw r9,2076(r11)
	PPC_STORE_U32(r11.u32 + 2076, ctx.r9.u32);
	// stfs f0,2084(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2084, temp.u32);
	// stfs f0,2088(r11)
	temp.f32 = float(f0.f64);
	PPC_STORE_U32(r11.u32 + 2088, temp.u32);
	// stw r10,2092(r11)
	PPC_STORE_U32(r11.u32 + 2092, ctx.r10.u32);
	// stw r10,2096(r11)
	PPC_STORE_U32(r11.u32 + 2096, ctx.r10.u32);
	// stw r10,2100(r11)
	PPC_STORE_U32(r11.u32 + 2100, ctx.r10.u32);
	// stw r10,2104(r11)
	PPC_STORE_U32(r11.u32 + 2104, ctx.r10.u32);
	// stw r10,2108(r11)
	PPC_STORE_U32(r11.u32 + 2108, ctx.r10.u32);
	// stw r10,2112(r11)
	PPC_STORE_U32(r11.u32 + 2112, ctx.r10.u32);
	// stw r10,2116(r11)
	PPC_STORE_U32(r11.u32 + 2116, ctx.r10.u32);
	// stw r10,2120(r11)
	PPC_STORE_U32(r11.u32 + 2120, ctx.r10.u32);
	// stw r10,2124(r11)
	PPC_STORE_U32(r11.u32 + 2124, ctx.r10.u32);
	// b 0x823ed184
	return;
}

__attribute__((alias("__imp__sub_8240D130"))) PPC_WEAK_FUNC(sub_8240D130);
PPC_FUNC_IMPL(__imp__sub_8240D130) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31993
	r11.s64 = -2096693248;
	// li r4,1
	ctx.r4.s64 = 1;
	// addi r31,r11,29036
	r31.s64 = r11.s64 + 29036;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82178d10
	sub_82178D10(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// lis r10,-32191
	ctx.r10.s64 = -2109669376;
	// addi r11,r11,-30696
	r11.s64 = r11.s64 + -30696;
	// addi r3,r10,-4512
	ctx.r3.s64 = ctx.r10.s64 + -4512;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D180"))) PPC_WEAK_FUNC(sub_8240D180);
PPC_FUNC_IMPL(__imp__sub_8240D180) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32235
	r11.s64 = -2112552960;
	// addi r5,r10,-30264
	ctx.r5.s64 = ctx.r10.s64 + -30264;
	// lis r10,-31993
	ctx.r10.s64 = -2096693248;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,29076
	ctx.r3.s64 = ctx.r10.s64 + 29076;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-10960
	ctx.r6.s64 = r11.s64 + -10960;
	// li r4,88
	ctx.r4.s64 = 88;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4488
	ctx.r3.s64 = r11.s64 + -4488;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D1D0"))) PPC_WEAK_FUNC(sub_8240D1D0);
PPC_FUNC_IMPL(__imp__sub_8240D1D0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4472
	ctx.r3.s64 = r11.s64 + -4472;
	// b 0x823edef0
	sub_823EDEF0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8240D1E0"))) PPC_WEAK_FUNC(sub_8240D1E0);
PPC_FUNC_IMPL(__imp__sub_8240D1E0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31993
	r11.s64 = -2096693248;
	// li r4,0
	ctx.r4.s64 = 0;
	// addi r31,r11,29104
	r31.s64 = r11.s64 + 29104;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82178d10
	sub_82178D10(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// lis r10,-32191
	ctx.r10.s64 = -2109669376;
	// addi r11,r11,-30052
	r11.s64 = r11.s64 + -30052;
	// addi r3,r10,-4448
	ctx.r3.s64 = ctx.r10.s64 + -4448;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D230"))) PPC_WEAK_FUNC(sub_8240D230);
PPC_FUNC_IMPL(__imp__sub_8240D230) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31993
	r11.s64 = -2096693248;
	// addi r3,r11,29116
	ctx.r3.s64 = r11.s64 + 29116;
	// bl 0x821504e8
	sub_821504E8(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4424
	ctx.r3.s64 = r11.s64 + -4424;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D268"))) PPC_WEAK_FUNC(sub_8240D268);
PPC_FUNC_IMPL(__imp__sub_8240D268) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	PPCRegister r31{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// std r31,-16(r1)
	PPC_STORE_U64(ctx.r1.u32 + -16, r31.u64);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31992
	r11.s64 = -2096627712;
	// li r4,2
	ctx.r4.s64 = 2;
	// addi r31,r11,-30132
	r31.s64 = r11.s64 + -30132;
	// mr r3,r31
	ctx.r3.u64 = r31.u64;
	// bl 0x82178d10
	sub_82178D10(ctx, base);
	// lis r11,-32254
	r11.s64 = -2113798144;
	// lis r10,-32191
	ctx.r10.s64 = -2109669376;
	// addi r11,r11,-29956
	r11.s64 = r11.s64 + -29956;
	// addi r3,r10,-4408
	ctx.r3.s64 = ctx.r10.s64 + -4408;
	// stw r11,0(r31)
	PPC_STORE_U32(r31.u32 + 0, r11.u32);
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// ld r31,-16(r1)
	r31.u64 = PPC_LOAD_U64(ctx.r1.u32 + -16);
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D2B8"))) PPC_WEAK_FUNC(sub_8240D2B8);
PPC_FUNC_IMPL(__imp__sub_8240D2B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31992
	r11.s64 = -2096627712;
	// addi r3,r11,-30092
	ctx.r3.s64 = r11.s64 + -30092;
	// bl 0x82150f40
	sub_82150F40(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4384
	ctx.r3.s64 = r11.s64 + -4384;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D2F0"))) PPC_WEAK_FUNC(sub_8240D2F0);
PPC_FUNC_IMPL(__imp__sub_8240D2F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31992
	r11.s64 = -2096627712;
	// addi r3,r11,-30192
	ctx.r3.s64 = r11.s64 + -30192;
	// bl 0x8216b7b0
	sub_8216B7B0(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4368
	ctx.r3.s64 = r11.s64 + -4368;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D328"))) PPC_WEAK_FUNC(sub_8240D328);
PPC_FUNC_IMPL(__imp__sub_8240D328) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31992
	r11.s64 = -2096627712;
	// li r5,128
	ctx.r5.s64 = 128;
	// addi r3,r11,-30220
	ctx.r3.s64 = r11.s64 + -30220;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8216a7a0
	sub_8216A7A0(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4352
	ctx.r3.s64 = r11.s64 + -4352;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D368"))) PPC_WEAK_FUNC(sub_8240D368);
PPC_FUNC_IMPL(__imp__sub_8240D368) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31992
	r11.s64 = -2096627712;
	// li r5,8
	ctx.r5.s64 = 8;
	// addi r3,r11,-30120
	ctx.r3.s64 = r11.s64 + -30120;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8216a7a0
	sub_8216A7A0(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4336
	ctx.r3.s64 = r11.s64 + -4336;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D3A8"))) PPC_WEAK_FUNC(sub_8240D3A8);
PPC_FUNC_IMPL(__imp__sub_8240D3A8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31992
	r11.s64 = -2096627712;
	// addi r3,r11,-29352
	ctx.r3.s64 = r11.s64 + -29352;
	// lis r11,-32254
	r11.s64 = -2113798144;
	// lwz r4,-26148(r11)
	ctx.r4.u64 = PPC_LOAD_U32(r11.u32 + -26148);
	// bl 0x82156960
	sub_82156960(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4320
	ctx.r3.s64 = r11.s64 + -4320;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D3E8"))) PPC_WEAK_FUNC(sub_8240D3E8);
PPC_FUNC_IMPL(__imp__sub_8240D3E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31992
	r11.s64 = -2096627712;
	// addi r3,r11,-29440
	ctx.r3.s64 = r11.s64 + -29440;
	// bl 0x8216b7b0
	sub_8216B7B0(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4304
	ctx.r3.s64 = r11.s64 + -4304;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D420"))) PPC_WEAK_FUNC(sub_8240D420);
PPC_FUNC_IMPL(__imp__sub_8240D420) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31992
	r11.s64 = -2096627712;
	// li r5,128
	ctx.r5.s64 = 128;
	// addi r3,r11,-29380
	ctx.r3.s64 = r11.s64 + -29380;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8216a7a0
	sub_8216A7A0(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4288
	ctx.r3.s64 = r11.s64 + -4288;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D460"))) PPC_WEAK_FUNC(sub_8240D460);
PPC_FUNC_IMPL(__imp__sub_8240D460) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-28856
	ctx.r5.s64 = ctx.r10.s64 + -28856;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,-28156
	ctx.r3.s64 = ctx.r10.s64 + -28156;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-24064
	ctx.r6.s64 = r11.s64 + -24064;
	// li r4,18
	ctx.r4.s64 = 18;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4272
	ctx.r3.s64 = r11.s64 + -4272;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D4B0"))) PPC_WEAK_FUNC(sub_8240D4B0);
PPC_FUNC_IMPL(__imp__sub_8240D4B0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-28848
	ctx.r5.s64 = ctx.r10.s64 + -28848;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,-28108
	ctx.r3.s64 = ctx.r10.s64 + -28108;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-23320
	ctx.r6.s64 = r11.s64 + -23320;
	// li r4,20
	ctx.r4.s64 = 20;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4256
	ctx.r3.s64 = r11.s64 + -4256;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D500"))) PPC_WEAK_FUNC(sub_8240D500);
PPC_FUNC_IMPL(__imp__sub_8240D500) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-28832
	ctx.r5.s64 = ctx.r10.s64 + -28832;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,-28204
	ctx.r3.s64 = ctx.r10.s64 + -28204;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-22904
	ctx.r6.s64 = r11.s64 + -22904;
	// li r4,21
	ctx.r4.s64 = 21;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4240
	ctx.r3.s64 = r11.s64 + -4240;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D550"))) PPC_WEAK_FUNC(sub_8240D550);
PPC_FUNC_IMPL(__imp__sub_8240D550) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-28820
	ctx.r5.s64 = ctx.r10.s64 + -28820;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,-28084
	ctx.r3.s64 = ctx.r10.s64 + -28084;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-21920
	ctx.r6.s64 = r11.s64 + -21920;
	// li r4,22
	ctx.r4.s64 = 22;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4224
	ctx.r3.s64 = r11.s64 + -4224;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D5A0"))) PPC_WEAK_FUNC(sub_8240D5A0);
PPC_FUNC_IMPL(__imp__sub_8240D5A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-28804
	ctx.r5.s64 = ctx.r10.s64 + -28804;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,-28180
	ctx.r3.s64 = ctx.r10.s64 + -28180;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-19128
	ctx.r6.s64 = r11.s64 + -19128;
	// li r4,77
	ctx.r4.s64 = 77;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4208
	ctx.r3.s64 = r11.s64 + -4208;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D5F0"))) PPC_WEAK_FUNC(sub_8240D5F0);
PPC_FUNC_IMPL(__imp__sub_8240D5F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-28788
	ctx.r5.s64 = ctx.r10.s64 + -28788;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,-28132
	ctx.r3.s64 = ctx.r10.s64 + -28132;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-20864
	ctx.r6.s64 = r11.s64 + -20864;
	// li r4,23
	ctx.r4.s64 = 23;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4192
	ctx.r3.s64 = r11.s64 + -4192;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D640"))) PPC_WEAK_FUNC(sub_8240D640);
PPC_FUNC_IMPL(__imp__sub_8240D640) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4176
	ctx.r3.s64 = r11.s64 + -4176;
	// b 0x823edef0
	sub_823EDEF0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8240D650"))) PPC_WEAK_FUNC(sub_8240D650);
PPC_FUNC_IMPL(__imp__sub_8240D650) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-28608
	ctx.r5.s64 = ctx.r10.s64 + -28608;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,-28024
	ctx.r3.s64 = ctx.r10.s64 + -28024;
	// li r7,4
	ctx.r7.s64 = 4;
	// addi r6,r11,-16216
	ctx.r6.s64 = r11.s64 + -16216;
	// li r4,80
	ctx.r4.s64 = 80;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4080
	ctx.r3.s64 = r11.s64 + -4080;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D6A0"))) PPC_WEAK_FUNC(sub_8240D6A0);
PPC_FUNC_IMPL(__imp__sub_8240D6A0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-28592
	ctx.r5.s64 = ctx.r10.s64 + -28592;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,-28048
	ctx.r3.s64 = ctx.r10.s64 + -28048;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-15888
	ctx.r6.s64 = r11.s64 + -15888;
	// li r4,81
	ctx.r4.s64 = 81;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4064
	ctx.r3.s64 = r11.s64 + -4064;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D6F0"))) PPC_WEAK_FUNC(sub_8240D6F0);
PPC_FUNC_IMPL(__imp__sub_8240D6F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister ctr{};
	PPCXERRegister xer{};
	PPCCRRegister cr6{};
	PPCRegister r11{};
	// lis r11,-31992
	r11.s64 = -2096627712;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r10,r11,-26968
	ctx.r10.s64 = r11.s64 + -26968;
	// addi r11,r10,260
	r11.s64 = ctx.r10.s64 + 260;
loc_8240D700:
	// stb r7,0(r11)
	PPC_STORE_U8(r11.u32 + 0, ctx.r7.u8);
	// addi r9,r10,420
	ctx.r9.s64 = ctx.r10.s64 + 420;
	// addi r11,r11,16
	r11.s64 = r11.s64 + 16;
	// cmpw cr6,r11,r9
	cr6.compare<int32_t>(r11.s32, ctx.r9.s32, xer);
	// blt cr6,0x8240d700
	if (cr6.getLT()) goto loc_8240D700;
	// li r9,-1
	ctx.r9.s64 = -1;
	// mr r11,r10
	r11.u64 = ctx.r10.u64;
	// li r8,64
	ctx.r8.s64 = 64;
	// mtctr r8
	ctr.u64 = ctx.r8.u64;
loc_8240D724:
	// stw r9,0(r11)
	PPC_STORE_U32(r11.u32 + 0, ctx.r9.u32);
	// addi r11,r11,4
	r11.s64 = r11.s64 + 4;
	// bdnz 0x8240d724
	--ctr.u64;
	if (ctr.u32 != 0) goto loc_8240D724;
	// mr r11,r7
	r11.u64 = ctx.r7.u64;
	// lis r9,-32191
	ctx.r9.s64 = -2109669376;
	// addi r3,r9,-4032
	ctx.r3.s64 = ctx.r9.s64 + -4032;
	// stw r11,256(r10)
	PPC_STORE_U32(ctx.r10.u32 + 256, r11.u32);
	// b 0x823edef0
	sub_823EDEF0(ctx, base);
	return;
}

__attribute__((alias("__imp__sub_8240D748"))) PPC_WEAK_FUNC(sub_8240D748);
PPC_FUNC_IMPL(__imp__sub_8240D748) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-28496
	ctx.r5.s64 = ctx.r10.s64 + -28496;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,-26548
	ctx.r3.s64 = ctx.r10.s64 + -26548;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-13664
	ctx.r6.s64 = r11.s64 + -13664;
	// li r4,90
	ctx.r4.s64 = 90;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4048
	ctx.r3.s64 = r11.s64 + -4048;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D798"))) PPC_WEAK_FUNC(sub_8240D798);
PPC_FUNC_IMPL(__imp__sub_8240D798) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-28408
	ctx.r5.s64 = ctx.r10.s64 + -28408;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,-26524
	ctx.r3.s64 = ctx.r10.s64 + -26524;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-9024
	ctx.r6.s64 = r11.s64 + -9024;
	// li r4,91
	ctx.r4.s64 = 91;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4024
	ctx.r3.s64 = r11.s64 + -4024;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D7E8"))) PPC_WEAK_FUNC(sub_8240D7E8);
PPC_FUNC_IMPL(__imp__sub_8240D7E8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-28312
	ctx.r5.s64 = ctx.r10.s64 + -28312;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,-26500
	ctx.r3.s64 = ctx.r10.s64 + -26500;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-7512
	ctx.r6.s64 = r11.s64 + -7512;
	// li r4,53
	ctx.r4.s64 = 53;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-4008
	ctx.r3.s64 = r11.s64 + -4008;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D838"))) PPC_WEAK_FUNC(sub_8240D838);
PPC_FUNC_IMPL(__imp__sub_8240D838) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-28120
	ctx.r5.s64 = ctx.r10.s64 + -28120;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r3,r10,-14448
	ctx.r3.s64 = ctx.r10.s64 + -14448;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-6656
	ctx.r6.s64 = r11.s64 + -6656;
	// li r4,3
	ctx.r4.s64 = 3;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-3992
	ctx.r3.s64 = r11.s64 + -3992;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D888"))) PPC_WEAK_FUNC(sub_8240D888);
PPC_FUNC_IMPL(__imp__sub_8240D888) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-28108
	ctx.r5.s64 = ctx.r10.s64 + -28108;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r3,r10,-14424
	ctx.r3.s64 = ctx.r10.s64 + -14424;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-6056
	ctx.r6.s64 = r11.s64 + -6056;
	// li r4,4
	ctx.r4.s64 = 4;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-3976
	ctx.r3.s64 = r11.s64 + -3976;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D8D8"))) PPC_WEAK_FUNC(sub_8240D8D8);
PPC_FUNC_IMPL(__imp__sub_8240D8D8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31992
	r11.s64 = -2096627712;
	// addi r3,r11,-12432
	ctx.r3.s64 = r11.s64 + -12432;
	// bl 0x82155fa8
	sub_82155FA8(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-3960
	ctx.r3.s64 = r11.s64 + -3960;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D910"))) PPC_WEAK_FUNC(sub_8240D910);
PPC_FUNC_IMPL(__imp__sub_8240D910) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31992
	r11.s64 = -2096627712;
	// addi r3,r11,-10416
	ctx.r3.s64 = r11.s64 + -10416;
	// bl 0x82155fa8
	sub_82155FA8(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-3944
	ctx.r3.s64 = r11.s64 + -3944;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D948"))) PPC_WEAK_FUNC(sub_8240D948);
PPC_FUNC_IMPL(__imp__sub_8240D948) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31992
	r11.s64 = -2096627712;
	// addi r3,r11,-14056
	ctx.r3.s64 = r11.s64 + -14056;
	// bl 0x821553f0
	sub_821553F0(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-3928
	ctx.r3.s64 = r11.s64 + -3928;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D980"))) PPC_WEAK_FUNC(sub_8240D980);
PPC_FUNC_IMPL(__imp__sub_8240D980) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31992
	r11.s64 = -2096627712;
	// addi r3,r11,-14096
	ctx.r3.s64 = r11.s64 + -14096;
	// bl 0x82155de0
	sub_82155DE0(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-3912
	ctx.r3.s64 = r11.s64 + -3912;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D9B8"))) PPC_WEAK_FUNC(sub_8240D9B8);
PPC_FUNC_IMPL(__imp__sub_8240D9B8) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r11,-31992
	r11.s64 = -2096627712;
	// addi r3,r11,-8376
	ctx.r3.s64 = r11.s64 + -8376;
	// bl 0x8214cd48
	sub_8214CD48(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-3896
	ctx.r3.s64 = r11.s64 + -3896;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240D9F0"))) PPC_WEAK_FUNC(sub_8240D9F0);
PPC_FUNC_IMPL(__imp__sub_8240D9F0) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-27412
	ctx.r5.s64 = ctx.r10.s64 + -27412;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,-8400
	ctx.r3.s64 = ctx.r10.s64 + -8400;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-2776
	ctx.r6.s64 = r11.s64 + -2776;
	// li r4,0
	ctx.r4.s64 = 0;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-3880
	ctx.r3.s64 = r11.s64 + -3880;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240DA40"))) PPC_WEAK_FUNC(sub_8240DA40);
PPC_FUNC_IMPL(__imp__sub_8240DA40) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-27404
	ctx.r5.s64 = ctx.r10.s64 + -27404;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,0
	ctx.r8.s64 = 0;
	// addi r3,r10,-6176
	ctx.r3.s64 = ctx.r10.s64 + -6176;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-2544
	ctx.r6.s64 = r11.s64 + -2544;
	// li r4,1
	ctx.r4.s64 = 1;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-3864
	ctx.r3.s64 = r11.s64 + -3864;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

__attribute__((alias("__imp__sub_8240DA90"))) PPC_WEAK_FUNC(sub_8240DA90);
PPC_FUNC_IMPL(__imp__sub_8240DA90) {
	PPC_FUNC_PROLOGUE();
	PPCRegister r11{};
	PPCRegister r12{};
	uint32_t ea{};
	// mflr r12
	// stw r12,-8(r1)
	PPC_STORE_U32(ctx.r1.u32 + -8, r12.u32);
	// stwu r1,-96(r1)
	ea = -96 + ctx.r1.u32;
	PPC_STORE_U32(ea, ctx.r1.u32);
	ctx.r1.u32 = ea;
	// lis r10,-32254
	ctx.r10.s64 = -2113798144;
	// lis r11,-32234
	r11.s64 = -2112487424;
	// addi r5,r10,-27396
	ctx.r5.s64 = ctx.r10.s64 + -27396;
	// lis r10,-31992
	ctx.r10.s64 = -2096627712;
	// li r8,1
	ctx.r8.s64 = 1;
	// addi r3,r10,-6200
	ctx.r3.s64 = ctx.r10.s64 + -6200;
	// li r7,0
	ctx.r7.s64 = 0;
	// addi r6,r11,-2392
	ctx.r6.s64 = r11.s64 + -2392;
	// li r4,2
	ctx.r4.s64 = 2;
	// bl 0x8215c868
	sub_8215C868(ctx, base);
	// lis r11,-32191
	r11.s64 = -2109669376;
	// addi r3,r11,-3848
	ctx.r3.s64 = r11.s64 + -3848;
	// bl 0x823edef0
	sub_823EDEF0(ctx, base);
	// addi r1,r1,96
	ctx.r1.s64 = ctx.r1.s64 + 96;
	// lwz r12,-8(r1)
	r12.u64 = PPC_LOAD_U32(ctx.r1.u32 + -8);
	// mtlr r12
	// blr 
	return;
}

